{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/da2985/e6885-adnet/blob/main/reinforce.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c1BWwgpSXW9"
      },
      "source": [
        "### Please use the following two lines to load from Google Drive\n",
        "\n",
        "If your file is not there, upload it to https://drive.google.com/drive/folders/1tsPKyB2E1nW8Qw--kZ9GaeGW2u2-XoV6?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqT6TJ9DLT5v",
        "outputId": "c7535db5-d7ae-4e90-bbf2-71906c02c6fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# This must be run within a Google Colab environment \n",
        "from google.colab import drive  \n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "2sTHMZwqNPlW"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "sys.path.append('/content/gdrive/EE6885')\n",
        "\n",
        "os.chdir(\"/content/gdrive/My Drive/EE6885\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvlhZxrmdezd",
        "outputId": "4dca6cb6-f2eb-4c6a-9e40-c284478ff77a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Basketball   Car24\t Dog1\t      Human5\t     MountainBike   Surfer\n",
            " Bird2\t      Car4\t Doll\t      Human6\t     Panda\t    Suv\n",
            " BlurBody     CarDark\t DragonBaby   Human7\t     RedTeam\t    Sylvester\n",
            " BlurCar1     CarScale\t Dudek\t      Human8\t     Rubik\t    Tiger1\n",
            " BlurCar2     ClifBar\t FaceOcc1     Human9\t     Shaking\t    Tiger2\n",
            " BlurCar3     Coke\t FaceOcc2     Ironman\t     Singer1\t    Toy\n",
            " BlurCar4     Couple\t Fish\t      Jogging\t     Singer2\t    Trans\n",
            " BlurFace     Coupon\t FleetFace    Jump\t     Skater\t    Trellis\n",
            " BlurOwl      Crossing\t Football1    Jumping\t     Skater2\t    Twinnings\n",
            " Board\t      Crowds\t Freeman1     KiteSurf\t    'Skater2 (1)'   Vase\n",
            " Bolt\t      Dancer\t Girl\t      Lemming\t     Skating1\t    Walking\n",
            " Bolt2\t      Dancer2\t Girl2\t      Liquor\t     Skating2\t    Walking2\n",
            " Box\t      David2\t Gym\t      Man\t     Skating3\t    Woman\n",
            " Boy\t      David3\t Human2       Matrix\t     Skiing\n",
            " Car1\t      Deer\t Human3       Mhyang\t     Soccer\n",
            " Car2\t      Dog\t Human4       MotorRolling   Subway\n"
          ]
        }
      ],
      "source": [
        "!ls adnet_datasets/OTB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNOHmxvDD8wD",
        "outputId": "67a52fc3-9c7f-473b-8489-bdc592ab94d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hdf5storage in /usr/local/lib/python3.7/dist-packages (0.1.18)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (0.15.0)\n",
            "Requirement already satisfied: h5py>=2.1 in /usr/local/lib/python3.7/dist-packages (from hdf5storage) (3.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from hdf5storage) (1.19.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.1->hdf5storage) (1.5.2)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n"
          ]
        }
      ],
      "source": [
        "pip install hdf5storage tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "gNmhYpyeDLrQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "import tensorflow_probability as tfp\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow.experimental.numpy as tnp\n",
        "\n",
        "import cv2\n",
        "import glob\n",
        "import hdf5storage\n",
        "import math\n",
        "import random\n",
        "import re\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.patches as patches\n",
        "import scipy.io as sio\n",
        "\n",
        "import linecache\n",
        "\n",
        "from typing import Dict, List, Tuple\n",
        "from operator import add\n",
        "import copy\n",
        "\n",
        "from numpy.random import seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "UsXgP5KrEGNW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb760a91-c799-472b-bc55-6c98749a856e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        " %load_ext autoreload \n",
        " %autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configurations"
      ],
      "metadata": {
        "id": "HdgRU7dpw6t4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "G3xZrSk9XdEA"
      },
      "outputs": [],
      "source": [
        "#@markdown Network configurations\n",
        "LEARNING_RATE = 1e-5 #@param {type:\"number\"}\n",
        "# The length of the action buffer\n",
        "L = 10 #@param {type:\"number\"}\n",
        "# Max Trajectory Length\n",
        "MAX_TRAJECTORY_LENGTH = 20 #@param {type:\"number\"}\n",
        "POLICY_TYPE = \"stochastic\" #@param [\"deterministic\", \"stochastic\"] {type:\"string\"}\n",
        "DROPOUT_4 = 0.5 #@param {type:\"number\"}\n",
        "DROPOUT_5 = 0.5 #@param {type:\"number\"}\n",
        "N_EPOCHS =  1#@param {type:\"number\"}\n",
        "# Number of trajectories to collect w/ same src & target before updating the gradient (only makes sense under stochastic policy)\n",
        "N_TRAJECTORIES =  4#@param {type:\"number\"}\n",
        "RANDOMIZE_TRAINING = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Loss/Reward Constants\n",
        "# This is a probability offset for adding noise since log(P(a|s)=1)=0\n",
        "PROB_OFFSET = 1e-5 #@param {type:\"number\"} \n",
        "# This is the discount factor\n",
        "GAMMA = 0.99 #@param {type:\"number\"}\n",
        "REWARD_SCHEME = \"final_bbox\" #@param [\"final_bbox\", \"individ_bbox\"] {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Bounding Box/Patch Constants (probably avoid touching)\n",
        "ALPHA = 0.03 #@param {type:\"number\"}\n",
        "MIN_WINDOW_SIZE = 10 #@param {type:\"number\"}\n",
        "PATCH_X = 112 #@param {type:\"number\"}\n",
        "PATCH_Y = 112 #@param {type:\"number\"}\n",
        "N_CHANNELS = 3 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown ---\n",
        "RANDOM_SEED = 6885\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed(RANDOM_SEED)\n",
        "tf.random.set_seed(RANDOM_SEED)\n",
        "\n",
        "DATASET_PATH = \"adnet_datasets/OTB/*\" #@param {type:\"string\"}\n",
        "ALL_DATASETS_LIST = glob.glob(DATASET_PATH)"
      ],
      "metadata": {
        "id": "AQ4YPvJCt9Dg"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8s6YHABjUG5"
      },
      "source": [
        "## Model Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfRbj1tuEIyA",
        "outputId": "b1b4eb7b-a215-4a1e-89bf-91c4f5276360"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "class ADNET(tf.keras.Model):\n",
        "\n",
        "    ACTION_DIM = 11\n",
        "    K = 10\n",
        "    CONF_SCORE_DIM = 2\n",
        "\n",
        "    def __init__(self):\n",
        "        super(ADNET, self).__init__()\n",
        "\n",
        "        self.action_history = tf.keras.layers.Input(shape = (1,1, ADNET.ACTION_DIM * ADNET.K))\n",
        "\n",
        "        self.conv1 = tf.keras.layers.Conv2D(filters = 96, kernel_size = (7, 7), strides = (2, 2), padding = 'VALID', activation = 'relu', name = 'conv_1')\n",
        "        self.max1  = tf.keras.layers.MaxPooling2D(pool_size=(3,3), strides = (1, 1), padding = 'VALID')\n",
        "        self.conv2 = tf.keras.layers.Conv2D(filters = 256, kernel_size = (5, 5), strides = (2, 2), padding = 'VALID', activation = 'relu', name = 'conv_2')\n",
        "        self.max2  = tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides = (2, 2), padding = 'VALID')\n",
        "        self.conv3 = tf.keras.layers.Conv2D(filters = 512, kernel_size = (3, 3), strides = (2, 2), padding = 'VALID', activation = 'relu', name = 'conv_3')\n",
        "        self.max3  = tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides = (1, 1), padding = 'VALID')\n",
        "        \n",
        "        self.fc1 = tf.keras.layers.Conv2D(filters = 512, kernel_size = (3, 3), padding = 'VALID', activation = 'relu', name = 'fc1')\n",
        "        self.fc2 = tf.keras.layers.Conv2D(filters = 512, kernel_size = (1,1), padding = 'VALID', activation = 'relu', name = 'fc2')\n",
        "        self.fc3 = tf.keras.layers.Conv2D(filters = 11, kernel_size = (1,1), padding = 'VALID', name = 'fc3',activation=\"softmax\")\n",
        "        self.fc4 = tf.keras.layers.Conv2D(filters = 2, kernel_size = (1,1), padding = 'VALID', name = 'fc4',activation=\"softmax\")\n",
        "\n",
        "        # TODO: ADD A SEED\n",
        "        self.dropout1=tf.keras.layers.Dropout(DROPOUT_4)\n",
        "        self.dropout2=tf.keras.layers.Dropout(DROPOUT_5)\n",
        "        \n",
        "\n",
        "    def build(self):\n",
        "      super(ADNET, self).build((None, 112, 112, 3))\n",
        "      self.action_history = np.zeros(shape = (1,1,1,110))\n",
        "\n",
        "\n",
        "    def call(self, input_tensor, training=False):\n",
        "        x = self.conv1(input_tensor)\n",
        "        x = self.max1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.max2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.max3(x)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = tf.keras.layers.Concatenate(axis=-1)([x, self.action_history])\n",
        "        action = self.fc3(x)\n",
        "        confidence = self.fc4(x)\n",
        "        return [action, confidence]\n",
        "\n",
        "\n",
        "    def compile(self, optimizer):\n",
        "   \t\tsuper().compile(optimizer, loss={\n",
        "         'output_1':tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "         'output_2': tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "         })\n",
        "     \n",
        "    def getEmbedding(self,input_tensor):\n",
        "        x = self.conv1(input_tensor)\n",
        "        x = self.max1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.max2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.max3(x)\n",
        "        return tf.reshape(x,(-1,))\n",
        "\n",
        "    def getFC1(self,input_tensor):\n",
        "        x = self.conv1(input_tensor)\n",
        "        x = self.max1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.max2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.max3(x)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "    def setActionHistory(self, action_history):\n",
        "      self.action_history = action_history.reshape(\n",
        "          (1, 1, 1, ADNET.ACTION_DIM * ADNET.K))\n",
        "\n",
        "    def updateActionHistory(self, a: int=8) -> tnp.ndarray:\n",
        "      '''\n",
        "      Left-to-right FIFO queue of actions\n",
        "      '''\n",
        "      ah = np.array(self.action_history).flatten()\n",
        "      ah[ADNET.ACTION_DIM:] = ah[:-ADNET.ACTION_DIM]\n",
        "      ah[:ADNET.ACTION_DIM] = 0 \n",
        "      ah[a] = 1\n",
        "      self.setActionHistory(ah)\n",
        "      return ah\n",
        "\n",
        "    def clearActionHistory(self):\n",
        "      self.action_history = tf.zeros((1, 1, 1, ADNET.ACTION_DIM * ADNET.K))\n",
        "\n",
        "    def getPrettyActionHistory(self):\n",
        "      action_hist = tf.reshape(model.action_history, [-1])\n",
        "      sbuffer = \"[\"\n",
        "      for i, x in enumerate(action_hist):\n",
        "        if i > 0 and i % model.ACTION_DIM == 0:\n",
        "          sbuffer+= \"\\x1b[35m,\\x1b[0m\"\n",
        "        if x == 1:\n",
        "          sbuffer += \"\\x1b[35m{0}\\x1b[0m\".format(int(x))\n",
        "        else:\n",
        "          sbuffer += \"{0}\".format(int(x))\n",
        "      sbuffer += \"]\"\n",
        "      return sbuffer \n",
        "\n",
        "\n",
        "    def debugModelSummary(self):\n",
        "      '''\n",
        "      call model.debugModelSummary().summary() to get around the inconvenience \n",
        "      from model.summary() returning 'multiple' for each layer's output shape\n",
        "      '''\n",
        "      dummyInput = tf.keras.layers.Input(shape = (112,112,3))\n",
        "      return tf.keras.Model(inputs=[dummyInput], outputs = self.call(dummyInput))\n",
        "\n",
        "def setWeights(model, weights, weights2):\n",
        "  model.layers[0].set_weights([weights2[\"conv1f\"],tf.reshape(weights2[\"conv1b\"],(96,))])\n",
        "  model.layers[2].set_weights([weights2[\"conv2f\"],tf.reshape(weights2[\"conv2b\"],(256,))])\n",
        "  model.layers[4].set_weights([weights2[\"conv3f\"],tf.reshape(weights2[\"conv3b\"],(512,))])\n",
        "  \n",
        "  model.layers[6].set_weights([weights[\"fc4f\"],tf.reshape(weights[\"fc4b\"],(512,))])\n",
        "  model.layers[7].set_weights([weights[\"fc5f\"],tf.reshape(weights[\"fc5b\"],(512,))])\n",
        "  model.layers[8].set_weights([weights[\"fc6_1f\"],tf.zeros(11)])\n",
        "  model.layers[9].set_weights([weights[\"fc6_2f\"],tf.zeros(2)])\n",
        "  \n",
        "  return model\n",
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "WwHHmGrxq-b6"
      },
      "outputs": [],
      "source": [
        "class ADNET_v2(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(ADNET_v2, self).__init__()\n",
        "\n",
        "        #self.action_history = tf.keras.layers.Input(shape = (1,1,110))\n",
        "        self.action_history = tf.keras.layers.Input(shape = (110))\n",
        "\n",
        "        self.resnet=tf.keras.applications.ResNet50V2(include_top=False,weights=\"imagenet\",input_shape=(112,112,3),pooling=\"max\")\n",
        "        #self.resnet = tf.keras.applications.ResNet50V2(include_top=False,weights=\"imagenet\",input_shape=(112,112,3),pooling=None)\n",
        "        #self.conv1 = tf.keras.layers.Conv2D(filters = 128, kernel_size = (4,4), padding = 'VALID', name = 'fc4',activation=\"relu\")\n",
        "        \n",
        "        self.fc1 = tf.keras.layers.Dense(512,kernel_initializer='glorot_uniform',activation = 'relu', name = 'fc1')\n",
        "        self.fc2 = tf.keras.layers.Dense(512,kernel_initializer='glorot_uniform', activation = 'relu', name = 'fc2')\n",
        "        self.fc3 = tf.keras.layers.Dense(11,kernel_initializer='glorot_uniform', name = 'fc3',activation=\"softmax\")\n",
        "        self.fc4 = tf.keras.layers.Dense(2,kernel_initializer='glorot_uniform',name = 'fc4',activation=\"softmax\")\n",
        "\n",
        "        self.dropout1=tf.keras.layers.Dropout(0)\n",
        "        self.dropout2=tf.keras.layers.Dropout(0)\n",
        "        \n",
        "\n",
        "    def build(self, action_history):\n",
        "      super(ADNET_v2, self).build((None, 112, 112, 3))\n",
        "      self.action_history=action_history\n",
        "      self.resnet.trainable = False\n",
        "\n",
        "\n",
        "    def setActionHistory(self, action_history):\n",
        "      self.action_history=action_history\n",
        "\n",
        "\n",
        "    def call(self, input_tensor, training=False):\n",
        "        x = self.resnet(input_tensor)\n",
        "        #x = self.conv1(x)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x=  self.dropout1(x)\n",
        "        x = self.fc2(x)\n",
        "        x=  self.dropout2(x)\n",
        "        x = tf.keras.layers.Concatenate(axis=-1)([x, self.action_history])\n",
        "        action = self.fc3(x)\n",
        "        confidence = self.fc4(x)\n",
        "        return [action, confidence]\n",
        "\n",
        "     \n",
        "    def debugModelSummary(self):\n",
        "      '''\n",
        "      call model.debugModelSummary().summary() to get around the inconvenience \n",
        "      from model.summary() returning 'multiple' for each layer's output shape\n",
        "      '''\n",
        "      dummyInput = tf.keras.layers.Input(shape = (112,112,3))\n",
        "      return tf.keras.Model(inputs=[dummyInput], outputs = self.call(dummyInput))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcjMuA1EjRsE"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xY2WCmjC2gLN"
      },
      "source": [
        "### Plotting & Debugging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "NtQ22_87T8MQ",
        "outputId": "50de84fa-fa71-4a15-b046-1fa371f56165"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[171 128  99 316]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "def get_ground_truths(ground_truth_file: str) -> np.array:\n",
        "  '''\n",
        "  Use me to convert a ground_truth_file to a numpy array\n",
        "  '''\n",
        "  with open(ground_truth_file) as f:\n",
        "    ground_truths = f.readlines()\n",
        "    to_nparray = lambda s: np.array(re.findall('\\d+', s), dtype=int)\n",
        "    truths = list(map(to_nparray, ground_truths))\n",
        "    return np.asarray(truths)\n",
        "  return None\n",
        "\n",
        "def plotNpImageBBox(img: np.array, bbox: np.array) -> np.array:\n",
        "  '''\n",
        "  Plots the bounding box on an image and returns the bounding box\n",
        "  '''\n",
        "  fig, ax = plt.subplots()\n",
        "  x, y, w, h = bbox\n",
        "  rect = patches.Rectangle((x, y), w, h, linewidth=1, edgecolor='r', facecolor='none')\n",
        "  ax.add_patch(rect)\n",
        "  plt.imshow(img)\n",
        "  return bbox\n",
        "\n",
        "def plotNpImageBBoxes(img: np.array, src_bbox: np.array, target_bbox: np.array, \n",
        "                      pred_bbox: np.array) -> np.array:\n",
        "  '''\n",
        "  Plots the bounding boxes on an image and returns the bounding box\n",
        "  '''\n",
        "  fig, ax = plt.subplots()\n",
        "  x1, y1, w1, h1 = src_bbox\n",
        "  x2, y2, w2, h2 = target_bbox\n",
        "  x3, y3, w3, h3 = pred_bbox\n",
        "  rect1 = patches.Rectangle((x1, y1), w1, h1, linewidth=1, edgecolor='b', facecolor='none')\n",
        "  rect2 = patches.Rectangle((x2, y2), w2, h2, linewidth=1, edgecolor='g', facecolor='none')\n",
        "  rect3 = patches.Rectangle((x3, y3), w3, h3, linewidth=1, edgecolor='r', facecolor='none')\n",
        "  ax.add_patch(rect1)\n",
        "  ax.add_patch(rect2)\n",
        "  ax.add_patch(rect3)\n",
        "  plt.imshow(img)\n",
        "  return pred_bbox  \n",
        "\n",
        "def plotImageBBox(img: str, bbox: np.array) -> np.array:\n",
        "  '''\n",
        "  Plots the bounding box on an image (from given filepath) and returns the \n",
        "  bounding box\n",
        "  '''\n",
        "  img = cv2.imread(img)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  plotNpImageBBox(img, bbox)\n",
        "  return bbox\n",
        "\n",
        "def plotDatasetImageBBox(dataset: str, frame_no: int) -> Tuple[np.array, int]:\n",
        "  '''\n",
        "  Plot an image's bounding box. Returns the ground truth and frame number.\n",
        "  WORKS FOR OTB100\n",
        "  '''\n",
        "  imgs = sorted(glob.glob(\"{0}/img/*\".format(dataset)))\n",
        "  gt = get_ground_truths(\"{0}/groundtruth_rect.txt\".format(dataset))\n",
        "  plotImageBBox(imgs[frame_no], gt[frame_no])\n",
        "  return gt[frame_no], frame_no\n",
        "\n",
        "\n",
        "# print(plotDatasetImageBBox(\"adnet_datasets/OTB/Basketball\", 50)[0])\n",
        "print(plotDatasetImageBBox(\"adnet_datasets/OTB/BlurBody\", 10)[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX5bfwFm2c80"
      },
      "source": [
        "### Movement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "VzDdHq04ERNg"
      },
      "outputs": [],
      "source": [
        "STOP_ACTION_INDEX = 8\n",
        "\n",
        "\n",
        "def calculate_IOU(bbox1: np.array, bbox2: np.array):\n",
        "    x1, y1, w1, h1 = bbox1\n",
        "    x2, y2, w2, h2 = bbox2\n",
        "           \n",
        "    i_x1 = max(x1, x2)\n",
        "    i_y1 = max(y1, y2)\n",
        "    i_x2 = min(x1 + w1, x2 + w2)\n",
        "    i_y2 = min(y1 + h1, y2 + h2)\n",
        "    if i_x1 >= i_x2 or i_y1 >= i_y2:\n",
        "      return 0.0\n",
        "\n",
        "    intersection_area = (i_x2 - i_x1) * (i_y2 - i_y1)\n",
        "    box1_area = w1 * h1\n",
        "    box2_area = w2 * h2\n",
        "    \n",
        "    iou = intersection_area / float(box1_area + box2_area - intersection_area)\n",
        "    return iou\n",
        "\n",
        "\n",
        "def move(image: np.array, bbox: np.array, action: str, \n",
        "         stride_magnitude: int=1) -> np.array:\n",
        "  '''\n",
        "  Returns the new bounding box after taking an action: \n",
        "  {\"left\", \"right\", \"up\", \"down\"}. Use stride to indicate the step size.\n",
        "  '''\n",
        "  if action not in set([\"left\", \"right\", \"up\", \"down\"]):\n",
        "    raise RuntimeError(\"Invalid action taken :(\") \n",
        "  \n",
        "  x, y, w, h = bbox\n",
        "  if action in set([\"left\", \"right\"]):\n",
        "    step = max(1, int(ALPHA * w)) * stride_magnitude * (-1 if action==\"left\" else 1)\n",
        "    x = min(max(0, int(x + step)), int(image.shape[1] - w - 1)) \n",
        "  else:\n",
        "    step = max(1, int(ALPHA * h)) * stride_magnitude * (-1 if action==\"up\" else 1)\n",
        "    y = min(max(0, int(y + step)), int(image.shape[0] - h - 1)) \n",
        "\n",
        "  return np.array([x, y, w, h])\n",
        "\n",
        "\n",
        "def scale(image: np.array, bbox: np.array, scaleUp: bool):\n",
        "  x, y, w, h = bbox\n",
        "  deltaW, deltaH = max(2, ALPHA * w), max(2, ALPHA * h)\n",
        "  if not scaleUp: \n",
        "    deltaW *= -1\n",
        "    deltaH *= -1\n",
        "  w = min(image.shape[1], max(MIN_WINDOW_SIZE, int(w + deltaW))) \n",
        "  h = min(image.shape[0], max(MIN_WINDOW_SIZE, int(h + deltaH)))\n",
        "  x = max(0, min(int(x - deltaW / 2), int(image.shape[1] - w - 1)))\n",
        "  y = max(0, min(int(y - deltaH / 2), int(image.shape[0] - h - 1)))\n",
        "  return np.array([x, y, w, h])\n",
        "\n",
        "\n",
        "def selectAction(img: np.array, bbox: np.array, index: int): \n",
        "  if index == 0 :\n",
        "    bbox = move(img, bbox, \"left\")\n",
        "  elif index == 1 :\n",
        "    bbox = move(img, bbox, \"left\", stride_magnitude=2)\n",
        "  elif index == 2 :\n",
        "    bbox = move(img, bbox, \"right\")\n",
        "  elif index == 3 :\n",
        "    bbox = move(img, bbox, \"right\", stride_magnitude=2)  \n",
        "  elif index == 4 :\n",
        "    bbox = move(img, bbox, \"up\")  \n",
        "  elif index == 5 :\n",
        "    bbox = move(img, bbox, \"up\", stride_magnitude=2)\n",
        "  elif index == 6 :\n",
        "    bbox = move(img, bbox, \"down\")\n",
        "  elif index == 7 :\n",
        "    bbox = move(img, bbox, \"down\", stride_magnitude=2)\n",
        "  elif index == 8:\n",
        "    bbox = bbox\n",
        "  elif index == 9 :\n",
        "    bbox = scale(img, bbox, False)     \n",
        "  elif index == 10 :\n",
        "    bbox = scale(img, bbox, True)      \n",
        "\n",
        "  x, y, w, h = bbox\n",
        "  assert 0 <= x <= img.shape[1] - w, \"x:{0}, w:{1} is out of bounds: [0, {2})\".format(x, w, img.shape[1] - 1)\n",
        "  assert 0 <= y <= img.shape[0] - h, \"y:{0}, h:{1} is out of bounds: [0, {2})\".format(y, h, img.shape[0] - 1)\n",
        "  assert MIN_WINDOW_SIZE <= w <= img.shape[1], \"w:{0}, is invalid\".format(w)\n",
        "  assert MIN_WINDOW_SIZE <= h <= img.shape[0], \"h:{0} is invalid\".format(h)\n",
        "  return index, bbox\n",
        "\n",
        "\n",
        "def human_readable_action(index: int) -> str:\n",
        "  '''\n",
        "  Map action numbers to human readable strings\n",
        "  '''\n",
        "  def _get_action(index:int) -> str:\n",
        "    if index == 0:\n",
        "      return \"left\"\n",
        "    elif index == 1:\n",
        "      return \"2x left\"\n",
        "    elif index == 2:\n",
        "      return \"right\"\n",
        "    elif index == 3:\n",
        "      return \"2x right\"\n",
        "    elif index == 4:\n",
        "      return \"up\"\n",
        "    elif index == 5:\n",
        "      return \"2x up\"\n",
        "    elif index == 6:\n",
        "      return \"down\"\n",
        "    elif index == 7:\n",
        "      return \"2x down\"\n",
        "    elif index == 8:\n",
        "      return \"stop\"\n",
        "    elif index == 9:\n",
        "      return \"scale down\"\n",
        "    elif index == 10 :\n",
        "      return \"scale up\"\n",
        "  return _get_action(index).upper()\n",
        "\n",
        "\n",
        "def getAction(img: np.array, bbox: np.array, action_probs: np.array):  \n",
        "  \n",
        "  action_probs = np.array(action_probs) + PROB_OFFSET\n",
        "  action_probs /= action_probs.sum()\n",
        "  \n",
        "  a = np.random.choice(np.arange(len(action_probs)), p=action_probs)\n",
        "  if POLICY_TYPE == \"deterministic\":\n",
        "    a = tf.math.argmax(action_probs)\n",
        "  return selectAction(img, bbox, a)\n",
        "\n",
        "\n",
        "def isStop(action: int):\n",
        "  return action == STOP_ACTION_INDEX\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLxdpmQ5jOjL"
      },
      "source": [
        "# REINFORCE Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CP9qJBgVq5B"
      },
      "source": [
        "### Trajectory Loss Function\n",
        "\n",
        "TODO: investigate adding https://www.analyticsvidhya.com/blog/2020/11/baseline-for-policy-gradients/\n",
        "Or rather https://arxiv.org/pdf/1301.2315.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Id7dQxPDVtJ_"
      },
      "outputs": [],
      "source": [
        "def getNonStopScore(bbox1: np.array, bbox2: np.array, gt: np.array) -> float:\n",
        "  # Issues with this blowing up the gradient in the wrong direction\n",
        "\n",
        "  def _dist(x1, y1, x2, y2):\n",
        "    return math.sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2)\n",
        "  \n",
        "  prevIou = calculate_IOU(bbox1, gt) \n",
        "  nextIou = calculate_IOU(bbox2, gt)\n",
        "  x1, y1 = bbox1[:2]\n",
        "  x2, y2 = bbox2[:2]\n",
        "  xg, yg = gt[:2]\n",
        "\n",
        "  # if prevIou == nextIou: EXPERIMENTED WITH USING EUCLIDEAN DISTANCE\n",
        "  #   return -1 * (_dist(x2, y2, xg, yg) - _dist(x1, y1, xg, yg))\n",
        "  result = nextIou - prevIou \n",
        "  return result \n",
        "\n",
        "def seqLosses(action_probs: List[np.array], actions_taken: List[int], \n",
        "              bboxes: List[np.array], \n",
        "              target_bbox: np.array) -> np.array:\n",
        "\n",
        "    assertMsg = \"Invalid trajectory: actions taken ({0}) + 1 != Bboxes length ({1})\".format(\n",
        "              len(actions_taken), len(bboxes)) \n",
        "    assert len(actions_taken) + 1 == len(bboxes), assertMsg\n",
        "          \n",
        "    src_bbox = np.array(bboxes[0])\n",
        "    end_bbox = np.array(bboxes[-1])\n",
        "    print(\"\\x1b[34m>> Calculating frame loss : {0} -> {1} (Target was {2})\\x1b[0m\".format(\n",
        "            np.array2string(src_bbox, separator=', '),\n",
        "            np.array2string(end_bbox, separator=', '),\n",
        "            np.array2string(target_bbox, separator=', ')))\n",
        "    rewards = np.zeros(len(actions_taken))\n",
        "    discounts = np.zeros(len(actions_taken))\n",
        "    for i, a in enumerate(actions_taken):\n",
        "      prev_bbox = np.array(bboxes[i])\n",
        "      next_bbox = np.array(bboxes[i+1])\n",
        "      ###################### CHANGE REWARD CALCULATION HERE ####################\n",
        "      if REWARD_SCHEME == \"final_bbox\":\n",
        "        rewards[i] = 1 if calculate_IOU(end_bbox, target_bbox) > 0.7\\\n",
        "                      else -1      \n",
        "      else:\n",
        "        if isStop(a):\n",
        "          rewards[i] = 1 if calculate_IOU(next_bbox, target_bbox) > 0.7 else -1\n",
        "        else:\n",
        "          rewards[i] = getNonStopScore(prev_bbox, next_bbox, target_bbox) \n",
        "      ###################### CHANGE REWARD CALCULATION UP ABOVE ################\n",
        "      prob_a = action_probs[i][a]\n",
        "      discounts[i] = GAMMA ** i\n",
        "      print(\"   |->> t={0} {1}-Reward ({2}) for {3}:bbox transition: {4} -> {5} w/ P(a|s)={6} and iou={7} and reward={8} and discount={9}\"\n",
        "            .format(i+1, \"Stop\" if isStop(a) else \"Diff\", \n",
        "                    np.around(rewards[i], decimals=3), \n",
        "                    human_readable_action(a).upper(),\n",
        "                    np.array2string(prev_bbox, separator=', '),\n",
        "                    np.array2string(next_bbox, separator=', '), prob_a, \n",
        "                    calculate_IOU(next_bbox, target_bbox), \n",
        "                    rewards[i], discounts[i]), \n",
        "            )\n",
        "    \n",
        "    gather_idx = [[i, a] for i, a in enumerate(actions_taken)]\n",
        "    p_a = tf.gather_nd(tf.stack(action_probs), gather_idx)\n",
        "    p_a = tf.clip_by_value(p_a, PROB_OFFSET, 1 - PROB_OFFSET) # done to prevent 0 reward   \n",
        "    \n",
        "    entropy = -1 * tf.math.reduce_sum((tf.math.log(action_probs) * action_probs), \n",
        "                                 axis=1) \n",
        "    \n",
        "    discount = tf.convert_to_tensor(discounts, dtype=tf.float32)\n",
        "    \n",
        "    \n",
        "    losses = -1 * (discount * rewards * tf.math.log(p_a))\n",
        "    \n",
        "    \n",
        "    print(\"   |->> Assigned losses: {0}\".format(losses))\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMujgGmUVu4k"
      },
      "source": [
        "### Tracking Procedure\n",
        "\n",
        "* This function collects trajectories either via argmax deterministic policy or sampling from a stochastic policy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "EqN0GHI5VlAM"
      },
      "outputs": [],
      "source": [
        "def getPatch(img: np.array, bbox: np.array) -> tf.Tensor:\n",
        "  def _patch(img: np.array, bbox: np.array) -> np.array:\n",
        "    x, y, w, h, = bbox\n",
        "    return img[y : (y + h), x : (x + w)]\n",
        "      \n",
        "  patch = tf.image.resize(_patch(img, bbox), [PATCH_X, PATCH_Y])\n",
        "  return tf.reshape(patch, (1, PATCH_X, PATCH_Y, N_CHANNELS))\n",
        "\n",
        "\n",
        "def tracking(model: ADNET, img: np.array, bbox: np.array,\n",
        "             t: int, target_bbox: np.array, \n",
        "             tracking_length: int= MAX_TRAJECTORY_LENGTH):\n",
        "    \"\"\" \n",
        "    Runs tracking until # actions > MAX_ACTIONS_SEQ_LIMIT, STOP is taken, or\n",
        "    oscillation occurs.\n",
        "    \"\"\"\n",
        "    print(\"|->> Beginning tracking for bbox:{0}\".format(bbox))    \n",
        "    patch = getPatch(img, bbox)\n",
        "    actions_taken = []\n",
        "    action_probs = []\n",
        "    bboxes = [tuple(bbox)]\n",
        "    prev_score = None\n",
        "    while len(actions_taken) < tracking_length:\n",
        "      prev_bbox = bbox.copy()\n",
        "      \n",
        "      probs, conf_score = model(patch)\n",
        "      probs = tf.reshape(probs, (model.ACTION_DIM)) \n",
        "      \n",
        "      a, bbox = getAction(np.array(img), bbox, probs)\n",
        "      prev_iou = calculate_IOU(prev_bbox, target_bbox)      \n",
        "      iou = calculate_IOU(bbox, target_bbox)   \n",
        "\n",
        "      if tuple(bbox) in bboxes:\n",
        "        print(\"|->> Revisiting bbox: {0}. Breaking action sequence\"\n",
        "                  .format(bbox))\n",
        "        print(\"   |->> Trajectory ending is FORCED\".format(iou))\n",
        "        a, bbox = 8, prev_bbox\n",
        "        if len(actions_taken) > 0:\n",
        "          # We observed too many trajectory STOPS were leading to gradient updates\n",
        "          # that reduce P(STOP|s) to near 0, which is undesirable. In this case, \n",
        "          # we allow STOPs if selected naturally by the policy or it's the only \n",
        "          # action on a trajectory (a trajectory MUST \n",
        "          # have at least one action). All other STOPs we just forego\n",
        "          # to prevent these harmful gradient updates\n",
        "          break\n",
        "      # elif prev_iou > iou or prev_iou > 0.8:\n",
        "      #   # TRAJECTORY IS WORSENING\n",
        "      #   print(\"             |->> IOU declining: {0}:{1} -> {2}:{3}.\"\n",
        "      #             .format(prev_bbox, prev_iou, bbox, iou))\n",
        "      #   print(\"             |->> Overriding with STOP\"\n",
        "      #           .format(iou))\n",
        "      #   a, bbox = 8, prev_bbox\n",
        "      \n",
        "      a_prob = probs[a] \n",
        "      print(\"   \\x1b[33m|->> #{1}-th Action selection: {2}/{3} (P(a|s) = {4})\\x1b[0m\"\n",
        "                .format(len(actions_taken), t, a, human_readable_action(a).upper(), \n",
        "                        np.around(a_prob, decimals=3)))\n",
        "      print(\"      |->> Bounding box moves to: {0}\"\n",
        "                .format(bbox))\n",
        "      print(\"         |->> Action Probabilities (Rounded): {0}, argmax={1}\"\n",
        "              .format(np.around(probs.numpy(), decimals=4), np.argmax(probs)))\n",
        "      print(\"         |->> Action Probabilities (RAW): {0}, argmax={1}\"\n",
        "              .format(probs.numpy(), np.argmax(probs)))\n",
        "\n",
        "      if VERBOSE:\n",
        "        print(\"         |->> Overwriting action in buffer {0}\"\n",
        "            .format(model.getPrettyActionHistory() if VERBOSE else \"\"))\n",
        "        \n",
        "      action_probs.append(probs)\n",
        "      actions_taken.append(a)\n",
        "      model.updateActionHistory(a)\n",
        "      bboxes.append(tuple(bbox))  \n",
        "      patch = getPatch(img, bbox)      \n",
        "\n",
        "      # Stopping condition\n",
        "      if isStop(a):\n",
        "        print(\"         |->> Hit a STOP on the {0}-th action!\".format(t))\n",
        "        break  \n",
        "      \n",
        "      t += 1\n",
        "\n",
        "    print(\"    \\x1b[31m|->> Completed tracking\\x1b[0m\")\n",
        "    \n",
        "    return action_probs, actions_taken, bboxes, t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akOkB6DOxC_v"
      },
      "source": [
        "### Single Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "4w8_6oDV7900"
      },
      "outputs": [],
      "source": [
        "VERBOSE = False\n",
        "\n",
        "def getFrame(dataset: str, frame: int) -> np.array:\n",
        "  f_path = \"{0}/img/{1}.jpg\".format(dataset, str(frame).zfill(4))\n",
        "  print(\"Frame path: {0}\".format(f_path))\n",
        "  img = cv2.imread(f_path)\n",
        "  return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\n",
        "def train(model: ADNET, opt: tf.keras.optimizers.Optimizer, \n",
        "          dataset: str, start_frame: int, end_frame: int, \n",
        "          retry_count: int=1) -> float:\n",
        "  '''\n",
        "  Run training for a model on a frame sequence {start_frame, end_frame} \n",
        "  n_retries times.\n",
        "  :param: dataset: is the dataset path to train from\n",
        "  :param: retry_count: number of times to train on the frame sequence. \n",
        "  :return: returns the model and average loss\n",
        "  '''\n",
        "\n",
        "  gt = get_ground_truths(\"%s/groundtruth_rect.txt\" % d)\n",
        "  frames = sorted(glob.glob(os.path.join('%s/img' % d, '*.jpg'))) \n",
        "  loss = 0.0\n",
        "\n",
        "  train_vars = model.trainable_variables\n",
        "  accum_gradient = [tf.zeros_like(this_var) for this_var in train_vars]\n",
        "  for i in range(retry_count):\n",
        "    print(\"\\n\\x1b[36m####################### EPISODE # {0} ############################\\x1b[0m\".format(i+1))\n",
        "    bbox = gt[start_frame]\n",
        "    print(\"Starting bounding box for {0}: frames {1}:{2} is {3}.\".format(dataset, start_frame, end_frame, bbox))\n",
        "    \n",
        "    t = 1    \n",
        "    model.clearActionHistory()\n",
        "    for i in range(start_frame+1, end_frame+1):\n",
        "      with tf.GradientTape() as tape:\n",
        "        target_bbox = gt[i]\n",
        "        prev_bbox = np.array(bbox, copy=True)\n",
        "\n",
        "        print(\"\\x1b[34m>> Attempting to reach frame {0} with src: {1} and target: {2}\\x1b[0m\"\n",
        "            .format(i, np.array2string(bbox, separator=', '), \n",
        "                    np.array2string(target_bbox, separator=', ')))\n",
        "        img = getFrame(dataset, i) \n",
        "        action_probs, taken_actions, bboxes, t = tracking(model, img, bbox, t, \n",
        "                                          target_bbox)\n",
        "        bbox = np.array(bboxes[-1])\n",
        "\n",
        "\n",
        "        frame_losses = seqLosses(action_probs, taken_actions, bboxes, target_bbox)\n",
        "        total_frame_loss = tf.reduce_sum(frame_losses)\n",
        "        \n",
        "        loss += np.sum(total_frame_loss.numpy())\n",
        "        print(\"{0}>> Total frame loss: {1}\\x1b[0m\".format(\n",
        "              \"\\x1b[92m\" if total_frame_loss > 0 else \"\\x1b[31m\", \n",
        "              total_frame_loss))\n",
        "\n",
        "      gradients = tape.gradient(total_frame_loss, train_vars)\n",
        "      accum_gradient = [(acum_grad+grad) for acum_grad, grad in zip(accum_gradient, gradients)]\n",
        "\n",
        "    print(\"Final bounding box: {0} reached in {1} timesteps (originating from {2}). Target was {3}\"\n",
        "          .format(bbox, t, np.array(gt[start_frame]), np.array(gt[end_frame])))\n",
        "    print(\"\\n\\x1b[36m############# END EPISODE # {0} in t={1} timesteps ################\\x1b[0m\".format(i+1, t))\n",
        "    \n",
        "\n",
        "  print(\"Avg Loss Across Trajectories: {0}\\x1b[0m\".format( \"\\x1b[92m\" if loss > 0 else \"\\x1b[31m\"))  \n",
        "  \n",
        "  \n",
        "  \n",
        "  accum_gradient = [g / retry_count for g in accum_gradient]\n",
        "  for i in range(len(accum_gradient)):\n",
        "      print(\"Layer Name: {}, GRAD NORM = {}\".format(\n",
        "      adnet_model.trainable_variables[i].name, tf.norm(accum_gradient[i])))\n",
        "  opt.apply_gradients(zip(accum_gradient, model.trainable_variables))\n",
        "  return model, loss / retry_count\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otMLmAPjVSiS",
        "outputId": "0f493727-04ae-484b-8e79-f17ed8f2654c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "   |->> t=3 Diff-Reward (-1.0) for UP:bbox transition: [153,  74,  63,  70] -> [153,  72,  63,  70] w/ P(a|s)=0.09265194833278656 and iou=0.4251412429378531 and reward=-1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [153,  72,  63,  70] -> [155,  72,  63,  70] w/ P(a|s)=0.09332922101020813 and iou=0.3975069252077562 and reward=-1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-1.0) for RIGHT:bbox transition: [155,  72,  63,  70] -> [156,  72,  63,  70] w/ P(a|s)=0.0893096998333931 and iou=0.3840877914951989 and reward=-1.0 and discount=0.96059601\n",
            "   |->> Assigned losses: [-2.4063554 -2.3492658 -2.3315651 -2.3011825 -2.3204591]\n",
            "\u001b[31m>> Total frame loss: -11.70882797241211\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 389 with src: [156,  72,  63,  70] and target: [120,  60,  72,  87]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0389.jpg\n",
            "|->> Beginning tracking for bbox:[156  72  63  70]\n",
            "   \u001b[33m|->> #50-th Action selection: 3/2X RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [158  72  63  70]\n",
            "         |->> Action Probabilities (Rounded): [0.0988 0.0914 0.0819 0.0919 0.0911 0.0921 0.0949 0.0952 0.0922 0.0851\n",
            " 0.0856], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09875612 0.09138814 0.08187285 0.09186835 0.09108269 0.09205072\n",
            " 0.09486148 0.09524442 0.0921674  0.08513567 0.08557216], argmax=0\n",
            "   \u001b[33m|->> #51-th Action selection: 2/RIGHT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [159  72  63  70]\n",
            "         |->> Action Probabilities (Rounded): [0.0909 0.0929 0.0895 0.0884 0.093  0.0918 0.0938 0.0949 0.0925 0.0864\n",
            " 0.0859], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09090514 0.09288955 0.08951144 0.08839564 0.09301612 0.09180031\n",
            " 0.09383974 0.09486894 0.09247169 0.0863595  0.08594186], argmax=7\n",
            "   \u001b[33m|->> #52-th Action selection: 3/2X RIGHT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [161  72  63  70]\n",
            "         |->> Action Probabilities (Rounded): [0.1002 0.0923 0.0786 0.0897 0.0928 0.093  0.094  0.0949 0.0924 0.086\n",
            " 0.086 ], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.1001865  0.0923297  0.07856837 0.08968337 0.09281975 0.09304938\n",
            " 0.09404894 0.09493048 0.09236211 0.08603884 0.08598258], argmax=0\n",
            "   \u001b[33m|->> #53-th Action selection: 2/RIGHT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [162  72  63  70]\n",
            "         |->> Action Probabilities (Rounded): [0.0892 0.094  0.0893 0.0862 0.0932 0.0928 0.0938 0.0947 0.0919 0.0886\n",
            " 0.0862], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08924982 0.09404313 0.08928436 0.08619887 0.09320183 0.09284526\n",
            " 0.09382974 0.09468995 0.09190533 0.08858597 0.08616574], argmax=7\n",
            "   \u001b[33m|->> #54-th Action selection: 10/SCALE UP (P(a|s) = 0.08500000089406967)\u001b[0m\n",
            "      |->> Bounding box moves to: [161  70  65  72]\n",
            "         |->> Action Probabilities (Rounded): [0.1013 0.0923 0.0775 0.0884 0.0927 0.0938 0.0944 0.095  0.0924 0.0867\n",
            " 0.0854], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.10127721 0.09232209 0.07754216 0.08839954 0.09274484 0.09377408\n",
            " 0.09441341 0.09503097 0.09236093 0.08672228 0.08541244], argmax=0\n",
            "   \u001b[33m|->> #55-th Action selection: 3/2X RIGHT (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [163  70  65  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0888 0.0941 0.0892 0.0873 0.0935 0.0934 0.0943 0.0952 0.0932 0.0898\n",
            " 0.0812], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08882765 0.09406262 0.08915663 0.08733247 0.09351762 0.09337155\n",
            " 0.09432386 0.0952282  0.09321375 0.0897525  0.08121322], argmax=7\n",
            "   \u001b[33m|->> #56-th Action selection: 5/2X UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [163  66  65  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0959 0.0933 0.0845 0.0865 0.0933 0.0934 0.0938 0.0948 0.0923 0.0878\n",
            " 0.0844], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09591337 0.09325078 0.0844684  0.08653487 0.09331751 0.09338927\n",
            " 0.09379616 0.09480438 0.09230015 0.08781745 0.08440767], argmax=0\n",
            "   \u001b[33m|->> #57-th Action selection: 5/2X UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [163  62  65  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0926 0.0927 0.0871 0.0865 0.0931 0.0927 0.0941 0.095  0.0927 0.089\n",
            " 0.0846], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09259157 0.09270041 0.08706331 0.08654213 0.09305632 0.09268543\n",
            " 0.09414088 0.09499229 0.09269299 0.08895025 0.08458447], argmax=7\n",
            "|->> Revisiting bbox: [163  62  65  72]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [156,  72,  63,  70] -> [163,  62,  65,  72] (Target was [120,  60,  72,  87])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [156,  72,  63,  70] -> [158,  72,  63,  70] w/ P(a|s)=0.09186834841966629 and iou=0.28695442488545936 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for RIGHT:bbox transition: [158,  72,  63,  70] -> [159,  72,  63,  70] w/ P(a|s)=0.089511439204216 and iou=0.27618364418938307 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [159,  72,  63,  70] -> [161,  72,  63,  70] w/ P(a|s)=0.08968336880207062 and iou=0.25517403574788333 and reward=-1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-1.0) for RIGHT:bbox transition: [161,  72,  63,  70] -> [162,  72,  63,  70] w/ P(a|s)=0.08928436040878296 and iou=0.244926522043387 and reward=-1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-1.0) for SCALE UP:bbox transition: [162,  72,  63,  70] -> [161,  70,  65,  72] w/ P(a|s)=0.08541243523359299 and iou=0.256198347107438 and reward=-1.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [161,  70,  65,  72] -> [163,  70,  65,  72] w/ P(a|s)=0.08733247220516205 and iou=0.23577235772357724 and reward=-1.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (-1.0) for 2X UP:bbox transition: [163,  70,  65,  72] -> [163,  66,  65,  72] w/ P(a|s)=0.09338926523923874 and iou=0.23577235772357724 and reward=-1.0 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (-1.0) for 2X UP:bbox transition: [163,  66,  65,  72] -> [163,  62,  65,  72] w/ P(a|s)=0.09268543124198914 and iou=0.23577235772357724 and reward=-1.0 and discount=0.9320653479069899\n",
            "   |->> Assigned losses: [-2.3873987 -2.3892548 -2.3634815 -2.3441734 -2.3633194 -2.3185449\n",
            " -2.2322295 -2.2169583]\n",
            "\u001b[31m>> Total frame loss: -18.615360260009766\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 390 with src: [163,  62,  65,  72] and target: [112,  60,  74,  85]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0390.jpg\n",
            "|->> Beginning tracking for bbox:[163  62  65  72]\n",
            "   \u001b[33m|->> #58-th Action selection: 0/LEFT (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [162  62  65  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0941 0.0924 0.0866 0.0872 0.0928 0.0911 0.0944 0.0941 0.0927 0.0889\n",
            " 0.0857], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09405341 0.09241937 0.08655303 0.08724052 0.09284937 0.09109624\n",
            " 0.09443837 0.09408341 0.09269168 0.08890639 0.08566818], argmax=6\n",
            "   \u001b[33m|->> #59-th Action selection: 4/UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [162  60  65  72]\n",
            "         |->> Action Probabilities (Rounded): [0.085  0.0925 0.0945 0.0889 0.0926 0.0918 0.0945 0.095  0.0937 0.0863\n",
            " 0.0852], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08500121 0.09247012 0.09449349 0.08885004 0.09264307 0.09175748\n",
            " 0.09447402 0.09504516 0.09372704 0.0863096  0.08522872], argmax=7\n",
            "   \u001b[33m|->> #60-th Action selection: 1/2X LEFT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [160  60  65  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0948 0.0917 0.0864 0.09   0.0903 0.0913 0.0944 0.0947 0.0933 0.0873\n",
            " 0.0858], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09476411 0.09170088 0.08637498 0.09001207 0.09027725 0.09128768\n",
            " 0.0944233  0.09472667 0.09329381 0.0873461  0.08579312], argmax=0\n",
            "   \u001b[33m|->> #61-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [161  61  63  69]\n",
            "         |->> Action Probabilities (Rounded): [0.0896 0.0888 0.0915 0.0907 0.0916 0.0913 0.0936 0.0952 0.0936 0.0875\n",
            " 0.0865], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08959586 0.08883654 0.09151467 0.09065386 0.09160645 0.09131535\n",
            " 0.09361809 0.09515003 0.09364385 0.08754465 0.08652066], argmax=7\n",
            "   \u001b[33m|->> #62-th Action selection: 3/2X RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [163  61  63  69]\n",
            "         |->> Action Probabilities (Rounded): [0.0917 0.0892 0.0892 0.0917 0.0914 0.0911 0.0946 0.0952 0.0938 0.0835\n",
            " 0.0886], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.0917137  0.08919087 0.08918513 0.09166262 0.09144752 0.09109236\n",
            " 0.0946316  0.0951637  0.09380722 0.08350654 0.08859872], argmax=7\n",
            "   \u001b[33m|->> #63-th Action selection: 0/LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [162  61  63  69]\n",
            "         |->> Action Probabilities (Rounded): [0.091  0.0895 0.09   0.0906 0.0928 0.0913 0.0941 0.0948 0.0938 0.0851\n",
            " 0.0871], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09101609 0.08948663 0.09002771 0.09061655 0.09280283 0.09127122\n",
            " 0.09407798 0.09480502 0.09376597 0.0850535  0.08707642], argmax=7\n",
            "   \u001b[33m|->> #64-th Action selection: 1/2X LEFT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [160  61  63  69]\n",
            "         |->> Action Probabilities (Rounded): [0.0842 0.0895 0.095  0.0918 0.0924 0.0923 0.0951 0.0957 0.0932 0.083\n",
            " 0.0879], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08418733 0.08948792 0.09502855 0.09177846 0.0923705  0.0922598\n",
            " 0.09505568 0.09574001 0.09318943 0.08301833 0.08788399], argmax=7\n",
            "   \u001b[33m|->> #65-th Action selection: 6/DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [160  63  63  69]\n",
            "         |->> Action Probabilities (Rounded): [0.092  0.0862 0.0877 0.092  0.093  0.0919 0.0945 0.0953 0.0936 0.0845\n",
            " 0.0893], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09198581 0.0862025  0.08774237 0.09197777 0.09298649 0.09191629\n",
            " 0.09447712 0.09528615 0.09359977 0.0844869  0.08933885], argmax=7\n",
            "   \u001b[33m|->> #66-th Action selection: 0/LEFT (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [159  63  63  69]\n",
            "         |->> Action Probabilities (Rounded): [0.0882 0.0871 0.0942 0.092  0.0936 0.0919 0.0918 0.0953 0.093  0.0843\n",
            " 0.0885], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08823921 0.08711295 0.09423255 0.09200022 0.09363788 0.09190954\n",
            " 0.09181072 0.09525824 0.09296229 0.08430653 0.08852988], argmax=7\n",
            "|->> Revisiting bbox: [159  63  63  69]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [163,  62,  65,  72] -> [159,  63,  63,  69] (Target was [112,  60,  74,  85])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for LEFT:bbox transition: [163,  62,  65,  72] -> [162,  62,  65,  72] w/ P(a|s)=0.09405340999364853 and iou=0.18697251677126164 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for UP:bbox transition: [162,  62,  65,  72] -> [162,  60,  65,  72] w/ P(a|s)=0.09264307469129562 and iou=0.18697251677126164 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [162,  60,  65,  72] -> [160,  60,  65,  72] w/ P(a|s)=0.09170088171958923 and iou=0.20575950758408443 and reward=-1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [160,  60,  65,  72] -> [161,  61,  63,  69] w/ P(a|s)=0.08754464983940125 and iou=0.1935592459605027 and reward=-1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [161,  61,  63,  69] -> [163,  61,  63,  69] w/ P(a|s)=0.09166261553764343 and iou=0.17535911602209944 and reward=-1.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-1.0) for LEFT:bbox transition: [163,  61,  63,  69] -> [162,  61,  63,  69] w/ P(a|s)=0.09101609140634537 and iou=0.18438926622870505 and reward=-1.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [162,  61,  63,  69] -> [160,  61,  63,  69] w/ P(a|s)=0.08948791772127151 and iou=0.20287232839534095 and reward=-1.0 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (-1.0) for DOWN:bbox transition: [160,  61,  63,  69] -> [160,  63,  63,  69] w/ P(a|s)=0.09447712451219559 and iou=0.20287232839534095 and reward=-1.0 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (-1.0) for LEFT:bbox transition: [160,  63,  63,  69] -> [159,  63,  63,  69] w/ P(a|s)=0.08823920786380768 and iou=0.21233188967403693 and reward=-1.0 and discount=0.9227446944279201\n",
            "   |->> Assigned losses: [-2.3638926 -2.3552113 -2.3416777 -2.3632662 -2.2954793 -2.2792559\n",
            " -2.2724051 -2.199113  -2.240151 ]\n",
            "\u001b[31m>> Total frame loss: -20.710451126098633\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 391 with src: [159,  63,  63,  69] and target: [106,  61,  74,  85]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0391.jpg\n",
            "|->> Beginning tracking for bbox:[159  63  63  69]\n",
            "   \u001b[33m|->> #67-th Action selection: 7/2X DOWN (P(a|s) = 0.09600000083446503)\u001b[0m\n",
            "      |->> Bounding box moves to: [159  67  63  69]\n",
            "         |->> Action Probabilities (Rounded): [0.0853 0.0871 0.0966 0.0934 0.0921 0.0932 0.0937 0.0956 0.0924 0.0826\n",
            " 0.088 ], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08530666 0.08707689 0.09661145 0.09338231 0.09205837 0.09324617\n",
            " 0.09372707 0.09561318 0.09236209 0.08259822 0.08801764], argmax=2\n",
            "   \u001b[33m|->> #68-th Action selection: 4/UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [159  65  63  69]\n",
            "         |->> Action Probabilities (Rounded): [0.0919 0.087  0.0894 0.0936 0.0935 0.0934 0.0929 0.0938 0.0926 0.0833\n",
            " 0.0887], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09187765 0.08698189 0.08944565 0.09357326 0.09346141 0.09335439\n",
            " 0.09287876 0.09376448 0.09259694 0.08331621 0.08874941], argmax=7\n",
            "|->> Revisiting bbox: [159  63  63  69]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [159,  63,  63,  69] -> [159,  65,  63,  69] (Target was [106,  61,  74,  85])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for 2X DOWN:bbox transition: [159,  63,  63,  69] -> [159,  67,  63,  69] w/ P(a|s)=0.09561318159103394 and iou=0.15770570309098825 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for UP:bbox transition: [159,  67,  63,  69] -> [159,  65,  63,  69] w/ P(a|s)=0.09346140921115875 and iou=0.15770570309098825 and reward=-1.0 and discount=0.99\n",
            "   |->> Assigned losses: [-2.3474445 -2.3465044]\n",
            "\u001b[31m>> Total frame loss: -4.693948745727539\u001b[0m\n",
            "Final bounding box: [159  65  63  69] reached in 69 timesteps (originating from [145  65  72  81]). Target was [106  61  74  85]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 392 in t=69 timesteps ################\u001b[0m\n",
            "\n",
            "\u001b[36m####################### EPISODE # 3 ############################\u001b[0m\n",
            "Starting bounding box for adnet_datasets/OTB/FaceOcc2: frames 381:391 is [145  65  72  81].\n",
            "\u001b[34m>> Attempting to reach frame 382 with src: [145,  65,  72,  81] and target: [149,  66,  69,  81]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0382.jpg\n",
            "|->> Beginning tracking for bbox:[145  65  72  81]\n",
            "   \u001b[33m|->> #1-th Action selection: 2/RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [147  65  72  81]\n",
            "         |->> Action Probabilities (Rounded): [0.0909 0.0908 0.091  0.0909 0.0909 0.0908 0.091  0.091  0.0912 0.0908\n",
            " 0.0909], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09088156 0.09078381 0.09096917 0.09092985 0.09091397 0.0907969\n",
            " 0.09095241 0.0909557  0.09115039 0.09079774 0.09086843], argmax=8\n",
            "   \u001b[33m|->> #2-th Action selection: 7/2X DOWN (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [147  69  72  81]\n",
            "         |->> Action Probabilities (Rounded): [0.0975 0.0908 0.0832 0.0917 0.0908 0.0918 0.0913 0.0916 0.0917 0.0894\n",
            " 0.0901], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09749839 0.09081178 0.08323558 0.09172169 0.09081782 0.09176315\n",
            " 0.0913439  0.09164496 0.09165298 0.08939025 0.09011953], argmax=0\n",
            "   \u001b[33m|->> #3-th Action selection: 0/LEFT (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [145  69  72  81]\n",
            "         |->> Action Probabilities (Rounded): [0.0883 0.0917 0.0931 0.0902 0.0917 0.0911 0.0913 0.0902 0.092  0.09\n",
            " 0.0902], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08827992 0.09173442 0.09313129 0.09020679 0.0917343  0.09109328\n",
            " 0.09134297 0.0901886  0.09204189 0.09002519 0.09022141], argmax=2\n",
            "   \u001b[33m|->> #4-th Action selection: 3/2X RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [149  69  72  81]\n",
            "         |->> Action Probabilities (Rounded): [0.0858 0.0917 0.0953 0.0916 0.0914 0.0921 0.0916 0.0914 0.0924 0.0873\n",
            " 0.0892], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08582278 0.09169972 0.09531215 0.09163822 0.09137968 0.0921087\n",
            " 0.09164692 0.09144299 0.09243818 0.08727797 0.08923271], argmax=2\n",
            "   \u001b[33m|->> #5-th Action selection: 10/SCALE UP (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [147  67  74  83]\n",
            "         |->> Action Probabilities (Rounded): [0.0929 0.0914 0.0883 0.0901 0.0917 0.0923 0.0915 0.0915 0.0919 0.0884\n",
            " 0.0898], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09294845 0.09142113 0.0883394  0.09009434 0.09171636 0.09226955\n",
            " 0.0915045  0.09152965 0.09191309 0.08842999 0.08983348], argmax=0\n",
            "   \u001b[33m|->> #6-th Action selection: 4/UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [147  65  74  83]\n",
            "         |->> Action Probabilities (Rounded): [0.0905 0.0914 0.0911 0.0907 0.0923 0.093  0.0921 0.0926 0.0924 0.0899\n",
            " 0.084 ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.09048403 0.09142597 0.09109998 0.09068616 0.09227482 0.09299433\n",
            " 0.09213943 0.09261439 0.09235486 0.08990683 0.08401916], argmax=5\n",
            "   \u001b[33m|->> #7-th Action selection: 5/2X UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [147  61  74  83]\n",
            "         |->> Action Probabilities (Rounded): [0.0931 0.0912 0.0899 0.0908 0.0902 0.0927 0.093  0.0925 0.0932 0.0875\n",
            " 0.086 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09313287 0.09116873 0.08986108 0.09084307 0.09018317 0.09269559\n",
            " 0.09298029 0.09247787 0.09323846 0.08746757 0.08595133], argmax=8\n",
            "|->> Revisiting bbox: [147  65  74  83]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [145,  65,  72,  81] -> [147,  61,  74,  83] (Target was [149,  66,  69,  81])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for RIGHT:bbox transition: [145,  65,  72,  81] -> [147,  65,  72,  81] w/ P(a|s)=0.09096916764974594 and iou=0.9354346720894764 and reward=1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for 2X DOWN:bbox transition: [147,  65,  72,  81] -> [147,  69,  72,  81] w/ P(a|s)=0.09164495766162872 and iou=0.8912071535022354 and reward=1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (1.0) for LEFT:bbox transition: [147,  69,  72,  81] -> [145,  69,  72,  81] w/ P(a|s)=0.08827991783618927 and iou=0.8670917116233448 and reward=1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (1.0) for 2X RIGHT:bbox transition: [145,  69,  72,  81] -> [149,  69,  72,  81] w/ P(a|s)=0.0916382223367691 and iou=0.8912071535022354 and reward=1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (1.0) for SCALE UP:bbox transition: [149,  69,  72,  81] -> [147,  67,  74,  83] w/ P(a|s)=0.08983347564935684 and iou=0.8887457736274352 and reward=1.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (1.0) for UP:bbox transition: [147,  67,  74,  83] -> [147,  65,  74,  83] w/ P(a|s)=0.09227482229471207 and iou=0.9099641810485184 and reward=1.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (1.0) for 2X UP:bbox transition: [147,  65,  74,  83] -> [147,  61,  74,  83] w/ P(a|s)=0.09269559383392334 and iou=0.8476925500078752 and reward=1.0 and discount=0.941480149401\n",
            "   |->> Assigned losses: [2.3972347 2.365935  2.3789406 2.3189242 2.314842  2.2661939 2.2392488]\n",
            "\u001b[92m>> Total frame loss: 16.28131866455078\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 383 with src: [147,  61,  74,  83] and target: [144,  67,  73,  79]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0383.jpg\n",
            "|->> Beginning tracking for bbox:[147  61  74  83]\n",
            "   \u001b[33m|->> #8-th Action selection: 0/LEFT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [145  61  74  83]\n",
            "         |->> Action Probabilities (Rounded): [0.0925 0.091  0.0908 0.091  0.0916 0.0909 0.092  0.0927 0.0931 0.0887\n",
            " 0.0857], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09245605 0.0910142  0.0907954  0.09104807 0.09160415 0.09090378\n",
            " 0.0919676  0.09271648 0.09305292 0.08870332 0.08573806], argmax=8\n",
            "   \u001b[33m|->> #9-th Action selection: 6/DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [145  63  74  83]\n",
            "         |->> Action Probabilities (Rounded): [0.0852 0.0916 0.0966 0.0916 0.0915 0.092  0.0935 0.0936 0.0923 0.0859\n",
            " 0.0862], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08516923 0.09158546 0.09657487 0.09162888 0.09150133 0.09198584\n",
            " 0.09350066 0.09358251 0.09234132 0.08592346 0.08620648], argmax=2\n",
            "   \u001b[33m|->> #10-th Action selection: 1/2X LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [141  63  74  83]\n",
            "         |->> Action Probabilities (Rounded): [0.0937 0.0908 0.088  0.093  0.0933 0.0917 0.0907 0.0938 0.0922 0.087\n",
            " 0.086 ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09366191 0.09077046 0.08801953 0.09299187 0.09329434 0.09165252\n",
            " 0.09065555 0.09376872 0.09224226 0.08695077 0.08599207], argmax=7\n",
            "   \u001b[33m|->> #11-th Action selection: 7/2X DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [141  67  74  83]\n",
            "         |->> Action Probabilities (Rounded): [0.0894 0.0885 0.0935 0.092  0.0921 0.0919 0.093  0.0938 0.0931 0.0869\n",
            " 0.0859], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08939446 0.08846889 0.09345748 0.09199409 0.09209972 0.09191785\n",
            " 0.09301837 0.09376097 0.09307675 0.08687168 0.08593979], argmax=7\n",
            "   \u001b[33m|->> #12-th Action selection: 2/RIGHT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [143  67  74  83]\n",
            "         |->> Action Probabilities (Rounded): [0.0935 0.0879 0.0899 0.0926 0.0932 0.0914 0.092  0.0924 0.0924 0.0876\n",
            " 0.0872], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09345081 0.08792717 0.08994205 0.09256179 0.09317251 0.09135015\n",
            " 0.09197259 0.092438   0.09244431 0.08756468 0.08717597], argmax=0\n",
            "|->> Revisiting bbox: [141  67  74  83]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [147,  61,  74,  83] -> [143,  67,  74,  83] (Target was [144,  67,  73,  79])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for LEFT:bbox transition: [147,  61,  74,  83] -> [145,  61,  74,  83] w/ P(a|s)=0.09245605021715164 and iou=0.8710133542812255 and reward=1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for DOWN:bbox transition: [145,  61,  74,  83] -> [145,  63,  74,  83] w/ P(a|s)=0.09350065886974335 and iou=0.9143224561967529 and reward=1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (1.0) for 2X LEFT:bbox transition: [145,  63,  74,  83] -> [141,  63,  74,  83] w/ P(a|s)=0.09077046066522598 and iou=0.8903174603174603 and reward=1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (1.0) for 2X DOWN:bbox transition: [141,  63,  74,  83] -> [141,  67,  74,  83] w/ P(a|s)=0.09376096725463867 and iou=0.8903174603174603 and reward=1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (1.0) for RIGHT:bbox transition: [141,  67,  74,  83] -> [143,  67,  74,  83] w/ P(a|s)=0.08994204550981522 and iou=0.938944969065451 and reward=1.0 and discount=0.96059601\n",
            "   |->> Assigned losses: [2.381022  2.346089  2.351673  2.296704  2.3136818]\n",
            "\u001b[92m>> Total frame loss: 11.689169883728027\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 384 with src: [143,  67,  74,  83] and target: [147,  66,  70,  81]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0384.jpg\n",
            "|->> Beginning tracking for bbox:[143  67  74  83]\n",
            "   \u001b[33m|->> #13-th Action selection: 1/2X LEFT (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [139  67  74  83]\n",
            "         |->> Action Probabilities (Rounded): [0.098  0.0878 0.0838 0.0935 0.0921 0.0924 0.0937 0.0935 0.0928 0.0861\n",
            " 0.0864], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09796507 0.08778057 0.08376521 0.09353475 0.09206546 0.09242129\n",
            " 0.09372917 0.09350695 0.09275863 0.08612207 0.08635086], argmax=0\n",
            "|->> Revisiting bbox: [143  67  74  83]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [143,  67,  74,  83] -> [139,  67,  74,  83] (Target was [147,  66,  70,  81])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for 2X LEFT:bbox transition: [143,  67,  74,  83] -> [139,  67,  74,  83] w/ P(a|s)=0.08778056502342224 and iou=0.8083282302510717 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [2.4329152]\n",
            "\u001b[92m>> Total frame loss: 2.432915210723877\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 385 with src: [139,  67,  74,  83] and target: [141,  67,  72,  80]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0385.jpg\n",
            "|->> Beginning tracking for bbox:[139  67  74  83]\n",
            "   \u001b[33m|->> #14-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [140  68  71  80]\n",
            "         |->> Action Probabilities (Rounded): [0.0881 0.0877 0.0921 0.0914 0.0938 0.0919 0.0936 0.0928 0.093  0.0881\n",
            " 0.0876], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.08809552 0.08768466 0.09208412 0.09143119 0.09376927 0.09193482\n",
            " 0.09355325 0.09275044 0.09300127 0.08806763 0.0876279 ], argmax=4\n",
            "   \u001b[33m|->> #15-th Action selection: 6/DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [140  70  71  80]\n",
            "         |->> Action Probabilities (Rounded): [0.091  0.0878 0.09   0.093  0.0934 0.0924 0.0945 0.0936 0.0935 0.0828\n",
            " 0.0881], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09099896 0.08782393 0.08996526 0.09295111 0.09337372 0.0923684\n",
            " 0.09445404 0.09360131 0.09351219 0.0828173  0.08813375], argmax=6\n",
            "   \u001b[33m|->> #16-th Action selection: 1/2X LEFT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [136  70  71  80]\n",
            "         |->> Action Probabilities (Rounded): [0.0898 0.0885 0.0928 0.0927 0.0946 0.0922 0.0913 0.0934 0.0925 0.0843\n",
            " 0.088 ], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.08977962 0.08850145 0.09280137 0.09268714 0.09456133 0.09219716\n",
            " 0.09132335 0.09340949 0.09248192 0.08427194 0.08798525], argmax=4\n",
            "   \u001b[33m|->> #17-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08399999886751175)\u001b[0m\n",
            "      |->> Bounding box moves to: [137  71  68  77]\n",
            "         |->> Action Probabilities (Rounded): [0.0911 0.0862 0.0917 0.0929 0.0922 0.0921 0.0938 0.0933 0.0932 0.0844\n",
            " 0.0891], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09109713 0.08623481 0.09165647 0.09293967 0.09221644 0.09208845\n",
            " 0.09379776 0.09328793 0.09315652 0.08439519 0.08912964], argmax=6\n",
            "   \u001b[33m|->> #18-th Action selection: 6/DOWN (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [137  73  68  77]\n",
            "         |->> Action Probabilities (Rounded): [0.0888 0.0871 0.092  0.0928 0.0942 0.0932 0.0932 0.094  0.0946 0.08\n",
            " 0.09  ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08875776 0.08711097 0.09199072 0.09282091 0.0942289  0.0932104\n",
            " 0.09322739 0.0940482  0.09462305 0.08001877 0.08996301], argmax=8\n",
            "   \u001b[33m|->> #19-th Action selection: 7/2X DOWN (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [137  77  68  77]\n",
            "         |->> Action Probabilities (Rounded): [0.0893 0.0882 0.0916 0.0926 0.0951 0.0927 0.0919 0.0935 0.0927 0.0834\n",
            " 0.089 ], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.08928965 0.08820318 0.09163719 0.09264152 0.09505776 0.09267451\n",
            " 0.091901   0.09349716 0.09271992 0.08336311 0.08901496], argmax=4\n",
            "|->> Revisiting bbox: [137  73  68  77]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [139,  67,  74,  83] -> [137,  77,  68,  77] (Target was [141,  67,  72,  80])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [139,  67,  74,  83] -> [140,  68,  71,  80] w/ P(a|s)=0.08806762844324112 and iou=0.9357021996615905 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for DOWN:bbox transition: [140,  68,  71,  80] -> [140,  70,  71,  80] w/ P(a|s)=0.09445404261350632 and iou=0.8909090909090909 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [140,  70,  71,  80] -> [136,  70,  71,  80] w/ P(a|s)=0.0885014459490776 and iou=0.7993079584775087 and reward=-1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [136,  70,  71,  80] -> [137,  71,  68,  77] w/ P(a|s)=0.08439518511295319 and iou=0.7932159165035877 and reward=-1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-1.0) for DOWN:bbox transition: [137,  71,  68,  77] -> [137,  73,  68,  77] w/ P(a|s)=0.09322738647460938 and iou=0.7565495207667732 and reward=-1.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-1.0) for 2X DOWN:bbox transition: [137,  73,  68,  77] -> [137,  77,  68,  77] w/ P(a|s)=0.09349715709686279 and iou=0.6875383670963782 and reward=-1.0 and discount=0.9509900498999999\n",
            "   |->> Assigned losses: [-2.4296503 -2.3360455 -2.3764842 -2.3988168 -2.2792194 -2.253679 ]\n",
            "\u001b[31m>> Total frame loss: -14.073894500732422\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 386 with src: [137,  77,  68,  77] and target: [137,  65,  73,  81]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0386.jpg\n",
            "|->> Beginning tracking for bbox:[137  77  68  77]\n",
            "   \u001b[33m|->> #20-th Action selection: 10/SCALE UP (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [135  75  70  79]\n",
            "         |->> Action Probabilities (Rounded): [0.089  0.0885 0.0914 0.0927 0.0933 0.0925 0.0933 0.0916 0.0938 0.0837\n",
            " 0.0903], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08895773 0.0885295  0.09143405 0.0926685  0.09326401 0.09245374\n",
            " 0.09330521 0.09157864 0.09380251 0.08373001 0.09027611], argmax=8\n",
            "   \u001b[33m|->> #21-th Action selection: 6/DOWN (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [135  77  70  79]\n",
            "         |->> Action Probabilities (Rounded): [0.0882 0.0903 0.0907 0.093  0.0943 0.0929 0.0925 0.0922 0.0949 0.0865\n",
            " 0.0846], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08820281 0.09025905 0.09070478 0.09302486 0.09427082 0.09292109\n",
            " 0.09246572 0.09221554 0.09485976 0.08646001 0.08461551], argmax=8\n",
            "|->> Revisiting bbox: [135  75  70  79]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [137,  77,  68,  77] -> [135,  77,  70,  79] (Target was [137,  65,  73,  81])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for SCALE UP:bbox transition: [137,  77,  68,  77] -> [135,  75,  70,  79] w/ P(a|s)=0.09027610719203949 and iou=0.7298563869992442 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for DOWN:bbox transition: [135,  75,  70,  79] -> [135,  77,  70,  79] w/ P(a|s)=0.09246572107076645 and iou=0.695008146941194 and reward=-1.0 and discount=0.99\n",
            "   |->> Assigned losses: [-2.4048824 -2.357108 ]\n",
            "\u001b[31m>> Total frame loss: -4.761990547180176\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 387 with src: [135,  77,  70,  79] and target: [132,  63,  69,  81]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0387.jpg\n",
            "|->> Beginning tracking for bbox:[135  77  70  79]\n",
            "   \u001b[33m|->> #22-th Action selection: 4/UP (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [135  75  70  79]\n",
            "         |->> Action Probabilities (Rounded): [0.0885 0.0901 0.0919 0.0929 0.0951 0.0929 0.0914 0.0926 0.0935 0.0847\n",
            " 0.0863], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.08850553 0.09011078 0.09194101 0.09290231 0.09512132 0.09289119\n",
            " 0.09136268 0.09260204 0.09348427 0.08474265 0.08633624], argmax=4\n",
            "   \u001b[33m|->> #23-th Action selection: 2/RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [137  75  70  79]\n",
            "         |->> Action Probabilities (Rounded): [0.0892 0.0901 0.0916 0.0936 0.0911 0.0927 0.0929 0.0924 0.0939 0.0865\n",
            " 0.0861], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08918598 0.09011276 0.09158089 0.09362577 0.09106591 0.09265561\n",
            " 0.09293883 0.09237689 0.09390197 0.0864784  0.08607698], argmax=8\n",
            "   \u001b[33m|->> #24-th Action selection: 2/RIGHT (P(a|s) = 0.08299999684095383)\u001b[0m\n",
            "      |->> Bounding box moves to: [139  75  70  79]\n",
            "         |->> Action Probabilities (Rounded): [0.0951 0.0914 0.0833 0.0938 0.093  0.0934 0.0914 0.0926 0.0938 0.0853\n",
            " 0.0869], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.0951442  0.09144842 0.08328997 0.09382547 0.09295511 0.09342768\n",
            " 0.09136826 0.0925589  0.09376048 0.08530278 0.08691871], argmax=0\n",
            "|->> Revisiting bbox: [139  75  70  79]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [135,  77,  70,  79] -> [139,  75,  70,  79] (Target was [132,  63,  69,  81])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for UP:bbox transition: [135,  77,  70,  79] -> [135,  75,  70,  79] w/ P(a|s)=0.09512131661176682 and iou=0.6936785986290936 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for RIGHT:bbox transition: [135,  75,  70,  79] -> [137,  75,  70,  79] w/ P(a|s)=0.09158089011907578 and iou=0.6588094882888259 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for RIGHT:bbox transition: [137,  75,  70,  79] -> [139,  75,  70,  79] w/ P(a|s)=0.0832899734377861 and iou=0.6253471714661599 and reward=-1.0 and discount=0.9801\n",
            "   |->> Assigned losses: [-2.3526022 -2.3666275 -2.435967 ]\n",
            "\u001b[31m>> Total frame loss: -7.155196666717529\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 388 with src: [139,  75,  70,  79] and target: [125,  65,  71,  80]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0388.jpg\n",
            "|->> Beginning tracking for bbox:[139  75  70  79]\n",
            "   \u001b[33m|->> #25-th Action selection: 9/SCALE DOWN (P(a|s) = 0.0860000029206276)\u001b[0m\n",
            "      |->> Bounding box moves to: [140  76  67  76]\n",
            "         |->> Action Probabilities (Rounded): [0.0923 0.0922 0.0845 0.0927 0.093  0.0932 0.0941 0.0933 0.0925 0.0861\n",
            " 0.0861], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09228322 0.0922255  0.08448091 0.09271745 0.09303561 0.0931643\n",
            " 0.09406118 0.09325884 0.09254992 0.08608713 0.08613596], argmax=6\n",
            "   \u001b[33m|->> #26-th Action selection: 3/2X RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [144  76  67  76]\n",
            "         |->> Action Probabilities (Rounded): [0.0882 0.0929 0.0901 0.0922 0.0941 0.093  0.0933 0.0934 0.0933 0.0821\n",
            " 0.0874], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.08824182 0.09293958 0.09006166 0.09215114 0.0940761  0.09303086\n",
            " 0.09330434 0.09341005 0.09331287 0.08205348 0.08741812], argmax=4\n",
            "   \u001b[33m|->> #27-th Action selection: 5/2X UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [144  72  67  76]\n",
            "         |->> Action Probabilities (Rounded): [0.0922 0.0936 0.0873 0.0903 0.0935 0.0933 0.093  0.0934 0.0925 0.0843\n",
            " 0.0866], argmax=1\n",
            "         |->> Action Probabilities (RAW): [0.0922044  0.0936151  0.08731278 0.09030752 0.09352928 0.09327206\n",
            " 0.09304499 0.09338187 0.09245702 0.08425771 0.08661722], argmax=1\n",
            "   \u001b[33m|->> #28-th Action selection: 3/2X RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [148  72  67  76]\n",
            "         |->> Action Probabilities (Rounded): [0.0913 0.0929 0.0887 0.0908 0.0937 0.0915 0.0937 0.0931 0.0918 0.0852\n",
            " 0.0874], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.0912585  0.09287925 0.0886829  0.09076246 0.09372451 0.09147566\n",
            " 0.09372931 0.09309676 0.09180822 0.08515017 0.08743229], argmax=6\n",
            "   \u001b[33m|->> #29-th Action selection: 6/DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [148  74  67  76]\n",
            "         |->> Action Probabilities (Rounded): [0.0923 0.0933 0.088  0.0885 0.0929 0.0915 0.094  0.0932 0.0926 0.0863\n",
            " 0.0873], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09225727 0.0932907  0.08801061 0.08852127 0.09285385 0.09153258\n",
            " 0.09403992 0.09323118 0.0926111  0.0863435  0.08730802], argmax=6\n",
            "   \u001b[33m|->> #30-th Action selection: 0/LEFT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [146  74  67  76]\n",
            "         |->> Action Probabilities (Rounded): [0.092  0.0927 0.0884 0.0891 0.0947 0.0918 0.0915 0.094  0.0926 0.0863\n",
            " 0.0869], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.09198637 0.09269824 0.08837053 0.0891428  0.09466919 0.09181418\n",
            " 0.09149835 0.09402572 0.0926299  0.08628414 0.08688058], argmax=4\n",
            "   \u001b[33m|->> #31-th Action selection: 5/2X UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [146  70  67  76]\n",
            "         |->> Action Probabilities (Rounded): [0.0856 0.0932 0.095  0.0895 0.0922 0.0928 0.0937 0.0945 0.0922 0.0837\n",
            " 0.0876], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08555723 0.09316064 0.09495026 0.08954821 0.09223545 0.09283921\n",
            " 0.0936856  0.09447417 0.09221774 0.08371431 0.08761717], argmax=2\n",
            "|->> Revisiting bbox: [146  70  67  76]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [139,  75,  70,  79] -> [146,  70,  67,  76] (Target was [125,  65,  71,  80])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [139,  75,  70,  79] -> [140,  76,  67,  76] w/ P(a|s)=0.08608713001012802 and iou=0.5593514765489288 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [140,  76,  67,  76] -> [144,  76,  67,  76] w/ P(a|s)=0.09215114265680313 and iou=0.4994432071269488 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for 2X UP:bbox transition: [144,  76,  67,  76] -> [144,  72,  67,  76] w/ P(a|s)=0.09327206015586853 and iou=0.544151376146789 and reward=-1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [144,  72,  67,  76] -> [148,  72,  67,  76] w/ P(a|s)=0.09076245874166489 and iou=0.48211337369290036 and reward=-1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-1.0) for DOWN:bbox transition: [148,  72,  67,  76] -> [148,  74,  67,  76] w/ P(a|s)=0.0940399244427681 and iou=0.4627919608908202 and reward=-1.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-1.0) for LEFT:bbox transition: [148,  74,  67,  76] -> [146,  74,  67,  76] w/ P(a|s)=0.09198637306690216 and iou=0.49155358626419277 and reward=-1.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (-1.0) for 2X UP:bbox transition: [146,  74,  67,  76] -> [146,  70,  67,  76] w/ P(a|s)=0.09283921122550964 and iou=0.5340358872116207 and reward=-1.0 and discount=0.941480149401\n",
            "   |->> Assigned losses: [-2.4523954 -2.360482  -2.325027  -2.3282416 -2.2708833 -2.2691715\n",
            " -2.237791 ]\n",
            "\u001b[31m>> Total frame loss: -16.24399185180664\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 389 with src: [146,  70,  67,  76] and target: [120,  60,  72,  87]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0389.jpg\n",
            "|->> Beginning tracking for bbox:[146  70  67  76]\n",
            "   \u001b[33m|->> #32-th Action selection: 0/LEFT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [144  70  67  76]\n",
            "         |->> Action Probabilities (Rounded): [0.0928 0.0919 0.0867 0.0907 0.0928 0.0912 0.0926 0.0943 0.0933 0.0852\n",
            " 0.0885], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09283601 0.09186227 0.08668571 0.09073311 0.09281665 0.09116711\n",
            " 0.09263085 0.09429345 0.09326363 0.08523007 0.08848114], argmax=7\n",
            "|->> Revisiting bbox: [144  70  67  76]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [146,  70,  67,  76] -> [144,  70,  67,  76] (Target was [120,  60,  72,  87])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for LEFT:bbox transition: [146,  70,  67,  76] -> [144,  70,  67,  76] w/ P(a|s)=0.09283600747585297 and iou=0.47327451997924236 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.3769207]\n",
            "\u001b[31m>> Total frame loss: -2.376920700073242\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 390 with src: [144,  70,  67,  76] and target: [112,  60,  74,  85]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0390.jpg\n",
            "|->> Beginning tracking for bbox:[144  70  67  76]\n",
            "   \u001b[33m|->> #33-th Action selection: 4/UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [144  68  67  76]\n",
            "         |->> Action Probabilities (Rounded): [0.0821 0.0922 0.0984 0.0906 0.0922 0.0922 0.0938 0.0949 0.0929 0.083\n",
            " 0.0876], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08211868 0.09219262 0.0984306  0.09064886 0.09222835 0.09217335\n",
            " 0.09383098 0.09489208 0.09294919 0.08295779 0.08757747], argmax=2\n",
            "   \u001b[33m|->> #34-th Action selection: 0/LEFT (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [142  68  67  76]\n",
            "         |->> Action Probabilities (Rounded): [0.0943 0.0904 0.0867 0.0922 0.0904 0.0915 0.0938 0.0947 0.0932 0.0842\n",
            " 0.0884], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09434394 0.09042019 0.08673396 0.09224347 0.09042512 0.09150116\n",
            " 0.09382088 0.09466452 0.09320749 0.0842239  0.08841544], argmax=7\n",
            "   \u001b[33m|->> #35-th Action selection: 0/LEFT (P(a|s) = 0.0820000022649765)\u001b[0m\n",
            "      |->> Bounding box moves to: [140  68  67  76]\n",
            "         |->> Action Probabilities (Rounded): [0.082  0.0905 0.0991 0.0927 0.0909 0.0923 0.0929 0.0954 0.0933 0.0827\n",
            " 0.0881], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.0820222  0.0905163  0.09905225 0.09273103 0.09089564 0.09230464\n",
            " 0.09293818 0.09539709 0.09329168 0.08270563 0.08814533], argmax=2\n",
            "   \u001b[33m|->> #36-th Action selection: 6/DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [140  70  67  76]\n",
            "         |->> Action Probabilities (Rounded): [0.0875 0.0896 0.0933 0.0937 0.0911 0.0924 0.0941 0.0957 0.0921 0.0826\n",
            " 0.088 ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08752061 0.08958456 0.09327281 0.09370708 0.09106049 0.09237937\n",
            " 0.09413289 0.09569854 0.09205861 0.0825877  0.08799737], argmax=7\n",
            "   \u001b[33m|->> #37-th Action selection: 5/2X UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [140  66  67  76]\n",
            "         |->> Action Probabilities (Rounded): [0.0913 0.089  0.0919 0.0942 0.093  0.0924 0.0908 0.0951 0.0917 0.0833\n",
            " 0.0873], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09132326 0.08897591 0.09186935 0.09423135 0.09301873 0.09235422\n",
            " 0.09076932 0.09513265 0.091717   0.08330821 0.0873    ], argmax=7\n",
            "|->> Revisiting bbox: [140  68  67  76]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [144,  70,  67,  76] -> [140,  66,  67,  76] (Target was [112,  60,  74,  85])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for UP:bbox transition: [144,  70,  67,  76] -> [144,  68,  67,  76] w/ P(a|s)=0.09222835302352905 and iou=0.38974358974358975 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for LEFT:bbox transition: [144,  68,  67,  76] -> [142,  68,  67,  76] w/ P(a|s)=0.09434393793344498 and iou=0.41602388653894 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for LEFT:bbox transition: [142,  68,  67,  76] -> [140,  68,  67,  76] w/ P(a|s)=0.08202219754457474 and iou=0.44331727111336544 and reward=-1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-1.0) for DOWN:bbox transition: [140,  68,  67,  76] -> [140,  70,  67,  76] w/ P(a|s)=0.09413288533687592 and iou=0.434947049924357 and reward=-1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-1.0) for 2X UP:bbox transition: [140,  70,  67,  76] -> [140,  66,  67,  76] w/ P(a|s)=0.09235422313213348 and iou=0.44331727111336544 and reward=-1.0 and discount=0.96059601\n",
            "   |->> Assigned losses: [-2.3834877 -2.3372004 -2.451     -2.292863  -2.2882588]\n",
            "\u001b[31m>> Total frame loss: -11.752809524536133\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 391 with src: [140,  66,  67,  76] and target: [106,  61,  74,  85]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0391.jpg\n",
            "|->> Beginning tracking for bbox:[140  66  67  76]\n",
            "|->> Revisiting bbox: [140  66  67  76]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #38-th Action selection: 8/STOP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [140  66  67  76]\n",
            "         |->> Action Probabilities (Rounded): [0.0923 0.0888 0.0928 0.0932 0.0913 0.0915 0.0928 0.0945 0.0913 0.0837\n",
            " 0.0878], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09232838 0.08880045 0.09284963 0.09315181 0.09131383 0.0915108\n",
            " 0.09276191 0.09453688 0.09126138 0.08367946 0.08780544], argmax=7\n",
            "         |->> Hit a STOP on the 38-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [140,  66,  67,  76] -> [140,  66,  67,  76] (Target was [106,  61,  74,  85])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [140,  66,  67,  76] -> [140,  66,  67,  76] w/ P(a|s)=0.0912613794207573 and iou=0.3644210021577559 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.3940277]\n",
            "\u001b[31m>> Total frame loss: -2.3940277099609375\u001b[0m\n",
            "Final bounding box: [140  66  67  76] reached in 38 timesteps (originating from [145  65  72  81]). Target was [106  61  74  85]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 392 in t=38 timesteps ################\u001b[0m\n",
            "\n",
            "\u001b[36m####################### EPISODE # 4 ############################\u001b[0m\n",
            "Starting bounding box for adnet_datasets/OTB/FaceOcc2: frames 381:391 is [145  65  72  81].\n",
            "\u001b[34m>> Attempting to reach frame 382 with src: [145,  65,  72,  81] and target: [149,  66,  69,  81]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0382.jpg\n",
            "|->> Beginning tracking for bbox:[145  65  72  81]\n",
            "   \u001b[33m|->> #1-th Action selection: 9/SCALE DOWN (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [146  66  69  78]\n",
            "         |->> Action Probabilities (Rounded): [0.0909 0.0908 0.091  0.0909 0.0909 0.0908 0.091  0.091  0.0912 0.0908\n",
            " 0.0909], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09088156 0.09078381 0.09096917 0.09092985 0.09091397 0.0907969\n",
            " 0.09095241 0.0909557  0.09115039 0.09079774 0.09086843], argmax=8\n",
            "   \u001b[33m|->> #2-th Action selection: 5/2X UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [146  62  69  78]\n",
            "         |->> Action Probabilities (Rounded): [0.0904 0.0913 0.0912 0.0917 0.0913 0.0912 0.0915 0.0917 0.0921 0.0857\n",
            " 0.0919], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09043553 0.09125423 0.09120771 0.09171186 0.09129062 0.09124953\n",
            " 0.09150833 0.09171443 0.09205465 0.0856851  0.09188807], argmax=8\n",
            "   \u001b[33m|->> #3-th Action selection: 2/RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [148  62  69  78]\n",
            "         |->> Action Probabilities (Rounded): [0.0911 0.0911 0.0913 0.0915 0.0912 0.0897 0.0917 0.0916 0.0926 0.0875\n",
            " 0.0906], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09107316 0.09108819 0.09128071 0.09152672 0.09121618 0.08974714\n",
            " 0.09167677 0.09158874 0.09263491 0.0875493  0.09061817], argmax=8\n",
            "|->> Revisiting bbox: [148  62  69  78]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [145,  65,  72,  81] -> [148,  62,  69,  78] (Target was [149,  66,  69,  81])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for SCALE DOWN:bbox transition: [145,  65,  72,  81] -> [146,  66,  69,  78] w/ P(a|s)=0.09079773724079132 and iou=0.884080370942813 and reward=1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for 2X UP:bbox transition: [146,  66,  69,  78] -> [146,  62,  69,  78] w/ P(a|s)=0.09124953299760818 and iou=0.8023656973878758 and reward=1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (1.0) for RIGHT:bbox transition: [146,  62,  69,  78] -> [148,  62,  69,  78] w/ P(a|s)=0.09128071367740631 and iou=0.8472806869843408 and reward=1.0 and discount=0.9801\n",
            "   |->> Assigned losses: [2.3991208 2.370216  2.3461788]\n",
            "\u001b[92m>> Total frame loss: 7.11551570892334\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 383 with src: [148,  62,  69,  78] and target: [144,  67,  73,  79]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0383.jpg\n",
            "|->> Beginning tracking for bbox:[148  62  69  78]\n",
            "   \u001b[33m|->> #4-th Action selection: 3/2X RIGHT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [152  62  69  78]\n",
            "         |->> Action Probabilities (Rounded): [0.0972 0.0911 0.0835 0.0926 0.0911 0.0907 0.0922 0.0922 0.0927 0.086\n",
            " 0.0907], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09719557 0.09114531 0.08351433 0.09257238 0.09114607 0.09067576\n",
            " 0.09219204 0.09216246 0.0927047  0.08596709 0.09072431], argmax=0\n",
            "   \u001b[33m|->> #5-th Action selection: 2/RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [154  62  69  78]\n",
            "         |->> Action Probabilities (Rounded): [0.0888 0.0924 0.0919 0.0891 0.0919 0.0905 0.0921 0.0926 0.0929 0.0874\n",
            " 0.0904], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0887742  0.09237531 0.09194912 0.08908118 0.09190837 0.09050947\n",
            " 0.09210303 0.09256813 0.09290604 0.08743017 0.090395  ], argmax=8\n",
            "   \u001b[33m|->> #6-th Action selection: 5/2X UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [154  58  69  78]\n",
            "         |->> Action Probabilities (Rounded): [0.0997 0.0914 0.0804 0.0908 0.0915 0.092  0.0927 0.0933 0.0931 0.0859\n",
            " 0.0893], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.0996801  0.09136331 0.08041028 0.09080375 0.09146346 0.09198522\n",
            " 0.09270325 0.09326345 0.09305171 0.08592895 0.08934652], argmax=0\n",
            "   \u001b[33m|->> #7-th Action selection: 0/LEFT (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [152  58  69  78]\n",
            "         |->> Action Probabilities (Rounded): [0.0882 0.0927 0.092  0.0893 0.0918 0.0902 0.093  0.0932 0.0931 0.0869\n",
            " 0.0895], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08821353 0.09272391 0.09202099 0.08927064 0.09181295 0.09016386\n",
            " 0.09303113 0.09322116 0.09312028 0.08689985 0.08952165], argmax=7\n",
            "|->> Revisiting bbox: [152  58  69  78]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [148,  62,  69,  78] -> [152,  58,  69,  78] (Target was [144,  67,  73,  79])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [148,  62,  69,  78] -> [152,  62,  69,  78] w/ P(a|s)=0.09257237613201141 and iou=0.7409431605246721 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for RIGHT:bbox transition: [152,  62,  69,  78] -> [154,  62,  69,  78] w/ P(a|s)=0.09194912016391754 and iou=0.7021374045801527 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for 2X UP:bbox transition: [154,  62,  69,  78] -> [154,  58,  69,  78] w/ P(a|s)=0.09198521822690964 and iou=0.6390767421346663 and reward=-1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-1.0) for LEFT:bbox transition: [154,  58,  69,  78] -> [152,  58,  69,  78] w/ P(a|s)=0.08821352571249008 and iou=0.6730192076830732 and reward=-1.0 and discount=0.970299\n",
            "   |->> Assigned losses: [-2.3797646 -2.3626547 -2.3386436 -2.3558812]\n",
            "\u001b[31m>> Total frame loss: -9.436944007873535\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 384 with src: [152,  58,  69,  78] and target: [147,  66,  70,  81]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0384.jpg\n",
            "|->> Beginning tracking for bbox:[152  58  69  78]\n",
            "   \u001b[33m|->> #8-th Action selection: 5/2X UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [152  54  69  78]\n",
            "         |->> Action Probabilities (Rounded): [0.0865 0.0925 0.0941 0.091  0.0917 0.0912 0.0933 0.094  0.093  0.0846\n",
            " 0.0883], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08646606 0.09251712 0.09410363 0.09095796 0.09166832 0.09120592\n",
            " 0.09325323 0.09398969 0.09297521 0.08460966 0.08825321], argmax=2\n",
            "   \u001b[33m|->> #9-th Action selection: 3/2X RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [156  54  69  78]\n",
            "         |->> Action Probabilities (Rounded): [0.0924 0.0918 0.0884 0.0908 0.0916 0.0897 0.0935 0.0941 0.0933 0.0854\n",
            " 0.089 ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09237438 0.09183753 0.08837415 0.09083828 0.09160186 0.08971833\n",
            " 0.09354058 0.09405511 0.09327029 0.08541822 0.0889713 ], argmax=7\n",
            "   \u001b[33m|->> #10-th Action selection: 6/DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [156  56  69  78]\n",
            "         |->> Action Probabilities (Rounded): [0.0908 0.0921 0.0903 0.0894 0.0921 0.0903 0.0938 0.0943 0.0923 0.086\n",
            " 0.0885], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.0908254  0.09211639 0.09032384 0.08940029 0.09210382 0.090312\n",
            " 0.09376733 0.09430081 0.09232899 0.08597331 0.08854783], argmax=7\n",
            "   \u001b[33m|->> #11-th Action selection: 0/LEFT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [154  56  69  78]\n",
            "         |->> Action Probabilities (Rounded): [0.093  0.0915 0.0885 0.0899 0.0931 0.0904 0.0916 0.0946 0.0932 0.0857\n",
            " 0.0884], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09302835 0.09150919 0.08853833 0.08992572 0.09312104 0.09042052\n",
            " 0.0916328  0.0946205  0.09319205 0.08565409 0.0883574 ], argmax=7\n",
            "   \u001b[33m|->> #12-th Action selection: 3/2X RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [158  56  69  78]\n",
            "         |->> Action Probabilities (Rounded): [0.0853 0.0917 0.0971 0.0905 0.0911 0.0915 0.0934 0.0946 0.0933 0.0844\n",
            " 0.0869], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08530791 0.09173708 0.09708832 0.09054011 0.09109635 0.09153862\n",
            " 0.09339909 0.09459835 0.09332398 0.08444794 0.08692224], argmax=2\n",
            "   \u001b[33m|->> #13-th Action selection: 3/2X RIGHT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [162  56  69  78]\n",
            "         |->> Action Probabilities (Rounded): [0.0952 0.091  0.0861 0.0888 0.0928 0.0925 0.0925 0.0946 0.0928 0.0858\n",
            " 0.0881], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09521224 0.09099106 0.08607521 0.08876543 0.09281236 0.09245881\n",
            " 0.09246773 0.09455533 0.09283187 0.08575911 0.08807085], argmax=0\n",
            "   \u001b[33m|->> #14-th Action selection: 10/SCALE UP (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [160  54  71  80]\n",
            "         |->> Action Probabilities (Rounded): [0.0909 0.091  0.09   0.0878 0.0924 0.0927 0.0935 0.0946 0.0922 0.0867\n",
            " 0.0881], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09091398 0.09097046 0.09004671 0.08776161 0.09241337 0.09273841\n",
            " 0.09350051 0.09464415 0.09219103 0.08669141 0.08812837], argmax=7\n",
            "   \u001b[33m|->> #15-th Action selection: 0/LEFT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [158  54  71  80]\n",
            "         |->> Action Probabilities (Rounded): [0.0933 0.0906 0.0875 0.0895 0.0934 0.0928 0.0935 0.0949 0.0933 0.0881\n",
            " 0.0831], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09328719 0.09060724 0.08748292 0.08948477 0.0933697  0.09280539\n",
            " 0.09352254 0.09492473 0.09333701 0.08806181 0.08311672], argmax=7\n",
            "   \u001b[33m|->> #16-th Action selection: 1/2X LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [154  54  71  80]\n",
            "         |->> Action Probabilities (Rounded): [0.085  0.0905 0.0959 0.0909 0.0925 0.0933 0.0937 0.0953 0.0936 0.0846\n",
            " 0.0848], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.0850455  0.09050498 0.09591216 0.09086186 0.09247531 0.09329956\n",
            " 0.09367466 0.09530424 0.09357545 0.08455041 0.0847958 ], argmax=2\n",
            "   \u001b[33m|->> #17-th Action selection: 6/DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [154  56  71  80]\n",
            "         |->> Action Probabilities (Rounded): [0.0942 0.0873 0.0872 0.091  0.0934 0.0935 0.094  0.0952 0.0927 0.0864\n",
            " 0.085 ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09418963 0.08731882 0.087205   0.09098727 0.09341113 0.09354778\n",
            " 0.0939789  0.09523097 0.09272227 0.08637533 0.0850329 ], argmax=7\n",
            "   \u001b[33m|->> #18-th Action selection: 7/2X DOWN (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [154  60  71  80]\n",
            "         |->> Action Probabilities (Rounded): [0.0892 0.0883 0.0914 0.0905 0.0946 0.0936 0.0916 0.0952 0.0924 0.0875\n",
            " 0.0858], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08919627 0.08832958 0.09137763 0.09047218 0.09460519 0.09362707\n",
            " 0.09156106 0.09516513 0.09235726 0.08751923 0.08578946], argmax=7\n",
            "   \u001b[33m|->> #19-th Action selection: 1/2X LEFT (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [150  60  71  80]\n",
            "         |->> Action Probabilities (Rounded): [0.0926 0.0881 0.0889 0.0911 0.0931 0.0934 0.0927 0.093  0.0925 0.0881\n",
            " 0.0866], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.09255455 0.0880727  0.08885635 0.09105133 0.09307657 0.09344868\n",
            " 0.09274188 0.09299038 0.09248826 0.08809136 0.08662789], argmax=5\n",
            "   \u001b[33m|->> #20-th Action selection: 2/RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [152  60  71  80]\n",
            "         |->> Action Probabilities (Rounded): [0.0913 0.0864 0.0907 0.0916 0.0938 0.0929 0.0928 0.0931 0.0929 0.0876\n",
            " 0.0869], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.09130846 0.08637953 0.09071846 0.09160648 0.09377743 0.09293554\n",
            " 0.09279687 0.09314404 0.09286587 0.08755545 0.08691192], argmax=4\n",
            "   \u001b[33m|->> #21-th Action selection: 1/2X LEFT (P(a|s) = 0.0860000029206276)\u001b[0m\n",
            "      |->> Bounding box moves to: [148  60  71  80]\n",
            "         |->> Action Probabilities (Rounded): [0.0986 0.0861 0.0826 0.0921 0.0928 0.0941 0.0941 0.0941 0.0929 0.0863\n",
            " 0.0864], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09862164 0.08614799 0.08263364 0.09205683 0.0927562  0.09408309\n",
            " 0.09408681 0.09407287 0.09285093 0.08631901 0.08637094], argmax=0\n",
            "   \u001b[33m|->> #22-th Action selection: 7/2X DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [148  64  71  80]\n",
            "         |->> Action Probabilities (Rounded): [0.0873 0.0856 0.0921 0.0905 0.0945 0.0934 0.0937 0.0936 0.0933 0.0887\n",
            " 0.0873], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.08733094 0.0856331  0.0921039  0.09053948 0.0944633  0.09343503\n",
            " 0.09370442 0.09356599 0.09325758 0.08866898 0.08729722], argmax=4\n",
            "   \u001b[33m|->> #23-th Action selection: 4/UP (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [148  62  71  80]\n",
            "         |->> Action Probabilities (Rounded): [0.0914 0.0859 0.0895 0.0915 0.0936 0.093  0.0939 0.0919 0.0937 0.0881\n",
            " 0.0875], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09142524 0.08594599 0.08947877 0.09148058 0.09361701 0.09297293\n",
            " 0.09386091 0.09194326 0.09367584 0.08807396 0.08752546], argmax=6\n",
            "|->> Revisiting bbox: [148  62  71  80]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [152,  58,  69,  78] -> [148,  62,  71,  80] (Target was [147,  66,  70,  81])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for 2X UP:bbox transition: [152,  58,  69,  78] -> [152,  54,  69,  78] w/ P(a|s)=0.09120591729879379 and iou=0.6344276841171251 and reward=1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for 2X RIGHT:bbox transition: [152,  54,  69,  78] -> [156,  54,  69,  78] w/ P(a|s)=0.09083828330039978 and iou=0.5730145175064048 and reward=1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (1.0) for DOWN:bbox transition: [156,  54,  69,  78] -> [156,  56,  69,  78] w/ P(a|s)=0.09376733005046844 and iou=0.600811123986095 and reward=1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (1.0) for LEFT:bbox transition: [156,  56,  69,  78] -> [154,  56,  69,  78] w/ P(a|s)=0.09302835166454315 and iou=0.6329787234042553 and reward=1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (1.0) for 2X RIGHT:bbox transition: [154,  56,  69,  78] -> [158,  56,  69,  78] w/ P(a|s)=0.09054011106491089 and iou=0.5698863636363637 and reward=1.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (1.0) for 2X RIGHT:bbox transition: [158,  56,  69,  78] -> [162,  56,  69,  78] w/ P(a|s)=0.08876542747020721 and iou=0.5114879649890591 and reward=1.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (1.0) for SCALE UP:bbox transition: [162,  56,  69,  78] -> [160,  54,  71,  80] w/ P(a|s)=0.08812836557626724 and iou=0.5185978057265186 and reward=1.0 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (1.0) for LEFT:bbox transition: [160,  54,  71,  80] -> [158,  54,  71,  80] w/ P(a|s)=0.09328719228506088 and iou=0.5467429817388935 and reward=1.0 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (1.0) for 2X LEFT:bbox transition: [158,  54,  71,  80] -> [154,  54,  71,  80] w/ P(a|s)=0.09050498157739639 and iou=0.6062836116614775 and reward=1.0 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (1.0) for DOWN:bbox transition: [154,  54,  71,  80] -> [154,  56,  71,  80] w/ P(a|s)=0.0939788967370987 and iou=0.6354466858789626 and reward=1.0 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (1.0) for 2X DOWN:bbox transition: [154,  56,  71,  80] -> [154,  60,  71,  80] w/ P(a|s)=0.09516513347625732 and iou=0.6970693779904307 and reward=1.0 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (1.0) for 2X LEFT:bbox transition: [154,  60,  71,  80] -> [150,  60,  71,  80] w/ P(a|s)=0.08807270228862762 and iou=0.7756570713391739 and reward=1.0 and discount=0.8953382542587164\n",
            "   |->> t=13 Diff-Reward (1.0) for RIGHT:bbox transition: [150,  60,  71,  80] -> [152,  60,  71,  80] w/ P(a|s)=0.09071845561265945 and iou=0.735474006116208 and reward=1.0 and discount=0.8863848717161292\n",
            "   |->> t=14 Diff-Reward (1.0) for 2X LEFT:bbox transition: [152,  60,  71,  80] -> [148,  60,  71,  80] w/ P(a|s)=0.08614799380302429 and iou=0.8177450352338245 and reward=1.0 and discount=0.8775210229989678\n",
            "   |->> t=15 Diff-Reward (1.0) for 2X DOWN:bbox transition: [148,  60,  71,  80] -> [148,  64,  71,  80] w/ P(a|s)=0.09356599301099777 and iou=0.9018096514745308 and reward=1.0 and discount=0.8687458127689782\n",
            "   |->> t=16 Diff-Reward (1.0) for UP:bbox transition: [148,  64,  71,  80] -> [148,  62,  71,  80] w/ P(a|s)=0.09361700713634491 and iou=0.8588273829020635 and reward=1.0 and discount=0.8600583546412884\n",
            "   |->> Assigned losses: [2.3946354 2.3746877 2.3198366 2.3043156 2.3073153 2.3030677 2.2868185\n",
            " 2.2109265 2.216756  2.1601806 2.1272347 2.1753073 2.1273186 2.1514082\n",
            " 2.0581355 2.0370853]\n",
            "\u001b[92m>> Total frame loss: 35.55502700805664\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 385 with src: [148,  62,  71,  80] and target: [141,  67,  72,  80]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0385.jpg\n",
            "|->> Beginning tracking for bbox:[148  62  71  80]\n",
            "   \u001b[33m|->> #24-th Action selection: 0/LEFT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [146  62  71  80]\n",
            "         |->> Action Probabilities (Rounded): [0.0894 0.0868 0.092  0.0927 0.0917 0.0926 0.0945 0.0926 0.093  0.0878\n",
            " 0.0869], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08939739 0.08675641 0.09202764 0.0927285  0.0917009  0.09256314\n",
            " 0.094549   0.09259737 0.09304285 0.08777718 0.08685968], argmax=6\n",
            "   \u001b[33m|->> #25-th Action selection: 1/2X LEFT (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [142  62  71  80]\n",
            "         |->> Action Probabilities (Rounded): [0.0842 0.0877 0.0979 0.0931 0.0918 0.0929 0.0935 0.0928 0.093  0.085\n",
            " 0.0881], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08424425 0.08765676 0.09790869 0.09314308 0.0917761  0.09287891\n",
            " 0.093478   0.09278991 0.09302802 0.08496535 0.08813104], argmax=2\n",
            "|->> Revisiting bbox: [142  62  71  80]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [148,  62,  71,  80] -> [142,  62,  71,  80] (Target was [141,  67,  72,  80])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for LEFT:bbox transition: [148,  62,  71,  80] -> [146,  62,  71,  80] w/ P(a|s)=0.08939739316701889 and iou=0.7833203429462198 and reward=1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for 2X LEFT:bbox transition: [146,  62,  71,  80] -> [142,  62,  71,  80] w/ P(a|s)=0.08765675872564316 and iou=0.8708094848732625 and reward=1.0 and discount=0.99\n",
            "   |->> Assigned losses: [2.4146638 2.4099834]\n",
            "\u001b[92m>> Total frame loss: 4.824646949768066\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 386 with src: [142,  62,  71,  80] and target: [137,  65,  73,  81]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0386.jpg\n",
            "|->> Beginning tracking for bbox:[142  62  71  80]\n",
            "   \u001b[33m|->> #26-th Action selection: 2/RIGHT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [144  62  71  80]\n",
            "         |->> Action Probabilities (Rounded): [0.0895 0.0855 0.0895 0.093  0.0927 0.0921 0.0943 0.0929 0.0941 0.0873\n",
            " 0.0892], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08952322 0.08548275 0.08950648 0.09297942 0.09266277 0.09210828\n",
            " 0.09427977 0.09290174 0.09406588 0.08726232 0.08922738], argmax=6\n",
            "   \u001b[33m|->> #27-th Action selection: 2/RIGHT (P(a|s) = 0.0860000029206276)\u001b[0m\n",
            "      |->> Bounding box moves to: [146  62  71  80]\n",
            "         |->> Action Probabilities (Rounded): [0.0942 0.0872 0.0855 0.0927 0.0932 0.0932 0.0939 0.0932 0.0927 0.0859\n",
            " 0.0883], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09424014 0.08721806 0.08553585 0.09268481 0.09316704 0.09322957\n",
            " 0.09387618 0.09317838 0.09271001 0.08585045 0.08830951], argmax=0\n",
            "   \u001b[33m|->> #28-th Action selection: 7/2X DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [146  66  71  80]\n",
            "         |->> Action Probabilities (Rounded): [0.094  0.0876 0.0839 0.0924 0.0935 0.0937 0.0945 0.0942 0.0928 0.0855\n",
            " 0.0879], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09404584 0.08764267 0.08388935 0.09240668 0.09346813 0.09366633\n",
            " 0.09445479 0.09417225 0.09277639 0.08554845 0.08792906], argmax=6\n",
            "   \u001b[33m|->> #29-th Action selection: 0/LEFT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [144  66  71  80]\n",
            "         |->> Action Probabilities (Rounded): [0.0888 0.0886 0.0916 0.091  0.0936 0.093  0.0941 0.0926 0.0929 0.086\n",
            " 0.0878], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08876152 0.08864032 0.0915576  0.09099412 0.09362742 0.09301565\n",
            " 0.0941418  0.09263881 0.09289826 0.0859591  0.08776533], argmax=6\n",
            "|->> Revisiting bbox: [144  66  71  80]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [142,  62,  71,  80] -> [144,  66,  71,  80] (Target was [137,  65,  73,  81])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for RIGHT:bbox transition: [142,  62,  71,  80] -> [144,  62,  71,  80] w/ P(a|s)=0.08950648456811905 and iou=0.7805252649362617 and reward=1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for RIGHT:bbox transition: [144,  62,  71,  80] -> [146,  62,  71,  80] w/ P(a|s)=0.08553584665060043 and iou=0.7393848462115529 and reward=1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (1.0) for 2X DOWN:bbox transition: [146,  62,  71,  80] -> [146,  66,  71,  80] w/ P(a|s)=0.09417225420475006 and iou=0.7909779082342037 and reward=1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (1.0) for LEFT:bbox transition: [146,  66,  71,  80] -> [144,  66,  71,  80] w/ P(a|s)=0.08876152336597443 and iou=0.8363693964834469 and reward=1.0 and discount=0.970299\n",
            "   |->> Assigned losses: [2.4134443 2.4342318 2.3156133 2.349872 ]\n",
            "\u001b[92m>> Total frame loss: 9.513161659240723\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 387 with src: [144,  66,  71,  80] and target: [132,  63,  69,  81]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0387.jpg\n",
            "|->> Beginning tracking for bbox:[144  66  71  80]\n",
            "   \u001b[33m|->> #30-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08399999886751175)\u001b[0m\n",
            "      |->> Bounding box moves to: [145  67  68  77]\n",
            "         |->> Action Probabilities (Rounded): [0.0847 0.0895 0.0961 0.0921 0.0928 0.0937 0.0944 0.0936 0.0923 0.0835\n",
            " 0.0871], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08474463 0.08946174 0.09610718 0.09214088 0.09277346 0.09372222\n",
            " 0.09444761 0.09364174 0.09234846 0.08352429 0.08708772], argmax=2\n",
            "   \u001b[33m|->> #31-th Action selection: 10/SCALE UP (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [143  65  70  79]\n",
            "         |->> Action Probabilities (Rounded): [0.0925 0.0894 0.0884 0.0935 0.0933 0.0935 0.0938 0.0934 0.0922 0.0808\n",
            " 0.0892], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09252661 0.08939959 0.08844316 0.0935015  0.09330637 0.09348731\n",
            " 0.09382003 0.09335775 0.09216302 0.08079182 0.08920283], argmax=6\n",
            "   \u001b[33m|->> #32-th Action selection: 7/2X DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [143  69  70  79]\n",
            "         |->> Action Probabilities (Rounded): [0.0898 0.0908 0.0922 0.0931 0.0934 0.094  0.0938 0.0941 0.0929 0.0838\n",
            " 0.0822], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08977049 0.0907632  0.09220269 0.09305513 0.09338059 0.09397595\n",
            " 0.09378321 0.09414364 0.09285729 0.08383494 0.08223285], argmax=7\n",
            "   \u001b[33m|->> #33-th Action selection: 3/2X RIGHT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [147  69  70  79]\n",
            "         |->> Action Probabilities (Rounded): [0.0931 0.09   0.0903 0.0928 0.0934 0.0933 0.0939 0.0927 0.0925 0.0824\n",
            " 0.0856], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09306058 0.08999481 0.09034019 0.09278452 0.09342339 0.09328159\n",
            " 0.0939313  0.09268236 0.09251914 0.08238043 0.08560172], argmax=6\n",
            "   \u001b[33m|->> #34-th Action selection: 5/2X UP (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [147  65  70  79]\n",
            "         |->> Action Probabilities (Rounded): [0.0924 0.0902 0.0899 0.091  0.0939 0.0935 0.0937 0.0931 0.093  0.0843\n",
            " 0.0849], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.09244048 0.09022382 0.08991357 0.09098729 0.0939467  0.09351571\n",
            " 0.09366471 0.09314411 0.09299123 0.08426002 0.08491243], argmax=4\n",
            "   \u001b[33m|->> #35-th Action selection: 5/2X UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [147  61  70  79]\n",
            "         |->> Action Probabilities (Rounded): [0.0915 0.0907 0.0894 0.0908 0.0935 0.0921 0.094  0.0922 0.0934 0.0855\n",
            " 0.0869], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09153223 0.0906836  0.0893622  0.09077021 0.09350668 0.09213227\n",
            " 0.09398426 0.09222237 0.09335458 0.08553439 0.08691715], argmax=6\n",
            "   \u001b[33m|->> #36-th Action selection: 1/2X LEFT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [143  61  70  79]\n",
            "         |->> Action Probabilities (Rounded): [0.0915 0.0917 0.0899 0.0911 0.093  0.0903 0.0939 0.0919 0.0939 0.0863\n",
            " 0.0866], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09154572 0.09167445 0.0898679  0.09106961 0.09298096 0.09032482\n",
            " 0.09386207 0.09191104 0.09385891 0.08628765 0.08661688], argmax=6\n",
            "   \u001b[33m|->> #37-th Action selection: 2/RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [145  61  70  79]\n",
            "         |->> Action Probabilities (Rounded): [0.0902 0.089  0.0911 0.0918 0.0933 0.0899 0.0936 0.0921 0.0945 0.0872\n",
            " 0.0874], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09015642 0.08897191 0.09114066 0.09183559 0.09326181 0.08993012\n",
            " 0.09355178 0.09208088 0.09452628 0.08718222 0.08736229], argmax=8\n",
            "   \u001b[33m|->> #38-th Action selection: 5/2X UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [145  57  70  79]\n",
            "         |->> Action Probabilities (Rounded): [0.0979 0.089  0.0823 0.0926 0.0925 0.0908 0.0937 0.0935 0.094  0.0865\n",
            " 0.0873], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09787722 0.08902791 0.08226545 0.09257296 0.09245116 0.09078962\n",
            " 0.0937238  0.09346315 0.094009   0.08650742 0.08731227], argmax=0\n",
            "   \u001b[33m|->> #39-th Action selection: 0/LEFT (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [143  57  70  79]\n",
            "         |->> Action Probabilities (Rounded): [0.0876 0.0894 0.0918 0.092  0.0928 0.0892 0.0942 0.0937 0.0945 0.0872\n",
            " 0.0876], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08763062 0.0893631  0.09176203 0.09196484 0.09283379 0.08923306\n",
            " 0.09420983 0.09366626 0.09454039 0.08721967 0.08757641], argmax=8\n",
            "   \u001b[33m|->> #40-th Action selection: 5/2X UP (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [143  53  70  79]\n",
            "         |->> Action Probabilities (Rounded): [0.0843 0.0906 0.0944 0.0926 0.0924 0.0899 0.0942 0.094  0.0944 0.0859\n",
            " 0.0875], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08429602 0.09055948 0.09441787 0.09255169 0.09236845 0.08989721\n",
            " 0.09419155 0.09398418 0.09438058 0.08588176 0.08747123], argmax=2\n",
            "   \u001b[33m|->> #41-th Action selection: 5/2X UP (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [143  49  70  79]\n",
            "         |->> Action Probabilities (Rounded): [0.0912 0.0895 0.089  0.0924 0.0919 0.0884 0.094  0.0934 0.0942 0.0881\n",
            " 0.0878], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09119651 0.08946753 0.08900554 0.09244908 0.09190949 0.08836221\n",
            " 0.09402999 0.0934202  0.09424726 0.08810434 0.0878079 ], argmax=8\n",
            "   \u001b[33m|->> #42-th Action selection: 0/LEFT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [141  49  70  79]\n",
            "         |->> Action Probabilities (Rounded): [0.0897 0.0898 0.0924 0.0916 0.0914 0.0874 0.0939 0.0932 0.0938 0.0879\n",
            " 0.089 ], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08966025 0.08984936 0.09235685 0.09156252 0.09140604 0.08742917\n",
            " 0.09394553 0.09315971 0.09375896 0.0878925  0.08897911], argmax=6\n",
            "   \u001b[33m|->> #43-th Action selection: 0/LEFT (P(a|s) = 0.08399999886751175)\u001b[0m\n",
            "      |->> Bounding box moves to: [139  49  70  79]\n",
            "         |->> Action Probabilities (Rounded): [0.0842 0.0896 0.097  0.0929 0.091  0.0883 0.0944 0.0947 0.0942 0.0853\n",
            " 0.0884], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08419082 0.08963114 0.09696059 0.09289473 0.09098642 0.0883275\n",
            " 0.09440728 0.09466322 0.09423866 0.08525987 0.08843973], argmax=2\n",
            "|->> Revisiting bbox: [143  49  70  79]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [144,  66,  71,  80] -> [139,  49,  70,  79] (Target was [132,  63,  69,  81])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [144,  66,  71,  80] -> [145,  67,  68,  77] w/ P(a|s)=0.08352429419755936 and iou=0.6620604943958237 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for SCALE UP:bbox transition: [145,  67,  68,  77] -> [143,  65,  70,  79] w/ P(a|s)=0.08920282870531082 and iou=0.7009331497628882 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for 2X DOWN:bbox transition: [143,  65,  70,  79] -> [143,  69,  70,  79] w/ P(a|s)=0.09414363652467728 and iou=0.6426355443935589 and reward=-1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [143,  69,  70,  79] -> [147,  69,  70,  79] w/ P(a|s)=0.09278451651334763 and iou=0.5729240345169048 and reward=-1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-1.0) for 2X UP:bbox transition: [147,  69,  70,  79] -> [147,  65,  70,  79] w/ P(a|s)=0.09351570904254913 and iou=0.6225010944112068 and reward=-1.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-1.0) for 2X UP:bbox transition: [147,  65,  70,  79] -> [147,  61,  70,  79] w/ P(a|s)=0.09213227033615112 and iou=0.5973279701192358 and reward=-1.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [147,  61,  70,  79] -> [143,  61,  70,  79] w/ P(a|s)=0.09167444705963135 and iou=0.6712761160378776 and reward=-1.0 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (-1.0) for RIGHT:bbox transition: [143,  61,  70,  79] -> [145,  61,  70,  79] w/ P(a|s)=0.09114065766334534 and iou=0.6334655501689437 and reward=-1.0 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (-1.0) for 2X UP:bbox transition: [145,  61,  70,  79] -> [145,  57,  70,  79] w/ P(a|s)=0.09078961610794067 and iou=0.5814251173375053 and reward=-1.0 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (-1.0) for LEFT:bbox transition: [145,  57,  70,  79] -> [143,  57,  70,  79] w/ P(a|s)=0.08763062208890915 and iou=0.614960058097313 and reward=-1.0 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (-1.0) for 2X UP:bbox transition: [143,  57,  70,  79] -> [143,  53,  70,  79] w/ P(a|s)=0.08989720791578293 and iou=0.5623155824083181 and reward=-1.0 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (-1.0) for 2X UP:bbox transition: [143,  53,  70,  79] -> [143,  49,  70,  79] w/ P(a|s)=0.0883622094988823 and iou=0.5129949653014015 and reward=-1.0 and discount=0.8953382542587164\n",
            "   |->> t=13 Diff-Reward (-1.0) for LEFT:bbox transition: [143,  49,  70,  79] -> [141,  49,  70,  79] w/ P(a|s)=0.08966024965047836 and iou=0.5402410306136584 and reward=-1.0 and discount=0.8863848717161292\n",
            "   |->> t=14 Diff-Reward (-1.0) for LEFT:bbox transition: [141,  49,  70,  79] -> [139,  49,  70,  79] w/ P(a|s)=0.08419082313776016 and iou=0.5684863873606997 and reward=-1.0 and discount=0.8775210229989678\n",
            "   |->> Assigned losses: [-2.4826179 -2.392674  -2.3159113 -2.306862  -2.2762532 -2.2676642\n",
            " -2.2496777 -2.232624  -2.2138586 -2.2240715 -2.1787362 -2.172369\n",
            " -2.137719  -2.1715746]\n",
            "\u001b[31m>> Total frame loss: -31.62261390686035\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 388 with src: [139,  49,  70,  79] and target: [125,  65,  71,  80]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0388.jpg\n",
            "|->> Beginning tracking for bbox:[139  49  70  79]\n",
            "   \u001b[33m|->> #44-th Action selection: 1/2X LEFT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [135  49  70  79]\n",
            "         |->> Action Probabilities (Rounded): [0.0848 0.0895 0.0968 0.0943 0.0913 0.0892 0.0939 0.0952 0.0939 0.0833\n",
            " 0.0878], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08475403 0.089499   0.09683271 0.0943373  0.09125938 0.08920606\n",
            " 0.09391095 0.0952204  0.09387769 0.08331596 0.08778648], argmax=2\n",
            "   \u001b[33m|->> #45-th Action selection: 2/RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [137  49  70  79]\n",
            "         |->> Action Probabilities (Rounded): [0.0897 0.0865 0.092  0.0939 0.0917 0.0904 0.0944 0.0953 0.0933 0.0845\n",
            " 0.0883], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08974339 0.08647908 0.09200859 0.09388169 0.09169755 0.09035064\n",
            " 0.09442116 0.09531741 0.09326853 0.08448431 0.08834767], argmax=7\n",
            "   \u001b[33m|->> #46-th Action selection: 10/SCALE UP (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [135  47  72  81]\n",
            "         |->> Action Probabilities (Rounded): [0.0959 0.0866 0.0854 0.0939 0.0918 0.0919 0.0947 0.0957 0.0929 0.0835\n",
            " 0.0876], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09594343 0.08663163 0.08540026 0.09394985 0.09178273 0.09192646\n",
            " 0.09467691 0.09573629 0.09286363 0.08353397 0.08755482], argmax=0\n",
            "   \u001b[33m|->> #47-th Action selection: 7/2X DOWN (P(a|s) = 0.09600000083446503)\u001b[0m\n",
            "      |->> Bounding box moves to: [135  51  72  81]\n",
            "         |->> Action Probabilities (Rounded): [0.0892 0.0882 0.0936 0.0931 0.093  0.0917 0.0943 0.0957 0.0934 0.0854\n",
            " 0.0823], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08923685 0.08818255 0.09355397 0.09309182 0.09303612 0.09174757\n",
            " 0.09433242 0.09567261 0.09343832 0.08535783 0.08234997], argmax=7\n",
            "   \u001b[33m|->> #48-th Action selection: 2/RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [137  51  72  81]\n",
            "         |->> Action Probabilities (Rounded): [0.0941 0.0879 0.0909 0.0935 0.0921 0.0915 0.0942 0.0936 0.093  0.0844\n",
            " 0.0848], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09411516 0.0878559  0.09090273 0.09346962 0.09209549 0.09150454\n",
            " 0.09423058 0.09362572 0.09298661 0.084382   0.08483164], argmax=6\n",
            "|->> Revisiting bbox: [135  51  72  81]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [139,  49,  70,  79] -> [137,  51,  72,  81] (Target was [125,  65,  71,  80])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [139,  49,  70,  79] -> [135,  49,  70,  79] w/ P(a|s)=0.08949899673461914 and iou=0.5216506040450658 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for RIGHT:bbox transition: [135,  49,  70,  79] -> [137,  49,  70,  79] w/ P(a|s)=0.09200859069824219 and iou=0.49606299212598426 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for SCALE UP:bbox transition: [137,  49,  70,  79] -> [135,  47,  72,  81] w/ P(a|s)=0.08755481988191605 and iou=0.501108358325727 and reward=-1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-1.0) for 2X DOWN:bbox transition: [135,  47,  72,  81] -> [135,  51,  72,  81] w/ P(a|s)=0.095672607421875 and iou=0.5504377104377104 and reward=-1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-1.0) for RIGHT:bbox transition: [135,  51,  72,  81] -> [137,  51,  72,  81] w/ P(a|s)=0.09090273082256317 and iou=0.5229527715306257 and reward=-1.0 and discount=0.96059601\n",
            "   |->> Assigned losses: [-2.413528  -2.3620145 -2.387024  -2.27712   -2.3034759]\n",
            "\u001b[31m>> Total frame loss: -11.743162155151367\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 389 with src: [137,  51,  72,  81] and target: [120,  60,  72,  87]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0389.jpg\n",
            "|->> Beginning tracking for bbox:[137  51  72  81]\n",
            "   \u001b[33m|->> #49-th Action selection: 0/LEFT (P(a|s) = 0.09799999743700027)\u001b[0m\n",
            "      |->> Bounding box moves to: [135  51  72  81]\n",
            "         |->> Action Probabilities (Rounded): [0.0984 0.0882 0.0842 0.0941 0.0924 0.0931 0.0943 0.0943 0.0926 0.0845\n",
            " 0.084 ], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09837706 0.08819268 0.08418594 0.09407803 0.09240985 0.09314098\n",
            " 0.09427466 0.09429874 0.09256331 0.08450317 0.08397564], argmax=0\n",
            "   \u001b[33m|->> #50-th Action selection: 5/2X UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [135  47  72  81]\n",
            "         |->> Action Probabilities (Rounded): [0.0822 0.0903 0.0996 0.0927 0.0932 0.0931 0.0939 0.0944 0.0926 0.0836\n",
            " 0.0845], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08216435 0.09030925 0.09959929 0.09272006 0.09320837 0.09307101\n",
            " 0.09388594 0.09439056 0.09256152 0.0836271  0.08446255], argmax=2\n",
            "   \u001b[33m|->> #51-th Action selection: 6/DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [135  49  72  81]\n",
            "         |->> Action Probabilities (Rounded): [0.0954 0.0888 0.0875 0.0932 0.0925 0.0919 0.094  0.0942 0.093  0.0845\n",
            " 0.0849], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.0954226  0.0887636  0.08752871 0.09321319 0.09250598 0.09190641\n",
            " 0.09398796 0.09424791 0.09303436 0.08448844 0.08490077], argmax=0\n",
            "|->> Revisiting bbox: [135  51  72  81]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [137,  51,  72,  81] -> [135,  49,  72,  81] (Target was [120,  60,  72,  87])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for LEFT:bbox transition: [137,  51,  72,  81] -> [135,  51,  72,  81] w/ P(a|s)=0.09837706387042999 and iou=0.5135135135135135 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for 2X UP:bbox transition: [135,  51,  72,  81] -> [135,  47,  72,  81] w/ P(a|s)=0.09307100623846054 and iou=0.47153284671532847 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for DOWN:bbox transition: [135,  47,  72,  81] -> [135,  49,  72,  81] w/ P(a|s)=0.09398796409368515 and iou=0.49222797927461137 and reward=-1.0 and discount=0.9801\n",
            "   |->> Assigned losses: [-2.3189476 -2.3506486 -2.317533 ]\n",
            "\u001b[31m>> Total frame loss: -6.987129211425781\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 390 with src: [135,  49,  72,  81] and target: [112,  60,  74,  85]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0390.jpg\n",
            "|->> Beginning tracking for bbox:[135  49  72  81]\n",
            "   \u001b[33m|->> #52-th Action selection: 10/SCALE UP (P(a|s) = 0.08500000089406967)\u001b[0m\n",
            "      |->> Bounding box moves to: [133  47  74  83]\n",
            "         |->> Action Probabilities (Rounded): [0.091  0.0893 0.0942 0.0926 0.0941 0.0927 0.0915 0.0943 0.0911 0.0846\n",
            " 0.0847], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09097644 0.08928771 0.09419451 0.09264445 0.09405695 0.09274358\n",
            " 0.09146421 0.09425516 0.0910969  0.08459555 0.08468448], argmax=7\n",
            "   \u001b[33m|->> #53-th Action selection: 2/RIGHT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [135  47  74  83]\n",
            "         |->> Action Probabilities (Rounded): [0.0943 0.0899 0.0897 0.093  0.0923 0.0925 0.0933 0.0942 0.0925 0.0877\n",
            " 0.0807], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09428681 0.08992718 0.08966021 0.09299012 0.0923144  0.09252062\n",
            " 0.09327976 0.09416027 0.09245701 0.08772065 0.08068298], argmax=0\n",
            "   \u001b[33m|->> #54-th Action selection: 9/SCALE DOWN (P(a|s) = 0.0860000029206276)\u001b[0m\n",
            "      |->> Bounding box moves to: [136  48  71  80]\n",
            "         |->> Action Probabilities (Rounded): [0.0963 0.0908 0.0839 0.0934 0.0932 0.0933 0.0927 0.0938 0.0941 0.0857\n",
            " 0.083 ], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09626458 0.09075561 0.08389366 0.09336206 0.09320623 0.09328656\n",
            " 0.0927053  0.09378424 0.09408674 0.08565731 0.08299775], argmax=0\n",
            "   \u001b[33m|->> #55-th Action selection: 1/2X LEFT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [132  48  71  80]\n",
            "         |->> Action Probabilities (Rounded): [0.089  0.0928 0.0922 0.0922 0.0938 0.0929 0.094  0.0942 0.0927 0.0823\n",
            " 0.084 ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08897638 0.09279574 0.09216027 0.09219048 0.09377571 0.09287077\n",
            " 0.09400154 0.09417861 0.09271845 0.08234981 0.08398227], argmax=7\n",
            "   \u001b[33m|->> #56-th Action selection: 1/2X LEFT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [128  48  71  80]\n",
            "         |->> Action Probabilities (Rounded): [0.0926 0.0894 0.0891 0.0926 0.0941 0.0928 0.0936 0.0937 0.0932 0.0847\n",
            " 0.0842], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0926392  0.089412   0.08907477 0.09258272 0.09406435 0.09284152\n",
            " 0.09363077 0.09369145 0.0932081  0.08466955 0.08418556], argmax=4\n",
            "|->> Revisiting bbox: [132  48  71  80]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [135,  49,  72,  81] -> [128,  48,  71,  80] (Target was [112,  60,  74,  85])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for SCALE UP:bbox transition: [135,  49,  72,  81] -> [133,  47,  74,  83] w/ P(a|s)=0.08468447625637054 and iou=0.42536115569823435 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for RIGHT:bbox transition: [133,  47,  74,  83] -> [135,  47,  74,  83] w/ P(a|s)=0.08966021239757538 and iou=0.4028436018957346 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [135,  47,  74,  83] -> [136,  48,  71,  80] w/ P(a|s)=0.08565731346607208 and iou=0.396732788798133 and reward=-1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [136,  48,  71,  80] -> [132,  48,  71,  80] w/ P(a|s)=0.09279573708772659 and iou=0.44251626898047725 and reward=-1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [132,  48,  71,  80] -> [128,  48,  71,  80] w/ P(a|s)=0.08941199630498886 and iou=0.4914029404435584 and reward=-1.0 and discount=0.96059601\n",
            "   |->> Assigned losses: [-2.468823  -2.387611  -2.4084985 -2.3067448 -2.3193595]\n",
            "\u001b[31m>> Total frame loss: -11.891036987304688\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 391 with src: [128,  48,  71,  80] and target: [106,  61,  74,  85]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0391.jpg\n",
            "|->> Beginning tracking for bbox:[128  48  71  80]\n",
            "   \u001b[33m|->> #57-th Action selection: 1/2X LEFT (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [124  48  71  80]\n",
            "         |->> Action Probabilities (Rounded): [0.0895 0.0875 0.0921 0.0921 0.0932 0.0927 0.094  0.0942 0.0934 0.0842\n",
            " 0.0869], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08953497 0.08749805 0.09212058 0.09212376 0.09324726 0.09274907\n",
            " 0.09401192 0.09415165 0.09344587 0.08423588 0.08688094], argmax=7\n",
            "   \u001b[33m|->> #58-th Action selection: 5/2X UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [124  44  71  80]\n",
            "         |->> Action Probabilities (Rounded): [0.091  0.085  0.0912 0.092  0.0938 0.0926 0.0951 0.0951 0.093  0.085\n",
            " 0.0863], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09100994 0.08499329 0.09117207 0.09202409 0.09375369 0.09260099\n",
            " 0.09514115 0.09507035 0.09296433 0.08495411 0.08631599], argmax=6\n",
            "   \u001b[33m|->> #59-th Action selection: 6/DOWN (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [124  46  71  80]\n",
            "         |->> Action Probabilities (Rounded): [0.0895 0.0852 0.0921 0.0924 0.0932 0.0909 0.0954 0.0947 0.094  0.0854\n",
            " 0.0872], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08949436 0.08521858 0.09214931 0.09242173 0.0931868  0.09085025\n",
            " 0.09538262 0.09467188 0.09400947 0.08537624 0.08723874], argmax=6\n",
            "   \u001b[33m|->> #60-th Action selection: 2/RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [126  46  71  80]\n",
            "         |->> Action Probabilities (Rounded): [0.0885 0.0867 0.092  0.0925 0.0949 0.0907 0.0926 0.0941 0.0933 0.0872\n",
            " 0.0874], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.08851071 0.08670025 0.09202322 0.09247597 0.09493329 0.09074486\n",
            " 0.09256914 0.09411409 0.09333819 0.08720689 0.08738337], argmax=4\n",
            "   \u001b[33m|->> #61-th Action selection: 6/DOWN (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [126  48  71  80]\n",
            "         |->> Action Probabilities (Rounded): [0.0953 0.0874 0.0839 0.0929 0.0925 0.0922 0.0947 0.0945 0.0934 0.086\n",
            " 0.0872], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09533765 0.08739506 0.08390996 0.09289131 0.09250583 0.09222328\n",
            " 0.09466792 0.09448746 0.09335001 0.08603117 0.08720037], argmax=0\n",
            "   \u001b[33m|->> #62-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [127  49  68  77]\n",
            "         |->> Action Probabilities (Rounded): [0.0859 0.0887 0.0936 0.0915 0.0951 0.0921 0.0912 0.0944 0.0936 0.0868\n",
            " 0.0871], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.08591377 0.0887403  0.09358189 0.09151161 0.0950726  0.09207577\n",
            " 0.09115221 0.09442828 0.09362425 0.08684303 0.08705629], argmax=4\n",
            "   \u001b[33m|->> #63-th Action selection: 6/DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [127  51  68  77]\n",
            "         |->> Action Probabilities (Rounded): [0.0905 0.089  0.0903 0.0922 0.0921 0.0923 0.0939 0.0945 0.0938 0.0818\n",
            " 0.0895], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09050885 0.08895849 0.09026259 0.09224865 0.09212714 0.09231839\n",
            " 0.09394192 0.09451877 0.0937999  0.08177784 0.08953745], argmax=7\n",
            "   \u001b[33m|->> #64-th Action selection: 2/RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [129  51  68  77]\n",
            "         |->> Action Probabilities (Rounded): [0.0877 0.0895 0.0924 0.0926 0.095  0.0924 0.09   0.0941 0.0934 0.0843\n",
            " 0.0887], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.08766452 0.08951832 0.09238791 0.09260997 0.0949595  0.09239287\n",
            " 0.08996921 0.09406009 0.09335683 0.0843364  0.08874437], argmax=4\n",
            "   \u001b[33m|->> #65-th Action selection: 7/2X DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [129  55  68  77]\n",
            "         |->> Action Probabilities (Rounded): [0.0959 0.0894 0.0836 0.0931 0.0918 0.0928 0.0935 0.0939 0.093  0.0842\n",
            " 0.0888], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09590691 0.08937317 0.08358642 0.09307336 0.09179856 0.09284923\n",
            " 0.0935348  0.09387103 0.09298034 0.08423475 0.08879137], argmax=0\n",
            "   \u001b[33m|->> #66-th Action selection: 3/2X RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [133  55  68  77]\n",
            "         |->> Action Probabilities (Rounded): [0.0859 0.0913 0.0934 0.0911 0.0947 0.092  0.0924 0.0919 0.0935 0.0852\n",
            " 0.0886], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.08585405 0.09132106 0.09335549 0.0911341  0.09465535 0.09203421\n",
            " 0.09241538 0.09191598 0.09353499 0.08520017 0.08857924], argmax=4\n",
            "   \u001b[33m|->> #67-th Action selection: 5/2X UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [133  51  68  77]\n",
            "         |->> Action Probabilities (Rounded): [0.0927 0.0921 0.0881 0.0897 0.093  0.0922 0.0931 0.0918 0.0927 0.0858\n",
            " 0.0889], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09274856 0.09207855 0.08808434 0.0897029  0.0930419  0.09215963\n",
            " 0.09307878 0.09175687 0.09271876 0.08576386 0.08886579], argmax=6\n",
            "|->> Revisiting bbox: [133  51  68  77]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [128,  48,  71,  80] -> [133,  51,  68,  77] (Target was [106,  61,  74,  85])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [128,  48,  71,  80] -> [124,  48,  71,  80] w/ P(a|s)=0.08749805390834808 and iou=0.4565587734241908 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for 2X UP:bbox transition: [124,  48,  71,  80] -> [124,  44,  71,  80] w/ P(a|s)=0.0926009863615036 and iou=0.417910447761194 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for DOWN:bbox transition: [124,  44,  71,  80] -> [124,  46,  71,  80] w/ P(a|s)=0.09538262337446213 and iou=0.4369747899159664 and reward=-1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-1.0) for RIGHT:bbox transition: [124,  46,  71,  80] -> [126,  46,  71,  80] w/ P(a|s)=0.09202322363853455 and iou=0.4148936170212766 and reward=-1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-1.0) for DOWN:bbox transition: [126,  46,  71,  80] -> [126,  48,  71,  80] w/ P(a|s)=0.09466791898012161 and iou=0.4331896551724138 and reward=-1.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [126,  48,  71,  80] -> [127,  49,  68,  77] w/ P(a|s)=0.08684302866458893 and iou=0.4263086251701522 and reward=-1.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (-1.0) for DOWN:bbox transition: [127,  49,  68,  77] -> [127,  51,  68,  77] w/ P(a|s)=0.09394191950559616 and iou=0.4452664576802508 and reward=-1.0 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (-1.0) for RIGHT:bbox transition: [127,  51,  68,  77] -> [129,  51,  68,  77] w/ P(a|s)=0.09238790720701218 and iou=0.42138364779874216 and reward=-1.0 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (-1.0) for 2X DOWN:bbox transition: [129,  51,  68,  77] -> [129,  55,  68,  77] w/ P(a|s)=0.09387102723121643 and iou=0.45806451612903226 and reward=-1.0 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [129,  55,  68,  77] -> [133,  55,  68,  77] w/ P(a|s)=0.09113410115242004 and iou=0.4074978629869337 and reward=-1.0 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (-1.0) for 2X UP:bbox transition: [133,  55,  68,  77] -> [133,  51,  68,  77] w/ P(a|s)=0.09215962886810303 and iou=0.375910230392742 and reward=-1.0 and discount=0.9043820750088044\n",
            "   |->> Assigned losses: [-2.4361386 -2.355661  -2.3030965 -2.3148563 -2.26449   -2.3238897\n",
            " -2.2266743 -2.2199552 -2.1830604 -2.1882603 -2.1562576]\n",
            "\u001b[31m>> Total frame loss: -24.972339630126953\u001b[0m\n",
            "Final bounding box: [133  51  68  77] reached in 68 timesteps (originating from [145  65  72  81]). Target was [106  61  74  85]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 392 in t=68 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[31m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 10.778289794921875\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 3.69881534576416\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/FaceOcc2 with 802 frames\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Starting bounding box for adnet_datasets/OTB/FaceOcc2: frames 27:37 is [120  51  73 101].\n",
            "\u001b[34m>> Attempting to reach frame 28 with src: [120,  51,  73, 101] and target: [120,  53,  72, 101]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0028.jpg\n",
            "|->> Beginning tracking for bbox:[120  51  73 101]\n",
            "   \u001b[33m|->> #1-th Action selection: 9/SCALE DOWN (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [121  52  70  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0909 0.0908 0.091  0.0909 0.0909 0.0908 0.091  0.091  0.0912 0.0908\n",
            " 0.0909], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09088143 0.09078364 0.0909692  0.0909298  0.0909142  0.09079628\n",
            " 0.09095277 0.09095596 0.09115104 0.09079725 0.09086843], argmax=8\n",
            "|->> Revisiting bbox: [121  52  70  97]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [120,  51,  73, 101] -> [121,  52,  70,  97] (Target was [120,  53,  72, 101])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for SCALE DOWN:bbox transition: [120,  51,  73, 101] -> [121,  52,  70,  97] w/ P(a|s)=0.09079724550247192 and iou=0.9152819395260147 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [2.3991263]\n",
            "\u001b[92m>> Total frame loss: 2.3991262912750244\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 29 with src: [121,  52,  70,  97] and target: [116,  55,  76,  98]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0029.jpg\n",
            "|->> Beginning tracking for bbox:[121  52  70  97]\n",
            "   \u001b[33m|->> #2-th Action selection: 7/2X DOWN (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [121  56  70  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0904 0.0913 0.0912 0.0917 0.0913 0.0912 0.0915 0.0917 0.0921 0.0857\n",
            " 0.0919], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09043574 0.09125368 0.0912076  0.09171174 0.09129108 0.09124862\n",
            " 0.09150841 0.09171464 0.09205598 0.08568428 0.0918882 ], argmax=8\n",
            "   \u001b[33m|->> #3-th Action selection: 7/2X DOWN (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [121  60  70  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0909 0.0912 0.0914 0.0915 0.0915 0.091  0.0913 0.0902 0.0925 0.0878\n",
            " 0.0907], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09090281 0.09123348 0.09137493 0.0914925  0.09152108 0.09097384\n",
            " 0.0913494  0.09021743 0.09249818 0.08775429 0.09068204], argmax=8\n",
            "|->> Revisiting bbox: [121  56  70  97]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [121,  52,  70,  97] -> [121,  60,  70,  97] (Target was [116,  55,  76,  98])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for 2X DOWN:bbox transition: [121,  52,  70,  97] -> [121,  56,  70,  97] w/ P(a|s)=0.09171464294195175 and iou=0.9116541353383458 and reward=1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for 2X DOWN:bbox transition: [121,  56,  70,  97] -> [121,  60,  70,  97] w/ P(a|s)=0.09021743386983871 and iou=0.842391304347826 and reward=1.0 and discount=0.99\n",
            "   |->> Assigned losses: [2.3890731 2.3814774]\n",
            "\u001b[92m>> Total frame loss: 4.770550727844238\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 30 with src: [121,  60,  70,  97] and target: [118,  57,  76,  97]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0030.jpg\n",
            "|->> Beginning tracking for bbox:[121  60  70  97]\n",
            "   \u001b[33m|->> #4-th Action selection: 1/2X LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [117  60  70  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0906 0.0915 0.091  0.0918 0.0917 0.0906 0.0914 0.089  0.093  0.0877\n",
            " 0.0917], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09062357 0.09146009 0.09104481 0.09175166 0.09173589 0.09063539\n",
            " 0.091384   0.08901707 0.09301332 0.08766282 0.09167138], argmax=8\n",
            "   \u001b[33m|->> #5-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [118  61  67  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0901 0.0891 0.0913 0.0919 0.0921 0.0908 0.0916 0.0896 0.0937 0.0885\n",
            " 0.0914], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09008401 0.08905473 0.09131154 0.09191868 0.09214983 0.09076305\n",
            " 0.09157041 0.0895926  0.09371472 0.08845695 0.09138349], argmax=8\n",
            "   \u001b[33m|->> #6-th Action selection: 6/DOWN (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [118  63  67  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0895 0.0896 0.0915 0.0926 0.0924 0.0915 0.0922 0.0907 0.0942 0.0834\n",
            " 0.0923], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08954388 0.08964467 0.09153966 0.0926331  0.0923538  0.09149674\n",
            " 0.09221581 0.09068643 0.09417122 0.08344487 0.09226988], argmax=8\n",
            "   \u001b[33m|->> #7-th Action selection: 1/2X LEFT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [114  63  67  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0902 0.0898 0.0914 0.0929 0.0938 0.0917 0.0899 0.0909 0.0937 0.0854\n",
            " 0.0902], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.09016007 0.08982371 0.0914485  0.09293804 0.09383126 0.09169307\n",
            " 0.0899447  0.09090824 0.0937197  0.08535921 0.09017345], argmax=4\n",
            "   \u001b[33m|->> #8-th Action selection: 5/2X UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [114  59  67  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0892 0.0879 0.0919 0.0929 0.0922 0.0916 0.0925 0.0912 0.0943 0.0852\n",
            " 0.0912], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08921193 0.08787753 0.09188226 0.09288655 0.09222279 0.09160571\n",
            " 0.09251833 0.09117493 0.09426116 0.08519996 0.09115881], argmax=8\n",
            "   \u001b[33m|->> #9-th Action selection: 0/LEFT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [112  59  67  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0888 0.0881 0.0914 0.0924 0.0935 0.0903 0.0919 0.0916 0.095  0.0859\n",
            " 0.091 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08877985 0.08809862 0.09144548 0.09239369 0.09346268 0.09032785\n",
            " 0.09193552 0.09161085 0.09501527 0.08593851 0.09099163], argmax=8\n",
            "   \u001b[33m|->> #10-th Action selection: 4/UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [112  57  67  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0818 0.0886 0.098  0.0939 0.0927 0.0913 0.0934 0.0926 0.0938 0.0839\n",
            " 0.0901], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08178347 0.08859125 0.09803415 0.09386444 0.09266956 0.09127749\n",
            " 0.09337472 0.09257662 0.09383159 0.08386017 0.09013652], argmax=2\n",
            "   \u001b[33m|->> #11-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08399999886751175)\u001b[0m\n",
            "      |->> Bounding box moves to: [113  58  64  91]\n",
            "         |->> Action Probabilities (Rounded): [0.0906 0.0885 0.0891 0.0945 0.0911 0.0912 0.0938 0.0928 0.0942 0.0843\n",
            " 0.09  ], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09062824 0.08853381 0.08908563 0.09447914 0.09107337 0.09116792\n",
            " 0.09379491 0.09276887 0.09422685 0.08428983 0.08995144], argmax=3\n",
            "   \u001b[33m|->> #12-th Action selection: 0/LEFT (P(a|s) = 0.0860000029206276)\u001b[0m\n",
            "      |->> Bounding box moves to: [112  58  64  91]\n",
            "         |->> Action Probabilities (Rounded): [0.0862 0.0891 0.0939 0.0941 0.092  0.0915 0.0933 0.0934 0.0944 0.0813\n",
            " 0.0907], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08617551 0.08913539 0.09393454 0.09412534 0.09202489 0.09149919\n",
            " 0.09327259 0.09335893 0.09444883 0.08134317 0.09068161], argmax=8\n",
            "   \u001b[33m|->> #13-th Action selection: 6/DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [112  60  64  91]\n",
            "         |->> Action Probabilities (Rounded): [0.0828 0.0893 0.0969 0.0944 0.0922 0.092  0.0944 0.0949 0.0931 0.081\n",
            " 0.089 ], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08282215 0.08927655 0.09689475 0.09440749 0.09222475 0.09199183\n",
            " 0.09444715 0.09486378 0.09314727 0.08096758 0.08895671], argmax=2\n",
            "   \u001b[33m|->> #14-th Action selection: 6/DOWN (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [112  62  64  91]\n",
            "         |->> Action Probabilities (Rounded): [0.0907 0.0885 0.0898 0.0949 0.0937 0.092  0.0915 0.095  0.093  0.0815\n",
            " 0.0896], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09065536 0.08853077 0.08976504 0.09492567 0.09365336 0.09195133\n",
            " 0.09153364 0.09497085 0.09296766 0.08148248 0.08956379], argmax=7\n",
            "|->> Revisiting bbox: [112  58  64  91]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [121,  60,  70,  97] -> [112,  62,  64,  91] (Target was [118,  57,  76,  97])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [121,  60,  70,  97] -> [117,  60,  70,  97] w/ P(a|s)=0.09146009385585785 and iou=0.8449713392391871 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [117,  60,  70,  97] -> [118,  61,  67,  94] w/ P(a|s)=0.08845695108175278 and iou=0.8376125823363355 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for DOWN:bbox transition: [118,  61,  67,  94] -> [118,  63,  67,  94] w/ P(a|s)=0.09221580624580383 and iou=0.8050970553281395 and reward=-1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [118,  63,  67,  94] -> [114,  63,  67,  94] w/ P(a|s)=0.08982370793819427 and iou=0.722313216580572 and reward=-1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-1.0) for 2X UP:bbox transition: [114,  63,  67,  94] -> [114,  59,  67,  94] w/ P(a|s)=0.09160570800304413 and iou=0.7643262777490966 and reward=-1.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-1.0) for LEFT:bbox transition: [114,  59,  67,  94] -> [112,  59,  67,  94] w/ P(a|s)=0.08877985179424286 and iou=0.7225302419354839 and reward=-1.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (-1.0) for UP:bbox transition: [112,  59,  67,  94] -> [112,  57,  67,  94] w/ P(a|s)=0.09266956150531769 and iou=0.7225302419354839 and reward=-1.0 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [112,  57,  67,  94] -> [113,  58,  64,  91] w/ P(a|s)=0.08428982645273209 and iou=0.6859588603551808 and reward=-1.0 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (-1.0) for LEFT:bbox transition: [113,  58,  64,  91] -> [112,  58,  64,  91] w/ P(a|s)=0.08617550879716873 and iou=0.6665824703207881 and reward=-1.0 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (-1.0) for DOWN:bbox transition: [112,  58,  64,  91] -> [112,  60,  64,  91] w/ P(a|s)=0.09444715082645416 and iou=0.6665824703207881 and reward=-1.0 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (-1.0) for DOWN:bbox transition: [112,  60,  64,  91] -> [112,  62,  64,  91] w/ P(a|s)=0.09153363853693008 and iou=0.6665824703207881 and reward=-1.0 and discount=0.9043820750088044\n",
            "   |->> Assigned losses: [-2.3918526 -2.400987  -2.3361897 -2.3383298 -2.2960758 -2.3029132\n",
            " -2.2395132 -2.305458  -2.261988  -2.1556404 -2.1624215]\n",
            "\u001b[31m>> Total frame loss: -25.191370010375977\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 31 with src: [112,  62,  64,  91] and target: [115,  53,  77, 100]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0031.jpg\n",
            "|->> Beginning tracking for bbox:[112  62  64  91]\n",
            "   \u001b[33m|->> #15-th Action selection: 7/2X DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [112  66  64  91]\n",
            "         |->> Action Probabilities (Rounded): [0.0886 0.0901 0.0937 0.0936 0.0931 0.0925 0.0907 0.0945 0.092  0.0825\n",
            " 0.0886], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08857047 0.09005395 0.09372341 0.09356395 0.09314188 0.09253957\n",
            " 0.09071414 0.09448852 0.09204609 0.08254361 0.08861443], argmax=7\n",
            "   \u001b[33m|->> #16-th Action selection: 3/2X RIGHT (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [114  66  64  91]\n",
            "         |->> Action Probabilities (Rounded): [0.0916 0.0894 0.0914 0.0937 0.0929 0.092  0.0917 0.0921 0.092  0.0843\n",
            " 0.0889], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09162988 0.08941569 0.09143986 0.0937089  0.09285596 0.09198535\n",
            " 0.09167403 0.09210812 0.09195172 0.0843243  0.08890621], argmax=3\n",
            "|->> Revisiting bbox: [112  66  64  91]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [112,  62,  64,  91] -> [114,  66,  64,  91] (Target was [115,  53,  77, 100])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for 2X DOWN:bbox transition: [112,  62,  64,  91] -> [112,  66,  64,  91] w/ P(a|s)=0.09448852390050888 and iou=0.6458561518802483 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [112,  66,  64,  91] -> [114,  66,  64,  91] w/ P(a|s)=0.09370889514684677 and iou=0.6814621409921671 and reward=-1.0 and discount=0.99\n",
            "   |->> Assigned losses: [-2.3592768 -2.3438866]\n",
            "\u001b[31m>> Total frame loss: -4.703163146972656\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 32 with src: [114,  66,  64,  91] and target: [116,  55,  73,  98]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0032.jpg\n",
            "|->> Beginning tracking for bbox:[114  66  64  91]\n",
            "   \u001b[33m|->> #17-th Action selection: 3/2X RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [116  66  64  91]\n",
            "         |->> Action Probabilities (Rounded): [0.0911 0.09   0.0918 0.0917 0.0928 0.0919 0.0918 0.0927 0.0926 0.0846\n",
            " 0.0889], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.09111764 0.08999775 0.09178454 0.09174332 0.09278274 0.0919191\n",
            " 0.09176848 0.09271059 0.09260885 0.08462844 0.08893855], argmax=4\n",
            "   \u001b[33m|->> #18-th Action selection: 10/SCALE UP (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [115  64  66  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0935 0.091  0.0893 0.0902 0.0928 0.0924 0.0925 0.0925 0.0917 0.0853\n",
            " 0.0888], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09351378 0.09098356 0.08930682 0.09015479 0.0927677  0.092379\n",
            " 0.09251922 0.09252627 0.09172721 0.08534022 0.08878136], argmax=0\n",
            "|->> Revisiting bbox: [115  64  66  93]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [114,  66,  64,  91] -> [115,  64,  66,  93] (Target was [116,  55,  73,  98])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for 2X RIGHT:bbox transition: [114,  66,  64,  91] -> [116,  66,  64,  91] w/ P(a|s)=0.09174332022666931 and iou=0.751417004048583 and reward=1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for SCALE UP:bbox transition: [116,  66,  64,  91] -> [115,  64,  66,  93] w/ P(a|s)=0.08878135681152344 and iou=0.7706140935127215 and reward=1.0 and discount=0.99\n",
            "   |->> Assigned losses: [2.3887606 2.397363 ]\n",
            "\u001b[92m>> Total frame loss: 4.786123275756836\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 33 with src: [115,  64,  66,  93] and target: [115,  57,  77,  97]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0033.jpg\n",
            "|->> Beginning tracking for bbox:[115  64  66  93]\n",
            "   \u001b[33m|->> #19-th Action selection: 0/LEFT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [114  64  66  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0925 0.091  0.0888 0.0907 0.0938 0.0937 0.093  0.0932 0.0928 0.0871\n",
            " 0.0834], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.09254052 0.09097525 0.08877893 0.09069779 0.0938278  0.09371825\n",
            " 0.09300572 0.0931778  0.09276865 0.08706862 0.08344065], argmax=4\n",
            "   \u001b[33m|->> #20-th Action selection: 6/DOWN (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [114  66  66  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0835 0.0918 0.0957 0.0914 0.0937 0.094  0.0931 0.0936 0.0933 0.0845\n",
            " 0.0854], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08351351 0.09179507 0.09574404 0.09141076 0.09367473 0.0939846\n",
            " 0.09310235 0.09357528 0.09334671 0.0844707  0.08538224], argmax=2\n",
            "   \u001b[33m|->> #21-th Action selection: 10/SCALE UP (P(a|s) = 0.08500000089406967)\u001b[0m\n",
            "      |->> Bounding box moves to: [113  64  68  95]\n",
            "         |->> Action Probabilities (Rounded): [0.0932 0.0908 0.087  0.0921 0.095  0.0937 0.0908 0.0935 0.0923 0.0865\n",
            " 0.0851], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.09315647 0.09082694 0.08696394 0.0920755  0.09501527 0.09368066\n",
            " 0.09079796 0.09354369 0.0923401  0.08649988 0.08509967], argmax=4\n",
            "   \u001b[33m|->> #22-th Action selection: 6/DOWN (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [113  66  68  95]\n",
            "         |->> Action Probabilities (Rounded): [0.0897 0.0911 0.0913 0.0919 0.0933 0.0941 0.0926 0.0935 0.0928 0.0889\n",
            " 0.0808], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.08968704 0.09107178 0.09132948 0.09186728 0.09332494 0.09413593\n",
            " 0.09256158 0.09349785 0.09281844 0.08889844 0.08080724], argmax=5\n",
            "   \u001b[33m|->> #23-th Action selection: 3/2X RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [117  66  68  95]\n",
            "         |->> Action Probabilities (Rounded): [0.0919 0.0917 0.0884 0.0919 0.0955 0.0932 0.0893 0.093  0.0927 0.0886\n",
            " 0.0837], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.09192759 0.09165054 0.08840136 0.09194417 0.09550119 0.0932366\n",
            " 0.08930165 0.09300888 0.09268102 0.08861418 0.08373281], argmax=4\n",
            "   \u001b[33m|->> #24-th Action selection: 4/UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [117  64  68  95]\n",
            "         |->> Action Probabilities (Rounded): [0.0916 0.0917 0.0895 0.0899 0.0927 0.0933 0.0924 0.0929 0.0926 0.0898\n",
            " 0.0835], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.09164549 0.09168423 0.08947692 0.08994325 0.09274937 0.09326991\n",
            " 0.09237379 0.09293869 0.0925839  0.08984625 0.0834882 ], argmax=5\n",
            "   \u001b[33m|->> #25-th Action selection: 0/LEFT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [115  64  68  95]\n",
            "         |->> Action Probabilities (Rounded): [0.0929 0.0912 0.0884 0.09   0.0923 0.0938 0.0921 0.0935 0.0927 0.0887\n",
            " 0.0845], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.09285636 0.09123909 0.0883999  0.08997652 0.09229951 0.09376053\n",
            " 0.09209665 0.09346694 0.0926633  0.08873764 0.08450364], argmax=5\n",
            "   \u001b[33m|->> #26-th Action selection: 1/2X LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [111  64  68  95]\n",
            "         |->> Action Probabilities (Rounded): [0.085  0.0911 0.0949 0.091  0.0919 0.0944 0.0929 0.0949 0.0925 0.087\n",
            " 0.0845], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08495627 0.0910629  0.09493914 0.09096725 0.09185943 0.09437236\n",
            " 0.09292711 0.09490086 0.09252926 0.0870279  0.08445746], argmax=2\n",
            "   \u001b[33m|->> #27-th Action selection: 10/SCALE UP (P(a|s) = 0.08500000089406967)\u001b[0m\n",
            "      |->> Bounding box moves to: [109  62  70  97]\n",
            "         |->> Action Probabilities (Rounded): [0.092  0.0882 0.0876 0.0921 0.0935 0.0935 0.0933 0.0946 0.0924 0.0876\n",
            " 0.0851], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09204845 0.08824219 0.08761004 0.09208687 0.09345465 0.09346265\n",
            " 0.09334602 0.09457537 0.09242889 0.08763018 0.08511475], argmax=7\n",
            "   \u001b[33m|->> #28-th Action selection: 6/DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [109  64  70  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0893 0.0887 0.0922 0.0926 0.0934 0.0937 0.0938 0.0951 0.0922 0.089\n",
            " 0.0802], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08929068 0.08866166 0.09216791 0.09255353 0.09338661 0.09367683\n",
            " 0.09376236 0.09513406 0.09221885 0.08895317 0.08019434], argmax=7\n",
            "   \u001b[33m|->> #29-th Action selection: 2/RIGHT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [111  64  70  97]\n",
            "         |->> Action Probabilities (Rounded): [0.092  0.0883 0.0899 0.0932 0.095  0.0933 0.0914 0.0947 0.092  0.0869\n",
            " 0.0835], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.09202658 0.08827427 0.08985856 0.09315006 0.09496992 0.0932937\n",
            " 0.09138317 0.09472135 0.09195562 0.08687445 0.08349226], argmax=4\n",
            "   \u001b[33m|->> #30-th Action selection: 5/2X UP (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [111  60  70  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0969 0.0894 0.0831 0.0933 0.0929 0.0937 0.0934 0.0942 0.0921 0.0876\n",
            " 0.0833], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09691483 0.08942959 0.08311253 0.09329206 0.09285109 0.09372868\n",
            " 0.09337594 0.09424701 0.09214953 0.08758114 0.08331763], argmax=0\n",
            "   \u001b[33m|->> #31-th Action selection: 2/RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [113  60  70  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0879 0.0902 0.0925 0.0912 0.094  0.0918 0.0932 0.0941 0.0926 0.0879\n",
            " 0.0847], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08790434 0.09017318 0.09249965 0.09118726 0.09402827 0.09175838\n",
            " 0.09318432 0.09407228 0.0925615  0.08792268 0.08470807], argmax=7\n",
            "   \u001b[33m|->> #32-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [114  61  67  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0999 0.0898 0.0809 0.0921 0.0926 0.0925 0.0939 0.0941 0.0919 0.0867\n",
            " 0.0854], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09994095 0.08981128 0.08090514 0.09210918 0.09264449 0.09248236\n",
            " 0.09393127 0.09413333 0.0918955  0.08672853 0.08541801], argmax=0\n",
            "   \u001b[33m|->> #33-th Action selection: 2/RIGHT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [116  61  67  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0874 0.0914 0.0929 0.0915 0.0936 0.0925 0.0937 0.095  0.0926 0.0825\n",
            " 0.0869], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08739378 0.09143098 0.09285317 0.0914878  0.09363014 0.09250731\n",
            " 0.0937227  0.09501936 0.09256111 0.08246291 0.08693071], argmax=7\n",
            "|->> Revisiting bbox: [114  61  67  94]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [115,  64,  66,  93] -> [116,  61,  67,  94] (Target was [115,  57,  77,  97])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for LEFT:bbox transition: [115,  64,  66,  93] -> [114,  64,  66,  93] w/ P(a|s)=0.09254051744937897 and iou=0.7541575351295604 and reward=1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for DOWN:bbox transition: [114,  64,  66,  93] -> [114,  66,  66,  93] w/ P(a|s)=0.0931023508310318 and iou=0.7252440725244073 and reward=1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (1.0) for SCALE UP:bbox transition: [114,  66,  66,  93] -> [113,  64,  68,  95] w/ P(a|s)=0.08509967476129532 and iou=0.7435223432219301 and reward=1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (1.0) for DOWN:bbox transition: [113,  64,  68,  95] -> [113,  66,  68,  95] w/ P(a|s)=0.09256158024072647 and iou=0.7151828592537864 and reward=1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (1.0) for 2X RIGHT:bbox transition: [113,  66,  68,  95] -> [117,  66,  68,  95] w/ P(a|s)=0.09194417297840118 and iou=0.753178099433606 and reward=1.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (1.0) for UP:bbox transition: [117,  66,  68,  95] -> [117,  64,  68,  95] w/ P(a|s)=0.09274937212467194 and iou=0.7837111025739532 and reward=1.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (1.0) for LEFT:bbox transition: [117,  64,  68,  95] -> [115,  64,  68,  95] w/ P(a|s)=0.09285636246204376 and iou=0.7837111025739532 and reward=1.0 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (1.0) for 2X LEFT:bbox transition: [115,  64,  68,  95] -> [111,  64,  68,  95] w/ P(a|s)=0.09106290340423584 and iou=0.7051046639735585 and reward=1.0 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (1.0) for SCALE UP:bbox transition: [111,  64,  68,  95] -> [109,  62,  70,  97] w/ P(a|s)=0.0851147472858429 and iou=0.7033807191494446 and reward=1.0 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (1.0) for DOWN:bbox transition: [109,  62,  70,  97] -> [109,  64,  70,  97] w/ P(a|s)=0.0937623605132103 and iou=0.677726791387222 and reward=1.0 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (1.0) for RIGHT:bbox transition: [109,  64,  70,  97] -> [111,  64,  70,  97] w/ P(a|s)=0.08985856175422668 and iou=0.714028128380815 and reward=1.0 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (1.0) for 2X UP:bbox transition: [111,  64,  70,  97] -> [111,  60,  70,  97] w/ P(a|s)=0.0937286838889122 and iou=0.7702048417132216 and reward=1.0 and discount=0.8953382542587164\n",
            "   |->> t=13 Diff-Reward (1.0) for RIGHT:bbox transition: [111,  60,  70,  97] -> [113,  60,  70,  97] w/ P(a|s)=0.09249965101480484 and iou=0.8125079445786195 and reward=1.0 and discount=0.8863848717161292\n",
            "   |->> t=14 Diff-Reward (1.0) for SCALE DOWN:bbox transition: [113,  60,  70,  97] -> [114,  61,  67,  94] w/ P(a|s)=0.0867285281419754 and iou=0.8045615414864333 and reward=1.0 and discount=0.8775210229989678\n",
            "   |->> t=15 Diff-Reward (1.0) for RIGHT:bbox transition: [114,  61,  67,  94] -> [116,  61,  67,  94] w/ P(a|s)=0.09285317361354828 and iou=0.8268312101910829 and reward=1.0 and discount=0.8687458127689782\n",
            "   |->> Assigned losses: [2.3801088 2.3503153 2.4148998 2.3091962 2.2925334 2.2613158 2.2376173\n",
            " 2.2334194 2.2734168 2.1622877 2.1791253 2.11958   2.1100838 2.1455147\n",
            " 2.064779 ]\n",
            "\u001b[92m>> Total frame loss: 33.53419494628906\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 34 with src: [116,  61,  67,  94] and target: [116,  56,  76,  97]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0034.jpg\n",
            "|->> Beginning tracking for bbox:[116  61  67  94]\n",
            "|->> Revisiting bbox: [116  61  67  94]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #34-th Action selection: 8/STOP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [116  61  67  94]\n",
            "         |->> Action Probabilities (Rounded): [0.101  0.0907 0.0806 0.093  0.0923 0.0931 0.0941 0.095  0.0923 0.0831\n",
            " 0.0851], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.10095697 0.0906945  0.08060832 0.09296193 0.0922677  0.09311331\n",
            " 0.09407484 0.09495068 0.09225834 0.0830621  0.08505128], argmax=0\n",
            "         |->> Hit a STOP on the 34-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [116,  61,  67,  94] -> [116,  61,  67,  94] (Target was [116,  56,  76,  97])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [116,  61,  67,  94] -> [116,  61,  67,  94] w/ P(a|s)=0.09225834161043167 and iou=0.8212096989075406 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [2.3831625]\n",
            "\u001b[92m>> Total frame loss: 2.383162498474121\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 35 with src: [116,  61,  67,  94] and target: [112,  58,  76,  96]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0035.jpg\n",
            "|->> Beginning tracking for bbox:[116  61  67  94]\n",
            "   \u001b[33m|->> #34-th Action selection: 1/2X LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [112  61  67  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0865 0.0911 0.0936 0.0911 0.093  0.0926 0.0949 0.0951 0.0938 0.0819\n",
            " 0.0865], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08646866 0.09107943 0.09355964 0.0911419  0.09304692 0.09257079\n",
            " 0.09487419 0.09507931 0.09379242 0.08187857 0.08650817], argmax=7\n",
            "|->> Revisiting bbox: [112  61  67  94]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [116,  61,  67,  94] -> [112,  61,  67,  94] (Target was [112,  58,  76,  96])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for 2X LEFT:bbox transition: [116,  61,  67,  94] -> [112,  61,  67,  94] w/ P(a|s)=0.09107942879199982 and iou=0.8462583186201277 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [2.3960233]\n",
            "\u001b[92m>> Total frame loss: 2.3960232734680176\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 36 with src: [112,  61,  67,  94] and target: [111,  61,  79,  93]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0036.jpg\n",
            "|->> Beginning tracking for bbox:[112  61  67  94]\n",
            "   \u001b[33m|->> #35-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08399999886751175)\u001b[0m\n",
            "      |->> Bounding box moves to: [113  62  64  91]\n",
            "         |->> Action Probabilities (Rounded): [0.0922 0.0894 0.0874 0.0917 0.0929 0.0929 0.0938 0.0949 0.094  0.084\n",
            " 0.0868], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09215252 0.08941393 0.08741547 0.09174586 0.09286235 0.09294827\n",
            " 0.09384535 0.09487532 0.09398438 0.08395609 0.08680048], argmax=7\n",
            "|->> Revisiting bbox: [113  62  64  91]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [112,  61,  67,  94] -> [113,  62,  64,  91] (Target was [111,  61,  79,  93])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for SCALE DOWN:bbox transition: [112,  61,  67,  94] -> [113,  62,  64,  91] w/ P(a|s)=0.08395609259605408 and iou=0.7927045052402341 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [2.4774613]\n",
            "\u001b[92m>> Total frame loss: 2.477461338043213\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 37 with src: [113,  62,  64,  91] and target: [110,  58,  75,  98]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0037.jpg\n",
            "|->> Beginning tracking for bbox:[113  62  64  91]\n",
            "   \u001b[33m|->> #36-th Action selection: 5/2X UP (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [113  58  64  91]\n",
            "         |->> Action Probabilities (Rounded): [0.0884 0.0911 0.0912 0.092  0.0925 0.0936 0.0945 0.0956 0.0942 0.0792\n",
            " 0.0879], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08839494 0.09106326 0.09117423 0.09196524 0.09250861 0.09358451\n",
            " 0.09446258 0.09560602 0.09419106 0.07916615 0.08788345], argmax=7\n",
            "   \u001b[33m|->> #37-th Action selection: 6/DOWN (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [113  60  64  91]\n",
            "         |->> Action Probabilities (Rounded): [0.0913 0.0912 0.0901 0.0918 0.0923 0.0916 0.0945 0.0945 0.094  0.081\n",
            " 0.0876], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09131959 0.09116763 0.09006966 0.09181122 0.09233646 0.09163953\n",
            " 0.09453767 0.09453699 0.09401022 0.08096123 0.08760985], argmax=6\n",
            "   \u001b[33m|->> #38-th Action selection: 7/2X DOWN (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [113  64  64  91]\n",
            "         |->> Action Probabilities (Rounded): [0.0894 0.0911 0.0917 0.0919 0.0935 0.0915 0.0923 0.0948 0.0946 0.0809\n",
            " 0.0882], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08944888 0.09110214 0.09169225 0.09194619 0.09346091 0.09149521\n",
            " 0.09232408 0.09480445 0.0945998  0.08093081 0.08819534], argmax=7\n",
            "   \u001b[33m|->> #39-th Action selection: 1/2X LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [111  64  64  91]\n",
            "         |->> Action Probabilities (Rounded): [0.09   0.091  0.0921 0.0919 0.092  0.091  0.0931 0.0927 0.0945 0.0832\n",
            " 0.0886], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09004671 0.09096494 0.09210456 0.09188985 0.0919669  0.0909725\n",
            " 0.09314615 0.09266619 0.09447606 0.08317579 0.08859039], argmax=8\n",
            "   \u001b[33m|->> #40-th Action selection: 10/SCALE UP (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [110  62  66  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0897 0.0886 0.0912 0.0923 0.0934 0.0918 0.0924 0.0931 0.0943 0.0836\n",
            " 0.0895], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0897348  0.08861269 0.09122957 0.09225639 0.09343538 0.09182943\n",
            " 0.09237427 0.09306446 0.0943372  0.08362083 0.08950499], argmax=8\n",
            "   \u001b[33m|->> #41-th Action selection: 4/UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [110  60  66  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0887 0.0893 0.0915 0.0932 0.0929 0.0923 0.0939 0.0936 0.0941 0.0863\n",
            " 0.0842], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08871496 0.08926176 0.09150862 0.0932385  0.09291113 0.09231017\n",
            " 0.09394172 0.09355095 0.09406439 0.08627152 0.08422626], argmax=8\n",
            "   \u001b[33m|->> #42-th Action selection: 9/SCALE DOWN (P(a|s) = 0.0860000029206276)\u001b[0m\n",
            "      |->> Bounding box moves to: [111  61  64  90]\n",
            "         |->> Action Probabilities (Rounded): [0.0892 0.0893 0.0925 0.093  0.0917 0.092  0.0939 0.0932 0.094  0.0857\n",
            " 0.0855], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08921129 0.08928194 0.09252118 0.093024   0.09170622 0.09200051\n",
            " 0.09386196 0.09323188 0.0940197  0.08568596 0.08545538], argmax=8\n",
            "   \u001b[33m|->> #43-th Action selection: 3/2X RIGHT (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [113  61  64  90]\n",
            "         |->> Action Probabilities (Rounded): [0.0893 0.0898 0.0918 0.0938 0.093  0.092  0.0939 0.0936 0.0924 0.083\n",
            " 0.0873], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.089275   0.08983099 0.09181035 0.09377716 0.09301316 0.09202237\n",
            " 0.09391376 0.09364038 0.09240953 0.08295845 0.08734886], argmax=6\n",
            "|->> Revisiting bbox: [111  61  64  90]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [113,  62,  64,  91] -> [113,  61,  64,  90] (Target was [110,  58,  75,  98])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for 2X UP:bbox transition: [113,  62,  64,  91] -> [113,  58,  64,  91] w/ P(a|s)=0.09358450770378113 and iou=0.7923809523809524 and reward=1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for DOWN:bbox transition: [113,  58,  64,  91] -> [113,  60,  64,  91] w/ P(a|s)=0.09453766793012619 and iou=0.7923809523809524 and reward=1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (1.0) for 2X DOWN:bbox transition: [113,  60,  64,  91] -> [113,  64,  64,  91] w/ P(a|s)=0.09480445086956024 and iou=0.7923809523809524 and reward=1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (1.0) for 2X LEFT:bbox transition: [113,  64,  64,  91] -> [111,  64,  64,  91] w/ P(a|s)=0.09096493571996689 and iou=0.7923809523809524 and reward=1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (1.0) for SCALE UP:bbox transition: [111,  64,  64,  91] -> [110,  62,  66,  93] w/ P(a|s)=0.08950499445199966 and iou=0.8351020408163266 and reward=1.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (1.0) for UP:bbox transition: [110,  62,  66,  93] -> [110,  60,  66,  93] w/ P(a|s)=0.09291113168001175 and iou=0.8351020408163266 and reward=1.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (1.0) for SCALE DOWN:bbox transition: [110,  60,  66,  93] -> [111,  61,  64,  90] w/ P(a|s)=0.08568596094846725 and iou=0.7836734693877551 and reward=1.0 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (1.0) for 2X RIGHT:bbox transition: [111,  61,  64,  90] -> [113,  61,  64,  90] w/ P(a|s)=0.09377715736627579 and iou=0.7836734693877551 and reward=1.0 and discount=0.9320653479069899\n",
            "   |->> Assigned losses: [2.3688905 2.3351696 2.3090556 2.3260796 2.3183608 2.2596586 2.3132792\n",
            " 2.206044 ]\n",
            "\u001b[92m>> Total frame loss: 18.436538696289062\u001b[0m\n",
            "Final bounding box: [113  61  64  90] reached in 44 timesteps (originating from [120  51  73 101]). Target was [110  58  75  98]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 38 in t=44 timesteps ################\u001b[0m\n",
            "\n",
            "\u001b[36m####################### EPISODE # 2 ############################\u001b[0m\n",
            "Starting bounding box for adnet_datasets/OTB/FaceOcc2: frames 27:37 is [120  51  73 101].\n",
            "\u001b[34m>> Attempting to reach frame 28 with src: [120,  51,  73, 101] and target: [120,  53,  72, 101]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0028.jpg\n",
            "|->> Beginning tracking for bbox:[120  51  73 101]\n",
            "|->> Revisiting bbox: [120  51  73 101]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #1-th Action selection: 8/STOP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [120  51  73 101]\n",
            "         |->> Action Probabilities (Rounded): [0.0909 0.0908 0.091  0.0909 0.0909 0.0908 0.091  0.091  0.0912 0.0908\n",
            " 0.0909], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09088143 0.09078364 0.0909692  0.0909298  0.0909142  0.09079628\n",
            " 0.09095277 0.09095596 0.09115104 0.09079725 0.09086843], argmax=8\n",
            "         |->> Hit a STOP on the 1-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [120,  51,  73, 101] -> [120,  51,  73, 101] (Target was [120,  53,  72, 101])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [120,  51,  73, 101] -> [120,  51,  73, 101] w/ P(a|s)=0.09115104377269745 and iou=0.9482506319010243 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [2.3952374]\n",
            "\u001b[92m>> Total frame loss: 2.395237445831299\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 29 with src: [120,  51,  73, 101] and target: [116,  55,  76,  98]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0029.jpg\n",
            "|->> Beginning tracking for bbox:[120  51  73 101]\n",
            "   \u001b[33m|->> #1-th Action selection: 0/LEFT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [118  51  73 101]\n",
            "         |->> Action Probabilities (Rounded): [0.0904 0.0904 0.0916 0.0906 0.0906 0.0908 0.0913 0.0912 0.0927 0.0895\n",
            " 0.091 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09038287 0.09037996 0.09164457 0.0905632  0.09055264 0.09077444\n",
            " 0.0913003  0.09124257 0.09266217 0.08950343 0.09099385], argmax=8\n",
            "   \u001b[33m|->> #2-th Action selection: 6/DOWN (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [118  54  73 101]\n",
            "         |->> Action Probabilities (Rounded): [0.083  0.091  0.0969 0.0925 0.0904 0.0924 0.0911 0.0928 0.0932 0.0867\n",
            " 0.0898], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08298201 0.09104709 0.0969411  0.09251688 0.09044506 0.09242319\n",
            " 0.09107312 0.0928466  0.09319169 0.08669361 0.08983966], argmax=2\n",
            "   \u001b[33m|->> #3-th Action selection: 0/LEFT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [116  54  73 101]\n",
            "         |->> Action Probabilities (Rounded): [0.0922 0.0905 0.0896 0.0926 0.0916 0.0922 0.089  0.0927 0.0926 0.0873\n",
            " 0.0897], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09216948 0.09053754 0.0895713  0.09264051 0.09160667 0.09217409\n",
            " 0.08899929 0.09273403 0.09257802 0.08727892 0.08971014], argmax=7\n",
            "   \u001b[33m|->> #4-th Action selection: 4/UP (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [116  51  73 101]\n",
            "         |->> Action Probabilities (Rounded): [0.0817 0.0909 0.101  0.093  0.09   0.0933 0.091  0.0935 0.0929 0.0844\n",
            " 0.0884], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08172636 0.09085952 0.10095049 0.09300558 0.0900076  0.0932558\n",
            " 0.09103774 0.09345268 0.0929134  0.08440793 0.08838285], argmax=2\n",
            "   \u001b[33m|->> #5-th Action selection: 0/LEFT (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [114  51  73 101]\n",
            "         |->> Action Probabilities (Rounded): [0.0938 0.0899 0.0893 0.0936 0.0895 0.0929 0.0907 0.0935 0.0929 0.085\n",
            " 0.0889], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09378558 0.08990954 0.08932108 0.0935538  0.08954147 0.092894\n",
            " 0.09072369 0.09349402 0.09291339 0.08498298 0.08888044], argmax=0\n",
            "|->> Revisiting bbox: [114  51  73 101]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [120,  51,  73, 101] -> [114,  51,  73, 101] (Target was [116,  55,  76,  98])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for LEFT:bbox transition: [120,  51,  73, 101] -> [118,  51,  73, 101] w/ P(a|s)=0.09038286656141281 and iou=0.9148578811369509 and reward=1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for DOWN:bbox transition: [118,  51,  73, 101] -> [118,  54,  73, 101] w/ P(a|s)=0.09107311815023422 and iou=0.9330898656580149 and reward=1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (1.0) for LEFT:bbox transition: [118,  54,  73, 101] -> [116,  54,  73, 101] w/ P(a|s)=0.09216947853565216 and iou=0.9330898656580149 and reward=1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (1.0) for UP:bbox transition: [116,  54,  73, 101] -> [116,  51,  73, 101] w/ P(a|s)=0.09000759571790695 and iou=0.9148578811369509 and reward=1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (1.0) for LEFT:bbox transition: [116,  51,  73, 101] -> [114,  51,  73, 101] w/ P(a|s)=0.09378558397293091 and iou=0.8680362994706328 and reward=1.0 and discount=0.96059601\n",
            "   |->> Assigned losses: [2.4037006 2.3721318 2.336682  2.3363454 2.273485 ]\n",
            "\u001b[92m>> Total frame loss: 11.722345352172852\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 30 with src: [114,  51,  73, 101] and target: [118,  57,  76,  97]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0030.jpg\n",
            "|->> Beginning tracking for bbox:[114  51  73 101]\n",
            "   \u001b[33m|->> #6-th Action selection: 10/SCALE UP (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [112  49  75 104]\n",
            "         |->> Action Probabilities (Rounded): [0.0821 0.0902 0.1019 0.0937 0.09   0.0936 0.0913 0.0947 0.0921 0.0826\n",
            " 0.0878], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.0821128  0.09024768 0.10191652 0.09370595 0.09004359 0.09356687\n",
            " 0.09125832 0.09466489 0.09211652 0.08256082 0.08780605], argmax=2\n",
            "   \u001b[33m|->> #7-th Action selection: 4/UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [112  46  75 104]\n",
            "         |->> Action Probabilities (Rounded): [0.0949 0.0898 0.0883 0.0944 0.0914 0.0935 0.0922 0.0948 0.0915 0.0855\n",
            " 0.0836], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09490436 0.08978473 0.08833712 0.09439671 0.09144063 0.09354676\n",
            " 0.09220937 0.09478902 0.0915231  0.08547442 0.08359376], argmax=0\n",
            "   \u001b[33m|->> #8-th Action selection: 0/LEFT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [110  46  75 104]\n",
            "         |->> Action Probabilities (Rounded): [0.0897 0.0897 0.0956 0.0943 0.0902 0.0936 0.0929 0.0947 0.0916 0.0831\n",
            " 0.0845], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08973466 0.08971377 0.09556304 0.09427948 0.09020263 0.09363026\n",
            " 0.09294022 0.09473754 0.09159938 0.08313071 0.08446838], argmax=2\n",
            "   \u001b[33m|->> #9-th Action selection: 6/DOWN (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [110  49  75 104]\n",
            "         |->> Action Probabilities (Rounded): [0.0867 0.0898 0.098  0.0947 0.0916 0.094  0.0928 0.0959 0.0904 0.0823\n",
            " 0.0839], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08673675 0.08975709 0.09799653 0.09466627 0.09158437 0.09397222\n",
            " 0.09277272 0.09588605 0.09037826 0.08231163 0.08393811], argmax=2\n",
            "   \u001b[33m|->> #10-th Action selection: 5/2X UP (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [110  43  75 104]\n",
            "         |->> Action Probabilities (Rounded): [0.0957 0.089  0.0901 0.095  0.0937 0.0938 0.0916 0.0956 0.0882 0.0828\n",
            " 0.0844], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09569288 0.08904057 0.09012464 0.09500027 0.09369946 0.09377956\n",
            " 0.0915675  0.0956478  0.08821982 0.08283784 0.08438965], argmax=0\n",
            "   \u001b[33m|->> #11-th Action selection: 10/SCALE UP (P(a|s) = 0.08500000089406967)\u001b[0m\n",
            "      |->> Bounding box moves to: [108  41  77 107]\n",
            "         |->> Action Probabilities (Rounded): [0.0917 0.0892 0.0946 0.0939 0.0914 0.0918 0.0928 0.0947 0.091  0.0839\n",
            " 0.0849], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09170865 0.08916143 0.09463917 0.09387197 0.0914302  0.09183022\n",
            " 0.09283021 0.09465934 0.09102961 0.08391238 0.08492683], argmax=7\n",
            "   \u001b[33m|->> #12-th Action selection: 0/LEFT (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [106  41  77 107]\n",
            "         |->> Action Probabilities (Rounded): [0.0941 0.0898 0.0901 0.0943 0.0932 0.0918 0.0926 0.0945 0.0913 0.0875\n",
            " 0.081 ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09407552 0.08983593 0.09006348 0.09426543 0.09322528 0.09179525\n",
            " 0.09255824 0.09447456 0.09127341 0.08747433 0.08095851], argmax=7\n",
            "   \u001b[33m|->> #13-th Action selection: 1/2X LEFT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [102  41  77 107]\n",
            "         |->> Action Probabilities (Rounded): [0.0854 0.0897 0.0992 0.0951 0.0925 0.0925 0.0932 0.0957 0.0918 0.0828\n",
            " 0.0822], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08540665 0.08967214 0.09915711 0.0950582  0.09246378 0.09254976\n",
            " 0.09316573 0.09573105 0.09177598 0.08277743 0.08224221], argmax=2\n",
            "   \u001b[33m|->> #14-th Action selection: 5/2X UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [102  35  77 107]\n",
            "         |->> Action Probabilities (Rounded): [0.0936 0.0872 0.0896 0.0945 0.0926 0.0922 0.0937 0.0949 0.0917 0.0865\n",
            " 0.0835], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09357122 0.08719393 0.0896416  0.09449467 0.09257326 0.09223394\n",
            " 0.09371018 0.09491964 0.09167511 0.08651941 0.08346699], argmax=7\n",
            "   \u001b[33m|->> #15-th Action selection: 10/SCALE UP (P(a|s) = 0.08399999886751175)\u001b[0m\n",
            "      |->> Bounding box moves to: [100  33  79 110]\n",
            "         |->> Action Probabilities (Rounded): [0.0895 0.0873 0.0937 0.0937 0.093  0.091  0.094  0.0947 0.0926 0.0861\n",
            " 0.0844], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08948138 0.08730967 0.0936603  0.09368423 0.09297111 0.09102006\n",
            " 0.09402072 0.09472286 0.09262925 0.086144   0.08435647], argmax=7\n",
            "   \u001b[33m|->> #16-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [101  34  76 106]\n",
            "         |->> Action Probabilities (Rounded): [0.0911 0.0883 0.0908 0.0942 0.0936 0.091  0.0943 0.0946 0.0925 0.0894\n",
            " 0.0801], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09111703 0.08832829 0.09084342 0.09421402 0.09361009 0.09095604\n",
            " 0.094261   0.09460729 0.0925359  0.08939141 0.08013543], argmax=7\n",
            "   \u001b[33m|->> #17-th Action selection: 4/UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [101  31  76 106]\n",
            "         |->> Action Probabilities (Rounded): [0.0904 0.0888 0.0925 0.0947 0.0927 0.0912 0.0945 0.095  0.0933 0.0822\n",
            " 0.0847], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09044131 0.08882479 0.09245793 0.09466133 0.09268636 0.09115197\n",
            " 0.09448237 0.09500179 0.09330314 0.08224514 0.08474394], argmax=7\n",
            "|->> Revisiting bbox: [101  31  76 106]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [114,  51,  73, 101] -> [101,  31,  76, 106] (Target was [118,  57,  76,  97])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for SCALE UP:bbox transition: [114,  51,  73, 101] -> [112,  49,  75, 104] w/ P(a|s)=0.08780605345964432 and iou=0.7749181094992981 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for UP:bbox transition: [112,  49,  75, 104] -> [112,  46,  75, 104] w/ P(a|s)=0.09144063293933868 and iou=0.7329525985151342 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for LEFT:bbox transition: [112,  46,  75, 104] -> [110,  46,  75, 104] w/ P(a|s)=0.08973465859889984 and iou=0.6969019125377475 and reward=-1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-1.0) for DOWN:bbox transition: [110,  46,  75, 104] -> [110,  49,  75, 104] w/ P(a|s)=0.0927727222442627 and iou=0.7359267734553776 and reward=-1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-1.0) for 2X UP:bbox transition: [110,  49,  75, 104] -> [110,  43,  75, 104] w/ P(a|s)=0.093779556453228 and iou=0.6595930868518923 and reward=-1.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-1.0) for SCALE UP:bbox transition: [110,  43,  75, 104] -> [108,  41,  77, 107] w/ P(a|s)=0.08492682874202728 and iou=0.6408450704225352 and reward=-1.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (-1.0) for LEFT:bbox transition: [108,  41,  77, 107] -> [106,  41,  77, 107] w/ P(a|s)=0.0940755233168602 and iou=0.6100453795379538 and reward=-1.0 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [106,  41,  77, 107] -> [102,  41,  77, 107] w/ P(a|s)=0.08967214077711105 and iou=0.5517892644135188 and reward=-1.0 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (-1.0) for 2X UP:bbox transition: [102,  41,  77, 107] -> [102,  35,  77, 107] w/ P(a|s)=0.09223394095897675 and iou=0.4973144062919624 and reward=-1.0 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (-1.0) for SCALE UP:bbox transition: [102,  35,  77, 107] -> [100,  33,  79, 110] w/ P(a|s)=0.08435647189617157 and iou=0.48502218934911245 and reward=-1.0 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [100,  33,  79, 110] -> [101,  34,  76, 106] w/ P(a|s)=0.08939141035079956 and iou=0.46500807140822337 and reward=-1.0 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (-1.0) for UP:bbox transition: [101,  34,  76, 106] -> [101,  31,  76, 106] w/ P(a|s)=0.09268635511398315 and iou=0.4407919312663429 and reward=-1.0 and discount=0.8953382542587164\n",
            "   |->> Assigned losses: [-2.4326248 -2.3681448 -2.3629212 -2.3069854 -2.2735467 -2.3451083\n",
            " -2.2253366 -2.2477643 -2.1992948 -2.2588575 -2.183839  -2.1295924]\n",
            "\u001b[31m>> Total frame loss: -27.334014892578125\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 31 with src: [101,  31,  76, 106] and target: [115,  53,  77, 100]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0031.jpg\n",
            "|->> Beginning tracking for bbox:[101  31  76 106]\n",
            "   \u001b[33m|->> #18-th Action selection: 3/2X RIGHT (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [105  31  76 106]\n",
            "         |->> Action Probabilities (Rounded): [0.0916 0.0889 0.0916 0.0943 0.091  0.0916 0.0947 0.0949 0.0938 0.0846\n",
            " 0.083 ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09155042 0.08887162 0.09162036 0.09433282 0.0909974  0.09160344\n",
            " 0.09471651 0.09493884 0.09375099 0.08457478 0.08304282], argmax=7\n",
            "   \u001b[33m|->> #19-th Action selection: 6/DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [105  34  76 106]\n",
            "         |->> Action Probabilities (Rounded): [0.0907 0.0903 0.0904 0.0917 0.0923 0.0912 0.0938 0.0945 0.0933 0.086\n",
            " 0.086 ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09066379 0.0903459  0.09037329 0.09166651 0.09229456 0.09115116\n",
            " 0.09377065 0.09449438 0.09325899 0.08597484 0.08600596], argmax=7\n",
            "   \u001b[33m|->> #20-th Action selection: 6/DOWN (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [105  37  76 106]\n",
            "         |->> Action Probabilities (Rounded): [0.0902 0.09   0.0904 0.0922 0.0935 0.0913 0.0918 0.0949 0.0935 0.0868\n",
            " 0.0854], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09023526 0.09002576 0.09039708 0.09223717 0.09350639 0.09131176\n",
            " 0.09179273 0.09488869 0.09349188 0.08676107 0.08535224], argmax=7\n",
            "|->> Revisiting bbox: [105  34  76 106]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [101,  31,  76, 106] -> [105,  37,  76, 106] (Target was [115,  53,  77, 100])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [101,  31,  76, 106] -> [105,  31,  76, 106] w/ P(a|s)=0.09433282166719437 and iou=0.5428907168037603 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for DOWN:bbox transition: [105,  31,  76, 106] -> [105,  34,  76, 106] w/ P(a|s)=0.09377064555883408 and iou=0.5733972438585979 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for DOWN:bbox transition: [105,  34,  76, 106] -> [105,  37,  76, 106] w/ P(a|s)=0.09179272502660751 and iou=0.6051344743276283 and reward=-1.0 and discount=0.9801\n",
            "   |->> Assigned losses: [-2.3609262 -2.3432343 -2.3406966]\n",
            "\u001b[31m>> Total frame loss: -7.044857025146484\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 32 with src: [105,  37,  76, 106] and target: [116,  55,  73,  98]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0032.jpg\n",
            "|->> Beginning tracking for bbox:[105  37  76 106]\n",
            "   \u001b[33m|->> #21-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [106  38  73 102]\n",
            "         |->> Action Probabilities (Rounded): [0.0917 0.0903 0.0904 0.092  0.093  0.092  0.091  0.0943 0.0927 0.0871\n",
            " 0.0852], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09168023 0.09033763 0.0904395  0.09201571 0.09304129 0.0920196\n",
            " 0.09103145 0.09434382 0.0927211  0.08713179 0.08523794], argmax=7\n",
            "   \u001b[33m|->> #22-th Action selection: 6/DOWN (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [106  41  73 102]\n",
            "         |->> Action Probabilities (Rounded): [0.0907 0.0906 0.0908 0.0927 0.0929 0.0924 0.0923 0.0943 0.0935 0.0818\n",
            " 0.088 ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.0906652  0.09061705 0.09076537 0.09273764 0.09288602 0.09243217\n",
            " 0.09233882 0.0943322  0.09346347 0.08180156 0.08796047], argmax=7\n",
            "   \u001b[33m|->> #23-th Action selection: 5/2X UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [106  35  73 102]\n",
            "         |->> Action Probabilities (Rounded): [0.0901 0.0917 0.0903 0.0922 0.0947 0.092  0.0898 0.0939 0.0929 0.085\n",
            " 0.0873], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.09010264 0.09170456 0.09033669 0.09221625 0.09472229 0.0920071\n",
            " 0.08983444 0.0939001  0.09294735 0.084966   0.08726256], argmax=4\n",
            "   \u001b[33m|->> #24-th Action selection: 10/SCALE UP (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [104  33  75 105]\n",
            "         |->> Action Probabilities (Rounded): [0.09   0.0923 0.0906 0.0925 0.0922 0.0904 0.0926 0.0931 0.0931 0.0849\n",
            " 0.0884], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08996531 0.09227679 0.09058741 0.09252021 0.09217764 0.09043134\n",
            " 0.09257751 0.09309428 0.09309801 0.08486574 0.08840574], argmax=8\n",
            "   \u001b[33m|->> #25-th Action selection: 4/UP (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [104  30  75 105]\n",
            "         |->> Action Probabilities (Rounded): [0.0901 0.0926 0.0896 0.0926 0.0941 0.0914 0.0917 0.0932 0.0938 0.0876\n",
            " 0.0833], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.09006789 0.09260324 0.0895663  0.09255866 0.0941348  0.09144752\n",
            " 0.09171016 0.09318884 0.09381268 0.08761563 0.0832943 ], argmax=4\n",
            "|->> Revisiting bbox: [104  33  75 105]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [105,  37,  76, 106] -> [104,  30,  75, 105] (Target was [116,  55,  73,  98])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [105,  37,  76, 106] -> [106,  38,  73, 102] w/ P(a|s)=0.0871317908167839 and iou=0.5792320173066522 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for DOWN:bbox transition: [106,  38,  73, 102] -> [106,  41,  73, 102] w/ P(a|s)=0.09233882278203964 and iou=0.6121908127208481 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for 2X UP:bbox transition: [106,  41,  73, 102] -> [106,  35,  73, 102] w/ P(a|s)=0.0920071005821228 and iou=0.5475938096247615 and reward=-1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-1.0) for SCALE UP:bbox transition: [106,  35,  73, 102] -> [104,  33,  75, 105] w/ P(a|s)=0.08840574324131012 and iou=0.5335714285714286 and reward=-1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-1.0) for UP:bbox transition: [104,  33,  75, 105] -> [104,  30,  75, 105] w/ P(a|s)=0.09413480013608932 and iou=0.5045550105115627 and reward=-1.0 and discount=0.96059601\n",
            "   |->> Assigned losses: [-2.4403334 -2.3584678 -2.3384104 -2.3537693 -2.2699149]\n",
            "\u001b[31m>> Total frame loss: -11.760895729064941\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 33 with src: [104,  30,  75, 105] and target: [115,  57,  77,  97]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0033.jpg\n",
            "|->> Beginning tracking for bbox:[104  30  75 105]\n",
            "   \u001b[33m|->> #26-th Action selection: 6/DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [104  33  75 105]\n",
            "         |->> Action Probabilities (Rounded): [0.0901 0.0922 0.0911 0.0927 0.0908 0.0913 0.0936 0.0932 0.0934 0.085\n",
            " 0.0864], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09014765 0.09221681 0.09106466 0.09274882 0.09078287 0.09134118\n",
            " 0.09361175 0.09324303 0.0934004  0.08502298 0.08641981], argmax=6\n",
            "   \u001b[33m|->> #27-th Action selection: 6/DOWN (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [104  36  75 105]\n",
            "         |->> Action Probabilities (Rounded): [0.091  0.0922 0.0906 0.0924 0.0933 0.0912 0.0899 0.093  0.0928 0.088\n",
            " 0.0855], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.09097308 0.09224954 0.09061288 0.09241479 0.09326208 0.09123936\n",
            " 0.08989219 0.09302948 0.09276829 0.08804889 0.08550948], argmax=4\n",
            "   \u001b[33m|->> #28-th Action selection: 1/2X LEFT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [100  36  75 105]\n",
            "         |->> Action Probabilities (Rounded): [0.0904 0.0923 0.091  0.0924 0.0925 0.0912 0.0904 0.0925 0.0928 0.0879\n",
            " 0.0865], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09042793 0.09226054 0.09098698 0.0924499  0.0924734  0.09124595\n",
            " 0.09035528 0.09253915 0.09282915 0.08793786 0.08649388], argmax=8\n",
            "   \u001b[33m|->> #29-th Action selection: 7/2X DOWN (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [100  42  75 105]\n",
            "         |->> Action Probabilities (Rounded): [0.0895 0.0901 0.0918 0.0928 0.0932 0.0911 0.0912 0.0924 0.0929 0.0879\n",
            " 0.087 ], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.08948367 0.0901462  0.0918337  0.09279457 0.09320293 0.09111662\n",
            " 0.09124168 0.0923719  0.09290371 0.08788037 0.0870247 ], argmax=4\n",
            "   \u001b[33m|->> #30-th Action selection: 1/2X LEFT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [ 96  42  75 105]\n",
            "         |->> Action Probabilities (Rounded): [0.0894 0.0902 0.0915 0.0924 0.0932 0.0911 0.092  0.0914 0.0929 0.0884\n",
            " 0.0876], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.08942095 0.09020978 0.09147159 0.09241963 0.09315103 0.09107943\n",
            " 0.09203135 0.09140923 0.09286725 0.08836154 0.08757828], argmax=4\n",
            "   \u001b[33m|->> #31-th Action selection: 7/2X DOWN (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [ 96  48  75 105]\n",
            "         |->> Action Probabilities (Rounded): [0.0886 0.0879 0.0912 0.0929 0.0939 0.0913 0.0927 0.0919 0.0931 0.0887\n",
            " 0.0878], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0885958  0.08788052 0.09120148 0.09294902 0.09393541 0.09127688\n",
            " 0.0926602  0.09186453 0.09305868 0.08873396 0.08784353], argmax=4\n",
            "|->> Revisiting bbox: [ 96  48  75 105]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [104,  30,  75, 105] -> [ 96,  48,  75, 105] (Target was [115,  57,  77,  97])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for DOWN:bbox transition: [104,  30,  75, 105] -> [104,  33,  75, 105] w/ P(a|s)=0.09361175447702408 and iou=0.510236220472441 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for DOWN:bbox transition: [104,  33,  75, 105] -> [104,  36,  75, 105] w/ P(a|s)=0.0898921936750412 and iou=0.5393258426966292 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [104,  36,  75, 105] -> [100,  36,  75, 105] w/ P(a|s)=0.09226053953170776 and iou=0.4891304347826087 and reward=-1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-1.0) for 2X DOWN:bbox transition: [100,  36,  75, 105] -> [100,  42,  75, 105] w/ P(a|s)=0.09237189590930939 and iou=0.5430410297666934 and reward=-1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [100,  42,  75, 105] -> [ 96,  42,  75, 105] w/ P(a|s)=0.09020978212356567 and iou=0.4891304347826087 and reward=-1.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-1.0) for 2X DOWN:bbox transition: [ 96,  42,  75, 105] -> [ 96,  48,  75, 105] w/ P(a|s)=0.09186453372240067 and iou=0.5393258426966292 and reward=-1.0 and discount=0.9509900498999999\n",
            "   |->> Assigned losses: [-2.3685994 -2.3850527 -2.335714  -2.3111868 -2.3108265 -2.2704318]\n",
            "\u001b[31m>> Total frame loss: -13.9818115234375\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 34 with src: [ 96,  48,  75, 105] and target: [116,  56,  76,  97]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0034.jpg\n",
            "|->> Beginning tracking for bbox:[ 96  48  75 105]\n",
            "   \u001b[33m|->> #32-th Action selection: 0/LEFT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [ 94  48  75 105]\n",
            "         |->> Action Probabilities (Rounded): [0.0887 0.0881 0.0922 0.0922 0.0933 0.0907 0.0933 0.09   0.0934 0.0899\n",
            " 0.0882], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08866618 0.08813409 0.09224133 0.09218592 0.093285   0.09073122\n",
            " 0.09326332 0.09001922 0.09339377 0.08991008 0.08816992], argmax=8\n",
            "   \u001b[33m|->> #33-th Action selection: 0/LEFT (P(a|s) = 0.08100000023841858)\u001b[0m\n",
            "      |->> Bounding box moves to: [ 92  48  75 105]\n",
            "         |->> Action Probabilities (Rounded): [0.0813 0.0884 0.0976 0.0937 0.0937 0.0917 0.0933 0.0914 0.0939 0.0877\n",
            " 0.0873], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08128853 0.0883769  0.09760615 0.09372279 0.0936903  0.09165473\n",
            " 0.09329015 0.09143955 0.093914   0.08766741 0.08734947], argmax=2\n",
            "   \u001b[33m|->> #34-th Action selection: 4/UP (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [ 92  45  75 105]\n",
            "         |->> Action Probabilities (Rounded): [0.0833 0.0885 0.0955 0.0944 0.0936 0.093  0.0938 0.0921 0.0926 0.0856\n",
            " 0.0874], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08334969 0.08846681 0.09553719 0.09443802 0.09363213 0.09298616\n",
            " 0.09383153 0.09208217 0.09264474 0.08558629 0.08744522], argmax=2\n",
            "   \u001b[33m|->> #35-th Action selection: 4/UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [ 92  42  75 105]\n",
            "         |->> Action Probabilities (Rounded): [0.0884 0.0881 0.0916 0.0942 0.0913 0.0928 0.0936 0.0925 0.0932 0.0859\n",
            " 0.0885], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.08844104 0.08806658 0.09158136 0.09415045 0.09125639 0.09281233\n",
            " 0.09358451 0.09250654 0.09320195 0.08588304 0.08851584], argmax=3\n",
            "   \u001b[33m|->> #36-th Action selection: 10/SCALE UP (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [ 90  40  77 108]\n",
            "         |->> Action Probabilities (Rounded): [0.0893 0.0885 0.0933 0.0934 0.0902 0.0926 0.0929 0.0924 0.0927 0.0858\n",
            " 0.0888], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.08934614 0.08850675 0.09334552 0.09340625 0.09019662 0.09264621\n",
            " 0.09291192 0.09239297 0.09269252 0.08576194 0.08879314], argmax=3\n",
            "   \u001b[33m|->> #37-th Action selection: 5/2X UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [ 90  34  77 108]\n",
            "         |->> Action Probabilities (Rounded): [0.0909 0.0884 0.091  0.0943 0.0914 0.0923 0.0933 0.0936 0.0931 0.0879\n",
            " 0.0839], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09088382 0.08843497 0.09097286 0.09428373 0.09140156 0.09228232\n",
            " 0.09331615 0.09357458 0.09307265 0.08786789 0.08390948], argmax=3\n",
            "   \u001b[33m|->> #38-th Action selection: 10/SCALE UP (P(a|s) = 0.0860000029206276)\u001b[0m\n",
            "      |->> Bounding box moves to: [ 88  32  79 111]\n",
            "         |->> Action Probabilities (Rounded): [0.0906 0.0886 0.0922 0.0938 0.0916 0.0906 0.0935 0.093  0.0934 0.0864\n",
            " 0.0863], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09056348 0.08855134 0.09220751 0.09375778 0.09164397 0.09062978\n",
            " 0.09352454 0.09299322 0.09344144 0.0864139  0.08627308], argmax=3\n",
            "   \u001b[33m|->> #39-th Action selection: 2/RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [ 90  32  79 111]\n",
            "         |->> Action Probabilities (Rounded): [0.0915 0.0898 0.091  0.0942 0.0927 0.0912 0.0935 0.0936 0.0926 0.0894\n",
            " 0.0806], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09146971 0.08975452 0.09096149 0.09420901 0.09273216 0.09119394\n",
            " 0.09353027 0.09355956 0.09261425 0.08938957 0.08058559], argmax=3\n",
            "   \u001b[33m|->> #40-th Action selection: 5/2X UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [ 90  26  79 111]\n",
            "         |->> Action Probabilities (Rounded): [0.098  0.0894 0.0835 0.0945 0.0929 0.0921 0.0936 0.0945 0.0927 0.0861\n",
            " 0.0826], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09803232 0.08944787 0.08345542 0.09450105 0.09292476 0.09209189\n",
            " 0.09364907 0.09448332 0.09274529 0.08607864 0.0825904 ], argmax=0\n",
            "   \u001b[33m|->> #41-th Action selection: 6/DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [ 90  29  79 111]\n",
            "         |->> Action Probabilities (Rounded): [0.0901 0.0909 0.0928 0.093  0.0928 0.0901 0.0937 0.0942 0.0924 0.0877\n",
            " 0.0824], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.0900588  0.09085221 0.09282211 0.09297992 0.09277527 0.09011018\n",
            " 0.09372497 0.09423672 0.09236231 0.08766185 0.08241569], argmax=7\n",
            "|->> Revisiting bbox: [ 90  26  79 111]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [ 96,  48,  75, 105] -> [ 90,  29,  79, 111] (Target was [116,  56,  76,  97])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for LEFT:bbox transition: [ 96,  48,  75, 105] -> [ 94,  48,  75, 105] w/ P(a|s)=0.08866617828607559 and iou=0.5087076983969919 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for LEFT:bbox transition: [ 94,  48,  75, 105] -> [ 92,  48,  75, 105] w/ P(a|s)=0.08128853142261505 and iou=0.4802912621359223 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for UP:bbox transition: [ 92,  48,  75, 105] -> [ 92,  45,  75, 105] w/ P(a|s)=0.09363213181495667 and iou=0.4586243183774993 and reward=-1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-1.0) for UP:bbox transition: [ 92,  45,  75, 105] -> [ 92,  42,  75, 105] w/ P(a|s)=0.09125638753175735 and iou=0.43758250047143127 and reward=-1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-1.0) for SCALE UP:bbox transition: [ 92,  42,  75, 105] -> [ 90,  40,  77, 108] w/ P(a|s)=0.08879314363002777 and iou=0.4267006184066933 and reward=-1.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-1.0) for 2X UP:bbox transition: [ 90,  40,  77, 108] -> [ 90,  34,  77, 108] w/ P(a|s)=0.09228231757879257 and iou=0.38807290745000883 and reward=-1.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (-1.0) for SCALE UP:bbox transition: [ 90,  34,  77, 108] -> [ 88,  32,  79, 111] w/ P(a|s)=0.08627308160066605 and iou=0.3791011619958988 and reward=-1.0 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (-1.0) for RIGHT:bbox transition: [ 88,  32,  79, 111] -> [ 90,  32,  79, 111] w/ P(a|s)=0.09096148610115051 and iou=0.39991326973113617 and reward=-1.0 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (-1.0) for 2X UP:bbox transition: [ 90,  32,  79, 111] -> [ 90,  26,  79, 111] w/ P(a|s)=0.0920918881893158 and iou=0.362339635381499 and reward=-1.0 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (-1.0) for DOWN:bbox transition: [ 90,  26,  79, 111] -> [ 90,  29,  79, 111] w/ P(a|s)=0.09372497349977493 and iou=0.3808709042689708 and reward=-1.0 and discount=0.9135172474836408\n",
            "   |->> Assigned losses: [-2.4228768 -2.484653  -2.321251  -2.3229756 -2.3260312 -2.2661166\n",
            " -2.3068502 -2.234458  -2.200717  -2.1626523]\n",
            "\u001b[31m>> Total frame loss: -23.048580169677734\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 35 with src: [ 90,  29,  79, 111] and target: [112,  58,  76,  96]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0035.jpg\n",
            "|->> Beginning tracking for bbox:[ 90  29  79 111]\n",
            "   \u001b[33m|->> #42-th Action selection: 3/2X RIGHT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [ 94  29  79 111]\n",
            "         |->> Action Probabilities (Rounded): [0.0956 0.0904 0.0895 0.0931 0.0932 0.0902 0.0917 0.0944 0.0919 0.0872\n",
            " 0.0828], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.0955957  0.0903884  0.08945073 0.09312001 0.09320793 0.09024023\n",
            " 0.0917307  0.09441022 0.09186676 0.0871813  0.08280795], argmax=0\n",
            "   \u001b[33m|->> #43-th Action selection: 6/DOWN (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [ 94  32  79 111]\n",
            "         |->> Action Probabilities (Rounded): [0.0928 0.0919 0.0906 0.0907 0.0918 0.0905 0.0928 0.0938 0.092  0.0889\n",
            " 0.0842], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09280136 0.09185238 0.09061633 0.09072883 0.09176732 0.09046979\n",
            " 0.0928155  0.09382003 0.09204303 0.08887004 0.08421538], argmax=7\n",
            "   \u001b[33m|->> #44-th Action selection: 0/LEFT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [ 92  32  79 111]\n",
            "         |->> Action Probabilities (Rounded): [0.092  0.0925 0.0892 0.091  0.0941 0.0908 0.0901 0.0936 0.0922 0.09\n",
            " 0.0847], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.09195347 0.09249877 0.0891616  0.0909752  0.09409902 0.09078237\n",
            " 0.09005396 0.09359422 0.09217594 0.08998625 0.08471918], argmax=4\n",
            "   \u001b[33m|->> #45-th Action selection: 0/LEFT (P(a|s) = 0.08399999886751175)\u001b[0m\n",
            "      |->> Bounding box moves to: [ 90  32  79 111]\n",
            "         |->> Action Probabilities (Rounded): [0.0836 0.0926 0.0965 0.0916 0.0916 0.0918 0.0933 0.0942 0.0931 0.0872\n",
            " 0.0845], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08362149 0.09264065 0.09651456 0.09157881 0.09156115 0.09184682\n",
            " 0.09326345 0.09424076 0.09305871 0.08721902 0.08445461], argmax=2\n",
            "|->> Revisiting bbox: [ 90  32  79 111]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [ 90,  29,  79, 111] -> [ 90,  32,  79, 111] (Target was [112,  58,  76,  96])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [ 90,  29,  79, 111] -> [ 94,  29,  79, 111] w/ P(a|s)=0.09312000870704651 and iou=0.4521377564855826 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for DOWN:bbox transition: [ 94,  29,  79, 111] -> [ 94,  32,  79, 111] w/ P(a|s)=0.09281550347805023 and iou=0.4765625 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for LEFT:bbox transition: [ 94,  32,  79, 111] -> [ 92,  32,  79, 111] w/ P(a|s)=0.09195347130298615 and iou=0.45384615384615384 and reward=-1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-1.0) for LEFT:bbox transition: [ 92,  32,  79, 111] -> [ 90,  32,  79, 111] w/ P(a|s)=0.08362148702144623 and iou=0.4318181818181818 and reward=-1.0 and discount=0.970299\n",
            "   |->> Assigned losses: [-2.373866  -2.3533702 -2.3389819 -2.4077532]\n",
            "\u001b[31m>> Total frame loss: -9.473971366882324\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 36 with src: [ 90,  32,  79, 111] and target: [111,  61,  79,  93]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0036.jpg\n",
            "|->> Beginning tracking for bbox:[ 90  32  79 111]\n",
            "   \u001b[33m|->> #46-th Action selection: 4/UP (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [ 90  29  79 111]\n",
            "         |->> Action Probabilities (Rounded): [0.0851 0.0918 0.0941 0.0926 0.0938 0.0927 0.092  0.0945 0.093  0.0855\n",
            " 0.0848], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08512492 0.09183431 0.0941025  0.09264753 0.09380974 0.09273924\n",
            " 0.09199224 0.09450801 0.09295513 0.08546092 0.08482543], argmax=7\n",
            "   \u001b[33m|->> #47-th Action selection: 5/2X UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [ 90  23  79 111]\n",
            "         |->> Action Probabilities (Rounded): [0.0908 0.091  0.0904 0.0925 0.0904 0.0927 0.0936 0.0945 0.0925 0.0854\n",
            " 0.0862], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09080299 0.09104472 0.09037948 0.09245723 0.09042227 0.09268907\n",
            " 0.09360541 0.09447604 0.09250949 0.0854149  0.08619834], argmax=7\n",
            "   \u001b[33m|->> #48-th Action selection: 10/SCALE UP (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [ 88  21  81 114]\n",
            "         |->> Action Probabilities (Rounded): [0.0902 0.0908 0.0919 0.0923 0.092  0.0913 0.0928 0.0941 0.0921 0.0859\n",
            " 0.0867], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09016673 0.09075245 0.09185778 0.09229167 0.09200539 0.09134846\n",
            " 0.0928163  0.09410702 0.09208929 0.0859007  0.08666416], argmax=7\n",
            "|->> Revisiting bbox: [ 88  21  81 114]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [ 90,  32,  79, 111] -> [ 88,  21,  81, 114] (Target was [111,  61,  79,  93])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for UP:bbox transition: [ 90,  32,  79, 111] -> [ 90,  29,  79, 111] w/ P(a|s)=0.09380973875522614 and iou=0.3972602739726027 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for 2X UP:bbox transition: [ 90,  29,  79, 111] -> [ 90,  23,  79, 111] w/ P(a|s)=0.09268907457590103 and iou=0.3563373169500084 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for SCALE UP:bbox transition: [ 90,  23,  79, 111] -> [ 88,  21,  81, 114] w/ P(a|s)=0.08666415512561798 and iou=0.34925543168687445 and reward=-1.0 and discount=0.9801\n",
            "   |->> Assigned losses: [-2.3664865 -2.3547196 -2.3970451]\n",
            "\u001b[31m>> Total frame loss: -7.118251323699951\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 37 with src: [ 88,  21,  81, 114] and target: [110,  58,  75,  98]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0037.jpg\n",
            "|->> Beginning tracking for bbox:[ 88  21  81 114]\n",
            "   \u001b[33m|->> #49-th Action selection: 10/SCALE UP (P(a|s) = 0.08299999684095383)\u001b[0m\n",
            "      |->> Bounding box moves to: [ 86  19  83 117]\n",
            "         |->> Action Probabilities (Rounded): [0.0921 0.0905 0.0908 0.0926 0.0917 0.0911 0.0938 0.094  0.0929 0.0872\n",
            " 0.0833], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09213415 0.09051649 0.09076691 0.09258116 0.09167112 0.09113586\n",
            " 0.09381284 0.09399022 0.09287541 0.08721279 0.08330306], argmax=7\n",
            "   \u001b[33m|->> #50-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [ 87  20  80 113]\n",
            "         |->> Action Probabilities (Rounded): [0.0914 0.0908 0.0914 0.0934 0.0927 0.0914 0.0932 0.0945 0.0931 0.0876\n",
            " 0.0804], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09136826 0.09078245 0.09136599 0.09342042 0.09270541 0.09144507\n",
            " 0.09323139 0.0945121  0.09313303 0.08764336 0.08039249], argmax=7\n",
            "   \u001b[33m|->> #51-th Action selection: 6/DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [ 87  23  80 113]\n",
            "         |->> Action Probabilities (Rounded): [0.0915 0.0908 0.0905 0.0937 0.0931 0.0927 0.0942 0.0948 0.0928 0.0827\n",
            " 0.0833], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09154493 0.09084184 0.09046108 0.09366004 0.09307022 0.09266713\n",
            " 0.09416906 0.09481548 0.0928115  0.08267682 0.08328191], argmax=7\n",
            "   \u001b[33m|->> #52-th Action selection: 0/LEFT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [ 85  23  80 113]\n",
            "         |->> Action Probabilities (Rounded): [0.092  0.0906 0.0904 0.0937 0.0948 0.0925 0.091  0.0949 0.0925 0.0853\n",
            " 0.0822], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.0920302  0.09058682 0.09043925 0.09369232 0.09480041 0.09251763\n",
            " 0.09101023 0.09488088 0.09250876 0.08532956 0.08220391], argmax=7\n",
            "   \u001b[33m|->> #53-th Action selection: 9/SCALE DOWN (P(a|s) = 0.0820000022649765)\u001b[0m\n",
            "      |->> Bounding box moves to: [ 86  24  77 109]\n",
            "         |->> Action Probabilities (Rounded): [0.0849 0.0907 0.0982 0.0947 0.0922 0.0928 0.0937 0.0951 0.0921 0.0821\n",
            " 0.0835], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08488266 0.09069461 0.09824844 0.09470643 0.09216339 0.09282325\n",
            " 0.09368466 0.09511185 0.09213499 0.08208876 0.08346098], argmax=2\n",
            "   \u001b[33m|->> #54-th Action selection: 3/2X RIGHT (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [ 90  24  77 109]\n",
            "         |->> Action Probabilities (Rounded): [0.0939 0.0901 0.0883 0.0955 0.0936 0.093  0.0929 0.0955 0.0929 0.0793\n",
            " 0.0852], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09385522 0.09008175 0.08833435 0.09547457 0.09361316 0.09297301\n",
            " 0.09286936 0.09546288 0.09291544 0.07926468 0.08515564], argmax=3\n",
            "|->> Revisiting bbox: [ 86  24  77 109]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [ 88,  21,  81, 114] -> [ 90,  24,  77, 109] (Target was [110,  58,  75,  98])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for SCALE UP:bbox transition: [ 88,  21,  81, 114] -> [ 86,  19,  83, 117] w/ P(a|s)=0.0833030566573143 and iou=0.36937153864676137 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [ 86,  19,  83, 117] -> [ 87,  20,  80, 113] w/ P(a|s)=0.08764336258172989 and iou=0.35286834502682624 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for DOWN:bbox transition: [ 87,  20,  80, 113] -> [ 87,  23,  80, 113] w/ P(a|s)=0.09416905790567398 and iou=0.37223710649698594 and reward=-1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-1.0) for LEFT:bbox transition: [ 87,  23,  80, 113] -> [ 85,  23,  80, 113] w/ P(a|s)=0.09203020483255386 and iou=0.35454545454545455 and reward=-1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [ 85,  23,  80, 113] -> [ 86,  24,  77, 109] w/ P(a|s)=0.08208876103162766 and iou=0.33778042148198506 and reward=-1.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [ 86,  24,  77, 109] -> [ 90,  24,  77, 109] w/ P(a|s)=0.09547457098960876 and iou=0.3727764213463551 and reward=-1.0 and discount=0.9509900498999999\n",
            "   |->> Assigned losses: [-2.48527   -2.4101348 -2.3156466 -2.3147826 -2.401446  -2.233776 ]\n",
            "\u001b[31m>> Total frame loss: -14.161056518554688\u001b[0m\n",
            "Final bounding box: [ 90  24  77 109] reached in 55 timesteps (originating from [120  51  73 101]). Target was [110  58  75  98]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 38 in t=55 timesteps ################\u001b[0m\n",
            "\n",
            "\u001b[36m####################### EPISODE # 3 ############################\u001b[0m\n",
            "Starting bounding box for adnet_datasets/OTB/FaceOcc2: frames 27:37 is [120  51  73 101].\n",
            "\u001b[34m>> Attempting to reach frame 28 with src: [120,  51,  73, 101] and target: [120,  53,  72, 101]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0028.jpg\n",
            "|->> Beginning tracking for bbox:[120  51  73 101]\n",
            "   \u001b[33m|->> #1-th Action selection: 1/2X LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [116  51  73 101]\n",
            "         |->> Action Probabilities (Rounded): [0.0909 0.0908 0.091  0.0909 0.0909 0.0908 0.091  0.091  0.0912 0.0908\n",
            " 0.0909], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09088143 0.09078364 0.0909692  0.0909298  0.0909142  0.09079628\n",
            " 0.09095277 0.09095596 0.09115104 0.09079725 0.09086843], argmax=8\n",
            "   \u001b[33m|->> #2-th Action selection: 2/RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [118  51  73 101]\n",
            "         |->> Action Probabilities (Rounded): [0.0905 0.0884 0.0916 0.091  0.0912 0.0909 0.0914 0.0914 0.0919 0.0908\n",
            " 0.091 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09045277 0.08839959 0.09164178 0.09097733 0.09120119 0.09088293\n",
            " 0.09135842 0.09135512 0.09193464 0.09082005 0.09097616], argmax=8\n",
            "   \u001b[33m|->> #3-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [119  52  70  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0972 0.0887 0.0838 0.0916 0.0911 0.0919 0.0919 0.0923 0.0922 0.0892\n",
            " 0.0901], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09716235 0.08869191 0.08375283 0.09159014 0.09111367 0.09194937\n",
            " 0.09192927 0.09227619 0.09223522 0.08922128 0.09007782], argmax=0\n",
            "   \u001b[33m|->> #4-th Action selection: 0/LEFT (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [117  52  70  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0873 0.0901 0.0933 0.0912 0.0924 0.0919 0.0926 0.0928 0.0927 0.0847\n",
            " 0.091 ], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08725803 0.09006435 0.09328413 0.09120142 0.09239481 0.09193356\n",
            " 0.09256925 0.09284434 0.09269227 0.08471634 0.09104149], argmax=2\n",
            "   \u001b[33m|->> #5-th Action selection: 7/2X DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [117  56  70  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0853 0.0901 0.0957 0.0921 0.0918 0.0928 0.0929 0.0937 0.0928 0.0839\n",
            " 0.0889], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08526047 0.09013201 0.09565442 0.09213296 0.09181597 0.09282732\n",
            " 0.09287718 0.09374285 0.09282901 0.08385673 0.08887103], argmax=2\n",
            "|->> Revisiting bbox: [117  52  70  97]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [120,  51,  73, 101] -> [117,  56,  70,  97] (Target was [120,  53,  72, 101])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for 2X LEFT:bbox transition: [120,  51,  73, 101] -> [116,  51,  73, 101] w/ P(a|s)=0.09078364074230194 and iou=0.8742001535705145 and reward=1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for RIGHT:bbox transition: [116,  51,  73, 101] -> [118,  51,  73, 101] w/ P(a|s)=0.09164178371429443 and iou=0.9229254201680672 and reward=1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (1.0) for SCALE DOWN:bbox transition: [118,  51,  73, 101] -> [119,  52,  70,  97] w/ P(a|s)=0.0892212837934494 and iou=0.89056197902662 and reward=1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (1.0) for LEFT:bbox transition: [119,  52,  70,  97] -> [117,  52,  70,  97] w/ P(a|s)=0.08725802600383759 and iou=0.8429882044560943 and reward=1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (1.0) for 2X DOWN:bbox transition: [117,  52,  70,  97] -> [117,  56,  70,  97] w/ P(a|s)=0.09374284744262695 and iou=0.8593150866058442 and reward=1.0 and discount=0.96059601\n",
            "   |->> Assigned losses: [2.3992763 2.3659694 2.3685446 2.3664484 2.273923 ]\n",
            "\u001b[92m>> Total frame loss: 11.774161338806152\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 29 with src: [117,  56,  70,  97] and target: [116,  55,  76,  98]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0029.jpg\n",
            "|->> Beginning tracking for bbox:[117  56  70  97]\n",
            "   \u001b[33m|->> #6-th Action selection: 2/RIGHT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [119  56  70  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0911 0.0895 0.0897 0.0924 0.0922 0.0923 0.0927 0.0921 0.0926 0.0848\n",
            " 0.0904], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.0910955  0.0895435  0.08970629 0.09243769 0.09220824 0.09233986\n",
            " 0.09267228 0.09213044 0.09264304 0.08478012 0.09044307], argmax=6\n",
            "   \u001b[33m|->> #7-th Action selection: 10/SCALE UP (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [117  54  72  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0959 0.0901 0.0845 0.0926 0.0921 0.0932 0.0928 0.0928 0.0924 0.0844\n",
            " 0.0891], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09588195 0.0901254  0.08454429 0.0926264  0.09206621 0.09322338\n",
            " 0.09283596 0.09282295 0.09239589 0.08437062 0.08910701], argmax=0\n",
            "   \u001b[33m|->> #8-th Action selection: 5/2X UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [117  50  72  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0884 0.0908 0.0917 0.092  0.0931 0.0933 0.0934 0.0933 0.0934 0.0865\n",
            " 0.0841], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.0883582  0.09078806 0.09167495 0.09204775 0.09313069 0.09326001\n",
            " 0.09342062 0.09326544 0.09341349 0.0865453  0.08409544], argmax=6\n",
            "   \u001b[33m|->> #9-th Action selection: 2/RIGHT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [119  50  72  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0928 0.0904 0.0898 0.0921 0.0929 0.0918 0.0932 0.0932 0.0934 0.0847\n",
            " 0.0857], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09275779 0.09039121 0.0897607  0.09212551 0.09290046 0.09181055\n",
            " 0.09320936 0.09315442 0.09344874 0.08474281 0.08569841], argmax=8\n",
            "   \u001b[33m|->> #10-th Action selection: 3/2X RIGHT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [123  50  72  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0968 0.0907 0.0837 0.093  0.0927 0.0931 0.094  0.0938 0.0925 0.0848\n",
            " 0.0849], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09682368 0.09067163 0.08367059 0.09300989 0.09268985 0.09306853\n",
            " 0.09403489 0.09380104 0.09245258 0.08484446 0.08493292], argmax=0\n",
            "   \u001b[33m|->> #11-th Action selection: 4/UP (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [123  48  72  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0894 0.0922 0.0906 0.0894 0.0937 0.0926 0.0941 0.094  0.0927 0.0857\n",
            " 0.0856], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08941925 0.09221283 0.09059691 0.08942334 0.09365752 0.09256911\n",
            " 0.09413336 0.09404343 0.09265354 0.08572209 0.08556858], argmax=6\n",
            "   \u001b[33m|->> #12-th Action selection: 5/2X UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [123  44  72  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0938 0.0919 0.0879 0.0904 0.091  0.0927 0.0945 0.0941 0.0938 0.0849\n",
            " 0.085 ], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09384421 0.09194372 0.08791269 0.09044538 0.09099057 0.09267751\n",
            " 0.09446704 0.09407219 0.09378722 0.08485545 0.08500405], argmax=6\n",
            "   \u001b[33m|->> #13-th Action selection: 10/SCALE UP (P(a|s) = 0.0860000029206276)\u001b[0m\n",
            "      |->> Bounding box moves to: [121  42  74 101]\n",
            "         |->> Action Probabilities (Rounded): [0.093  0.092  0.0897 0.0907 0.0915 0.0905 0.0933 0.0939 0.0926 0.0864\n",
            " 0.0864], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.0930243  0.09196845 0.08973409 0.09068359 0.09149281 0.0904876\n",
            " 0.09329812 0.09391309 0.09263536 0.08636013 0.0864025 ], argmax=7\n",
            "   \u001b[33m|->> #14-th Action selection: 10/SCALE UP (P(a|s) = 0.08100000023841858)\u001b[0m\n",
            "      |->> Bounding box moves to: [119  40  76 104]\n",
            "         |->> Action Probabilities (Rounded): [0.0936 0.0918 0.089  0.0914 0.0919 0.0908 0.094  0.0938 0.0931 0.0894\n",
            " 0.0812], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09360934 0.09184153 0.08898441 0.09142713 0.09193937 0.09078033\n",
            " 0.09396135 0.09381264 0.09310858 0.08936603 0.08116926], argmax=6\n",
            "   \u001b[33m|->> #15-th Action selection: 5/2X UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [119  34  76 104]\n",
            "         |->> Action Probabilities (Rounded): [0.091  0.093  0.0895 0.0913 0.0926 0.091  0.0937 0.0941 0.0945 0.0904\n",
            " 0.0789], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09095266 0.09302468 0.08950621 0.0912821  0.09263393 0.09103856\n",
            " 0.09369249 0.09405083 0.09447539 0.09040927 0.07893386], argmax=8\n",
            "|->> Revisiting bbox: [119  40  76 104]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [117,  56,  70,  97] -> [119,  34,  76, 104] (Target was [116,  55,  76,  98])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for RIGHT:bbox transition: [117,  56,  70,  97] -> [119,  56,  70,  97] w/ P(a|s)=0.08970628678798676 and iou=0.9116541353383458 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for SCALE UP:bbox transition: [119,  56,  70,  97] -> [117,  54,  72,  99] w/ P(a|s)=0.08910700678825378 and iou=0.9382978723404255 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for 2X UP:bbox transition: [117,  54,  72,  99] -> [117,  50,  72,  99] w/ P(a|s)=0.0932600125670433 and iou=0.8668032786885246 and reward=-1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-1.0) for RIGHT:bbox transition: [117,  50,  72,  99] -> [119,  50,  72,  99] w/ P(a|s)=0.08976069837808609 and iou=0.8668032786885246 and reward=-1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [119,  50,  72,  99] -> [123,  50,  72,  99] w/ P(a|s)=0.09300988912582397 and iou=0.8017305315203955 and reward=-1.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-1.0) for UP:bbox transition: [123,  50,  72,  99] -> [123,  48,  72,  99] w/ P(a|s)=0.09365751594305038 and iou=0.7715119105493436 and reward=-1.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (-1.0) for 2X UP:bbox transition: [123,  48,  72,  99] -> [123,  44,  72,  99] w/ P(a|s)=0.0926775112748146 and iou=0.7140169332079022 and reward=-1.0 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (-1.0) for SCALE UP:bbox transition: [123,  44,  72,  99] -> [121,  42,  74, 101] w/ P(a|s)=0.08640249818563461 and iou=0.7203135808162324 and reward=-1.0 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (-1.0) for SCALE UP:bbox transition: [121,  42,  74, 101] -> [119,  40,  76, 104] w/ P(a|s)=0.0811692625284195 and iou=0.7337097684923772 and reward=-1.0 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (-1.0) for 2X UP:bbox transition: [119,  40,  76, 104] -> [119,  34,  76, 104] w/ P(a|s)=0.09103856235742569 and iou=0.6519961261164318 and reward=-1.0 and discount=0.9135172474836408\n",
            "   |->> Assigned losses: [-2.4112144 -2.393738  -2.3251538 -2.3390107 -2.2814631 -2.2520497\n",
            " -2.2394323 -2.2823844 -2.3172135 -2.1892185]\n",
            "\u001b[31m>> Total frame loss: -23.030879974365234\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 30 with src: [119,  34,  76, 104] and target: [118,  57,  76,  97]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0030.jpg\n",
            "|->> Beginning tracking for bbox:[119  34  76 104]\n",
            "   \u001b[33m|->> #16-th Action selection: 4/UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [119  31  76 104]\n",
            "         |->> Action Probabilities (Rounded): [0.0913 0.0921 0.0894 0.0915 0.093  0.0898 0.0942 0.0943 0.094  0.0896\n",
            " 0.0808], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09127451 0.09214712 0.08935051 0.09146394 0.09298367 0.08980447\n",
            " 0.09424561 0.09426431 0.0940331  0.08960622 0.08082657], argmax=7\n",
            "   \u001b[33m|->> #17-th Action selection: 0/LEFT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [117  31  76 104]\n",
            "         |->> Action Probabilities (Rounded): [0.0915 0.092  0.09   0.092  0.0908 0.0896 0.0943 0.0941 0.0936 0.0905\n",
            " 0.0816], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.0915074  0.09200159 0.08997421 0.09198716 0.09076986 0.08959955\n",
            " 0.09433429 0.09412854 0.09363751 0.09045996 0.08159984], argmax=6\n",
            "   \u001b[33m|->> #18-th Action selection: 0/LEFT (P(a|s) = 0.08399999886751175)\u001b[0m\n",
            "      |->> Bounding box moves to: [115  31  76 104]\n",
            "         |->> Action Probabilities (Rounded): [0.0841 0.0923 0.0972 0.0924 0.0907 0.0902 0.0936 0.0947 0.0937 0.0875\n",
            " 0.0835], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08410307 0.09228577 0.09722447 0.09242186 0.09072713 0.09022449\n",
            " 0.09357864 0.0947102  0.09371761 0.0875265  0.08348029], argmax=2\n",
            "   \u001b[33m|->> #19-th Action selection: 5/2X UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [115  25  76 104]\n",
            "         |->> Action Probabilities (Rounded): [0.0854 0.0915 0.0933 0.0934 0.0916 0.0916 0.0944 0.0954 0.0934 0.0862\n",
            " 0.0838], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08540004 0.09151807 0.0933321  0.09335501 0.09160552 0.091582\n",
            " 0.09437624 0.09538606 0.09344568 0.08624759 0.08375174], argmax=7\n",
            "   \u001b[33m|->> #20-th Action selection: 1/2X LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [111  25  76 104]\n",
            "         |->> Action Probabilities (Rounded): [0.0903 0.0905 0.0898 0.0936 0.0921 0.0898 0.0937 0.0948 0.0928 0.0875\n",
            " 0.085 ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09033881 0.09054333 0.08975464 0.09364797 0.0920881  0.08978017\n",
            " 0.09373657 0.09477301 0.09281095 0.08754019 0.08498622], argmax=7\n",
            "   \u001b[33m|->> #21-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [112  26  73 100]\n",
            "         |->> Action Probabilities (Rounded): [0.0889 0.0879 0.0932 0.0937 0.0923 0.0898 0.0939 0.0945 0.0925 0.0877\n",
            " 0.0857], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08885568 0.08785729 0.09319796 0.09369493 0.09228256 0.08975068\n",
            " 0.09393223 0.09454488 0.09248088 0.08770175 0.0857012 ], argmax=7\n",
            "   \u001b[33m|->> #22-th Action selection: 3/2X RIGHT (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [116  26  73 100]\n",
            "         |->> Action Probabilities (Rounded): [0.0906 0.088  0.0913 0.0946 0.0927 0.0905 0.0941 0.0953 0.0933 0.0825\n",
            " 0.087 ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09059817 0.08803426 0.09131113 0.09459169 0.09271519 0.09046266\n",
            " 0.09414376 0.09533676 0.0932669  0.0825316  0.08700794], argmax=7\n",
            "|->> Revisiting bbox: [112  26  73 100]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [119,  34,  76, 104] -> [116,  26,  73, 100] (Target was [118,  57,  76,  97])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for UP:bbox transition: [119,  34,  76, 104] -> [119,  31,  76, 104] w/ P(a|s)=0.0929836705327034 and iou=0.6206238064926798 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for LEFT:bbox transition: [119,  31,  76, 104] -> [117,  31,  76, 104] w/ P(a|s)=0.09150739759206772 and iou=0.6206238064926798 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for LEFT:bbox transition: [117,  31,  76, 104] -> [115,  31,  76, 104] w/ P(a|s)=0.0841030701994896 and iou=0.5942391984971822 and reward=-1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-1.0) for 2X UP:bbox transition: [115,  31,  76, 104] -> [115,  25,  76, 104] w/ P(a|s)=0.09158200025558472 and iou=0.5245508982035928 and reward=-1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [115,  25,  76, 104] -> [111,  25,  76, 104] w/ P(a|s)=0.09054332971572876 and iou=0.4819557625145518 and reward=-1.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [111,  25,  76, 104] -> [112,  26,  73, 100] w/ P(a|s)=0.08770175278186798 and iou=0.4600457756990745 and reward=-1.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [112,  26,  73, 100] -> [116,  26,  73, 100] w/ P(a|s)=0.09459169209003448 and iou=0.5012790340734677 and reward=-1.0 and discount=0.941480149401\n",
            "   |->> Assigned losses: [-2.3753314 -2.367422  -2.4264455 -2.3195198 -2.3072813 -2.3145323\n",
            " -2.2201848]\n",
            "\u001b[31m>> Total frame loss: -16.330717086791992\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 31 with src: [116,  26,  73, 100] and target: [115,  53,  77, 100]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0031.jpg\n",
            "|->> Beginning tracking for bbox:[116  26  73 100]\n",
            "   \u001b[33m|->> #23-th Action selection: 0/LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [114  26  73 100]\n",
            "         |->> Action Probabilities (Rounded): [0.0909 0.0886 0.0909 0.0924 0.0927 0.0915 0.0946 0.0951 0.0927 0.0845\n",
            " 0.0859], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09094267 0.0886329  0.09091445 0.09235588 0.0927217  0.09150084\n",
            " 0.09464169 0.09514355 0.09273275 0.0845364  0.08587716], argmax=7\n",
            "|->> Revisiting bbox: [114  26  73 100]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [116,  26,  73, 100] -> [114,  26,  73, 100] (Target was [115,  53,  77, 100])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for LEFT:bbox transition: [116,  26,  73, 100] -> [114,  26,  73, 100] w/ P(a|s)=0.09094267338514328 and iou=0.5394088669950738 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.397526]\n",
            "\u001b[31m>> Total frame loss: -2.3975260257720947\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 32 with src: [114,  26,  73, 100] and target: [116,  55,  73,  98]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0032.jpg\n",
            "|->> Beginning tracking for bbox:[114  26  73 100]\n",
            "   \u001b[33m|->> #24-th Action selection: 4/UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [114  23  73 100]\n",
            "         |->> Action Probabilities (Rounded): [0.0842 0.0888 0.0963 0.0932 0.0927 0.0922 0.0949 0.0958 0.0928 0.0816\n",
            " 0.0875], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08423108 0.08882639 0.09630566 0.09322648 0.09265282 0.09218485\n",
            " 0.09488415 0.09583569 0.09276171 0.08156991 0.08752123], argmax=2\n",
            "   \u001b[33m|->> #25-th Action selection: 9/SCALE DOWN (P(a|s) = 0.0820000022649765)\u001b[0m\n",
            "      |->> Bounding box moves to: [115  24  70  97]\n",
            "         |->> Action Probabilities (Rounded): [0.093  0.0882 0.0892 0.093  0.0906 0.0919 0.0946 0.0954 0.0933 0.0825\n",
            " 0.0882], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09300046 0.08822078 0.0892358  0.09304693 0.09058029 0.09194029\n",
            " 0.0946298  0.09541242 0.09325578 0.08249113 0.08818631], argmax=7\n",
            "   \u001b[33m|->> #26-th Action selection: 4/UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [115  22  70  97]\n",
            "         |->> Action Probabilities (Rounded): [0.09   0.0887 0.0933 0.0931 0.0917 0.0929 0.0936 0.096  0.0926 0.0785\n",
            " 0.0895], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08999072 0.08873925 0.09332461 0.09313729 0.09171305 0.09285256\n",
            " 0.09362815 0.09601611 0.09255891 0.0785231  0.08951619], argmax=7\n",
            "   \u001b[33m|->> #27-th Action selection: 3/2X RIGHT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [119  22  70  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0946 0.0885 0.0899 0.0934 0.0895 0.0925 0.095  0.0958 0.0927 0.0802\n",
            " 0.088 ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09458128 0.08845364 0.08992929 0.09337605 0.08945288 0.09251749\n",
            " 0.09504361 0.09583244 0.09265842 0.08018085 0.08797402], argmax=7\n",
            "   \u001b[33m|->> #28-th Action selection: 10/SCALE UP (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [117  20  72  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0918 0.0899 0.0901 0.0915 0.0914 0.0921 0.0933 0.0955 0.0933 0.0817\n",
            " 0.0895], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09175124 0.08987825 0.09014697 0.09149703 0.09138854 0.09206824\n",
            " 0.09328528 0.09550118 0.09326252 0.08171482 0.08950592], argmax=7\n",
            "   \u001b[33m|->> #29-th Action selection: 4/UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [117  18  72  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0909 0.0908 0.0886 0.0912 0.0922 0.0924 0.0947 0.0956 0.0933 0.0857\n",
            " 0.0845], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09086498 0.09079228 0.08863562 0.09116796 0.09221452 0.09242751\n",
            " 0.09470326 0.09562221 0.09331798 0.08572165 0.08453204], argmax=7\n",
            "   \u001b[33m|->> #30-th Action selection: 4/UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [117  16  72  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0916 0.0906 0.089  0.0916 0.091  0.0929 0.0944 0.0953 0.0933 0.0841\n",
            " 0.086 ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09161163 0.09058315 0.08904646 0.09164322 0.09103477 0.09291804\n",
            " 0.09439938 0.0953324  0.09330695 0.08412873 0.08599526], argmax=7\n",
            "   \u001b[33m|->> #31-th Action selection: 2/RIGHT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [119  16  72  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0925 0.0914 0.0895 0.0917 0.0896 0.0926 0.0936 0.0952 0.0931 0.0854\n",
            " 0.0854], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09247811 0.09136733 0.0895219  0.09167849 0.08959723 0.09259529\n",
            " 0.09362852 0.09522122 0.09312166 0.08538962 0.08540063], argmax=7\n",
            "   \u001b[33m|->> #32-th Action selection: 4/UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [119  14  72  99]\n",
            "         |->> Action Probabilities (Rounded): [0.1004 0.0912 0.081  0.0921 0.0907 0.0927 0.0934 0.0952 0.0919 0.0856\n",
            " 0.0858], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.10037819 0.09119348 0.08101258 0.09208772 0.09073672 0.09272771\n",
            " 0.0934088  0.09520926 0.09189224 0.08559044 0.08576288], argmax=0\n",
            "   \u001b[33m|->> #33-th Action selection: 3/2X RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [123  14  72  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0898 0.0922 0.0916 0.0917 0.0897 0.0919 0.0947 0.0951 0.092  0.0855\n",
            " 0.0857], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08983646 0.09222885 0.09163152 0.09171215 0.08972024 0.09188442\n",
            " 0.09467483 0.09512333 0.09198021 0.08553489 0.08567316], argmax=7\n",
            "   \u001b[33m|->> #34-th Action selection: 4/UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [123  12  72  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0947 0.0932 0.0862 0.0893 0.0912 0.0916 0.0927 0.0945 0.0921 0.0879\n",
            " 0.0866], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09467402 0.09317639 0.08622464 0.08931303 0.09121789 0.0915998\n",
            " 0.09267487 0.09452845 0.09207299 0.08793519 0.08658273], argmax=0\n",
            "|->> Revisiting bbox: [123  14  72  99]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [114,  26,  73, 100] -> [123,  12,  72,  99] (Target was [116,  55,  73,  98])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for UP:bbox transition: [114,  26,  73, 100] -> [114,  23,  73, 100] w/ P(a|s)=0.0926528200507164 and iou=0.5015582796592561 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [114,  23,  73, 100] -> [115,  24,  70,  97] w/ P(a|s)=0.08249112963676453 and iou=0.4849840255591054 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for UP:bbox transition: [115,  24,  70,  97] -> [115,  22,  70,  97] w/ P(a|s)=0.09171304851770401 and iou=0.4634760705289673 and reward=-1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [115,  22,  70,  97] -> [119,  22,  70,  97] w/ P(a|s)=0.0933760479092598 and iou=0.47337278106508873 and reward=-1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-1.0) for SCALE UP:bbox transition: [119,  22,  70,  97] -> [117,  20,  72,  99] w/ P(a|s)=0.08950591832399368 and iou=0.4763283026669423 and reward=-1.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-1.0) for UP:bbox transition: [117,  20,  72,  99] -> [117,  18,  72,  99] w/ P(a|s)=0.09221451729536057 and iou=0.45467508657567735 and reward=-1.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (-1.0) for UP:bbox transition: [117,  18,  72,  99] -> [117,  16,  72,  99] w/ P(a|s)=0.09103477001190186 and iou=0.4336478618751255 and reward=-1.0 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (-1.0) for RIGHT:bbox transition: [117,  16,  72,  99] -> [119,  16,  72,  99] w/ P(a|s)=0.08952189981937408 and iou=0.41658401110890697 and reward=-1.0 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (-1.0) for UP:bbox transition: [119,  16,  72,  99] -> [119,  14,  72,  99] w/ P(a|s)=0.09073672443628311 and iou=0.39718254744668363 and reward=-1.0 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [119,  14,  72,  99] -> [123,  14,  72,  99] w/ P(a|s)=0.09171215444803238 and iou=0.3661756265544289 and reward=-1.0 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (-1.0) for UP:bbox transition: [123,  14,  72,  99] -> [123,  12,  72,  99] w/ P(a|s)=0.09121789038181305 and iou=0.34914037407897225 and reward=-1.0 and discount=0.9043820750088044\n",
            "   |->> Assigned losses: [-2.378896  -2.470114  -2.3415475 -2.300696  -2.318351  -2.2668157\n",
            " -2.2562702 -2.2493272 -2.2143965 -2.1824844 -2.1655467]\n",
            "\u001b[31m>> Total frame loss: -25.14444351196289\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 33 with src: [123,  12,  72,  99] and target: [115,  57,  77,  97]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0033.jpg\n",
            "|->> Beginning tracking for bbox:[123  12  72  99]\n",
            "   \u001b[33m|->> #35-th Action selection: 1/2X LEFT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [119  12  72  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0919 0.0926 0.0887 0.0902 0.0899 0.0921 0.0944 0.0949 0.0915 0.0873\n",
            " 0.0865], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09188809 0.09259094 0.08871026 0.09016213 0.08992898 0.09214206\n",
            " 0.09437651 0.09492016 0.09148356 0.08725452 0.08654289], argmax=7\n",
            "   \u001b[33m|->> #36-th Action selection: 5/2X UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [119   8  72  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0934 0.0899 0.0886 0.0897 0.0911 0.0916 0.0931 0.0945 0.0918 0.0894\n",
            " 0.0869], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09335969 0.08994878 0.08856831 0.08971777 0.09106832 0.09158432\n",
            " 0.09312156 0.09454606 0.09179878 0.08940215 0.08688419], argmax=7\n",
            "   \u001b[33m|->> #37-th Action selection: 0/LEFT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [117   8  72  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0916 0.0898 0.0891 0.0898 0.0914 0.0901 0.0946 0.0943 0.0928 0.0892\n",
            " 0.0873], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09162727 0.08981687 0.08906601 0.08980974 0.09138778 0.09012715\n",
            " 0.0945644  0.09431629 0.0927993  0.08921657 0.08726862], argmax=6\n",
            "   \u001b[33m|->> #38-th Action selection: 5/2X UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [117   4  72  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0848 0.0905 0.0959 0.0917 0.0929 0.0909 0.094  0.0948 0.0916 0.0866\n",
            " 0.0864], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08476423 0.09046636 0.09590032 0.09166373 0.09291756 0.09087517\n",
            " 0.09395929 0.09479434 0.09158871 0.08663496 0.08643538], argmax=2\n",
            "   \u001b[33m|->> #39-th Action selection: 3/2X RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [121   4  72  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0931 0.0895 0.088  0.0918 0.0915 0.0892 0.0945 0.0945 0.092  0.0871\n",
            " 0.0888], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09310875 0.08954324 0.08800406 0.09182602 0.09147911 0.08919623\n",
            " 0.09450724 0.09445343 0.09197792 0.08713318 0.08877078], argmax=6\n",
            "   \u001b[33m|->> #40-th Action selection: 10/SCALE UP (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [119   2  74 101]\n",
            "         |->> Action Probabilities (Rounded): [0.0894 0.0902 0.0915 0.0897 0.0923 0.09   0.0938 0.0942 0.0924 0.0879\n",
            " 0.0885], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08941913 0.09020273 0.09153076 0.0897227  0.092296   0.08997303\n",
            " 0.0938014  0.09423277 0.09241252 0.08793816 0.08847079], argmax=7\n",
            "   \u001b[33m|->> #41-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [120   3  71  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0928 0.0897 0.0888 0.0906 0.0922 0.0905 0.0945 0.0948 0.093  0.0893\n",
            " 0.0837], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09278585 0.08970995 0.0887972  0.09059686 0.09219121 0.09047528\n",
            " 0.09454732 0.09484228 0.0930463  0.08932848 0.08367928], argmax=7\n",
            "   \u001b[33m|->> #42-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08399999886751175)\u001b[0m\n",
            "      |->> Bounding box moves to: [121   4  68  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0904 0.0901 0.0901 0.0918 0.0925 0.091  0.0941 0.0949 0.0944 0.0836\n",
            " 0.0872], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09039531 0.0900737  0.09011609 0.0918007  0.09247269 0.09100968\n",
            " 0.09410433 0.09490165 0.09438297 0.08356347 0.0871794 ], argmax=7\n",
            "   \u001b[33m|->> #43-th Action selection: 6/DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [121   6  68  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0907 0.0905 0.0894 0.0924 0.0929 0.0917 0.0944 0.0952 0.094  0.0818\n",
            " 0.087 ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09065598 0.09049461 0.08935769 0.09238657 0.0929421  0.09173426\n",
            " 0.09443702 0.0952125  0.09402511 0.08176475 0.08698938], argmax=7\n",
            "   \u001b[33m|->> #44-th Action selection: 7/2X DOWN (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [121  10  68  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0901 0.0908 0.0905 0.0928 0.0944 0.0916 0.092  0.0948 0.0934 0.0828\n",
            " 0.0869], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09013306 0.09075272 0.09054904 0.0927688  0.09438064 0.09155384\n",
            " 0.09204571 0.09478595 0.09336598 0.08280272 0.08686151], argmax=7\n",
            "   \u001b[33m|->> #45-th Action selection: 3/2X RIGHT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [125  10  68  94]\n",
            "         |->> Action Probabilities (Rounded): [0.09   0.0904 0.0907 0.0929 0.0927 0.0913 0.0933 0.0929 0.0943 0.0836\n",
            " 0.088 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08998325 0.09038343 0.09070173 0.09293988 0.09265146 0.09126535\n",
            " 0.09333444 0.09293985 0.09425658 0.0835524  0.08799168], argmax=8\n",
            "   \u001b[33m|->> #46-th Action selection: 6/DOWN (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [125  12  68  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0917 0.0919 0.0889 0.0909 0.0934 0.0915 0.0922 0.0928 0.094  0.0848\n",
            " 0.0879], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09171132 0.09187806 0.0889041  0.09086684 0.09335284 0.09154601\n",
            " 0.09220742 0.09284361 0.09397364 0.08482245 0.08789377], argmax=8\n",
            "   \u001b[33m|->> #47-th Action selection: 6/DOWN (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [125  14  68  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0917 0.0912 0.0895 0.0916 0.0942 0.0924 0.091  0.093  0.0933 0.0846\n",
            " 0.0875], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.09174689 0.09118775 0.08945438 0.09159963 0.09417439 0.09244481\n",
            " 0.09099939 0.09301351 0.0932812  0.08462415 0.08747396], argmax=4\n",
            "|->> Revisiting bbox: [125  10  68  94]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [123,  12,  72,  99] -> [125,  14,  68,  94] (Target was [115,  57,  77,  97])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [123,  12,  72,  99] -> [119,  12,  72,  99] w/ P(a|s)=0.09259093552827835 and iou=0.3630591091605192 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for 2X UP:bbox transition: [119,  12,  72,  99] -> [119,   8,  72,  99] w/ P(a|s)=0.09158432483673096 and iou=0.3273620078203146 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for LEFT:bbox transition: [119,   8,  72,  99] -> [117,   8,  72,  99] w/ P(a|s)=0.09162726998329163 and iou=0.3273620078203146 and reward=-1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-1.0) for 2X UP:bbox transition: [117,   8,  72,  99] -> [117,   4,  72,  99] w/ P(a|s)=0.09087517112493515 and iou=0.29348692955250333 and reward=-1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [117,   4,  72,  99] -> [121,   4,  72,  99] w/ P(a|s)=0.09182602167129517 and iou=0.28823581325567027 and reward=-1.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-1.0) for SCALE UP:bbox transition: [121,   4,  72,  99] -> [119,   2,  74, 101] w/ P(a|s)=0.08847078680992126 and iou=0.2898575744497195 and reward=-1.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [119,   2,  74, 101] -> [120,   3,  71,  97] w/ P(a|s)=0.08932848274707794 and iou=0.2701052817835973 and reward=-1.0 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [120,   3,  71,  97] -> [121,   4,  68,  94] w/ P(a|s)=0.08356346935033798 and iou=0.25178361780908515 and reward=-1.0 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (-1.0) for DOWN:bbox transition: [121,   4,  68,  94] -> [121,   6,  68,  94] w/ P(a|s)=0.09443701803684235 and iou=0.26734936454237906 and reward=-1.0 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (-1.0) for 2X DOWN:bbox transition: [121,   6,  68,  94] -> [121,  10,  68,  94] w/ P(a|s)=0.09478595107793808 and iou=0.29967182372245665 and reward=-1.0 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [121,  10,  68,  94] -> [125,  10,  68,  94] w/ P(a|s)=0.09293987601995468 and iou=0.2939693801344287 and reward=-1.0 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (-1.0) for DOWN:bbox transition: [125,  10,  68,  94] -> [125,  12,  68,  94] w/ P(a|s)=0.0922074168920517 and iou=0.3103611268670826 and reward=-1.0 and discount=0.8953382542587164\n",
            "   |->> t=13 Diff-Reward (-1.0) for DOWN:bbox transition: [125,  12,  68,  94] -> [125,  14,  68,  94] w/ P(a|s)=0.09099938720464706 and iou=0.3271734967445423 and reward=-1.0 and discount=0.8863848717161292\n",
            "   |->> Assigned losses: [-2.379564  -2.36659   -2.3424647 -2.3270376 -2.2937684 -2.3062296\n",
            " -2.274084  -2.313525  -2.1775134 -2.1523693 -2.1486332 -2.1342309\n",
            " -2.124578 ]\n",
            "\u001b[31m>> Total frame loss: -29.34058952331543\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 34 with src: [125,  14,  68,  94] and target: [116,  56,  76,  97]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0034.jpg\n",
            "|->> Beginning tracking for bbox:[125  14  68  94]\n",
            "   \u001b[33m|->> #48-th Action selection: 0/LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [123  14  68  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0907 0.0924 0.0895 0.091  0.0938 0.0924 0.0899 0.0922 0.0938 0.0867\n",
            " 0.0876], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09069856 0.09244761 0.08954685 0.09097335 0.09375381 0.09236778\n",
            " 0.08994208 0.09223776 0.09375679 0.0867221  0.08755326], argmax=8\n",
            "|->> Revisiting bbox: [125  14  68  94]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [125,  14,  68,  94] -> [123,  14,  68,  94] (Target was [116,  56,  76,  97])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for LEFT:bbox transition: [125,  14,  68,  94] -> [123,  14,  68,  94] w/ P(a|s)=0.09069856256246567 and iou=0.3457176378568635 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.4002137]\n",
            "\u001b[31m>> Total frame loss: -2.4002137184143066\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 35 with src: [123,  14,  68,  94] and target: [112,  58,  76,  96]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0035.jpg\n",
            "|->> Beginning tracking for bbox:[123  14  68  94]\n",
            "   \u001b[33m|->> #49-th Action selection: 0/LEFT (P(a|s) = 0.08299999684095383)\u001b[0m\n",
            "      |->> Bounding box moves to: [121  14  68  94]\n",
            "         |->> Action Probabilities (Rounded): [0.083  0.0924 0.0957 0.0922 0.0933 0.0939 0.0912 0.0928 0.0937 0.0843\n",
            " 0.0876], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.0830351  0.09237365 0.09566712 0.0921541  0.09332356 0.09389909\n",
            " 0.09123853 0.09276197 0.09367692 0.08428414 0.0875859 ], argmax=2\n",
            "   \u001b[33m|->> #50-th Action selection: 5/2X UP (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [121  10  68  94]\n",
            "         |->> Action Probabilities (Rounded): [0.084  0.0921 0.0937 0.0936 0.0939 0.094  0.0919 0.0939 0.0928 0.0827\n",
            " 0.0873], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.08399495 0.09213809 0.09365988 0.09357032 0.09393539 0.09403858\n",
            " 0.0919179  0.09385328 0.09283919 0.08274652 0.08730592], argmax=5\n",
            "   \u001b[33m|->> #51-th Action selection: 3/2X RIGHT (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [125  10  68  94]\n",
            "         |->> Action Probabilities (Rounded): [0.089  0.091  0.0899 0.0936 0.0931 0.0922 0.0925 0.093  0.0926 0.0836\n",
            " 0.0894], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.08898351 0.09095448 0.08992009 0.09356523 0.09312047 0.09224202\n",
            " 0.09251049 0.09304545 0.09264035 0.08361977 0.08939818], argmax=3\n",
            "   \u001b[33m|->> #52-th Action selection: 2/RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [127  10  68  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0897 0.0912 0.0908 0.0908 0.0934 0.092  0.0922 0.0927 0.0922 0.0856\n",
            " 0.0893], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0897139  0.09119529 0.09083415 0.09080929 0.0934362  0.09201889\n",
            " 0.09222549 0.09266175 0.09219982 0.0855795  0.08932567], argmax=4\n",
            "   \u001b[33m|->> #53-th Action selection: 1/2X LEFT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [123  10  68  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0987 0.0899 0.0818 0.0921 0.0928 0.0925 0.0933 0.0931 0.0923 0.0851\n",
            " 0.0884], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09869502 0.08994143 0.0818077  0.09209154 0.09280369 0.09250078\n",
            " 0.09329087 0.09312508 0.09226207 0.08512715 0.08835471], argmax=0\n",
            "|->> Revisiting bbox: [121  10  68  94]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [123,  14,  68,  94] -> [123,  10,  68,  94] (Target was [112,  58,  76,  96])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for LEFT:bbox transition: [123,  14,  68,  94] -> [121,  14,  68,  94] w/ P(a|s)=0.08303510397672653 and iou=0.3240472044882956 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for 2X UP:bbox transition: [121,  14,  68,  94] -> [121,  10,  68,  94] w/ P(a|s)=0.09403857588768005 and iou=0.29059023194418254 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [121,  10,  68,  94] -> [125,  10,  68,  94] w/ P(a|s)=0.09356522560119629 and iou=0.26858202038924933 and reward=-1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-1.0) for RIGHT:bbox transition: [125,  10,  68,  94] -> [127,  10,  68,  94] w/ P(a|s)=0.09083414822816849 and iou=0.2578570115787539 and reward=-1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [127,  10,  68,  94] -> [123,  10,  68,  94] w/ P(a|s)=0.08994142711162567 and iou=0.27949149373714716 and reward=-1.0 and discount=0.96059601\n",
            "   |->> Assigned losses: [-2.4884918 -2.3404098 -2.3219514 -2.3274755 -2.3136883]\n",
            "\u001b[31m>> Total frame loss: -11.792016983032227\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 36 with src: [123,  10,  68,  94] and target: [111,  61,  79,  93]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0036.jpg\n",
            "|->> Beginning tracking for bbox:[123  10  68  94]\n",
            "   \u001b[33m|->> #54-th Action selection: 3/2X RIGHT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [127  10  68  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0888 0.0886 0.0922 0.0902 0.0933 0.0925 0.0937 0.0937 0.0926 0.0859\n",
            " 0.0885], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08877651 0.08862039 0.09221648 0.09015793 0.09327896 0.09248459\n",
            " 0.09373672 0.09365857 0.09261126 0.08592049 0.08853809], argmax=6\n",
            "   \u001b[33m|->> #55-th Action selection: 9/SCALE DOWN (P(a|s) = 0.0860000029206276)\u001b[0m\n",
            "      |->> Bounding box moves to: [128  11  65  91]\n",
            "         |->> Action Probabilities (Rounded): [0.0945 0.0887 0.0871 0.0887 0.093  0.093  0.0937 0.0944 0.0922 0.0864\n",
            " 0.0883], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09454398 0.08867961 0.08710675 0.08870989 0.09297789 0.09302016\n",
            " 0.09370776 0.09444574 0.09216277 0.08635372 0.0882917 ], argmax=0\n",
            "   \u001b[33m|->> #56-th Action selection: 10/SCALE UP (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [127   9  67  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0906 0.0893 0.0904 0.0906 0.0939 0.0933 0.0941 0.0952 0.0923 0.0814\n",
            " 0.089 ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09059075 0.08928314 0.09035361 0.09057358 0.09385674 0.0932899\n",
            " 0.09413359 0.09515127 0.09228287 0.08143748 0.08904705], argmax=7\n",
            "   \u001b[33m|->> #57-th Action selection: 6/DOWN (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [127  11  67  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0935 0.0895 0.0883 0.0911 0.0931 0.0933 0.0948 0.0957 0.0928 0.0851\n",
            " 0.0827], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09353568 0.08947042 0.08831818 0.09112393 0.09311876 0.09332823\n",
            " 0.09477723 0.09566136 0.09281807 0.08512682 0.0827213 ], argmax=7\n",
            "   \u001b[33m|->> #58-th Action selection: 10/SCALE UP (P(a|s) = 0.08500000089406967)\u001b[0m\n",
            "      |->> Bounding box moves to: [125   9  69  95]\n",
            "         |->> Action Probabilities (Rounded): [0.0927 0.0891 0.09   0.0913 0.0942 0.0931 0.0923 0.0955 0.0936 0.0831\n",
            " 0.0851], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09270061 0.08907255 0.09003553 0.09131683 0.09420945 0.09308245\n",
            " 0.092274   0.09552329 0.09360871 0.0830962  0.0850804 ], argmax=7\n",
            "   \u001b[33m|->> #59-th Action selection: 4/UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [125   7  69  95]\n",
            "         |->> Action Probabilities (Rounded): [0.0928 0.0903 0.0895 0.091  0.093  0.0931 0.0937 0.0951 0.0936 0.0877\n",
            " 0.0801], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09280233 0.09032169 0.08951708 0.09096193 0.09301201 0.09314648\n",
            " 0.09370234 0.09510968 0.09363336 0.08770201 0.08009116], argmax=7\n",
            "   \u001b[33m|->> #60-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [126   8  66  92]\n",
            "         |->> Action Probabilities (Rounded): [0.0906 0.0908 0.0894 0.0914 0.0919 0.0933 0.0932 0.0948 0.0944 0.0867\n",
            " 0.0836], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09055959 0.09076849 0.0894156  0.0914316  0.09192933 0.09326676\n",
            " 0.0931742  0.09475077 0.09438304 0.08671486 0.08360571], argmax=7\n",
            "   \u001b[33m|->> #61-th Action selection: 4/UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [126   6  66  92]\n",
            "         |->> Action Probabilities (Rounded): [0.0903 0.0916 0.0894 0.0919 0.0923 0.0937 0.0935 0.095  0.0938 0.0837\n",
            " 0.0847], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09032054 0.09162273 0.08941738 0.09185841 0.09232867 0.09372276\n",
            " 0.09350315 0.09504978 0.0937748  0.0836764  0.08472537], argmax=7\n",
            "   \u001b[33m|->> #62-th Action selection: 3/2X RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [128   6  66  92]\n",
            "         |->> Action Probabilities (Rounded): [0.0898 0.0918 0.0902 0.0922 0.0912 0.093  0.0949 0.0947 0.0937 0.0846\n",
            " 0.084 ], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08976206 0.0917666  0.090227   0.09221935 0.09121693 0.09303384\n",
            " 0.09485187 0.09465437 0.0937172  0.0845587  0.08399205], argmax=6\n",
            "   \u001b[33m|->> #63-th Action selection: 3/2X RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [130   6  66  92]\n",
            "         |->> Action Probabilities (Rounded): [0.0907 0.0917 0.0884 0.0907 0.0925 0.0925 0.0931 0.0945 0.0934 0.086\n",
            " 0.0865], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09071498 0.09172146 0.088387   0.09065746 0.0924968  0.09252325\n",
            " 0.09312385 0.09453332 0.09339753 0.08597492 0.08646945], argmax=7\n",
            "   \u001b[33m|->> #64-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [131   7  64  89]\n",
            "         |->> Action Probabilities (Rounded): [0.0908 0.0924 0.087  0.0893 0.093  0.0926 0.0942 0.0947 0.0927 0.087\n",
            " 0.0864], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09080659 0.0923769  0.08702739 0.08931445 0.09295828 0.09262843\n",
            " 0.09417072 0.09467641 0.0926637  0.08699619 0.08638097], argmax=7\n",
            "   \u001b[33m|->> #65-th Action selection: 1/2X LEFT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [129   7  64  89]\n",
            "         |->> Action Probabilities (Rounded): [0.0898 0.0926 0.0877 0.0912 0.094  0.0931 0.0939 0.0948 0.0931 0.082\n",
            " 0.0877], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08982053 0.0926113  0.08765144 0.09124245 0.09400979 0.09306036\n",
            " 0.09392258 0.09482063 0.09307362 0.08203819 0.08774912], argmax=7\n",
            "   \u001b[33m|->> #66-th Action selection: 4/UP (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [129   5  64  89]\n",
            "         |->> Action Probabilities (Rounded): [0.0899 0.09   0.0886 0.0906 0.0936 0.0927 0.0944 0.0945 0.0934 0.0857\n",
            " 0.0866], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08986369 0.09004901 0.08864362 0.09059595 0.0935597  0.09271379\n",
            " 0.09439608 0.09453738 0.09338608 0.08568106 0.08657362], argmax=7\n",
            "   \u001b[33m|->> #67-th Action selection: 10/SCALE UP (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [128   3  66  91]\n",
            "         |->> Action Probabilities (Rounded): [0.0907 0.0905 0.0884 0.0909 0.0919 0.0924 0.0946 0.0947 0.0932 0.0845\n",
            " 0.0883], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09070904 0.09048429 0.08839876 0.09085454 0.09187409 0.09241385\n",
            " 0.09455646 0.09466167 0.09317812 0.08454493 0.08832426], argmax=7\n",
            "   \u001b[33m|->> #68-th Action selection: 6/DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [128   5  66  91]\n",
            "         |->> Action Probabilities (Rounded): [0.0903 0.0905 0.0886 0.0916 0.0927 0.0926 0.0941 0.0955 0.0934 0.0875\n",
            " 0.0833], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09030318 0.09046183 0.08858294 0.09155005 0.0927031  0.09261627\n",
            " 0.09412728 0.09549314 0.09335165 0.08748882 0.08332181], argmax=7\n",
            "   \u001b[33m|->> #69-th Action selection: 6/DOWN (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [128   7  66  91]\n",
            "         |->> Action Probabilities (Rounded): [0.0904 0.0906 0.0889 0.0917 0.0934 0.0922 0.092  0.0949 0.0932 0.0859\n",
            " 0.0867], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09039596 0.09064674 0.08894068 0.09167208 0.09342869 0.09218933\n",
            " 0.09195    0.09487999 0.09323601 0.08592895 0.08673158], argmax=7\n",
            "|->> Revisiting bbox: [128   7  66  91]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [123,  10,  68,  94] -> [128,   7,  66,  91] (Target was [111,  61,  79,  93])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [123,  10,  68,  94] -> [127,  10,  68,  94] w/ P(a|s)=0.09015793353319168 and iou=0.2456029011786038 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [127,  10,  68,  94] -> [128,  11,  65,  91] w/ P(a|s)=0.08635371923446655 and iou=0.2371268656716418 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for SCALE UP:bbox transition: [128,  11,  65,  91] -> [127,   9,  67,  93] w/ P(a|s)=0.08904705196619034 and iou=0.234924965893588 and reward=-1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-1.0) for DOWN:bbox transition: [127,   9,  67,  93] -> [127,  11,  67,  93] w/ P(a|s)=0.09477723389863968 and iou=0.24924096052994757 and reward=-1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-1.0) for SCALE UP:bbox transition: [127,  11,  67,  93] -> [125,   9,  69,  95] w/ P(a|s)=0.08508040010929108 and iou=0.2516431079499415 and reward=-1.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-1.0) for UP:bbox transition: [125,   9,  69,  95] -> [125,   7,  69,  95] w/ P(a|s)=0.0930120125412941 and iou=0.2371629438462223 and reward=-1.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [125,   7,  69,  95] -> [126,   8,  66,  92] w/ P(a|s)=0.08671486377716064 and iou=0.22850865146937654 and reward=-1.0 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (-1.0) for UP:bbox transition: [126,   8,  66,  92] -> [126,   6,  66,  92] w/ P(a|s)=0.09232866764068604 and iou=0.21427925074653878 and reward=-1.0 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [126,   6,  66,  92] -> [128,   6,  66,  92] w/ P(a|s)=0.09221934527158737 and iou=0.20620224719101124 and reward=-1.0 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [128,   6,  66,  92] -> [130,   6,  66,  92] w/ P(a|s)=0.09065745770931244 and iou=0.1982319849986606 and reward=-1.0 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [130,   6,  66,  92] -> [131,   7,  64,  89] w/ P(a|s)=0.08699619024991989 and iou=0.188103479686646 and reward=-1.0 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [131,   7,  64,  89] -> [129,   7,  64,  89] w/ P(a|s)=0.09261129796504974 and iou=0.19572790612394572 and reward=-1.0 and discount=0.8953382542587164\n",
            "   |->> t=13 Diff-Reward (-1.0) for UP:bbox transition: [129,   7,  64,  89] -> [129,   5,  64,  89] w/ P(a|s)=0.09355970472097397 and iou=0.18250226654578422 and reward=-1.0 and discount=0.8863848717161292\n",
            "   |->> t=14 Diff-Reward (-1.0) for SCALE UP:bbox transition: [129,   5,  64,  89] -> [128,   3,  66,  91] w/ P(a|s)=0.08832425624132156 and iou=0.18094985407269834 and reward=-1.0 and discount=0.8775210229989678\n",
            "   |->> t=15 Diff-Reward (-1.0) for DOWN:bbox transition: [128,   3,  66,  91] -> [128,   5,  66,  91] w/ P(a|s)=0.09412727504968643 and iou=0.19404453187874451 and reward=-1.0 and discount=0.8687458127689782\n",
            "   |->> t=16 Diff-Reward (-1.0) for DOWN:bbox transition: [128,   5,  66,  91] -> [128,   7,  66,  91] w/ P(a|s)=0.09194999933242798 and iou=0.20743286011393436 and reward=-1.0 and discount=0.8600583546412884\n",
            "   |->> Assigned losses: [-2.4061923 -2.4248104 -2.3704603 -2.2862437 -2.367061  -2.2586267\n",
            " -2.3020413 -2.220553  -2.1994407 -2.1930509 -2.2084024 -2.130318\n",
            " -2.0999835 -2.129516  -2.0529397 -2.0525382]\n",
            "\u001b[31m>> Total frame loss: -35.702178955078125\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 37 with src: [128,   7,  66,  91] and target: [110,  58,  75,  98]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0037.jpg\n",
            "|->> Beginning tracking for bbox:[128   7  66  91]\n",
            "   \u001b[33m|->> #70-th Action selection: 1/2X LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [126   7  66  91]\n",
            "         |->> Action Probabilities (Rounded): [0.0906 0.0906 0.0899 0.0917 0.0935 0.0925 0.0909 0.0943 0.0931 0.0871\n",
            " 0.0858], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09055565 0.09060664 0.08992452 0.09167316 0.09354009 0.09246766\n",
            " 0.09090054 0.09430715 0.09307458 0.08712746 0.08582258], argmax=7\n",
            "   \u001b[33m|->> #71-th Action selection: 0/LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [125   7  66  91]\n",
            "         |->> Action Probabilities (Rounded): [0.0906 0.0883 0.0904 0.0908 0.0928 0.0925 0.0922 0.0939 0.0931 0.0885\n",
            " 0.0869], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09060155 0.08827847 0.09038354 0.09080452 0.0928029  0.09250829\n",
            " 0.09221175 0.09385548 0.0931078  0.0885181  0.08692764], argmax=7\n",
            "   \u001b[33m|->> #72-th Action selection: 7/2X DOWN (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [125  11  66  91]\n",
            "         |->> Action Probabilities (Rounded): [0.0831 0.0885 0.0958 0.0919 0.0935 0.0937 0.0925 0.0951 0.093  0.0861\n",
            " 0.0867], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08306243 0.08846495 0.09584723 0.09194021 0.09351411 0.09374351\n",
            " 0.09252748 0.09511194 0.09302926 0.08605641 0.08670253], argmax=2\n",
            "   \u001b[33m|->> #73-th Action selection: 6/DOWN (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [125  13  66  91]\n",
            "         |->> Action Probabilities (Rounded): [0.0905 0.0882 0.0887 0.093  0.0933 0.0928 0.0933 0.0928 0.0926 0.0873\n",
            " 0.0873], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.09053102 0.08820475 0.08870529 0.09296459 0.09333251 0.09280532\n",
            " 0.0933249  0.09281179 0.0926339  0.08734693 0.08733898], argmax=4\n",
            "   \u001b[33m|->> #74-th Action selection: 10/SCALE UP (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [124  11  68  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0867 0.089  0.0933 0.0933 0.0951 0.0926 0.0908 0.0925 0.0925 0.0871\n",
            " 0.0872], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.08667605 0.08901493 0.09326122 0.09329881 0.09507144 0.09261576\n",
            " 0.09078322 0.09246437 0.09251732 0.08709922 0.08719768], argmax=4\n",
            "   \u001b[33m|->> #75-th Action selection: 3/2X RIGHT (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [128  11  68  93]\n",
            "         |->> Action Probabilities (Rounded): [0.09   0.0886 0.0909 0.0937 0.0934 0.0927 0.0931 0.0924 0.0927 0.0901\n",
            " 0.0824], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.0900243  0.08860531 0.09085419 0.0936714  0.09336314 0.09272934\n",
            " 0.0931002  0.09240982 0.09274394 0.09009001 0.08240835], argmax=3\n",
            "   \u001b[33m|->> #76-th Action selection: 6/DOWN (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [128  13  68  93]\n",
            "         |->> Action Probabilities (Rounded): [0.09   0.0904 0.0912 0.0916 0.0944 0.0929 0.0916 0.0924 0.0927 0.0882\n",
            " 0.0846], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0899967  0.09037685 0.09123576 0.09159345 0.09435043 0.09293064\n",
            " 0.09163085 0.09236495 0.09270898 0.08818534 0.08462603], argmax=4\n",
            "   \u001b[33m|->> #77-th Action selection: 2/RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [130  13  68  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0906 0.0901 0.0905 0.092  0.0948 0.0934 0.0908 0.0926 0.0921 0.0891\n",
            " 0.0841], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.09057833 0.09007662 0.09052324 0.09203123 0.09477964 0.09336779\n",
            " 0.09075105 0.09256602 0.09208751 0.08909827 0.08414032], argmax=4\n",
            "|->> Revisiting bbox: [130  13  68  93]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [128,   7,  66,  91] -> [130,  13,  68,  93] (Target was [110,  58,  75,  98])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [128,   7,  66,  91] -> [126,   7,  66,  91] w/ P(a|s)=0.09060664474964142 and iou=0.21462349945434703 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for LEFT:bbox transition: [126,   7,  66,  91] -> [125,   7,  66,  91] w/ P(a|s)=0.09060154855251312 and iou=0.21905805038335158 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for 2X DOWN:bbox transition: [125,   7,  66,  91] -> [125,  11,  66,  91] w/ P(a|s)=0.09511193633079529 and iou=0.24636058230683092 and reward=-1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-1.0) for DOWN:bbox transition: [125,  11,  66,  91] -> [125,  13,  66,  91] w/ P(a|s)=0.09332489967346191 and iou=0.26047565118912797 and reward=-1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-1.0) for SCALE UP:bbox transition: [125,  13,  66,  91] -> [124,  11,  68,  93] w/ P(a|s)=0.0871976837515831 and iou=0.25818917924181084 and reward=-1.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [124,  11,  68,  93] -> [128,  11,  68,  93] w/ P(a|s)=0.09367139637470245 and iou=0.23724212812160694 and reward=-1.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (-1.0) for DOWN:bbox transition: [128,  11,  68,  93] -> [128,  13,  68,  93] w/ P(a|s)=0.09163085371255875 and iou=0.2501371365880417 and reward=-1.0 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (-1.0) for RIGHT:bbox transition: [128,  13,  68,  93] -> [130,  13,  68,  93] w/ P(a|s)=0.09052324295043945 and iou=0.2392604676454595 and reward=-1.0 and discount=0.9320653479069899\n",
            "   |->> Assigned losses: [-2.4012277 -2.3772712 -2.305882  -2.3012273 -2.3434486 -2.2519085\n",
            " -2.2501256 -2.2389596]\n",
            "\u001b[31m>> Total frame loss: -18.470050811767578\u001b[0m\n",
            "Final bounding box: [130  13  68  93] reached in 78 timesteps (originating from [120  51  73 101]). Target was [110  58  75  98]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 38 in t=78 timesteps ################\u001b[0m\n",
            "\n",
            "\u001b[36m####################### EPISODE # 4 ############################\u001b[0m\n",
            "Starting bounding box for adnet_datasets/OTB/FaceOcc2: frames 27:37 is [120  51  73 101].\n",
            "\u001b[34m>> Attempting to reach frame 28 with src: [120,  51,  73, 101] and target: [120,  53,  72, 101]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0028.jpg\n",
            "|->> Beginning tracking for bbox:[120  51  73 101]\n",
            "   \u001b[33m|->> #1-th Action selection: 9/SCALE DOWN (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [121  52  70  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0909 0.0908 0.091  0.0909 0.0909 0.0908 0.091  0.091  0.0912 0.0908\n",
            " 0.0909], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09088143 0.09078364 0.0909692  0.0909298  0.0909142  0.09079628\n",
            " 0.09095277 0.09095596 0.09115104 0.09079725 0.09086843], argmax=8\n",
            "   \u001b[33m|->> #2-th Action selection: 4/UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [121  50  70  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0904 0.0913 0.0912 0.0917 0.0913 0.0912 0.0915 0.0917 0.0921 0.0857\n",
            " 0.0919], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09043574 0.09125368 0.0912076  0.09171174 0.09129108 0.09124862\n",
            " 0.09150841 0.09171464 0.09205598 0.08568428 0.0918882 ], argmax=8\n",
            "   \u001b[33m|->> #3-th Action selection: 2/RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [123  50  70  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0915 0.0913 0.0914 0.0918 0.0893 0.0913 0.092  0.0919 0.0925 0.087\n",
            " 0.09  ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09152921 0.09127788 0.09143897 0.09176506 0.0893113  0.09125159\n",
            " 0.0919961  0.09193952 0.09249074 0.08695166 0.09004799], argmax=8\n",
            "   \u001b[33m|->> #4-th Action selection: 4/UP (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [123  48  70  97]\n",
            "         |->> Action Probabilities (Rounded): [0.098  0.0913 0.0834 0.0925 0.0902 0.0919 0.0915 0.0926 0.0926 0.0856\n",
            " 0.0905], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09795739 0.09132717 0.08335675 0.09251832 0.09021182 0.09188206\n",
            " 0.09147955 0.09260094 0.09256269 0.08559034 0.09051299], argmax=0\n",
            "   \u001b[33m|->> #5-th Action selection: 0/LEFT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [121  48  70  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0888 0.0922 0.093  0.0911 0.0891 0.0913 0.0929 0.0929 0.0927 0.0863\n",
            " 0.0897], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08877762 0.09224561 0.09303655 0.09109182 0.08910216 0.09133136\n",
            " 0.09286192 0.09287129 0.09270021 0.08631208 0.0896694 ], argmax=2\n",
            "   \u001b[33m|->> #6-th Action selection: 0/LEFT (P(a|s) = 0.0860000029206276)\u001b[0m\n",
            "      |->> Bounding box moves to: [119  48  70  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0863 0.092  0.0956 0.0923 0.0903 0.0922 0.0917 0.0938 0.0926 0.0842\n",
            " 0.089 ], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08628528 0.09202345 0.09559296 0.09232764 0.09025501 0.09222564\n",
            " 0.09173016 0.09382126 0.09258111 0.08415344 0.08900399], argmax=2\n",
            "   \u001b[33m|->> #7-th Action selection: 5/2X UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [119  44  70  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0852 0.0917 0.0952 0.0933 0.0905 0.0929 0.0931 0.0947 0.0917 0.083\n",
            " 0.0887], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08520623 0.09170268 0.09523746 0.09325114 0.0905411  0.09291731\n",
            " 0.09305282 0.09474042 0.09170801 0.082967   0.08867584], argmax=2\n",
            "|->> Revisiting bbox: [119  44  70  97]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [120,  51,  73, 101] -> [119,  44,  70,  97] (Target was [120,  53,  72, 101])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for SCALE DOWN:bbox transition: [120,  51,  73, 101] -> [121,  52,  70,  97] w/ P(a|s)=0.09079724550247192 and iou=0.9152819395260147 and reward=1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for UP:bbox transition: [121,  52,  70,  97] -> [121,  50,  70,  97] w/ P(a|s)=0.09129107743501663 and iou=0.8794439989307672 and reward=1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (1.0) for RIGHT:bbox transition: [121,  50,  70,  97] -> [123,  50,  70,  97] w/ P(a|s)=0.09143897145986557 and iou=0.8561246040126715 and reward=1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (1.0) for UP:bbox transition: [123,  50,  70,  97] -> [123,  48,  70,  97] w/ P(a|s)=0.09021182358264923 and iou=0.8229193673839772 and reward=1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (1.0) for LEFT:bbox transition: [123,  48,  70,  97] -> [121,  48,  70,  97] w/ P(a|s)=0.08877761662006378 and iou=0.844922592495408 and reward=1.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (1.0) for LEFT:bbox transition: [121,  48,  70,  97] -> [119,  48,  70,  97] w/ P(a|s)=0.08628527820110321 and iou=0.8229193673839772 and reward=1.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (1.0) for 2X UP:bbox transition: [119,  48,  70,  97] -> [119,  44,  70,  97] w/ P(a|s)=0.0929173082113266 and iou=0.7599499374217772 and reward=1.0 and discount=0.941480149401\n",
            "   |->> Assigned losses: [2.3991263 2.3697653 2.344481  2.3341463 2.3261993 2.330017  2.2369995]\n",
            "\u001b[92m>> Total frame loss: 16.340734481811523\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 29 with src: [119,  44,  70,  97] and target: [116,  55,  76,  98]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0029.jpg\n",
            "|->> Beginning tracking for bbox:[119  44  70  97]\n",
            "   \u001b[33m|->> #8-th Action selection: 7/2X DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [119  48  70  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0919 0.091  0.0901 0.0932 0.0916 0.0912 0.0927 0.0943 0.0915 0.0841\n",
            " 0.0886], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09189973 0.09095117 0.0900597  0.09319169 0.09156682 0.09115382\n",
            " 0.09272551 0.0942849  0.09149523 0.08408743 0.08858403], argmax=7\n",
            "   \u001b[33m|->> #9-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08500000089406967)\u001b[0m\n",
            "      |->> Bounding box moves to: [120  49  67  94]\n",
            "         |->> Action Probabilities (Rounded): [0.09   0.0907 0.093  0.0925 0.0917 0.0909 0.0935 0.0927 0.0917 0.0845\n",
            " 0.0888], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09003078 0.09066296 0.09299388 0.09249669 0.09165221 0.09089918\n",
            " 0.09347565 0.09266007 0.09174889 0.08453877 0.08884097], argmax=6\n",
            "   \u001b[33m|->> #10-th Action selection: 4/UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [120  47  67  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0929 0.0908 0.0901 0.0938 0.0927 0.0911 0.0932 0.0934 0.0921 0.08\n",
            " 0.09  ], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09294721 0.09083433 0.09006483 0.09378033 0.09267201 0.09106887\n",
            " 0.09316709 0.09342973 0.09207625 0.08000924 0.08995007], argmax=3\n",
            "   \u001b[33m|->> #11-th Action selection: 0/LEFT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [118  47  67  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0923 0.0909 0.0918 0.0938 0.0901 0.0917 0.0943 0.0936 0.0924 0.0811\n",
            " 0.0881], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09229185 0.09090216 0.09177902 0.09377454 0.09011415 0.09170963\n",
            " 0.09427211 0.09359068 0.09235884 0.08106885 0.08813822], argmax=6\n",
            "|->> Revisiting bbox: [120  47  67  94]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [119,  44,  70,  97] -> [118,  47,  67,  94] (Target was [116,  55,  76,  98])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for 2X DOWN:bbox transition: [119,  44,  70,  97] -> [119,  48,  70,  97] w/ P(a|s)=0.09428489953279495 and iou=0.7936507936507936 and reward=1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for SCALE DOWN:bbox transition: [119,  48,  70,  97] -> [120,  49,  67,  94] w/ P(a|s)=0.0845387727022171 and iou=0.7510828025477707 and reward=1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (1.0) for UP:bbox transition: [120,  49,  67,  94] -> [120,  47,  67,  94] w/ P(a|s)=0.09267200529575348 and iou=0.7216933867735471 and reward=1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (1.0) for LEFT:bbox transition: [120,  47,  67,  94] -> [118,  47,  67,  94] w/ P(a|s)=0.09229184687137604 and iou=0.7216933867735471 and reward=1.0 and discount=0.970299\n",
            "   |->> Assigned losses: [2.3614342 2.4458396 2.331353  2.312028 ]\n",
            "\u001b[92m>> Total frame loss: 9.450654983520508\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 30 with src: [118,  47,  67,  94] and target: [118,  57,  76,  97]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0030.jpg\n",
            "|->> Beginning tracking for bbox:[118  47  67  94]\n",
            "   \u001b[33m|->> #12-th Action selection: 0/LEFT (P(a|s) = 0.0860000029206276)\u001b[0m\n",
            "      |->> Bounding box moves to: [116  47  67  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0856 0.0913 0.0974 0.0941 0.091  0.0922 0.0931 0.0942 0.0924 0.0806\n",
            " 0.0882], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08555876 0.09127631 0.09739625 0.09409582 0.09097728 0.0921812\n",
            " 0.09310059 0.09424073 0.09237804 0.08061351 0.0881815 ], argmax=2\n",
            "|->> Revisiting bbox: [118  47  67  94]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [118,  47,  67,  94] -> [116,  47,  67,  94] (Target was [118,  57,  76,  97])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for LEFT:bbox transition: [118,  47,  67,  94] -> [116,  47,  67,  94] w/ P(a|s)=0.08555875718593597 and iou=0.6650426309378806 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.458552]\n",
            "\u001b[31m>> Total frame loss: -2.4585518836975098\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 31 with src: [116,  47,  67,  94] and target: [115,  53,  77, 100]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0031.jpg\n",
            "|->> Beginning tracking for bbox:[116  47  67  94]\n",
            "   \u001b[33m|->> #13-th Action selection: 1/2X LEFT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [112  47  67  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0861 0.0902 0.0958 0.0948 0.0918 0.0928 0.0939 0.0948 0.0925 0.0797\n",
            " 0.0875], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08609468 0.09021006 0.09576043 0.09480769 0.09181791 0.0928492\n",
            " 0.09394512 0.09481525 0.09253087 0.07968686 0.08748197], argmax=2\n",
            "   \u001b[33m|->> #14-th Action selection: 5/2X UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [112  43  67  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0914 0.0868 0.0917 0.0949 0.0922 0.0924 0.0934 0.0949 0.0923 0.0817\n",
            " 0.0883], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.0913578  0.08682209 0.09166647 0.09488204 0.09223518 0.09243265\n",
            " 0.09339788 0.09491922 0.09231682 0.08171081 0.08825903], argmax=7\n",
            "|->> Revisiting bbox: [112  47  67  94]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [116,  47,  67,  94] -> [112,  43,  67,  94] (Target was [115,  53,  77, 100])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [116,  47,  67,  94] -> [112,  47,  67,  94] w/ P(a|s)=0.09021005779504776 and iou=0.6732010518766436 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for 2X UP:bbox transition: [112,  47,  67,  94] -> [112,  43,  67,  94] w/ P(a|s)=0.0924326479434967 and iou=0.6235212247738344 and reward=-1.0 and discount=0.99\n",
            "   |->> Assigned losses: [-2.4056144 -2.3574622]\n",
            "\u001b[31m>> Total frame loss: -4.7630767822265625\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 32 with src: [112,  43,  67,  94] and target: [116,  55,  73,  98]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0032.jpg\n",
            "|->> Beginning tracking for bbox:[112  43  67  94]\n",
            "   \u001b[33m|->> #15-th Action selection: 1/2X LEFT (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [108  43  67  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0921 0.0865 0.093  0.0941 0.0918 0.0911 0.0941 0.0946 0.0923 0.082\n",
            " 0.0883], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09207305 0.08653349 0.09299842 0.09407639 0.09184375 0.09113256\n",
            " 0.09409988 0.09461689 0.09230958 0.08200441 0.08831159], argmax=7\n",
            "   \u001b[33m|->> #16-th Action selection: 7/2X DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [108  47  67  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0918 0.0848 0.0921 0.0945 0.0927 0.0905 0.094  0.0942 0.0928 0.0836\n",
            " 0.0889], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09182195 0.0848377  0.09212372 0.09450782 0.09274182 0.09054764\n",
            " 0.09398261 0.09424271 0.09276769 0.08356794 0.08885841], argmax=3\n",
            "   \u001b[33m|->> #17-th Action selection: 1/2X LEFT (P(a|s) = 0.0860000029206276)\u001b[0m\n",
            "      |->> Bounding box moves to: [104  47  67  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0902 0.0864 0.0932 0.0933 0.0921 0.0902 0.0942 0.0924 0.0933 0.0851\n",
            " 0.0897], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09020235 0.08644048 0.09316549 0.09328455 0.09209552 0.09021732\n",
            " 0.09418952 0.09241339 0.09326937 0.08506553 0.08965648], argmax=6\n",
            "   \u001b[33m|->> #18-th Action selection: 2/RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [106  47  67  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0899 0.0844 0.0917 0.0936 0.0932 0.0912 0.0942 0.0929 0.0934 0.0859\n",
            " 0.0897], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08989331 0.08441453 0.09166805 0.09359571 0.09321386 0.0911938\n",
            " 0.09417282 0.09290173 0.09336121 0.085919   0.08966597], argmax=6\n",
            "   \u001b[33m|->> #19-th Action selection: 1/2X LEFT (P(a|s) = 0.08500000089406967)\u001b[0m\n",
            "      |->> Bounding box moves to: [102  47  67  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0963 0.0852 0.0844 0.0939 0.0928 0.0923 0.0946 0.0941 0.0931 0.0845\n",
            " 0.0888], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.0963024  0.08522282 0.08442766 0.0938535  0.0927517  0.09231241\n",
            " 0.09459516 0.09414445 0.09311596 0.08451719 0.08875677], argmax=0\n",
            "|->> Revisiting bbox: [104  47  67  94]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [112,  43,  67,  94] -> [102,  47,  67,  94] (Target was [116,  55,  73,  98])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [112,  43,  67,  94] -> [108,  43,  67,  94] w/ P(a|s)=0.08653348684310913 and iou=0.5616438356164384 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for 2X DOWN:bbox transition: [108,  43,  67,  94] -> [108,  47,  67,  94] w/ P(a|s)=0.09424271434545517 and iou=0.6056338028169014 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [108,  47,  67,  94] -> [104,  47,  67,  94] w/ P(a|s)=0.08644048124551773 and iou=0.5423068103645953 and reward=-1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-1.0) for RIGHT:bbox transition: [104,  47,  67,  94] -> [106,  47,  67,  94] w/ P(a|s)=0.09166805446147919 and iou=0.5733333333333334 and reward=-1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [106,  47,  67,  94] -> [102,  47,  67,  94] w/ P(a|s)=0.08522281795740128 and iou=0.512480323813807 and reward=-1.0 and discount=0.96059601\n",
            "   |->> Assigned losses: [-2.447224  -2.338263  -2.3995779 -2.3186083 -2.3654542]\n",
            "\u001b[31m>> Total frame loss: -11.86912727355957\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 33 with src: [102,  47,  67,  94] and target: [115,  57,  77,  97]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0033.jpg\n",
            "|->> Beginning tracking for bbox:[102  47  67  94]\n",
            "   \u001b[33m|->> #20-th Action selection: 2/RIGHT (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [104  47  67  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0872 0.0835 0.0948 0.0924 0.0934 0.0917 0.0945 0.0942 0.0934 0.0866\n",
            " 0.0884], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08715605 0.08350908 0.09478764 0.09237961 0.09337199 0.09173618\n",
            " 0.09445966 0.09420473 0.09342599 0.08657938 0.08838972], argmax=2\n",
            "|->> Revisiting bbox: [104  47  67  94]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [102,  47,  67,  94] -> [104,  47,  67,  94] (Target was [115,  57,  77,  97])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for RIGHT:bbox transition: [102,  47,  67,  94] -> [104,  47,  67,  94] w/ P(a|s)=0.09478764235973358 and iou=0.5190334326381992 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.3561163]\n",
            "\u001b[31m>> Total frame loss: -2.35611629486084\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 34 with src: [104,  47,  67,  94] and target: [116,  56,  76,  97]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0034.jpg\n",
            "|->> Beginning tracking for bbox:[104  47  67  94]\n",
            "   \u001b[33m|->> #21-th Action selection: 5/2X UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [104  43  67  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0999 0.0839 0.0826 0.0928 0.0924 0.093  0.095  0.0946 0.0932 0.0849\n",
            " 0.0876], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09989258 0.08391434 0.08259694 0.09284907 0.09240408 0.09303364\n",
            " 0.09496553 0.09463272 0.09322833 0.08485302 0.08762976], argmax=0\n",
            "   \u001b[33m|->> #22-th Action selection: 3/2X RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [108  43  67  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0857 0.0859 0.0943 0.0915 0.0934 0.0909 0.0951 0.0943 0.0939 0.0869\n",
            " 0.0882], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08567506 0.08587568 0.0942736  0.09151547 0.09341731 0.09090494\n",
            " 0.09505893 0.0942513  0.09390204 0.08691975 0.08820593], argmax=6\n",
            "   \u001b[33m|->> #23-th Action selection: 5/2X UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [108  39  67  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0921 0.0877 0.0884 0.0893 0.0928 0.0907 0.0946 0.0934 0.0935 0.0886\n",
            " 0.089 ], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.0921298  0.08771105 0.08837175 0.08929547 0.09275205 0.09072613\n",
            " 0.0945683  0.09336252 0.09347732 0.0886289  0.08897665], argmax=6\n",
            "   \u001b[33m|->> #24-th Action selection: 3/2X RIGHT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [112  39  67  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0883 0.0882 0.0913 0.0902 0.0926 0.0894 0.0947 0.0937 0.0942 0.0884\n",
            " 0.0889], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08834356 0.08817857 0.09134634 0.09019656 0.09256562 0.08944362\n",
            " 0.0946767  0.09374244 0.09423053 0.08836875 0.0889073 ], argmax=6\n",
            "   \u001b[33m|->> #25-th Action selection: 10/SCALE UP (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [110  37  69  96]\n",
            "         |->> Action Probabilities (Rounded): [0.0919 0.0895 0.0887 0.0879 0.0928 0.0903 0.0943 0.0932 0.0932 0.0892\n",
            " 0.089 ], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.0918763  0.0894997  0.08873372 0.08790359 0.09277731 0.09030194\n",
            " 0.09431921 0.09324298 0.09315033 0.08915859 0.08903634], argmax=6\n",
            "   \u001b[33m|->> #26-th Action selection: 6/DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [110  39  69  96]\n",
            "         |->> Action Probabilities (Rounded): [0.0901 0.0901 0.0888 0.0894 0.0931 0.0912 0.0945 0.0944 0.0945 0.0903\n",
            " 0.0837], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.0900791  0.0901219  0.08875794 0.08943931 0.09305387 0.0911608\n",
            " 0.09449902 0.09442571 0.09448395 0.09029847 0.08367988], argmax=6\n",
            "   \u001b[33m|->> #27-th Action selection: 7/2X DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [110  43  69  96]\n",
            "         |->> Action Probabilities (Rounded): [0.0912 0.0908 0.0895 0.089  0.094  0.0914 0.0919 0.0944 0.0939 0.0887\n",
            " 0.0852], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09122852 0.09083678 0.08951515 0.08898302 0.09399667 0.09137833\n",
            " 0.0918993  0.09437475 0.09386402 0.08874468 0.08517883], argmax=7\n",
            "|->> Revisiting bbox: [110  43  69  96]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [104,  47,  67,  94] -> [110,  43,  69,  96] (Target was [116,  56,  76,  97])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for 2X UP:bbox transition: [104,  47,  67,  94] -> [104,  43,  67,  94] w/ P(a|s)=0.09303364157676697 and iou=0.4834508952794357 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [104,  43,  67,  94] -> [108,  43,  67,  94] w/ P(a|s)=0.09151547402143478 and iou=0.5375098414126644 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for 2X UP:bbox transition: [108,  43,  67,  94] -> [108,  39,  67,  94] w/ P(a|s)=0.09072612971067429 and iou=0.49775391694970966 and reward=-1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [108,  39,  67,  94] -> [112,  39,  67,  94] w/ P(a|s)=0.09019656479358673 and iou=0.550062365347545 and reward=-1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-1.0) for SCALE UP:bbox transition: [112,  39,  67,  94] -> [110,  37,  69,  96] w/ P(a|s)=0.08903633803129196 and iou=0.5304537998906507 and reward=-1.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-1.0) for DOWN:bbox transition: [110,  37,  69,  96] -> [110,  39,  69,  96] w/ P(a|s)=0.09449902176856995 and iou=0.5518350149684 and reward=-1.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (-1.0) for 2X DOWN:bbox transition: [110,  39,  69,  96] -> [110,  43,  69,  96] w/ P(a|s)=0.09437475353479385 and iou=0.5964411999543744 and reward=-1.0 and discount=0.941480149401\n",
            "   |->> Assigned losses: [-2.374794  -2.3673348 -2.3521516 -2.3343103 -2.3234038 -2.2435431\n",
            " -2.2223468]\n",
            "\u001b[31m>> Total frame loss: -16.217884063720703\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 35 with src: [110,  43,  69,  96] and target: [112,  58,  76,  96]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0035.jpg\n",
            "|->> Beginning tracking for bbox:[110  43  69  96]\n",
            "   \u001b[33m|->> #28-th Action selection: 5/2X UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [110  39  69  96]\n",
            "         |->> Action Probabilities (Rounded): [0.0907 0.0909 0.0897 0.09   0.0924 0.0912 0.0933 0.0924 0.0941 0.0899\n",
            " 0.0853], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09065784 0.09093977 0.08968684 0.08998282 0.09244828 0.09122837\n",
            " 0.09333789 0.09244944 0.09407688 0.08992369 0.08526818], argmax=8\n",
            "   \u001b[33m|->> #29-th Action selection: 9/SCALE DOWN (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [111  40  66  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0907 0.0915 0.0894 0.0899 0.0931 0.0895 0.0924 0.0919 0.0945 0.0902\n",
            " 0.087 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09074984 0.09150711 0.08939848 0.08986273 0.0930858  0.08949069\n",
            " 0.09237164 0.09188825 0.09448069 0.09019085 0.08697396], argmax=8\n",
            "   \u001b[33m|->> #30-th Action selection: 5/2X UP (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [111  36  66  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0901 0.0922 0.0898 0.0916 0.0926 0.09   0.0937 0.0924 0.0944 0.0851\n",
            " 0.0881], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09007257 0.09219181 0.08984002 0.09156512 0.09261911 0.0899764\n",
            " 0.09373618 0.09241018 0.09440895 0.08507973 0.08809996], argmax=8\n",
            "   \u001b[33m|->> #31-th Action selection: 0/LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [110  36  66  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0908 0.0921 0.0895 0.0913 0.0925 0.0884 0.0929 0.0921 0.0951 0.0879\n",
            " 0.0874], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09081783 0.09214018 0.08954357 0.09126785 0.0924501  0.08836392\n",
            " 0.09287222 0.09214265 0.09506311 0.08789174 0.08744685], argmax=8\n",
            "   \u001b[33m|->> #32-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08500000089406967)\u001b[0m\n",
            "      |->> Bounding box moves to: [111  37  64  90]\n",
            "         |->> Action Probabilities (Rounded): [0.0831 0.0918 0.0961 0.0928 0.0924 0.09   0.0936 0.0929 0.0946 0.0848\n",
            " 0.088 ], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08309922 0.09176704 0.09609437 0.09278356 0.09236214 0.09003803\n",
            " 0.09356688 0.09288967 0.09460008 0.08478484 0.08801422], argmax=2\n",
            "|->> Revisiting bbox: [111  37  64  90]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [110,  43,  69,  96] -> [111,  37,  64,  90] (Target was [112,  58,  76,  96])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for 2X UP:bbox transition: [110,  43,  69,  96] -> [110,  39,  69,  96] w/ P(a|s)=0.09122837334871292 and iou=0.5888597192101358 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [110,  39,  69,  96] -> [111,  40,  66,  93] w/ P(a|s)=0.09019085019826889 and iou=0.5695758850332983 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for 2X UP:bbox transition: [111,  40,  66,  93] -> [111,  36,  66,  93] w/ P(a|s)=0.08997640013694763 and iou=0.5233019616736592 and reward=-1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-1.0) for LEFT:bbox transition: [111,  36,  66,  93] -> [110,  36,  66,  93] w/ P(a|s)=0.09081783145666122 and iou=0.5111361079865017 and reward=-1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [110,  36,  66,  93] -> [111,  37,  64,  90] w/ P(a|s)=0.08478483557701111 and iou=0.49913882190837067 and reward=-1.0 and discount=0.96059601\n",
            "   |->> Assigned losses: [-2.3943894 -2.381769  -2.3602846 -2.3276498 -2.3704038]\n",
            "\u001b[31m>> Total frame loss: -11.834495544433594\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 36 with src: [111,  37,  64,  90] and target: [111,  61,  79,  93]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0036.jpg\n",
            "|->> Beginning tracking for bbox:[111  37  64  90]\n",
            "   \u001b[33m|->> #33-th Action selection: 2/RIGHT (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [112  37  64  90]\n",
            "         |->> Action Probabilities (Rounded): [0.0908 0.0915 0.0879 0.094  0.0928 0.09   0.0937 0.0937 0.0948 0.0816\n",
            " 0.0891], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09081317 0.09146828 0.08790909 0.09401442 0.09283158 0.09001282\n",
            " 0.09370556 0.09366415 0.09484094 0.08161593 0.08912408], argmax=8\n",
            "   \u001b[33m|->> #34-th Action selection: 2/RIGHT (P(a|s) = 0.08399999886751175)\u001b[0m\n",
            "      |->> Bounding box moves to: [113  37  64  90]\n",
            "         |->> Action Probabilities (Rounded): [0.0942 0.0914 0.0841 0.0943 0.0926 0.0921 0.0937 0.0937 0.0942 0.0823\n",
            " 0.0876], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09415476 0.09135297 0.08406611 0.09427034 0.09261695 0.09205025\n",
            " 0.09366351 0.09368498 0.09423206 0.08229719 0.08761086], argmax=3\n",
            "   \u001b[33m|->> #35-th Action selection: 5/2X UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [113  33  64  90]\n",
            "         |->> Action Probabilities (Rounded): [0.0944 0.0921 0.0831 0.0941 0.0931 0.0919 0.094  0.0941 0.0937 0.0815\n",
            " 0.088 ], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09443029 0.09210259 0.08313201 0.09414267 0.09307659 0.09187222\n",
            " 0.09400687 0.09409794 0.09368402 0.08150166 0.08795317], argmax=0\n",
            "|->> Revisiting bbox: [113  37  64  90]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [111,  37,  64,  90] -> [113,  33,  64,  90] (Target was [111,  61,  79,  93])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for RIGHT:bbox transition: [111,  37,  64,  90] -> [112,  37,  64,  90] w/ P(a|s)=0.08790909498929977 and iou=0.4755150287065181 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for RIGHT:bbox transition: [112,  37,  64,  90] -> [113,  37,  64,  90] w/ P(a|s)=0.08406610786914825 and iou=0.4755150287065181 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for 2X UP:bbox transition: [113,  37,  64,  90] -> [113,  33,  64,  90] w/ P(a|s)=0.09187222272157669 and iou=0.4341831710252763 and reward=-1.0 and discount=0.9801\n",
            "   |->> Assigned losses: [-2.431452  -2.4513903 -2.339848 ]\n",
            "\u001b[31m>> Total frame loss: -7.222690105438232\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 37 with src: [113,  33,  64,  90] and target: [110,  58,  75,  98]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0037.jpg\n",
            "|->> Beginning tracking for bbox:[113  33  64  90]\n",
            "   \u001b[33m|->> #36-th Action selection: 3/2X RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [115  33  64  90]\n",
            "         |->> Action Probabilities (Rounded): [0.089  0.0923 0.0912 0.0923 0.0929 0.09   0.0941 0.0934 0.094  0.0821\n",
            " 0.0887], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08903762 0.09226937 0.09115997 0.09232822 0.09292035 0.08997139\n",
            " 0.09405526 0.0934089  0.09400918 0.08214402 0.08869572], argmax=6\n",
            "   \u001b[33m|->> #37-th Action selection: 7/2X DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [115  37  64  90]\n",
            "         |->> Action Probabilities (Rounded): [0.0931 0.0924 0.0884 0.0903 0.0923 0.0908 0.0938 0.0938 0.0929 0.083\n",
            " 0.0891], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09308155 0.09236148 0.0884095  0.09032121 0.09232343 0.09082622\n",
            " 0.09380025 0.09383477 0.09286346 0.08304933 0.08912878], argmax=7\n",
            "   \u001b[33m|->> #38-th Action selection: 7/2X DOWN (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [115  41  64  90]\n",
            "         |->> Action Probabilities (Rounded): [0.0917 0.092  0.0898 0.091  0.0922 0.0909 0.0939 0.0932 0.0928 0.0839\n",
            " 0.0887], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09168371 0.09195131 0.0898088  0.0909804  0.09224632 0.09088811\n",
            " 0.09385604 0.09318104 0.09278547 0.0839292  0.0886896 ], argmax=6\n",
            "   \u001b[33m|->> #39-th Action selection: 7/2X DOWN (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [115  45  64  90]\n",
            "         |->> Action Probabilities (Rounded): [0.0916 0.0924 0.0895 0.0907 0.0924 0.091  0.0937 0.0916 0.094  0.0845\n",
            " 0.0887], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09161283 0.09242421 0.08945976 0.09070964 0.09239987 0.09102853\n",
            " 0.09371407 0.09155012 0.09395063 0.08449876 0.08865158], argmax=8\n",
            "   \u001b[33m|->> #40-th Action selection: 2/RIGHT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [116  45  64  90]\n",
            "         |->> Action Probabilities (Rounded): [0.0923 0.0919 0.0898 0.0908 0.0928 0.0906 0.0932 0.09   0.0938 0.0862\n",
            " 0.0886], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09230214 0.09194162 0.08975296 0.09078939 0.09278799 0.09058642\n",
            " 0.09323289 0.08999362 0.09375197 0.08622781 0.08863316], argmax=8\n",
            "   \u001b[33m|->> #41-th Action selection: 5/2X UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [116  41  64  90]\n",
            "         |->> Action Probabilities (Rounded): [0.0998 0.0919 0.0815 0.0915 0.0928 0.0922 0.093  0.0908 0.0935 0.085\n",
            " 0.088 ], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.0997775  0.09187587 0.08148334 0.09152134 0.09277742 0.0922431\n",
            " 0.09296884 0.09078408 0.09350544 0.0850208  0.08804218], argmax=0\n",
            "   \u001b[33m|->> #42-th Action selection: 6/DOWN (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [116  43  64  90]\n",
            "         |->> Action Probabilities (Rounded): [0.0881 0.0931 0.091  0.0905 0.0932 0.0905 0.0931 0.0903 0.0943 0.087\n",
            " 0.0889], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08806829 0.09311407 0.09100702 0.09045295 0.09319329 0.0905114\n",
            " 0.09306978 0.09034575 0.09432596 0.08697905 0.08893247], argmax=8\n",
            "   \u001b[33m|->> #43-th Action selection: 3/2X RIGHT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [118  43  64  90]\n",
            "         |->> Action Probabilities (Rounded): [0.0935 0.0928 0.0885 0.0904 0.0937 0.0904 0.0906 0.0902 0.0942 0.0881\n",
            " 0.0877], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09347388 0.09281973 0.08847953 0.09035058 0.09366675 0.09044298\n",
            " 0.09057916 0.09020916 0.09415467 0.08807983 0.08774374], argmax=8\n",
            "   \u001b[33m|->> #44-th Action selection: 5/2X UP (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [118  39  64  90]\n",
            "         |->> Action Probabilities (Rounded): [0.0917 0.0929 0.0902 0.089  0.0918 0.0905 0.092  0.0903 0.0941 0.0889\n",
            " 0.0887], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09167172 0.09287341 0.09015942 0.08900309 0.09178024 0.09046794\n",
            " 0.09198965 0.09034185 0.09406653 0.08894601 0.08870012], argmax=8\n",
            "   \u001b[33m|->> #45-th Action selection: 1/2X LEFT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [116  39  64  90]\n",
            "         |->> Action Probabilities (Rounded): [0.0924 0.0922 0.0883 0.0901 0.0926 0.089  0.0913 0.0905 0.0946 0.0897\n",
            " 0.0893], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0924415  0.09215555 0.08826806 0.09008401 0.09263504 0.0890018\n",
            " 0.09132924 0.09052117 0.09455518 0.08974234 0.08926606], argmax=8\n",
            "   \u001b[33m|->> #46-th Action selection: 2/RIGHT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [117  39  64  90]\n",
            "         |->> Action Probabilities (Rounded): [0.0907 0.0897 0.0898 0.0903 0.0922 0.0895 0.093  0.0907 0.0946 0.0898\n",
            " 0.0897], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09074689 0.08966891 0.08983211 0.09026902 0.09218519 0.08953675\n",
            " 0.09297983 0.09066796 0.09463707 0.08975583 0.08972044], argmax=8\n",
            "   \u001b[33m|->> #47-th Action selection: 10/SCALE UP (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [116  37  66  92]\n",
            "         |->> Action Probabilities (Rounded): [0.0978 0.0901 0.0824 0.0914 0.0929 0.0904 0.0926 0.0915 0.094  0.088\n",
            " 0.0889], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09778405 0.09006716 0.08241428 0.09139772 0.09290069 0.0904461\n",
            " 0.09259985 0.09151079 0.09399561 0.08798596 0.08889784], argmax=0\n",
            "   \u001b[33m|->> #48-th Action selection: 10/SCALE UP (P(a|s) = 0.08399999886751175)\u001b[0m\n",
            "      |->> Bounding box moves to: [115  35  68  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0877 0.091  0.0913 0.0907 0.0935 0.0912 0.0936 0.0928 0.0944 0.0902\n",
            " 0.0836], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08773743 0.09104354 0.09125051 0.09068146 0.09349892 0.09118512\n",
            " 0.0936316  0.09280531 0.09436092 0.09019287 0.08361229], argmax=8\n",
            "   \u001b[33m|->> #49-th Action selection: 0/LEFT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [113  35  68  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0917 0.091  0.0878 0.0917 0.0933 0.0918 0.0943 0.094  0.0944 0.0897\n",
            " 0.0803], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09173665 0.09099423 0.08778246 0.09172255 0.0932753  0.09179479\n",
            " 0.09426323 0.09400929 0.09441304 0.08967126 0.08033725], argmax=8\n",
            "|->> Revisiting bbox: [115  35  68  94]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [113,  33,  64,  90] -> [113,  35,  68,  94] (Target was [110,  58,  75,  98])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [113,  33,  64,  90] -> [115,  33,  64,  90] w/ P(a|s)=0.09232822060585022 and iou=0.464804469273743 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for 2X DOWN:bbox transition: [115,  33,  64,  90] -> [115,  37,  64,  90] w/ P(a|s)=0.0938347652554512 and iou=0.5079365079365079 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for 2X DOWN:bbox transition: [115,  37,  64,  90] -> [115,  41,  64,  90] w/ P(a|s)=0.09318104386329651 and iou=0.5536857075136288 and reward=-1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-1.0) for 2X DOWN:bbox transition: [115,  41,  64,  90] -> [115,  45,  64,  90] w/ P(a|s)=0.09155011922121048 and iou=0.6022977267171841 and reward=-1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-1.0) for RIGHT:bbox transition: [115,  45,  64,  90] -> [116,  45,  64,  90] w/ P(a|s)=0.08975295722484589 and iou=0.6022977267171841 and reward=-1.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-1.0) for 2X UP:bbox transition: [116,  45,  64,  90] -> [116,  41,  64,  90] w/ P(a|s)=0.09224309772253036 and iou=0.5536857075136288 and reward=-1.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (-1.0) for DOWN:bbox transition: [116,  41,  64,  90] -> [116,  43,  64,  90] w/ P(a|s)=0.09306977689266205 and iou=0.5776173285198556 and reward=-1.0 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [116,  43,  64,  90] -> [118,  43,  64,  90] w/ P(a|s)=0.09035058319568634 and iou=0.5776173285198556 and reward=-1.0 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (-1.0) for 2X UP:bbox transition: [118,  43,  64,  90] -> [118,  39,  64,  90] w/ P(a|s)=0.09046794474124908 and iou=0.5304692972215737 and reward=-1.0 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [118,  39,  64,  90] -> [116,  39,  64,  90] w/ P(a|s)=0.09215554594993591 and iou=0.5304692972215737 and reward=-1.0 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (-1.0) for RIGHT:bbox transition: [116,  39,  64,  90] -> [117,  39,  64,  90] w/ P(a|s)=0.0898321121931076 and iou=0.5304692972215737 and reward=-1.0 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (-1.0) for SCALE UP:bbox transition: [117,  39,  64,  90] -> [116,  37,  66,  92] w/ P(a|s)=0.08889783918857574 and iou=0.5364010989010989 and reward=-1.0 and discount=0.8953382542587164\n",
            "   |->> t=13 Diff-Reward (-1.0) for SCALE UP:bbox transition: [116,  37,  66,  92] -> [115,  35,  68,  94] w/ P(a|s)=0.08361228555440903 and iou=0.5416199237155037 and reward=-1.0 and discount=0.8863848717161292\n",
            "   |->> t=14 Diff-Reward (-1.0) for LEFT:bbox transition: [115,  35,  68,  94] -> [113,  35,  68,  94] w/ P(a|s)=0.09173665195703506 and iou=0.5416199237155037 and reward=-1.0 and discount=0.8775210229989678\n",
            "   |->> Assigned losses: [-2.3824055 -2.342558  -2.325984  -2.3198576 -2.3157034 -2.266521\n",
            " -2.235456  -2.2407389 -2.2171338 -2.1780784 -2.1793914 -2.166958\n",
            " -2.1996214 -2.0962515]\n",
            "\u001b[31m>> Total frame loss: -31.466659545898438\u001b[0m\n",
            "Final bounding box: [113  35  68  94] reached in 50 timesteps (originating from [120  51  73 101]). Target was [110  58  75  98]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 38 in t=50 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[31m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 10.913171768188477\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 4.716760158538818\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/FaceOcc2 with 802 frames\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Starting bounding box for adnet_datasets/OTB/FaceOcc2: frames 229:239 is [132  51  71  98].\n",
            "\u001b[34m>> Attempting to reach frame 230 with src: [132,  51,  71,  98] and target: [130,  51,  74,  97]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0230.jpg\n",
            "|->> Beginning tracking for bbox:[132  51  71  98]\n",
            "   \u001b[33m|->> #1-th Action selection: 4/UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [132  49  71  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0909 0.0908 0.091  0.0909 0.0909 0.0908 0.091  0.091  0.0912 0.0908\n",
            " 0.0909], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09088132 0.09078348 0.09096932 0.09092965 0.09091438 0.09079558\n",
            " 0.09095298 0.09095631 0.09115178 0.09079684 0.09086832], argmax=8\n",
            "   \u001b[33m|->> #2-th Action selection: 10/SCALE UP (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [130  47  73 100]\n",
            "         |->> Action Probabilities (Rounded): [0.0915 0.0909 0.0914 0.0912 0.0889 0.0909 0.0916 0.0913 0.0918 0.0901\n",
            " 0.0903], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09150619 0.09091338 0.09144098 0.09119102 0.08890816 0.09087653\n",
            " 0.0915701  0.09132639 0.09179567 0.09014457 0.09032705], argmax=8\n",
            "   \u001b[33m|->> #3-th Action selection: 10/SCALE UP (P(a|s) = 0.08500000089406967)\u001b[0m\n",
            "      |->> Bounding box moves to: [128  45  75 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0916 0.0913 0.0911 0.0916 0.0904 0.0912 0.091  0.0921 0.0924 0.0921\n",
            " 0.0852], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09162045 0.09130728 0.09109597 0.09163356 0.09037885 0.09123375\n",
            " 0.09095013 0.0921068  0.09242386 0.09206069 0.08518863], argmax=8\n",
            "   \u001b[33m|->> #4-th Action selection: 4/UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [128  42  75 103]\n",
            "         |->> Action Probabilities (Rounded): [0.091  0.0915 0.091  0.0921 0.091  0.0915 0.0921 0.0926 0.093  0.0919\n",
            " 0.0821], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09101794 0.09154981 0.09100249 0.0921462  0.09099652 0.0915346\n",
            " 0.09206928 0.09264591 0.09298485 0.09190809 0.08214433], argmax=8\n",
            "|->> Revisiting bbox: [128  42  75 103]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [132,  51,  71,  98] -> [128,  42,  75, 103] (Target was [130,  51,  74,  97])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for UP:bbox transition: [132,  51,  71,  98] -> [132,  49,  71,  98] w/ P(a|s)=0.09091438353061676 and iou=0.9311475409836065 and reward=1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for SCALE UP:bbox transition: [132,  49,  71,  98] -> [130,  47,  73, 100] w/ P(a|s)=0.09032705426216125 and iou=0.9381526104417671 and reward=1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (1.0) for SCALE UP:bbox transition: [130,  47,  73, 100] -> [128,  45,  75, 103] w/ P(a|s)=0.08518862724304199 and iou=0.9052671950907696 and reward=1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (1.0) for UP:bbox transition: [128,  45,  75, 103] -> [128,  42,  75, 103] w/ P(a|s)=0.09099651873111725 and iou=0.853376445715707 and reward=1.0 and discount=0.970299\n",
            "   |->> Assigned losses: [2.3978372 2.3802752 2.4138758 2.3257427]\n",
            "\u001b[92m>> Total frame loss: 9.517730712890625\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 231 with src: [128,  42,  75, 103] and target: [131,  51,  73,  99]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0231.jpg\n",
            "|->> Beginning tracking for bbox:[128  42  75 103]\n",
            "   \u001b[33m|->> #5-th Action selection: 2/RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [130  42  75 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0915 0.0915 0.0915 0.0924 0.0897 0.0915 0.0921 0.0927 0.0932 0.0905\n",
            " 0.0834], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09151632 0.09146084 0.0915456  0.0924444  0.08970507 0.09147011\n",
            " 0.09211771 0.09271    0.09315449 0.09050147 0.08337395], argmax=8\n",
            "   \u001b[33m|->> #6-th Action selection: 2/RIGHT (P(a|s) = 0.08299999684095383)\u001b[0m\n",
            "      |->> Bounding box moves to: [132  42  75 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0981 0.0914 0.0831 0.0927 0.0908 0.0923 0.0919 0.0933 0.0926 0.0901\n",
            " 0.0836], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09810293 0.09143816 0.08314057 0.09274107 0.09079153 0.09226746\n",
            " 0.09191982 0.09331559 0.09255606 0.09009332 0.08363349], argmax=0\n",
            "   \u001b[33m|->> #7-th Action selection: 7/2X DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [132  48  75 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0947 0.0924 0.0842 0.0921 0.0919 0.0926 0.0931 0.0939 0.092  0.089\n",
            " 0.0841], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09472091 0.09235092 0.08419322 0.0920677  0.09193578 0.09263739\n",
            " 0.09313943 0.09385724 0.09203342 0.08895697 0.084107  ], argmax=0\n",
            "   \u001b[33m|->> #8-th Action selection: 2/RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [134  48  75 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0901 0.0929 0.0906 0.0909 0.0925 0.0919 0.0929 0.0922 0.0923 0.0896\n",
            " 0.0843], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09007498 0.09285237 0.09055765 0.09089217 0.0925267  0.09185254\n",
            " 0.09287513 0.09216227 0.09226311 0.08959723 0.08434586], argmax=6\n",
            "   \u001b[33m|->> #9-th Action selection: 5/2X UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [134  42  75 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0994 0.0927 0.0804 0.092  0.0924 0.093  0.093  0.0929 0.092  0.0882\n",
            " 0.0841], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09941985 0.09266335 0.08043257 0.09199429 0.09240508 0.09296567\n",
            " 0.09295649 0.09288245 0.09198855 0.08823107 0.08406059], argmax=0\n",
            "   \u001b[33m|->> #10-th Action selection: 2/RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [136  42  75 103]\n",
            "         |->> Action Probabilities (Rounded): [0.089  0.0934 0.0915 0.0908 0.0933 0.0912 0.0933 0.0928 0.0915 0.0886\n",
            " 0.0847], argmax=1\n",
            "         |->> Action Probabilities (RAW): [0.0890298  0.09339987 0.09145094 0.0908175  0.09330571 0.09123933\n",
            " 0.09326707 0.09278955 0.09145919 0.08857025 0.0846708 ], argmax=1\n",
            "   \u001b[33m|->> #11-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [137  43  72  99]\n",
            "         |->> Action Probabilities (Rounded): [0.1001 0.0928 0.0804 0.0919 0.0923 0.0921 0.0941 0.0933 0.0922 0.087\n",
            " 0.0839], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.10014819 0.09276423 0.08038551 0.09189087 0.09226119 0.09212265\n",
            " 0.09409221 0.09331933 0.09218442 0.08696087 0.08387052], argmax=0\n",
            "   \u001b[33m|->> #12-th Action selection: 3/2X RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [141  43  72  99]\n",
            "         |->> Action Probabilities (Rounded): [0.088  0.0941 0.092  0.091  0.0938 0.0922 0.0942 0.0939 0.0927 0.0825\n",
            " 0.0856], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.0880319  0.09409808 0.09195028 0.09096101 0.09383629 0.09224081\n",
            " 0.09423392 0.09386699 0.09272471 0.08248805 0.08556794], argmax=6\n",
            "   \u001b[33m|->> #13-th Action selection: 7/2X DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [141  47  72  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0959 0.0938 0.0861 0.089  0.0931 0.0924 0.094  0.0938 0.0921 0.0843\n",
            " 0.0856], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09588079 0.09379422 0.08607966 0.08897747 0.09311613 0.09237912\n",
            " 0.09396272 0.09376067 0.09212507 0.08431648 0.08560769], argmax=0\n",
            "   \u001b[33m|->> #14-th Action selection: 1/2X LEFT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [137  47  72  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0912 0.0934 0.0896 0.0894 0.0927 0.0922 0.0939 0.0921 0.0931 0.084\n",
            " 0.0884], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09115748 0.09343031 0.08957796 0.08939407 0.09267917 0.09223583\n",
            " 0.09388152 0.09214717 0.09311903 0.08397453 0.08840299], argmax=6\n",
            "   \u001b[33m|->> #15-th Action selection: 7/2X DOWN (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [137  51  72  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0929 0.0909 0.0888 0.0892 0.0932 0.092  0.0939 0.0921 0.0936 0.0851\n",
            " 0.0883], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09287338 0.09093156 0.088777   0.08924641 0.09317423 0.09197233\n",
            " 0.09392883 0.09209333 0.09362636 0.08511568 0.08826091], argmax=6\n",
            "   \u001b[33m|->> #16-th Action selection: 0/LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [135  51  72  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0906 0.0904 0.09   0.0899 0.0934 0.0919 0.0938 0.0906 0.0946 0.0859\n",
            " 0.089 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09055959 0.09036022 0.0900125  0.08994165 0.09335717 0.09185904\n",
            " 0.09379721 0.09063394 0.09458926 0.08586954 0.08901981], argmax=8\n",
            "   \u001b[33m|->> #17-th Action selection: 3/2X RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [139  51  72  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0838 0.0911 0.0957 0.0914 0.0933 0.0925 0.0936 0.0919 0.0939 0.0844\n",
            " 0.0884], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08376673 0.09106373 0.09570713 0.09142716 0.09331082 0.09254341\n",
            " 0.0935922  0.09185162 0.09387557 0.08443204 0.08842955], argmax=2\n",
            "|->> Revisiting bbox: [135  51  72  99]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [128,  42,  75, 103] -> [139,  51,  72,  99] (Target was [131,  51,  73,  99])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for RIGHT:bbox transition: [128,  42,  75, 103] -> [130,  42,  75, 103] w/ P(a|s)=0.09154559671878815 and iou=0.8482076637824475 and reward=1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for RIGHT:bbox transition: [130,  42,  75, 103] -> [132,  42,  75, 103] w/ P(a|s)=0.08314056694507599 and iou=0.8269794721407625 and reward=1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (1.0) for 2X DOWN:bbox transition: [132,  42,  75, 103] -> [132,  48,  75, 103] w/ P(a|s)=0.09385723620653152 and iou=0.911042944785276 and reward=1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (1.0) for RIGHT:bbox transition: [132,  48,  75, 103] -> [134,  48,  75, 103] w/ P(a|s)=0.09055764973163605 and iou=0.8638743455497382 and reward=1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (1.0) for 2X UP:bbox transition: [134,  48,  75, 103] -> [134,  42,  75, 103] w/ P(a|s)=0.09296566992998123 and iou=0.7859531772575251 and reward=1.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (1.0) for RIGHT:bbox transition: [134,  42,  75, 103] -> [136,  42,  75, 103] w/ P(a|s)=0.09145094454288483 and iou=0.7467289719626168 and reward=1.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (1.0) for SCALE DOWN:bbox transition: [136,  42,  75, 103] -> [137,  43,  72,  99] w/ P(a|s)=0.08696086704730988 and iou=0.7383143618309518 and reward=1.0 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (1.0) for 2X RIGHT:bbox transition: [137,  43,  72,  99] -> [141,  43,  72,  99] w/ P(a|s)=0.09096100926399231 and iou=0.6649269311064718 and reward=1.0 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (1.0) for 2X DOWN:bbox transition: [141,  43,  72,  99] -> [141,  47,  72,  99] w/ P(a|s)=0.0937606692314148 and iou=0.7150537634408602 and reward=1.0 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (1.0) for 2X LEFT:bbox transition: [141,  47,  72,  99] -> [137,  47,  72,  99] w/ P(a|s)=0.09343031048774719 and iou=0.7966207759699625 and reward=1.0 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (1.0) for 2X DOWN:bbox transition: [137,  47,  72,  99] -> [137,  51,  72,  99] w/ P(a|s)=0.092093326151371 and iou=0.8589743589743589 and reward=1.0 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (1.0) for LEFT:bbox transition: [137,  51,  72,  99] -> [135,  51,  72,  99] w/ P(a|s)=0.09055959433317184 and iou=0.9078947368421053 and reward=1.0 and discount=0.8953382542587164\n",
            "   |->> t=13 Diff-Reward (1.0) for 2X RIGHT:bbox transition: [135,  51,  72,  99] -> [139,  51,  72,  99] w/ P(a|s)=0.09142716228961945 and iou=0.8125 and reward=1.0 and discount=0.8863848717161292\n",
            "   |->> Assigned losses: [2.390918  2.4623501 2.3188972 2.3304338 2.28192   2.274723  2.299374\n",
            " 2.234463  2.1841457 2.1655285 2.1569085 2.150376  2.120421 ]\n",
            "\u001b[92m>> Total frame loss: 29.370460510253906\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 232 with src: [139,  51,  72,  99] and target: [130,  50,  75,  97]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0232.jpg\n",
            "|->> Beginning tracking for bbox:[139  51  72  99]\n",
            "   \u001b[33m|->> #18-th Action selection: 6/DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [139  53  72  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0923 0.0903 0.0867 0.0902 0.0933 0.0926 0.0939 0.0924 0.0938 0.0854\n",
            " 0.0891], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09231524 0.09026615 0.0866921  0.09023398 0.09332688 0.09262238\n",
            " 0.09388682 0.0923689  0.09377164 0.08541472 0.08910125], argmax=6\n",
            "   \u001b[33m|->> #19-th Action selection: 9/SCALE DOWN (P(a|s) = 0.0860000029206276)\u001b[0m\n",
            "      |->> Bounding box moves to: [140  54  69  96]\n",
            "         |->> Action Probabilities (Rounded): [0.0882 0.0903 0.0915 0.0904 0.0944 0.0926 0.0911 0.0928 0.0938 0.0864\n",
            " 0.0886], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.08816132 0.09025471 0.09147273 0.09042679 0.09443863 0.09264871\n",
            " 0.09109315 0.09278677 0.09379623 0.08635419 0.08856681], argmax=4\n",
            "   \u001b[33m|->> #20-th Action selection: 5/2X UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [140  50  69  96]\n",
            "         |->> Action Probabilities (Rounded): [0.0919 0.0903 0.089  0.091  0.0927 0.0933 0.0933 0.0925 0.0939 0.0818\n",
            " 0.0903], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0919062  0.09033905 0.08897026 0.09099104 0.09273114 0.0933382\n",
            " 0.09325559 0.09250747 0.09386384 0.081777   0.09032026], argmax=8\n",
            "|->> Revisiting bbox: [140  50  69  96]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [139,  51,  72,  99] -> [140,  50,  69,  96] (Target was [130,  50,  75,  97])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for DOWN:bbox transition: [139,  51,  72,  99] -> [139,  53,  72,  99] w/ P(a|s)=0.09388681501150131 and iou=0.7566776436150751 and reward=1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for SCALE DOWN:bbox transition: [139,  53,  72,  99] -> [140,  54,  69,  96] w/ P(a|s)=0.08635418862104416 and iou=0.7696715049656226 and reward=1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (1.0) for 2X UP:bbox transition: [140,  54,  69,  96] -> [140,  50,  69,  96] w/ P(a|s)=0.09333819895982742 and iou=0.8147277712495103 and reward=1.0 and discount=0.9801\n",
            "   |->> Assigned losses: [2.3656654 2.424805  2.3243322]\n",
            "\u001b[92m>> Total frame loss: 7.114802360534668\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 233 with src: [140,  50,  69,  96] and target: [130,  50,  74,  98]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0233.jpg\n",
            "|->> Beginning tracking for bbox:[140  50  69  96]\n",
            "   \u001b[33m|->> #21-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08399999886751175)\u001b[0m\n",
            "      |->> Bounding box moves to: [141  51  66  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0901 0.09   0.0896 0.0918 0.0938 0.0915 0.092  0.0926 0.0946 0.0843\n",
            " 0.0897], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09007207 0.08995642 0.08964663 0.09182859 0.09379394 0.09150915\n",
            " 0.09197578 0.09264658 0.0945816  0.08432098 0.08966824], argmax=8\n",
            "   \u001b[33m|->> #22-th Action selection: 10/SCALE UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [140  49  68  95]\n",
            "         |->> Action Probabilities (Rounded): [0.0905 0.0907 0.0899 0.0922 0.0929 0.0917 0.0935 0.0926 0.0938 0.0808\n",
            " 0.0916], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09048958 0.09065502 0.0898547  0.09220008 0.09290963 0.09167708\n",
            " 0.09350248 0.0925955  0.09375426 0.08075694 0.09160475], argmax=8\n",
            "   \u001b[33m|->> #23-th Action selection: 10/SCALE UP (P(a|s) = 0.08399999886751175)\u001b[0m\n",
            "      |->> Bounding box moves to: [138  47  70  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0899 0.0908 0.0897 0.0936 0.094  0.0919 0.0933 0.0935 0.0943 0.0847\n",
            " 0.0844], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08990487 0.09075256 0.0897377  0.09356466 0.09396844 0.09185842\n",
            " 0.09326374 0.09350953 0.09428324 0.08470914 0.08444769], argmax=8\n",
            "   \u001b[33m|->> #24-th Action selection: 7/2X DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [138  51  70  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0897 0.0908 0.0901 0.0936 0.0936 0.0923 0.0938 0.0941 0.0952 0.0846\n",
            " 0.0822], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08968873 0.09079297 0.09010806 0.09364586 0.09360819 0.0922894\n",
            " 0.09375603 0.09407802 0.09520456 0.08457939 0.08224874], argmax=8\n",
            "   \u001b[33m|->> #25-th Action selection: 4/UP (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [138  49  70  97]\n",
            "         |->> Action Probabilities (Rounded): [0.091  0.0913 0.0901 0.0935 0.0936 0.0918 0.0935 0.0925 0.0942 0.0849\n",
            " 0.0835], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09102648 0.09127421 0.09012191 0.09345645 0.09363081 0.0918388\n",
            " 0.0935288  0.09249891 0.09420901 0.08494357 0.08347104], argmax=8\n",
            "|->> Revisiting bbox: [138  51  70  97]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [140,  50,  69,  96] -> [138,  49,  70,  97] (Target was [130,  50,  74,  98])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for SCALE DOWN:bbox transition: [140,  50,  69,  96] -> [141,  51,  66,  93] w/ P(a|s)=0.08432097733020782 and iou=0.7779843314300889 and reward=1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for SCALE UP:bbox transition: [141,  51,  66,  93] -> [140,  49,  68,  95] w/ P(a|s)=0.09160474687814713 and iou=0.7817047817047817 and reward=1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (1.0) for SCALE UP:bbox transition: [140,  49,  68,  95] -> [138,  47,  70,  97] w/ P(a|s)=0.08444768935441971 and iou=0.7915284511354937 and reward=1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (1.0) for 2X DOWN:bbox transition: [138,  47,  70,  97] -> [138,  51,  70,  97] w/ P(a|s)=0.09407801926136017 and iou=0.837958115183246 and reward=1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (1.0) for UP:bbox transition: [138,  51,  70,  97] -> [138,  49,  70,  97] w/ P(a|s)=0.09363081306219101 and iou=0.8222164547106151 and reward=1.0 and discount=0.96059601\n",
            "   |->> Assigned losses: [2.4731245 2.3663695 2.4224377 2.2934287 2.2750716]\n",
            "\u001b[92m>> Total frame loss: 11.83043098449707\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 234 with src: [138,  49,  70,  97] and target: [129,  53,  77,  96]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0234.jpg\n",
            "|->> Beginning tracking for bbox:[138  49  70  97]\n",
            "   \u001b[33m|->> #26-th Action selection: 0/LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [136  49  70  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0913 0.0913 0.0901 0.0933 0.0912 0.0921 0.0941 0.093  0.0943 0.0856\n",
            " 0.0836], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09129244 0.09126143 0.09009472 0.09334381 0.09123681 0.09208082\n",
            " 0.09413815 0.0930214  0.09433275 0.08555894 0.08363879], argmax=8\n",
            "|->> Revisiting bbox: [138  49  70  97]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [138,  49,  70,  97] -> [136,  49,  70,  97] (Target was [129,  53,  77,  96])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for LEFT:bbox transition: [138,  49,  70,  97] -> [136,  49,  70,  97] w/ P(a|s)=0.09129244089126587 and iou=0.8485401459854015 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [2.3936872]\n",
            "\u001b[92m>> Total frame loss: 2.3936872482299805\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 235 with src: [136,  49,  70,  97] and target: [127,  51,  78,  95]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0235.jpg\n",
            "|->> Beginning tracking for bbox:[136  49  70  97]\n",
            "   \u001b[33m|->> #27-th Action selection: 1/2X LEFT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [132  49  70  97]\n",
            "         |->> Action Probabilities (Rounded): [0.083  0.0924 0.0957 0.0936 0.0925 0.0926 0.093  0.0935 0.094  0.0847\n",
            " 0.0849], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08297451 0.09242199 0.09566615 0.09358542 0.09253587 0.09263204\n",
            " 0.09301097 0.09352682 0.09398679 0.08471473 0.08494482], argmax=2\n",
            "   \u001b[33m|->> #28-th Action selection: 4/UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [132  47  70  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0902 0.0895 0.0882 0.0943 0.0926 0.0919 0.0943 0.0936 0.0937 0.0861\n",
            " 0.0856], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09015373 0.08950584 0.08822829 0.0943122  0.09262104 0.09186942\n",
            " 0.0942934  0.09358595 0.0937134  0.08608171 0.08563508], argmax=3\n",
            "   \u001b[33m|->> #29-th Action selection: 3/2X RIGHT (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [136  47  70  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0874 0.0896 0.093  0.0937 0.0913 0.0921 0.0941 0.0941 0.0936 0.0855\n",
            " 0.0855], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08735989 0.08961789 0.09303635 0.09371889 0.09126241 0.09214588\n",
            " 0.09407891 0.09412219 0.0936418  0.08552723 0.08548862], argmax=7\n",
            "|->> Revisiting bbox: [136  47  70  97]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [136,  49,  70,  97] -> [136,  47,  70,  97] (Target was [127,  51,  78,  95])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for 2X LEFT:bbox transition: [136,  49,  70,  97] -> [132,  49,  70,  97] w/ P(a|s)=0.0924219861626625 and iou=0.8807947019867549 and reward=1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for UP:bbox transition: [132,  49,  70,  97] -> [132,  47,  70,  97] w/ P(a|s)=0.09262104332447052 and iou=0.846553966189857 and reward=1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (1.0) for 2X RIGHT:bbox transition: [132,  47,  70,  97] -> [136,  47,  70,  97] w/ P(a|s)=0.09371889382600784 and iou=0.824489271489143 and reward=1.0 and discount=0.9801\n",
            "   |->> Assigned losses: [2.3813903 2.3554466 2.320343 ]\n",
            "\u001b[92m>> Total frame loss: 7.057179927825928\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 236 with src: [136,  47,  70,  97] and target: [128,  52,  75,  94]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0236.jpg\n",
            "|->> Beginning tracking for bbox:[136  47  70  97]\n",
            "   \u001b[33m|->> #30-th Action selection: 0/LEFT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [134  47  70  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0915 0.0895 0.0889 0.0918 0.0922 0.0918 0.0931 0.0941 0.093  0.088\n",
            " 0.0861], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09154643 0.08946795 0.0889166  0.09176167 0.09222332 0.09178244\n",
            " 0.09312068 0.09405921 0.0929762  0.08803747 0.08610805], argmax=7\n",
            "   \u001b[33m|->> #31-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08500000089406967)\u001b[0m\n",
            "      |->> Bounding box moves to: [135  48  67  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0826 0.0895 0.0961 0.0931 0.0928 0.0933 0.0942 0.0949 0.0927 0.0849\n",
            " 0.0858], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08258948 0.08949891 0.09608731 0.09310529 0.09278113 0.09334819\n",
            " 0.09424389 0.09493792 0.0926696  0.08494497 0.08579326], argmax=2\n",
            "   \u001b[33m|->> #32-th Action selection: 5/2X UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [135  44  67  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0921 0.0894 0.0877 0.0933 0.093  0.093  0.0945 0.0949 0.0927 0.0824\n",
            " 0.0871], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09205189 0.08936241 0.08768994 0.09333163 0.09301034 0.09301555\n",
            " 0.09445059 0.0948609  0.09266594 0.08242884 0.08713192], argmax=7\n",
            "   \u001b[33m|->> #33-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08399999886751175)\u001b[0m\n",
            "      |->> Bounding box moves to: [136  45  64  91]\n",
            "         |->> Action Probabilities (Rounded): [0.0892 0.0894 0.092  0.0925 0.0932 0.0914 0.0939 0.0941 0.0927 0.0844\n",
            " 0.0872], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08919017 0.08937304 0.09200127 0.09252236 0.09315953 0.09142633\n",
            " 0.09394093 0.0941234  0.0926661  0.08435986 0.08723699], argmax=7\n",
            "   \u001b[33m|->> #34-th Action selection: 2/RIGHT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [137  45  64  91]\n",
            "         |->> Action Probabilities (Rounded): [0.0917 0.0897 0.0898 0.0933 0.0932 0.0914 0.0939 0.0946 0.0925 0.079\n",
            " 0.0907], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09174506 0.08970618 0.08975627 0.09329095 0.09324865 0.09144817\n",
            " 0.09394123 0.09461586 0.09251191 0.07900497 0.0907307 ], argmax=7\n",
            "   \u001b[33m|->> #35-th Action selection: 1/2X LEFT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [135  45  64  91]\n",
            "         |->> Action Probabilities (Rounded): [0.0979 0.0891 0.0832 0.094  0.092  0.0923 0.0944 0.0958 0.0927 0.0803\n",
            " 0.0883], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.0978682  0.08913755 0.08321533 0.0939841  0.09197973 0.09229432\n",
            " 0.09440752 0.09584387 0.09269749 0.08030268 0.08826915], argmax=0\n",
            "   \u001b[33m|->> #36-th Action selection: 7/2X DOWN (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [135  49  64  91]\n",
            "         |->> Action Probabilities (Rounded): [0.0885 0.0878 0.0923 0.0921 0.0932 0.0922 0.0947 0.0954 0.0934 0.0809\n",
            " 0.0896], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08854293 0.08779921 0.09232239 0.09207816 0.09316183 0.09215627\n",
            " 0.09472784 0.09536128 0.09336017 0.08093622 0.08955373], argmax=7\n",
            "   \u001b[33m|->> #37-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08299999684095383)\u001b[0m\n",
            "      |->> Bounding box moves to: [136  50  62  88]\n",
            "         |->> Action Probabilities (Rounded): [0.0921 0.0883 0.0887 0.0917 0.0931 0.0918 0.0945 0.0936 0.0936 0.0833\n",
            " 0.0893], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09210492 0.08833709 0.08866496 0.09173862 0.09305161 0.09180755\n",
            " 0.09453391 0.09359479 0.09355018 0.08328371 0.08933265], argmax=6\n",
            "   \u001b[33m|->> #38-th Action selection: 4/UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [136  48  62  88]\n",
            "         |->> Action Probabilities (Rounded): [0.0894 0.09   0.0908 0.0927 0.0931 0.0923 0.0941 0.094  0.0938 0.0794\n",
            " 0.0904], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.0893526  0.090013   0.09081475 0.09270751 0.09310126 0.09229339\n",
            " 0.09413284 0.09400996 0.09375274 0.07944943 0.09037255], argmax=6\n",
            "|->> Revisiting bbox: [136  50  62  88]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [136,  47,  70,  97] -> [136,  48,  62,  88] (Target was [128,  52,  75,  94])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for LEFT:bbox transition: [136,  47,  70,  97] -> [134,  47,  70,  97] w/ P(a|s)=0.091546431183815 and iou=0.8473037907100908 and reward=1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for SCALE DOWN:bbox transition: [134,  47,  70,  97] -> [135,  48,  67,  94] w/ P(a|s)=0.08494497090578079 and iou=0.8239956272205521 and reward=1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (1.0) for 2X UP:bbox transition: [135,  48,  67,  94] -> [135,  44,  67,  94] w/ P(a|s)=0.09301555156707764 and iou=0.7595570788294226 and reward=1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (1.0) for SCALE DOWN:bbox transition: [135,  44,  67,  94] -> [136,  45,  64,  91] w/ P(a|s)=0.08435986191034317 and iou=0.7169911976527074 and reward=1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (1.0) for RIGHT:bbox transition: [136,  45,  64,  91] -> [137,  45,  64,  91] w/ P(a|s)=0.08975627273321152 and iou=0.7169911976527074 and reward=1.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (1.0) for 2X LEFT:bbox transition: [137,  45,  64,  91] -> [135,  45,  64,  91] w/ P(a|s)=0.08913754671812057 and iou=0.7169911976527074 and reward=1.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (1.0) for 2X DOWN:bbox transition: [135,  45,  64,  91] -> [135,  49,  64,  91] w/ P(a|s)=0.09536128491163254 and iou=0.7776857221761945 and reward=1.0 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (1.0) for SCALE DOWN:bbox transition: [135,  49,  64,  91] -> [136,  50,  62,  88] w/ P(a|s)=0.08328371495008469 and iou=0.7432394758851408 and reward=1.0 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (1.0) for UP:bbox transition: [136,  50,  62,  88] -> [136,  48,  62,  88] w/ P(a|s)=0.09310125559568405 and iou=0.7136201699095642 and reward=1.0 and discount=0.9227446944279201\n",
            "   |->> Assigned losses: [2.390909  2.4410942 2.3277261 2.399223  2.3156679 2.2990894 2.2125561\n",
            " 2.3166506 2.1906583]\n",
            "\u001b[92m>> Total frame loss: 20.89357566833496\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 237 with src: [136,  48,  62,  88] and target: [131,  50,  72,  97]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0237.jpg\n",
            "|->> Beginning tracking for bbox:[136  48  62  88]\n",
            "   \u001b[33m|->> #39-th Action selection: 6/DOWN (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [136  50  62  88]\n",
            "         |->> Action Probabilities (Rounded): [0.0929 0.0899 0.0894 0.0929 0.0907 0.0923 0.0948 0.0938 0.0935 0.0811\n",
            " 0.0888], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09291412 0.08992237 0.0893617  0.09289812 0.09065741 0.09229265\n",
            " 0.09477371 0.09377703 0.09351933 0.08105707 0.08882648], argmax=6\n",
            "|->> Revisiting bbox: [136  50  62  88]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [136,  48,  62,  88] -> [136,  50,  62,  88] (Target was [131,  50,  72,  97])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for DOWN:bbox transition: [136,  48,  62,  88] -> [136,  50,  62,  88] w/ P(a|s)=0.09477370977401733 and iou=0.7812142038946163 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [2.3562632]\n",
            "\u001b[92m>> Total frame loss: 2.3562631607055664\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 238 with src: [136,  50,  62,  88] and target: [128,  49,  76,  99]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0238.jpg\n",
            "|->> Beginning tracking for bbox:[136  50  62  88]\n",
            "   \u001b[33m|->> #40-th Action selection: 0/LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [135  50  62  88]\n",
            "         |->> Action Probabilities (Rounded): [0.0906 0.0903 0.0913 0.0934 0.0929 0.0918 0.0915 0.0939 0.0942 0.081\n",
            " 0.0891], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09063835 0.09026694 0.09132773 0.0934342  0.09286875 0.091812\n",
            " 0.091461   0.09390201 0.09418645 0.08100619 0.0890964 ], argmax=8\n",
            "   \u001b[33m|->> #41-th Action selection: 3/2X RIGHT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [137  50  62  88]\n",
            "         |->> Action Probabilities (Rounded): [0.0831 0.0914 0.0974 0.0932 0.0917 0.0923 0.0936 0.0938 0.0934 0.0809\n",
            " 0.0891], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08309074 0.09141359 0.09744482 0.09322301 0.09169824 0.09232937\n",
            " 0.09355997 0.09382982 0.09343343 0.08089396 0.089083  ], argmax=2\n",
            "   \u001b[33m|->> #42-th Action selection: 10/SCALE UP (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [136  48  64  90]\n",
            "         |->> Action Probabilities (Rounded): [0.0919 0.0909 0.0874 0.0917 0.0932 0.0924 0.092  0.0937 0.0936 0.0838\n",
            " 0.0894], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09190444 0.09089212 0.08738111 0.09172013 0.09315328 0.09242724\n",
            " 0.09204442 0.09374323 0.09355944 0.08376887 0.08940569], argmax=7\n",
            "   \u001b[33m|->> #43-th Action selection: 0/LEFT (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [135  48  64  90]\n",
            "         |->> Action Probabilities (Rounded): [0.0878 0.0912 0.0913 0.0919 0.0931 0.0939 0.0937 0.0943 0.0931 0.0858\n",
            " 0.0839], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08776762 0.09115362 0.09131499 0.09189014 0.09314718 0.09392647\n",
            " 0.09371153 0.09433106 0.09312785 0.08577229 0.0838572 ], argmax=7\n",
            "   \u001b[33m|->> #44-th Action selection: 5/2X UP (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [135  44  64  90]\n",
            "         |->> Action Probabilities (Rounded): [0.0841 0.0908 0.0954 0.0925 0.0938 0.0939 0.0935 0.0945 0.0931 0.0832\n",
            " 0.0851], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08408854 0.09084777 0.09539057 0.09252554 0.09378412 0.093919\n",
            " 0.09353589 0.09454355 0.09305879 0.08319721 0.08510903], argmax=2\n",
            "   \u001b[33m|->> #45-th Action selection: 3/2X RIGHT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [137  44  64  90]\n",
            "         |->> Action Probabilities (Rounded): [0.0913 0.0894 0.0886 0.0933 0.0931 0.0917 0.0937 0.0937 0.0933 0.0858\n",
            " 0.086 ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09127627 0.08941318 0.08864307 0.09328904 0.09311718 0.09168097\n",
            " 0.09366729 0.09372851 0.0933499  0.08581951 0.08601507], argmax=7\n",
            "   \u001b[33m|->> #46-th Action selection: 4/UP (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [137  42  64  90]\n",
            "         |->> Action Probabilities (Rounded): [0.0899 0.0913 0.0909 0.0904 0.0936 0.0921 0.0935 0.0938 0.0918 0.086\n",
            " 0.0868], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08985531 0.09130303 0.09094352 0.09041384 0.09361529 0.09210366\n",
            " 0.09346598 0.09380271 0.09175437 0.08599221 0.08675016], argmax=7\n",
            "   \u001b[33m|->> #47-th Action selection: 9/SCALE DOWN (P(a|s) = 0.0860000029206276)\u001b[0m\n",
            "      |->> Bounding box moves to: [138  43  62  87]\n",
            "         |->> Action Probabilities (Rounded): [0.0927 0.0902 0.0885 0.0919 0.091  0.0922 0.0943 0.0947 0.092  0.0858\n",
            " 0.0867], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09273517 0.09019663 0.08853333 0.09186504 0.0910214  0.09220186\n",
            " 0.09428778 0.09474128 0.09198449 0.08575493 0.08667815], argmax=7\n",
            "   \u001b[33m|->> #48-th Action selection: 6/DOWN (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [138  45  62  87]\n",
            "         |->> Action Probabilities (Rounded): [0.0915 0.0912 0.0904 0.0916 0.0919 0.0921 0.0931 0.0951 0.0932 0.0825\n",
            " 0.0875], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09150881 0.0911945  0.09039864 0.09161825 0.09186713 0.09214582\n",
            " 0.09309042 0.09505093 0.09318829 0.08245264 0.08748458], argmax=7\n",
            "   \u001b[33m|->> #49-th Action selection: 2/RIGHT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [139  45  62  87]\n",
            "         |->> Action Probabilities (Rounded): [0.0935 0.0907 0.0895 0.0918 0.093  0.0921 0.0919 0.0949 0.092  0.0844\n",
            " 0.0863], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09351853 0.09074083 0.08945393 0.09176338 0.0929832  0.09205131\n",
            " 0.09188286 0.09486292 0.09204472 0.08441845 0.0862799 ], argmax=7\n",
            "|->> Revisiting bbox: [138  45  62  87]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [136,  50,  62,  88] -> [139,  45,  62,  87] (Target was [128,  49,  76,  99])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for LEFT:bbox transition: [136,  50,  62,  88] -> [135,  50,  62,  88] w/ P(a|s)=0.09063834697008133 and iou=0.7251461988304093 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [135,  50,  62,  88] -> [137,  50,  62,  88] w/ P(a|s)=0.09322300553321838 and iou=0.7251461988304093 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for SCALE UP:bbox transition: [137,  50,  62,  88] -> [136,  48,  64,  90] w/ P(a|s)=0.08940568566322327 and iou=0.7506589351607802 and reward=-1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-1.0) for LEFT:bbox transition: [136,  48,  64,  90] -> [135,  48,  64,  90] w/ P(a|s)=0.08776762336492538 and iou=0.7506589351607802 and reward=-1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-1.0) for 2X UP:bbox transition: [135,  48,  64,  90] -> [135,  44,  64,  90] w/ P(a|s)=0.09391900151968002 and iou=0.6935237123916369 and reward=-1.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [135,  44,  64,  90] -> [137,  44,  64,  90] w/ P(a|s)=0.09328904002904892 and iou=0.6935237123916369 and reward=-1.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (-1.0) for UP:bbox transition: [137,  44,  64,  90] -> [137,  42,  64,  90] w/ P(a|s)=0.09361528605222702 and iou=0.6663321625689914 and reward=-1.0 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [137,  42,  64,  90] -> [138,  43,  62,  87] w/ P(a|s)=0.08575493097305298 and iou=0.6360182370820668 and reward=-1.0 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (-1.0) for DOWN:bbox transition: [138,  43,  62,  87] -> [138,  45,  62,  87] w/ P(a|s)=0.09309042245149612 and iou=0.6621204323211528 and reward=-1.0 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (-1.0) for RIGHT:bbox transition: [138,  45,  62,  87] -> [139,  45,  62,  87] w/ P(a|s)=0.08945392817258835 and iou=0.6621204323211528 and reward=-1.0 and discount=0.9135172474836408\n",
            "   |->> Assigned losses: [-2.400878  -2.349033  -2.3665211 -2.3607981 -2.2721195 -2.2557983\n",
            " -2.2299538 -2.2893963 -2.1907656 -2.2052593]\n",
            "\u001b[31m>> Total frame loss: -22.920522689819336\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 239 with src: [139,  45,  62,  87] and target: [130,  50,  74,  96]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0239.jpg\n",
            "|->> Beginning tracking for bbox:[139  45  62  87]\n",
            "   \u001b[33m|->> #50-th Action selection: 10/SCALE UP (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [138  43  64  89]\n",
            "         |->> Action Probabilities (Rounded): [0.0998 0.0903 0.0821 0.0925 0.0916 0.093  0.0932 0.095  0.0928 0.0832\n",
            " 0.0866], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09979296 0.09028861 0.082073   0.09250715 0.091638   0.09297168\n",
            " 0.09320334 0.09498492 0.092793   0.08317192 0.08657541], argmax=0\n",
            "   \u001b[33m|->> #51-th Action selection: 6/DOWN (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [138  45  64  89]\n",
            "         |->> Action Probabilities (Rounded): [0.0886 0.0921 0.0903 0.0915 0.0941 0.0929 0.0925 0.0952 0.0936 0.0871\n",
            " 0.0822], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08861254 0.09207608 0.0902521  0.0914542  0.09405971 0.09289428\n",
            " 0.09254914 0.09517854 0.09362133 0.08714882 0.08215328], argmax=7\n",
            "|->> Revisiting bbox: [138  45  64  89]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [139,  45,  62,  87] -> [138,  45,  64,  89] (Target was [130,  50,  74,  96])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for SCALE UP:bbox transition: [139,  45,  62,  87] -> [138,  43,  64,  89] w/ P(a|s)=0.08657541126012802 and iou=0.6949152542372882 and reward=1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for DOWN:bbox transition: [138,  43,  64,  89] -> [138,  45,  64,  89] w/ P(a|s)=0.09254913777112961 and iou=0.7241379310344828 and reward=1.0 and discount=0.99\n",
            "   |->> Assigned losses: [2.4467394 2.3562155]\n",
            "\u001b[92m>> Total frame loss: 4.80295467376709\u001b[0m\n",
            "Final bounding box: [138  45  64  89] reached in 52 timesteps (originating from [132  51  71  98]). Target was [130  50  74  96]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 240 in t=52 timesteps ################\u001b[0m\n",
            "\n",
            "\u001b[36m####################### EPISODE # 2 ############################\u001b[0m\n",
            "Starting bounding box for adnet_datasets/OTB/FaceOcc2: frames 229:239 is [132  51  71  98].\n",
            "\u001b[34m>> Attempting to reach frame 230 with src: [132,  51,  71,  98] and target: [130,  51,  74,  97]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0230.jpg\n",
            "|->> Beginning tracking for bbox:[132  51  71  98]\n",
            "   \u001b[33m|->> #1-th Action selection: 7/2X DOWN (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [132  55  71  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0909 0.0908 0.091  0.0909 0.0909 0.0908 0.091  0.091  0.0912 0.0908\n",
            " 0.0909], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09088132 0.09078348 0.09096932 0.09092965 0.09091438 0.09079558\n",
            " 0.09095298 0.09095631 0.09115178 0.09079684 0.09086832], argmax=8\n",
            "   \u001b[33m|->> #2-th Action selection: 0/LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [130  55  71  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0909 0.0909 0.0914 0.0909 0.0911 0.0906 0.0909 0.0896 0.0918 0.091\n",
            " 0.091 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09087592 0.09086549 0.091373   0.09091669 0.09110439 0.09059694\n",
            " 0.09092281 0.08961236 0.0917993  0.09097342 0.09095968], argmax=8\n",
            "   \u001b[33m|->> #3-th Action selection: 1/2X LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [126  55  71  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0838 0.0913 0.0975 0.092  0.0912 0.0915 0.0913 0.0909 0.0923 0.0883\n",
            " 0.0901], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08376386 0.09128765 0.09746324 0.09200188 0.09117319 0.09151185\n",
            " 0.09126288 0.09089907 0.09228761 0.08827877 0.09006999], argmax=2\n",
            "   \u001b[33m|->> #4-th Action selection: 5/2X UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [126  51  71  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0921 0.088  0.0895 0.0923 0.0916 0.0914 0.0915 0.091  0.0926 0.0891\n",
            " 0.0906], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09206049 0.0880476  0.08952828 0.09234342 0.09164947 0.09142363\n",
            " 0.0915435  0.09100757 0.09263558 0.08911437 0.09064605], argmax=8\n",
            "   \u001b[33m|->> #5-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [127  52  68  95]\n",
            "         |->> Action Probabilities (Rounded): [0.0886 0.0883 0.0941 0.0916 0.0915 0.0902 0.0919 0.0915 0.0929 0.0889\n",
            " 0.0902], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08862457 0.08834981 0.09409612 0.09164535 0.09153067 0.09023812\n",
            " 0.09194009 0.09153615 0.09291489 0.08889323 0.09023096], argmax=2\n",
            "   \u001b[33m|->> #6-th Action selection: 1/2X LEFT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [123  52  68  95]\n",
            "         |->> Action Probabilities (Rounded): [0.091  0.0886 0.0914 0.0931 0.0922 0.0906 0.0926 0.092  0.093  0.0841\n",
            " 0.0915], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09102352 0.08855908 0.09138558 0.09309522 0.09215349 0.09059314\n",
            " 0.09264228 0.09195302 0.09300206 0.08411305 0.09147953], argmax=3\n",
            "   \u001b[33m|->> #7-th Action selection: 5/2X UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [123  48  68  95]\n",
            "         |->> Action Probabilities (Rounded): [0.0899 0.0866 0.0927 0.0928 0.0921 0.0905 0.093  0.0926 0.0939 0.0857\n",
            " 0.0901], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08990391 0.08663683 0.09274307 0.09284538 0.0920563  0.09050081\n",
            " 0.09295908 0.09264469 0.09386065 0.0857209  0.09012841], argmax=8\n",
            "   \u001b[33m|->> #8-th Action selection: 10/SCALE UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [121  46  70  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0901 0.087  0.0921 0.0926 0.0919 0.0895 0.0936 0.0927 0.0941 0.0855\n",
            " 0.091 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09012964 0.08695856 0.09206695 0.09259852 0.0919093  0.08946536\n",
            " 0.09359732 0.09268665 0.09409373 0.08546706 0.09102686], argmax=8\n",
            "   \u001b[33m|->> #9-th Action selection: 6/DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [121  48  70  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0898 0.0876 0.0916 0.0936 0.0928 0.09   0.0938 0.0935 0.0941 0.0881\n",
            " 0.085 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08982704 0.08759851 0.09162331 0.09359872 0.0928009  0.09003711\n",
            " 0.09382276 0.0934792  0.09410278 0.08813832 0.08497137], argmax=8\n",
            "   \u001b[33m|->> #10-th Action selection: 10/SCALE UP (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [119  46  72  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0898 0.0881 0.0926 0.0937 0.0936 0.0902 0.0913 0.0934 0.0944 0.0862\n",
            " 0.0867], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08976466 0.08810601 0.09258386 0.09367085 0.09362216 0.0902269\n",
            " 0.09130645 0.09343653 0.09444221 0.08618206 0.08665828], argmax=8\n",
            "   \u001b[33m|->> #11-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [120  47  69  96]\n",
            "         |->> Action Probabilities (Rounded): [0.0901 0.0884 0.0915 0.0942 0.0923 0.0912 0.0937 0.0942 0.0945 0.0891\n",
            " 0.0809], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09014156 0.08841428 0.09145158 0.09415875 0.09230534 0.09124902\n",
            " 0.09367389 0.09419362 0.09446733 0.08906931 0.08087526], argmax=8\n",
            "   \u001b[33m|->> #12-th Action selection: 0/LEFT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [118  47  69  96]\n",
            "         |->> Action Probabilities (Rounded): [0.0889 0.0893 0.092  0.0943 0.0938 0.0917 0.0935 0.0949 0.0948 0.082\n",
            " 0.0848], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08894513 0.0892605  0.09201681 0.0942921  0.09375817 0.09167928\n",
            " 0.09350277 0.09491737 0.09480701 0.08197124 0.08484964], argmax=7\n",
            "|->> Revisiting bbox: [118  47  69  96]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [132,  51,  71,  98] -> [118,  47,  69,  96] (Target was [130,  51,  74,  97])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for 2X DOWN:bbox transition: [132,  51,  71,  98] -> [132,  55,  71,  98] w/ P(a|s)=0.09095630794763565 and iou=0.8765432098765432 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for LEFT:bbox transition: [132,  55,  71,  98] -> [130,  55,  71,  98] w/ P(a|s)=0.09087592363357544 and iou=0.8765432098765432 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [130,  55,  71,  98] -> [126,  55,  71,  98] w/ P(a|s)=0.09128765016794205 and iou=0.788235294117647 and reward=-1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-1.0) for 2X UP:bbox transition: [126,  55,  71,  98] -> [126,  51,  71,  98] w/ P(a|s)=0.0914236307144165 and iou=0.8509886080921828 and reward=-1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [126,  51,  71,  98] -> [127,  52,  68,  95] w/ P(a|s)=0.08889323472976685 and iou=0.8274152485595605 and reward=-1.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [127,  52,  68,  95] -> [123,  52,  68,  95] w/ P(a|s)=0.08855907618999481 and iou=0.7388754303200306 and reward=-1.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (-1.0) for 2X UP:bbox transition: [123,  52,  68,  95] -> [123,  48,  68,  95] w/ P(a|s)=0.09050080925226212 and iou=0.6992275105905806 and reward=-1.0 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (-1.0) for SCALE UP:bbox transition: [123,  48,  68,  95] -> [121,  46,  70,  97] w/ P(a|s)=0.09102686494588852 and iou=0.6716132120631881 and reward=-1.0 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (-1.0) for DOWN:bbox transition: [121,  46,  70,  97] -> [121,  48,  70,  97] w/ P(a|s)=0.09382276237010956 and iou=0.6963808598494049 and reward=-1.0 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (-1.0) for SCALE UP:bbox transition: [121,  48,  70,  97] -> [119,  46,  72,  99] w/ P(a|s)=0.08665827661752701 and iou=0.6689220718618759 and reward=-1.0 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [119,  46,  72,  99] -> [120,  47,  69,  96] w/ P(a|s)=0.08906931430101395 and iou=0.6481967996178648 and reward=-1.0 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (-1.0) for LEFT:bbox transition: [120,  47,  69,  96] -> [118,  47,  69,  96] w/ P(a|s)=0.08894512802362442 and iou=0.6127599906520215 and reward=-1.0 and discount=0.8953382542587164\n",
            "   |->> Assigned losses: [-2.397376  -2.3742776 -2.3461041 -2.321199  -2.324949  -2.305281\n",
            " -2.2618086 -2.2337885 -2.1835349 -2.2342646 -2.1871037 -2.166482 ]\n",
            "\u001b[31m>> Total frame loss: -27.336170196533203\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 231 with src: [118,  47,  69,  96] and target: [131,  51,  73,  99]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0231.jpg\n",
            "|->> Beginning tracking for bbox:[118  47  69  96]\n",
            "|->> Revisiting bbox: [118  47  69  96]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #13-th Action selection: 8/STOP (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [118  47  69  96]\n",
            "         |->> Action Probabilities (Rounded): [0.0813 0.0902 0.0975 0.0945 0.0931 0.0922 0.0943 0.0953 0.0944 0.0839\n",
            " 0.0835], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08133575 0.09015516 0.09746833 0.09445533 0.09306143 0.09215219\n",
            " 0.09425626 0.09526974 0.09436945 0.08392767 0.08354869], argmax=2\n",
            "         |->> Hit a STOP on the 13-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [118,  47,  69,  96] -> [118,  47,  69,  96] (Target was [131,  51,  73,  99])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [118,  47,  69,  96] -> [118,  47,  69,  96] w/ P(a|s)=0.09436944872140884 and iou=0.5922519829865501 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.360538]\n",
            "\u001b[31m>> Total frame loss: -2.3605380058288574\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 232 with src: [118,  47,  69,  96] and target: [130,  50,  75,  97]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0232.jpg\n",
            "|->> Beginning tracking for bbox:[118  47  69  96]\n",
            "   \u001b[33m|->> #13-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08299999684095383)\u001b[0m\n",
            "      |->> Bounding box moves to: [119  48  66  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0893 0.0902 0.0888 0.0939 0.0932 0.0919 0.0939 0.0946 0.095  0.0833\n",
            " 0.0858], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08927868 0.09021022 0.08879079 0.09388714 0.09321029 0.09193534\n",
            " 0.09390349 0.09463792 0.09495988 0.08334334 0.08584289], argmax=8\n",
            "   \u001b[33m|->> #14-th Action selection: 3/2X RIGHT (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [121  48  66  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0847 0.0907 0.092  0.0951 0.0933 0.0937 0.0939 0.0956 0.095  0.0793\n",
            " 0.0867], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08469845 0.09070993 0.0919954  0.09507047 0.09330104 0.0936759\n",
            " 0.09390151 0.09562428 0.09497737 0.07931863 0.08672699], argmax=7\n",
            "   \u001b[33m|->> #15-th Action selection: 6/DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [121  50  66  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0896 0.0907 0.0891 0.0925 0.0931 0.0932 0.0939 0.0952 0.094  0.0828\n",
            " 0.086 ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08963361 0.09071287 0.08910852 0.09246275 0.09313806 0.09315523\n",
            " 0.09387892 0.09517562 0.09395275 0.08276305 0.08601868], argmax=7\n",
            "|->> Revisiting bbox: [121  50  66  93]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [118,  47,  69,  96] -> [121,  50,  66,  93] (Target was [130,  50,  75,  97])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [118,  47,  69,  96] -> [119,  48,  66,  93] w/ P(a|s)=0.08334334194660187 and iou=0.5952664129400571 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [119,  48,  66,  93] -> [121,  48,  66,  93] w/ P(a|s)=0.09507046639919281 and iou=0.6305616338439095 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for DOWN:bbox transition: [121,  48,  66,  93] -> [121,  50,  66,  93] w/ P(a|s)=0.09387891739606857 and iou=0.6534763313609467 and reward=-1.0 and discount=0.9801\n",
            "   |->> Assigned losses: [-2.4847865 -2.3296056 -2.318671 ]\n",
            "\u001b[31m>> Total frame loss: -7.133063316345215\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 233 with src: [121,  50,  66,  93] and target: [130,  50,  74,  98]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0233.jpg\n",
            "|->> Beginning tracking for bbox:[121  50  66  93]\n",
            "   \u001b[33m|->> #16-th Action selection: 0/LEFT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [120  50  66  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0893 0.0914 0.0904 0.0933 0.0941 0.0934 0.0912 0.0949 0.0941 0.0819\n",
            " 0.086 ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.0892794  0.09141174 0.09038085 0.09329913 0.09414019 0.09337443\n",
            " 0.09119657 0.09492183 0.09405272 0.08191525 0.08602794], argmax=7\n",
            "   \u001b[33m|->> #17-th Action selection: 3/2X RIGHT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [122  50  66  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0827 0.0919 0.0965 0.0931 0.0924 0.0948 0.0932 0.0955 0.0937 0.0809\n",
            " 0.0854], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08272752 0.09185661 0.09653788 0.09306113 0.09239579 0.09478331\n",
            " 0.09316288 0.09547871 0.09368215 0.08094522 0.08536886], argmax=2\n",
            "   \u001b[33m|->> #18-th Action selection: 2/RIGHT (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [123  50  66  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0919 0.0913 0.0868 0.0914 0.0941 0.0945 0.0921 0.095  0.0931 0.0822\n",
            " 0.0876], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09193402 0.09131781 0.08678551 0.09136457 0.09413056 0.09454522\n",
            " 0.09214403 0.09495801 0.0930649  0.08218542 0.08756991], argmax=7\n",
            "|->> Revisiting bbox: [122  50  66  93]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [121,  50,  66,  93] -> [123,  50,  66,  93] (Target was [130,  50,  74,  98])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for LEFT:bbox transition: [121,  50,  66,  93] -> [120,  50,  66,  93] w/ P(a|s)=0.08927939832210541 and iou=0.6365191884624786 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [120,  50,  66,  93] -> [122,  50,  66,  93] w/ P(a|s)=0.09306112676858902 and iou=0.6745872936468235 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for RIGHT:bbox transition: [122,  50,  66,  93] -> [123,  50,  66,  93] w/ P(a|s)=0.08678551018238068 and iou=0.6942933063393648 and reward=-1.0 and discount=0.9801\n",
            "   |->> Assigned losses: [-2.4159846 -2.3507538 -2.3956738]\n",
            "\u001b[31m>> Total frame loss: -7.162412166595459\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 234 with src: [123,  50,  66,  93] and target: [129,  53,  77,  96]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0234.jpg\n",
            "|->> Beginning tracking for bbox:[123  50  66  93]\n",
            "   \u001b[33m|->> #19-th Action selection: 3/2X RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [125  50  66  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0954 0.0908 0.0833 0.0922 0.0931 0.0953 0.0934 0.0962 0.0923 0.0813\n",
            " 0.0867], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09539446 0.09077941 0.08334789 0.0922031  0.0930867  0.09528213\n",
            " 0.09338713 0.09619714 0.09229375 0.08134662 0.08668166], argmax=7\n",
            "   \u001b[33m|->> #20-th Action selection: 2/RIGHT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [126  50  66  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0906 0.0917 0.0892 0.0889 0.0938 0.0945 0.0936 0.0954 0.0916 0.0825\n",
            " 0.0883], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09062987 0.091732   0.08915994 0.08891101 0.09377846 0.09450526\n",
            " 0.09355395 0.09535863 0.09155898 0.08247188 0.08834003], argmax=7\n",
            "|->> Revisiting bbox: [125  50  66  93]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [123,  50,  66,  93] -> [126,  50,  66,  93] (Target was [129,  53,  77,  96])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for 2X RIGHT:bbox transition: [123,  50,  66,  93] -> [125,  50,  66,  93] w/ P(a|s)=0.09220309555530548 and iou=0.7018867924528301 and reward=1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for RIGHT:bbox transition: [125,  50,  66,  93] -> [126,  50,  66,  93] w/ P(a|s)=0.08915993571281433 and iou=0.7213740458015268 and reward=1.0 and discount=0.99\n",
            "   |->> Assigned losses: [2.3837616 2.3931503]\n",
            "\u001b[92m>> Total frame loss: 4.776911735534668\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 235 with src: [126,  50,  66,  93] and target: [127,  51,  78,  95]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0235.jpg\n",
            "|->> Beginning tracking for bbox:[126  50  66  93]\n",
            "   \u001b[33m|->> #21-th Action selection: 5/2X UP (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [126  46  66  93]\n",
            "         |->> Action Probabilities (Rounded): [0.1011 0.0903 0.0798 0.0901 0.0931 0.0952 0.0937 0.0956 0.0919 0.0821\n",
            " 0.0871], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.10113022 0.09034    0.07980634 0.09009048 0.09313829 0.09516633\n",
            " 0.09367727 0.09555491 0.0918597  0.08213632 0.08710017], argmax=0\n",
            "   \u001b[33m|->> #22-th Action selection: 1/2X LEFT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [124  46  66  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0901 0.0928 0.0903 0.0878 0.0939 0.093  0.0944 0.095  0.09   0.0847\n",
            " 0.0879], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.0901427  0.09283634 0.09033726 0.08783267 0.09388329 0.09296449\n",
            " 0.09440695 0.09501252 0.08998248 0.08466639 0.08793495], argmax=7\n",
            "   \u001b[33m|->> #23-th Action selection: 6/DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [124  48  66  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0939 0.089  0.0863 0.0893 0.0932 0.0927 0.094  0.0945 0.0925 0.0862\n",
            " 0.0883], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09392469 0.08903424 0.08628684 0.08932763 0.0932057  0.09267577\n",
            " 0.0940431  0.0945092  0.09252274 0.08616074 0.08830939], argmax=7\n",
            "   \u001b[33m|->> #24-th Action selection: 5/2X UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [124  44  66  93]\n",
            "         |->> Action Probabilities (Rounded): [0.092  0.0898 0.09   0.0886 0.0938 0.0924 0.0913 0.0948 0.0927 0.087\n",
            " 0.0876], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09199999 0.08984219 0.0899881  0.08856771 0.09380464 0.09240592\n",
            " 0.09128995 0.09479158 0.0926607  0.08700816 0.08764108], argmax=7\n",
            "   \u001b[33m|->> #25-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [125  45  64  90]\n",
            "         |->> Action Probabilities (Rounded): [0.0942 0.0893 0.0893 0.0902 0.0919 0.0906 0.0938 0.094  0.092  0.0871\n",
            " 0.0876], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09424647 0.0892824  0.08927254 0.09015723 0.09189724 0.09063274\n",
            " 0.09384213 0.0939737  0.09200005 0.08709905 0.08759644], argmax=0\n",
            "   \u001b[33m|->> #26-th Action selection: 6/DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [125  47  64  90]\n",
            "         |->> Action Probabilities (Rounded): [0.0922 0.0899 0.09   0.0906 0.0928 0.0911 0.0935 0.0946 0.094  0.0822\n",
            " 0.0891], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.0921646  0.08994549 0.09001169 0.09059227 0.09278404 0.09111802\n",
            " 0.09350804 0.09463111 0.09397571 0.08220206 0.08906697], argmax=7\n",
            "   \u001b[33m|->> #27-th Action selection: 1/2X LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [123  47  64  90]\n",
            "         |->> Action Probabilities (Rounded): [0.092  0.0907 0.0904 0.0905 0.0934 0.0909 0.0916 0.094  0.0933 0.0854\n",
            " 0.0879], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09195865 0.09066164 0.09035747 0.09048966 0.09338837 0.09086391\n",
            " 0.09157804 0.0940041  0.09333079 0.08542025 0.08794713], argmax=7\n",
            "   \u001b[33m|->> #28-th Action selection: 5/2X UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [123  43  64  90]\n",
            "         |->> Action Probabilities (Rounded): [0.0909 0.0884 0.0911 0.0909 0.0923 0.0911 0.0933 0.0936 0.094  0.0852\n",
            " 0.0892], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09086259 0.08838952 0.09111146 0.09090443 0.09231689 0.09110514\n",
            " 0.093349   0.09359226 0.09402496 0.08516887 0.0891749 ], argmax=8\n",
            "   \u001b[33m|->> #29-th Action selection: 10/SCALE UP (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [122  41  66  92]\n",
            "         |->> Action Probabilities (Rounded): [0.0896 0.0884 0.0911 0.0915 0.0926 0.0896 0.0929 0.0934 0.0948 0.0865\n",
            " 0.0897], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08961211 0.08841338 0.09111338 0.09149549 0.09257066 0.08955413\n",
            " 0.09285404 0.09336638 0.09482062 0.08650068 0.0896991 ], argmax=8\n",
            "   \u001b[33m|->> #30-th Action selection: 7/2X DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [122  45  66  92]\n",
            "         |->> Action Probabilities (Rounded): [0.0885 0.089  0.0921 0.0929 0.093  0.0899 0.0943 0.0937 0.0943 0.0882\n",
            " 0.0842], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08848117 0.0889888  0.09212561 0.09288818 0.09302469 0.08994848\n",
            " 0.09425041 0.09366165 0.09429409 0.08815213 0.08418476], argmax=8\n",
            "   \u001b[33m|->> #31-th Action selection: 6/DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [122  47  66  92]\n",
            "         |->> Action Probabilities (Rounded): [0.0882 0.0893 0.0924 0.0932 0.093  0.0895 0.0936 0.0917 0.0947 0.0875\n",
            " 0.087 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08817817 0.08929724 0.09237643 0.0931728  0.09296757 0.08952551\n",
            " 0.09356568 0.09172425 0.0946953  0.08754186 0.08695523], argmax=8\n",
            "   \u001b[33m|->> #32-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [123  48  64  89]\n",
            "         |->> Action Probabilities (Rounded): [0.0881 0.0896 0.0914 0.0933 0.0943 0.0903 0.0913 0.092  0.0945 0.0889\n",
            " 0.0862], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08813909 0.08963737 0.09143323 0.09331452 0.09427568 0.09030861\n",
            " 0.09130292 0.09200253 0.09450025 0.08889918 0.0861866 ], argmax=8\n",
            "   \u001b[33m|->> #33-th Action selection: 0/LEFT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [122  48  64  89]\n",
            "         |->> Action Probabilities (Rounded): [0.0887 0.0913 0.0917 0.0935 0.093  0.0907 0.0933 0.092  0.094  0.0835\n",
            " 0.0883], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08872416 0.09125837 0.09171111 0.09350479 0.09298747 0.09066847\n",
            " 0.09332567 0.09202982 0.09398876 0.08345732 0.08834406], argmax=8\n",
            "   \u001b[33m|->> #34-th Action selection: 7/2X DOWN (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [122  52  64  89]\n",
            "         |->> Action Probabilities (Rounded): [0.0818 0.0912 0.0975 0.0944 0.0933 0.0918 0.0922 0.0932 0.0946 0.0833\n",
            " 0.0867], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08175422 0.09123211 0.09753247 0.09443039 0.09326251 0.0917751\n",
            " 0.09220918 0.09316211 0.09457242 0.08332266 0.0867468 ], argmax=2\n",
            "   \u001b[33m|->> #35-th Action selection: 7/2X DOWN (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [122  56  64  89]\n",
            "         |->> Action Probabilities (Rounded): [0.0898 0.0908 0.0887 0.0943 0.0934 0.092  0.0931 0.0915 0.0938 0.0842\n",
            " 0.0885], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.08978113 0.0907588  0.08871879 0.09426942 0.0934419  0.09201589\n",
            " 0.09305554 0.09146905 0.09376837 0.08424749 0.08847361], argmax=3\n",
            "|->> Revisiting bbox: [122  52  64  89]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [126,  50,  66,  93] -> [122,  56,  64,  89] (Target was [127,  51,  78,  95])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for 2X UP:bbox transition: [126,  50,  66,  93] -> [126,  46,  66,  93] w/ P(a|s)=0.09516633301973343 and iou=0.7307102708226878 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [126,  46,  66,  93] -> [124,  46,  66,  93] w/ P(a|s)=0.09283634275197983 and iou=0.6926536731634183 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for DOWN:bbox transition: [124,  46,  66,  93] -> [124,  48,  66,  93] w/ P(a|s)=0.09404309839010239 and iou=0.7197258187357197 and reward=-1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-1.0) for 2X UP:bbox transition: [124,  48,  66,  93] -> [124,  44,  66,  93] w/ P(a|s)=0.09240591526031494 and iou=0.666420664206642 and reward=-1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [124,  44,  66,  93] -> [125,  45,  64,  90] w/ P(a|s)=0.08709905296564102 and iou=0.6541070082893745 and reward=-1.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-1.0) for DOWN:bbox transition: [125,  45,  64,  90] -> [125,  47,  64,  90] w/ P(a|s)=0.0935080423951149 and iou=0.680275580505231 and reward=-1.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [125,  47,  64,  90] -> [123,  47,  64,  90] w/ P(a|s)=0.09066163748502731 and iou=0.6441947565543071 and reward=-1.0 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (-1.0) for 2X UP:bbox transition: [123,  47,  64,  90] -> [123,  43,  64,  90] w/ P(a|s)=0.0911051407456398 and iou=0.5963636363636363 and reward=-1.0 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (-1.0) for SCALE UP:bbox transition: [123,  43,  64,  90] -> [122,  41,  66,  92] w/ P(a|s)=0.08969909697771072 and iou=0.5898584905660378 and reward=-1.0 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (-1.0) for 2X DOWN:bbox transition: [122,  41,  66,  92] -> [122,  45,  66,  92] w/ P(a|s)=0.09366165101528168 and iou=0.6369596891694997 and reward=-1.0 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (-1.0) for DOWN:bbox transition: [122,  45,  66,  92] -> [122,  47,  66,  92] w/ P(a|s)=0.0935656800866127 and iou=0.6615725905841755 and reward=-1.0 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [122,  47,  66,  92] -> [123,  48,  64,  89] w/ P(a|s)=0.08889918029308319 and iou=0.6493833375283161 and reward=-1.0 and discount=0.8953382542587164\n",
            "   |->> t=13 Diff-Reward (-1.0) for LEFT:bbox transition: [123,  48,  64,  89] -> [122,  48,  64,  89] w/ P(a|s)=0.08872415870428085 and iou=0.6317231075697212 and reward=-1.0 and discount=0.8863848717161292\n",
            "   |->> t=14 Diff-Reward (-1.0) for 2X DOWN:bbox transition: [122,  48,  64,  89] -> [122,  52,  64,  89] w/ P(a|s)=0.09316211193799973 and iou=0.6684914067472947 and reward=-1.0 and discount=0.8775210229989678\n",
            "   |->> t=15 Diff-Reward (-1.0) for 2X DOWN:bbox transition: [122,  52,  64,  89] -> [122,  56,  64,  89] w/ P(a|s)=0.09146904945373535 and iou=0.6684914067472947 and reward=-1.0 and discount=0.8687458127689782\n",
            "   |->> Assigned losses: [-2.352129  -2.353148  -2.3169584 -2.3108296 -2.3445356 -2.2535684\n",
            " -2.260137  -2.2329872 -2.2250092 -2.1632695 -2.1425638 -2.1669445\n",
            " -2.1470218 -2.0827208 -2.0778267]\n",
            "\u001b[31m>> Total frame loss: -33.429649353027344\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 236 with src: [122,  56,  64,  89] and target: [128,  52,  75,  94]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0236.jpg\n",
            "|->> Beginning tracking for bbox:[122  56  64  89]\n",
            "   \u001b[33m|->> #36-th Action selection: 3/2X RIGHT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [124  56  64  89]\n",
            "         |->> Action Probabilities (Rounded): [0.0866 0.0909 0.0929 0.0933 0.0941 0.0915 0.0928 0.0901 0.0937 0.0864\n",
            " 0.0879], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.08655921 0.09089888 0.09288383 0.09326211 0.09407166 0.09152129\n",
            " 0.09277461 0.09005482 0.09370495 0.08639939 0.08786932], argmax=4\n",
            "   \u001b[33m|->> #37-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [125  57  62  86]\n",
            "         |->> Action Probabilities (Rounded): [0.0907 0.0906 0.089  0.0918 0.0933 0.0915 0.0927 0.0901 0.094  0.0873\n",
            " 0.089 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09066127 0.09061757 0.0890048  0.09177081 0.0933372  0.0915428\n",
            " 0.09269119 0.09008435 0.09401123 0.08725093 0.08902785], argmax=8\n",
            "   \u001b[33m|->> #38-th Action selection: 4/UP (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [125  55  62  86]\n",
            "         |->> Action Probabilities (Rounded): [0.0893 0.0916 0.0902 0.0933 0.094  0.0921 0.0929 0.0912 0.0941 0.0819\n",
            " 0.0893], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08934489 0.0915832  0.09015919 0.09330194 0.09400664 0.09210221\n",
            " 0.09294806 0.09116903 0.09414215 0.08191749 0.08932518], argmax=8\n",
            "   \u001b[33m|->> #39-th Action selection: 4/UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [125  53  62  86]\n",
            "         |->> Action Probabilities (Rounded): [0.0913 0.0919 0.0898 0.0926 0.0913 0.0927 0.0936 0.0911 0.0939 0.0837\n",
            " 0.0879], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09134341 0.0919472  0.08983904 0.09261436 0.09129782 0.09271219\n",
            " 0.09361799 0.09108697 0.09394796 0.08368882 0.08790425], argmax=8\n",
            "   \u001b[33m|->> #40-th Action selection: 4/UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [125  51  62  86]\n",
            "         |->> Action Probabilities (Rounded): [0.0913 0.092  0.0898 0.0926 0.0907 0.0923 0.0926 0.0917 0.094  0.0831\n",
            " 0.0899], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0913036  0.0920001  0.08983438 0.09264997 0.09069724 0.09234127\n",
            " 0.09257586 0.09170766 0.09395335 0.08306151 0.08987503], argmax=8\n",
            "   \u001b[33m|->> #41-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08399999886751175)\u001b[0m\n",
            "      |->> Bounding box moves to: [126  52  60  83]\n",
            "         |->> Action Probabilities (Rounded): [0.0919 0.0921 0.0901 0.0922 0.0892 0.0917 0.0931 0.0928 0.0938 0.0838\n",
            " 0.0892], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09189755 0.09208511 0.09013055 0.09224363 0.0892395  0.09171903\n",
            " 0.09307549 0.09275591 0.09377941 0.08382941 0.08924444], argmax=8\n",
            "   \u001b[33m|->> #42-th Action selection: 9/SCALE DOWN (P(a|s) = 0.07999999821186066)\u001b[0m\n",
            "      |->> Bounding box moves to: [127  53  58  80]\n",
            "         |->> Action Probabilities (Rounded): [0.0916 0.0918 0.0896 0.0937 0.0907 0.0917 0.0929 0.0935 0.0935 0.08\n",
            " 0.091 ], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09164795 0.09176439 0.08964519 0.09370319 0.09072454 0.09168502\n",
            " 0.09291244 0.09347563 0.09349667 0.07995185 0.09099311], argmax=3\n",
            "|->> Revisiting bbox: [127  53  58  80]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [122,  56,  64,  89] -> [127,  53,  58,  80] (Target was [128,  52,  75,  94])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [122,  56,  64,  89] -> [124,  56,  64,  89] w/ P(a|s)=0.09326210618019104 and iou=0.7210369970294356 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [124,  56,  64,  89] -> [125,  57,  62,  86] w/ P(a|s)=0.08725092560052872 and iou=0.6943076081007116 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for UP:bbox transition: [125,  57,  62,  86] -> [125,  55,  62,  86] w/ P(a|s)=0.09400664269924164 and iou=0.6943076081007116 and reward=-1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-1.0) for UP:bbox transition: [125,  55,  62,  86] -> [125,  53,  62,  86] w/ P(a|s)=0.09129782021045685 and iou=0.6943076081007116 and reward=-1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-1.0) for UP:bbox transition: [125,  53,  62,  86] -> [125,  51,  62,  86] w/ P(a|s)=0.09069723635911942 and iou=0.6807384281254242 and reward=-1.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [125,  51,  62,  86] -> [126,  52,  60,  83] w/ P(a|s)=0.08382941037416458 and iou=0.6671286031042128 and reward=-1.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [126,  52,  60,  83] -> [127,  53,  58,  80] w/ P(a|s)=0.07995185256004333 and iou=0.6395511921458625 and reward=-1.0 and discount=0.941480149401\n",
            "   |->> Assigned losses: [-2.3723414 -2.4145775 -2.3173385 -2.3225353 -2.30565   -2.3574772\n",
            " -2.3784902]\n",
            "\u001b[31m>> Total frame loss: -16.46841049194336\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 237 with src: [127,  53,  58,  80] and target: [131,  50,  72,  97]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0237.jpg\n",
            "|->> Beginning tracking for bbox:[127  53  58  80]\n",
            "   \u001b[33m|->> #43-th Action selection: 0/LEFT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [126  53  58  80]\n",
            "         |->> Action Probabilities (Rounded): [0.092  0.0921 0.0895 0.0935 0.0916 0.0915 0.0936 0.0935 0.0937 0.0786\n",
            " 0.0902], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09200607 0.09213961 0.08951781 0.09352575 0.09161196 0.09151535\n",
            " 0.09363393 0.09353827 0.09371341 0.07860266 0.09019522], argmax=8\n",
            "   \u001b[33m|->> #44-th Action selection: 6/DOWN (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [126  55  58  80]\n",
            "         |->> Action Probabilities (Rounded): [0.0837 0.093  0.0952 0.0939 0.0926 0.0922 0.0934 0.094  0.0935 0.0792\n",
            " 0.0894], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08368405 0.09297536 0.0951696  0.09388643 0.09261658 0.09216134\n",
            " 0.09342957 0.09402386 0.09347939 0.07922323 0.08935061], argmax=2\n",
            "   \u001b[33m|->> #45-th Action selection: 7/2X DOWN (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [126  59  58  80]\n",
            "         |->> Action Probabilities (Rounded): [0.0928 0.0918 0.087  0.0935 0.0939 0.0922 0.0913 0.0945 0.0925 0.0807\n",
            " 0.0899], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09276521 0.09180206 0.08695903 0.09349712 0.0938785  0.09218638\n",
            " 0.09134534 0.09454958 0.09247964 0.08066248 0.08987468], argmax=7\n",
            "   \u001b[33m|->> #46-th Action selection: 2/RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [127  59  58  80]\n",
            "         |->> Action Probabilities (Rounded): [0.0891 0.0914 0.092  0.0931 0.0922 0.0922 0.0929 0.093  0.0924 0.0821\n",
            " 0.0896], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.08909275 0.09137056 0.09204665 0.09310183 0.0922443  0.09218175\n",
            " 0.09287086 0.09298266 0.09239972 0.08205941 0.08964954], argmax=3\n",
            "|->> Revisiting bbox: [127  59  58  80]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [127,  53,  58,  80] -> [127,  59,  58,  80] (Target was [131,  50,  72,  97])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for LEFT:bbox transition: [127,  53,  58,  80] -> [126,  53,  58,  80] w/ P(a|s)=0.09200607240200043 and iou=0.5742145178764897 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for DOWN:bbox transition: [126,  53,  58,  80] -> [126,  55,  58,  80] w/ P(a|s)=0.0934295654296875 and iou=0.5742145178764897 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for 2X DOWN:bbox transition: [126,  55,  58,  80] -> [126,  59,  58,  80] w/ P(a|s)=0.09454958140850067 and iou=0.5742145178764897 and reward=-1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-1.0) for RIGHT:bbox transition: [126,  59,  58,  80] -> [127,  59,  58,  80] w/ P(a|s)=0.09204664826393127 and iou=0.5914567360350493 and reward=-1.0 and discount=0.970299\n",
            "   |->> Assigned losses: [-2.3859007 -2.346842  -2.3116941 -2.3146093]\n",
            "\u001b[31m>> Total frame loss: -9.359046936035156\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 238 with src: [127,  59,  58,  80] and target: [128,  49,  76,  99]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0238.jpg\n",
            "|->> Beginning tracking for bbox:[127  59  58  80]\n",
            "   \u001b[33m|->> #47-th Action selection: 1/2X LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [125  59  58  80]\n",
            "         |->> Action Probabilities (Rounded): [0.0979 0.0915 0.0817 0.0946 0.0929 0.0927 0.0923 0.093  0.0924 0.0813\n",
            " 0.0895], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09794151 0.0914913  0.08173399 0.09457199 0.09293231 0.09274665\n",
            " 0.09234844 0.09300506 0.09239775 0.08130135 0.08952963], argmax=0\n",
            "   \u001b[33m|->> #48-th Action selection: 2/RIGHT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [126  59  58  80]\n",
            "         |->> Action Probabilities (Rounded): [0.0872 0.0899 0.0934 0.0928 0.0932 0.0922 0.0934 0.093  0.0924 0.0834\n",
            " 0.0891], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08723446 0.08987327 0.09344655 0.09276491 0.09318567 0.09224147\n",
            " 0.09340601 0.0929938  0.09235412 0.08340502 0.08909473], argmax=2\n",
            "   \u001b[33m|->> #49-th Action selection: 10/SCALE UP (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [125  57  60  82]\n",
            "         |->> Action Probabilities (Rounded): [0.0991 0.0899 0.0813 0.0929 0.0929 0.0937 0.0935 0.0936 0.0923 0.0825\n",
            " 0.0882], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09914299 0.0898768  0.08133355 0.09285008 0.09294751 0.09365286\n",
            " 0.09354845 0.09363823 0.09225715 0.08250554 0.08824686], argmax=0\n",
            "|->> Revisiting bbox: [125  57  60  82]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [127,  59,  58,  80] -> [125,  57,  60,  82] (Target was [128,  49,  76,  99])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [127,  59,  58,  80] -> [125,  59,  58,  80] w/ P(a|s)=0.09149130433797836 and iou=0.5667181865018032 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for RIGHT:bbox transition: [125,  59,  58,  80] -> [126,  59,  58,  80] w/ P(a|s)=0.09344654530286789 and iou=0.5830296720458095 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for SCALE UP:bbox transition: [126,  59,  58,  80] -> [125,  57,  60,  82] w/ P(a|s)=0.08824685961008072 and iou=0.6015444015444016 and reward=-1.0 and discount=0.9801\n",
            "   |->> Assigned losses: [-2.3915114 -2.346662  -2.3793075]\n",
            "\u001b[31m>> Total frame loss: -7.117481231689453\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 239 with src: [125,  57,  60,  82] and target: [130,  50,  74,  96]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0239.jpg\n",
            "|->> Beginning tracking for bbox:[125  57  60  82]\n",
            "|->> Revisiting bbox: [125  57  60  82]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #50-th Action selection: 8/STOP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [125  57  60  82]\n",
            "         |->> Action Probabilities (Rounded): [0.0866 0.0907 0.0926 0.0924 0.0942 0.094  0.094  0.0941 0.0927 0.0854\n",
            " 0.0834], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.08663943 0.09071728 0.09255061 0.09237287 0.09415425 0.09397504\n",
            " 0.09395965 0.09414516 0.09270743 0.08541339 0.08336489], argmax=4\n",
            "         |->> Hit a STOP on the 50-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [125,  57,  60,  82] -> [125,  57,  60,  82] (Target was [130,  50,  74,  96])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [125,  57,  60,  82] -> [125,  57,  60,  82] w/ P(a|s)=0.09270742535591125 and iou=0.6002129358530742 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.3783066]\n",
            "\u001b[31m>> Total frame loss: -2.3783066272735596\u001b[0m\n",
            "Final bounding box: [125  57  60  82] reached in 50 timesteps (originating from [132  51  71  98]). Target was [130  50  74  96]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 240 in t=50 timesteps ################\u001b[0m\n",
            "\n",
            "\u001b[36m####################### EPISODE # 3 ############################\u001b[0m\n",
            "Starting bounding box for adnet_datasets/OTB/FaceOcc2: frames 229:239 is [132  51  71  98].\n",
            "\u001b[34m>> Attempting to reach frame 230 with src: [132,  51,  71,  98] and target: [130,  51,  74,  97]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0230.jpg\n",
            "|->> Beginning tracking for bbox:[132  51  71  98]\n",
            "   \u001b[33m|->> #1-th Action selection: 4/UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [132  49  71  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0909 0.0908 0.091  0.0909 0.0909 0.0908 0.091  0.091  0.0912 0.0908\n",
            " 0.0909], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09088132 0.09078348 0.09096932 0.09092965 0.09091438 0.09079558\n",
            " 0.09095298 0.09095631 0.09115178 0.09079684 0.09086832], argmax=8\n",
            "   \u001b[33m|->> #2-th Action selection: 0/LEFT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [130  49  71  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0915 0.0909 0.0914 0.0912 0.0889 0.0909 0.0916 0.0913 0.0918 0.0901\n",
            " 0.0903], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09150619 0.09091338 0.09144098 0.09119102 0.08890816 0.09087653\n",
            " 0.0915701  0.09132639 0.09179567 0.09014457 0.09032705], argmax=8\n",
            "   \u001b[33m|->> #3-th Action selection: 3/2X RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [134  49  71  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0844 0.0912 0.098  0.092  0.0899 0.0916 0.0909 0.0925 0.092  0.0877\n",
            " 0.0898], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08439983 0.09121706 0.09796567 0.09196541 0.08994836 0.09160094\n",
            " 0.09094448 0.09246908 0.09199296 0.08772722 0.08976891], argmax=2\n",
            "|->> Revisiting bbox: [132  49  71  98]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [132,  51,  71,  98] -> [134,  49,  71,  98] (Target was [130,  51,  74,  97])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for UP:bbox transition: [132,  51,  71,  98] -> [132,  49,  71,  98] w/ P(a|s)=0.09091438353061676 and iou=0.9311475409836065 and reward=1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for LEFT:bbox transition: [132,  49,  71,  98] -> [130,  49,  71,  98] w/ P(a|s)=0.09150619059801102 and iou=0.9311475409836065 and reward=1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (1.0) for 2X RIGHT:bbox transition: [130,  49,  71,  98] -> [134,  49,  71,  98] w/ P(a|s)=0.09196541458368301 and iou=0.9061488673139159 and reward=1.0 and discount=0.9801\n",
            "   |->> Assigned losses: [2.3978372 2.3674352 2.3388546]\n",
            "\u001b[92m>> Total frame loss: 7.104126930236816\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 231 with src: [134,  49,  71,  98] and target: [131,  51,  73,  99]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0231.jpg\n",
            "|->> Beginning tracking for bbox:[134  49  71  98]\n",
            "   \u001b[33m|->> #4-th Action selection: 7/2X DOWN (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [134  53  71  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0935 0.0909 0.0881 0.0903 0.0905 0.0915 0.0918 0.0925 0.0917 0.0889\n",
            " 0.0903], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09347225 0.09089451 0.08811793 0.0903388  0.09045866 0.09146932\n",
            " 0.09184957 0.09248628 0.09174716 0.08891165 0.09025391], argmax=0\n",
            "   \u001b[33m|->> #5-th Action selection: 1/2X LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [130  53  71  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0895 0.0907 0.0926 0.0904 0.0916 0.0915 0.0916 0.0913 0.092  0.0889\n",
            " 0.09  ], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08951999 0.09065098 0.0925923  0.09043281 0.0915805  0.09154244\n",
            " 0.09155843 0.09129589 0.09198391 0.08887284 0.08996992], argmax=2\n",
            "   \u001b[33m|->> #6-th Action selection: 6/DOWN (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [130  55  71  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0925 0.0883 0.0896 0.0905 0.0916 0.0914 0.0922 0.0916 0.0925 0.0893\n",
            " 0.0904], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09251536 0.08833133 0.08962274 0.09050528 0.09163738 0.09137854\n",
            " 0.09223112 0.09156846 0.09249935 0.08933237 0.09037805], argmax=0\n",
            "   \u001b[33m|->> #7-th Action selection: 1/2X LEFT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [126  55  71  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0914 0.0885 0.0915 0.0912 0.0935 0.0917 0.0897 0.0921 0.0923 0.0887\n",
            " 0.0894], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.09136975 0.08852109 0.0915005  0.09120188 0.09345031 0.09174635\n",
            " 0.08974522 0.09205163 0.09231568 0.08867452 0.08942308], argmax=4\n",
            "   \u001b[33m|->> #8-th Action selection: 2/RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [128  55  71  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0915 0.0865 0.092  0.0911 0.0916 0.0919 0.0924 0.0922 0.0925 0.0889\n",
            " 0.0896], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09151043 0.08650067 0.09195518 0.09107566 0.09155999 0.09189387\n",
            " 0.09241828 0.09215981 0.092456   0.08887011 0.08960001], argmax=8\n",
            "|->> Revisiting bbox: [128  55  71  98]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [134,  49,  71,  98] -> [128,  55,  71,  98] (Target was [131,  51,  73,  99])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for 2X DOWN:bbox transition: [134,  49,  71,  98] -> [134,  53,  71,  98] w/ P(a|s)=0.09248627722263336 and iou=0.9181879648411089 and reward=1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for 2X LEFT:bbox transition: [134,  53,  71,  98] -> [130,  53,  71,  98] w/ P(a|s)=0.09065097570419312 and iou=0.9181879648411089 and reward=1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (1.0) for DOWN:bbox transition: [130,  53,  71,  98] -> [130,  55,  71,  98] w/ P(a|s)=0.09223112463951111 and iou=0.8825481088254811 and reward=1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (1.0) for 2X LEFT:bbox transition: [130,  55,  71,  98] -> [126,  55,  71,  98] w/ P(a|s)=0.0885210856795311 and iou=0.7921667719519899 and reward=1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (1.0) for RIGHT:bbox transition: [126,  55,  71,  98] -> [128,  55,  71,  98] w/ P(a|s)=0.09195517748594284 and iou=0.8362459546925566 and reward=1.0 and discount=0.96059601\n",
            "   |->> Assigned losses: [2.380695  2.3767314 2.336027  2.352504  2.2924182]\n",
            "\u001b[92m>> Total frame loss: 11.738375663757324\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 232 with src: [128,  55,  71,  98] and target: [130,  50,  75,  97]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0232.jpg\n",
            "|->> Beginning tracking for bbox:[128  55  71  98]\n",
            "   \u001b[33m|->> #9-th Action selection: 1/2X LEFT (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [124  55  71  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0973 0.0869 0.083  0.0924 0.093  0.0931 0.0922 0.093  0.0929 0.0872\n",
            " 0.089 ], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09726738 0.08689747 0.08300904 0.09236258 0.09304389 0.09305141\n",
            " 0.09219171 0.09302253 0.09291029 0.08722386 0.08901978], argmax=0\n",
            "   \u001b[33m|->> #10-th Action selection: 2/RIGHT (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [126  55  71  98]\n",
            "         |->> Action Probabilities (Rounded): [0.087  0.0858 0.0935 0.0908 0.0936 0.0925 0.0937 0.0936 0.0931 0.0878\n",
            " 0.0887], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08701333 0.08577117 0.09354061 0.0907592  0.09357689 0.09246528\n",
            " 0.09368628 0.09360059 0.09306553 0.08777907 0.08874205], argmax=6\n",
            "   \u001b[33m|->> #11-th Action selection: 3/2X RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [130  55  71  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0998 0.086  0.0815 0.0915 0.0928 0.0936 0.0941 0.094  0.0927 0.0861\n",
            " 0.0878], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09975906 0.08604343 0.0814843  0.09153169 0.09282324 0.09357411\n",
            " 0.09410977 0.0940311  0.09267801 0.08613028 0.08783501], argmax=0\n",
            "   \u001b[33m|->> #12-th Action selection: 5/2X UP (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [130  51  71  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0876 0.0872 0.092  0.0889 0.0938 0.0935 0.0942 0.0943 0.093  0.0873\n",
            " 0.0882], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08761702 0.0871699  0.0919714  0.08887195 0.09380171 0.09353425\n",
            " 0.09423712 0.09429868 0.09304103 0.0872536  0.08820333], argmax=7\n",
            "   \u001b[33m|->> #13-th Action selection: 4/UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [130  49  71  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0929 0.0879 0.0871 0.0892 0.0934 0.0917 0.0945 0.0935 0.093  0.0883\n",
            " 0.0887], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09286567 0.08792263 0.08708332 0.08920175 0.0933524  0.09165436\n",
            " 0.09449223 0.09345005 0.09296688 0.08829618 0.08871449], argmax=6\n",
            "   \u001b[33m|->> #14-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [131  50  68  95]\n",
            "         |->> Action Probabilities (Rounded): [0.0886 0.0887 0.0916 0.0901 0.0909 0.0917 0.0951 0.0937 0.0936 0.0876\n",
            " 0.0884], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08860703 0.08866256 0.09163439 0.09013909 0.09093002 0.09166503\n",
            " 0.09513394 0.09368272 0.0935505  0.0876338  0.08836091], argmax=6\n",
            "   \u001b[33m|->> #15-th Action selection: 4/UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [131  48  68  95]\n",
            "         |->> Action Probabilities (Rounded): [0.0912 0.0897 0.09   0.0904 0.0923 0.0917 0.0938 0.0948 0.0931 0.0833\n",
            " 0.0897], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09122565 0.08973048 0.0899567  0.09044267 0.09231859 0.0916796\n",
            " 0.09382344 0.09476224 0.0930652  0.08332386 0.0896716 ], argmax=7\n",
            "   \u001b[33m|->> #16-th Action selection: 0/LEFT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [129  48  68  95]\n",
            "         |->> Action Probabilities (Rounded): [0.0904 0.0906 0.0904 0.0908 0.09   0.0916 0.0955 0.0948 0.0936 0.0845\n",
            " 0.0879], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.0903592  0.09062134 0.0903809  0.09078309 0.08996201 0.09164622\n",
            " 0.09549144 0.09477775 0.09362368 0.08445837 0.087896  ], argmax=6\n",
            "   \u001b[33m|->> #17-th Action selection: 6/DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [129  50  68  95]\n",
            "         |->> Action Probabilities (Rounded): [0.0838 0.0909 0.0961 0.0919 0.0914 0.0921 0.0938 0.0957 0.0934 0.0825\n",
            " 0.0885], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08376105 0.09088605 0.09610172 0.09192722 0.09139504 0.0920786\n",
            " 0.09382816 0.09570602 0.09335977 0.08248353 0.08847283], argmax=2\n",
            "|->> Revisiting bbox: [129  50  68  95]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [128,  55,  71,  98] -> [129,  50,  68,  95] (Target was [130,  50,  75,  97])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for 2X LEFT:bbox transition: [128,  55,  71,  98] -> [124,  55,  71,  98] w/ P(a|s)=0.08689747005701065 and iou=0.7245849993941597 and reward=1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for RIGHT:bbox transition: [124,  55,  71,  98] -> [126,  55,  71,  98] w/ P(a|s)=0.09354060888290405 and iou=0.7639112653364729 and reward=1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (1.0) for 2X RIGHT:bbox transition: [126,  55,  71,  98] -> [130,  55,  71,  98] w/ P(a|s)=0.09153168648481369 and iou=0.8482015322685366 and reward=1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (1.0) for 2X UP:bbox transition: [130,  55,  71,  98] -> [130,  51,  71,  98] w/ P(a|s)=0.09353425353765488 and iou=0.9189699339355535 and reward=1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (1.0) for UP:bbox transition: [130,  51,  71,  98] -> [130,  49,  71,  98] w/ P(a|s)=0.09335239976644516 and iou=0.9375170160631636 and reward=1.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (1.0) for SCALE DOWN:bbox transition: [130,  49,  71,  98] -> [131,  50,  68,  95] w/ P(a|s)=0.08763380348682404 and iou=0.8879725085910652 and reward=1.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (1.0) for UP:bbox transition: [131,  50,  68,  95] -> [131,  48,  68,  95] w/ P(a|s)=0.092318594455719 and iou=0.8533261368236406 and reward=1.0 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (1.0) for LEFT:bbox transition: [131,  48,  68,  95] -> [129,  48,  68,  95] w/ P(a|s)=0.09035920351743698 and iou=0.8303571428571429 and reward=1.0 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (1.0) for DOWN:bbox transition: [129,  48,  68,  95] -> [129,  50,  68,  95] w/ P(a|s)=0.09382815659046173 and iou=0.8636363636363636 and reward=1.0 and discount=0.9227446944279201\n",
            "   |->> Assigned losses: [2.4430263 2.345666  2.3434877 2.2990534 2.2779322 2.3152692 2.2430856\n",
            " 2.2406502 2.183482 ]\n",
            "\u001b[92m>> Total frame loss: 20.691652297973633\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 233 with src: [129,  50,  68,  95] and target: [130,  50,  74,  98]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0233.jpg\n",
            "|->> Beginning tracking for bbox:[129  50  68  95]\n",
            "   \u001b[33m|->> #18-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08399999886751175)\u001b[0m\n",
            "      |->> Bounding box moves to: [130  51  65  92]\n",
            "         |->> Action Probabilities (Rounded): [0.0929 0.0909 0.088  0.0917 0.0927 0.0918 0.0921 0.095  0.0928 0.084\n",
            " 0.0882], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09286924 0.09085795 0.08802968 0.09166625 0.09273513 0.09181169\n",
            " 0.09206232 0.09500209 0.09279548 0.08399222 0.08817793], argmax=7\n",
            "|->> Revisiting bbox: [130  51  65  92]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [129,  50,  68,  95] -> [130,  51,  65,  92] (Target was [130,  50,  74,  98])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for SCALE DOWN:bbox transition: [129,  50,  68,  95] -> [130,  51,  65,  92] w/ P(a|s)=0.08399222046136856 and iou=0.8246001103143961 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [2.4770312]\n",
            "\u001b[92m>> Total frame loss: 2.4770312309265137\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 234 with src: [130,  51,  65,  92] and target: [129,  53,  77,  96]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0234.jpg\n",
            "|->> Beginning tracking for bbox:[130  51  65  92]\n",
            "   \u001b[33m|->> #19-th Action selection: 1/2X LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [128  51  65  92]\n",
            "         |->> Action Probabilities (Rounded): [0.0886 0.0911 0.0926 0.0927 0.0919 0.0923 0.0934 0.0949 0.0929 0.0802\n",
            " 0.0894], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.0886194  0.09107555 0.09256335 0.09270242 0.09189213 0.09225305\n",
            " 0.09344036 0.09488976 0.09292911 0.08021413 0.08942072], argmax=7\n",
            "   \u001b[33m|->> #20-th Action selection: 9/SCALE DOWN (P(a|s) = 0.0820000022649765)\u001b[0m\n",
            "      |->> Bounding box moves to: [129  52  63  89]\n",
            "         |->> Action Probabilities (Rounded): [0.0922 0.0889 0.0898 0.0922 0.0928 0.092  0.0931 0.0945 0.0932 0.0825\n",
            " 0.0888], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.0922245  0.08893381 0.0897677  0.0922204  0.092792   0.09202449\n",
            " 0.09305844 0.09452294 0.09319401 0.08247095 0.08879077], argmax=7\n",
            "   \u001b[33m|->> #21-th Action selection: 7/2X DOWN (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [129  56  63  89]\n",
            "         |->> Action Probabilities (Rounded): [0.0899 0.0893 0.0909 0.0937 0.0928 0.092  0.094  0.0951 0.0932 0.0781\n",
            " 0.0909], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.0899463  0.08932925 0.09093854 0.09367785 0.09282552 0.09202263\n",
            " 0.0939602  0.09505606 0.09322414 0.07809672 0.09092277], argmax=7\n",
            "   \u001b[33m|->> #22-th Action selection: 7/2X DOWN (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [129  60  63  89]\n",
            "         |->> Action Probabilities (Rounded): [0.0901 0.0898 0.0915 0.0934 0.0933 0.0917 0.0938 0.0929 0.0929 0.0811\n",
            " 0.0895], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09011037 0.08977373 0.09149819 0.09343936 0.09333487 0.09172888\n",
            " 0.09379435 0.09285772 0.09286576 0.08106989 0.08952688], argmax=6\n",
            "   \u001b[33m|->> #23-th Action selection: 7/2X DOWN (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [129  64  63  89]\n",
            "         |->> Action Probabilities (Rounded): [0.0896 0.0899 0.0906 0.0937 0.0934 0.0919 0.0937 0.0912 0.0933 0.0819\n",
            " 0.0909], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.08956467 0.08990392 0.09056937 0.09374759 0.09335136 0.09187428\n",
            " 0.09370734 0.09124713 0.09330229 0.08185154 0.09088045], argmax=3\n",
            "   \u001b[33m|->> #24-th Action selection: 2/RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [130  64  63  89]\n",
            "         |->> Action Probabilities (Rounded): [0.0888 0.09   0.0912 0.0937 0.0941 0.0918 0.0933 0.09   0.0938 0.083\n",
            " 0.0904], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.08884318 0.08999257 0.09116475 0.093688   0.09408513 0.09175479\n",
            " 0.09325339 0.09002413 0.093816   0.08295794 0.09042019], argmax=4\n",
            "   \u001b[33m|->> #25-th Action selection: 3/2X RIGHT (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [132  64  63  89]\n",
            "         |->> Action Probabilities (Rounded): [0.0969 0.0901 0.0831 0.0943 0.0928 0.0925 0.0932 0.0905 0.0934 0.0836\n",
            " 0.0896], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09692388 0.09011446 0.08305056 0.09426893 0.09277419 0.092532\n",
            " 0.09319487 0.0904766  0.09343593 0.08364873 0.08957987], argmax=0\n",
            "|->> Revisiting bbox: [130  64  63  89]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [130,  51,  65,  92] -> [132,  64,  63,  89] (Target was [129,  53,  77,  96])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for 2X LEFT:bbox transition: [130,  51,  65,  92] -> [128,  51,  65,  92] w/ P(a|s)=0.09107555449008942 and iou=0.7566999474513926 and reward=1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for SCALE DOWN:bbox transition: [128,  51,  65,  92] -> [129,  52,  63,  89] w/ P(a|s)=0.08247094601392746 and iou=0.7436619718309859 and reward=1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (1.0) for 2X DOWN:bbox transition: [129,  52,  63,  89] -> [129,  56,  63,  89] w/ P(a|s)=0.09505605697631836 and iou=0.7585227272727273 and reward=1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (1.0) for 2X DOWN:bbox transition: [129,  56,  63,  89] -> [129,  60,  63,  89] w/ P(a|s)=0.0928577184677124 and iou=0.7585227272727273 and reward=1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (1.0) for 2X DOWN:bbox transition: [129,  60,  63,  89] -> [129,  64,  63,  89] w/ P(a|s)=0.09124712646007538 and iou=0.7005494505494505 and reward=1.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (1.0) for RIGHT:bbox transition: [129,  64,  63,  89] -> [130,  64,  63,  89] w/ P(a|s)=0.09116474539041519 and iou=0.7005494505494505 and reward=1.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (1.0) for 2X RIGHT:bbox transition: [130,  64,  63,  89] -> [132,  64,  63,  89] w/ P(a|s)=0.09426892548799515 and iou=0.7005494505494505 and reward=1.0 and discount=0.941480149401\n",
            "   |->> Assigned losses: [2.396066  2.4703562 2.306458  2.3060968 2.2998435 2.2777038 2.223403 ]\n",
            "\u001b[92m>> Total frame loss: 16.279926300048828\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 235 with src: [132,  64,  63,  89] and target: [127,  51,  78,  95]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0235.jpg\n",
            "|->> Beginning tracking for bbox:[132  64  63  89]\n",
            "   \u001b[33m|->> #26-th Action selection: 3/2X RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [134  64  63  89]\n",
            "         |->> Action Probabilities (Rounded): [0.0879 0.0914 0.0913 0.0908 0.0941 0.0927 0.0929 0.0908 0.094  0.0845\n",
            " 0.0896], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.08790471 0.09138596 0.09134431 0.09083126 0.09407705 0.09270359\n",
            " 0.09286793 0.09076935 0.09399648 0.08454863 0.08957069], argmax=4\n",
            "|->> Revisiting bbox: [134  64  63  89]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [132,  64,  63,  89] -> [134,  64,  63,  89] (Target was [127,  51,  78,  95])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [132,  64,  63,  89] -> [134,  64,  63,  89] w/ P(a|s)=0.09083125740289688 and iou=0.6580053496369889 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.3987517]\n",
            "\u001b[31m>> Total frame loss: -2.398751735687256\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 236 with src: [134,  64,  63,  89] and target: [128,  52,  75,  94]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0236.jpg\n",
            "|->> Beginning tracking for bbox:[134  64  63  89]\n",
            "   \u001b[33m|->> #27-th Action selection: 7/2X DOWN (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [134  68  63  89]\n",
            "         |->> Action Probabilities (Rounded): [0.0917 0.092  0.0862 0.0892 0.0938 0.0927 0.0931 0.0911 0.094  0.0864\n",
            " 0.0897], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09169494 0.0919539  0.08624883 0.08921987 0.09383842 0.09271962\n",
            " 0.09311169 0.09112196 0.09402023 0.08635196 0.08971857], argmax=8\n",
            "|->> Revisiting bbox: [134  64  63  89]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [134,  64,  63,  89] -> [134,  68,  63,  89] (Target was [128,  52,  75,  94])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for 2X DOWN:bbox transition: [134,  64,  63,  89] -> [134,  68,  63,  89] w/ P(a|s)=0.09112195670604706 and iou=0.6346377373111197 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.3955564]\n",
            "\u001b[31m>> Total frame loss: -2.3955564498901367\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 237 with src: [134,  68,  63,  89] and target: [131,  50,  72,  97]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0237.jpg\n",
            "|->> Beginning tracking for bbox:[134  68  63  89]\n",
            "   \u001b[33m|->> #28-th Action selection: 3/2X RIGHT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [136  68  63  89]\n",
            "         |->> Action Probabilities (Rounded): [0.089  0.0918 0.0887 0.0895 0.0939 0.0927 0.093  0.09   0.0942 0.087\n",
            " 0.0903], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08895544 0.09176597 0.088736   0.08948041 0.09387881 0.09270673\n",
            " 0.09304547 0.08997604 0.09419079 0.08695862 0.09030573], argmax=8\n",
            "   \u001b[33m|->> #29-th Action selection: 7/2X DOWN (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [136  72  63  89]\n",
            "         |->> Action Probabilities (Rounded): [0.092  0.0923 0.0861 0.0878 0.0935 0.0922 0.0927 0.0902 0.0941 0.0891\n",
            " 0.09  ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09196531 0.09234051 0.08613079 0.08783928 0.09350825 0.092191\n",
            " 0.09269064 0.09015097 0.09411756 0.08909896 0.08996666], argmax=8\n",
            "   \u001b[33m|->> #30-th Action selection: 1/2X LEFT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [134  72  63  89]\n",
            "         |->> Action Probabilities (Rounded): [0.0907 0.0926 0.0874 0.0887 0.0939 0.092  0.0924 0.0886 0.0946 0.0889\n",
            " 0.0901], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09071159 0.09260761 0.08743483 0.08870394 0.09386838 0.09204423\n",
            " 0.09240523 0.0886151  0.09460557 0.08889475 0.09010871], argmax=8\n",
            "   \u001b[33m|->> #31-th Action selection: 1/2X LEFT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [132  72  63  89]\n",
            "         |->> Action Probabilities (Rounded): [0.0916 0.0902 0.0874 0.0888 0.0938 0.0918 0.0924 0.0893 0.0943 0.0903\n",
            " 0.09  ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09164679 0.09024052 0.08740576 0.08875381 0.09380456 0.09175189\n",
            " 0.09243003 0.08931985 0.0942832  0.09031942 0.09004416], argmax=8\n",
            "   \u001b[33m|->> #32-th Action selection: 0/LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [131  72  63  89]\n",
            "         |->> Action Probabilities (Rounded): [0.0906 0.0875 0.0884 0.0892 0.0938 0.0923 0.0929 0.0905 0.0946 0.09\n",
            " 0.0901], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09056349 0.08754525 0.08843368 0.08918265 0.09384296 0.09229117\n",
            " 0.09288909 0.09053896 0.0945622  0.09000678 0.09014375], argmax=8\n",
            "   \u001b[33m|->> #33-th Action selection: 6/DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [131  74  63  89]\n",
            "         |->> Action Probabilities (Rounded): [0.0835 0.0884 0.095  0.0897 0.0933 0.0933 0.0936 0.0927 0.0944 0.0874\n",
            " 0.0887], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08348826 0.08841645 0.09496942 0.0896752  0.09334489 0.09331148\n",
            " 0.09360051 0.09272094 0.09444743 0.08736482 0.08866065], argmax=2\n",
            "|->> Revisiting bbox: [131  72  63  89]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [134,  68,  63,  89] -> [131,  74,  63,  89] (Target was [131,  50,  72,  97])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [134,  68,  63,  89] -> [136,  68,  63,  89] w/ P(a|s)=0.08948041498661041 and iou=0.6536643026004728 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for 2X DOWN:bbox transition: [136,  68,  63,  89] -> [136,  72,  63,  89] w/ P(a|s)=0.09015096724033356 and iou=0.6006864988558352 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [136,  72,  63,  89] -> [134,  72,  63,  89] w/ P(a|s)=0.09260760992765427 and iou=0.6006864988558352 and reward=-1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [134,  72,  63,  89] -> [132,  72,  63,  89] w/ P(a|s)=0.09024051576852798 and iou=0.6006864988558352 and reward=-1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-1.0) for LEFT:bbox transition: [132,  72,  63,  89] -> [131,  72,  63,  89] w/ P(a|s)=0.09056349098682404 and iou=0.6006864988558352 and reward=-1.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-1.0) for DOWN:bbox transition: [131,  72,  63,  89] -> [131,  74,  63,  89] w/ P(a|s)=0.09360051155090332 and iou=0.5754504504504504 and reward=-1.0 and discount=0.9509900498999999\n",
            "   |->> Assigned losses: [-2.4137354 -2.382207  -2.3320343 -2.3338377 -2.3070674 -2.2526286]\n",
            "\u001b[31m>> Total frame loss: -14.02151107788086\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 238 with src: [131,  74,  63,  89] and target: [128,  49,  76,  99]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0238.jpg\n",
            "|->> Beginning tracking for bbox:[131  74  63  89]\n",
            "   \u001b[33m|->> #34-th Action selection: 3/2X RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [133  74  63  89]\n",
            "         |->> Action Probabilities (Rounded): [0.0922 0.0873 0.0868 0.0907 0.0946 0.0932 0.0916 0.0929 0.0938 0.088\n",
            " 0.0888], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.09221609 0.08731329 0.08677427 0.0907274  0.09463621 0.09323499\n",
            " 0.09164451 0.09287997 0.09380135 0.08797358 0.08879837], argmax=4\n",
            "   \u001b[33m|->> #35-th Action selection: 4/UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [133  72  63  89]\n",
            "         |->> Action Probabilities (Rounded): [0.0893 0.0879 0.0903 0.0887 0.0927 0.093  0.0931 0.093  0.0936 0.0891\n",
            " 0.0893], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08927939 0.08794801 0.09028781 0.08873528 0.0926804  0.09300402\n",
            " 0.09306863 0.09297545 0.09363205 0.08907656 0.08931236], argmax=8\n",
            "   \u001b[33m|->> #36-th Action selection: 3/2X RIGHT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [135  72  63  89]\n",
            "         |->> Action Probabilities (Rounded): [0.0923 0.0877 0.0886 0.0904 0.0916 0.0928 0.0927 0.0926 0.0938 0.0881\n",
            " 0.0894], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09225423 0.08766211 0.08861637 0.09036606 0.09162802 0.09282014\n",
            " 0.09267316 0.09264798 0.09376798 0.0881298  0.08943412], argmax=8\n",
            "   \u001b[33m|->> #37-th Action selection: 4/UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [135  70  63  89]\n",
            "         |->> Action Probabilities (Rounded): [0.0918 0.0888 0.0895 0.0888 0.0917 0.0926 0.0925 0.0931 0.0931 0.0884\n",
            " 0.0896], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.091763   0.08883891 0.08948667 0.08881042 0.09174558 0.0926178\n",
            " 0.09253225 0.09311774 0.09308386 0.08842044 0.08958328], argmax=7\n",
            "   \u001b[33m|->> #38-th Action selection: 2/RIGHT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [136  70  63  89]\n",
            "         |->> Action Probabilities (Rounded): [0.0916 0.0888 0.0889 0.0897 0.0905 0.0929 0.0939 0.0937 0.093  0.088\n",
            " 0.0891], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09158473 0.0887984  0.08894046 0.08968054 0.09045258 0.0929097\n",
            " 0.09392223 0.09368605 0.09297606 0.08797959 0.08906965], argmax=6\n",
            "|->> Revisiting bbox: [136  70  63  89]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [131,  74,  63,  89] -> [136,  70,  63,  89] (Target was [128,  49,  76,  99])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [131,  74,  63,  89] -> [133,  74,  63,  89] w/ P(a|s)=0.09072739630937576 and iou=0.5504782146652497 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for UP:bbox transition: [133,  74,  63,  89] -> [133,  72,  63,  89] w/ P(a|s)=0.09268040210008621 and iou=0.5738942826321467 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [133,  72,  63,  89] -> [135,  72,  63,  89] w/ P(a|s)=0.09036605805158615 and iou=0.5738942826321467 and reward=-1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-1.0) for UP:bbox transition: [135,  72,  63,  89] -> [135,  70,  63,  89] w/ P(a|s)=0.09174557775259018 and iou=0.5980284775465499 and reward=-1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-1.0) for RIGHT:bbox transition: [135,  70,  63,  89] -> [136,  70,  63,  89] w/ P(a|s)=0.08894046396017075 and iou=0.5980284775465499 and reward=-1.0 and discount=0.96059601\n",
            "   |->> Assigned losses: [-2.399896  -2.3548121 -2.356049  -2.3177881 -2.3244388]\n",
            "\u001b[31m>> Total frame loss: -11.752984046936035\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 239 with src: [136,  70,  63,  89] and target: [130,  50,  74,  96]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0239.jpg\n",
            "|->> Beginning tracking for bbox:[136  70  63  89]\n",
            "   \u001b[33m|->> #39-th Action selection: 7/2X DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [136  74  63  89]\n",
            "         |->> Action Probabilities (Rounded): [0.0974 0.0894 0.0821 0.0907 0.0916 0.0932 0.093  0.0941 0.0929 0.087\n",
            " 0.0885], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09740409 0.08944893 0.0821033  0.09073792 0.0915681  0.09324425\n",
            " 0.09301072 0.09410784 0.09290231 0.0869972  0.0884754 ], argmax=0\n",
            "   \u001b[33m|->> #40-th Action selection: 2/RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [137  74  63  89]\n",
            "         |->> Action Probabilities (Rounded): [0.0874 0.09   0.0916 0.0898 0.093  0.0922 0.0941 0.0932 0.0925 0.0877\n",
            " 0.0885], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08735929 0.09001128 0.0915608  0.08979128 0.09296484 0.09224356\n",
            " 0.09411678 0.09323736 0.09250429 0.08770265 0.08850786], argmax=6\n",
            "   \u001b[33m|->> #41-th Action selection: 3/2X RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [139  74  63  89]\n",
            "         |->> Action Probabilities (Rounded): [0.1016 0.0906 0.0793 0.0908 0.0924 0.0929 0.0932 0.0933 0.092  0.0863\n",
            " 0.0876], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.10157693 0.09061087 0.07933893 0.09080095 0.09235576 0.09287439\n",
            " 0.09323379 0.0933121  0.09199576 0.08634374 0.08755688], argmax=0\n",
            "   \u001b[33m|->> #42-th Action selection: 3/2X RIGHT (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [141  74  63  89]\n",
            "         |->> Action Probabilities (Rounded): [0.09   0.0927 0.0902 0.088  0.0929 0.0929 0.0934 0.0934 0.0918 0.0871\n",
            " 0.0877], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08995784 0.09270838 0.09016678 0.08799116 0.09285494 0.09285405\n",
            " 0.093405   0.09335016 0.09183083 0.08713092 0.08774993], argmax=6\n",
            "   \u001b[33m|->> #43-th Action selection: 0/LEFT (P(a|s) = 0.09600000083446503)\u001b[0m\n",
            "      |->> Bounding box moves to: [140  74  63  89]\n",
            "         |->> Action Probabilities (Rounded): [0.0965 0.0929 0.0837 0.0864 0.0931 0.0928 0.093  0.093  0.0919 0.0888\n",
            " 0.088 ], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.0964518  0.09293074 0.08370055 0.08635984 0.09314924 0.09277425\n",
            " 0.09299327 0.09299116 0.09186137 0.08875117 0.08803661], argmax=0\n",
            "   \u001b[33m|->> #44-th Action selection: 3/2X RIGHT (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [142  74  63  89]\n",
            "         |->> Action Probabilities (Rounded): [0.085  0.0926 0.0938 0.0878 0.0925 0.094  0.0942 0.0943 0.0924 0.0859\n",
            " 0.0876], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08496534 0.09264834 0.09376887 0.08779918 0.0924955  0.09398925\n",
            " 0.09420083 0.09427745 0.09236777 0.08589648 0.08759101], argmax=7\n",
            "|->> Revisiting bbox: [141  74  63  89]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [136,  70,  63,  89] -> [142,  74,  63,  89] (Target was [130,  50,  74,  96])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for 2X DOWN:bbox transition: [136,  70,  63,  89] -> [136,  74,  63,  89] w/ P(a|s)=0.09410783648490906 and iou=0.5548623853211009 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for RIGHT:bbox transition: [136,  74,  63,  89] -> [137,  74,  63,  89] w/ P(a|s)=0.09156079590320587 and iou=0.5548623853211009 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [137,  74,  63,  89] -> [139,  74,  63,  89] w/ P(a|s)=0.0908009484410286 and iou=0.5548623853211009 and reward=-1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [139,  74,  63,  89] -> [141,  74,  63,  89] w/ P(a|s)=0.0879911556839943 and iou=0.5548623853211009 and reward=-1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-1.0) for LEFT:bbox transition: [141,  74,  63,  89] -> [140,  74,  63,  89] w/ P(a|s)=0.09645179659128189 and iou=0.5548623853211009 and reward=-1.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [140,  74,  63,  89] -> [142,  74,  63,  89] w/ P(a|s)=0.08779918402433395 and iou=0.541287740996726 and reward=-1.0 and discount=0.9509900498999999\n",
            "   |->> Assigned losses: [-2.363314  -2.3668447 -2.3513436 -2.3583302 -2.2465575 -2.3134763]\n",
            "\u001b[31m>> Total frame loss: -13.999866485595703\u001b[0m\n",
            "Final bounding box: [142  74  63  89] reached in 45 timesteps (originating from [132  51  71  98]). Target was [130  50  74  96]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 240 in t=45 timesteps ################\u001b[0m\n",
            "\n",
            "\u001b[36m####################### EPISODE # 4 ############################\u001b[0m\n",
            "Starting bounding box for adnet_datasets/OTB/FaceOcc2: frames 229:239 is [132  51  71  98].\n",
            "\u001b[34m>> Attempting to reach frame 230 with src: [132,  51,  71,  98] and target: [130,  51,  74,  97]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0230.jpg\n",
            "|->> Beginning tracking for bbox:[132  51  71  98]\n",
            "   \u001b[33m|->> #1-th Action selection: 10/SCALE UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [130  49  73 100]\n",
            "         |->> Action Probabilities (Rounded): [0.0909 0.0908 0.091  0.0909 0.0909 0.0908 0.091  0.091  0.0912 0.0908\n",
            " 0.0909], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09088132 0.09078348 0.09096932 0.09092965 0.09091438 0.09079558\n",
            " 0.09095298 0.09095631 0.09115178 0.09079684 0.09086832], argmax=8\n",
            "   \u001b[33m|->> #2-th Action selection: 7/2X DOWN (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [130  55  73 100]\n",
            "         |->> Action Probabilities (Rounded): [0.0909 0.0911 0.0907 0.0915 0.0914 0.0914 0.0913 0.0917 0.0921 0.0925\n",
            " 0.0854], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.09091414 0.09113032 0.09072704 0.09148691 0.09135413 0.09137399\n",
            " 0.09133046 0.09171817 0.09208314 0.09245667 0.085425  ], argmax=9\n",
            "|->> Revisiting bbox: [130  55  73 100]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [132,  51,  71,  98] -> [130,  55,  73, 100] (Target was [130,  51,  74,  97])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for SCALE UP:bbox transition: [132,  51,  71,  98] -> [130,  49,  73, 100] w/ P(a|s)=0.09086832404136658 and iou=0.9572799783696093 and reward=1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for 2X DOWN:bbox transition: [130,  49,  73, 100] -> [130,  55,  73, 100] w/ P(a|s)=0.0917181745171547 and iou=0.8829496683573936 and reward=1.0 and discount=0.99\n",
            "   |->> Assigned losses: [2.3983438 2.3651445]\n",
            "\u001b[92m>> Total frame loss: 4.763488292694092\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 231 with src: [130,  55,  73, 100] and target: [131,  51,  73,  99]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0231.jpg\n",
            "|->> Beginning tracking for bbox:[130  55  73 100]\n",
            "   \u001b[33m|->> #3-th Action selection: 9/SCALE DOWN (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [131  56  70  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0908 0.0911 0.0916 0.0914 0.0916 0.0911 0.0912 0.0902 0.0926 0.0907\n",
            " 0.0877], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09078193 0.09107792 0.09162334 0.09142992 0.09162597 0.0910762\n",
            " 0.09119512 0.09016062 0.09262359 0.09074542 0.08766002], argmax=8\n",
            "   \u001b[33m|->> #4-th Action selection: 7/2X DOWN (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [131  60  70  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0903 0.0916 0.091  0.0924 0.0921 0.0915 0.0918 0.0911 0.0932 0.0867\n",
            " 0.0884], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09034792 0.09163387 0.09101072 0.09243566 0.0920539  0.09145071\n",
            " 0.09176547 0.09106687 0.09319864 0.08668552 0.0883507 ], argmax=8\n",
            "   \u001b[33m|->> #5-th Action selection: 2/RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [133  60  70  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0906 0.0916 0.0912 0.0921 0.0924 0.0913 0.0916 0.0895 0.0933 0.0883\n",
            " 0.0882], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09057444 0.09156232 0.09120675 0.09207339 0.09242282 0.09125584\n",
            " 0.09162325 0.08948852 0.09331419 0.08829965 0.0881788 ], argmax=8\n",
            "   \u001b[33m|->> #6-th Action selection: 2/RIGHT (P(a|s) = 0.08299999684095383)\u001b[0m\n",
            "      |->> Bounding box moves to: [135  60  70  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0969 0.0918 0.0826 0.0932 0.0921 0.0921 0.092  0.0905 0.0936 0.0868\n",
            " 0.0884], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09685223 0.09176045 0.08263386 0.09318469 0.09213692 0.09206787\n",
            " 0.09201026 0.09052778 0.09358578 0.0868048  0.08843539], argmax=0\n",
            "|->> Revisiting bbox: [135  60  70  97]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [130,  55,  73, 100] -> [135,  60,  70,  97] (Target was [131,  51,  73,  99])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for SCALE DOWN:bbox transition: [130,  55,  73, 100] -> [131,  56,  70,  97] w/ P(a|s)=0.09074541926383972 and iou=0.8847653623773026 and reward=1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for 2X DOWN:bbox transition: [131,  56,  70,  97] -> [131,  60,  70,  97] w/ P(a|s)=0.091066874563694 and iou=0.8163794220552028 and reward=1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (1.0) for RIGHT:bbox transition: [131,  60,  70,  97] -> [133,  60,  70,  97] w/ P(a|s)=0.09120675176382065 and iou=0.8163794220552028 and reward=1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (1.0) for RIGHT:bbox transition: [133,  60,  70,  97] -> [135,  60,  70,  97] w/ P(a|s)=0.0826338604092598 and iou=0.795439989752786 and reward=1.0 and discount=0.970299\n",
            "   |->> Assigned losses: [2.3996973 2.3721995 2.3469732 2.4192812]\n",
            "\u001b[92m>> Total frame loss: 9.538150787353516\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 232 with src: [135,  60,  70,  97] and target: [130,  50,  75,  97]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0232.jpg\n",
            "|->> Beginning tracking for bbox:[135  60  70  97]\n",
            "   \u001b[33m|->> #7-th Action selection: 7/2X DOWN (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [135  64  70  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0938 0.0925 0.0844 0.0924 0.093  0.0927 0.0924 0.0912 0.0936 0.0865\n",
            " 0.0876], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09383877 0.09249921 0.08435018 0.09241814 0.09296238 0.09269263\n",
            " 0.0923669  0.09115614 0.09358747 0.08653039 0.08759778], argmax=0\n",
            "   \u001b[33m|->> #8-th Action selection: 10/SCALE UP (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [133  62  72  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0894 0.0928 0.0903 0.0912 0.0933 0.0921 0.0922 0.09   0.0937 0.0872\n",
            " 0.0877], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08944783 0.09283201 0.09031348 0.09115642 0.09330623 0.0921345\n",
            " 0.09220553 0.09000072 0.09371348 0.08721244 0.08767738], argmax=8\n",
            "   \u001b[33m|->> #9-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [134  63  69  96]\n",
            "         |->> Action Probabilities (Rounded): [0.0918 0.0929 0.0882 0.0923 0.0932 0.093  0.0925 0.0908 0.0938 0.0889\n",
            " 0.0827], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09178703 0.09291785 0.08820392 0.0922577  0.09323228 0.09297129\n",
            " 0.0924975  0.09078017 0.09379716 0.08888648 0.08266868], argmax=8\n",
            "   \u001b[33m|->> #10-th Action selection: 5/2X UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [134  59  69  96]\n",
            "         |->> Action Probabilities (Rounded): [0.0901 0.0936 0.0897 0.0932 0.0937 0.093  0.093  0.0917 0.0938 0.0825\n",
            " 0.0856], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09013061 0.09361241 0.08970557 0.09315002 0.09368031 0.09304885\n",
            " 0.09299273 0.09174469 0.09382933 0.08248707 0.08561836], argmax=8\n",
            "   \u001b[33m|->> #11-th Action selection: 2/RIGHT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [136  59  69  96]\n",
            "         |->> Action Probabilities (Rounded): [0.091  0.0931 0.0893 0.0927 0.0935 0.0913 0.0935 0.0915 0.0945 0.0853\n",
            " 0.0842], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09101839 0.09313232 0.08925674 0.09272783 0.0935038  0.09134148\n",
            " 0.09346873 0.09145452 0.09452965 0.08533609 0.08423041], argmax=8\n",
            "   \u001b[33m|->> #12-th Action selection: 10/SCALE UP (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [134  57  71  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0971 0.0928 0.0821 0.0931 0.0935 0.092  0.0938 0.092  0.0938 0.0829\n",
            " 0.0868], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09709011 0.09282169 0.08210466 0.09310536 0.09354455 0.09199331\n",
            " 0.09381274 0.09203056 0.09377217 0.08293197 0.08679289], argmax=0\n",
            "   \u001b[33m|->> #13-th Action selection: 6/DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [134  59  71  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0882 0.0937 0.0907 0.0918 0.0943 0.0922 0.0938 0.0934 0.0941 0.0862\n",
            " 0.0816], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.08819214 0.09371612 0.09072142 0.09182466 0.09429973 0.09217927\n",
            " 0.09384604 0.09339608 0.09406748 0.08618522 0.08157187], argmax=4\n",
            "   \u001b[33m|->> #14-th Action selection: 0/LEFT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [132  59  71  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0928 0.0932 0.0884 0.092  0.0943 0.0925 0.0911 0.0929 0.0939 0.0858\n",
            " 0.0831], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.09283139 0.0931576  0.08836776 0.09204241 0.09433476 0.092496\n",
            " 0.09112327 0.09290452 0.09390764 0.08577722 0.08305743], argmax=4\n",
            "|->> Revisiting bbox: [132  59  71  98]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [135,  60,  70,  97] -> [132,  59,  71,  98] (Target was [130,  50,  75,  97])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for 2X DOWN:bbox transition: [135,  60,  70,  97] -> [135,  64,  70,  97] w/ P(a|s)=0.09115613996982574 and iou=0.7038158691701999 and reward=1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for SCALE UP:bbox transition: [135,  64,  70,  97] -> [133,  62,  72,  99] w/ P(a|s)=0.08767738193273544 and iou=0.7388627308946034 and reward=1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (1.0) for SCALE DOWN:bbox transition: [133,  62,  72,  99] -> [134,  63,  69,  96] w/ P(a|s)=0.08888648450374603 and iou=0.7152906330988523 and reward=1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (1.0) for 2X UP:bbox transition: [134,  63,  69,  96] -> [134,  59,  69,  96] w/ P(a|s)=0.09304884821176529 and iou=0.7757761594480644 and reward=1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (1.0) for RIGHT:bbox transition: [134,  59,  69,  96] -> [136,  59,  69,  96] w/ P(a|s)=0.08925674110651016 and iou=0.7757761594480644 and reward=1.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (1.0) for SCALE UP:bbox transition: [136,  59,  69,  96] -> [134,  57,  71,  98] w/ P(a|s)=0.08679288625717163 and iou=0.8147392579370138 and reward=1.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (1.0) for DOWN:bbox transition: [134,  57,  71,  98] -> [134,  59,  71,  98] w/ P(a|s)=0.09384603798389435 and iou=0.7824671258609893 and reward=1.0 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (1.0) for LEFT:bbox transition: [134,  59,  71,  98] -> [132,  59,  71,  98] w/ P(a|s)=0.09283138811588287 and iou=0.7824671258609893 and reward=1.0 and discount=0.9320653479069899\n",
            "   |->> Assigned losses: [2.3951814 2.4097505 2.372229  2.3041017 2.321029  2.3244388 2.227636\n",
            " 2.215492 ]\n",
            "\u001b[92m>> Total frame loss: 18.56985855102539\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 233 with src: [132,  59,  71,  98] and target: [130,  50,  74,  98]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0233.jpg\n",
            "|->> Beginning tracking for bbox:[132  59  71  98]\n",
            "   \u001b[33m|->> #15-th Action selection: 7/2X DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [132  63  71  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0834 0.0931 0.0974 0.0929 0.0924 0.0933 0.0933 0.0942 0.0933 0.0845\n",
            " 0.0823], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08339545 0.09305842 0.09735681 0.09287543 0.0923578  0.09325963\n",
            " 0.09329212 0.09423608 0.0933042  0.08454984 0.08231419], argmax=2\n",
            "   \u001b[33m|->> #16-th Action selection: 4/UP (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [132  61  71  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0925 0.092  0.088  0.0931 0.0938 0.0924 0.0923 0.0918 0.0934 0.0861\n",
            " 0.0847], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.09245988 0.09199614 0.08804553 0.09308386 0.09383691 0.0923887\n",
            " 0.09225798 0.09179821 0.09337377 0.08606886 0.08469019], argmax=4\n",
            "   \u001b[33m|->> #17-th Action selection: 5/2X UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [132  57  71  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0882 0.0922 0.0925 0.0931 0.0911 0.0923 0.0937 0.0926 0.0933 0.0862\n",
            " 0.0849], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08816002 0.09217682 0.0924765  0.09313265 0.09108648 0.09232584\n",
            " 0.09371437 0.09255601 0.09330739 0.08619506 0.08486883], argmax=6\n",
            "   \u001b[33m|->> #18-th Action selection: 10/SCALE UP (P(a|s) = 0.0860000029206276)\u001b[0m\n",
            "      |->> Bounding box moves to: [130  55  73 100]\n",
            "         |->> Action Probabilities (Rounded): [0.0924 0.0916 0.0897 0.0929 0.0923 0.0904 0.0927 0.0926 0.0928 0.0869\n",
            " 0.0856], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09240808 0.09163024 0.08972938 0.09289572 0.09232605 0.09041944\n",
            " 0.09265545 0.09259277 0.09282395 0.08690667 0.08561225], argmax=3\n",
            "   \u001b[33m|->> #19-th Action selection: 4/UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [130  52  73 100]\n",
            "         |->> Action Probabilities (Rounded): [0.0902 0.0916 0.0913 0.0935 0.0921 0.0909 0.0935 0.0931 0.0936 0.0881\n",
            " 0.0822], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09017513 0.09155497 0.09133773 0.0935157  0.09213167 0.09085107\n",
            " 0.09354125 0.09308401 0.09360158 0.08805308 0.08215381], argmax=8\n",
            "   \u001b[33m|->> #20-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [131  53  70  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0916 0.0916 0.0919 0.0933 0.0904 0.0908 0.0936 0.0928 0.0934 0.0871\n",
            " 0.0836], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09160261 0.09164237 0.09186183 0.09326366 0.09037318 0.09075882\n",
            " 0.09357715 0.09280667 0.09335793 0.08713312 0.08362258], argmax=6\n",
            "   \u001b[33m|->> #21-th Action selection: 0/LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [129  53  70  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0909 0.0918 0.0909 0.0938 0.0922 0.0916 0.0933 0.0936 0.0936 0.0838\n",
            " 0.0846], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09086851 0.09181657 0.09085832 0.09376397 0.09215052 0.09162626\n",
            " 0.09327884 0.0936357  0.09356756 0.08379303 0.08464067], argmax=3\n",
            "   \u001b[33m|->> #22-th Action selection: 10/SCALE UP (P(a|s) = 0.08399999886751175)\u001b[0m\n",
            "      |->> Bounding box moves to: [127  51  72  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0836 0.0919 0.097  0.0945 0.0924 0.0919 0.0936 0.0942 0.0932 0.0835\n",
            " 0.0843], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08356808 0.09189001 0.09695517 0.09451585 0.09241182 0.09188879\n",
            " 0.09355397 0.09424896 0.09319681 0.08350015 0.08427045], argmax=2\n",
            "   \u001b[33m|->> #23-th Action selection: 10/SCALE UP (P(a|s) = 0.0820000022649765)\u001b[0m\n",
            "      |->> Bounding box moves to: [125  49  74 101]\n",
            "         |->> Action Probabilities (Rounded): [0.0933 0.091  0.088  0.0952 0.0925 0.0916 0.0939 0.0943 0.0928 0.0854\n",
            " 0.082 ], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09332994 0.09099647 0.08804124 0.09515052 0.09252147 0.09162723\n",
            " 0.09385009 0.09431337 0.09277596 0.08539985 0.08199387], argmax=3\n",
            "   \u001b[33m|->> #24-th Action selection: 1/2X LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [121  49  74 101]\n",
            "         |->> Action Probabilities (Rounded): [0.0894 0.0911 0.092  0.0946 0.0933 0.0924 0.0937 0.0947 0.0938 0.0863\n",
            " 0.0788], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.0893805  0.09106575 0.091995   0.09462645 0.09329048 0.09237692\n",
            " 0.09370741 0.09473666 0.09375875 0.08629744 0.07876467], argmax=7\n",
            "   \u001b[33m|->> #25-th Action selection: 1/2X LEFT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [117  49  74 101]\n",
            "         |->> Action Probabilities (Rounded): [0.0909 0.0888 0.0899 0.0943 0.0938 0.0921 0.0937 0.0943 0.0932 0.0871\n",
            " 0.0818], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09092688 0.0888109  0.08994687 0.09428592 0.09384702 0.0921106\n",
            " 0.09368359 0.09432133 0.09320667 0.08710554 0.08175466], argmax=7\n",
            "   \u001b[33m|->> #26-th Action selection: 4/UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [117  46  74 101]\n",
            "         |->> Action Probabilities (Rounded): [0.0888 0.0864 0.0924 0.0936 0.0934 0.0922 0.0946 0.0952 0.0933 0.0877\n",
            " 0.0823], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08876855 0.0863992  0.09237719 0.09364222 0.0934035  0.0922382\n",
            " 0.09462075 0.09519798 0.09333871 0.08769742 0.08231626], argmax=7\n",
            "   \u001b[33m|->> #27-th Action selection: 1/2X LEFT (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [113  46  74 101]\n",
            "         |->> Action Probabilities (Rounded): [0.0899 0.0872 0.0911 0.0935 0.0918 0.0926 0.0952 0.0952 0.0932 0.0873\n",
            " 0.083 ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08994605 0.08717549 0.09111267 0.09351145 0.09177588 0.09257916\n",
            " 0.09517703 0.09517778 0.09322107 0.08732004 0.08300338], argmax=7\n",
            "   \u001b[33m|->> #28-th Action selection: 6/DOWN (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [113  49  74 101]\n",
            "         |->> Action Probabilities (Rounded): [0.0891 0.0853 0.0914 0.0934 0.0932 0.0928 0.0947 0.0954 0.0928 0.0881\n",
            " 0.0839], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08905833 0.08528568 0.09141409 0.09343868 0.09322853 0.09280968\n",
            " 0.09468509 0.09535836 0.09278444 0.08806247 0.08387469], argmax=7\n",
            "   \u001b[33m|->> #29-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [114  50  71  97]\n",
            "         |->> Action Probabilities (Rounded): [0.089  0.0859 0.0919 0.093  0.0939 0.0924 0.0927 0.0955 0.0928 0.0877\n",
            " 0.0851], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08901944 0.08593523 0.09192335 0.09302833 0.09391307 0.09237627\n",
            " 0.09268541 0.09552851 0.09279676 0.08767741 0.08511622], argmax=7\n",
            "   \u001b[33m|->> #30-th Action selection: 7/2X DOWN (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [114  54  71  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0891 0.0862 0.092  0.0941 0.0931 0.0929 0.0943 0.0954 0.0931 0.083\n",
            " 0.0868], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08910811 0.08617978 0.09204376 0.09410013 0.09314244 0.09293931\n",
            " 0.09429214 0.09536807 0.0930717  0.08299387 0.08676062], argmax=7\n",
            "   \u001b[33m|->> #31-th Action selection: 6/DOWN (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [114  56  71  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0897 0.0869 0.0916 0.0932 0.094  0.0925 0.0933 0.0932 0.0934 0.0861\n",
            " 0.0861], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.08968712 0.08694282 0.09157113 0.09322302 0.09395468 0.09253376\n",
            " 0.09328284 0.09322291 0.09342255 0.08605254 0.08610661], argmax=4\n",
            "   \u001b[33m|->> #32-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [115  57  68  94]\n",
            "         |->> Action Probabilities (Rounded): [0.088  0.0882 0.091  0.0935 0.0949 0.0922 0.0916 0.0931 0.0932 0.0872\n",
            " 0.087 ], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.08801638 0.08824585 0.09101799 0.09349389 0.09492146 0.09216848\n",
            " 0.09160247 0.09313864 0.09319033 0.08715941 0.08704512], argmax=4\n",
            "   \u001b[33m|->> #33-th Action selection: 3/2X RIGHT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [119  57  68  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0878 0.089  0.0923 0.0934 0.0932 0.0923 0.0934 0.0928 0.0937 0.0826\n",
            " 0.0894], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08784538 0.08904569 0.09225165 0.09343813 0.09317444 0.09231322\n",
            " 0.09342125 0.09281633 0.09369601 0.08263059 0.0893673 ], argmax=8\n",
            "   \u001b[33m|->> #34-th Action selection: 6/DOWN (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [119  59  68  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0887 0.0894 0.0902 0.0914 0.0941 0.0924 0.0923 0.0926 0.0941 0.0846\n",
            " 0.0901], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08871738 0.08936783 0.09024081 0.09138399 0.09406371 0.09241647\n",
            " 0.09232257 0.0926093  0.09412725 0.0846042  0.0901465 ], argmax=8\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [132,  59,  71,  98] -> [119,  59,  68,  94] (Target was [130,  50,  74,  98])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for 2X DOWN:bbox transition: [132,  59,  71,  98] -> [132,  63,  71,  98] w/ P(a|s)=0.09423607587814331 and iou=0.7382262996941896 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for UP:bbox transition: [132,  63,  71,  98] -> [132,  61,  71,  98] w/ P(a|s)=0.09383691102266312 and iou=0.7689530685920578 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for 2X UP:bbox transition: [132,  61,  71,  98] -> [132,  57,  71,  98] w/ P(a|s)=0.0923258364200592 and iou=0.8337850045167118 and reward=-1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-1.0) for SCALE UP:bbox transition: [132,  57,  71,  98] -> [130,  55,  73, 100] w/ P(a|s)=0.08561225235462189 and iou=0.8745330413499935 and reward=-1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-1.0) for UP:bbox transition: [130,  55,  73, 100] -> [130,  52,  73, 100] w/ P(a|s)=0.09213166683912277 and iou=0.9289501590668081 and reward=-1.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [130,  52,  73, 100] -> [131,  53,  70,  97] w/ P(a|s)=0.08713311702013016 and iou=0.8996212121212122 and reward=-1.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (-1.0) for LEFT:bbox transition: [131,  53,  70,  97] -> [129,  53,  70,  97] w/ P(a|s)=0.0908685103058815 and iou=0.8755175637772138 and reward=-1.0 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (-1.0) for SCALE UP:bbox transition: [129,  53,  70,  97] -> [127,  51,  72,  99] w/ P(a|s)=0.08427044749259949 and iou=0.8706907766358788 and reward=-1.0 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (-1.0) for SCALE UP:bbox transition: [127,  51,  72,  99] -> [125,  49,  74, 101] w/ P(a|s)=0.08199387043714523 and iou=0.8490708186840783 and reward=-1.0 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [125,  49,  74, 101] -> [121,  49,  74, 101] w/ P(a|s)=0.09106574952602386 and iou=0.7623264719961704 and reward=-1.0 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [121,  49,  74, 101] -> [117,  49,  74, 101] w/ P(a|s)=0.08881089836359024 and iou=0.6833561957018747 and reward=-1.0 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (-1.0) for UP:bbox transition: [117,  49,  74, 101] -> [117,  46,  74, 101] w/ P(a|s)=0.09340349584817886 and iou=0.6716993983426042 and reward=-1.0 and discount=0.8953382542587164\n",
            "   |->> t=13 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [117,  46,  74, 101] -> [113,  46,  74, 101] w/ P(a|s)=0.08717548847198486 and iou=0.6011742959660759 and reward=-1.0 and discount=0.8863848717161292\n",
            "   |->> t=14 Diff-Reward (-1.0) for DOWN:bbox transition: [113,  46,  74, 101] -> [113,  49,  74, 101] w/ P(a|s)=0.09468509256839752 and iou=0.6111597374179432 and reward=-1.0 and discount=0.8775210229989678\n",
            "   |->> t=15 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [113,  49,  74, 101] -> [114,  50,  71,  97] w/ P(a|s)=0.08767741173505783 and iou=0.6059745570195366 and reward=-1.0 and discount=0.8687458127689782\n",
            "   |->> t=16 Diff-Reward (-1.0) for 2X DOWN:bbox transition: [114,  50,  71,  97] -> [114,  54,  71,  97] w/ P(a|s)=0.09536807239055634 and iou=0.5764299252982495 and reward=-1.0 and discount=0.8600583546412884\n",
            "   |->> t=17 Diff-Reward (-1.0) for DOWN:bbox transition: [114,  54,  71,  97] -> [114,  56,  71,  97] w/ P(a|s)=0.09328284114599228 and iou=0.5573301024341888 and reward=-1.0 and discount=0.8514577710948755\n",
            "   |->> t=18 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [114,  56,  71,  97] -> [115,  57,  68,  94] w/ P(a|s)=0.0871594101190567 and iou=0.5467634055095794 and reward=-1.0 and discount=0.8429431933839268\n",
            "   |->> t=19 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [115,  57,  68,  94] -> [119,  57,  68,  94] w/ P(a|s)=0.09343812614679337 and iou=0.6133380631429585 and reward=-1.0 and discount=0.8345137614500875\n",
            "   |->> t=20 Diff-Reward (-1.0) for DOWN:bbox transition: [119,  57,  68,  94] -> [119,  59,  68,  94] w/ P(a|s)=0.09232257306575775 and iou=0.591879593979699 and reward=-1.0 and discount=0.8261686238355866\n",
            "   |->> Assigned losses: [-2.3619523 -2.3425353 -2.3350208 -2.384924  -2.2905762 -2.3207183\n",
            " -2.257991  -2.3056726 -2.3078866 -2.1889458 -2.1897314 -2.1226916\n",
            " -2.1626303 -2.0684915 -2.1146064 -2.021147  -2.0197594 -2.0567954\n",
            " -1.978178  -1.968319 ]\n",
            "\u001b[31m>> Total frame loss: -43.79857635498047\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 234 with src: [119,  59,  68,  94] and target: [129,  53,  77,  96]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0234.jpg\n",
            "|->> Beginning tracking for bbox:[119  59  68  94]\n",
            "   \u001b[33m|->> #35-th Action selection: 2/RIGHT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [121  59  68  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0892 0.0903 0.0902 0.0919 0.0949 0.0925 0.0913 0.0928 0.0927 0.084\n",
            " 0.0901], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.08921206 0.09034901 0.09022886 0.09185639 0.09485886 0.09252223\n",
            " 0.09129444 0.09277786 0.09270855 0.0840464  0.09014533], argmax=4\n",
            "|->> Revisiting bbox: [119  59  68  94]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [119,  59,  68,  94] -> [121,  59,  68,  94] (Target was [129,  53,  77,  96])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for RIGHT:bbox transition: [119,  59,  68,  94] -> [121,  59,  68,  94] w/ P(a|s)=0.0902288630604744 and iou=0.6440839694656488 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.405406]\n",
            "\u001b[31m>> Total frame loss: -2.4054059982299805\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 235 with src: [121,  59,  68,  94] and target: [127,  51,  78,  95]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0235.jpg\n",
            "|->> Beginning tracking for bbox:[121  59  68  94]\n",
            "   \u001b[33m|->> #36-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08399999886751175)\u001b[0m\n",
            "      |->> Bounding box moves to: [122  60  65  91]\n",
            "         |->> Action Probabilities (Rounded): [0.0957 0.0916 0.0825 0.0922 0.0927 0.0933 0.0928 0.0927 0.0934 0.0841\n",
            " 0.089 ], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09573863 0.09161112 0.08251417 0.09215201 0.09272505 0.09326666\n",
            " 0.09276378 0.0926799  0.09342787 0.08413248 0.08898833], argmax=0\n",
            "   \u001b[33m|->> #37-th Action selection: 2/RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [123  60  65  91]\n",
            "         |->> Action Probabilities (Rounded): [0.0858 0.0926 0.0914 0.0915 0.0949 0.0934 0.0922 0.0929 0.0942 0.0802\n",
            " 0.0909], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.08582186 0.09263843 0.09144639 0.09146021 0.09487855 0.09336992\n",
            " 0.0921808  0.09287703 0.09424556 0.08020334 0.09087791], argmax=4\n",
            "   \u001b[33m|->> #38-th Action selection: 4/UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [123  58  65  91]\n",
            "         |->> Action Probabilities (Rounded): [0.0986 0.0929 0.0798 0.0924 0.0934 0.0938 0.0935 0.0935 0.0928 0.0809\n",
            " 0.0883], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09857489 0.09293836 0.07982472 0.09240486 0.09338956 0.09381858\n",
            " 0.09352542 0.09346339 0.09282943 0.08090481 0.08832601], argmax=0\n",
            "   \u001b[33m|->> #39-th Action selection: 7/2X DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [123  62  65  91]\n",
            "         |->> Action Probabilities (Rounded): [0.0866 0.0938 0.0916 0.0917 0.092  0.0934 0.0937 0.0935 0.0932 0.0813\n",
            " 0.0892], argmax=1\n",
            "         |->> Action Probabilities (RAW): [0.08662724 0.09379531 0.09156358 0.09165297 0.09199146 0.09343676\n",
            " 0.09370995 0.09353412 0.09315788 0.08130734 0.08922338], argmax=1\n",
            "   \u001b[33m|->> #40-th Action selection: 3/2X RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [125  62  65  91]\n",
            "         |->> Action Probabilities (Rounded): [0.0938 0.0933 0.0872 0.0907 0.0923 0.0926 0.0923 0.0917 0.0931 0.0839\n",
            " 0.089 ], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09381638 0.09328828 0.08723854 0.09069572 0.09230235 0.09261996\n",
            " 0.09228629 0.09172647 0.09310015 0.08391465 0.08901119], argmax=0\n",
            "   \u001b[33m|->> #41-th Action selection: 4/UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [125  60  65  91]\n",
            "         |->> Action Probabilities (Rounded): [0.0904 0.0936 0.0888 0.0892 0.0925 0.0927 0.094  0.0928 0.0925 0.0845\n",
            " 0.089 ], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09035359 0.09356248 0.08879384 0.08917033 0.09251192 0.09271335\n",
            " 0.09403513 0.09282599 0.09252799 0.08451788 0.08898753], argmax=6\n",
            "   \u001b[33m|->> #42-th Action selection: 10/SCALE UP (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [124  58  67  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0934 0.0928 0.0877 0.0899 0.091  0.0928 0.0938 0.093  0.0925 0.0846\n",
            " 0.0885], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09336614 0.09279185 0.08771381 0.08994012 0.09099004 0.09284436\n",
            " 0.09375849 0.09298081 0.09251197 0.08458211 0.08852034], argmax=6\n",
            "   \u001b[33m|->> #43-th Action selection: 4/UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [124  56  67  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0922 0.0932 0.0881 0.0899 0.092  0.093  0.0932 0.0936 0.0936 0.088\n",
            " 0.0833], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09220465 0.09318316 0.08811721 0.08985196 0.09195473 0.09304165\n",
            " 0.09317406 0.0935537  0.09364141 0.08801214 0.08326529], argmax=8\n",
            "   \u001b[33m|->> #44-th Action selection: 4/UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [124  54  67  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0922 0.0931 0.0895 0.0909 0.0908 0.0925 0.0941 0.0932 0.0928 0.0858\n",
            " 0.085 ], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09221501 0.09314463 0.08945758 0.09089141 0.0908155  0.09253767\n",
            " 0.09411932 0.09318835 0.09277643 0.08582886 0.08502519], argmax=6\n",
            "   \u001b[33m|->> #45-th Action selection: 5/2X UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [124  50  67  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0927 0.0928 0.0897 0.091  0.0895 0.092  0.0934 0.0938 0.0932 0.087\n",
            " 0.0847], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09274984 0.09276856 0.08972626 0.09102017 0.08954491 0.09204791\n",
            " 0.09338819 0.09384461 0.09323446 0.08699782 0.08467728], argmax=7\n",
            "   \u001b[33m|->> #46-th Action selection: 1/2X LEFT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [120  50  67  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0916 0.0925 0.0893 0.0916 0.0907 0.0901 0.0931 0.0931 0.0932 0.0881\n",
            " 0.0869], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09156122 0.09248647 0.08928669 0.09155565 0.09066039 0.09007016\n",
            " 0.09314469 0.09309684 0.09317805 0.08809478 0.08686503], argmax=8\n",
            "   \u001b[33m|->> #47-th Action selection: 5/2X UP (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [120  46  67  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0914 0.0899 0.0902 0.0914 0.0918 0.0896 0.0937 0.0931 0.0926 0.0895\n",
            " 0.0868], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09141006 0.08986133 0.09019143 0.09139735 0.09178414 0.08959629\n",
            " 0.0936605  0.09306855 0.09264846 0.08953684 0.08684512], argmax=6\n",
            "   \u001b[33m|->> #48-th Action selection: 2/RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [122  46  67  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0911 0.0897 0.0906 0.0916 0.0914 0.088  0.0937 0.093  0.0932 0.0903\n",
            " 0.0874], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09107587 0.08973194 0.09060582 0.09156078 0.09135015 0.08802258\n",
            " 0.09372919 0.09304577 0.09319234 0.09028471 0.08740079], argmax=6\n",
            "|->> Revisiting bbox: [120  46  67  93]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [121,  59,  68,  94] -> [122,  46,  67,  93] (Target was [127,  51,  78,  95])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [121,  59,  68,  94] -> [122,  60,  65,  91] w/ P(a|s)=0.08413247764110565 and iou=0.6319657072872015 and reward=-1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for RIGHT:bbox transition: [122,  60,  65,  91] -> [123,  60,  65,  91] w/ P(a|s)=0.0914463922381401 and iou=0.6493377893303627 and reward=-1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-1.0) for UP:bbox transition: [123,  60,  65,  91] -> [123,  58,  65,  91] w/ P(a|s)=0.09338956326246262 and iou=0.6746261153701144 and reward=-1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-1.0) for 2X DOWN:bbox transition: [123,  58,  65,  91] -> [123,  62,  65,  91] w/ P(a|s)=0.09353411942720413 and iou=0.6248018534325083 and reward=-1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [123,  62,  65,  91] -> [125,  62,  65,  91] w/ P(a|s)=0.09069572389125824 and iou=0.6587825220963526 and reward=-1.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-1.0) for UP:bbox transition: [125,  62,  65,  91] -> [125,  60,  65,  91] w/ P(a|s)=0.09251192212104797 and iou=0.6852156317187302 and reward=-1.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (-1.0) for SCALE UP:bbox transition: [125,  60,  65,  91] -> [124,  58,  67,  93] w/ P(a|s)=0.0885203406214714 and iou=0.7032088899987514 and reward=-1.0 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (-1.0) for UP:bbox transition: [124,  58,  67,  93] -> [124,  56,  67,  93] w/ P(a|s)=0.09195473045110703 and iou=0.7308717167872097 and reward=-1.0 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (-1.0) for UP:bbox transition: [124,  56,  67,  93] -> [124,  54,  67,  93] w/ P(a|s)=0.09081549942493439 and iou=0.7594479556300787 and reward=-1.0 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (-1.0) for 2X UP:bbox transition: [124,  54,  67,  93] -> [124,  50,  67,  93] w/ P(a|s)=0.09204791486263275 and iou=0.7594479556300787 and reward=-1.0 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [124,  50,  67,  93] -> [120,  50,  67,  93] w/ P(a|s)=0.09248647093772888 and iou=0.6797192463982268 and reward=-1.0 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (-1.0) for 2X UP:bbox transition: [120,  50,  67,  93] -> [120,  46,  67,  93] w/ P(a|s)=0.08959629386663437 and iou=0.6315034086831719 and reward=-1.0 and discount=0.8953382542587164\n",
            "   |->> t=13 Diff-Reward (-1.0) for RIGHT:bbox transition: [120,  46,  67,  93] -> [122,  46,  67,  93] w/ P(a|s)=0.09060581773519516 and iou=0.66658521686011 and reward=-1.0 and discount=0.8863848717161292\n",
            "   |->> Assigned losses: [-2.4753625 -2.3680823 -2.3237932 -2.2990546 -2.305666  -2.2637537\n",
            " -2.2826402 -2.2243357 -2.2135956 -2.179146  -2.153056  -2.159951\n",
            " -2.1284199]\n",
            "\u001b[31m>> Total frame loss: -29.37685775756836\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 236 with src: [122,  46,  67,  93] and target: [128,  52,  75,  94]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0236.jpg\n",
            "|->> Beginning tracking for bbox:[122  46  67  93]\n",
            "   \u001b[33m|->> #49-th Action selection: 6/DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [122  48  67  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0976 0.0895 0.0819 0.0927 0.0923 0.0897 0.0937 0.0935 0.093  0.0892\n",
            " 0.0869], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09758884 0.08950879 0.08188397 0.09271152 0.09229603 0.08965536\n",
            " 0.09368413 0.09353706 0.09299573 0.08919233 0.0869462 ], argmax=0\n",
            "   \u001b[33m|->> #50-th Action selection: 3/2X RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [126  48  67  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0884 0.0906 0.0923 0.0914 0.0934 0.0894 0.0919 0.0941 0.0923 0.0893\n",
            " 0.0869], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08841071 0.09060379 0.09227309 0.09138089 0.09338136 0.08941142\n",
            " 0.09186347 0.09413829 0.0923485  0.0892634  0.08692502], argmax=7\n",
            "   \u001b[33m|->> #51-th Action selection: 0/LEFT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [124  48  67  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0929 0.0907 0.0887 0.0903 0.0915 0.0899 0.0933 0.0935 0.0929 0.0894\n",
            " 0.0869], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09294732 0.09068529 0.08866597 0.09034605 0.09146638 0.08987389\n",
            " 0.09328651 0.09353779 0.09285127 0.08940607 0.08693347], argmax=7\n",
            "   \u001b[33m|->> #52-th Action selection: 1/2X LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [120  48  67  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0834 0.0911 0.0965 0.0914 0.0928 0.0914 0.0927 0.0946 0.0926 0.0866\n",
            " 0.0868], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.0833917  0.0910797  0.09654872 0.09138716 0.09279776 0.09139504\n",
            " 0.09270524 0.09461011 0.09262338 0.08662231 0.08683887], argmax=2\n",
            "   \u001b[33m|->> #53-th Action selection: 7/2X DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [120  52  67  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0927 0.0881 0.0881 0.0913 0.0919 0.0912 0.094  0.0942 0.0925 0.0874\n",
            " 0.0887], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09272679 0.08814221 0.08809316 0.09127072 0.0918714  0.09119473\n",
            " 0.09395278 0.09417944 0.09247849 0.08737762 0.0887127 ], argmax=7\n",
            "|->> Revisiting bbox: [120  48  67  93]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [122,  46,  67,  93] -> [120,  52,  67,  93] (Target was [128,  52,  75,  94])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for DOWN:bbox transition: [122,  46,  67,  93] -> [122,  48,  67,  93] w/ P(a|s)=0.0936841294169426 and iou=0.6914161996943454 and reward=1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for 2X RIGHT:bbox transition: [122,  48,  67,  93] -> [126,  48,  67,  93] w/ P(a|s)=0.09138088673353195 and iou=0.7717449306296692 and reward=1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (1.0) for LEFT:bbox transition: [126,  48,  67,  93] -> [124,  48,  67,  93] w/ P(a|s)=0.09294731914997101 and iou=0.7306489444878812 and reward=1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (1.0) for 2X LEFT:bbox transition: [124,  48,  67,  93] -> [120,  48,  67,  93] w/ P(a|s)=0.0910796970129013 and iou=0.6539227895392279 and reward=1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (1.0) for 2X DOWN:bbox transition: [120,  48,  67,  93] -> [120,  52,  67,  93] w/ P(a|s)=0.09417944401502609 and iou=0.7040030792917629 and reward=1.0 and discount=0.96059601\n",
            "   |->> Assigned losses: [2.3678265 2.3687918 2.3284454 2.3248563 2.2694592]\n",
            "\u001b[92m>> Total frame loss: 11.659378051757812\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 237 with src: [120,  52,  67,  93] and target: [131,  50,  72,  97]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0237.jpg\n",
            "|->> Beginning tracking for bbox:[120  52  67  93]\n",
            "   \u001b[33m|->> #54-th Action selection: 3/2X RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [124  52  67  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0874 0.0885 0.0933 0.0905 0.0929 0.0915 0.0935 0.0928 0.0935 0.0875\n",
            " 0.0886], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08736905 0.08854049 0.09332726 0.09053908 0.09293395 0.09145265\n",
            " 0.09351561 0.09280504 0.09348641 0.08747493 0.08855549], argmax=6\n",
            "   \u001b[33m|->> #55-th Action selection: 6/DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [124  54  67  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0916 0.0887 0.0889 0.0894 0.0932 0.0915 0.0938 0.0927 0.093  0.0881\n",
            " 0.089 ], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09163606 0.08868726 0.08889131 0.08935431 0.0932494  0.09154575\n",
            " 0.09376799 0.09272086 0.09297948 0.08814368 0.08902396], argmax=6\n",
            "   \u001b[33m|->> #56-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [125  55  64  90]\n",
            "         |->> Action Probabilities (Rounded): [0.0904 0.0884 0.0901 0.0905 0.0947 0.0924 0.0917 0.0932 0.0927 0.0873\n",
            " 0.0886], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.09038063 0.08843017 0.09009524 0.09049736 0.09470809 0.09238876\n",
            " 0.09165246 0.0932023  0.09274396 0.08728422 0.08861686], argmax=4\n",
            "   \u001b[33m|->> #57-th Action selection: 3/2X RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [127  55  64  90]\n",
            "         |->> Action Probabilities (Rounded): [0.0911 0.0904 0.0904 0.0906 0.0922 0.0929 0.0934 0.0929 0.0936 0.083\n",
            " 0.0896], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09108625 0.09038842 0.0904317  0.09056089 0.09220993 0.09285197\n",
            " 0.09338762 0.0929101  0.09360745 0.08297413 0.08959159], argmax=8\n",
            "|->> Revisiting bbox: [127  55  64  90]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [120,  52,  67,  93] -> [127,  55,  64,  90] (Target was [131,  50,  72,  97])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for 2X RIGHT:bbox transition: [120,  52,  67,  93] -> [124,  52,  67,  93] w/ P(a|s)=0.09053907543420792 and iou=0.730844793713163 and reward=1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for DOWN:bbox transition: [124,  52,  67,  93] -> [124,  54,  67,  93] w/ P(a|s)=0.09376799315214157 and iou=0.730844793713163 and reward=1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (1.0) for SCALE DOWN:bbox transition: [124,  54,  67,  93] -> [125,  55,  64,  90] w/ P(a|s)=0.08728422224521637 and iou=0.69377990430622 and reward=1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (1.0) for 2X RIGHT:bbox transition: [125,  55,  64,  90] -> [127,  55,  64,  90] w/ P(a|s)=0.09056089073419571 and iou=0.7352941176470589 and reward=1.0 and discount=0.970299\n",
            "   |->> Assigned losses: [2.4019737 2.3432624 2.3900576 2.330399 ]\n",
            "\u001b[92m>> Total frame loss: 9.465692520141602\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 238 with src: [127,  55,  64,  90] and target: [128,  49,  76,  99]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/FaceOcc2/img/0238.jpg\n",
            "|->> Beginning tracking for bbox:[127  55  64  90]\n",
            "   \u001b[33m|->> #58-th Action selection: 1/2X LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [125  55  64  90]\n",
            "         |->> Action Probabilities (Rounded): [0.0918 0.0906 0.0888 0.0888 0.0944 0.0936 0.0921 0.0929 0.0933 0.085\n",
            " 0.0886], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.09175282 0.09062495 0.08884568 0.08878134 0.09440698 0.09363671\n",
            " 0.09214967 0.0929272  0.09330144 0.08499971 0.08857351], argmax=4\n",
            "   \u001b[33m|->> #59-th Action selection: 2/RIGHT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [126  55  64  90]\n",
            "         |->> Action Probabilities (Rounded): [0.0906 0.0877 0.0889 0.0897 0.0937 0.0931 0.0937 0.0937 0.0935 0.0855\n",
            " 0.0899], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09055169 0.08773955 0.08893237 0.08966521 0.09367094 0.09314802\n",
            " 0.09367017 0.09372119 0.09349686 0.08546862 0.08993541], argmax=7\n",
            "   \u001b[33m|->> #60-th Action selection: 6/DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [126  57  64  90]\n",
            "         |->> Action Probabilities (Rounded): [0.0978 0.0877 0.0809 0.0905 0.0932 0.0941 0.0937 0.0942 0.0936 0.0852\n",
            " 0.0891], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09784876 0.08774657 0.08086015 0.09051076 0.09321183 0.09406218\n",
            " 0.09367076 0.09420792 0.09363298 0.08515239 0.08909567], argmax=0\n",
            "   \u001b[33m|->> #61-th Action selection: 9/SCALE DOWN (P(a|s) = 0.0860000029206276)\u001b[0m\n",
            "      |->> Bounding box moves to: [127  58  62  87]\n",
            "         |->> Action Probabilities (Rounded): [0.0878 0.0888 0.0917 0.0904 0.0951 0.0932 0.0916 0.0938 0.0934 0.0856\n",
            " 0.0886], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.08783462 0.08881377 0.09169447 0.09035824 0.09511402 0.09321351\n",
            " 0.09156263 0.09382589 0.09336281 0.08557859 0.08864143], argmax=4\n",
            "   \u001b[33m|->> #62-th Action selection: 4/UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [127  56  62  87]\n",
            "         |->> Action Probabilities (Rounded): [0.0916 0.09   0.0879 0.0909 0.0932 0.0932 0.0939 0.0936 0.0937 0.082\n",
            " 0.09  ], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09155313 0.0900325  0.08788054 0.09092906 0.09322576 0.09319744\n",
            " 0.09392459 0.09359957 0.09367867 0.08197482 0.09000392], argmax=6\n",
            "   \u001b[33m|->> #63-th Action selection: 0/LEFT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [126  56  62  87]\n",
            "         |->> Action Probabilities (Rounded): [0.0899 0.091  0.0898 0.0913 0.0918 0.0934 0.0929 0.0939 0.0937 0.0836\n",
            " 0.0887], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.089882   0.09098121 0.08984487 0.09131339 0.0917564  0.0933529\n",
            " 0.09292909 0.09387679 0.093676   0.08364459 0.08874275], argmax=7\n",
            "   \u001b[33m|->> #64-th Action selection: 10/SCALE UP (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [125  54  64  89]\n",
            "         |->> Action Probabilities (Rounded): [0.0847 0.0916 0.0951 0.0916 0.0918 0.0937 0.0931 0.0951 0.0927 0.0815\n",
            " 0.0891], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08468268 0.09159494 0.09507886 0.09156106 0.09180832 0.09370893\n",
            " 0.09313844 0.09509137 0.09269408 0.08149373 0.08914761], argmax=7\n",
            "   \u001b[33m|->> #65-th Action selection: 2/RIGHT (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [126  54  64  89]\n",
            "         |->> Action Probabilities (Rounded): [0.0911 0.091  0.0873 0.0928 0.0929 0.0935 0.0944 0.0952 0.0935 0.0846\n",
            " 0.0838], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09110373 0.09102482 0.08728348 0.09283365 0.09288263 0.09352068\n",
            " 0.09435043 0.09519237 0.09350201 0.08455297 0.08375324], argmax=7\n",
            "   \u001b[33m|->> #66-th Action selection: 3/2X RIGHT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [128  54  64  89]\n",
            "         |->> Action Probabilities (Rounded): [0.0945 0.0907 0.084  0.0929 0.0932 0.0946 0.0938 0.0954 0.0931 0.0824\n",
            " 0.0854], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09446447 0.09066481 0.08401555 0.0929245  0.09315946 0.09455401\n",
            " 0.09382165 0.09543859 0.09310507 0.08243507 0.08541682], argmax=7\n",
            "   \u001b[33m|->> #67-th Action selection: 6/DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [128  56  64  89]\n",
            "         |->> Action Probabilities (Rounded): [0.0895 0.0912 0.0896 0.0897 0.0939 0.0938 0.0942 0.0951 0.092  0.0857\n",
            " 0.0852], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08950364 0.0911899  0.08962566 0.0896918  0.09392966 0.09383283\n",
            " 0.09421892 0.0951109  0.09198947 0.08574346 0.08516374], argmax=7\n",
            "|->> Revisiting bbox: [128  56  64  89]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [127,  55,  64,  90] -> [128,  56,  64,  89] (Target was [128,  49,  76,  99])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for 2X LEFT:bbox transition: [127,  55,  64,  90] -> [125,  55,  64,  90] w/ P(a|s)=0.09062495082616806 and iou=0.7043879907621247 and reward=1.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for RIGHT:bbox transition: [125,  55,  64,  90] -> [126,  55,  64,  90] w/ P(a|s)=0.08893237262964249 and iou=0.7242990654205608 and reward=1.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (1.0) for DOWN:bbox transition: [126,  55,  64,  90] -> [126,  57,  64,  90] w/ P(a|s)=0.09367076307535172 and iou=0.7242990654205608 and reward=1.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (1.0) for SCALE DOWN:bbox transition: [126,  57,  64,  90] -> [127,  58,  62,  87] w/ P(a|s)=0.08557859063148499 and iou=0.6972802522664564 and reward=1.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (1.0) for UP:bbox transition: [127,  58,  62,  87] -> [127,  56,  62,  87] w/ P(a|s)=0.09322576224803925 and iou=0.6972802522664564 and reward=1.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (1.0) for LEFT:bbox transition: [127,  56,  62,  87] -> [126,  56,  62,  87] w/ P(a|s)=0.0898820012807846 and iou=0.6780982073265783 and reward=1.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (1.0) for SCALE UP:bbox transition: [126,  56,  62,  87] -> [125,  54,  64,  89] w/ P(a|s)=0.08914760500192642 and iou=0.696829675266333 and reward=1.0 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (1.0) for RIGHT:bbox transition: [125,  54,  64,  89] -> [126,  54,  64,  89] w/ P(a|s)=0.08728347718715668 and iou=0.71643728901584 and reward=1.0 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (1.0) for 2X RIGHT:bbox transition: [126,  54,  64,  89] -> [128,  54,  64,  89] w/ P(a|s)=0.09292449802160263 and iou=0.7570441254651781 and reward=1.0 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (1.0) for DOWN:bbox transition: [128,  54,  64,  89] -> [128,  56,  64,  89] w/ P(a|s)=0.09421892464160919 and iou=0.7570441254651781 and reward=1.0 and discount=0.9135172474836408\n",
            "   |->> Assigned losses: [2.4010258 2.3956802 2.3208466 2.3853056 2.279236  2.29118   2.2759924\n",
            " 2.2729292 2.192412  2.1578503]\n",
            "\u001b[92m>> Total frame loss: 22.972457885742188\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "adnet_model = ADNET()\n",
        "adnet_model.build()\n",
        "YIFAN_WEIGHTS_PATH = \"yifanweights.mat\"\n",
        "weights = hdf5storage.loadmat(YIFAN_WEIGHTS_PATH)\n",
        "adnet_model = setWeights(adnet_model,weights,weights)\n",
        "adnet_model.layers[-3].trainable=False\n",
        "# adnet_model.layers[0].trainable=False\n",
        "# adnet_model.layers[1].trainable=False\n",
        "# adnet_model.layers[2].trainable=False\n",
        "# adnet_model.layers[3].trainable=False\n",
        "# adnet_model.layers[4].trainable=False\n",
        "# adnet_model.layers[5].trainable=False\n",
        "\n",
        "\n",
        "def epochs_train(model: ADNET, opt: tf.keras.optimizers.Optimizer, d: str, \n",
        "                 epochs: int=1, retry_count: int=1, action_strategy: str=\"max\",\n",
        "                 seq_length: int=10, randomize: bool=RANDOMIZE_TRAINING):\n",
        "\n",
        "  gt = get_ground_truths(\"%s/groundtruth_rect.txt\" % d)\n",
        "  frames = sorted(glob.glob(os.path.join('%s/img' % d, '*.jpg')))\n",
        "\n",
        "  losses = {}\n",
        "  bad_data_log = []\n",
        "  for e in range(epochs):\n",
        "\n",
        "    epoch_loss = []\n",
        "    frames = list(range(len(frames) - L))\n",
        "    if randomize: random.shuffle(frames)\n",
        "    for i in frames:\n",
        "\n",
        "      print(\"\\n\\n#############################################\")\n",
        "      print(\"Dataset={0} with {1} frames\".format(d, len(frames)))\n",
        "      print(\"#################################################\")\n",
        "      start_frame = i\n",
        "      end_frame = start_frame + seq_length\n",
        "\n",
        "      adnet_model, l = train(model, opt, d, start_frame, end_frame, \n",
        "                             retry_count=retry_count)\n",
        "      epoch_loss.append(l)\n",
        "      print(\"#################################################\")\n",
        "      print(\"#################################################\")\n",
        "    losses[e] = epoch_loss\n",
        "\n",
        "  print(\"Training complete\")\n",
        "  return model, losses\n",
        "\n",
        "\n",
        "\n",
        "rand_idx = 37\n",
        "d = ALL_DATASETS_LIST[rand_idx] \n",
        "\n",
        "# Issue list\n",
        "# blur car 3 has issues\n",
        "\n",
        "model, losses = epochs_train(adnet_model, Adam(learning_rate=LEARNING_RATE), \n",
        "                             d, epochs=N_EPOCHS, retry_count=N_TRAJECTORIES, \n",
        "                             randomize=RANDOMIZE_TRAINING)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "L1SsVnMeg8Up",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88b07e51-1da5-404d-d7cb-d83d29041301"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> \u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m(72)\u001b[0;36mquick_execute\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m     70 \u001b[0;31m          \u001b[0;34m\"Inputs to eager execution function cannot be Keras symbolic \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     71 \u001b[0;31m          \"tensors, but found {}\".format(keras_symbolic_tensors))\n",
            "\u001b[0m\u001b[0;32m---> 72 \u001b[0;31m    \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     73 \u001b[0;31m  \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     74 \u001b[0;31m  \u001b[0;32mreturn\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> u\n",
            "> \u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m(3877)\u001b[0;36mgather_nd_eager_fallback\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m   3875 \u001b[0;31m  \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Tparams\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_Tparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Tindices\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_Tindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m   3876 \u001b[0;31m  _result = _execute.execute(b\"GatherNd\", 1, inputs=_inputs_flat,\n",
            "\u001b[0m\u001b[0;32m-> 3877 \u001b[0;31m                             attrs=_attrs, ctx=ctx, name=name)\n",
            "\u001b[0m\u001b[0;32m   3878 \u001b[0;31m  \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m   3879 \u001b[0;31m    _execute.record_gradient(\n",
            "\u001b[0m\n",
            "ipdb> \n",
            "> \u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m(3854)\u001b[0;36mgather_nd\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m   3852 \u001b[0;31m          params, indices, name=name, ctx=_ctx)\n",
            "\u001b[0m\u001b[0;32m   3853 \u001b[0;31m    \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m-> 3854 \u001b[0;31m      \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m   3855 \u001b[0;31m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m   3856 \u001b[0;31m  _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
            "\u001b[0m\n",
            "ipdb> u\n",
            "> \u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m(5451)\u001b[0;36mgather_nd\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m   5449 \u001b[0;31m      \u001b[0;32mreturn\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m   5450 \u001b[0;31m    \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m-> 5451 \u001b[0;31m      \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m   5452 \u001b[0;31m  \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m   5453 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mbatch_gather_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> u\n",
            "> \u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m(1104)\u001b[0;36mop_dispatch_handler\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m   1102 \u001b[0;31m          \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m   1103 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m-> 1104 \u001b[0;31m          \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m   1105 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m   1106 \u001b[0;31m    \u001b[0madd_fallback_dispatch_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> u\n",
            "> \u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m(155)\u001b[0;36merror_handler\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m    153 \u001b[0;31m      \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    154 \u001b[0;31m    \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m--> 155 \u001b[0;31m      \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    156 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    157 \u001b[0;31m  \u001b[0;32mreturn\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> u\n",
            "> \u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m(5459)\u001b[0;36mgather_nd_v2\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m   5457 \u001b[0;31m\u001b[0;34m@\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_dispatch_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m   5458 \u001b[0;31m\u001b[0;32mdef\u001b[0m \u001b[0mgather_nd_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m-> 5459 \u001b[0;31m  \u001b[0;32mreturn\u001b[0m \u001b[0mgather_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m   5460 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m   5461 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> u\n",
            "> \u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m(1104)\u001b[0;36mop_dispatch_handler\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m   1102 \u001b[0;31m          \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m   1103 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m-> 1104 \u001b[0;31m          \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m   1105 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m   1106 \u001b[0;31m    \u001b[0madd_fallback_dispatch_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> u\n",
            "> \u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m(155)\u001b[0;36merror_handler\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m    153 \u001b[0;31m      \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    154 \u001b[0;31m    \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m--> 155 \u001b[0;31m      \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    156 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    157 \u001b[0;31m  \u001b[0;32mreturn\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> u\n",
            "> \u001b[0;32m<ipython-input-33-cb02ae61322b>\u001b[0m(59)\u001b[0;36mseqLosses\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m     57 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     58 \u001b[0;31m    \u001b[0mgather_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions_taken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m---> 59 \u001b[0;31m    \u001b[0mp_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgather_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     60 \u001b[0;31m    \u001b[0mp_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_by_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPROB_OFFSET\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mPROB_OFFSET\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# done to prevent 0 reward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     61 \u001b[0;31m    \u001b[0;31m# rewards = tf.convert_to_tensor(rewards, dtype=tf.float64)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> actions_taken\n",
            "[]\n",
            "ipdb> q\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "PYDEV DEBUGGER WARNING:\n",
            "sys.settrace() should not be used when the debugger is being used.\n",
            "This may cause the debugger to stop working correctly.\n",
            "If this is needed, please check: \n",
            "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
            "to see how to restore the debug tracing back correctly.\n",
            "Call Location:\n",
            "  File \"/usr/lib/python3.7/bdb.py\", line 357, in set_quit\n",
            "    sys.settrace(None)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%debug"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ufig = plt.figure()\n",
        "\n",
        "all_losses = np.concatenate([v for _, v in losses.items()])\n",
        "plt.plot(np.arange(len(all_losses)), all_losses) \n",
        "plt.xlabel('Number of Episodes')\n",
        "plt.ylabel('Avg Trajectory  Loss')"
      ],
      "metadata": {
        "id": "9LF9uTq5yY31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbUe72jpsol6"
      },
      "outputs": [],
      "source": [
        "# UNTESTED; uncomfirmed if works\n",
        "\n",
        "def move2Frame(model: ADNET, img: np.array, src_frame: int, src_bbox: np.array, \n",
        "               target_frame: int, target_bbox: np.array) -> np.array:\n",
        "  \n",
        "  bbox = src_bbox\n",
        "  actions = []\n",
        "  img = getFrame(dataset, target_frame) \n",
        "  target_bbox = gt[i]\n",
        "  for t in range(model.K):\n",
        "    patch = getPatch(img, bbox)\n",
        "    probs, conf_score = model(patch)\n",
        "    a_prob = tf.reshape(probs, (model.ACTION_DIM)) \n",
        "    a, bbox = selectMaxAction(np.array(img), bbox, a_prob)\n",
        "\n",
        "    actions.append(a)\n",
        "    model.updateActionHistory(a)\n",
        "    if isStop(a):\n",
        "        break  \n",
        "  \n",
        "  target_iou = calculate_IOU(bbox, target_bbox)   \n",
        "  return bbox, target_iou, actions\n",
        "\n",
        "\n",
        "def predict(model: ADNET, d: str, start_frame: int, end_frame: int):\n",
        "  gt = get_ground_truths(\"%s/groundtruth_rect.txt\" % d)\n",
        "  frames = sorted(glob.glob(os.path.join('%s/img' % d, '*.jpg'))) \n",
        "\n",
        "  ious = []\n",
        "  bbox = gt[start_frame]\n",
        "  model.clearActionHistory()\n",
        "  for i in range(start_frame+1, end_frame+1):\n",
        "    img = getFrame(dataset, i) \n",
        "    bbox, iou, actions = move2Frame(model, img, d)\n",
        "    ious.append(iou)\n",
        "  return model, ious\n",
        "\n",
        "\n",
        "def predict(model: ADNET, d: str):\n",
        "  gt = get_ground_truths(\"%s/groundtruth_rect.txt\" % d)\n",
        "  frames = sorted(glob.glob(os.path.join('%s/img' % d, '*.jpg'))) \n",
        "  return predict(model, d, 0, len(frames)-1)\n",
        "\n",
        "\n",
        "\n",
        "rand_idx = 11\n",
        "d = ALL_DATASETS_LIST[rand_idx] \n",
        "model, ious = predict(adnet_model, d)\n",
        "\n",
        "fig = plt.figure()\n",
        "for e in losses:\n",
        "  plt.plot(np.arange(len(ious)), ious) \n",
        "plt.xlabel('Frame')\n",
        "plt.ylabel('IOU')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMtzZ9r5nu8A"
      },
      "source": [
        "### Observations\n",
        "\n",
        "* The paper sums all sequence rewards. However, we found this to produce too much variance. We reduce_mean instead to address this. If we had"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmQvTRA7j9ET"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkTBunYkHcUQ"
      },
      "outputs": [],
      "source": [
        "print(erroneous_datasets)\n",
        "\n",
        "# !ls adnet_datasets/OTB/Diving/img/\n",
        "# ! wc -l adnet_datasets/OTB/Diving/groundtruth_rect.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0g-v8GupB9y"
      },
      "outputs": [],
      "source": [
        "def predict(model: tf.keras.Model,img: np.array,bbox: np.array) -> np.array:\n",
        "  ACTION_DIM=11\n",
        "  K=10\n",
        "  \n",
        "  action_hist = np.zeros((ACTION_DIM * K, 1))\n",
        "  seen_bboxes = set()\n",
        "  for t in range(K):\n",
        "    #model.setActionHistory(action_hist.reshape((1, 1, 1, ACTION_DIM * K)))\n",
        "    model.setActionHistory(action_hist.reshape((1,ACTION_DIM * K))) ### For ADNET_v2\n",
        "    patch = tf.image.resize(img[bbox[1]:(bbox[1] + bbox[3]), \n",
        "                                bbox[0]:(bbox[0] + bbox[2])], [112, 112])\n",
        "    patch = tf.reshape(patch, (1, 112, 112, 3))\n",
        "    a_prob = tf.reshape(model(patch)[0], (ACTION_DIM)) \n",
        "    a, bbox = selectAction(np.array(img), bbox, a_prob)\n",
        "    if isStop(a) or tuple(bbox) in seen_bboxes:\n",
        "      break\n",
        "\n",
        "    action_hist[t * ACTION_DIM + a] = 1 \n",
        "    seen_bboxes.add(tuple(bbox))\n",
        "  return bbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03dOCNAKz6sg"
      },
      "outputs": [],
      "source": [
        "def plotNpImageBBoxGT(img: np.array, bbox: np.array,gbbox: np.array) -> np.array:\n",
        "  '''\n",
        "  Plots the bounding box on an image and returns the bounding box\n",
        "  '''\n",
        "  fig, ax = plt.subplots()\n",
        "  x_pre,y_pre, w_pre, h_pre = bbox\n",
        "  x_gr,y_gr, w_gr, h_gr = gbbox\n",
        "  predicted_rect = patches.Rectangle((x_pre, y_pre), w_pre, h_pre, linewidth=1, edgecolor='r', facecolor='none')\n",
        "  gt_rect = patches.Rectangle((x_gr, y_gr), w_gr, h_gr, linewidth=1, edgecolor='b', facecolor='none')\n",
        "  ax.add_patch(predicted_rect)\n",
        "  ax.add_patch(gt_rect)\n",
        "  plt.imshow(img)\n",
        "  return bbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAvwFremUHsQ"
      },
      "outputs": [],
      "source": [
        "ALL_DATASETS_LIST = glob.glob(\"adnet_datasets/OTB/*\")\n",
        "j = random.randint(0, len(ALL_DATASETS_LIST)) \n",
        "dataset = ALL_DATASETS_LIST[j] \n",
        "frames = sorted(glob.glob(os.path.join('%s/img' % dataset, '*.jpg')))\n",
        "gt = get_ground_truths(\"%s/groundtruth_rect.txt\" % dataset)\n",
        "\n",
        "predicted_bbox = gt[0]\n",
        "for i, frame in enumerate(frames[1:]):\n",
        "  img = cv2.imread(frame)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  print(img.shape)\n",
        "  predicted_bbox=predict(model,img,predicted_bbox)\n",
        "  print(predicted_bbox)\n",
        "  gtbbox=gt[i]\n",
        "  plotNpImageBBoxGT(img,predicted_bbox,gtbbox)\n",
        "  #print(gtbbox)\n",
        "  #print(predicted_bbox)\n",
        "  break\n",
        "  #bbox = \n",
        "  #print(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_metrics( model: tf.keras.Model, model2:tf.keras.Model  ):\n",
        "    all_boxes = []\n",
        "    all_gt = []\n",
        "    time_perframe_for_each_video =[]\n",
        "    test_list = glob.glob(\"adnet_datasets/Test/*\")\n",
        "    d = ALL_DATASETS_LIST[rand_idx] \n",
        "    gt = get_ground_truths(\"%s/groundtruth_rect.txt\" % d)\n",
        "  \n",
        "    for  i in range(len(test_list)):  # start with 1\n",
        "      dataset = test_list[i]\n",
        "      print(dataset)\n",
        "      #frames = sorted(glob.glob(os.path.join('%s/img' % dataset, '*.jpg')))\n",
        "      gt = get_ground_truths(\"%s/groundtruth_rect.txt\" % dataset)     \n",
        "      all_gt.append(gt)\n",
        "      frames = sorted(glob.glob(os.path.join('%s/img' % dataset, '*.jpg')))\n",
        "      print(frames)\n",
        "      number_of_frames = len(frames)\n",
        "      #start_frame = random.randint(0, number_of_frames) maybe to test robustnes do not start always with first frame TRE\n",
        "      start_frame = 0\n",
        "      boxes_m1 =[]\n",
        "      boxes_m2 = []\n",
        "      time_perframe = []\n",
        "      predicted_box = gt[0]\n",
        "      predicted_box2 = gt[0]\n",
        "      start = time.time()\n",
        "      for f in range(len(frames) - start_frame):\n",
        "        img = cv2.imread(frames[f])\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        predicted_bbox=predict(model,img,predicted_box)\n",
        "        #predicted_bbox2 = predict(model, img,predicted_bbox) if we want to compare 2 models\n",
        "        boxes_m1.append(predicted_box)\n",
        "        #boxes_m2.append(predicted_bbox)\n",
        "      end = time.time()\n",
        "      time_perframe = (start-end)/len(frames)\n",
        "      all_boxes.append(boxes_m1)\n",
        "      time_perframe_for_each_video.append(time_perframe)\n",
        "    return all_boxes, all_gt , time_perframe_for_each_video\n",
        "\n",
        "\n",
        "\n",
        "all_boxes, all_gt , time_perframe_for_each_video = test_metrics(model , adnet_model)\n",
        "print (all_boxes)\n",
        "print(all_gt)"
      ],
      "metadata": {
        "id": "DhMMozN6J64i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9712yCAxLmtI"
      },
      "source": [
        "# TESTING & DEBUGGING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Me8c91RVoLvD"
      },
      "outputs": [],
      "source": [
        "# Update this with the appropriate dataset\n",
        "TEST_IMAGE_PATH = \"adnet_datasets/OTB/Couple/img/0082.jpg\"\n",
        "TEST_BBOX = get_ground_truths(\"adnet_datasets/OTB/Couple/groundtruth_rect.txt\")[82]\n",
        "TEST_IMAGE = cv2.imread(TEST_IMAGE_PATH)\n",
        "\n",
        "\n",
        "# Update the following two vars\n",
        "src_bbox = np.array([143, 131, 34, 87]) \n",
        "pred_bbox = np.array([138, 41, 32, 89])\n",
        "print(plotNpImageBBoxes(TEST_IMAGE, src_bbox, TEST_BBOX, pred_bbox))\n",
        "\n",
        "\n",
        "print(\"IOU: {0}\".format(calculate_IOU(pred_bbox, src_bbox)))\n",
        "\n",
        "print(\"Test bbox is: {0}\".format(TEST_BBOX))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzbeopDmi6q_"
      },
      "outputs": [],
      "source": [
        "# VERTICAL MOVEMENT TESTING \n",
        "TEST_IMAGE_PATH = \"adnet_datasets/OTB/Skater2/img/0005.jpg\"\n",
        "TEST_BBOX = get_ground_truths(\"adnet_datasets/OTB/Skater2/groundtruth_rect.txt\")[4]\n",
        "TEST_IMAGE = cv2.imread(TEST_IMAGE_PATH)\n",
        "\n",
        "# Test move down\n",
        "print(\"Down-shifted bounding box\")\n",
        "bbox = move2(img, TEST_BBOX, \"down\")\n",
        "print(plotNpImageBBox(img, bbox))\n",
        "\n",
        "print(\"Down-shifted bounding box\")\n",
        "bbox = move2(img, bbox, \"down\")\n",
        "print(plotNpImageBBox(img, bbox))\n",
        "\n",
        "print(\"Down-shifted bounding box\")\n",
        "bbox = move2(img, bbox, \"down\")\n",
        "print(plotNpImageBBox(img, bbox))\n",
        "\n",
        "print(\"Down-shifted bounding box\")\n",
        "bbox = move2(img, bbox, \"down\")\n",
        "print(plotNpImageBBox(img, bbox))\n",
        "\n",
        "\n",
        "print(\"Down-shifted bounding box\")\n",
        "bbox = move2(img, bbox, \"down\")\n",
        "print(plotNpImageBBox(img, bbox))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNBblMU8d4qh"
      },
      "outputs": [],
      "source": [
        "# HORIZONTAL MOVEMENT TESTING \n",
        "TEST_IMAGE_PATH = \"adnet_datasets/OTB/Skater2/img/0005.jpg\"\n",
        "TEST_BBOX = get_ground_truths(\"adnet_datasets/OTB/Skater2/groundtruth_rect.txt\")[4]\n",
        "TEST_IMAGE = cv2.imread(TEST_IMAGE_PATH)\n",
        "\n",
        "img, bbox = TEST_IMAGE, TEST_BBOX\n",
        "print(\"Original bounding box\")\n",
        "print(plotNpImageBBox(img, TEST_BBOX))\n",
        "\n",
        "# Test move left\n",
        "print(\"Left-shifted bounding box\")\n",
        "bbox = move2(img, TEST_BBOX, \"left\")\n",
        "print(plotNpImageBBox(img, bbox))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1MXfEC2IDNk"
      },
      "outputs": [],
      "source": [
        "# MOVEMENT TEST\n",
        "\n",
        "print(\"IOU between {1} and {2} is {0}\".format(calculate_IOU(np.array([143, 131,  34,  87]), np.array([138,  41,  32,  89])), [143, 131,  34,  87], [138,  41,  32,  89]))\n",
        "\n",
        "for i in range(11):\n",
        "  print(selectAction(np.zeros([300, 300, 3]), np.array([252, 65, 25, 30]), i))\n",
        "\n",
        "print(selectAction(np.zeros([300, 300, 3]), np.array([131,7,117,168]), 5))\n",
        "print(\"The following UP should do nothing because 0.03 * 168 * 2 is too large\")\n",
        "print(selectAction(np.zeros([300, 300, 3]), np.array([131,7,117,168]), 5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1j-Ud5nXofHE"
      },
      "outputs": [],
      "source": [
        "print(selectAction(np.zeros([450, 450, 3]), np.array([315,  0, 32,  35]), 5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBBRcPEAohhe"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "safe_reinforce.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}