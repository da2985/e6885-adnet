{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/da2985/e6885-adnet/blob/main/reinforce.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c1BWwgpSXW9"
      },
      "source": [
        "# Imports & Starting Configs\n",
        "\n",
        "Please use the following two lines to load from Google Drive\n",
        "\n",
        "If your file is not there, upload it to https://drive.google.com/drive/folders/1tsPKyB2E1nW8Qw--kZ9GaeGW2u2-XoV6?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vqT6TJ9DLT5v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e143dde2-d2b8-4a68-f95f-dd2be453d10a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# This must be run within a Google Colab environment \n",
        "from google.colab import drive  \n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2sTHMZwqNPlW"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "sys.path.append('/content/gdrive/EE6885')\n",
        "\n",
        "os.chdir(\"/content/gdrive/My Drive/EE6885\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EvlhZxrmdezd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2921e52-725e-4f56-82ae-f91c3b238174"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Basketball  Bolt  Car4\t    ClifBar  Doll      Fish    MotorRolling\n",
            "Bird2\t    Boy   CarDark   Crowds   Dudek     Human2  Skater\n",
            "BlurCar3    Car1  CarScale  Deer     FaceOcc2  Human6  Skating1\n"
          ]
        }
      ],
      "source": [
        "!ls adnet_datasets/OTB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nNOHmxvDD8wD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e93cfbc0-9254-4821-dc87-024acf1229b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hdf5storage\n",
            "  Downloading hdf5storage-0.1.18-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 972 kB/s \n",
            "\u001b[?25hCollecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.15.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 9.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py>=2.1 in /usr/local/lib/python3.7/dist-packages (from hdf5storage) (3.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from hdf5storage) (1.19.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.1->hdf5storage) (1.5.2)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons, hdf5storage\n",
            "Successfully installed hdf5storage-0.1.18 tensorflow-addons-0.15.0\n"
          ]
        }
      ],
      "source": [
        "pip install hdf5storage tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gNmhYpyeDLrQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "import tensorflow_probability as tfp\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow.experimental.numpy as tnp\n",
        "\n",
        "import cv2\n",
        "import glob\n",
        "import hdf5storage\n",
        "import math\n",
        "import random\n",
        "import re\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.patches as patches\n",
        "import scipy.io as sio\n",
        "\n",
        "import linecache\n",
        "\n",
        "from typing import Dict, List, Tuple\n",
        "from operator import add\n",
        "import copy\n",
        "\n",
        "from numpy.random import seed\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UsXgP5KrEGNW"
      },
      "outputs": [],
      "source": [
        " %load_ext autoreload \n",
        " %autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdgRU7dpw6t4"
      },
      "source": [
        "# Configurations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "G3xZrSk9XdEA"
      },
      "outputs": [],
      "source": [
        "#@markdown Network configurations\n",
        "LEARNING_RATE = 1e-4 #@param {type:\"number\"}\n",
        "GOAL_IOU = 0.7 #@param {type:\"number\"}\n",
        "\n",
        "# The length of the action buffer\n",
        "L = 10 #@param {type:\"number\"}\n",
        "# Max Trajectory Length \n",
        "MAX_TRAJECTORY_LENGTH =  10#@param {type:\"number\"}\n",
        "POLICY_TYPE = \"stochastic\" #@param [\"deterministic\", \"stochastic\"] {type:\"string\"}\n",
        "DROPOUT_4 = 0.5 #@param {type:\"number\"}\n",
        "DROPOUT_5 = 0.5 #@param {type:\"number\"}\n",
        "N_EPOCHS =  1#@param {type:\"number\"}\n",
        "\n",
        "# Number of retries to collect sequence loss sum (to reduce variance)\n",
        "N_RETRIES =   1#@param {type:\"number\"}\n",
        "\n",
        "# Randomizes the order in which frames are trained on from a video clip\n",
        "RANDOMIZE_TRAINING = False #@param {type:\"boolean\"}\n",
        "\n",
        "# The paper uses sum. I thought avg would help address giant swings, but the training was taking way too long\n",
        "# with negligible updates\n",
        "GRAD_ACCUM_SCHEME = \"sum\" #@param [\"avg\", \"sum\"] {type:\"string\"}\n",
        "\n",
        "# Use to avoid overly long trajectories. \n",
        "# During trajectory collection, we were not receiving \n",
        "# enough positvie signals\n",
        "PREMATURE_BREAK = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Loss/Reward Constants\n",
        "# This is a probability offset for adding noise since log(P(a|s)=1)=0\n",
        "PROB_OFFSET = 1e-5 #@param {type:\"number\"} \n",
        "# This is the discount factor\n",
        "GAMMA = 1 #@param {type:\"number\"}\n",
        "\n",
        "# The paper uses final_bbox where only the final bounding box placement is accounted\n",
        "# in reward calculation. individ_bbox individually assign rewards per each bounding box.\n",
        "REWARD_SCHEME = \"only_final_bbox\" #@param [\"only_final_bbox\", \"final_bbox\", \"individ_bbox\"] {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Bounding Box/Patch Constants (probably avoid touching)\n",
        "ALPHA = 0.03 #@param {type:\"number\"}\n",
        "MIN_WINDOW_SIZE = 10 #@param {type:\"number\"}\n",
        "PATCH_X = 112 #@param {type:\"number\"}\n",
        "PATCH_Y = 112 #@param {type:\"number\"}\n",
        "N_CHANNELS = 3 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown ---\n",
        "RANDOM_SEED = 6885\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AQ4YPvJCt9Dg"
      },
      "outputs": [],
      "source": [
        "seed(RANDOM_SEED)\n",
        "tf.random.set_seed(RANDOM_SEED)\n",
        "\n",
        "DATASET_PATH = \"adnet_datasets/OTB/*\" #@param {type:\"string\"}\n",
        "ALL_DATASETS_LIST = glob.glob(DATASET_PATH)\n",
        "\n",
        "\n",
        "# UPDATE ME; RANDOM IDX SELECTED FROM OUR OTB FOLDER\n",
        "TRAINING_IDX = [2,5,6,7,8]\n",
        "TEXTING_IDX = [3,4,10,11]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCB-wEWrfk6N"
      },
      "source": [
        "### Successful Configurations (Minimize Me Please)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "mKjyrVB3fdcT"
      },
      "outputs": [],
      "source": [
        "### SUCCESSFUL CONFIGS\n",
        "\n",
        "# 12/18 4:41 PM\n",
        "# #@markdown Network configurations\n",
        "# LEARNING_RATE = 1e-4 #@param {type:\"number\"}\n",
        "# # The length of the action buffer\n",
        "# L = 10 #@param {type:\"number\"}\n",
        "# # Max Trajectory Length \n",
        "# MAX_TRAJECTORY_LENGTH = 20 #@param {type:\"number\"}\n",
        "# POLICY_TYPE = \"stochastic\" #@param [\"deterministic\", \"stochastic\"] {type:\"string\"}\n",
        "# DROPOUT_4 = 0.5 #@param {type:\"number\"}\n",
        "# DROPOUT_5 = 0.5 #@param {type:\"number\"}\n",
        "# N_EPOCHS =  1#@param {type:\"number\"}\n",
        "\n",
        "# # Number of retries to collect sequence loss sum (to reduce variance)\n",
        "# N_RETRIES =  4 #@param {type:\"number\"}\n",
        "\n",
        "# # Randomizes the order in which frames are trained on from a video clip\n",
        "# RANDOMIZE_TRAINING = True #@param {type:\"boolean\"}\n",
        "# GRAD_ACCUM_SCHEME = \"sum\" #@param [\"avg\", \"sum\"] {type:\"string\"}\n",
        "# # The paper uses sum\n",
        "\n",
        "\n",
        "# #@markdown ---\n",
        "# #@markdown Loss/Reward Constants\n",
        "# # This is a probability offset for adding noise since log(P(a|s)=1)=0\n",
        "# PROB_OFFSET = 1e-5 #@param {type:\"number\"} \n",
        "# # This is the discount factor\n",
        "# GAMMA = 0.99 #@param {type:\"number\"}\n",
        "# REWARD_SCHEME = \"final_bbox\" #@param [\"final_bbox\", \"individ_bbox\"] {type:\"string\"}\n",
        "\n",
        "# #@markdown ---\n",
        "# #@markdown Bounding Box/Patch Constants (probably avoid touching)\n",
        "# ALPHA = 0.03 #@param {type:\"number\"}\n",
        "# MIN_WINDOW_SIZE = 10 #@param {type:\"number\"}\n",
        "# PATCH_X = 112 #@param {type:\"number\"}\n",
        "# PATCH_Y = 112 #@param {type:\"number\"}\n",
        "# N_CHANNELS = 3 #@param {type:\"number\"}\n",
        "\n",
        "# #@markdown ---\n",
        "# RANDOM_SEED = 6885\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8s6YHABjUG5"
      },
      "source": [
        "## Model Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cfRbj1tuEIyA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c285c85-5804-430c-93ae-a1ec1a3f57f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  0\n"
          ]
        }
      ],
      "source": [
        "class ADNET(tf.keras.Model):\n",
        "\n",
        "    ACTION_DIM = 11\n",
        "    K = 10\n",
        "    CONF_SCORE_DIM = 2\n",
        "\n",
        "    def __init__(self):\n",
        "        super(ADNET, self).__init__()\n",
        "\n",
        "        self.action_history = tf.keras.layers.Input(shape = (1,1, ADNET.ACTION_DIM * ADNET.K))\n",
        "\n",
        "        self.conv1 = tf.keras.layers.Conv2D(filters = 96, kernel_size = (7, 7), strides = (2, 2), padding = 'VALID', activation = 'relu', name = 'conv_1')\n",
        "        self.max1  = tf.keras.layers.MaxPooling2D(pool_size=(3,3), strides = (1, 1), padding = 'VALID')\n",
        "        self.conv2 = tf.keras.layers.Conv2D(filters = 256, kernel_size = (5, 5), strides = (2, 2), padding = 'VALID', activation = 'relu', name = 'conv_2')\n",
        "        self.max2  = tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides = (2, 2), padding = 'VALID')\n",
        "        self.conv3 = tf.keras.layers.Conv2D(filters = 512, kernel_size = (3, 3), strides = (2, 2), padding = 'VALID', activation = 'relu', name = 'conv_3')\n",
        "        self.max3  = tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides = (1, 1), padding = 'VALID')\n",
        "        \n",
        "        self.fc1 = tf.keras.layers.Conv2D(filters = 512, kernel_size = (3, 3), padding = 'VALID', activation = 'relu', name = 'fc1')\n",
        "        self.fc2 = tf.keras.layers.Conv2D(filters = 512, kernel_size = (1,1), padding = 'VALID', activation = 'relu', name = 'fc2')\n",
        "        self.fc3 = tf.keras.layers.Conv2D(filters = 11, kernel_size = (1,1), padding = 'VALID', name = 'fc3',activation=\"softmax\")\n",
        "        self.fc4 = tf.keras.layers.Conv2D(filters = 2, kernel_size = (1,1), padding = 'VALID', name = 'fc4',activation=\"softmax\")\n",
        "\n",
        "        # TODO: ADD A SEED\n",
        "        self.dropout1=tf.keras.layers.Dropout(DROPOUT_4)\n",
        "        self.dropout2=tf.keras.layers.Dropout(DROPOUT_5)\n",
        "        \n",
        "\n",
        "    def build(self):\n",
        "      super(ADNET, self).build((None, 112, 112, 3))\n",
        "      self.action_history = np.zeros(shape = (1,1,1,110))\n",
        "\n",
        "\n",
        "    def call(self, input_tensor, training=False):\n",
        "        x = self.conv1(input_tensor)\n",
        "        x = self.max1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.max2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.max3(x)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = tf.keras.layers.Concatenate(axis=-1)([x, self.action_history])\n",
        "        action = self.fc3(x)\n",
        "        confidence = self.fc4(x)\n",
        "        return [action, confidence]\n",
        "\n",
        "\n",
        "    def compile(self, optimizer):\n",
        "   \t\tsuper().compile(optimizer, loss={\n",
        "         'output_1':tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "         'output_2': tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "         })\n",
        "     \n",
        "    def getEmbedding(self,input_tensor):\n",
        "        x = self.conv1(input_tensor)\n",
        "        x = self.max1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.max2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.max3(x)\n",
        "        return tf.reshape(x,(-1,))\n",
        "\n",
        "    def getFC1(self,input_tensor):\n",
        "        x = self.conv1(input_tensor)\n",
        "        x = self.max1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.max2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.max3(x)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "    def setActionHistory(self, action_history):\n",
        "      self.action_history = action_history.reshape(\n",
        "          (1, 1, 1, ADNET.ACTION_DIM * ADNET.K))\n",
        "\n",
        "    def updateActionHistory(self, a: int=8) -> tnp.ndarray:\n",
        "      '''\n",
        "      Left-to-right FIFO queue of actions\n",
        "      '''\n",
        "      ah = np.array(self.action_history).flatten()\n",
        "      ah[ADNET.ACTION_DIM:] = ah[:-ADNET.ACTION_DIM]\n",
        "      ah[:ADNET.ACTION_DIM] = 0 \n",
        "      ah[a] = 1\n",
        "      self.setActionHistory(ah)\n",
        "      return ah\n",
        "\n",
        "    def clearActionHistory(self):\n",
        "      self.action_history = tf.zeros((1, 1, 1, ADNET.ACTION_DIM * ADNET.K))\n",
        "\n",
        "    def getPrettyActionHistory(self):\n",
        "      action_hist = tf.reshape(model.action_history, [-1])\n",
        "      sbuffer = \"[\"\n",
        "      for i, x in enumerate(action_hist):\n",
        "        if i > 0 and i % model.ACTION_DIM == 0:\n",
        "          sbuffer+= \"\\x1b[35m,\\x1b[0m\"\n",
        "        if x == 1:\n",
        "          sbuffer += \"\\x1b[35m{0}\\x1b[0m\".format(int(x))\n",
        "        else:\n",
        "          sbuffer += \"{0}\".format(int(x))\n",
        "      sbuffer += \"]\"\n",
        "      return sbuffer \n",
        "\n",
        "\n",
        "    def debugModelSummary(self):\n",
        "      '''\n",
        "      call model.debugModelSummary().summary() to get around the inconvenience \n",
        "      from model.summary() returning 'multiple' for each layer's output shape\n",
        "      '''\n",
        "      dummyInput = tf.keras.layers.Input(shape = (112,112,3))\n",
        "      return tf.keras.Model(inputs=[dummyInput], outputs = self.call(dummyInput))\n",
        "\n",
        "def setAllWeights(model, weights):\n",
        "  model.layers[0].set_weights([weights[\"conv1f\"], tf.reshape(weights[\"conv1b\"],(96,))])\n",
        "  model.layers[2].set_weights([weights[\"conv2f\"], tf.reshape(weights[\"conv2b\"],(256,))])\n",
        "  model.layers[4].set_weights([weights[\"conv3f\"], tf.reshape(weights[\"conv3b\"],(512,))])\n",
        "  model.layers[6].set_weights([weights[\"fc4f\"], tf.reshape(weights[\"fc4b\"],(512,))])\n",
        "  model.layers[7].set_weights([weights[\"fc5f\"], tf.reshape(weights[\"fc5b\"],(512,))])\n",
        "  model.layers[8].set_weights([weights[\"fc6_1f\"], tf.zeros(11)])\n",
        "  model.layers[9].set_weights([weights[\"fc6_2f\"], tf.zeros(2)])\n",
        "\n",
        "\n",
        "def setWeights(model, weights, weights2):\n",
        "  model.layers[0].set_weights([weights2[\"conv1f\"],tf.reshape(weights2[\"conv1b\"],(96,))])\n",
        "  model.layers[2].set_weights([weights2[\"conv2f\"],tf.reshape(weights2[\"conv2b\"],(256,))])\n",
        "  model.layers[4].set_weights([weights2[\"conv3f\"],tf.reshape(weights2[\"conv3b\"],(512,))])\n",
        "  \n",
        "  model.layers[6].set_weights([weights[\"fc4f\"],tf.reshape(weights[\"fc4b\"],(512,))])\n",
        "  model.layers[7].set_weights([weights[\"fc5f\"],tf.reshape(weights[\"fc5b\"],(512,))])\n",
        "  model.layers[8].set_weights([weights[\"fc6_1f\"],tf.zeros(11)])\n",
        "  model.layers[9].set_weights([weights[\"fc6_2f\"],tf.zeros(2)])\n",
        "  \n",
        "  return model\n",
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "WwHHmGrxq-b6"
      },
      "outputs": [],
      "source": [
        "class ADNET_v2(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(ADNET_v2, self).__init__()\n",
        "\n",
        "        #self.action_history = tf.keras.layers.Input(shape = (1,1,110))\n",
        "        self.action_history = tf.keras.layers.Input(shape = (110))\n",
        "\n",
        "        self.resnet=tf.keras.applications.ResNet50V2(include_top=False,weights=\"imagenet\",input_shape=(112,112,3),pooling=\"max\")\n",
        "        #self.resnet = tf.keras.applications.ResNet50V2(include_top=False,weights=\"imagenet\",input_shape=(112,112,3),pooling=None)\n",
        "        #self.conv1 = tf.keras.layers.Conv2D(filters = 128, kernel_size = (4,4), padding = 'VALID', name = 'fc4',activation=\"relu\")\n",
        "        \n",
        "        self.fc1 = tf.keras.layers.Dense(512,kernel_initializer='glorot_uniform',activation = 'relu', name = 'fc1')\n",
        "        self.fc2 = tf.keras.layers.Dense(512,kernel_initializer='glorot_uniform', activation = 'relu', name = 'fc2')\n",
        "        self.fc3 = tf.keras.layers.Dense(11,kernel_initializer='glorot_uniform', name = 'fc3',activation=\"softmax\")\n",
        "        self.fc4 = tf.keras.layers.Dense(2,kernel_initializer='glorot_uniform',name = 'fc4',activation=\"softmax\")\n",
        "\n",
        "        self.dropout1=tf.keras.layers.Dropout(0)\n",
        "        self.dropout2=tf.keras.layers.Dropout(0)\n",
        "        \n",
        "\n",
        "    def build(self, action_history):\n",
        "      super(ADNET_v2, self).build((None, 112, 112, 3))\n",
        "      self.action_history=action_history\n",
        "      self.resnet.trainable = False\n",
        "\n",
        "\n",
        "    def setActionHistory(self, action_history):\n",
        "      self.action_history=action_history\n",
        "\n",
        "\n",
        "    def call(self, input_tensor, training=False):\n",
        "        x = self.resnet(input_tensor)\n",
        "        #x = self.conv1(x)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x=  self.dropout1(x)\n",
        "        x = self.fc2(x)\n",
        "        x=  self.dropout2(x)\n",
        "        x = tf.keras.layers.Concatenate(axis=-1)([x, self.action_history])\n",
        "        action = self.fc3(x)\n",
        "        confidence = self.fc4(x)\n",
        "        return [action, confidence]\n",
        "\n",
        "     \n",
        "    def debugModelSummary(self):\n",
        "      '''\n",
        "      call model.debugModelSummary().summary() to get around the inconvenience \n",
        "      from model.summary() returning 'multiple' for each layer's output shape\n",
        "      '''\n",
        "      dummyInput = tf.keras.layers.Input(shape = (112,112,3))\n",
        "      return tf.keras.Model(inputs=[dummyInput], outputs = self.call(dummyInput))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcjMuA1EjRsE"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xY2WCmjC2gLN"
      },
      "source": [
        "### Plotting & Debugging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "NtQ22_87T8MQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "4b703391-f25c-4420-9c40-57fd33ff4e56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[290 239  34  81]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "def get_ground_truths(ground_truth_file: str) -> np.array:\n",
        "  '''\n",
        "  Use me to convert a ground_truth_file to a numpy array\n",
        "  '''\n",
        "  with open(ground_truth_file) as f:\n",
        "    ground_truths = f.readlines()\n",
        "    to_nparray = lambda s: np.array(re.findall('\\d+', s), dtype=int)\n",
        "    truths = list(map(to_nparray, ground_truths))\n",
        "    return np.asarray(truths)\n",
        "  return None\n",
        "\n",
        "def plotNpImageBBox(img: np.array, bbox: np.array) -> np.array:\n",
        "  '''\n",
        "  Plots the bounding box on an image and returns the bounding box\n",
        "  '''\n",
        "  fig, ax = plt.subplots()\n",
        "  x, y, w, h = bbox\n",
        "  rect = patches.Rectangle((x, y), w, h, linewidth=1, edgecolor='r', facecolor='none')\n",
        "  ax.add_patch(rect)\n",
        "  plt.imshow(img)\n",
        "  return bbox\n",
        "\n",
        "def plotNpImageBBoxes(img: np.array, src_bbox: np.array, target_bbox: np.array, \n",
        "                      pred_bbox: np.array) -> np.array:\n",
        "  '''\n",
        "  Plots the bounding boxes on an image and returns the bounding box\n",
        "  '''\n",
        "  fig, ax = plt.subplots()\n",
        "  x1, y1, w1, h1 = src_bbox\n",
        "  x2, y2, w2, h2 = target_bbox\n",
        "  x3, y3, w3, h3 = pred_bbox\n",
        "  rect1 = patches.Rectangle((x1, y1), w1, h1, linewidth=1, edgecolor='b', facecolor='none')\n",
        "  rect2 = patches.Rectangle((x2, y2), w2, h2, linewidth=1, edgecolor='g', facecolor='none')\n",
        "  rect3 = patches.Rectangle((x3, y3), w3, h3, linewidth=1, edgecolor='r', facecolor='none')\n",
        "  ax.add_patch(rect1)\n",
        "  ax.add_patch(rect2)\n",
        "  ax.add_patch(rect3)\n",
        "  plt.imshow(img)\n",
        "  return pred_bbox  \n",
        "\n",
        "def plotImageBBox(img: str, bbox: np.array) -> np.array:\n",
        "  '''\n",
        "  Plots the bounding box on an image (from given filepath) and returns the \n",
        "  bounding box\n",
        "  '''\n",
        "  img = cv2.imread(img)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  plotNpImageBBox(img, bbox)\n",
        "  return bbox\n",
        "\n",
        "def plotDatasetImageBBox(dataset: str, frame_no: int) -> Tuple[np.array, int]:\n",
        "  '''\n",
        "  Plot an image's bounding box. Returns the ground truth and frame number.\n",
        "  WORKS FOR OTB100\n",
        "  '''\n",
        "  imgs = sorted(glob.glob(\"{0}/img/*\".format(dataset)))\n",
        "  gt = get_ground_truths(\"{0}/groundtruth_rect.txt\".format(dataset))\n",
        "  plotImageBBox(imgs[frame_no], gt[frame_no])\n",
        "  return gt[frame_no], frame_no\n",
        "\n",
        "\n",
        "print(plotDatasetImageBBox(\"adnet_datasets/OTB/Basketball\", 50)[0])\n",
        "# print(plotDatasetImageBBox(\"adnet_datasets/OTB/BlurBody\", 10)[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX5bfwFm2c80"
      },
      "source": [
        "### Movement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "VzDdHq04ERNg"
      },
      "outputs": [],
      "source": [
        "STOP_ACTION_INDEX = 8\n",
        "\n",
        "def getFrame(f_path: str) -> np.array:\n",
        "  print(\"Frame path: {0}\".format(f_path))\n",
        "  img = cv2.imread(f_path)\n",
        "  return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\n",
        "def calculate_IOU(bbox1: np.array, bbox2: np.array):\n",
        "    x1, y1, w1, h1 = bbox1\n",
        "    x2, y2, w2, h2 = bbox2\n",
        "           \n",
        "    i_x1 = max(x1, x2)\n",
        "    i_y1 = max(y1, y2)\n",
        "    i_x2 = min(x1 + w1, x2 + w2)\n",
        "    i_y2 = min(y1 + h1, y2 + h2)\n",
        "    if i_x1 >= i_x2 or i_y1 >= i_y2:\n",
        "      return 0.0\n",
        "\n",
        "    intersection_area = (i_x2 - i_x1) * (i_y2 - i_y1)\n",
        "    box1_area = w1 * h1\n",
        "    box2_area = w2 * h2\n",
        "    \n",
        "    iou = intersection_area / float(box1_area + box2_area - intersection_area)\n",
        "    return iou\n",
        "\n",
        "\n",
        "def standardize_bbox(img: np.array, bbox: np.array):\n",
        "  '''\n",
        "  Refits the bounding box to ensure that it is valid. X and Y get clipped first.\n",
        "  Assumes reasonable bounding boxes and solely for the bad data we found in\n",
        "  our ground truth dataset\n",
        "  '''\n",
        "  x, y, w, h = bbox\n",
        "  nx, ny, nw, nh = bbox\n",
        "\n",
        "  is_invalid = False\n",
        "  import pdb\n",
        "  # pdb.set_trace()\n",
        "  if x < 0 or x + w >= img.shape[1]:\n",
        "    w = np.clip(w, MIN_WINDOW_SIZE, img.shape[1])\n",
        "    # clip whichever keeps the most area    \n",
        "    x1 = np.clip(x, 0, img.shape[1] - 1)\n",
        "    w1 = np.clip(w, MIN_WINDOW_SIZE, img.shape[1] - x1)\n",
        "    x2 = np.clip(x, 0, img.shape[1] - w)\n",
        "    w2 = np.clip(w, MIN_WINDOW_SIZE, img.shape[1])\n",
        "    nx, nw = (x1, w1) if x1 + w1 > x2 + w2 else (x2, w2)\n",
        "    is_invalid = True\n",
        "\n",
        "  if y < 0 or y + h >= img.shape[0]:\n",
        "    h = np.clip(h, MIN_WINDOW_SIZE, img.shape[0])\n",
        "    # clip whichever keeps the most area\n",
        "    y1 = np.clip(y, 0, img.shape[0] - 1)\n",
        "    h1 = np.clip(h, MIN_WINDOW_SIZE, img.shape[0] - y1)\n",
        "    y2 = np.clip(y, 0, img.shape[0] - h)\n",
        "    h2 = np.clip(h, MIN_WINDOW_SIZE, img.shape[0])\n",
        "    ny, nh = (y1, h1) if y1 + h1 > y2 + h2 else (y2, h2)\n",
        "    is_invalid = True\n",
        "  \n",
        "  stdzd_bbox = np.array([nx, ny, nw, nh])\n",
        "  if is_invalid: \n",
        "    print(\"WARNING: Bounding box: {0} had to be standardized to {1}\".format(bbox, stdzd_bbox))\n",
        "  return stdzd_bbox\n",
        "\n",
        "\n",
        "def move(image: np.array, bbox: np.array, action: str, \n",
        "         stride_magnitude: int=1) -> np.array:\n",
        "  '''\n",
        "  Returns the new bounding box after taking an action: \n",
        "  {\"left\", \"right\", \"up\", \"down\"}. Use stride to indicate the step size.\n",
        "  '''\n",
        "  if action not in set([\"left\", \"right\", \"up\", \"down\"]):\n",
        "    raise RuntimeError(\"Invalid action taken :(\") \n",
        "  \n",
        "  x, y, w, h = bbox\n",
        "  if action in set([\"left\", \"right\"]):\n",
        "    step = max(1, int(ALPHA * w)) * stride_magnitude * (-1 if action==\"left\" else 1)\n",
        "    x = min(max(0, int(x + step)), int(image.shape[1] - w - 1)) \n",
        "  else:\n",
        "    step = max(1, int(ALPHA * h)) * stride_magnitude * (-1 if action==\"up\" else 1)\n",
        "    y = min(max(0, int(y + step)), int(image.shape[0] - h - 1)) \n",
        "\n",
        "  return np.array([x, y, w, h])\n",
        "\n",
        "\n",
        "def scale(image: np.array, bbox: np.array, scaleUp: bool):\n",
        "  x, y, w, h = bbox\n",
        "  deltaW, deltaH = max(2, ALPHA * w), max(2, ALPHA * h)\n",
        "  if not scaleUp: \n",
        "    deltaW *= -1\n",
        "    deltaH *= -1\n",
        "  nw = min(image.shape[1], max(MIN_WINDOW_SIZE, int(w + deltaW))) \n",
        "  nh = min(image.shape[0], max(MIN_WINDOW_SIZE, int(h + deltaH)))\n",
        "  \n",
        "\n",
        "  x = max(0, min(int(x - deltaW / 2), int(image.shape[1] - w - 1)))\n",
        "  y = max(0, min(int(y - deltaH / 2), int(image.shape[0] - h - 1)))\n",
        "  return np.array([x, y, nw, nh])\n",
        "\n",
        "\n",
        "def selectAction(img: np.array, bbox: np.array, index: int): \n",
        "  if index == 0 :\n",
        "    bbox = move(img, bbox, \"left\")\n",
        "  elif index == 1 :\n",
        "    bbox = move(img, bbox, \"left\", stride_magnitude=2)\n",
        "  elif index == 2 :\n",
        "    bbox = move(img, bbox, \"right\")\n",
        "  elif index == 3 :\n",
        "    bbox = move(img, bbox, \"right\", stride_magnitude=2)  \n",
        "  elif index == 4 :\n",
        "    bbox = move(img, bbox, \"up\")  \n",
        "  elif index == 5 :\n",
        "    bbox = move(img, bbox, \"up\", stride_magnitude=2)\n",
        "  elif index == 6 :\n",
        "    bbox = move(img, bbox, \"down\")\n",
        "  elif index == 7 :\n",
        "    bbox = move(img, bbox, \"down\", stride_magnitude=2)\n",
        "  elif index == 8:\n",
        "    bbox = bbox\n",
        "  elif index == 9 :\n",
        "    bbox = scale(img, bbox, False)     \n",
        "  elif index == 10 :\n",
        "    bbox = scale(img, bbox, True)    \n",
        "  else:\n",
        "    raise ValueError(\"Invalid action provided: {0}\".format(index))\n",
        "\n",
        "  x, y, w, h = bbox\n",
        "  # some of the data is just invalid :/\n",
        "  # assert 0 <= x <= img.shape[1] - w, \"x:{0}, w:{1} is out of bounds: [0, {2}]\".format(x, w, img.shape[1])\n",
        "  # assert 0 <= y <= img.shape[0] - h, \"y:{0}, h:{1} is out of bounds: [0, {2}]\".format(y, h, img.shape[0])\n",
        "  # assert MIN_WINDOW_SIZE <= w <= img.shape[1], \"w:{0}, is invalid\".format(w)\n",
        "  # assert MIN_WINDOW_SIZE <= h <= img.shape[0], \"h:{0} is invalid\".format(h)\n",
        "  return index, bbox\n",
        "\n",
        "\n",
        "def human_readable_action(index: int) -> str:\n",
        "  '''\n",
        "  Map action numbers to human readable strings\n",
        "  '''\n",
        "  def _get_action(index:int) -> str:\n",
        "    if index == 0:\n",
        "      return \"left\"\n",
        "    elif index == 1:\n",
        "      return \"2x left\"\n",
        "    elif index == 2:\n",
        "      return \"right\"\n",
        "    elif index == 3:\n",
        "      return \"2x right\"\n",
        "    elif index == 4:\n",
        "      return \"up\"\n",
        "    elif index == 5:\n",
        "      return \"2x up\"\n",
        "    elif index == 6:\n",
        "      return \"down\"\n",
        "    elif index == 7:\n",
        "      return \"2x down\"\n",
        "    elif index == 8:\n",
        "      return \"stop\"\n",
        "    elif index == 9:\n",
        "      return \"scale down\"\n",
        "    elif index == 10 :\n",
        "      return \"scale up\"\n",
        "  return _get_action(index).upper()\n",
        "\n",
        "\n",
        "def getAction(img: np.array, bbox: np.array, action_probs: np.array):  \n",
        "  a = -1\n",
        "  if POLICY_TYPE == \"deterministic\":\n",
        "    a = tf.math.argmax(action_probs)\n",
        "  else:\n",
        "    action_probs = np.array(action_probs) + PROB_OFFSET\n",
        "    action_probs /= action_probs.sum()\n",
        "  \n",
        "    a = np.random.choice(np.arange(len(action_probs)), p=action_probs)\n",
        "  return selectAction(img, bbox, a)\n",
        "\n",
        "\n",
        "def isStop(action: int):\n",
        "  return action == STOP_ACTION_INDEX\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLxdpmQ5jOjL"
      },
      "source": [
        "# REINFORCE Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CP9qJBgVq5B"
      },
      "source": [
        "### Trajectory Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Id7dQxPDVtJ_"
      },
      "outputs": [],
      "source": [
        "def getIndividScore(bbox1: np.array, bbox2: np.array, gt: np.array) -> float:\n",
        "\n",
        "  prevIou = calculate_IOU(bbox1, gt) \n",
        "  nextIou = calculate_IOU(bbox2, gt)\n",
        "  x1, y1 = bbox1[:2]\n",
        "  x2, y2 = bbox2[:2]\n",
        "  xg, yg = gt[:2]\n",
        "\n",
        "  # if prevIou == nextIou: EXPERIMENTED WITH USING EUCLIDEAN DISTANCE\n",
        "  #   return -1 * (_dist(x2, y2, xg, yg) - _dist(x1, y1, xg, yg))\n",
        "  result = nextIou - prevIou \n",
        "  return result \n",
        "\n",
        "def seqLosses(action_probs: List[np.array], actions_taken: List[int], \n",
        "              bboxes: List[np.array], \n",
        "              target_bbox: np.array) -> np.array:\n",
        "\n",
        "    assertMsg = \"Invalid trajectory: actions taken ({0}) + 1 != Bboxes length ({1})\".format(\n",
        "              len(actions_taken), len(bboxes)) \n",
        "    assert len(actions_taken) + 1 == len(bboxes), assertMsg\n",
        "          \n",
        "    src_bbox = np.array(bboxes[0])\n",
        "    end_bbox = np.array(bboxes[-1])\n",
        "    print(\"\\x1b[34m>> Calculating frame loss : {0} -> {1} (Target was {2})\\x1b[0m\".format(\n",
        "            np.array2string(src_bbox, separator=', '),\n",
        "            np.array2string(end_bbox, separator=', '),\n",
        "            np.array2string(target_bbox, separator=', ')))\n",
        "    rewards = np.zeros(len(actions_taken))\n",
        "    discounts = np.zeros(len(actions_taken))\n",
        "    for i, a in enumerate(actions_taken):\n",
        "      prev_bbox = np.array(bboxes[i])\n",
        "      next_bbox = np.array(bboxes[i+1])\n",
        "      ###################### CHANGE REWARD CALCULATION HERE ####################\n",
        "      if REWARD_SCHEME == \"final_bbox\":\n",
        "        rewards[i] = 1 if calculate_IOU(end_bbox, target_bbox) > GOAL_IOU\\\n",
        "                      else -1      \n",
        "      elif REWARD_SCHEME == \"only_final_bbox\" and i == len(actions_taken) - 1:\n",
        "        rewards[i] = 1 if calculate_IOU(end_bbox, target_bbox) > GOAL_IOU\\\n",
        "                      else -1      \n",
        "      else:\n",
        "        if isStop(a):\n",
        "          rewards[i] = 1 if calculate_IOU(next_bbox, target_bbox) > GOAL_IOU else -1\n",
        "        else:\n",
        "          rewards[i] = getIndividScore(prev_bbox, next_bbox, target_bbox) \n",
        "      ###################### CHANGE REWARD CALCULATION UP ABOVE ################\n",
        "      prob_a = action_probs[i][a]\n",
        "      discounts[i] = GAMMA ** i\n",
        "      print(\"   |->> t={0} {1}-Reward ({2}) for {3}:bbox transition: {4} -> {5} w/ P(a|s)={6} and iou={7} and reward={8} and discount={9}\"\n",
        "            .format(i+1, \"Stop\" if isStop(a) else \"Diff\", \n",
        "                    np.around(rewards[i], decimals=3), \n",
        "                    human_readable_action(a).upper(),\n",
        "                    np.array2string(prev_bbox, separator=', '),\n",
        "                    np.array2string(next_bbox, separator=', '), prob_a, \n",
        "                    calculate_IOU(next_bbox, target_bbox), \n",
        "                    rewards[i], discounts[i]), \n",
        "            )\n",
        "    \n",
        "    gather_idx = [[i, a] for i, a in enumerate(actions_taken)]\n",
        "    p_a = tf.gather_nd(tf.stack(action_probs), gather_idx)\n",
        "    p_a = tf.clip_by_value(p_a, PROB_OFFSET, 1 - PROB_OFFSET) # done to prevent 0 reward   \n",
        "    \n",
        "    entropy = -1 * tf.math.reduce_sum((tf.math.log(action_probs) * action_probs), \n",
        "                                 axis=1) \n",
        "    \n",
        "    discount = tf.convert_to_tensor(discounts, dtype=tf.float32)\n",
        "    losses = -1 * (discount * rewards * tf.math.log(p_a))\n",
        "    \n",
        "    \n",
        "    print(\"   |->> Assigned losses: {0}\".format(losses))\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMujgGmUVu4k"
      },
      "source": [
        "### Tracking Procedure\n",
        "\n",
        "* This function collects trajectories either via argmax deterministic policy or sampling from a stochastic policy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "EqN0GHI5VlAM"
      },
      "outputs": [],
      "source": [
        "def getPatch(img: np.array, bbox: np.array) -> tf.Tensor:\n",
        "  def _patch(img: np.array, bbox: np.array) -> np.array:\n",
        "    x, y, w, h, = bbox\n",
        "    return img[y : (y + h), x : (x + w)]\n",
        "      \n",
        "  patch = tf.image.resize(_patch(img, bbox), [PATCH_X, PATCH_Y])\n",
        "  return tf.reshape(patch, (1, PATCH_X, PATCH_Y, N_CHANNELS))\n",
        "\n",
        "\n",
        "def tracking(model: ADNET, img: np.array, bbox: np.array,\n",
        "             t: int, target_bbox: np.array, \n",
        "             tracking_length: int= MAX_TRAJECTORY_LENGTH):\n",
        "    \"\"\" \n",
        "    Runs tracking until # actions > MAX_ACTIONS_SEQ_LIMIT, STOP is taken, or\n",
        "    oscillation occurs.\n",
        "    \"\"\"\n",
        "    print(\"|->> Beginning tracking for bbox:{0}\".format(bbox))    \n",
        "    patch = getPatch(img, bbox)\n",
        "    actions_taken = []\n",
        "    action_probs = []\n",
        "    bboxes = [tuple(bbox)]\n",
        "    prev_score = None\n",
        "    while len(actions_taken) < tracking_length:\n",
        "      prev_bbox = bbox.copy()\n",
        "      \n",
        "      probs, conf_score = model(patch)\n",
        "      probs = tf.reshape(probs, (model.ACTION_DIM)) \n",
        "      \n",
        "      a, bbox = getAction(np.array(img), bbox, probs)\n",
        "      prev_iou = calculate_IOU(prev_bbox, target_bbox)      \n",
        "      iou = calculate_IOU(bbox, target_bbox)   \n",
        "\n",
        "      if tuple(bbox) in bboxes:\n",
        "        print(\"|->> Revisiting bbox: {0}. ACtion {1} did nothing. Breaking action sequence\"\n",
        "                  .format(bbox, a))\n",
        "        print(\"   |->> Trajectory ending is FORCED\".format(iou))\n",
        "        a, bbox = 8, prev_bbox\n",
        "        if len(actions_taken) > 0:\n",
        "          # We observed too many trajectory STOPS were leading to gradient updates\n",
        "          # that reduce P(STOP|s) to near 0, which is undesirable. In this case, \n",
        "          # we allow STOPs if selected naturally by the policy or it's the only \n",
        "          # action on a trajectory (a trajectory MUST \n",
        "          # have at least one action). All other STOPs we just forego\n",
        "          # to prevent these harmful gradient updates\n",
        "          break\n",
        "      elif PREMATURE_BREAK and not isStop(a) and iou < GOAL_IOU  and prev_iou > GOAL_IOU:\n",
        "        # TRAJECTORY IS WORSENING\n",
        "        print(\"             |->> IOU declining: {0}:{1} -> {2}:{3}.\"\n",
        "                  .format(prev_bbox, prev_iou, bbox, iou))\n",
        "        print(\"             |->> Overriding with STOP\"\n",
        "                .format(iou))\n",
        "        a, bbox = 8, prev_bbox\n",
        "      \n",
        "      a_prob = probs[a] \n",
        "      print(\"   \\x1b[33m|->> #{0}/t={1}-th Action selection: {2}/{3} (P(a|s) = {4})\\x1b[0m\"\n",
        "                .format(len(actions_taken), t, a, human_readable_action(a).upper(), \n",
        "                        np.around(a_prob, decimals=3)))\n",
        "      print(\"      |->> Bounding box moves to: {0}\"\n",
        "                .format(bbox))\n",
        "      print(\"         |->> Action Probabilities (Rounded): {0}, argmax={1}\"\n",
        "              .format(np.around(probs.numpy(), decimals=4), np.argmax(probs)))\n",
        "      print(\"         |->> Action Probabilities (RAW): {0}, argmax={1}\"\n",
        "              .format(probs.numpy(), np.argmax(probs)))\n",
        "\n",
        "      if VERBOSE:\n",
        "        print(\"         |->> Overwriting action in buffer {0}\"\n",
        "            .format(model.getPrettyActionHistory() if VERBOSE else \"\"))\n",
        "        \n",
        "      action_probs.append(probs)\n",
        "      actions_taken.append(a)\n",
        "      model.updateActionHistory(a)\n",
        "      bboxes.append(tuple(bbox))  \n",
        "      patch = getPatch(img, bbox)      \n",
        "\n",
        "      # Stopping condition\n",
        "      if isStop(a):\n",
        "        print(\"         |->> Hit a STOP on the {0}-th action!\".format(t))\n",
        "        break  \n",
        "      \n",
        "      t += 1\n",
        "\n",
        "    print(\"    \\x1b[31m|->> Completed tracking\\x1b[0m\")\n",
        "    \n",
        "    return action_probs, actions_taken, bboxes, t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akOkB6DOxC_v"
      },
      "source": [
        "### Single Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "4w8_6oDV7900"
      },
      "outputs": [],
      "source": [
        "VERBOSE = False\n",
        "\n",
        "def train(model: ADNET, opt: tf.keras.optimizers.Optimizer, \n",
        "          dataset: str, start_frame: int, end_frame: int, \n",
        "          retry_count: int=N_RETRIES) -> float:\n",
        "  '''\n",
        "  Run training for a model on a frame sequence {start_frame, end_frame} \n",
        "  n_retries times.\n",
        "  :param: dataset: is the dataset path to train from\n",
        "  :param: retry_count: number of times to train on the frame sequence. \n",
        "  :return: returns the model and average loss\n",
        "  '''\n",
        "\n",
        "  gt = get_ground_truths(\"%s/groundtruth_rect.txt\" % dataset)\n",
        "  frames = sorted(glob.glob(os.path.join('%s/img' % dataset, '*.jpg'))) \n",
        "  loss = 0.0\n",
        "\n",
        "  train_vars = model.trainable_variables\n",
        "  accum_gradient = [tf.zeros_like(this_var) for this_var in train_vars]\n",
        "  for i in range(retry_count):\n",
        "    print(\"\\n\\x1b[36m####################### EPISODE # {0} ############################\\x1b[0m\".format(i+1))\n",
        "    bbox = standardize_bbox(getFrame(frames[start_frame]), gt[start_frame])\n",
        "    print(\"Starting bounding box={3} for {0}'s frames (index: {1})\\nsrc:{2}\\ntarget:{3}.\".format(\n",
        "        dataset, i, frames[start_frame], frames[end_frame], bbox))\n",
        "    \n",
        "    t = 1    \n",
        "    model.clearActionHistory()\n",
        "    for i in range(start_frame+1, end_frame+1):\n",
        "      with tf.GradientTape() as tape:\n",
        "        target_bbox = gt[i]\n",
        "        prev_bbox = np.array(bbox, copy=True)\n",
        "\n",
        "        print(\"\\x1b[34m>> Attempting to reach frame {0} with src: {1} and target: {2}\\x1b[0m\"\n",
        "            .format(i, np.array2string(bbox, separator=', '), \n",
        "                    np.array2string(target_bbox, separator=', ')))\n",
        "        img = getFrame(frames[i])\n",
        "        action_probs, taken_actions, bboxes, t = tracking(model, img, \n",
        "                                                          bbox, t, target_bbox)\n",
        "        bbox = np.array(bboxes[-1])\n",
        "\n",
        "\n",
        "        frame_losses = seqLosses(action_probs, taken_actions, bboxes, target_bbox)\n",
        "        total_frame_loss = tf.reduce_sum(frame_losses)\n",
        "        \n",
        "        loss += np.sum(total_frame_loss.numpy())\n",
        "        print(\"{0}>> Total frame loss: {1}\\x1b[0m\".format(\n",
        "              \"\\x1b[92m\" if total_frame_loss > 0 else \"\\x1b[31m\", \n",
        "              total_frame_loss))\n",
        "\n",
        "      gradients = tape.gradient(total_frame_loss, train_vars)\n",
        "      accum_gradient = [(acum_grad + grad) \n",
        "                        for acum_grad, grad in zip(accum_gradient, gradients)]\n",
        "\n",
        "    print(\"Final bounding box: {0} reached in {1} timesteps (originating from {2}). Target was {3}\"\n",
        "          .format(bbox, t, np.array(gt[start_frame]), np.array(gt[end_frame])))\n",
        "    print(\"\\n\\x1b[36m############# END EPISODE # {0} in t={1} timesteps ################\\x1b[0m\"\n",
        "          .format(i+1, t))\n",
        "    \n",
        "\n",
        "  print(\"Avg Loss Across Trajectories: {0}\\x1b[0m\".format(\n",
        "      \"\\x1b[92m\" if loss > 0 else \"\\x1b[31m\"))  \n",
        "  \n",
        "  \n",
        "  \n",
        "  accum_gradient = [g / retry_count if GRAD_ACCUM_SCHEME == \"avg\" else g \n",
        "                    for g in accum_gradient]\n",
        "  for i in range(len(accum_gradient)):\n",
        "      print(\"Layer Name: {}, GRAD NORM = {}\".format(\n",
        "      adnet_model.trainable_variables[i].name, tf.norm(accum_gradient[i])))\n",
        "  opt.apply_gradients(zip(accum_gradient, model.trainable_variables))\n",
        "  return model, loss / retry_count\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFKnC5VrgVhn"
      },
      "source": [
        "### Epoch Training Loops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "otMLmAPjVSiS"
      },
      "outputs": [],
      "source": [
        "def epochs_train(model: ADNET, opt: tf.keras.optimizers.Optimizer, \n",
        "                 datasets: List[str], \n",
        "                 epochs: int=1, retry_count: int=1, action_strategy: str=\"max\",\n",
        "                 seq_length: int=10, randomize: bool=RANDOMIZE_TRAINING):\n",
        "\n",
        "  print(\"TRAINING ON: {0}\".format(datasets))\n",
        "  # Collect list of datasets & trainable frames\n",
        "  dataset_frames = []\n",
        "  for d in datasets:\n",
        "    frames = sorted(glob.glob(os.path.join('%s/img' % d, '*.jpg')))\n",
        "    frames = list(range(len(frames) - L))\n",
        "    for f in frames:\n",
        "      dataset_frames.append((d, f))\n",
        "  if randomize: random.shuffle(dataset_frames)\n",
        "\n",
        "  # Train for n epochs\n",
        "  losses = {}\n",
        "  bad_data_log = []\n",
        "  for e in range(epochs):\n",
        "    epoch_loss = []\n",
        "    \n",
        "    for i, d_frame in enumerate(dataset_frames):\n",
        "      d, start_frame = d_frame\n",
        "      end_frame = start_frame + seq_length\n",
        "\n",
        "      print(\"\\n\\n#############################################\")\n",
        "      print(\"Dataset={0}\".format(d))\n",
        "      print(\"#################################################\")\n",
        "      adnet_model, l = train(model, opt, d, start_frame, end_frame, \n",
        "                             retry_count=retry_count)\n",
        "      epoch_loss.append(l)\n",
        "      print(\"#################################################\")\n",
        "      print(\"#################################################\")\n",
        "      \n",
        "    losses[e] = epoch_loss\n",
        "\n",
        "  print(\"Finished Training On: {0}\".format(datasets))\n",
        "  return model, losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5g5kT2HgaoO"
      },
      "source": [
        "# Training Procedure"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adnet_model = ADNET()\n",
        "adnet_model.build()\n",
        "WEIGHTS_PATH = \"yifanweights.mat\"\n",
        "weights = hdf5storage.loadmat(WEIGHTS_PATH)\n",
        "adnet_model = setWeights(adnet_model, weights, weights)\n",
        "\n",
        "# adnet_model.load_weights(\"/content/gdrive/My Drive/EE6885/kaan-weights\")\n",
        "\n",
        "adnet_model.layers[-3].trainable=False"
      ],
      "metadata": {
        "id": "Isj57xK2FnN7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To reload saved weights"
      ],
      "metadata": {
        "id": "pZt5PyM2Foj4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # loaded_model.compile(optimizer=Adam(learning_rate=LEARNING_RATE))\n",
        "# adnet_model.set_weights(loaded_model.get_weights())"
      ],
      "metadata": {
        "id": "P7aHgxIpCLpa"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "aEsOSSVhg-qp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d62518f2-ce09-48a2-e649-4446844e1e01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on datasets: ['adnet_datasets/OTB/BlurCar3', 'adnet_datasets/OTB/Bolt', 'adnet_datasets/OTB/Car4', 'adnet_datasets/OTB/CarDark', 'adnet_datasets/OTB/CarScale']\n"
          ]
        }
      ],
      "source": [
        "# N_VIDEOS = 3\n",
        "# datasets = np.random.choice(len(ALL_DATASETS_LIST), size=N_VIDEOS, replace=False)\n",
        "datasets = TRAINING_IDX\n",
        "\n",
        "datasets = list(map(lambda rand_idx: ALL_DATASETS_LIST[rand_idx], datasets))\n",
        "print(\"Training on datasets: {0}\".format(datasets))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41yhNXMygPIy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79c7e4ac-e726-440e-d046-18ddfa6f1937"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "   |->> t=9 Diff-Reward (-0.026) for SCALE DOWN:bbox transition: [237, 219,  81,  69] -> [238, 220,  78,  66] w/ P(a|s)=0.08451838046312332 and iou=0.8218390804597702 and reward=-0.026437857010992327 and discount=1.0\n",
            "   |->> t=10 Diff-Reward (1.0) for RIGHT:bbox transition: [238, 220,  78,  66] -> [240, 220,  78,  66] w/ P(a|s)=0.09096068143844604 and iou=0.8218390804597702 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.          0.05252327 -0.11834211 -0.1800237  -0.13282955  0.07861989\n",
            "  0.16386892  0.10629271 -0.06532229  2.397328  ]\n",
            "\u001b[92m>> Total frame loss: 2.302114963531494\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 64 with src: [240, 220,  78,  66] and target: [259, 213,  84,  73]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0067.jpg\n",
            "|->> Beginning tracking for bbox:[240 220  78  66]\n",
            "   \u001b[33m|->> #0/t=18-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08399999886751175)\u001b[0m\n",
            "      |->> Bounding box moves to: [241 221  75  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0971 0.0912 0.0806 0.0927 0.0931 0.0935 0.0932 0.0943 0.0914 0.0838\n",
            " 0.0892], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09707227 0.09120266 0.08060069 0.09266676 0.0931046  0.0934899\n",
            " 0.09316759 0.09434135 0.0913697  0.08381687 0.08916754], argmax=0\n",
            "   \u001b[33m|->> #1/t=19-th Action selection: 2/RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [243 221  75  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0864 0.0926 0.0906 0.0919 0.0931 0.0939 0.0947 0.0954 0.0913 0.0787\n",
            " 0.0914], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08644456 0.09260248 0.09061763 0.0918638  0.09311464 0.09389937\n",
            " 0.0946644  0.09540585 0.09131235 0.07868662 0.09138826], argmax=7\n",
            "   \u001b[33m|->> #2/t=20-th Action selection: 9/SCALE DOWN (P(a|s) = 0.0820000022649765)\u001b[0m\n",
            "      |->> Bounding box moves to: [244 222  72  62]\n",
            "         |->> Action Probabilities (Rounded): [0.0986 0.0914 0.079  0.0925 0.0935 0.0942 0.0946 0.0948 0.0913 0.082\n",
            " 0.0883], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.0985569  0.09136472 0.07902677 0.09248407 0.09346414 0.0941533\n",
            " 0.0945657  0.09481131 0.09129494 0.0819596  0.08831856], argmax=0\n",
            "   \u001b[33m|->> #3/t=21-th Action selection: 2/RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [246 222  72  62]\n",
            "         |->> Action Probabilities (Rounded): [0.0866 0.0927 0.0908 0.0915 0.093  0.0938 0.0948 0.095  0.0918 0.0785\n",
            " 0.0915], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08663917 0.09274713 0.09077203 0.0915361  0.09297048 0.09379886\n",
            " 0.09477272 0.09503048 0.09179067 0.07846794 0.09147446], argmax=7\n",
            "   \u001b[33m|->> #4/t=22-th Action selection: 9/SCALE DOWN (P(a|s) = 0.07999999821186066)\u001b[0m\n",
            "      |->> Bounding box moves to: [247 223  69  60]\n",
            "         |->> Action Probabilities (Rounded): [0.1008 0.0925 0.079  0.0923 0.0925 0.0946 0.0948 0.0946 0.0912 0.0803\n",
            " 0.0874], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.10075462 0.09248994 0.07895569 0.09227255 0.09253375 0.09456015\n",
            " 0.09483313 0.0945924  0.09122023 0.08034047 0.08744704], argmax=0\n",
            "   \u001b[33m|->> #5/t=23-th Action selection: 6/DOWN (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [247 224  69  60]\n",
            "         |->> Action Probabilities (Rounded): [0.087  0.0937 0.0907 0.0913 0.0935 0.0947 0.0949 0.0957 0.0916 0.0762\n",
            " 0.0909], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08698656 0.09368812 0.09068412 0.09127653 0.0934756  0.09470201\n",
            " 0.09485523 0.09566098 0.09155541 0.07623862 0.0908769 ], argmax=7\n",
            "   \u001b[33m|->> #6/t=24-th Action selection: 5/2X UP (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [247 222  69  60]\n",
            "         |->> Action Probabilities (Rounded): [0.0949 0.0929 0.0862 0.0923 0.0944 0.0943 0.0919 0.0944 0.0905 0.0794\n",
            " 0.0889], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.094905   0.09289148 0.08621879 0.09226643 0.09442504 0.09429051\n",
            " 0.09193898 0.0943604  0.09046553 0.0793867  0.08885115], argmax=0\n",
            "   \u001b[33m|->> #7/t=25-th Action selection: 3/2X RIGHT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [251 222  69  60]\n",
            "         |->> Action Probabilities (Rounded): [0.0902 0.0932 0.0899 0.0926 0.0919 0.0924 0.094  0.0948 0.0908 0.0798\n",
            " 0.0905], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09022477 0.0931717  0.08986792 0.09257488 0.09186557 0.09238132\n",
            " 0.09396279 0.09480259 0.09079511 0.07983171 0.09052154], argmax=7\n",
            "   \u001b[33m|->> #8/t=26-th Action selection: 5/2X UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [251 220  69  60]\n",
            "         |->> Action Probabilities (Rounded): [0.0922 0.0938 0.0883 0.0905 0.093  0.093  0.0935 0.0934 0.0907 0.0819\n",
            " 0.0896], argmax=1\n",
            "         |->> Action Probabilities (RAW): [0.09224685 0.09375381 0.08831751 0.09047473 0.09303731 0.09302112\n",
            " 0.09354522 0.09338834 0.09070159 0.08194113 0.08957243], argmax=1\n",
            "|->> Revisiting bbox: [251 222  69  60]. ACtion 7 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [240, 220,  78,  66] -> [251, 220,  69,  60] (Target was [259, 213,  84,  73])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.026) for SCALE DOWN:bbox transition: [240, 220,  78,  66] -> [241, 221,  75,  64] w/ P(a|s)=0.08381687104701996 and iou=0.500823723228995 and reward=-0.026389924212109728 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.027) for RIGHT:bbox transition: [241, 221,  75,  64] -> [243, 221,  75,  64] w/ P(a|s)=0.09061762690544128 and iou=0.5276690888764674 and reward=0.026845365647472308 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.027) for SCALE DOWN:bbox transition: [243, 221,  75,  64] -> [244, 222,  72,  62] w/ P(a|s)=0.08195959776639938 and iou=0.5004248088360238 and reward=-0.027244280040443547 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.027) for RIGHT:bbox transition: [244, 222,  72,  62] -> [246, 222,  72,  62] w/ P(a|s)=0.09077202528715134 and iou=0.5272412799077544 and reward=0.026816471071730574 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (-0.028) for SCALE DOWN:bbox transition: [246, 222,  72,  62] -> [247, 223,  69,  60] w/ P(a|s)=0.08034047484397888 and iou=0.4991243432574431 and reward=-0.028116936650311286 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (0.0) for DOWN:bbox transition: [247, 223,  69,  60] -> [247, 224,  69,  60] w/ P(a|s)=0.09485522657632828 and iou=0.4991243432574431 and reward=0.0 and discount=1.0\n",
            "   |->> t=7 Diff-Reward (0.0) for 2X UP:bbox transition: [247, 224,  69,  60] -> [247, 222,  69,  60] w/ P(a|s)=0.09429050981998444 and iou=0.4991243432574431 and reward=0.0 and discount=1.0\n",
            "   |->> t=8 Diff-Reward (0.054) for 2X RIGHT:bbox transition: [247, 222,  69,  60] -> [251, 222,  69,  60] w/ P(a|s)=0.09257487952709198 and iou=0.5535390199637024 and reward=0.05441467670625927 and discount=1.0\n",
            "   |->> t=9 Diff-Reward (-1.0) for 2X UP:bbox transition: [251, 222,  69,  60] -> [251, 220,  69,  60] w/ P(a|s)=0.09302112460136414 and iou=0.5535390199637024 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.06542382  0.06445859 -0.06815235  0.06434355 -0.07089634  0.\n",
            "  0.          0.12949264 -2.3749287 ]\n",
            "\u001b[31m>> Total frame loss: -2.321106433868408\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 65 with src: [251, 220,  69,  60] and target: [280, 211,  83,  66]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0068.jpg\n",
            "|->> Beginning tracking for bbox:[251 220  69  60]\n",
            "   \u001b[33m|->> #0/t=27-th Action selection: 5/2X UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [251 218  69  60]\n",
            "         |->> Action Probabilities (Rounded): [0.0913 0.0921 0.0891 0.0907 0.0921 0.091  0.0938 0.0947 0.0912 0.0836\n",
            " 0.0903], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09129678 0.09205825 0.08913238 0.09074771 0.09210313 0.09099337\n",
            " 0.09383882 0.09468199 0.09122278 0.08363263 0.09029217], argmax=7\n",
            "   \u001b[33m|->> #1/t=28-th Action selection: 2/RIGHT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [253 218  69  60]\n",
            "         |->> Action Probabilities (Rounded): [0.0913 0.0928 0.0895 0.0912 0.0919 0.0901 0.0945 0.0928 0.0914 0.085\n",
            " 0.0896], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09129672 0.09277896 0.08949079 0.0912422  0.09186601 0.09005032\n",
            " 0.09452045 0.09279712 0.09139448 0.08498001 0.08958303], argmax=6\n",
            "   \u001b[33m|->> #2/t=29-th Action selection: 3/2X RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [257 218  69  60]\n",
            "         |->> Action Probabilities (Rounded): [0.097  0.0918 0.082  0.0921 0.0911 0.0904 0.0941 0.0939 0.0918 0.086\n",
            " 0.0899], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09701184 0.09176018 0.08200124 0.09205711 0.09110847 0.09035698\n",
            " 0.09409269 0.09392063 0.09182129 0.08599424 0.0898753 ], argmax=0\n",
            "   \u001b[33m|->> #3/t=30-th Action selection: 10/SCALE UP (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [255 217  71  62]\n",
            "         |->> Action Probabilities (Rounded): [0.0886 0.0938 0.0906 0.0885 0.0925 0.0904 0.0939 0.0938 0.0915 0.087\n",
            " 0.0892], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.0886002  0.09376448 0.09064832 0.08853395 0.09246919 0.09041011\n",
            " 0.09394278 0.09383838 0.09150722 0.08704872 0.08923668], argmax=6\n",
            "   \u001b[33m|->> #4/t=31-th Action selection: 10/SCALE UP (P(a|s) = 0.08399999886751175)\u001b[0m\n",
            "      |->> Bounding box moves to: [253 216  73  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0927 0.0922 0.0856 0.0911 0.092  0.0913 0.0937 0.0947 0.0925 0.0902\n",
            " 0.0841], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09269451 0.09218119 0.08563129 0.09110031 0.09195347 0.09126032\n",
            " 0.09370667 0.09465942 0.09250572 0.09020169 0.08410535], argmax=7\n",
            "   \u001b[33m|->> #5/t=32-th Action selection: 5/2X UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [253 214  73  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0899 0.0925 0.0886 0.0909 0.092  0.0915 0.0939 0.0941 0.0934 0.0909\n",
            " 0.0823], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08991867 0.09250434 0.08861972 0.09088035 0.09203628 0.09147743\n",
            " 0.09386169 0.09414442 0.09336106 0.09086261 0.08233345], argmax=7\n",
            "   \u001b[33m|->> #6/t=33-th Action selection: 6/DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [253 215  73  64]\n",
            "         |->> Action Probabilities (Rounded): [0.092  0.0924 0.088  0.0908 0.0917 0.0898 0.0938 0.0934 0.0929 0.0922\n",
            " 0.083 ], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09197009 0.09235062 0.08795616 0.09084879 0.09168138 0.08982685\n",
            " 0.09384765 0.09344357 0.09288355 0.0921541  0.08303724], argmax=6\n",
            "   \u001b[33m|->> #7/t=34-th Action selection: 1/2X LEFT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [249 215  73  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0915 0.0919 0.0904 0.0911 0.0933 0.0901 0.092  0.0932 0.0916 0.0916\n",
            " 0.0833], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.09151928 0.09186227 0.09042273 0.09113139 0.09327486 0.09007318\n",
            " 0.09196839 0.09316457 0.0916391  0.0916492  0.08329505], argmax=4\n",
            "   \u001b[33m|->> #8/t=35-th Action selection: 0/LEFT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [247 215  73  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0916 0.0893 0.0893 0.0912 0.0918 0.0908 0.0933 0.0937 0.0919 0.092\n",
            " 0.0852], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09156331 0.08932802 0.08933069 0.09122334 0.09180519 0.0907608\n",
            " 0.0932954  0.09368    0.09190464 0.0919508  0.08515781], argmax=7\n",
            "   \u001b[33m|->> #9/t=36-th Action selection: 6/DOWN (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [247 216  73  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0838 0.09   0.0964 0.092  0.0922 0.0919 0.0928 0.0948 0.0921 0.0893\n",
            " 0.0847], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08376138 0.08998064 0.09635205 0.09196821 0.09220064 0.09194344\n",
            " 0.09284975 0.09484621 0.09210192 0.08931387 0.08468189], argmax=2\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [251, 220,  69,  60] -> [247, 216,  73,  64] (Target was [280, 211,  83,  66])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.014) for 2X UP:bbox transition: [251, 220,  69,  60] -> [251, 218,  69,  60] w/ P(a|s)=0.09099337458610535 and iou=0.32515844585285203 and reward=0.01444708035816683 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.022) for RIGHT:bbox transition: [251, 218,  69,  60] -> [253, 218,  69,  60] w/ P(a|s)=0.08949079364538193 and iou=0.34705882352941175 and reward=0.021900377676559724 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.046) for 2X RIGHT:bbox transition: [253, 218,  69,  60] -> [257, 218,  69,  60] w/ P(a|s)=0.09205710887908936 and iou=0.39310544611819237 and reward=0.04604662258878062 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-0.005) for SCALE UP:bbox transition: [257, 218,  69,  60] -> [255, 217,  71,  62] w/ P(a|s)=0.08923668414354324 and iou=0.38764044943820225 and reward=-0.0054649966799901195 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (-0.006) for SCALE UP:bbox transition: [255, 217,  71,  62] -> [253, 216,  73,  64] w/ P(a|s)=0.08410535007715225 and iou=0.3820806100217865 and reward=-0.005559839416415746 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (0.018) for 2X UP:bbox transition: [253, 216,  73,  64] -> [253, 214,  73,  64] w/ P(a|s)=0.09147743135690689 and iou=0.3996138996138996 and reward=0.017533289592113088 and discount=1.0\n",
            "   |->> t=7 Diff-Reward (-0.009) for DOWN:bbox transition: [253, 214,  73,  64] -> [253, 215,  73,  64] w/ P(a|s)=0.09384764730930328 and iou=0.39079199780761853 and reward=-0.008821901806281063 and discount=1.0\n",
            "   |->> t=8 Diff-Reward (-0.046) for 2X LEFT:bbox transition: [253, 215,  73,  64] -> [249, 215,  73,  64] w/ P(a|s)=0.0918622687458992 and iou=0.3450834879406308 and reward=-0.04570850986698771 and discount=1.0\n",
            "   |->> t=9 Diff-Reward (-0.022) for LEFT:bbox transition: [249, 215,  73,  64] -> [247, 215,  73,  64] w/ P(a|s)=0.09156331419944763 and iou=0.32333767926988266 and reward=-0.021745808670748157 and discount=1.0\n",
            "   |->> t=10 Diff-Reward (-1.0) for DOWN:bbox transition: [247, 215,  73,  64] -> [247, 216,  73,  64] w/ P(a|s)=0.09284975379705429 and iou=0.3164721141374838 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.0346292   0.05285918  0.10983714 -0.01320596 -0.01376441  0.04193372\n",
            " -0.02087335 -0.10912747 -0.05198824 -2.3767726 ]\n",
            "\u001b[31m>> Total frame loss: -2.34647274017334\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 66 with src: [247, 216,  73,  64] and target: [284, 212,  87,  76]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0069.jpg\n",
            "|->> Beginning tracking for bbox:[247 216  73  64]\n",
            "   \u001b[33m|->> #0/t=37-th Action selection: 1/2X LEFT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [243 216  73  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0925 0.0895 0.0885 0.0926 0.093  0.0924 0.0915 0.0943 0.0906 0.0904\n",
            " 0.0846], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09246939 0.08945766 0.0885141  0.09263805 0.09300056 0.09237256\n",
            " 0.09154673 0.09433706 0.09061839 0.09041784 0.08462766], argmax=7\n",
            "   \u001b[33m|->> #1/t=38-th Action selection: 6/DOWN (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [243 217  73  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0884 0.0867 0.0927 0.0918 0.0923 0.0929 0.0933 0.0941 0.0915 0.0904\n",
            " 0.0859], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08840533 0.08668993 0.09265083 0.09178268 0.09230552 0.09285732\n",
            " 0.09334955 0.09411462 0.09152859 0.09039161 0.08592401], argmax=7\n",
            "   \u001b[33m|->> #2/t=39-th Action selection: 10/SCALE UP (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [241 216  75  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0909 0.0865 0.0903 0.0935 0.0943 0.0925 0.0905 0.0939 0.0905 0.0906\n",
            " 0.0866], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.09085447 0.08648116 0.0902628  0.09349822 0.0942928  0.09250088\n",
            " 0.09048547 0.09393298 0.09053082 0.0905991  0.08656131], argmax=4\n",
            "   \u001b[33m|->> #3/t=40-th Action selection: 2/RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [243 216  75  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0894 0.0875 0.092  0.094  0.0926 0.093  0.0932 0.094  0.0906 0.0917\n",
            " 0.0819], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08939467 0.08753672 0.09203438 0.09398332 0.09259041 0.09300664\n",
            " 0.09320527 0.0940212  0.09060192 0.09173593 0.08188948], argmax=7\n",
            "   \u001b[33m|->> #4/t=41-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [244 217  72  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0963 0.0879 0.0834 0.0938 0.0933 0.0942 0.0927 0.0936 0.0912 0.089\n",
            " 0.0846], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09634082 0.08789213 0.08341583 0.09375677 0.0933206  0.09419023\n",
            " 0.09271678 0.09357201 0.09118094 0.0889814  0.0846325 ], argmax=0\n",
            "   \u001b[33m|->> #5/t=42-th Action selection: 4/UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [244 216  72  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0865 0.0892 0.0938 0.093  0.093  0.0936 0.094  0.094  0.0916 0.0843\n",
            " 0.087 ], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08649614 0.08924741 0.09381603 0.09302411 0.09301928 0.09359965\n",
            " 0.09396886 0.09396815 0.09163219 0.08425804 0.08697005], argmax=6\n",
            "   \u001b[33m|->> #6/t=43-th Action selection: 1/2X LEFT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [240 216  72  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0922 0.0893 0.0896 0.0927 0.0921 0.0939 0.0943 0.0941 0.0906 0.0853\n",
            " 0.086 ], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09221288 0.08930935 0.08957758 0.09267777 0.09206951 0.09385338\n",
            " 0.09430095 0.09407336 0.09064613 0.08531559 0.08596354], argmax=6\n",
            "   \u001b[33m|->> #7/t=44-th Action selection: 7/2X DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [240 218  72  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0901 0.0873 0.0915 0.0932 0.0918 0.0938 0.0935 0.094  0.0908 0.0865\n",
            " 0.0876], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09012624 0.08725784 0.09151284 0.09316518 0.09177841 0.09376468\n",
            " 0.0935294  0.09398504 0.09079751 0.08645947 0.08762339], argmax=7\n",
            "   \u001b[33m|->> #8/t=45-th Action selection: 7/2X DOWN (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [240 220  72  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0917 0.0884 0.0908 0.092  0.0923 0.0927 0.0944 0.0926 0.0907 0.0869\n",
            " 0.0874], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09167775 0.08839876 0.09081028 0.09203357 0.09226563 0.09266081\n",
            " 0.09440333 0.09264679 0.09073191 0.08693244 0.08743866], argmax=6\n",
            "   \u001b[33m|->> #9/t=46-th Action selection: 7/2X DOWN (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [240 222  72  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0888 0.0896 0.0904 0.0924 0.093  0.0921 0.0942 0.0909 0.0912 0.0889\n",
            " 0.0885], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08879732 0.08961856 0.09039373 0.09239627 0.0930123  0.09205891\n",
            " 0.09416665 0.09087814 0.09123952 0.08891509 0.08852346], argmax=6\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [247, 216,  73,  64] -> [240, 222,  72,  64] (Target was [284, 212,  87,  76])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.035) for 2X LEFT:bbox transition: [247, 216,  73,  64] -> [243, 216,  73,  64] w/ P(a|s)=0.08945766091346741 and iou=0.22174101342572541 and reward=-0.034829142476279024 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for DOWN:bbox transition: [243, 216,  73,  64] -> [243, 217,  73,  64] w/ P(a|s)=0.09334954619407654 and iou=0.22174101342572541 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.002) for SCALE UP:bbox transition: [243, 217,  73,  64] -> [241, 216,  75,  66] w/ P(a|s)=0.08656131476163864 and iou=0.2234920634920635 and reward=0.001751050066338078 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.017) for RIGHT:bbox transition: [241, 216,  75,  66] -> [243, 216,  75,  66] w/ P(a|s)=0.09203438460826874 and iou=0.24082421120412106 and reward=0.017332147712057572 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (-0.018) for SCALE DOWN:bbox transition: [243, 216,  75,  66] -> [244, 217,  72,  64] w/ P(a|s)=0.08898140490055084 and iou=0.22328826864369822 and reward=-0.017535942560422846 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (0.0) for UP:bbox transition: [244, 217,  72,  64] -> [244, 216,  72,  64] w/ P(a|s)=0.0930192843079567 and iou=0.22328826864369822 and reward=0.0 and discount=1.0\n",
            "   |->> t=7 Diff-Reward (-0.033) for 2X LEFT:bbox transition: [244, 216,  72,  64] -> [240, 216,  72,  64] w/ P(a|s)=0.08930934965610504 and iou=0.1900721255833687 and reward=-0.03321614306032952 and discount=1.0\n",
            "   |->> t=8 Diff-Reward (0.0) for 2X DOWN:bbox transition: [240, 216,  72,  64] -> [240, 218,  72,  64] w/ P(a|s)=0.09398504346609116 and iou=0.1900721255833687 and reward=0.0 and discount=1.0\n",
            "   |->> t=9 Diff-Reward (0.0) for 2X DOWN:bbox transition: [240, 218,  72,  64] -> [240, 220,  72,  64] w/ P(a|s)=0.09264679253101349 and iou=0.1900721255833687 and reward=0.0 and discount=1.0\n",
            "   |->> t=10 Diff-Reward (-1.0) for 2X DOWN:bbox transition: [240, 220,  72,  64] -> [240, 222,  72,  64] w/ P(a|s)=0.09087814390659332 and iou=0.1900721255833687 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.08407719  0.          0.00428465  0.04134745 -0.04242519  0.\n",
            " -0.08023855  0.          0.         -2.3982358 ]\n",
            "\u001b[31m>> Total frame loss: -2.559344530105591\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 67 with src: [240, 222,  72,  64] and target: [284, 231,  80,  75]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0070.jpg\n",
            "|->> Beginning tracking for bbox:[240 222  72  64]\n",
            "   \u001b[33m|->> #0/t=47-th Action selection: 4/UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [240 221  72  64]\n",
            "         |->> Action Probabilities (Rounded): [0.09   0.09   0.0899 0.0923 0.0931 0.092  0.0934 0.0892 0.0912 0.0892\n",
            " 0.0897], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09002509 0.08995546 0.08987509 0.09230894 0.09314679 0.09203374\n",
            " 0.09336366 0.08921379 0.09124158 0.08918489 0.08965099], argmax=6\n",
            "   \u001b[33m|->> #1/t=48-th Action selection: 5/2X UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [240 219  72  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0904 0.091  0.0899 0.0926 0.0912 0.0916 0.0936 0.0904 0.0916 0.0883\n",
            " 0.0894], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09038261 0.09099622 0.08992392 0.09261779 0.0911782  0.09158527\n",
            " 0.09359252 0.09038553 0.09159997 0.08830425 0.08943374], argmax=6\n",
            "|->> Revisiting bbox: [240 219  72  64]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [240, 222,  72,  64] -> [240, 219,  72,  64] (Target was [284, 231,  80,  75])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.004) for UP:bbox transition: [240, 222,  72,  64] -> [240, 221,  72,  64] w/ P(a|s)=0.09314678609371185 and iou=0.1662269129287599 and reward=-0.0036010535467584093 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for 2X UP:bbox transition: [240, 221,  72,  64] -> [240, 219,  72,  64] w/ P(a|s)=0.09158527106046677 and iou=0.1590909090909091 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.00854738 -2.3904848 ]\n",
            "\u001b[31m>> Total frame loss: -2.3990321159362793\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 68 with src: [240, 219,  72,  64] and target: [261, 245,  90,  72]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0071.jpg\n",
            "|->> Beginning tracking for bbox:[240 219  72  64]\n",
            "   \u001b[33m|->> #0/t=49-th Action selection: 7/2X DOWN (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [240 221  72  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0904 0.0913 0.0908 0.0926 0.0912 0.0902 0.0923 0.0898 0.0917 0.0896\n",
            " 0.0899], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09043474 0.09132162 0.09081711 0.09261277 0.0912374  0.09023102\n",
            " 0.09230338 0.08979926 0.09172225 0.08962842 0.08989203], argmax=3\n",
            "   \u001b[33m|->> #1/t=50-th Action selection: 7/2X DOWN (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [240 223  72  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0895 0.0904 0.0909 0.0931 0.0913 0.0898 0.0932 0.0888 0.092  0.0898\n",
            " 0.0912], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08951568 0.0903941  0.09092576 0.09310846 0.09131674 0.0897937\n",
            " 0.09321078 0.08876429 0.09198985 0.0897732  0.09120737], argmax=6\n",
            "   \u001b[33m|->> #2/t=51-th Action selection: 1/2X LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [236 223  72  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0899 0.091  0.0905 0.0926 0.0922 0.0895 0.0921 0.0881 0.0926 0.0902\n",
            " 0.0912], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.08994646 0.09103956 0.09052721 0.09260961 0.09222566 0.08947385\n",
            " 0.0921049  0.0880513  0.09257818 0.0902357  0.09120751], argmax=3\n",
            "   \u001b[33m|->> #3/t=52-th Action selection: 1/2X LEFT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [232 223  72  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0891 0.089  0.0904 0.0926 0.0926 0.0894 0.0919 0.0889 0.0928 0.0921\n",
            " 0.0911], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08912574 0.08901016 0.0904482  0.09263181 0.09255157 0.08937025\n",
            " 0.09185436 0.08892213 0.09280531 0.09214569 0.09113483], argmax=8\n",
            "   \u001b[33m|->> #4/t=53-th Action selection: 10/SCALE UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [230 222  74  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0895 0.0869 0.091  0.0924 0.0924 0.0897 0.092  0.0889 0.0935 0.0922\n",
            " 0.0916], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08947467 0.08690978 0.09096292 0.09241237 0.09240193 0.08971424\n",
            " 0.09199689 0.08890553 0.09346082 0.09218016 0.09158074], argmax=8\n",
            "   \u001b[33m|->> #5/t=54-th Action selection: 3/2X RIGHT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [234 222  74  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0901 0.0878 0.0907 0.0928 0.0929 0.0902 0.0931 0.0899 0.0936 0.0934\n",
            " 0.0857], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09005287 0.08778054 0.09070357 0.09277796 0.09288119 0.09020144\n",
            " 0.09305082 0.08986176 0.09362584 0.09341038 0.08565363], argmax=8\n",
            "   \u001b[33m|->> #6/t=55-th Action selection: 0/LEFT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [232 222  74  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0903 0.0887 0.0895 0.0915 0.0932 0.0914 0.0927 0.0905 0.0929 0.0915\n",
            " 0.0879], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.09028921 0.08870979 0.0894551  0.09147198 0.09319544 0.09137563\n",
            " 0.09272833 0.09052284 0.09293471 0.09145173 0.08786515], argmax=4\n",
            "|->> Revisiting bbox: [232 222  74  66]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [240, 219,  72,  64] -> [232, 222,  74,  66] (Target was [261, 245,  90,  72])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.014) for 2X DOWN:bbox transition: [240, 219,  72,  64] -> [240, 221,  72,  64] w/ P(a|s)=0.08979926258325577 and iou=0.22546419098143236 and reward=0.013660912292907779 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.014) for 2X DOWN:bbox transition: [240, 221,  72,  64] -> [240, 223,  72,  64] w/ P(a|s)=0.08876429498195648 and iou=0.23943661971830985 and reward=0.013972428736877485 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.023) for 2X LEFT:bbox transition: [240, 223,  72,  64] -> [236, 223,  72,  64] w/ P(a|s)=0.09103956073522568 and iou=0.21658986175115208 and reward=-0.022846757967157766 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-0.022) for 2X LEFT:bbox transition: [236, 223,  72,  64] -> [232, 223,  72,  64] w/ P(a|s)=0.08901015669107437 and iou=0.19457013574660634 and reward=-0.022019726004545742 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (-0.0) for SCALE UP:bbox transition: [232, 223,  72,  64] -> [230, 222,  74,  66] w/ P(a|s)=0.09158074110746384 and iou=0.19432475039411456 and reward=-0.0002453853524917726 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (0.022) for 2X RIGHT:bbox transition: [230, 222,  74,  66] -> [234, 222,  74,  66] w/ P(a|s)=0.09277796000242233 and iou=0.21631167719148026 and reward=0.02198692679736569 and discount=1.0\n",
            "   |->> t=7 Diff-Reward (-1.0) for LEFT:bbox transition: [234, 222,  74,  66] -> [232, 222,  74,  66] w/ P(a|s)=0.09028920531272888 and iou=0.20521794463888005 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 3.2925237e-02  3.3838019e-02 -5.4751370e-02 -5.3265817e-02\n",
            " -5.8660208e-04  5.2274931e-02 -2.4047375e+00]\n",
            "\u001b[31m>> Total frame loss: -2.3943030834198\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 69 with src: [232, 222,  74,  66] and target: [252, 242,  91,  71]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0072.jpg\n",
            "|->> Beginning tracking for bbox:[232 222  74  66]\n",
            "   \u001b[33m|->> #0/t=56-th Action selection: 9/SCALE DOWN (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [233 223  71  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0832 0.0882 0.0957 0.0923 0.0931 0.0923 0.0934 0.0931 0.0925 0.0896\n",
            " 0.0866], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08319695 0.08820125 0.09571685 0.092274   0.09313015 0.0922906\n",
            " 0.09339957 0.09311088 0.09245106 0.08959164 0.08663704], argmax=2\n",
            "   \u001b[33m|->> #1/t=57-th Action selection: 1/2X LEFT (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [229 223  71  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0908 0.0883 0.0878 0.0929 0.093  0.0928 0.0942 0.0933 0.0922 0.0851\n",
            " 0.0897], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09084532 0.08825026 0.08780492 0.09285292 0.09296017 0.0928042\n",
            " 0.09415699 0.09326589 0.09218744 0.08513758 0.08973428], argmax=6\n",
            "   \u001b[33m|->> #2/t=58-th Action selection: 10/SCALE UP (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [227 222  73  66]\n",
            "         |->> Action Probabilities (Rounded): [0.087  0.0863 0.0924 0.0924 0.0933 0.093  0.0935 0.0931 0.0923 0.0884\n",
            " 0.0883], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08698483 0.08631432 0.09238836 0.09237637 0.09333313 0.09295754\n",
            " 0.09349731 0.09312607 0.09233966 0.08835455 0.08832785], argmax=6\n",
            "   \u001b[33m|->> #3/t=59-th Action selection: 7/2X DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [227 224  73  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0909 0.0872 0.0885 0.0923 0.0936 0.0938 0.0945 0.0945 0.0921 0.0889\n",
            " 0.0837], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.0909135  0.08718616 0.08853097 0.09233262 0.09360158 0.09378956\n",
            " 0.09446278 0.09446467 0.09205244 0.08893881 0.08372697], argmax=7\n",
            "|->> Revisiting bbox: [227 224  73  66]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [232, 222,  74,  66] -> [227, 224,  73,  66] (Target was [252, 242,  91,  71])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.01) for SCALE DOWN:bbox transition: [232, 222,  74,  66] -> [233, 223,  71,  64] w/ P(a|s)=0.08959163725376129 and iou=0.2700519330640508 and reward=-0.010277600848600132 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.026) for 2X LEFT:bbox transition: [233, 223,  71,  64] -> [229, 223,  71,  64] w/ P(a|s)=0.08825025707483292 and iou=0.24420576596947427 and reward=-0.025846167094576517 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.001) for SCALE UP:bbox transition: [229, 223,  71,  64] -> [227, 222,  73,  66] w/ P(a|s)=0.08832785487174988 and iou=0.24341307463344725 and reward=-0.0007926913360270238 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-1.0) for 2X DOWN:bbox transition: [227, 222,  73,  66] -> [227, 224,  73,  66] w/ P(a|s)=0.09446466714143753 and iou=0.2567130919220056 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.4794642e-02 -6.2743604e-02 -1.9236240e-03 -2.3595295e+00]\n",
            "\u001b[31m>> Total frame loss: -2.448991298675537\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 70 with src: [227, 224,  73,  66] and target: [261, 227,  92,  72]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0073.jpg\n",
            "|->> Beginning tracking for bbox:[227 224  73  66]\n",
            "   \u001b[33m|->> #0/t=60-th Action selection: 2/RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [229 224  73  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0883 0.0873 0.0905 0.0928 0.0938 0.0934 0.0943 0.0932 0.0926 0.0878\n",
            " 0.086 ], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08830966 0.08725382 0.09054798 0.09281164 0.09382591 0.09341092\n",
            " 0.09433606 0.09319127 0.09255034 0.08779563 0.08596668], argmax=6\n",
            "|->> Revisiting bbox: [229 224  73  66]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [227, 224,  73,  66] -> [229, 224,  73,  66] (Target was [261, 227,  92,  72])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for RIGHT:bbox transition: [227, 224,  73,  66] -> [229, 224,  73,  66] w/ P(a|s)=0.09054797887802124 and iou=0.29156789705384356 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.4018755]\n",
            "\u001b[31m>> Total frame loss: -2.4018754959106445\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 71 with src: [229, 224,  73,  66] and target: [271, 222,  91,  70]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0074.jpg\n",
            "|->> Beginning tracking for bbox:[229 224  73  66]\n",
            "   \u001b[33m|->> #0/t=61-th Action selection: 6/DOWN (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [229 225  73  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0956 0.0874 0.0821 0.0935 0.0932 0.094  0.0952 0.0936 0.0913 0.0886\n",
            " 0.0856], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09563823 0.0874012  0.08205691 0.09345981 0.09323695 0.09402011\n",
            " 0.09517416 0.09355107 0.0912618  0.08857413 0.08562569], argmax=0\n",
            "   \u001b[33m|->> #1/t=62-th Action selection: 3/2X RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [233 225  73  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0876 0.0896 0.0917 0.0921 0.0952 0.0939 0.0921 0.0936 0.0907 0.0879\n",
            " 0.0856], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.08760326 0.08961812 0.09169192 0.09208249 0.09516921 0.09391393\n",
            " 0.09209391 0.09359001 0.09072191 0.08789831 0.08561691], argmax=4\n",
            "   \u001b[33m|->> #2/t=63-th Action selection: 5/2X UP (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [233 223  73  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0936 0.0902 0.0873 0.09   0.0924 0.0941 0.0925 0.0936 0.0911 0.0887\n",
            " 0.0864], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.09364107 0.09019756 0.08732278 0.09000344 0.09242433 0.09411781\n",
            " 0.09252867 0.09361361 0.091057   0.0886929  0.08640079], argmax=5\n",
            "   \u001b[33m|->> #3/t=64-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [234 224  70  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0915 0.0896 0.0894 0.0911 0.0931 0.0923 0.0926 0.0932 0.0909 0.0885\n",
            " 0.0876], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09153587 0.08960491 0.0894325  0.09110971 0.09311048 0.09231428\n",
            " 0.09258531 0.09322757 0.0909311  0.08851908 0.08762921], argmax=7\n",
            "   \u001b[33m|->> #4/t=65-th Action selection: 3/2X RIGHT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [238 224  70  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0915 0.0904 0.0894 0.0927 0.0922 0.0924 0.0943 0.0938 0.0913 0.0834\n",
            " 0.0888], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09150677 0.09038211 0.08937234 0.09267882 0.09218165 0.09235837\n",
            " 0.09425702 0.09377382 0.09128508 0.08336499 0.08883905], argmax=6\n",
            "   \u001b[33m|->> #5/t=66-th Action selection: 5/2X UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [238 222  70  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0898 0.0915 0.0883 0.0899 0.0937 0.0925 0.0937 0.0931 0.0916 0.0875\n",
            " 0.0882], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08982859 0.09154844 0.08832923 0.08994677 0.0936648  0.09250214\n",
            " 0.09371093 0.09312879 0.09162414 0.08749421 0.08822192], argmax=6\n",
            "   \u001b[33m|->> #6/t=67-th Action selection: 0/LEFT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [236 222  70  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0917 0.0914 0.088  0.0904 0.0931 0.0905 0.0936 0.093  0.0916 0.088\n",
            " 0.0888], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09170286 0.09136257 0.08797857 0.09039894 0.09305605 0.09045866\n",
            " 0.09358446 0.09300329 0.0916467  0.08802546 0.08878245], argmax=6\n",
            "   \u001b[33m|->> #7/t=68-th Action selection: 1/2X LEFT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [232 222  70  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0834 0.0921 0.0948 0.0921 0.0922 0.0914 0.0942 0.093  0.0919 0.0861\n",
            " 0.0888], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08343709 0.09213006 0.09481475 0.0920659  0.09217322 0.09138695\n",
            " 0.09418523 0.09295937 0.09193458 0.0860718  0.08884107], argmax=2\n",
            "   \u001b[33m|->> #8/t=69-th Action selection: 0/LEFT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [230 222  70  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0925 0.089  0.0869 0.0909 0.0919 0.0914 0.0934 0.0936 0.092  0.0877\n",
            " 0.0907], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09250158 0.08897251 0.08688633 0.09093974 0.09192009 0.09139272\n",
            " 0.09337213 0.09356059 0.09201968 0.08770635 0.09072835], argmax=7\n",
            "   \u001b[33m|->> #9/t=70-th Action selection: 0/LEFT (P(a|s) = 0.0820000022649765)\u001b[0m\n",
            "      |->> Bounding box moves to: [228 222  70  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0822 0.0891 0.0981 0.0917 0.0914 0.0932 0.0947 0.095  0.0914 0.0844\n",
            " 0.0889], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08219637 0.08911545 0.09807193 0.09168258 0.09136751 0.09321384\n",
            " 0.09465358 0.09497358 0.09144785 0.08440267 0.08887466], argmax=2\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [229, 224,  73,  66] -> [228, 222,  70,  64] (Target was [271, 222,  91,  70])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for DOWN:bbox transition: [229, 224,  73,  66] -> [229, 225,  73,  66] w/ P(a|s)=0.0951741635799408 and iou=0.2238022314591993 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.036) for 2X RIGHT:bbox transition: [229, 225,  73,  66] -> [233, 225,  73,  66] w/ P(a|s)=0.09208248555660248 and iou=0.2601937373282271 and reward=0.036391505869027785 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X UP:bbox transition: [233, 225,  73,  66] -> [233, 223,  73,  66] w/ P(a|s)=0.09411781281232834 and iou=0.2601937373282271 and reward=0.0 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-0.018) for SCALE DOWN:bbox transition: [233, 223,  73,  66] -> [234, 224,  70,  64] w/ P(a|s)=0.08851908147335052 and iou=0.24170290684367132 and reward=-0.01849083048455577 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (0.037) for 2X RIGHT:bbox transition: [234, 224,  70,  64] -> [238, 224,  70,  64] w/ P(a|s)=0.09267881512641907 and iou=0.279179438811601 and reward=0.03747653196792969 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (0.0) for 2X UP:bbox transition: [238, 224,  70,  64] -> [238, 222,  70,  64] w/ P(a|s)=0.09250213950872421 and iou=0.279179438811601 and reward=0.0 and discount=1.0\n",
            "   |->> t=7 Diff-Reward (-0.019) for LEFT:bbox transition: [238, 222,  70,  64] -> [236, 222,  70,  64] w/ P(a|s)=0.09170285612344742 and iou=0.2601626016260163 and reward=-0.019016837185584723 and discount=1.0\n",
            "   |->> t=8 Diff-Reward (-0.036) for 2X LEFT:bbox transition: [236, 222,  70,  64] -> [232, 222,  70,  64] w/ P(a|s)=0.09213005751371384 and iou=0.22377622377622378 and reward=-0.03638637784979251 and discount=1.0\n",
            "   |->> t=9 Diff-Reward (-0.017) for LEFT:bbox transition: [232, 222,  70,  64] -> [230, 222,  70,  64] w/ P(a|s)=0.09250158071517944 and iou=0.20635979541916832 and reward=-0.017416428357055452 and discount=1.0\n",
            "   |->> t=10 Diff-Reward (-1.0) for LEFT:bbox transition: [230, 222,  70,  64] -> [228, 222,  70,  64] w/ P(a|s)=0.08219636976718903 and iou=0.18943214207410655 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.          0.08679631  0.         -0.0448317   0.08914226  0.\n",
            " -0.04543506 -0.08676528 -0.04146032 -2.498644  ]\n",
            "\u001b[31m>> Total frame loss: -2.5411977767944336\u001b[0m\n",
            "Final bounding box: [228 222  70  64] reached in 71 timesteps (originating from [237 219  85  73]). Target was [271 222  91  70]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 72 in t=71 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[31m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 9.29286003112793\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 2.650899887084961\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/BlurCar3\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0065.jpg\n",
            "Starting bounding box=adnet_datasets/OTB/BlurCar3/img/0075.jpg for adnet_datasets/OTB/BlurCar3's frames (index: 0)\n",
            "src:adnet_datasets/OTB/BlurCar3/img/0065.jpg\n",
            "target:adnet_datasets/OTB/BlurCar3/img/0075.jpg.\n",
            "\u001b[34m>> Attempting to reach frame 63 with src: [237, 218,  80,  73] and target: [238, 220,  87,  72]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0066.jpg\n",
            "|->> Beginning tracking for bbox:[237 218  80  73]\n",
            "|->> Revisiting bbox: [237 218  80  73]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 8/STOP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [237 218  80  73]\n",
            "         |->> Action Probabilities (Rounded): [0.091  0.0907 0.0909 0.091  0.0908 0.0909 0.0909 0.0909 0.0909 0.0911\n",
            " 0.091 ], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.09097967 0.09071834 0.0908737  0.0909574  0.09076229 0.09090375\n",
            " 0.09092928 0.09089237 0.09087975 0.09108942 0.09101405], argmax=9\n",
            "         |->> Hit a STOP on the 1-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [237, 218,  80,  73] -> [237, 218,  80,  73] (Target was [238, 220,  87,  72])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [237, 218,  80,  73] -> [237, 218,  80,  73] w/ P(a|s)=0.09087974578142166 and iou=0.8635873749037721 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [2.3982182]\n",
            "\u001b[92m>> Total frame loss: 2.3982181549072266\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 64 with src: [237, 218,  80,  73] and target: [259, 213,  84,  73]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0067.jpg\n",
            "|->> Beginning tracking for bbox:[237 218  80  73]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 4/UP (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [237 216  80  73]\n",
            "         |->> Action Probabilities (Rounded): [0.0905 0.0904 0.0916 0.0905 0.0905 0.0908 0.0913 0.0913 0.0921 0.0899\n",
            " 0.0912], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09054692 0.09039445 0.09161698 0.09045148 0.09047071 0.09075123\n",
            " 0.09133208 0.09129744 0.09209224 0.08986343 0.09118305], argmax=8\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [238 217  77  70]\n",
            "         |->> Action Probabilities (Rounded): [0.0908 0.0908 0.0909 0.092  0.0882 0.0915 0.0912 0.0921 0.0929 0.0891\n",
            " 0.0904], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09079126 0.09079815 0.09092093 0.09204981 0.08822364 0.09150395\n",
            " 0.09122086 0.09208107 0.09289213 0.08909759 0.09042054], argmax=8\n",
            "   \u001b[33m|->> #2/t=3-th Action selection: 1/2X LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [234 217  77  70]\n",
            "         |->> Action Probabilities (Rounded): [0.0903 0.0913 0.0915 0.0925 0.0895 0.0918 0.091  0.0925 0.093  0.0845\n",
            " 0.0921], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09034287 0.09127722 0.09154062 0.09252349 0.08951285 0.09178578\n",
            " 0.09099077 0.0924514  0.09301914 0.08448538 0.09207047], argmax=8\n",
            "|->> Revisiting bbox: [238 217  77  70]. ACtion 3 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [237, 218,  80,  73] -> [234, 217,  77,  70] (Target was [259, 213,  84,  73])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.022) for UP:bbox transition: [237, 218,  80,  73] -> [237, 216,  80,  73] w/ P(a|s)=0.09047070890665054 and iou=0.5131445904954499 and reward=0.021864072309102145 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.009) for SCALE DOWN:bbox transition: [237, 216,  80,  73] -> [238, 217,  77,  70] w/ P(a|s)=0.08909758925437927 and iou=0.5045703839122486 and reward=-0.008574206583201294 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [238, 217,  77,  70] -> [234, 217,  77,  70] w/ P(a|s)=0.09127721935510635 and iou=0.45223090496596924 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.05253344 -0.02073263 -2.3938541 ]\n",
            "\u001b[31m>> Total frame loss: -2.362053394317627\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 65 with src: [234, 217,  77,  70] and target: [280, 211,  83,  66]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0068.jpg\n",
            "|->> Beginning tracking for bbox:[234 217  77  70]\n",
            "|->> Revisiting bbox: [234 217  77  70]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=4-th Action selection: 8/STOP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [234 217  77  70]\n",
            "         |->> Action Probabilities (Rounded): [0.0902 0.0891 0.0917 0.0924 0.09   0.0917 0.0922 0.0928 0.0931 0.0864\n",
            " 0.0903], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09020881 0.08912905 0.09169248 0.09242713 0.09001304 0.09165395\n",
            " 0.09221831 0.09276628 0.09314228 0.08642158 0.09032711], argmax=8\n",
            "         |->> Hit a STOP on the 4-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [234, 217,  77,  70] -> [234, 217,  77,  70] (Target was [280, 211,  83,  66])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [234, 217,  77,  70] -> [234, 217,  77,  70] w/ P(a|s)=0.09314227849245071 and iou=0.20648312611012434 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.3736272]\n",
            "\u001b[31m>> Total frame loss: -2.373627185821533\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 66 with src: [234, 217,  77,  70] and target: [284, 212,  87,  76]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0069.jpg\n",
            "|->> Beginning tracking for bbox:[234 217  77  70]\n",
            "   \u001b[33m|->> #0/t=4-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08500000089406967)\u001b[0m\n",
            "      |->> Bounding box moves to: [235 218  74  67]\n",
            "         |->> Action Probabilities (Rounded): [0.09   0.0889 0.0921 0.0918 0.0905 0.0916 0.092  0.0935 0.0937 0.0849\n",
            " 0.091 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09003627 0.08892018 0.09209029 0.09175612 0.09047202 0.09158292\n",
            " 0.09198271 0.0934938  0.09373952 0.08489497 0.09103121], argmax=8\n",
            "   \u001b[33m|->> #1/t=5-th Action selection: 3/2X RIGHT (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [239 218  74  67]\n",
            "         |->> Action Probabilities (Rounded): [0.0887 0.0894 0.0904 0.0936 0.0912 0.0927 0.0925 0.0945 0.0943 0.0809\n",
            " 0.0918], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08870582 0.08935124 0.09044075 0.09364599 0.09121041 0.09274626\n",
            " 0.09251802 0.09446906 0.09425464 0.08087615 0.09178168], argmax=7\n",
            "   \u001b[33m|->> #2/t=6-th Action selection: 5/2X UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [239 214  74  67]\n",
            "         |->> Action Probabilities (Rounded): [0.0903 0.0902 0.0903 0.0918 0.0915 0.0929 0.0925 0.0943 0.0924 0.0832\n",
            " 0.0905], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.0903424  0.09020295 0.09034694 0.09176125 0.09154809 0.09289841\n",
            " 0.0924798  0.09426957 0.09241666 0.08323189 0.09050215], argmax=7\n",
            "   \u001b[33m|->> #3/t=7-th Action selection: 4/UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [239 212  74  67]\n",
            "         |->> Action Probabilities (Rounded): [0.0901 0.0899 0.0904 0.0925 0.0914 0.0912 0.094  0.0945 0.0926 0.0825\n",
            " 0.091 ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09006807 0.08986286 0.09039351 0.09249159 0.09135603 0.09120457\n",
            " 0.09397727 0.09452832 0.09264494 0.08247943 0.09099336], argmax=7\n",
            "   \u001b[33m|->> #4/t=8-th Action selection: 1/2X LEFT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [235 212  74  67]\n",
            "         |->> Action Probabilities (Rounded): [0.09   0.0903 0.0916 0.0927 0.0892 0.0915 0.0937 0.0942 0.0924 0.0838\n",
            " 0.0907], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08997679 0.09026452 0.09158135 0.09271962 0.08922578 0.09145722\n",
            " 0.09369421 0.09416914 0.09239394 0.08384189 0.09067554], argmax=7\n",
            "   \u001b[33m|->> #5/t=9-th Action selection: 2/RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [237 212  74  67]\n",
            "         |->> Action Probabilities (Rounded): [0.0909 0.0885 0.0907 0.0922 0.0915 0.0918 0.0935 0.0946 0.0905 0.0853\n",
            " 0.0905], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09091942 0.08845423 0.09071453 0.09220436 0.09150701 0.09183569\n",
            " 0.09354454 0.09459822 0.09046549 0.0852954  0.09046113], argmax=7\n",
            "|->> Revisiting bbox: [239 212  74  67]. ACtion 2 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [234, 217,  77,  70] -> [237, 212,  74,  67] (Target was [284, 212,  87,  76])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.018) for SCALE DOWN:bbox transition: [234, 217,  77,  70] -> [235, 218,  74,  67] w/ P(a|s)=0.08489497005939484 and iou=0.16927741283476502 and reward=-0.017629232734855227 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.033) for 2X RIGHT:bbox transition: [235, 218,  74,  67] -> [239, 218,  74,  67] w/ P(a|s)=0.09364598989486694 and iou=0.2018281915446141 and reward=0.03255077870984907 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X UP:bbox transition: [239, 218,  74,  67] -> [239, 214,  74,  67] w/ P(a|s)=0.0928984135389328 and iou=0.2018281915446141 and reward=0.0 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.0) for UP:bbox transition: [239, 214,  74,  67] -> [239, 212,  74,  67] w/ P(a|s)=0.09135603159666061 and iou=0.2018281915446141 and reward=0.0 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (-0.033) for 2X LEFT:bbox transition: [239, 212,  74,  67] -> [235, 212,  74,  67] w/ P(a|s)=0.09026452153921127 and iou=0.16927741283476502 and reward=-0.03255077870984907 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (-1.0) for RIGHT:bbox transition: [235, 212,  74,  67] -> [237, 212,  74,  67] w/ P(a|s)=0.09071452915668488 and iou=0.18532937199057473 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.04347969  0.07708785  0.          0.         -0.07828497 -2.4000378 ]\n",
            "\u001b[31m>> Total frame loss: -2.4447145462036133\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 67 with src: [237, 212,  74,  67] and target: [284, 231,  80,  75]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0070.jpg\n",
            "|->> Beginning tracking for bbox:[237 212  74  67]\n",
            "   \u001b[33m|->> #0/t=10-th Action selection: 7/2X DOWN (P(a|s) = 0.09600000083446503)\u001b[0m\n",
            "      |->> Bounding box moves to: [237 216  74  67]\n",
            "         |->> Action Probabilities (Rounded): [0.0965 0.0887 0.0823 0.0926 0.0909 0.0926 0.0946 0.0956 0.0911 0.0855\n",
            " 0.0895], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.0965203  0.08871904 0.08231416 0.09261306 0.09093214 0.09258398\n",
            " 0.09456165 0.09563034 0.09113788 0.08551289 0.08947461], argmax=0\n",
            "   \u001b[33m|->> #1/t=11-th Action selection: 4/UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [237 214  74  67]\n",
            "         |->> Action Probabilities (Rounded): [0.0858 0.0903 0.0922 0.0917 0.0925 0.0918 0.0938 0.094  0.0915 0.0863\n",
            " 0.0901], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08584674 0.09028985 0.09224997 0.091712   0.0924841  0.09180195\n",
            " 0.09377845 0.09396492 0.09147266 0.08629145 0.09010794], argmax=7\n",
            "|->> Revisiting bbox: [237 212  74  67]. ACtion 4 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [237, 212,  74,  67] -> [237, 214,  74,  67] (Target was [284, 231,  80,  75])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.013) for 2X DOWN:bbox transition: [237, 212,  74,  67] -> [237, 216,  74,  67] w/ P(a|s)=0.09563034027814865 and iou=0.14695415532761147 and reward=0.012820435600846836 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for UP:bbox transition: [237, 216,  74,  67] -> [237, 214,  74,  67] w/ P(a|s)=0.09248410165309906 and iou=0.14050791007493754 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.03009296 -2.3807185 ]\n",
            "\u001b[31m>> Total frame loss: -2.350625514984131\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 68 with src: [237, 214,  74,  67] and target: [261, 245,  90,  72]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0071.jpg\n",
            "|->> Beginning tracking for bbox:[237 214  74  67]\n",
            "   \u001b[33m|->> #0/t=12-th Action selection: 3/2X RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [241 214  74  67]\n",
            "         |->> Action Probabilities (Rounded): [0.0927 0.0895 0.0887 0.0915 0.0901 0.0915 0.0946 0.0935 0.0913 0.087\n",
            " 0.0896], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09272519 0.08954315 0.08871008 0.09151255 0.09013497 0.09148467\n",
            " 0.094556   0.09345412 0.0912881  0.08702854 0.08956264], argmax=6\n",
            "   \u001b[33m|->> #1/t=13-th Action selection: 4/UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [241 212  74  67]\n",
            "         |->> Action Probabilities (Rounded): [0.0924 0.0911 0.0893 0.0901 0.0914 0.0926 0.0933 0.093  0.0886 0.088\n",
            " 0.0902], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09237287 0.09113384 0.08931102 0.09008339 0.09140161 0.09261195\n",
            " 0.09331828 0.09298763 0.08857544 0.08795951 0.09024447], argmax=6\n",
            "   \u001b[33m|->> #2/t=14-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [242 213  71  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0927 0.0902 0.0883 0.0903 0.0894 0.0913 0.0946 0.0929 0.0912 0.0892\n",
            " 0.0899], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09272011 0.09023091 0.08826219 0.09029615 0.08938349 0.09134396\n",
            " 0.09457332 0.09292677 0.09115984 0.08922783 0.08987546], argmax=6\n",
            "   \u001b[33m|->> #3/t=15-th Action selection: 6/DOWN (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [242 214  71  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0912 0.0908 0.0888 0.0919 0.0908 0.092  0.0932 0.0928 0.0921 0.0851\n",
            " 0.0911], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09124042 0.09084944 0.08884284 0.09186815 0.09078527 0.09203199\n",
            " 0.09322318 0.09276003 0.09212871 0.08514005 0.09112997], argmax=6\n",
            "   \u001b[33m|->> #4/t=16-th Action selection: 0/LEFT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [240 214  71  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0922 0.0912 0.0897 0.0911 0.0933 0.0914 0.0914 0.0935 0.0906 0.0872\n",
            " 0.0884], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09215511 0.09119531 0.08971942 0.09109177 0.09327418 0.09144217\n",
            " 0.09142768 0.09346231 0.09060618 0.0872035  0.08842239], argmax=7\n",
            "|->> Revisiting bbox: [240 214  71  64]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [237, 214,  74,  67] -> [240, 214,  71,  64] (Target was [261, 245,  90,  72])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.018) for 2X RIGHT:bbox transition: [237, 214,  74,  67] -> [241, 214,  74,  67] w/ P(a|s)=0.09151255339384079 and iou=0.2047609016220771 and reward=0.018000162879599407 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.014) for UP:bbox transition: [241, 214,  74,  67] -> [241, 212,  74,  67] w/ P(a|s)=0.091401606798172 and iou=0.1912101645490523 and reward=-0.013550737073024816 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.013) for SCALE DOWN:bbox transition: [241, 212,  74,  67] -> [242, 213,  71,  64] w/ P(a|s)=0.0892278254032135 and iou=0.17777777777777778 and reward=-0.013432386771274507 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.007) for DOWN:bbox transition: [242, 213,  71,  64] -> [242, 214,  71,  64] w/ P(a|s)=0.09322317689657211 and iou=0.18435754189944134 and reward=0.006579764121663556 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (-1.0) for LEFT:bbox transition: [242, 214,  71,  64] -> [240, 214,  71,  64] w/ P(a|s)=0.0921551063656807 and iou=0.17601877533603585 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.04304342 -0.03242004 -0.0324602   0.01561219 -2.384282  ]\n",
            "\u001b[31m>> Total frame loss: -2.3905067443847656\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 69 with src: [240, 214,  71,  64] and target: [252, 242,  91,  71]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0072.jpg\n",
            "|->> Beginning tracking for bbox:[240 214  71  64]\n",
            "   \u001b[33m|->> #0/t=17-th Action selection: 6/DOWN (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [240 215  71  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0846 0.0917 0.0957 0.0924 0.0914 0.0932 0.0931 0.094  0.09   0.0845\n",
            " 0.0896], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08461226 0.0916602  0.09568679 0.09239437 0.09135305 0.09320001\n",
            " 0.09305727 0.09395871 0.09001444 0.08445413 0.08960878], argmax=2\n",
            "   \u001b[33m|->> #1/t=18-th Action selection: 3/2X RIGHT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [244 215  71  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0925 0.0909 0.0873 0.0929 0.0941 0.0925 0.0902 0.0933 0.0907 0.0864\n",
            " 0.0891], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.09252557 0.09093418 0.08734791 0.09291513 0.0941294  0.09253371\n",
            " 0.09019265 0.09328754 0.09068355 0.08638088 0.08906947], argmax=4\n",
            "   \u001b[33m|->> #2/t=19-th Action selection: 4/UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [244 214  71  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0905 0.0917 0.0911 0.0904 0.0914 0.0934 0.0925 0.0927 0.09   0.0866\n",
            " 0.0898], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.09051914 0.09172557 0.09105366 0.09039578 0.09136362 0.0933835\n",
            " 0.09248079 0.09266414 0.09000546 0.08656581 0.08984251], argmax=5\n",
            "   \u001b[33m|->> #3/t=20-th Action selection: 7/2X DOWN (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [244 216  71  64]\n",
            "         |->> Action Probabilities (Rounded): [0.094  0.0908 0.0879 0.0913 0.0908 0.0927 0.0925 0.0933 0.0904 0.087\n",
            " 0.0893], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09401566 0.09083    0.08793026 0.0912554  0.09080004 0.09270348\n",
            " 0.09245893 0.09328572 0.09036859 0.08701716 0.08933476], argmax=0\n",
            "   \u001b[33m|->> #4/t=21-th Action selection: 3/2X RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [248 216  71  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0921 0.0914 0.09   0.0911 0.0908 0.0927 0.0919 0.0919 0.0904 0.0875\n",
            " 0.0902], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.09207881 0.0913719  0.09001515 0.09107617 0.0907626  0.09271128\n",
            " 0.09190317 0.0918959  0.09040838 0.08753255 0.09024416], argmax=5\n",
            "   \u001b[33m|->> #5/t=22-th Action selection: 10/SCALE UP (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [246 215  73  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0924 0.0915 0.0882 0.0893 0.0925 0.0927 0.0934 0.0919 0.0896 0.0885\n",
            " 0.0902], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09238807 0.091463   0.08822202 0.0892645  0.09252983 0.09265588\n",
            " 0.09335647 0.09190624 0.08957934 0.0884802  0.09015447], argmax=6\n",
            "   \u001b[33m|->> #6/t=23-th Action selection: 6/DOWN (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [246 216  73  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0916 0.0919 0.0879 0.0911 0.0926 0.0934 0.0924 0.093  0.0911 0.0902\n",
            " 0.0849], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.09156602 0.09190878 0.08793321 0.09107906 0.09257276 0.09342233\n",
            " 0.09238415 0.09295601 0.091057   0.09021421 0.08490651], argmax=5\n",
            "   \u001b[33m|->> #7/t=24-th Action selection: 1/2X LEFT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [242 216  73  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0911 0.0915 0.0889 0.0918 0.0948 0.0934 0.0904 0.0926 0.0915 0.0876\n",
            " 0.0865], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.09105796 0.09154649 0.08892393 0.09176747 0.09475438 0.09339693\n",
            " 0.09038217 0.09256857 0.09150717 0.08762084 0.0864741 ], argmax=4\n",
            "|->> Revisiting bbox: [242 216  73  66]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [240, 214,  71,  64] -> [242, 216,  73,  66] (Target was [252, 242,  91,  71])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.008) for DOWN:bbox transition: [240, 214,  71,  64] -> [240, 215,  71,  64] w/ P(a|s)=0.09305727481842041 and iou=0.2474495579233734 and reward=0.008287301420727283 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.021) for 2X RIGHT:bbox transition: [240, 215,  71,  64] -> [244, 215,  71,  64] w/ P(a|s)=0.0929151326417923 and iou=0.2687341480285912 and reward=0.0212845901052178 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.009) for UP:bbox transition: [244, 215,  71,  64] -> [244, 214,  71,  64] w/ P(a|s)=0.09136361628770828 and iou=0.2595856701384915 and reward=-0.009148477890099704 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.018) for 2X DOWN:bbox transition: [244, 214,  71,  64] -> [244, 216,  71,  64] w/ P(a|s)=0.09328571707010269 and iou=0.27801649053536176 and reward=0.018430820396870273 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (0.023) for 2X RIGHT:bbox transition: [244, 216,  71,  64] -> [248, 216,  71,  64] w/ P(a|s)=0.09107617288827896 and iou=0.3009812034519447 and reward=0.02296471291658292 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (0.001) for SCALE UP:bbox transition: [248, 216,  71,  64] -> [246, 215,  73,  66] w/ P(a|s)=0.09015446901321411 and iou=0.30152319409185324 and reward=0.0005419906399085628 and discount=1.0\n",
            "   |->> t=7 Diff-Reward (0.01) for DOWN:bbox transition: [246, 215,  73,  66] -> [246, 216,  73,  66] w/ P(a|s)=0.09238415211439133 and iou=0.3116641469938365 and reward=0.010140952901983247 and discount=1.0\n",
            "   |->> t=8 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [246, 216,  73,  66] -> [242, 216,  73,  66] w/ P(a|s)=0.09154649078845978 and iou=0.2877040758077406 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 1.9678529e-02  5.0573651e-02 -2.1891464e-02  4.3719530e-02\n",
            "  5.5024806e-02  1.3041545e-03  2.4153721e-02 -2.3909082e+00]\n",
            "\u001b[31m>> Total frame loss: -2.2183454036712646\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 70 with src: [242, 216,  73,  66] and target: [261, 227,  92,  72]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0073.jpg\n",
            "|->> Beginning tracking for bbox:[242 216  73  66]\n",
            "   \u001b[33m|->> #0/t=25-th Action selection: 6/DOWN (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [242 217  73  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0926 0.0889 0.089  0.091  0.0922 0.0929 0.0927 0.0921 0.0909 0.0914\n",
            " 0.0863], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.0925878  0.08889141 0.08902193 0.09095524 0.09223275 0.09294488\n",
            " 0.0926868  0.09211612 0.09087616 0.09138942 0.08629747], argmax=5\n",
            "   \u001b[33m|->> #1/t=26-th Action selection: 2/RIGHT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [244 217  73  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0928 0.089  0.0901 0.0906 0.0943 0.0926 0.0902 0.0931 0.0907 0.0902\n",
            " 0.0864], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.09275871 0.08898944 0.0901367  0.0906238  0.0942964  0.09257094\n",
            " 0.09016734 0.09308654 0.0907484  0.0902086  0.08641312], argmax=4\n",
            "   \u001b[33m|->> #2/t=27-th Action selection: 5/2X UP (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [244 215  73  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0976 0.0897 0.0807 0.0922 0.092  0.0937 0.0929 0.0928 0.0908 0.0909\n",
            " 0.0866], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09760977 0.08972101 0.08070113 0.09216364 0.09201851 0.09372199\n",
            " 0.09292951 0.09281315 0.09082315 0.09089556 0.08660262], argmax=0\n",
            "   \u001b[33m|->> #3/t=28-th Action selection: 1/2X LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [240 215  73  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0886 0.0906 0.0905 0.09   0.0939 0.0915 0.092  0.0932 0.0911 0.0912\n",
            " 0.0874], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0886282  0.09064604 0.09045704 0.09003838 0.09385841 0.091463\n",
            " 0.09198599 0.09319508 0.09112864 0.09122789 0.08737129], argmax=4\n",
            "   \u001b[33m|->> #4/t=29-th Action selection: 5/2X UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [240 213  73  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0917 0.0878 0.089  0.0917 0.0921 0.0916 0.0938 0.0923 0.0913 0.091\n",
            " 0.0877], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09171266 0.08780796 0.08895382 0.09174569 0.09207738 0.09156285\n",
            " 0.09383393 0.09229913 0.09134318 0.09096935 0.08769408], argmax=6\n",
            "   \u001b[33m|->> #5/t=30-th Action selection: 6/DOWN (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [240 214  73  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0904 0.088  0.0909 0.0908 0.0928 0.0902 0.0932 0.0926 0.0911 0.0913\n",
            " 0.0886], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09036057 0.08801096 0.09091839 0.09081221 0.09278028 0.09019063\n",
            " 0.09323244 0.09264908 0.09109138 0.09134831 0.08860572], argmax=6\n",
            "|->> Revisiting bbox: [240 214  73  66]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [242, 216,  73,  66] -> [240, 214,  73,  66] (Target was [261, 227,  92,  72])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.009) for DOWN:bbox transition: [242, 216,  73,  66] -> [242, 217,  73,  66] w/ P(a|s)=0.09268680214881897 and iou=0.3592302209550962 and reward=0.008663648717135874 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.018) for RIGHT:bbox transition: [242, 217,  73,  66] -> [244, 217,  73,  66] w/ P(a|s)=0.09013669937849045 and iou=0.3775583915241994 and reward=0.018328170569103186 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.018) for 2X UP:bbox transition: [244, 217,  73,  66] -> [244, 215,  73,  66] w/ P(a|s)=0.09372199326753616 and iou=0.3592302209550962 and reward=-0.018328170569103186 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-0.034) for 2X LEFT:bbox transition: [244, 215,  73,  66] -> [240, 215,  73,  66] w/ P(a|s)=0.09064604341983795 and iou=0.325225851285615 and reward=-0.03400436966948123 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (-0.016) for 2X UP:bbox transition: [240, 215,  73,  66] -> [240, 213,  73,  66] w/ P(a|s)=0.09156285226345062 and iou=0.30945296406500344 and reward=-0.015772887220611542 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (-1.0) for DOWN:bbox transition: [240, 213,  73,  66] -> [240, 214,  73,  66] w/ P(a|s)=0.09323243796825409 and iou=0.31729219433571265 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.02060674  0.04410542 -0.04339052 -0.08163745 -0.03770871 -2.3726597 ]\n",
            "\u001b[31m>> Total frame loss: -2.470684289932251\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 71 with src: [240, 214,  73,  66] and target: [271, 222,  91,  70]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0074.jpg\n",
            "|->> Beginning tracking for bbox:[240 214  73  66]\n",
            "   \u001b[33m|->> #0/t=31-th Action selection: 2/RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [242 214  73  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0905 0.0881 0.0909 0.0929 0.0933 0.0907 0.0919 0.0927 0.0905 0.091\n",
            " 0.0874], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.09048289 0.08809322 0.09088563 0.09290311 0.09330674 0.09073719\n",
            " 0.09191745 0.0927441  0.09051671 0.0910182  0.08739477], argmax=4\n",
            "   \u001b[33m|->> #1/t=32-th Action selection: 4/UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [242 213  73  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0966 0.089  0.0837 0.0927 0.0916 0.0913 0.0937 0.0933 0.0914 0.089\n",
            " 0.0877], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.0965583  0.08895495 0.08365347 0.09271204 0.09161992 0.09131219\n",
            " 0.09374519 0.09327058 0.09143929 0.08899015 0.08774391], argmax=0\n",
            "   \u001b[33m|->> #2/t=33-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [243 214  70  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0879 0.0904 0.093  0.0912 0.091  0.0908 0.0936 0.0936 0.0913 0.0889\n",
            " 0.0884], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08789275 0.09038884 0.09300945 0.09119702 0.09101652 0.09077734\n",
            " 0.09358016 0.09355833 0.091277   0.08891848 0.08838416], argmax=6\n",
            "   \u001b[33m|->> #3/t=34-th Action selection: 1/2X LEFT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [239 214  70  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0923 0.0903 0.0889 0.0928 0.0907 0.0918 0.0931 0.0936 0.0911 0.0843\n",
            " 0.0912], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09226729 0.09027116 0.08893425 0.09276307 0.09073398 0.09178953\n",
            " 0.09313095 0.09355136 0.09107784 0.08432566 0.09115487], argmax=7\n",
            "   \u001b[33m|->> #4/t=35-th Action selection: 4/UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [239 213  70  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0894 0.089  0.0915 0.0919 0.0917 0.0916 0.0944 0.0936 0.0912 0.0869\n",
            " 0.0888], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08941422 0.08898392 0.09146925 0.09194688 0.0916539  0.0915952\n",
            " 0.09442985 0.0935688  0.09122455 0.08691835 0.08879507], argmax=6\n",
            "   \u001b[33m|->> #5/t=36-th Action selection: 3/2X RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [243 213  70  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0916 0.0893 0.0908 0.0924 0.0893 0.0915 0.0946 0.0939 0.0921 0.0853\n",
            " 0.0892], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09162001 0.08930432 0.09078077 0.09242077 0.08928738 0.09151559\n",
            " 0.0946019  0.09386228 0.09214623 0.08526435 0.08919638], argmax=6\n",
            "   \u001b[33m|->> #6/t=37-th Action selection: 7/2X DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [243 215  70  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0899 0.0894 0.0908 0.0904 0.0919 0.0912 0.0938 0.094  0.0913 0.0875\n",
            " 0.0896], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08991045 0.08938231 0.09080914 0.09043012 0.09194914 0.09121292\n",
            " 0.09382156 0.09396682 0.09133054 0.0875405  0.0896465 ], argmax=7\n",
            "   \u001b[33m|->> #7/t=38-th Action selection: 10/SCALE UP (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [241 214  72  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0912 0.0894 0.0895 0.0905 0.0919 0.0916 0.0943 0.0922 0.0907 0.0885\n",
            " 0.0902], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09122697 0.0893999  0.08947236 0.09052174 0.09187587 0.09158664\n",
            " 0.09433647 0.09221338 0.09070808 0.08845343 0.09020521], argmax=6\n",
            "   \u001b[33m|->> #8/t=39-th Action selection: 4/UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [241 213  72  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0909 0.0907 0.0891 0.0917 0.0922 0.0918 0.0943 0.0925 0.0919 0.0895\n",
            " 0.0854], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.0909136  0.09071168 0.08907827 0.09174193 0.09215484 0.09178074\n",
            " 0.09429879 0.09252927 0.09192699 0.08946961 0.0853942 ], argmax=6\n",
            "|->> Revisiting bbox: [241 213  72  66]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [240, 214,  73,  66] -> [241, 213,  72,  66] (Target was [271, 222,  91,  70])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.017) for RIGHT:bbox transition: [240, 214,  73,  66] -> [242, 214,  73,  66] w/ P(a|s)=0.09088563174009323 and iou=0.29550717924965264 and reward=0.017170798993711156 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.007) for UP:bbox transition: [242, 214,  73,  66] -> [242, 213,  73,  66] w/ P(a|s)=0.09161991626024246 and iou=0.2889400921658986 and reward=-0.006567087083754031 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.012) for SCALE DOWN:bbox transition: [242, 213,  73,  66] -> [243, 214,  70,  64] w/ P(a|s)=0.08891847729682922 and iou=0.27677100494233936 and reward=-0.01216908722355925 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-0.033) for 2X LEFT:bbox transition: [243, 214,  70,  64] -> [239, 214,  70,  64] w/ P(a|s)=0.09027116000652313 and iou=0.24398073836276082 and reward=-0.032790266579578536 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (-0.005) for UP:bbox transition: [239, 214,  70,  64] -> [239, 213,  70,  64] w/ P(a|s)=0.09165389835834503 and iou=0.23858447488584475 and reward=-0.0053962634769160744 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (0.032) for 2X RIGHT:bbox transition: [239, 213,  70,  64] -> [243, 213,  70,  64] w/ P(a|s)=0.09242077171802521 and iou=0.27049180327868855 and reward=0.0319073283928438 and discount=1.0\n",
            "   |->> t=7 Diff-Reward (0.013) for 2X DOWN:bbox transition: [243, 213,  70,  64] -> [243, 215,  70,  64] w/ P(a|s)=0.09396681934595108 and iou=0.28311258278145696 and reward=0.012620779502768409 and discount=1.0\n",
            "   |->> t=8 Diff-Reward (-0.003) for SCALE UP:bbox transition: [243, 215,  70,  64] -> [241, 214,  72,  66] w/ P(a|s)=0.09020521491765976 and iou=0.2804513009440479 and reward=-0.0026612818374090463 and discount=1.0\n",
            "   |->> t=9 Diff-Reward (-1.0) for UP:bbox transition: [241, 214,  72,  66] -> [241, 213,  72,  66] w/ P(a|s)=0.0921548381447792 and iou=0.27428964252978916 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.04117821 -0.01569604 -0.02944962 -0.07885853 -0.01289564  0.07598422\n",
            "  0.02984579 -0.00640216 -2.3842852 ]\n",
            "\u001b[31m>> Total frame loss: -2.3805789947509766\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 72 with src: [241, 213,  72,  66] and target: [276, 221,  89,  68]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0075.jpg\n",
            "|->> Beginning tracking for bbox:[241 213  72  66]\n",
            "   \u001b[33m|->> #0/t=40-th Action selection: 3/2X RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [245 213  72  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0908 0.0916 0.0891 0.0915 0.0906 0.0928 0.0934 0.0928 0.0919 0.0884\n",
            " 0.0871], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09082452 0.09164377 0.08907446 0.09153497 0.090587   0.0928375\n",
            " 0.09338532 0.09277181 0.09192859 0.08835459 0.08705739], argmax=6\n",
            "   \u001b[33m|->> #1/t=41-th Action selection: 3/2X RIGHT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [249 213  72  66]\n",
            "         |->> Action Probabilities (Rounded): [0.092  0.0915 0.089  0.0897 0.0918 0.0927 0.0932 0.0927 0.091  0.0899\n",
            " 0.0866], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09198483 0.09147379 0.08896128 0.08965484 0.09181124 0.09272045\n",
            " 0.09319012 0.09269324 0.09097114 0.08991089 0.08662812], argmax=6\n",
            "   \u001b[33m|->> #2/t=42-th Action selection: 10/SCALE UP (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [247 212  74  68]\n",
            "         |->> Action Probabilities (Rounded): [0.0907 0.0912 0.0874 0.0891 0.0925 0.0926 0.094  0.0935 0.0904 0.0904\n",
            " 0.0881], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.0907433  0.09124254 0.08741271 0.08913101 0.09251045 0.09255851\n",
            " 0.09397106 0.09345167 0.09038094 0.09044982 0.08814794], argmax=6\n",
            "   \u001b[33m|->> #3/t=43-th Action selection: 9/SCALE DOWN (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [248 213  71  65]\n",
            "         |->> Action Probabilities (Rounded): [0.0905 0.0915 0.086  0.0898 0.0933 0.0931 0.0936 0.094  0.0922 0.0928\n",
            " 0.0832], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09051613 0.09145671 0.08599959 0.08980903 0.09327136 0.09311181\n",
            " 0.09356976 0.09398118 0.09222221 0.09281277 0.08324941], argmax=7\n",
            "   \u001b[33m|->> #4/t=44-th Action selection: 0/LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [246 213  71  65]\n",
            "         |->> Action Probabilities (Rounded): [0.0905 0.0915 0.0871 0.0905 0.0931 0.0937 0.094  0.0941 0.0924 0.0872\n",
            " 0.086 ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09050716 0.09147988 0.08708364 0.09048514 0.093096   0.09369484\n",
            " 0.09398887 0.09410888 0.09238984 0.08718145 0.0859843 ], argmax=7\n",
            "   \u001b[33m|->> #5/t=45-th Action selection: 3/2X RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [250 213  71  65]\n",
            "         |->> Action Probabilities (Rounded): [0.085  0.092  0.0929 0.091  0.0933 0.0939 0.0937 0.0944 0.0915 0.0881\n",
            " 0.0843], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08502003 0.09198394 0.09287951 0.09100317 0.09330315 0.09387036\n",
            " 0.0937027  0.09436795 0.09154266 0.08806398 0.08426251], argmax=7\n",
            "|->> Revisiting bbox: [248 213  71  65]. ACtion 0 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [241, 213,  72,  66] -> [250, 213,  71,  65] (Target was [276, 221,  89,  68])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.034) for 2X RIGHT:bbox transition: [241, 213,  72,  66] -> [245, 213,  72,  66] w/ P(a|s)=0.09153497219085693 and iou=0.28222169475433184 and reward=0.03435844689108397 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.036) for 2X RIGHT:bbox transition: [245, 213,  72,  66] -> [249, 213,  72,  66] w/ P(a|s)=0.089654840528965 and iou=0.3185257505491823 and reward=0.036304055794850465 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.004) for SCALE UP:bbox transition: [249, 213,  72,  66] -> [247, 212,  74,  68] w/ P(a|s)=0.08814793825149536 and iou=0.3149839838652272 and reward=-0.0035417666839551165 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-0.017) for SCALE DOWN:bbox transition: [247, 212,  74,  68] -> [248, 213,  71,  65] w/ P(a|s)=0.09281276911497116 and iou=0.2983203505355404 and reward=-0.01666363332968679 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (-0.018) for LEFT:bbox transition: [248, 213,  71,  65] -> [246, 213,  71,  65] w/ P(a|s)=0.0905071571469307 and iou=0.28055222088835535 and reward=-0.01776812964718505 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [246, 213,  71,  65] -> [250, 213,  71,  65] w/ P(a|s)=0.0910031720995903 and iou=0.3165884966674895 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.08215222  0.08755769 -0.00860203 -0.03961231 -0.04268485 -2.3968608 ]\n",
            "\u001b[31m>> Total frame loss: -2.3180501461029053\u001b[0m\n",
            "Final bounding box: [250 213  71  65] reached in 46 timesteps (originating from [237 218  80  73]). Target was [276 221  89  68]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 73 in t=46 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[31m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 8.26050853729248\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 2.5028533935546875\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/BlurCar3\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0066.jpg\n",
            "Starting bounding box=adnet_datasets/OTB/BlurCar3/img/0076.jpg for adnet_datasets/OTB/BlurCar3's frames (index: 0)\n",
            "src:adnet_datasets/OTB/BlurCar3/img/0066.jpg\n",
            "target:adnet_datasets/OTB/BlurCar3/img/0076.jpg.\n",
            "\u001b[34m>> Attempting to reach frame 64 with src: [238, 220,  87,  72] and target: [259, 213,  84,  73]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0067.jpg\n",
            "|->> Beginning tracking for bbox:[238 220  87  72]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 5/2X UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [238 216  87  72]\n",
            "         |->> Action Probabilities (Rounded): [0.091  0.0907 0.0909 0.091  0.0908 0.0909 0.0909 0.0909 0.0909 0.0911\n",
            " 0.091 ], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.09097953 0.09071101 0.09087411 0.09095857 0.0907588  0.09090352\n",
            " 0.09092912 0.09089209 0.0908816  0.0910924  0.09101924], argmax=9\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 2/RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [240 216  87  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0912 0.0907 0.0912 0.091  0.0906 0.0895 0.0911 0.091  0.0914 0.0912\n",
            " 0.0911], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09116529 0.09069886 0.09120741 0.0909912  0.09058375 0.08946577\n",
            " 0.09114894 0.09098992 0.09144045 0.09123144 0.09107693], argmax=8\n",
            "   \u001b[33m|->> #2/t=3-th Action selection: 5/2X UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [240 212  87  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0976 0.0906 0.0837 0.0922 0.0905 0.0906 0.0921 0.0912 0.0914 0.0899\n",
            " 0.0901], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09760275 0.09058431 0.08373542 0.09221708 0.09048382 0.09059715\n",
            " 0.09210699 0.0912021  0.09142976 0.0899355  0.09010507], argmax=0\n",
            "   \u001b[33m|->> #3/t=4-th Action selection: 9/SCALE DOWN (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [241 213  84  69]\n",
            "         |->> Action Probabilities (Rounded): [0.089  0.0917 0.0931 0.0903 0.091  0.0888 0.0916 0.0918 0.0918 0.0905\n",
            " 0.0903], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08895223 0.09170321 0.09307474 0.09030484 0.09098397 0.08879023\n",
            " 0.09164102 0.09182453 0.09183374 0.0905453  0.09034621], argmax=2\n",
            "   \u001b[33m|->> #4/t=5-th Action selection: 5/2X UP (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [241 209  84  69]\n",
            "         |->> Action Probabilities (Rounded): [0.0926 0.0914 0.0897 0.0924 0.0907 0.0897 0.0927 0.0923 0.0923 0.085\n",
            " 0.0912], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09263169 0.09141075 0.08969653 0.09240391 0.09074413 0.08970372\n",
            " 0.09267247 0.09227034 0.0922735  0.08499775 0.09119516], argmax=6\n",
            "   \u001b[33m|->> #5/t=6-th Action selection: 1/2X LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [237 209  84  69]\n",
            "         |->> Action Probabilities (Rounded): [0.0912 0.0915 0.0918 0.0917 0.0905 0.0881 0.0924 0.0923 0.0923 0.0875\n",
            " 0.0905], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.0912189  0.09146321 0.09179186 0.09174506 0.09053498 0.0881424\n",
            " 0.09238727 0.09234022 0.09229294 0.08753792 0.09054521], argmax=6\n",
            "   \u001b[33m|->> #6/t=7-th Action selection: 2/RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [239 209  84  69]\n",
            "         |->> Action Probabilities (Rounded): [0.0916 0.0893 0.0913 0.0927 0.0908 0.0885 0.0931 0.0923 0.0924 0.0871\n",
            " 0.0908], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09162321 0.08931185 0.09130186 0.0926706  0.09081813 0.08851551\n",
            " 0.0931197  0.09234975 0.09238078 0.08707926 0.09082936], argmax=6\n",
            "|->> Revisiting bbox: [239 209  84  69]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [238, 220,  87,  72] -> [239, 209,  84,  69] (Target was [259, 213,  84,  73])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.052) for 2X UP:bbox transition: [238, 220,  87,  72] -> [238, 216,  87,  72] w/ P(a|s)=0.09090352058410645 and iou=0.5941358024691358 and reward=0.052344757693016386 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.029) for RIGHT:bbox transition: [238, 216,  87,  72] -> [240, 216,  87,  72] w/ P(a|s)=0.09120740741491318 and iou=0.6233630172865374 and reward=0.029227214817401648 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.015) for 2X UP:bbox transition: [240, 216,  87,  72] -> [240, 212,  87,  72] w/ P(a|s)=0.09059714525938034 and iou=0.6379492600422833 and reward=0.014586242755745826 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-0.02) for SCALE DOWN:bbox transition: [240, 212,  87,  72] -> [241, 213,  84,  69] w/ P(a|s)=0.09054529666900635 and iou=0.6175752644426363 and reward=-0.02037399559964692 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (-0.056) for 2X UP:bbox transition: [241, 213,  84,  69] -> [241, 209,  84,  69] w/ P(a|s)=0.08970372378826141 and iou=0.5616653574234093 and reward=-0.055909907019227045 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (-0.051) for 2X LEFT:bbox transition: [241, 209,  84,  69] -> [237, 209,  84,  69] w/ P(a|s)=0.09146320819854736 and iou=0.5102557609521398 and reward=-0.051409596471269525 and discount=1.0\n",
            "   |->> t=7 Diff-Reward (-1.0) for RIGHT:bbox transition: [237, 209,  84,  69] -> [239, 209,  84,  69] w/ P(a|s)=0.09130185842514038 and iou=0.5355303810504635 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.12552045  0.06998805  0.03502642 -0.0489364  -0.13481237 -0.12296242\n",
            " -2.3935843 ]\n",
            "\u001b[31m>> Total frame loss: -2.4697604179382324\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 65 with src: [239, 209,  84,  69] and target: [280, 211,  83,  66]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0068.jpg\n",
            "|->> Beginning tracking for bbox:[239 209  84  69]\n",
            "   \u001b[33m|->> #0/t=8-th Action selection: 0/LEFT (P(a|s) = 0.09799999743700027)\u001b[0m\n",
            "      |->> Bounding box moves to: [237 209  84  69]\n",
            "         |->> Action Probabilities (Rounded): [0.0975 0.0893 0.0834 0.0924 0.0908 0.09   0.0937 0.0932 0.0929 0.0871\n",
            " 0.0898], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09750245 0.08927742 0.08341467 0.09240467 0.09077709 0.08995464\n",
            " 0.09372185 0.09316281 0.09285295 0.08714588 0.08978555], argmax=0\n",
            "   \u001b[33m|->> #1/t=9-th Action selection: 0/LEFT (P(a|s) = 0.08100000023841858)\u001b[0m\n",
            "      |->> Bounding box moves to: [235 209  84  69]\n",
            "         |->> Action Probabilities (Rounded): [0.0813 0.0904 0.0992 0.0922 0.0915 0.091  0.0937 0.0947 0.0919 0.0852\n",
            " 0.0888], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08131479 0.09035809 0.09915762 0.0922157  0.09154646 0.09102496\n",
            " 0.09373666 0.09471945 0.09188242 0.08519475 0.08884909], argmax=2\n",
            "   \u001b[33m|->> #2/t=10-th Action selection: 6/DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [235 211  84  69]\n",
            "         |->> Action Probabilities (Rounded): [0.087  0.0897 0.0925 0.0938 0.0907 0.0923 0.0945 0.0953 0.0915 0.0836\n",
            " 0.0891], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08701601 0.08965175 0.09246533 0.09378447 0.09074955 0.09230883\n",
            " 0.09446204 0.09530423 0.09149122 0.08363326 0.08913329], argmax=7\n",
            "   \u001b[33m|->> #3/t=11-th Action selection: 6/DOWN (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [235 213  84  69]\n",
            "         |->> Action Probabilities (Rounded): [0.0893 0.0893 0.0927 0.0933 0.0927 0.0921 0.0919 0.0955 0.0905 0.0841\n",
            " 0.0886], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08925606 0.0892627  0.09266685 0.09329996 0.0926793  0.09213137\n",
            " 0.09190173 0.0955142  0.09054675 0.08409335 0.08864773], argmax=7\n",
            "|->> Revisiting bbox: [235 213  84  69]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [239, 209,  84,  69] -> [235, 213,  84,  69] (Target was [280, 211,  83,  66])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.021) for LEFT:bbox transition: [239, 209,  84,  69] -> [237, 209,  84,  69] w/ P(a|s)=0.0975024476647377 and iou=0.3158263305322129 and reward=-0.020589032198939317 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.02) for LEFT:bbox transition: [237, 209,  84,  69] -> [235, 209,  84,  69] w/ P(a|s)=0.08131479471921921 and iou=0.29586206896551726 and reward=-0.019964261566695618 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.0) for DOWN:bbox transition: [235, 209,  84,  69] -> [235, 211,  84,  69] w/ P(a|s)=0.09446204453706741 and iou=0.29586206896551726 and reward=0.0 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-1.0) for DOWN:bbox transition: [235, 211,  84,  69] -> [235, 213,  84,  69] w/ P(a|s)=0.09190172702074051 and iou=0.2843472317156528 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.04792875 -0.05009886  0.         -2.3870354 ]\n",
            "\u001b[31m>> Total frame loss: -2.485063076019287\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 66 with src: [235, 213,  84,  69] and target: [284, 212,  87,  76]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0069.jpg\n",
            "|->> Beginning tracking for bbox:[235 213  84  69]\n",
            "   \u001b[33m|->> #0/t=12-th Action selection: 7/2X DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [235 217  84  69]\n",
            "         |->> Action Probabilities (Rounded): [0.0912 0.0895 0.0925 0.0933 0.0921 0.0929 0.0912 0.0944 0.0897 0.0846\n",
            " 0.0887], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09119524 0.08946076 0.0925466  0.09327751 0.09208389 0.09286837\n",
            " 0.091166   0.09438008 0.08972379 0.08462792 0.08866982], argmax=7\n",
            "   \u001b[33m|->> #1/t=13-th Action selection: 4/UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [235 215  84  69]\n",
            "         |->> Action Probabilities (Rounded): [0.0915 0.0887 0.0919 0.0935 0.0915 0.0923 0.0918 0.0927 0.0907 0.0859\n",
            " 0.0895], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.0914739  0.08871312 0.09192585 0.09354369 0.09145725 0.09225858\n",
            " 0.09176033 0.09270304 0.09071991 0.08593866 0.08950569], argmax=3\n",
            "   \u001b[33m|->> #2/t=14-th Action selection: 2/RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [237 215  84  69]\n",
            "         |->> Action Probabilities (Rounded): [0.0922 0.0896 0.0921 0.0929 0.0904 0.093  0.0927 0.0926 0.0904 0.0852\n",
            " 0.089 ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.09218501 0.08963489 0.09205463 0.09285753 0.09035598 0.09298152\n",
            " 0.09273463 0.09258003 0.0904175  0.08516724 0.08903106], argmax=5\n",
            "   \u001b[33m|->> #3/t=15-th Action selection: 2/RIGHT (P(a|s) = 0.08399999886751175)\u001b[0m\n",
            "      |->> Bounding box moves to: [239 215  84  69]\n",
            "         |->> Action Probabilities (Rounded): [0.0991 0.0895 0.0839 0.0932 0.0911 0.0937 0.0926 0.0925 0.0895 0.0865\n",
            " 0.0884], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09907053 0.08954661 0.08392898 0.09320781 0.09111517 0.09365021\n",
            " 0.09255996 0.09245516 0.08949539 0.08653644 0.08843383], argmax=0\n",
            "   \u001b[33m|->> #4/t=16-th Action selection: 10/SCALE UP (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [237 213  86  71]\n",
            "         |->> Action Probabilities (Rounded): [0.0954 0.0905 0.0849 0.0924 0.092  0.0947 0.0936 0.0929 0.0904 0.0861\n",
            " 0.087 ], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09541233 0.09052349 0.08488531 0.09243767 0.09196404 0.09471703\n",
            " 0.09358191 0.09294353 0.09042362 0.0861159  0.08699515], argmax=0\n",
            "   \u001b[33m|->> #5/t=17-th Action selection: 1/2X LEFT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [233 213  86  71]\n",
            "         |->> Action Probabilities (Rounded): [0.0922 0.0918 0.0902 0.092  0.093  0.0943 0.0928 0.0938 0.0909 0.0872\n",
            " 0.0819], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.09217143 0.09177996 0.09020811 0.09198775 0.09298714 0.09427854\n",
            " 0.09283292 0.09378862 0.09086479 0.08722568 0.08187499], argmax=5\n",
            "|->> Revisiting bbox: [233 213  86  71]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [235, 213,  84,  69] -> [233, 213,  86,  71] (Target was [284, 212,  87,  76])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X DOWN:bbox transition: [235, 213,  84,  69] -> [235, 217,  84,  69] w/ P(a|s)=0.09438008069992065 and iou=0.24166916841789252 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for UP:bbox transition: [235, 217,  84,  69] -> [235, 215,  84,  69] w/ P(a|s)=0.09145724773406982 and iou=0.24166916841789252 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.017) for RIGHT:bbox transition: [235, 215,  84,  69] -> [237, 215,  84,  69] w/ P(a|s)=0.09205462783575058 and iou=0.25905631659056316 and reward=0.017387148172670647 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.018) for RIGHT:bbox transition: [237, 215,  84,  69] -> [239, 215,  84,  69] w/ P(a|s)=0.08392897993326187 and iou=0.27693732633528867 and reward=0.017881009744725507 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (0.001) for SCALE UP:bbox transition: [239, 215,  84,  69] -> [237, 213,  86,  71] w/ P(a|s)=0.08699514716863632 and iou=0.2783194290883506 and reward=0.0013821027530619423 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [237, 213,  86,  71] -> [233, 213,  86,  71] w/ P(a|s)=0.09177996218204498 and iou=0.24284178637740644 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.          0.          0.04147483  0.04430529  0.00337496 -2.3883612 ]\n",
            "\u001b[31m>> Total frame loss: -2.299206018447876\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 67 with src: [233, 213,  86,  71] and target: [284, 231,  80,  75]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0070.jpg\n",
            "|->> Beginning tracking for bbox:[233 213  86  71]\n",
            "|->> Revisiting bbox: [233 213  86  71]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=18-th Action selection: 8/STOP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [233 213  86  71]\n",
            "         |->> Action Probabilities (Rounded): [0.0944 0.0883 0.0894 0.0925 0.0926 0.0937 0.0932 0.0942 0.0907 0.0865\n",
            " 0.0846], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09435736 0.08827743 0.08937249 0.09254889 0.09260375 0.09371755\n",
            " 0.09320652 0.0941981  0.09066664 0.08648144 0.08456983], argmax=0\n",
            "         |->> Hit a STOP on the 18-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [233, 213,  86,  71] -> [233, 213,  86,  71] (Target was [284, 231,  80,  75])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [233, 213,  86,  71] -> [233, 213,  86,  71] w/ P(a|s)=0.09066664427518845 and iou=0.18095795532143205 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.4005659]\n",
            "\u001b[31m>> Total frame loss: -2.4005658626556396\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 68 with src: [233, 213,  86,  71] and target: [261, 245,  90,  72]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0071.jpg\n",
            "|->> Beginning tracking for bbox:[233 213  86  71]\n",
            "   \u001b[33m|->> #0/t=18-th Action selection: 4/UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [233 211  86  71]\n",
            "         |->> Action Probabilities (Rounded): [0.0923 0.089  0.0913 0.0915 0.0918 0.0932 0.0937 0.0931 0.0911 0.0877\n",
            " 0.0853], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09228951 0.08898546 0.09129806 0.09146217 0.09183368 0.09320613\n",
            " 0.09366369 0.09313478 0.09114917 0.08768345 0.08529385], argmax=6\n",
            "   \u001b[33m|->> #1/t=19-th Action selection: 4/UP (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [233 209  86  71]\n",
            "         |->> Action Probabilities (Rounded): [0.0911 0.0905 0.0894 0.0926 0.0904 0.093  0.0942 0.0934 0.0919 0.0875\n",
            " 0.086 ], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09106056 0.09053139 0.08937325 0.09258404 0.09040152 0.09300094\n",
            " 0.09424455 0.09339896 0.09190894 0.08746073 0.08603515], argmax=6\n",
            "|->> Revisiting bbox: [233 211  86  71]. ACtion 6 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [233, 213,  86,  71] -> [233, 209,  86,  71] (Target was [261, 245,  90,  72])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.014) for UP:bbox transition: [233, 213,  86,  71] -> [233, 211,  86,  71] w/ P(a|s)=0.0918336808681488 and iou=0.20555555555555555 and reward=-0.013545568039950079 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for UP:bbox transition: [233, 211,  86,  71] -> [233, 209,  86,  71] w/ P(a|s)=0.09040152281522751 and iou=0.19230769230769232 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.03234378 -2.4034941 ]\n",
            "\u001b[31m>> Total frame loss: -2.435837984085083\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 69 with src: [233, 209,  86,  71] and target: [252, 242,  91,  71]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0072.jpg\n",
            "|->> Beginning tracking for bbox:[233 209  86  71]\n",
            "   \u001b[33m|->> #0/t=20-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [234 210  83  68]\n",
            "         |->> Action Probabilities (Rounded): [0.0919 0.0912 0.0901 0.0921 0.0891 0.0929 0.0933 0.0932 0.0919 0.0879\n",
            " 0.0863], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09192482 0.09118374 0.09013154 0.09209035 0.08908325 0.09293688\n",
            " 0.09333404 0.09321298 0.09192269 0.08786983 0.08630987], argmax=6\n",
            "   \u001b[33m|->> #1/t=21-th Action selection: 10/SCALE UP (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [232 208  85  70]\n",
            "         |->> Action Probabilities (Rounded): [0.0917 0.0912 0.09   0.0926 0.0904 0.0931 0.0938 0.0946 0.0915 0.0829\n",
            " 0.0881], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09167047 0.09123741 0.08995868 0.09262669 0.09044819 0.09313634\n",
            " 0.09383915 0.09457991 0.09146108 0.08290389 0.08813816], argmax=7\n",
            "   \u001b[33m|->> #2/t=22-th Action selection: 10/SCALE UP (P(a|s) = 0.0820000022649765)\u001b[0m\n",
            "      |->> Bounding box moves to: [230 206  87  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0909 0.0914 0.0896 0.0929 0.0914 0.0937 0.0937 0.0951 0.0919 0.0875\n",
            " 0.0819], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.0909401  0.0913645  0.08958135 0.09287953 0.09143845 0.09374735\n",
            " 0.09374693 0.09511237 0.09185632 0.08747888 0.08185426], argmax=7\n",
            "   \u001b[33m|->> #3/t=23-th Action selection: 7/2X DOWN (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [230 210  87  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0899 0.0914 0.0895 0.0938 0.0925 0.0942 0.094  0.0951 0.0929 0.087\n",
            " 0.0796], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08991443 0.09142568 0.08946481 0.09383225 0.09251045 0.09418254\n",
            " 0.09402138 0.09512748 0.0929272  0.08701707 0.07957671], argmax=7\n",
            "   \u001b[33m|->> #4/t=24-th Action selection: 3/2X RIGHT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [234 210  87  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0899 0.0911 0.0903 0.0932 0.0932 0.0931 0.0932 0.0933 0.0922 0.0882\n",
            " 0.0823], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08988595 0.09106784 0.09033871 0.09322913 0.09316703 0.09312654\n",
            " 0.09323531 0.09326538 0.09217954 0.08821949 0.08228508], argmax=7\n",
            "|->> Revisiting bbox: [230 210  87  72]. ACtion 1 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [233, 209,  86,  71] -> [234, 210,  87,  72] (Target was [252, 242,  91,  71])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.014) for SCALE DOWN:bbox transition: [233, 209,  86,  71] -> [234, 210,  83,  68] w/ P(a|s)=0.08786983042955399 and iou=0.23963133640552994 and reward=-0.014435124027560559 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.007) for SCALE UP:bbox transition: [234, 210,  83,  68] -> [232, 208,  85,  70] w/ P(a|s)=0.0881381556391716 and iou=0.2323503127792672 and reward=-0.007281023626262734 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.007) for SCALE UP:bbox transition: [232, 208,  85,  70] -> [230, 206,  87,  72] w/ P(a|s)=0.08185426145792007 and iou=0.22532498796340877 and reward=-0.007025324815858436 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.031) for 2X DOWN:bbox transition: [230, 206,  87,  72] -> [230, 210,  87,  72] w/ P(a|s)=0.09512747824192047 and iou=0.25679012345679014 and reward=0.03146513549338137 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [230, 210,  87,  72] -> [234, 210,  87,  72] w/ P(a|s)=0.09322912991046906 and iou=0.2769693928750627 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.03510476 -0.01768451 -0.01758309  0.07402291 -2.372695  ]\n",
            "\u001b[31m>> Total frame loss: -2.369044303894043\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 70 with src: [234, 210,  87,  72] and target: [261, 227,  92,  72]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0073.jpg\n",
            "|->> Beginning tracking for bbox:[234 210  87  72]\n",
            "   \u001b[33m|->> #0/t=25-th Action selection: 0/LEFT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [232 210  87  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0901 0.0915 0.0901 0.0919 0.093  0.0926 0.0942 0.0929 0.0905 0.0896\n",
            " 0.0835], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09013839 0.09148208 0.09013071 0.09192152 0.093031   0.09256963\n",
            " 0.09421672 0.09292727 0.09050263 0.08957347 0.0835066 ], argmax=6\n",
            "   \u001b[33m|->> #1/t=26-th Action selection: 5/2X UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [232 206  87  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0833 0.0914 0.0954 0.0931 0.093  0.0935 0.0939 0.0937 0.0904 0.0868\n",
            " 0.0855], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08327317 0.09144197 0.09538121 0.09311113 0.09298655 0.09348449\n",
            " 0.09391277 0.09370957 0.09040792 0.08678839 0.08550274], argmax=2\n",
            "   \u001b[33m|->> #2/t=27-th Action selection: 0/LEFT (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [230 206  87  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0936 0.0917 0.0869 0.0929 0.0928 0.092  0.0937 0.0936 0.0889 0.0879\n",
            " 0.0861], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.093563   0.09173486 0.08692028 0.09285966 0.09281781 0.09196585\n",
            " 0.09371736 0.09356102 0.08889403 0.08789825 0.08606787], argmax=6\n",
            "   \u001b[33m|->> #3/t=28-th Action selection: 5/2X UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [230 202  87  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0812 0.0916 0.0981 0.0934 0.0926 0.0928 0.094  0.0938 0.0905 0.0866\n",
            " 0.0856], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08117269 0.09162118 0.0980657  0.09336989 0.09255251 0.09280472\n",
            " 0.09401956 0.0938121  0.09046226 0.08655765 0.08556172], argmax=2\n",
            "   \u001b[33m|->> #4/t=29-th Action selection: 10/SCALE UP (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [228 200  89  74]\n",
            "         |->> Action Probabilities (Rounded): [0.0935 0.09   0.0862 0.0933 0.0922 0.0905 0.0934 0.0944 0.0907 0.0886\n",
            " 0.0872], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09346556 0.09002933 0.08618177 0.09333181 0.09218044 0.09048926\n",
            " 0.09342831 0.09440639 0.09069218 0.08860872 0.08718621], argmax=7\n",
            "   \u001b[33m|->> #5/t=30-th Action selection: 10/SCALE UP (P(a|s) = 0.08100000023841858)\u001b[0m\n",
            "      |->> Bounding box moves to: [226 198  91  76]\n",
            "         |->> Action Probabilities (Rounded): [0.0874 0.0905 0.0919 0.0948 0.0927 0.0921 0.094  0.0943 0.0918 0.0893\n",
            " 0.0814], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.08737782 0.09052591 0.09187787 0.09480079 0.09270167 0.09206815\n",
            " 0.09397683 0.09425238 0.09175871 0.08928312 0.0813768 ], argmax=3\n",
            "   \u001b[33m|->> #6/t=31-th Action selection: 0/LEFT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [224 198  91  76]\n",
            "         |->> Action Probabilities (Rounded): [0.0928 0.0902 0.0883 0.0934 0.0927 0.0916 0.0934 0.0944 0.0919 0.0915\n",
            " 0.0798], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09275734 0.0902413  0.08834727 0.09344085 0.09267157 0.09161515\n",
            " 0.09339184 0.09439677 0.09191194 0.09147393 0.07975208], argmax=7\n",
            "|->> Revisiting bbox: [224 198  91  76]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [234, 210,  87,  72] -> [224, 198,  91,  76] (Target was [261, 227,  92,  72])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.015) for LEFT:bbox transition: [234, 210,  87,  72] -> [232, 210,  87,  72] w/ P(a|s)=0.09013839066028595 and iou=0.32893380078366674 and reward=-0.015246424497935285 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.031) for 2X UP:bbox transition: [232, 210,  87,  72] -> [232, 206,  87,  72] w/ P(a|s)=0.09348449110984802 and iou=0.29788519637462235 and reward=-0.03104860440904439 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.013) for LEFT:bbox transition: [232, 206,  87,  72] -> [230, 206,  87,  72] w/ P(a|s)=0.09356299787759781 and iou=0.284688995215311 and reward=-0.01319620115931136 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-0.028) for 2X UP:bbox transition: [230, 206,  87,  72] -> [230, 202,  87,  72] w/ P(a|s)=0.09280472248792648 and iou=0.25663026521060844 and reward=-0.028058730004702548 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (-0.008) for SCALE UP:bbox transition: [230, 202,  87,  72] -> [228, 200,  89,  74] w/ P(a|s)=0.08718620985746384 and iou=0.24881830213650974 and reward=-0.0078119630740987045 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (-0.008) for SCALE UP:bbox transition: [228, 200,  89,  74] -> [226, 198,  91,  76] w/ P(a|s)=0.08137679845094681 and iou=0.2412907957462413 and reward=-0.007527506390268446 and discount=1.0\n",
            "   |->> t=7 Diff-Reward (-1.0) for LEFT:bbox transition: [226, 198,  91,  76] -> [224, 198,  91,  76] w/ P(a|s)=0.09275733679533005 and iou=0.2306853299400109 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.03668913 -0.07358395 -0.03126339 -0.06670284 -0.01905892 -0.01888399\n",
            " -2.3777685 ]\n",
            "\u001b[31m>> Total frame loss: -2.623950719833374\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 71 with src: [224, 198,  91,  76] and target: [271, 222,  91,  70]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0074.jpg\n",
            "|->> Beginning tracking for bbox:[224 198  91  76]\n",
            "   \u001b[33m|->> #0/t=32-th Action selection: 6/DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [224 200  91  76]\n",
            "         |->> Action Probabilities (Rounded): [0.0846 0.0901 0.0973 0.0946 0.0916 0.0928 0.0937 0.0942 0.0926 0.0874\n",
            " 0.0812], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08463093 0.09007651 0.0972553  0.094634   0.09160935 0.09276633\n",
            " 0.09368984 0.09418273 0.09264985 0.08735239 0.08115273], argmax=2\n",
            "|->> Revisiting bbox: [224 198  91  76]. ACtion 4 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [224, 198,  91,  76] -> [224, 200,  91,  76] (Target was [271, 222,  91,  70])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for DOWN:bbox transition: [224, 198,  91,  76] -> [224, 200,  91,  76] w/ P(a|s)=0.09368983656167984 and iou=0.21778185151237398 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.3677657]\n",
            "\u001b[31m>> Total frame loss: -2.3677656650543213\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 72 with src: [224, 200,  91,  76] and target: [276, 221,  89,  68]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0075.jpg\n",
            "|->> Beginning tracking for bbox:[224 200  91  76]\n",
            "   \u001b[33m|->> #0/t=33-th Action selection: 3/2X RIGHT (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [228 200  91  76]\n",
            "         |->> Action Probabilities (Rounded): [0.0949 0.0897 0.0886 0.0937 0.0935 0.0925 0.0908 0.0939 0.0906 0.0883\n",
            " 0.0836], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09485292 0.0897032  0.08857971 0.09367736 0.09346008 0.09251851\n",
            " 0.09080681 0.09386507 0.09056919 0.08833909 0.0836281 ], argmax=0\n",
            "   \u001b[33m|->> #1/t=34-th Action selection: 10/SCALE UP (P(a|s) = 0.08399999886751175)\u001b[0m\n",
            "      |->> Bounding box moves to: [226 198  93  78]\n",
            "         |->> Action Probabilities (Rounded): [0.0917 0.0893 0.0922 0.0916 0.0916 0.0932 0.0933 0.0947 0.09   0.0882\n",
            " 0.0841], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09171839 0.08933349 0.09223713 0.09156562 0.09156051 0.09324721\n",
            " 0.0933001  0.09469745 0.08999746 0.0882308  0.08411191], argmax=7\n",
            "   \u001b[33m|->> #2/t=35-th Action selection: 1/2X LEFT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [222 198  93  78]\n",
            "         |->> Action Probabilities (Rounded): [0.0937 0.0896 0.0885 0.093  0.093  0.0933 0.0924 0.0954 0.0915 0.09\n",
            " 0.0795], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09373567 0.08957428 0.08851294 0.09301598 0.09303711 0.09326713\n",
            " 0.09239049 0.09544265 0.09151005 0.08997129 0.07954247], argmax=7\n",
            "   \u001b[33m|->> #3/t=36-th Action selection: 0/LEFT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [220 198  93  78]\n",
            "         |->> Action Probabilities (Rounded): [0.0917 0.0879 0.0912 0.0928 0.0922 0.0929 0.0935 0.0947 0.0915 0.0893\n",
            " 0.0823], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09171145 0.08793639 0.09115152 0.09276294 0.09221066 0.09290732\n",
            " 0.09347276 0.09471901 0.09150785 0.0893141  0.08230603], argmax=7\n",
            "   \u001b[33m|->> #4/t=37-th Action selection: 6/DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [220 200  93  78]\n",
            "         |->> Action Probabilities (Rounded): [0.0848 0.0879 0.0964 0.093  0.0926 0.0944 0.094  0.0951 0.0912 0.0887\n",
            " 0.082 ], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08480848 0.08785929 0.09640712 0.0930397  0.09262179 0.09435228\n",
            " 0.09403643 0.09505127 0.09116735 0.08866312 0.08199323], argmax=2\n",
            "   \u001b[33m|->> #5/t=38-th Action selection: 10/SCALE UP (P(a|s) = 0.08299999684095383)\u001b[0m\n",
            "      |->> Bounding box moves to: [218 198  95  80]\n",
            "         |->> Action Probabilities (Rounded): [0.092  0.0882 0.089  0.0934 0.0943 0.0937 0.0918 0.0944 0.0901 0.0897\n",
            " 0.0834], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09199879 0.08817522 0.08898649 0.09344169 0.09430493 0.09372902\n",
            " 0.09176592 0.09442995 0.09010139 0.08966366 0.08340301], argmax=7\n",
            "   \u001b[33m|->> #6/t=39-th Action selection: 1/2X LEFT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [214 198  95  80]\n",
            "         |->> Action Probabilities (Rounded): [0.0882 0.0891 0.0916 0.0934 0.0935 0.0948 0.0932 0.0953 0.0908 0.0911\n",
            " 0.0791], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08821011 0.08910886 0.09163919 0.09335993 0.0934652  0.09478967\n",
            " 0.09316099 0.09531858 0.09075547 0.09105199 0.07914003], argmax=7\n",
            "   \u001b[33m|->> #7/t=40-th Action selection: 0/LEFT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [212 198  95  80]\n",
            "         |->> Action Probabilities (Rounded): [0.092  0.0861 0.0894 0.093  0.0936 0.0941 0.0928 0.095  0.091  0.0894\n",
            " 0.0836], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09203798 0.086124   0.08939022 0.0929977  0.09355383 0.09410454\n",
            " 0.09276688 0.09503909 0.09102088 0.08936189 0.08360295], argmax=7\n",
            "   \u001b[33m|->> #8/t=41-th Action selection: 7/2X DOWN (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [212 202  95  80]\n",
            "         |->> Action Probabilities (Rounded): [0.0848 0.0864 0.0979 0.0934 0.092  0.0949 0.0939 0.0948 0.0908 0.0874\n",
            " 0.0836], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08481383 0.08642275 0.09792689 0.09344243 0.09201775 0.0948821\n",
            " 0.09391073 0.09476549 0.09082343 0.08736453 0.08363007], argmax=2\n",
            "   \u001b[33m|->> #9/t=42-th Action selection: 3/2X RIGHT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [216 202  95  80]\n",
            "         |->> Action Probabilities (Rounded): [0.0917 0.0869 0.0882 0.0927 0.0937 0.0942 0.0943 0.0925 0.09   0.0898\n",
            " 0.0859], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09172585 0.08687463 0.08824138 0.09266868 0.09371276 0.09419882\n",
            " 0.09428383 0.09246641 0.09004527 0.08984594 0.08593643], argmax=6\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [224, 200,  91,  76] -> [216, 202,  95,  80] (Target was [276, 221,  89,  68])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.025) for 2X RIGHT:bbox transition: [224, 200,  91,  76] -> [228, 200,  91,  76] w/ P(a|s)=0.09367736428976059 and iou=0.22305008016599076 and reward=0.02486103831068262 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.007) for SCALE UP:bbox transition: [228, 200,  91,  76] -> [226, 198,  93,  78] w/ P(a|s)=0.08411191403865814 and iou=0.21615940042043688 and reward=-0.006890679745553879 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.024) for 2X LEFT:bbox transition: [226, 198,  93,  78] -> [222, 198,  93,  78] w/ P(a|s)=0.08957427740097046 and iou=0.19218708001075172 and reward=-0.023972320409685166 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-0.012) for LEFT:bbox transition: [222, 198,  93,  78] -> [220, 198,  93,  78] w/ P(a|s)=0.09171145409345627 and iou=0.18055185875255078 and reward=-0.011635221258200934 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (0.008) for DOWN:bbox transition: [220, 198,  93,  78] -> [220, 200,  93,  78] w/ P(a|s)=0.09403643012046814 and iou=0.18835402339912477 and reward=0.007802164646573989 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (-0.006) for SCALE UP:bbox transition: [220, 200,  93,  78] -> [218, 198,  95,  80] w/ P(a|s)=0.08340301364660263 and iou=0.18270813480031187 and reward=-0.005645888598812904 and discount=1.0\n",
            "   |->> t=7 Diff-Reward (-0.023) for 2X LEFT:bbox transition: [218, 198,  95,  80] -> [214, 198,  95,  80] w/ P(a|s)=0.08910886198282242 and iou=0.15979950726361397 and reward=-0.022908627536697895 and discount=1.0\n",
            "   |->> t=8 Diff-Reward (-0.011) for LEFT:bbox transition: [214, 198,  95,  80] -> [212, 198,  95,  80] w/ P(a|s)=0.09203797578811646 and iou=0.14867480016827933 and reward=-0.01112470709533464 and discount=1.0\n",
            "   |->> t=9 Diff-Reward (0.012) for 2X DOWN:bbox transition: [212, 198,  95,  80] -> [212, 202,  95,  80] w/ P(a|s)=0.09476549178361893 and iou=0.16078564747895588 and reward=0.012110847310676548 and discount=1.0\n",
            "   |->> t=10 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [212, 202,  95,  80] -> [216, 202,  95,  80] w/ P(a|s)=0.09266868233680725 and iou=0.18537813666753494 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.05886842 -0.01705862 -0.05783771 -0.0277978   0.01844489 -0.01402479\n",
            " -0.05539069 -0.02653859  0.02853739 -2.3787248 ]\n",
            "\u001b[31m>> Total frame loss: -2.471522092819214\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 73 with src: [216, 202,  95,  80] and target: [282, 206,  82,  70]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0076.jpg\n",
            "|->> Beginning tracking for bbox:[216 202  95  80]\n",
            "   \u001b[33m|->> #0/t=43-th Action selection: 4/UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [216 200  95  80]\n",
            "         |->> Action Probabilities (Rounded): [0.0884 0.0878 0.0915 0.0911 0.0933 0.0944 0.0938 0.0936 0.0904 0.0897\n",
            " 0.0861], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.0883875  0.08778568 0.09150485 0.09109394 0.09326279 0.09442378\n",
            " 0.09382693 0.09356038 0.09036153 0.08971383 0.08607875], argmax=5\n",
            "   \u001b[33m|->> #1/t=44-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [217 201  92  77]\n",
            "         |->> Action Probabilities (Rounded): [0.0913 0.0875 0.0897 0.0923 0.0916 0.0932 0.0943 0.094  0.0909 0.0886\n",
            " 0.0866], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09130504 0.08752529 0.08969133 0.09233673 0.09162308 0.09316275\n",
            " 0.09426279 0.09397864 0.09085934 0.08862074 0.08663429], argmax=6\n",
            "   \u001b[33m|->> #2/t=45-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08399999886751175)\u001b[0m\n",
            "      |->> Bounding box moves to: [218 202  89  74]\n",
            "         |->> Action Probabilities (Rounded): [0.0917 0.0882 0.0906 0.0929 0.0918 0.0937 0.0934 0.0933 0.0913 0.0839\n",
            " 0.0894], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.09166604 0.0881711  0.09056355 0.09290241 0.09176824 0.09370021\n",
            " 0.09339989 0.09329754 0.09125416 0.08385703 0.08941983], argmax=5\n",
            "   \u001b[33m|->> #3/t=46-th Action selection: 1/2X LEFT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [214 202  89  74]\n",
            "         |->> Action Probabilities (Rounded): [0.0912 0.089  0.09   0.0938 0.0925 0.0937 0.0946 0.0933 0.091  0.0816\n",
            " 0.0895], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09118427 0.08896795 0.09000321 0.09377625 0.09245373 0.09369414\n",
            " 0.09462669 0.09325745 0.09097226 0.08158818 0.08947591], argmax=6\n",
            "   \u001b[33m|->> #4/t=47-th Action selection: 1/2X LEFT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [210 202  89  74]\n",
            "         |->> Action Probabilities (Rounded): [0.0903 0.0886 0.0892 0.0928 0.0936 0.0929 0.0938 0.0943 0.0916 0.0839\n",
            " 0.0889], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09031408 0.08860604 0.08919968 0.09283989 0.09357008 0.09291188\n",
            " 0.0938477  0.094331   0.09157683 0.08391106 0.08889176], argmax=7\n",
            "   \u001b[33m|->> #5/t=48-th Action selection: 0/LEFT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [208 202  89  74]\n",
            "         |->> Action Probabilities (Rounded): [0.0892 0.0858 0.0901 0.0928 0.0934 0.0929 0.0942 0.0946 0.0924 0.0848\n",
            " 0.0898], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08922225 0.08584247 0.09009453 0.09278983 0.09341619 0.09294324\n",
            " 0.09415512 0.09455113 0.09239177 0.08477552 0.08981796], argmax=7\n",
            "   \u001b[33m|->> #6/t=49-th Action selection: 10/SCALE UP (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [206 200  91  76]\n",
            "         |->> Action Probabilities (Rounded): [0.084  0.0858 0.0963 0.0929 0.0927 0.0935 0.0948 0.0949 0.0918 0.0832\n",
            " 0.0901], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08398995 0.08581045 0.0963284  0.0929143  0.09267284 0.09350482\n",
            " 0.09479787 0.09494323 0.09179628 0.08317894 0.09006296], argmax=2\n",
            "   \u001b[33m|->> #7/t=50-th Action selection: 3/2X RIGHT (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [210 200  91  76]\n",
            "         |->> Action Probabilities (Rounded): [0.0927 0.0867 0.0876 0.0939 0.0924 0.0935 0.0953 0.0949 0.092  0.0861\n",
            " 0.0849], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09265765 0.08665828 0.08760993 0.0939125  0.09244119 0.093504\n",
            " 0.09534679 0.09493661 0.09199324 0.08608153 0.08485825], argmax=6\n",
            "   \u001b[33m|->> #8/t=51-th Action selection: 10/SCALE UP (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [208 198  93  78]\n",
            "         |->> Action Probabilities (Rounded): [0.0884 0.0884 0.0907 0.0911 0.0932 0.0939 0.0941 0.095  0.0917 0.0854\n",
            " 0.088 ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08844708 0.08835872 0.09072968 0.09106547 0.09323728 0.09393735\n",
            " 0.09409791 0.0950102  0.09168064 0.08539734 0.0880383 ], argmax=7\n",
            "   \u001b[33m|->> #9/t=52-th Action selection: 5/2X UP (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [208 194  93  78]\n",
            "         |->> Action Probabilities (Rounded): [0.0912 0.0877 0.0879 0.0923 0.0935 0.0937 0.0946 0.0958 0.0918 0.0888\n",
            " 0.0827], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09123997 0.08766976 0.08786366 0.09232157 0.09352301 0.09372267\n",
            " 0.09459473 0.09576892 0.09177984 0.08882294 0.08269295], argmax=7\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [216, 202,  95,  80] -> [208, 194,  93,  78] (Target was [282, 206,  82,  70])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for UP:bbox transition: [216, 202,  95,  80] -> [216, 200,  95,  80] w/ P(a|s)=0.09326279163360596 and iou=0.1794871794871795 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.007) for SCALE DOWN:bbox transition: [216, 200,  95,  80] -> [217, 201,  92,  77] w/ P(a|s)=0.08862073719501495 and iou=0.17285531370038412 and reward=-0.006631865786795366 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.007) for SCALE DOWN:bbox transition: [217, 201,  92,  77] -> [218, 202,  89,  74] w/ P(a|s)=0.08385702967643738 and iou=0.16546898638426627 and reward=-0.007386327316117852 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-0.03) for 2X LEFT:bbox transition: [218, 202,  89,  74] -> [214, 202,  89,  74] w/ P(a|s)=0.0889679491519928 and iou=0.13540899042004423 and reward=-0.03005999596422204 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (-0.029) for 2X LEFT:bbox transition: [214, 202,  89,  74] -> [210, 202,  89,  74] w/ P(a|s)=0.08860604465007782 and iou=0.10686063218390805 and reward=-0.028548358236136176 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (-0.014) for LEFT:bbox transition: [210, 202,  89,  74] -> [208, 202,  89,  74] w/ P(a|s)=0.089222252368927 and iou=0.09311812699538843 and reward=-0.013742505188519619 and discount=1.0\n",
            "   |->> t=7 Diff-Reward (-0.003) for SCALE UP:bbox transition: [208, 202,  89,  74] -> [206, 200,  91,  76] w/ P(a|s)=0.09006296098232269 and iou=0.09047044632086852 and reward=-0.0026476806745199116 and discount=1.0\n",
            "   |->> t=8 Diff-Reward (0.027) for 2X RIGHT:bbox transition: [206, 200,  91,  76] -> [210, 200,  91,  76] w/ P(a|s)=0.0939125046133995 and iou=0.11742892459826947 and reward=0.026958478277400943 and discount=1.0\n",
            "   |->> t=9 Diff-Reward (-0.003) for SCALE UP:bbox transition: [210, 200,  91,  76] -> [208, 198,  93,  78] w/ P(a|s)=0.08803829550743103 and iou=0.11402606310013717 and reward=-0.0034028614981322924 and discount=1.0\n",
            "   |->> t=10 Diff-Reward (-1.0) for 2X UP:bbox transition: [208, 198,  93,  78] -> [208, 194,  93,  78] w/ P(a|s)=0.09372267127037048 and iou=0.10681431005110732 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.         -0.01607159 -0.01830806 -0.07272953 -0.06918852 -0.03321048\n",
            " -0.00637362  0.06376737 -0.0082689  -2.3674152 ]\n",
            "\u001b[31m>> Total frame loss: -2.5277984142303467\u001b[0m\n",
            "Final bounding box: [208 194  93  78] reached in 53 timesteps (originating from [238 220  87  72]). Target was [282 206  82  70]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 74 in t=53 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[31m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 9.194794654846191\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 2.138511896133423\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/BlurCar3\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0067.jpg\n",
            "Starting bounding box=adnet_datasets/OTB/BlurCar3/img/0077.jpg for adnet_datasets/OTB/BlurCar3's frames (index: 0)\n",
            "src:adnet_datasets/OTB/BlurCar3/img/0067.jpg\n",
            "target:adnet_datasets/OTB/BlurCar3/img/0077.jpg.\n",
            "\u001b[34m>> Attempting to reach frame 65 with src: [259, 213,  84,  73] and target: [280, 211,  83,  66]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0068.jpg\n",
            "|->> Beginning tracking for bbox:[259 213  84  73]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 6/DOWN (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [259 215  84  73]\n",
            "         |->> Action Probabilities (Rounded): [0.091  0.0907 0.0909 0.091  0.0908 0.0909 0.0909 0.0909 0.0909 0.0911\n",
            " 0.091 ], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.09097924 0.0907042  0.0908745  0.09095836 0.09075558 0.09090326\n",
            " 0.09092782 0.09089288 0.09088326 0.09109601 0.09102488], argmax=9\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 5/2X UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [259 211  84  73]\n",
            "         |->> Action Probabilities (Rounded): [0.0914 0.0909 0.0914 0.0912 0.0921 0.091  0.0887 0.0911 0.0907 0.0908\n",
            " 0.0905], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.09142817 0.09091041 0.09144156 0.09124499 0.09213006 0.0909842\n",
            " 0.08870963 0.09111149 0.09074996 0.09083284 0.09045672], argmax=4\n",
            "|->> Revisiting bbox: [259 215  84  73]. ACtion 7 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [259, 213,  84,  73] -> [259, 211,  84,  73] (Target was [280, 211,  83,  66])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.025) for DOWN:bbox transition: [259, 213,  84,  73] -> [259, 215,  84,  73] w/ P(a|s)=0.09092782437801361 and iou=0.5070093457943925 and reward=-0.025057162519146692 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for 2X UP:bbox transition: [259, 215,  84,  73] -> [259, 211,  84,  73] w/ P(a|s)=0.09098420292139053 and iou=0.5579710144927537 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.06007929 -2.3970695 ]\n",
            "\u001b[31m>> Total frame loss: -2.457148790359497\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 66 with src: [259, 211,  84,  73] and target: [284, 212,  87,  76]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0069.jpg\n",
            "|->> Beginning tracking for bbox:[259 211  84  73]\n",
            "   \u001b[33m|->> #0/t=3-th Action selection: 10/SCALE UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [257 209  86  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0917 0.0908 0.0918 0.0912 0.0899 0.0896 0.0908 0.0909 0.0915 0.0912\n",
            " 0.0908], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.09165669 0.09075707 0.09178168 0.09115327 0.08993457 0.08958576\n",
            " 0.09078835 0.09087858 0.09153209 0.09116262 0.09076937], argmax=2\n",
            "   \u001b[33m|->> #1/t=4-th Action selection: 4/UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [257 207  86  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0909 0.0912 0.0914 0.0921 0.0916 0.0903 0.0907 0.0914 0.0923 0.0927\n",
            " 0.0854], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.090879   0.09124755 0.09142585 0.09207435 0.09155623 0.09031958\n",
            " 0.09073368 0.09135188 0.09231593 0.09273287 0.08536308], argmax=9\n",
            "   \u001b[33m|->> #2/t=5-th Action selection: 1/2X LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [253 207  86  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0919 0.0911 0.0921 0.0921 0.0888 0.0904 0.0918 0.0918 0.0923 0.0905\n",
            " 0.0872], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.091866   0.0911468  0.09206266 0.09208792 0.08878747 0.09040736\n",
            " 0.09182263 0.09177765 0.09234562 0.09053243 0.08716349], argmax=8\n",
            "   \u001b[33m|->> #3/t=6-th Action selection: 0/LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [251 207  86  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0912 0.0892 0.0917 0.0921 0.0905 0.0906 0.091  0.0919 0.0924 0.0923\n",
            " 0.087 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09124336 0.0891795  0.09167302 0.09213655 0.09054561 0.09061159\n",
            " 0.09097496 0.09194495 0.09242425 0.09229715 0.08696903], argmax=8\n",
            "   \u001b[33m|->> #4/t=7-th Action selection: 7/2X DOWN (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [251 211  86  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0836 0.0893 0.0984 0.0925 0.0902 0.0915 0.093  0.093  0.0918 0.0895\n",
            " 0.0873], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08359575 0.08926621 0.09841774 0.09245012 0.09016897 0.09153748\n",
            " 0.09301214 0.09298567 0.09181026 0.08945999 0.08729566], argmax=2\n",
            "   \u001b[33m|->> #5/t=8-th Action selection: 4/UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [251 209  86  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0918 0.0889 0.0893 0.0929 0.0917 0.0911 0.0924 0.0918 0.0913 0.0904\n",
            " 0.0882], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09183858 0.08893102 0.08933977 0.09293905 0.09172815 0.09113371\n",
            " 0.09243507 0.09178377 0.09128806 0.09035256 0.08823026], argmax=3\n",
            "   \u001b[33m|->> #6/t=9-th Action selection: 2/RIGHT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [253 209  86  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0888 0.0894 0.0933 0.0929 0.0897 0.0919 0.0936 0.0923 0.0911 0.0894\n",
            " 0.0877], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08881787 0.0894204  0.09325477 0.09286039 0.08970901 0.091882\n",
            " 0.09356782 0.09231388 0.09107724 0.08941328 0.08768332], argmax=6\n",
            "   \u001b[33m|->> #7/t=10-th Action selection: 1/2X LEFT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [249 209  86  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0989 0.089  0.0819 0.0938 0.0912 0.0922 0.0928 0.0925 0.0909 0.0886\n",
            " 0.0881], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.0988619  0.08901509 0.0819316  0.09384517 0.09120198 0.09215065\n",
            " 0.09284087 0.09249798 0.09087384 0.0886343  0.08814669], argmax=0\n",
            "|->> Revisiting bbox: [249 209  86  75]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [259, 211,  84,  73] -> [249, 209,  86,  75] (Target was [284, 212,  87,  76])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.018) for SCALE UP:bbox transition: [259, 211,  84,  73] -> [257, 209,  86,  75] w/ P(a|s)=0.09076936542987823 and iou=0.48196051735874745 and reward=-0.018039482641252547 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.02) for UP:bbox transition: [257, 209,  86,  75] -> [257, 207,  86,  75] w/ P(a|s)=0.09155622869729996 and iou=0.46238244514106586 and reward=-0.019578072217681597 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.044) for 2X LEFT:bbox transition: [257, 207,  86,  75] -> [253, 207,  86,  75] w/ P(a|s)=0.0911467969417572 and iou=0.41793313069908816 and reward=-0.044449314441977694 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-0.021) for LEFT:bbox transition: [253, 207,  86,  75] -> [251, 207,  86,  75] w/ P(a|s)=0.09124336391687393 and iou=0.3967065868263473 and reward=-0.021226543872740866 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (0.032) for 2X DOWN:bbox transition: [251, 207,  86,  75] -> [251, 211,  86,  75] w/ P(a|s)=0.09298566728830338 and iou=0.42910284463894965 and reward=0.03239625781260236 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (-0.016) for UP:bbox transition: [251, 211,  86,  75] -> [251, 209,  86,  75] w/ P(a|s)=0.09172815084457397 and iou=0.4127190136275146 and reward=-0.016383831011435035 and discount=1.0\n",
            "   |->> t=7 Diff-Reward (0.022) for RIGHT:bbox transition: [251, 209,  86,  75] -> [253, 209,  86,  75] w/ P(a|s)=0.09325477480888367 and iou=0.43506921555702044 and reward=0.02235020192950582 and discount=1.0\n",
            "   |->> t=8 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [253, 209,  86,  75] -> [249, 209,  86,  75] w/ P(a|s)=0.08901508897542953 and iou=0.39105431309904154 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.04328454 -0.04680729 -0.10646873 -0.05082113  0.07695115 -0.03913976\n",
            "  0.05302406 -2.4189494 ]\n",
            "\u001b[31m>> Total frame loss: -2.575495481491089\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 67 with src: [249, 209,  86,  75] and target: [284, 231,  80,  75]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0070.jpg\n",
            "|->> Beginning tracking for bbox:[249 209  86  75]\n",
            "   \u001b[33m|->> #0/t=11-th Action selection: 2/RIGHT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [251 209  86  75]\n",
            "         |->> Action Probabilities (Rounded): [0.087  0.0883 0.0932 0.0924 0.0918 0.0915 0.0942 0.0932 0.0909 0.0895\n",
            " 0.0882], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08698598 0.0883319  0.09316812 0.09237234 0.09175945 0.09153321\n",
            " 0.09417154 0.09318756 0.09086174 0.08946373 0.08816436], argmax=6\n",
            "   \u001b[33m|->> #1/t=12-th Action selection: 2/RIGHT (P(a|s) = 0.08100000023841858)\u001b[0m\n",
            "      |->> Bounding box moves to: [253 209  86  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0998 0.0874 0.0814 0.0934 0.0919 0.0932 0.0937 0.0935 0.0905 0.0882\n",
            " 0.087 ], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09976356 0.08744831 0.08142985 0.09341924 0.09188896 0.09317802\n",
            " 0.09370198 0.09346095 0.09050263 0.08822741 0.08697911], argmax=0\n",
            "|->> Revisiting bbox: [251 209  86  75]. ACtion 0 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [249, 209,  86,  75] -> [253, 209,  86,  75] (Target was [284, 231,  80,  75])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.014) for RIGHT:bbox transition: [249, 209,  86,  75] -> [251, 209,  86,  75] w/ P(a|s)=0.09316811710596085 and iou=0.291359817446323 and reward=0.014043720185627384 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for RIGHT:bbox transition: [251, 209,  86,  75] -> [253, 209,  86,  75] w/ P(a|s)=0.0814298465847969 and iou=0.30571578395385424 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.03333066 -2.5080135 ]\n",
            "\u001b[31m>> Total frame loss: -2.4746828079223633\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 68 with src: [253, 209,  86,  75] and target: [261, 245,  90,  72]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0071.jpg\n",
            "|->> Beginning tracking for bbox:[253 209  86  75]\n",
            "   \u001b[33m|->> #0/t=13-th Action selection: 5/2X UP (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [253 205  86  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0938 0.0886 0.0846 0.0923 0.0929 0.0943 0.0947 0.0949 0.0903 0.0872\n",
            " 0.0863], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09381449 0.08862957 0.08464154 0.09225236 0.09293868 0.09430993\n",
            " 0.09473751 0.09491739 0.0902782  0.08716029 0.08632007], argmax=7\n",
            "   \u001b[33m|->> #1/t=14-th Action selection: 10/SCALE UP (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [251 203  88  77]\n",
            "         |->> Action Probabilities (Rounded): [0.0913 0.0897 0.09   0.0907 0.0928 0.0921 0.0938 0.0946 0.0899 0.0874\n",
            " 0.0878], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09125007 0.08974905 0.09000826 0.09069958 0.0927764  0.09210495\n",
            " 0.09379891 0.09458032 0.08985163 0.08740286 0.08777791], argmax=7\n",
            "   \u001b[33m|->> #2/t=15-th Action selection: 0/LEFT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [249 203  88  77]\n",
            "         |->> Action Probabilities (Rounded): [0.0931 0.0891 0.0893 0.0923 0.0922 0.0921 0.0954 0.0943 0.091  0.0885\n",
            " 0.0829], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09308994 0.08906638 0.0892546  0.09226813 0.09224316 0.09207573\n",
            " 0.09539272 0.09427857 0.09096965 0.08850955 0.08285162], argmax=6\n",
            "|->> Revisiting bbox: [249 203  88  77]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [253, 209,  86,  75] -> [249, 203,  88,  77] (Target was [261, 245,  90,  72])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.04) for 2X UP:bbox transition: [253, 209,  86,  75] -> [253, 205,  86,  75] w/ P(a|s)=0.09430993348360062 and iou=0.2676470588235294 and reward=-0.03999857224443176 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.008) for SCALE UP:bbox transition: [253, 205,  86,  75] -> [251, 203,  88,  77] w/ P(a|s)=0.08777790516614914 and iou=0.259357780733422 and reward=-0.008289278090107377 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-1.0) for LEFT:bbox transition: [251, 203,  88,  77] -> [249, 203,  88,  77] w/ P(a|s)=0.09308993816375732 and iou=0.25103812759531896 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.09444338 -0.02016736 -2.3741891 ]\n",
            "\u001b[31m>> Total frame loss: -2.488799810409546\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 69 with src: [249, 203,  88,  77] and target: [252, 242,  91,  71]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0072.jpg\n",
            "|->> Beginning tracking for bbox:[249 203  88  77]\n",
            "   \u001b[33m|->> #0/t=16-th Action selection: 4/UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [249 201  88  77]\n",
            "         |->> Action Probabilities (Rounded): [0.0867 0.0905 0.0966 0.0928 0.0916 0.0933 0.0936 0.094  0.0907 0.0853\n",
            " 0.085 ], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08674396 0.09046466 0.09659887 0.09277768 0.09161014 0.09328604\n",
            " 0.09364427 0.09398604 0.09065884 0.08525314 0.08497631], argmax=2\n",
            "   \u001b[33m|->> #1/t=17-th Action selection: 0/LEFT (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [247 201  88  77]\n",
            "         |->> Action Probabilities (Rounded): [0.0949 0.0906 0.0877 0.093  0.0899 0.0927 0.0946 0.0938 0.0907 0.0875\n",
            " 0.0846], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09488422 0.09056462 0.08771737 0.09296339 0.08994909 0.09270921\n",
            " 0.09457571 0.09382847 0.09071378 0.0875239  0.0845703 ], argmax=0\n",
            "   \u001b[33m|->> #2/t=18-th Action selection: 1/2X LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [243 201  88  77]\n",
            "         |->> Action Probabilities (Rounded): [0.0828 0.0914 0.0992 0.0921 0.0911 0.0944 0.0937 0.0955 0.0899 0.085\n",
            " 0.085 ], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08284865 0.09138864 0.09919753 0.09208425 0.0910814  0.09435742\n",
            " 0.093668   0.09551636 0.08992011 0.08496197 0.0849757 ], argmax=2\n",
            "   \u001b[33m|->> #3/t=19-th Action selection: 10/SCALE UP (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [241 199  90  79]\n",
            "         |->> Action Probabilities (Rounded): [0.0941 0.0873 0.0876 0.0923 0.0915 0.0929 0.0949 0.0954 0.0898 0.0873\n",
            " 0.0867], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09410368 0.08734406 0.0876397  0.09234899 0.09153609 0.09285485\n",
            " 0.09491888 0.09542824 0.08978856 0.08731133 0.08672561], argmax=7\n",
            "|->> Revisiting bbox: [241 199  90  79]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [249, 203,  88,  77] -> [241, 199,  90,  79] (Target was [252, 242,  91,  71])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.022) for UP:bbox transition: [249, 203,  88,  77] -> [249, 201,  88,  77] w/ P(a|s)=0.0916101410984993 and iou=0.30067799941043527 and reward=-0.02209605874885323 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.009) for LEFT:bbox transition: [249, 201,  88,  77] -> [247, 201,  88,  77] w/ P(a|s)=0.09488421678543091 and iou=0.2915406381110352 and reward=-0.00913736129940007 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.018) for 2X LEFT:bbox transition: [247, 201,  88,  77] -> [243, 201,  88,  77] w/ P(a|s)=0.09138864278793335 and iou=0.27364572308284424 and reward=-0.01789491502819096 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-1.0) for SCALE UP:bbox transition: [243, 201,  88,  77] -> [241, 199,  90,  79] w/ P(a|s)=0.086725614964962 and iou=0.26512538454367485 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.05281429 -0.02151938 -0.04281598 -2.445006  ]\n",
            "\u001b[31m>> Total frame loss: -2.5621554851531982\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 70 with src: [241, 199,  90,  79] and target: [261, 227,  92,  72]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0073.jpg\n",
            "|->> Beginning tracking for bbox:[241 199  90  79]\n",
            "   \u001b[33m|->> #0/t=20-th Action selection: 10/SCALE UP (P(a|s) = 0.08100000023841858)\u001b[0m\n",
            "      |->> Bounding box moves to: [239 197  92  81]\n",
            "         |->> Action Probabilities (Rounded): [0.089  0.0885 0.0928 0.093  0.0921 0.0941 0.0944 0.0957 0.0908 0.0883\n",
            " 0.0813], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08899175 0.088491   0.09276222 0.09301161 0.09213282 0.09410191\n",
            " 0.09440839 0.09573569 0.09078804 0.08828235 0.0812942 ], argmax=7\n",
            "   \u001b[33m|->> #1/t=21-th Action selection: 2/RIGHT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [241 197  92  81]\n",
            "         |->> Action Probabilities (Rounded): [0.0924 0.0884 0.0893 0.0933 0.0929 0.0941 0.0947 0.0956 0.0912 0.089\n",
            " 0.0789], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09244588 0.08843376 0.08932687 0.09325355 0.09291429 0.09409619\n",
            " 0.09472871 0.09563734 0.09121086 0.08901922 0.07893339], argmax=7\n",
            "   \u001b[33m|->> #2/t=22-th Action selection: 2/RIGHT (P(a|s) = 0.08299999684095383)\u001b[0m\n",
            "      |->> Bounding box moves to: [243 197  92  81]\n",
            "         |->> Action Probabilities (Rounded): [0.0978 0.0882 0.0834 0.0947 0.0924 0.0943 0.0947 0.0951 0.0915 0.0875\n",
            " 0.0804], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09777337 0.08823048 0.08336611 0.09472746 0.09239665 0.09429302\n",
            " 0.09469729 0.09510745 0.09150882 0.08749384 0.08040556], argmax=0\n",
            "|->> Revisiting bbox: [239 197  92  81]. ACtion 1 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [241, 199,  90,  79] -> [243, 197,  92,  81] (Target was [261, 227,  92,  72])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.011) for SCALE UP:bbox transition: [241, 199,  90,  79] -> [239, 197,  92,  81] w/ P(a|s)=0.08129420131444931 and iou=0.33980582524271846 and reward=-0.011433844178769137 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.013) for RIGHT:bbox transition: [239, 197,  92,  81] -> [241, 197,  92,  81] w/ P(a|s)=0.089326873421669 and iou=0.35294117647058826 and reward=0.013135351227869796 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-1.0) for RIGHT:bbox transition: [241, 197,  92,  81] -> [243, 197,  92,  81] w/ P(a|s)=0.08336611092090607 and iou=0.36633663366336633 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.0286953   0.03172782 -2.4845133 ]\n",
            "\u001b[31m>> Total frame loss: -2.481480836868286\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 71 with src: [243, 197,  92,  81] and target: [271, 222,  91,  70]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0074.jpg\n",
            "|->> Beginning tracking for bbox:[243 197  92  81]\n",
            "   \u001b[33m|->> #0/t=23-th Action selection: 1/2X LEFT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [239 197  92  81]\n",
            "         |->> Action Probabilities (Rounded): [0.0951 0.0891 0.0852 0.0933 0.0934 0.0941 0.0947 0.0954 0.0904 0.0882\n",
            " 0.0812], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09506743 0.08907543 0.08518226 0.09330959 0.09335477 0.09414607\n",
            " 0.094702   0.09538329 0.0904359  0.08817787 0.08116543], argmax=7\n",
            "   \u001b[33m|->> #1/t=24-th Action selection: 4/UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [239 195  92  81]\n",
            "         |->> Action Probabilities (Rounded): [0.0913 0.0875 0.0902 0.0923 0.0934 0.0949 0.0941 0.0955 0.0898 0.0885\n",
            " 0.0826], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09129815 0.08749574 0.09021559 0.09233425 0.09336088 0.09489328\n",
            " 0.09405664 0.09545578 0.08983911 0.08846916 0.08258146], argmax=7\n",
            "   \u001b[33m|->> #2/t=25-th Action selection: 2/RIGHT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [241 195  92  81]\n",
            "         |->> Action Probabilities (Rounded): [0.0941 0.0872 0.0901 0.0922 0.0903 0.0944 0.095  0.0959 0.0904 0.0874\n",
            " 0.0831], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09410466 0.08723162 0.09008504 0.09221704 0.09032765 0.09436737\n",
            " 0.0949631  0.0958579  0.09042571 0.08735982 0.08306013], argmax=7\n",
            "   \u001b[33m|->> #3/t=26-th Action selection: 5/2X UP (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [241 191  92  81]\n",
            "         |->> Action Probabilities (Rounded): [0.0991 0.0885 0.0823 0.0926 0.0915 0.0948 0.0943 0.0956 0.0896 0.088\n",
            " 0.0837], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09914881 0.08849052 0.08228043 0.09260293 0.09154999 0.09479032\n",
            " 0.09426995 0.09561991 0.08958409 0.08800776 0.08365538], argmax=0\n",
            "   \u001b[33m|->> #4/t=27-th Action selection: 5/2X UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [241 187  92  81]\n",
            "         |->> Action Probabilities (Rounded): [0.0893 0.0895 0.0918 0.0914 0.0921 0.092  0.0955 0.095  0.0901 0.089\n",
            " 0.0843], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08925249 0.08949142 0.09178878 0.09138973 0.09211458 0.09199616\n",
            " 0.09552681 0.09504256 0.09010095 0.08896469 0.08433177], argmax=6\n",
            "   \u001b[33m|->> #5/t=28-th Action selection: 4/UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [241 185  92  81]\n",
            "         |->> Action Probabilities (Rounded): [0.0924 0.0897 0.0886 0.0922 0.0923 0.0904 0.0948 0.094  0.0905 0.0894\n",
            " 0.0856], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09239098 0.08974285 0.08858348 0.09217001 0.09231912 0.09040752\n",
            " 0.09482174 0.09404047 0.09051091 0.08943992 0.08557302], argmax=6\n",
            "   \u001b[33m|->> #6/t=29-th Action selection: 0/LEFT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [239 185  92  81]\n",
            "         |->> Action Probabilities (Rounded): [0.0921 0.0906 0.0912 0.0917 0.0898 0.0907 0.0947 0.0937 0.09   0.0892\n",
            " 0.0863], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09206124 0.09059519 0.09121516 0.09170673 0.08981255 0.09069882\n",
            " 0.09474672 0.0936843  0.0899902  0.08920904 0.08628003], argmax=6\n",
            "   \u001b[33m|->> #7/t=30-th Action selection: 3/2X RIGHT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [243 185  92  81]\n",
            "         |->> Action Probabilities (Rounded): [0.0861 0.0911 0.0962 0.0926 0.0903 0.0918 0.0938 0.0943 0.0903 0.087\n",
            " 0.0865], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08609179 0.09113033 0.09619971 0.09257887 0.09025696 0.09182476\n",
            " 0.09377726 0.09428706 0.09029491 0.08701641 0.08654194], argmax=2\n",
            "   \u001b[33m|->> #8/t=31-th Action selection: 6/DOWN (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [243 187  92  81]\n",
            "         |->> Action Probabilities (Rounded): [0.0933 0.0911 0.088  0.0903 0.0903 0.0911 0.0949 0.0944 0.0906 0.0878\n",
            " 0.0882], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09326348 0.09112039 0.08802069 0.0902825  0.09031658 0.09109217\n",
            " 0.0949047  0.09437016 0.09062026 0.08778309 0.08822594], argmax=6\n",
            "   \u001b[33m|->> #9/t=32-th Action selection: 1/2X LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [239 187  92  81]\n",
            "         |->> Action Probabilities (Rounded): [0.0903 0.0906 0.0919 0.0911 0.0928 0.0911 0.091  0.0945 0.0902 0.088\n",
            " 0.0887], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09027404 0.09061579 0.09186339 0.09105128 0.09276804 0.09108197\n",
            " 0.09104398 0.09448803 0.09016816 0.08797283 0.08867249], argmax=7\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [243, 197,  92,  81] -> [239, 187,  92,  81] (Target was [271, 222,  91,  70])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.029) for 2X LEFT:bbox transition: [243, 197,  92,  81] -> [239, 197,  92,  81] w/ P(a|s)=0.08907543122768402 and iou=0.3211623016631619 and reward=-0.028906071065886718 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.015) for UP:bbox transition: [239, 197,  92,  81] -> [239, 195,  92,  81] w/ P(a|s)=0.09336087852716446 and iou=0.30618030618030617 and reward=-0.014981995482855726 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.013) for RIGHT:bbox transition: [239, 195,  92,  81] -> [241, 195,  92,  81] w/ P(a|s)=0.09008504450321198 and iou=0.31964865380943286 and reward=0.013468347629126687 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-0.031) for 2X UP:bbox transition: [241, 195,  92,  81] -> [241, 191,  92,  81] w/ P(a|s)=0.09479031711816788 and iou=0.28912516321581794 and reward=-0.03052349059361492 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (-0.029) for 2X UP:bbox transition: [241, 191,  92,  81] -> [241, 187,  92,  81] w/ P(a|s)=0.09199616312980652 and iou=0.2599817684594348 and reward=-0.029143394756383112 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (-0.014) for UP:bbox transition: [241, 187,  92,  81] -> [241, 185,  92,  81] w/ P(a|s)=0.09231912344694138 and iou=0.2458986839733189 and reward=-0.014083084486115921 and discount=1.0\n",
            "   |->> t=7 Diff-Reward (-0.01) for LEFT:bbox transition: [241, 185,  92,  81] -> [239, 185,  92,  81] w/ P(a|s)=0.09206123650074005 and iou=0.23609372205329995 and reward=-0.00980496192001895 and discount=1.0\n",
            "   |->> t=8 Diff-Reward (0.02) for 2X RIGHT:bbox transition: [239, 185,  92,  81] -> [243, 185,  92,  81] w/ P(a|s)=0.09257887303829193 and iou=0.25586043976013084 and reward=0.01976671770683089 and discount=1.0\n",
            "   |->> t=9 Diff-Reward (0.015) for DOWN:bbox transition: [243, 185,  92,  81] -> [243, 187,  92,  81] w/ P(a|s)=0.09490469843149185 and iou=0.2706379849236992 and reward=0.014777545163568384 and discount=1.0\n",
            "   |->> t=10 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [243, 187,  92,  81] -> [239, 187,  92,  81] w/ P(a|s)=0.09061579406261444 and iou=0.24950280238654854 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.06990274 -0.03552655  0.03241833 -0.07191603 -0.06953639 -0.033553\n",
            " -0.02338779  0.04703875  0.03479937 -2.4011269 ]\n",
            "\u001b[31m>> Total frame loss: -2.5906929969787598\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 72 with src: [239, 187,  92,  81] and target: [276, 221,  89,  68]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0075.jpg\n",
            "|->> Beginning tracking for bbox:[239 187  92  81]\n",
            "   \u001b[33m|->> #0/t=33-th Action selection: 2/RIGHT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [241 187  92  81]\n",
            "         |->> Action Probabilities (Rounded): [0.0928 0.0876 0.0895 0.0916 0.0908 0.0911 0.0936 0.0938 0.0908 0.0888\n",
            " 0.0897], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09281586 0.08759904 0.08953764 0.09155735 0.0907989  0.09108877\n",
            " 0.09363309 0.0937546  0.09075335 0.08878845 0.0896729 ], argmax=7\n",
            "|->> Revisiting bbox: [239 187  92  81]. ACtion 0 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [239, 187,  92,  81] -> [241, 187,  92,  81] (Target was [276, 221,  89,  68])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for RIGHT:bbox transition: [239, 187,  92,  81] -> [241, 187,  92,  81] w/ P(a|s)=0.08953763544559479 and iou=0.24748267898383372 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.4130962]\n",
            "\u001b[31m>> Total frame loss: -2.4130961894989014\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 73 with src: [241, 187,  92,  81] and target: [282, 206,  82,  70]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0076.jpg\n",
            "|->> Beginning tracking for bbox:[241 187  92  81]\n",
            "   \u001b[33m|->> #0/t=34-th Action selection: 0/LEFT (P(a|s) = 0.09799999743700027)\u001b[0m\n",
            "      |->> Bounding box moves to: [239 187  92  81]\n",
            "         |->> Action Probabilities (Rounded): [0.098  0.089  0.0827 0.092  0.0921 0.0927 0.0928 0.0942 0.0905 0.0879\n",
            " 0.0882], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09801485 0.08896095 0.08266395 0.09195258 0.09208521 0.09274386\n",
            " 0.09281357 0.09418941 0.09049205 0.08788072 0.0882028 ], argmax=0\n",
            "   \u001b[33m|->> #1/t=35-th Action selection: 1/2X LEFT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [235 187  92  81]\n",
            "         |->> Action Probabilities (Rounded): [0.0817 0.0898 0.099  0.0911 0.0917 0.0929 0.0945 0.0953 0.09   0.0858\n",
            " 0.0882], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08173518 0.08975682 0.09904747 0.0910983  0.09167402 0.09293621\n",
            " 0.09453838 0.09527308 0.09001502 0.08575184 0.08817362], argmax=2\n",
            "|->> Revisiting bbox: [235 187  92  81]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [241, 187,  92,  81] -> [235, 187,  92,  81] (Target was [282, 206,  82,  70])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.016) for LEFT:bbox transition: [241, 187,  92,  81] -> [239, 187,  92,  81] w/ P(a|s)=0.09801484644412994 and iou=0.2991924364782352 and reward=-0.01606180080990044 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [239, 187,  92,  81] -> [235, 187,  92,  81] w/ P(a|s)=0.08975682407617569 and iou=0.2682176504518362 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.03730572 -2.4106512 ]\n",
            "\u001b[31m>> Total frame loss: -2.4479570388793945\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 74 with src: [235, 187,  92,  81] and target: [265, 181,  91,  69]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0077.jpg\n",
            "|->> Beginning tracking for bbox:[235 187  92  81]\n",
            "   \u001b[33m|->> #0/t=36-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [236 188  89  78]\n",
            "         |->> Action Probabilities (Rounded): [0.0944 0.0864 0.0865 0.0927 0.0921 0.0927 0.0935 0.0947 0.0912 0.0871\n",
            " 0.0887], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09437247 0.08637583 0.08645628 0.09273098 0.09209016 0.09265982\n",
            " 0.09351812 0.09473547 0.09122668 0.08713703 0.08869723], argmax=7\n",
            "   \u001b[33m|->> #1/t=37-th Action selection: 5/2X UP (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [236 184  89  78]\n",
            "         |->> Action Probabilities (Rounded): [0.0879 0.0868 0.0942 0.092  0.0923 0.0937 0.0945 0.0954 0.0913 0.0818\n",
            " 0.0902], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.0879272  0.08675101 0.09419447 0.09196392 0.09233178 0.09369223\n",
            " 0.09452933 0.09536886 0.09125439 0.08180752 0.09017928], argmax=7\n",
            "   \u001b[33m|->> #2/t=38-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08500000089406967)\u001b[0m\n",
            "      |->> Bounding box moves to: [237 185  86  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0943 0.0867 0.089  0.0925 0.0927 0.0923 0.0944 0.0949 0.0895 0.0848\n",
            " 0.0889], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09434611 0.0867161  0.08900464 0.09245251 0.09268337 0.09228583\n",
            " 0.09437364 0.094917   0.08954927 0.08480998 0.08886156], argmax=7\n",
            "   \u001b[33m|->> #3/t=39-th Action selection: 3/2X RIGHT (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [241 185  86  75]\n",
            "         |->> Action Probabilities (Rounded): [0.091  0.0872 0.0913 0.0935 0.0926 0.0927 0.0956 0.0947 0.0914 0.0792\n",
            " 0.0908], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09096918 0.08715644 0.09130819 0.09351645 0.0926085  0.09274779\n",
            " 0.09558902 0.09465662 0.09138726 0.07923673 0.09082385], argmax=6\n",
            "   \u001b[33m|->> #4/t=40-th Action selection: 6/DOWN (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [241 187  86  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0922 0.0884 0.0893 0.0903 0.0933 0.0926 0.0946 0.0942 0.0911 0.0834\n",
            " 0.0907], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09217117 0.08840809 0.08927549 0.09031443 0.0932986  0.09256344\n",
            " 0.09464002 0.09421088 0.09106585 0.08338484 0.0906672 ], argmax=6\n",
            "|->> Revisiting bbox: [241 185  86  75]. ACtion 4 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [235, 187,  92,  81] -> [241, 187,  86,  75] (Target was [265, 181,  91,  69])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.006) for SCALE DOWN:bbox transition: [235, 187,  92,  81] -> [236, 188,  89,  78] w/ P(a|s)=0.08713702857494354 and iou=0.3915377328702242 and reward=-0.0060195190381727715 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.036) for 2X UP:bbox transition: [236, 188,  89,  78] -> [236, 184,  89,  78] w/ P(a|s)=0.09369222819805145 and iou=0.42759961127308066 and reward=0.03606187840285646 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.007) for SCALE DOWN:bbox transition: [236, 184,  89,  78] -> [237, 185,  86,  75] w/ P(a|s)=0.08480998128652573 and iou=0.4208058935149012 and reward=-0.006793717758179441 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.042) for 2X RIGHT:bbox transition: [237, 185,  86,  75] -> [241, 185,  86,  75] w/ P(a|s)=0.09351644665002823 and iou=0.4632716404184389 and reward=0.04246574690353766 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (-1.0) for DOWN:bbox transition: [241, 185,  86,  75] -> [241, 187,  86,  75] w/ P(a|s)=0.09464001655578613 and iou=0.4427065623937436 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.01468927  0.08538516 -0.01676243  0.10062759 -2.3576748 ]\n",
            "\u001b[31m>> Total frame loss: -2.2031137943267822\u001b[0m\n",
            "Final bounding box: [241 187  86  75] reached in 41 timesteps (originating from [259 213  84  73]). Target was [265 181  91  69]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 75 in t=41 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[31m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 9.039007186889648\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 3.6482760906219482\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/BlurCar3\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0068.jpg\n",
            "Starting bounding box=adnet_datasets/OTB/BlurCar3/img/0078.jpg for adnet_datasets/OTB/BlurCar3's frames (index: 0)\n",
            "src:adnet_datasets/OTB/BlurCar3/img/0068.jpg\n",
            "target:adnet_datasets/OTB/BlurCar3/img/0078.jpg.\n",
            "\u001b[34m>> Attempting to reach frame 66 with src: [280, 211,  83,  66] and target: [284, 212,  87,  76]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0069.jpg\n",
            "|->> Beginning tracking for bbox:[280 211  83  66]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 10/SCALE UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [278 210  85  68]\n",
            "         |->> Action Probabilities (Rounded): [0.091  0.0907 0.0909 0.091  0.0908 0.0909 0.0909 0.0909 0.0909 0.0911\n",
            " 0.091 ], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.09097881 0.09069625 0.09087276 0.09095939 0.09075336 0.09090286\n",
            " 0.09092653 0.09089454 0.09088559 0.09110016 0.09102977], argmax=9\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 2/RIGHT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [280 210  85  68]\n",
            "         |->> Action Probabilities (Rounded): [0.091  0.0911 0.0905 0.0914 0.0912 0.0915 0.0913 0.0916 0.0919 0.0929\n",
            " 0.0856], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.09096953 0.09107098 0.09049996 0.09142622 0.09120701 0.09148876\n",
            " 0.09131344 0.09161527 0.09194946 0.09287898 0.08558036], argmax=9\n",
            "   \u001b[33m|->> #2/t=3-th Action selection: 3/2X RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [284 210  85  68]\n",
            "         |->> Action Probabilities (Rounded): [0.0976 0.0909 0.0831 0.0923 0.0911 0.0925 0.0917 0.092  0.0921 0.09\n",
            " 0.0869], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09758063 0.09085073 0.08305904 0.09229252 0.0911141  0.09248117\n",
            " 0.09166195 0.09198374 0.09205473 0.08998888 0.08693255], argmax=0\n",
            "   \u001b[33m|->> #3/t=4-th Action selection: 9/SCALE DOWN (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [285 211  82  65]\n",
            "         |->> Action Probabilities (Rounded): [0.089  0.0925 0.0916 0.0889 0.0919 0.0923 0.0916 0.0922 0.0915 0.0917\n",
            " 0.0868], argmax=1\n",
            "         |->> Action Probabilities (RAW): [0.08902684 0.09245057 0.09164462 0.08894112 0.09193217 0.09228662\n",
            " 0.09157145 0.09223276 0.09147741 0.09165284 0.08678357], argmax=1\n",
            "   \u001b[33m|->> #4/t=5-th Action selection: 0/LEFT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [283 211  82  65]\n",
            "         |->> Action Probabilities (Rounded): [0.0931 0.0914 0.0877 0.0905 0.0923 0.0929 0.0925 0.0932 0.0919 0.0856\n",
            " 0.0889], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.093114   0.09135888 0.08769868 0.09054136 0.09230766 0.09294612\n",
            " 0.09250133 0.09316843 0.09190892 0.08556489 0.08888981], argmax=7\n",
            "   \u001b[33m|->> #5/t=6-th Action selection: 3/2X RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [287 211  82  65]\n",
            "         |->> Action Probabilities (Rounded): [0.0839 0.0919 0.0963 0.0915 0.0916 0.0939 0.0928 0.0937 0.0915 0.0856\n",
            " 0.0873], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08387757 0.09189025 0.09634842 0.09150597 0.09160464 0.09387372\n",
            " 0.09284464 0.09366746 0.09150597 0.08558516 0.08729619], argmax=2\n",
            "   \u001b[33m|->> #6/t=7-th Action selection: 3/2X RIGHT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [291 211  82  65]\n",
            "         |->> Action Probabilities (Rounded): [0.0944 0.0918 0.0855 0.09   0.0923 0.0935 0.0928 0.0938 0.0906 0.0868\n",
            " 0.0885], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09437013 0.09183607 0.0854995  0.09000225 0.09228431 0.09353922\n",
            " 0.09278505 0.09382487 0.09061702 0.08675052 0.08849113], argmax=0\n",
            "   \u001b[33m|->> #7/t=8-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [292 212  79  63]\n",
            "         |->> Action Probabilities (Rounded): [0.0901 0.0915 0.0896 0.0879 0.0929 0.094  0.0933 0.0942 0.0912 0.0872\n",
            " 0.0881], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09008015 0.09153248 0.08955576 0.08790454 0.09286019 0.09404021\n",
            " 0.09334083 0.09422631 0.09115736 0.08717956 0.08812265], argmax=7\n",
            "   \u001b[33m|->> #8/t=9-th Action selection: 2/RIGHT (P(a|s) = 0.0860000029206276)\u001b[0m\n",
            "      |->> Bounding box moves to: [294 212  79  63]\n",
            "         |->> Action Probabilities (Rounded): [0.0927 0.0909 0.086  0.0906 0.0929 0.0942 0.0938 0.0948 0.0912 0.0829\n",
            " 0.09  ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09267776 0.09090375 0.08595061 0.09063311 0.09294416 0.09415111\n",
            " 0.09384055 0.09483542 0.09119273 0.08286469 0.09000611], argmax=7\n",
            "   \u001b[33m|->> #9/t=10-th Action selection: 4/UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [294 211  79  63]\n",
            "         |->> Action Probabilities (Rounded): [0.0986 0.0908 0.0796 0.0908 0.0928 0.0952 0.0945 0.095  0.091  0.0837\n",
            " 0.0881], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09856668 0.09082613 0.07955112 0.09078372 0.09279168 0.09521054\n",
            " 0.09450752 0.09503306 0.0909755  0.0836898  0.08806422], argmax=0\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [280, 211,  83,  66] -> [294, 211,  79,  63] (Target was [284, 212,  87,  76])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.012) for SCALE UP:bbox transition: [280, 211,  83,  66] -> [278, 210,  85,  68] w/ P(a|s)=0.09102977067232132 and iou=0.7263861799944274 and reward=-0.011931577014918315 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.032) for RIGHT:bbox transition: [278, 210,  85,  68] -> [280, 210,  85,  68] w/ P(a|s)=0.09049995988607407 and iou=0.7587283565143343 and reward=0.032342176519906896 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.068) for 2X RIGHT:bbox transition: [280, 210,  85,  68] -> [284, 210,  85,  68] w/ P(a|s)=0.09229251742362976 and iou=0.8271896195812445 and reward=0.06846126306691014 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-0.043) for SCALE DOWN:bbox transition: [284, 210,  85,  68] -> [285, 211,  82,  65] w/ P(a|s)=0.09165284037590027 and iou=0.7839856587989245 and reward=-0.04320396078232003 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (-0.017) for LEFT:bbox transition: [285, 211,  82,  65] -> [283, 211,  82,  65] w/ P(a|s)=0.09311399608850479 and iou=0.767090855282628 and reward=-0.016894803516296464 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (0.017) for 2X RIGHT:bbox transition: [283, 211,  82,  65] -> [287, 211,  82,  65] w/ P(a|s)=0.0915059745311737 and iou=0.7839856587989245 and reward=0.016894803516296464 and discount=1.0\n",
            "   |->> t=7 Diff-Reward (-0.033) for 2X RIGHT:bbox transition: [287, 211,  82,  65] -> [291, 211,  82,  65] w/ P(a|s)=0.09000225365161896 and iou=0.7505130460275579 and reward=-0.033472612771366594 and discount=1.0\n",
            "   |->> t=8 Diff-Reward (0.002) for SCALE DOWN:bbox transition: [291, 211,  82,  65] -> [292, 212,  79,  63] w/ P(a|s)=0.08717955648899078 and iou=0.7527223230490018 and reward=0.0022092770214439117 and discount=1.0\n",
            "   |->> t=9 Diff-Reward (-0.033) for RIGHT:bbox transition: [292, 212,  79,  63] -> [294, 212,  79,  63] w/ P(a|s)=0.08595060557126999 and iou=0.719946571682992 and reward=-0.03277575136600974 and discount=1.0\n",
            "   |->> t=10 Diff-Reward (1.0) for UP:bbox transition: [294, 212,  79,  63] -> [294, 211,  79,  63] w/ P(a|s)=0.09279167652130127 and iou=0.7005135730007337 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.02859484  0.07769904  0.16312896 -0.10324655 -0.04010709  0.04040141\n",
            " -0.08059939  0.00539016 -0.08043113  2.3773983 ]\n",
            "\u001b[92m>> Total frame loss: 2.3310387134552\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 67 with src: [294, 211,  79,  63] and target: [284, 231,  80,  75]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0070.jpg\n",
            "|->> Beginning tracking for bbox:[294 211  79  63]\n",
            "   \u001b[33m|->> #0/t=11-th Action selection: 2/RIGHT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [296 211  79  63]\n",
            "         |->> Action Probabilities (Rounded): [0.0898 0.0926 0.0894 0.0892 0.091  0.0948 0.0948 0.0956 0.0907 0.0838\n",
            " 0.0882], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08981416 0.09261801 0.08936692 0.08921797 0.09101392 0.09484336\n",
            " 0.09482451 0.09563816 0.090715   0.08378739 0.0881606 ], argmax=7\n",
            "   \u001b[33m|->> #1/t=12-th Action selection: 2/RIGHT (P(a|s) = 0.07800000160932541)\u001b[0m\n",
            "      |->> Bounding box moves to: [298 211  79  63]\n",
            "         |->> Action Probabilities (Rounded): [0.1015 0.0912 0.0781 0.0905 0.0915 0.0948 0.094  0.0953 0.0913 0.0834\n",
            " 0.0883], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.10147308 0.09117926 0.07811951 0.09045662 0.09149764 0.09483936\n",
            " 0.09404621 0.09534094 0.09130108 0.083409   0.08833732], argmax=0\n",
            "   \u001b[33m|->> #2/t=13-th Action selection: 2/RIGHT (P(a|s) = 0.0820000022649765)\u001b[0m\n",
            "      |->> Bounding box moves to: [300 211  79  63]\n",
            "         |->> Action Probabilities (Rounded): [0.0949 0.0916 0.0817 0.091  0.0917 0.095  0.0944 0.0961 0.0906 0.0841\n",
            " 0.0889], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09490316 0.09155086 0.08174511 0.09099334 0.09173912 0.09500473\n",
            " 0.0944066  0.09610868 0.09060863 0.08407424 0.0888655 ], argmax=7\n",
            "   \u001b[33m|->> #3/t=14-th Action selection: 2/RIGHT (P(a|s) = 0.07900000363588333)\u001b[0m\n",
            "      |->> Bounding box moves to: [302 211  79  63]\n",
            "         |->> Action Probabilities (Rounded): [0.1002 0.0922 0.0791 0.0906 0.0919 0.0955 0.0944 0.0957 0.0899 0.0833\n",
            " 0.087 ], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.10022591 0.0922403  0.07910881 0.09059965 0.09189053 0.09549418\n",
            " 0.09444767 0.0956763  0.08994722 0.08334973 0.08701967], argmax=0\n",
            "|->> Revisiting bbox: [298 211  79  63]. ACtion 1 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [294, 211,  79,  63] -> [302, 211,  79,  63] (Target was [284, 231,  80,  75])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.015) for RIGHT:bbox transition: [294, 211,  79,  63] -> [296, 211,  79,  63] w/ P(a|s)=0.08936692029237747 and iou=0.36309449894449275 and reward=-0.014713960952582705 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.014) for RIGHT:bbox transition: [296, 211,  79,  63] -> [298, 211,  79,  63] w/ P(a|s)=0.07811950892210007 and iou=0.3486914854404718 and reward=-0.014403013504020956 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.014) for RIGHT:bbox transition: [298, 211,  79,  63] -> [300, 211,  79,  63] w/ P(a|s)=0.08174511045217514 and iou=0.33458966565349546 and reward=-0.014101819786976333 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-1.0) for RIGHT:bbox transition: [300, 211,  79,  63] -> [302, 211,  79,  63] w/ P(a|s)=0.0791088119149208 and iou=0.32077968956804237 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.03553429 -0.0367207  -0.03531306 -2.536931  ]\n",
            "\u001b[31m>> Total frame loss: -2.6444990634918213\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 68 with src: [302, 211,  79,  63] and target: [261, 245,  90,  72]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0071.jpg\n",
            "|->> Beginning tracking for bbox:[302 211  79  63]\n",
            "|->> Revisiting bbox: [302 211  79  63]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=15-th Action selection: 8/STOP (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [302 211  79  63]\n",
            "         |->> Action Probabilities (Rounded): [0.0988 0.092  0.0808 0.0897 0.0921 0.0955 0.0946 0.0963 0.0902 0.0838\n",
            " 0.0862], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09884185 0.09203655 0.08077753 0.08968803 0.09208063 0.09550076\n",
            " 0.0946268  0.09625699 0.09021236 0.08378822 0.08619026], argmax=0\n",
            "         |->> Hit a STOP on the 15-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [302, 211,  79,  63] -> [302, 211,  79,  63] (Target was [261, 245,  90,  72])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [302, 211,  79,  63] -> [302, 211,  79,  63] w/ P(a|s)=0.09021236002445221 and iou=0.14159027500996413 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.4055889]\n",
            "\u001b[31m>> Total frame loss: -2.4055888652801514\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 69 with src: [302, 211,  79,  63] and target: [252, 242,  91,  71]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0072.jpg\n",
            "|->> Beginning tracking for bbox:[302 211  79  63]\n",
            "   \u001b[33m|->> #0/t=15-th Action selection: 0/LEFT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [300 211  79  63]\n",
            "         |->> Action Probabilities (Rounded): [0.0926 0.0929 0.0878 0.0881 0.0923 0.0943 0.0944 0.0954 0.0901 0.0845\n",
            " 0.0875], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09263659 0.09294767 0.08783868 0.08812232 0.09232117 0.09426945\n",
            " 0.0943953  0.09537235 0.09008658 0.08450897 0.08750088], argmax=7\n",
            "   \u001b[33m|->> #1/t=16-th Action selection: 3/2X RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [304 211  79  63]\n",
            "         |->> Action Probabilities (Rounded): [0.0864 0.0924 0.0921 0.0921 0.0909 0.0956 0.0941 0.0968 0.0904 0.082\n",
            " 0.0872], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08642013 0.09242044 0.09210437 0.09206792 0.09093799 0.0956162\n",
            " 0.09408254 0.09675569 0.09040555 0.0819547  0.08723448], argmax=7\n",
            "   \u001b[33m|->> #2/t=17-th Action selection: 5/2X UP (P(a|s) = 0.09600000083446503)\u001b[0m\n",
            "      |->> Bounding box moves to: [304 209  79  63]\n",
            "         |->> Action Probabilities (Rounded): [0.0943 0.093  0.0863 0.09   0.0914 0.0955 0.094  0.0949 0.09   0.0832\n",
            " 0.0873], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.09431522 0.09299993 0.08633339 0.08998299 0.09142662 0.09551332\n",
            " 0.0940053  0.09493669 0.08995625 0.08319074 0.08733951], argmax=5\n",
            "   \u001b[33m|->> #3/t=18-th Action selection: 2/RIGHT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [306 209  79  63]\n",
            "         |->> Action Probabilities (Rounded): [0.092  0.0921 0.0903 0.0897 0.0917 0.0936 0.0942 0.0953 0.0904 0.0837\n",
            " 0.0869], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09198816 0.0920562  0.09034555 0.08968397 0.09172045 0.09364702\n",
            " 0.09422817 0.09530482 0.09040842 0.08374159 0.08687563], argmax=7\n",
            "   \u001b[33m|->> #4/t=19-th Action selection: 5/2X UP (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [306 207  79  63]\n",
            "         |->> Action Probabilities (Rounded): [0.1004 0.0914 0.081  0.0911 0.0913 0.0943 0.0945 0.0949 0.0902 0.0841\n",
            " 0.0868], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.10043972 0.091421   0.08099445 0.09106452 0.09127519 0.09430206\n",
            " 0.09445816 0.09492266 0.09020696 0.08409183 0.0868235 ], argmax=0\n",
            "   \u001b[33m|->> #5/t=20-th Action selection: 6/DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [306 208  79  63]\n",
            "         |->> Action Probabilities (Rounded): [0.0906 0.0923 0.0914 0.0891 0.092  0.0922 0.0939 0.0952 0.091  0.0849\n",
            " 0.0873], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09056814 0.09234422 0.09138752 0.08908419 0.0920294  0.09217091\n",
            " 0.09394536 0.0951855  0.09103303 0.08493124 0.08732057], argmax=7\n",
            "|->> Revisiting bbox: [306 207  79  63]. ACtion 4 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [302, 211,  79,  63] -> [306, 208,  79,  63] (Target was [252, 242,  91,  71])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.007) for LEFT:bbox transition: [302, 211,  79,  63] -> [300, 211,  79,  63] w/ P(a|s)=0.0926365926861763 and iou=0.13675213675213677 and reward=0.007184686623754377 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.014) for 2X RIGHT:bbox transition: [300, 211,  79,  63] -> [304, 211,  79,  63] w/ P(a|s)=0.09206791967153549 and iou=0.1224730127576055 and reward=-0.014279123994531268 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.009) for 2X UP:bbox transition: [304, 211,  79,  63] -> [304, 209,  79,  63] w/ P(a|s)=0.09551332145929337 and iou=0.11394624074795481 and reward=-0.008526772009650685 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-0.006) for RIGHT:bbox transition: [304, 209,  79,  63] -> [306, 209,  79,  63] w/ P(a|s)=0.09034555405378342 and iou=0.10747482571649884 and reward=-0.006471415031455971 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (-0.008) for 2X UP:bbox transition: [306, 209,  79,  63] -> [306, 207,  79,  63] w/ P(a|s)=0.09430205821990967 and iou=0.09959623149394348 and reward=-0.007878594222555366 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (-1.0) for DOWN:bbox transition: [306, 207,  79,  63] -> [306, 208,  79,  63] w/ P(a|s)=0.09394536167383194 and iou=0.1035214664737096 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.01709288 -0.03405898 -0.02002504 -0.01555802 -0.01860335 -2.365042  ]\n",
            "\u001b[31m>> Total frame loss: -2.43619441986084\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 70 with src: [306, 208,  79,  63] and target: [261, 227,  92,  72]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0073.jpg\n",
            "|->> Beginning tracking for bbox:[306 208  79  63]\n",
            "   \u001b[33m|->> #0/t=21-th Action selection: 10/SCALE UP (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [304 207  81  65]\n",
            "         |->> Action Probabilities (Rounded): [0.0954 0.0918 0.0888 0.0908 0.0927 0.0922 0.0918 0.0946 0.0896 0.0852\n",
            " 0.0872], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09536447 0.09175646 0.08884812 0.09081656 0.09269807 0.09216848\n",
            " 0.09176262 0.09460761 0.08961689 0.08517203 0.08718864], argmax=0\n",
            "   \u001b[33m|->> #1/t=22-th Action selection: 2/RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [306 207  81  65]\n",
            "         |->> Action Probabilities (Rounded): [0.0921 0.0918 0.0909 0.0918 0.0907 0.0923 0.0935 0.0947 0.0914 0.0881\n",
            " 0.0827], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09213573 0.09176732 0.09090142 0.09184431 0.09072818 0.09225897\n",
            " 0.09347735 0.09465657 0.09143178 0.08807886 0.08271951], argmax=7\n",
            "|->> Revisiting bbox: [304 207  81  65]. ACtion 0 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [306, 208,  79,  63] -> [306, 207,  81,  65] (Target was [261, 227,  92,  72])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.011) for SCALE UP:bbox transition: [306, 208,  79,  63] -> [304, 207,  81,  65] w/ P(a|s)=0.08718863874673843 and iou=0.22769516728624536 and reward=0.010764505374989713 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for RIGHT:bbox transition: [304, 207,  81,  65] -> [306, 207,  81,  65] w/ P(a|s)=0.09090141952037811 and iou=0.21639042357274402 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.02626196 -2.3979797 ]\n",
            "\u001b[31m>> Total frame loss: -2.371717691421509\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 71 with src: [306, 207,  81,  65] and target: [271, 222,  91,  70]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0074.jpg\n",
            "|->> Beginning tracking for bbox:[306 207  81  65]\n",
            "   \u001b[33m|->> #0/t=23-th Action selection: 1/2X LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [302 207  81  65]\n",
            "         |->> Action Probabilities (Rounded): [0.0998 0.0911 0.0824 0.0925 0.0922 0.0927 0.0924 0.0947 0.0914 0.0863\n",
            " 0.0845], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09976006 0.09112597 0.08236966 0.09253901 0.09216343 0.09265335\n",
            " 0.09242249 0.0947097  0.09138788 0.0863218  0.08454663], argmax=0\n",
            "   \u001b[33m|->> #1/t=24-th Action selection: 4/UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [302 206  81  65]\n",
            "         |->> Action Probabilities (Rounded): [0.0907 0.0898 0.0922 0.0914 0.0922 0.0927 0.094  0.0944 0.089  0.0888\n",
            " 0.0847], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09072353 0.0898228  0.09219056 0.09144735 0.09215579 0.09270743\n",
            " 0.09395006 0.09441876 0.08900297 0.08884795 0.08473279], argmax=7\n",
            "|->> Revisiting bbox: [302 207  81  65]. ACtion 6 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [306, 207,  81,  65] -> [302, 206,  81,  65] (Target was [271, 222,  91,  70])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.031) for 2X LEFT:bbox transition: [306, 207,  81,  65] -> [302, 207,  81,  65] w/ P(a|s)=0.0911259651184082 and iou=0.3474232773595831 and reward=0.030501941762525964 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for UP:bbox transition: [302, 207,  81,  65] -> [302, 206,  81,  65] w/ P(a|s)=0.09215579181909561 and iou=0.33812535940195515 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.07306778 -2.3842747 ]\n",
            "\u001b[31m>> Total frame loss: -2.311206817626953\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 72 with src: [302, 206,  81,  65] and target: [276, 221,  89,  68]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0075.jpg\n",
            "|->> Beginning tracking for bbox:[302 206  81  65]\n",
            "   \u001b[33m|->> #0/t=25-th Action selection: 10/SCALE UP (P(a|s) = 0.08500000089406967)\u001b[0m\n",
            "      |->> Bounding box moves to: [300 205  83  67]\n",
            "         |->> Action Probabilities (Rounded): [0.0959 0.0886 0.0888 0.0906 0.0902 0.0922 0.0943 0.0945 0.0913 0.0883\n",
            " 0.0852], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09592434 0.08861635 0.0887628  0.09064456 0.09022942 0.09215289\n",
            " 0.09428576 0.09449738 0.09134246 0.08830388 0.08524019], argmax=0\n",
            "   \u001b[33m|->> #1/t=26-th Action selection: 3/2X RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [304 205  83  67]\n",
            "         |->> Action Probabilities (Rounded): [0.0905 0.0901 0.0898 0.0921 0.0911 0.0927 0.0937 0.0943 0.0919 0.0919\n",
            " 0.082 ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09048933 0.09005556 0.08978876 0.09205204 0.09114815 0.09270047\n",
            " 0.09372093 0.09429897 0.09189082 0.09187875 0.0819762 ], argmax=7\n",
            "   \u001b[33m|->> #2/t=27-th Action selection: 3/2X RIGHT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [308 205  83  67]\n",
            "         |->> Action Probabilities (Rounded): [0.0917 0.0913 0.0895 0.0902 0.092  0.0923 0.0941 0.0942 0.0908 0.0903\n",
            " 0.0835], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09168709 0.09132527 0.0895184  0.0901964  0.09201373 0.09226917\n",
            " 0.0941369  0.09418535 0.09082215 0.09030124 0.08354425], argmax=7\n",
            "   \u001b[33m|->> #3/t=28-th Action selection: 3/2X RIGHT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [312 205  83  67]\n",
            "         |->> Action Probabilities (Rounded): [0.0914 0.0906 0.0882 0.089  0.0928 0.0929 0.0941 0.094  0.0917 0.0911\n",
            " 0.0842], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09135859 0.09059706 0.08820409 0.08904248 0.09282535 0.09286188\n",
            " 0.09413338 0.09395125 0.09173849 0.09110099 0.08418646], argmax=6\n",
            "   \u001b[33m|->> #4/t=29-th Action selection: 5/2X UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [312 201  83  67]\n",
            "         |->> Action Probabilities (Rounded): [0.0922 0.0906 0.0876 0.0878 0.0933 0.0934 0.0936 0.0933 0.0905 0.0917\n",
            " 0.086 ], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09220054 0.09062567 0.08760891 0.08775848 0.09329204 0.09338067\n",
            " 0.0936021  0.09329762 0.09048761 0.09170417 0.0860422 ], argmax=6\n",
            "   \u001b[33m|->> #5/t=30-th Action selection: 4/UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [312 199  83  67]\n",
            "         |->> Action Probabilities (Rounded): [0.0914 0.0906 0.0863 0.0885 0.0935 0.0923 0.0942 0.094  0.0904 0.0926\n",
            " 0.0862], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09135473 0.09063497 0.08627913 0.08846197 0.09345903 0.09228739\n",
            " 0.09419985 0.09401474 0.09044137 0.09263918 0.08622772], argmax=6\n",
            "   \u001b[33m|->> #6/t=31-th Action selection: 9/SCALE DOWN (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [313 200  80  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0911 0.0912 0.0885 0.089  0.09   0.092  0.0954 0.0942 0.0911 0.0915\n",
            " 0.086 ], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09111788 0.09115387 0.08850447 0.08903279 0.0899517  0.09204715\n",
            " 0.09543251 0.09416944 0.09106049 0.0914939  0.08603584], argmax=6\n",
            "   \u001b[33m|->> #7/t=32-th Action selection: 1/2X LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [309 200  80  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0909 0.0912 0.0874 0.0901 0.0918 0.0919 0.0939 0.0946 0.0919 0.0867\n",
            " 0.0896], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09087361 0.09117881 0.08744172 0.09012052 0.09183177 0.09186179\n",
            " 0.09387711 0.09461819 0.09194476 0.08665738 0.08959432], argmax=7\n",
            "|->> Revisiting bbox: [309 200  80  64]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [302, 206,  81,  65] -> [309, 200,  80,  64] (Target was [276, 221,  89,  68])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.014) for SCALE UP:bbox transition: [302, 206,  81,  65] -> [300, 205,  83,  67] w/ P(a|s)=0.0852401927113533 and iou=0.39949385394070863 and reward=0.013795311024092982 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.034) for 2X RIGHT:bbox transition: [300, 205,  83,  67] -> [304, 205,  83,  67] w/ P(a|s)=0.09205203503370285 and iou=0.3659139026111503 and reward=-0.03357995132955832 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.032) for 2X RIGHT:bbox transition: [304, 205,  83,  67] -> [308, 205,  83,  67] w/ P(a|s)=0.0901964008808136 and iou=0.333907649896623 and reward=-0.032006252714527283 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-0.031) for 2X RIGHT:bbox transition: [308, 205,  83,  67] -> [312, 205,  83,  67] w/ P(a|s)=0.08904247730970383 and iou=0.30336700336700334 and reward=-0.030540646529619686 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (-0.03) for 2X UP:bbox transition: [312, 205,  83,  67] -> [312, 201,  83,  67] w/ P(a|s)=0.09338067471981049 and iou=0.27307607980705983 and reward=-0.030290923559943506 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (-0.015) for UP:bbox transition: [312, 201,  83,  67] -> [312, 199,  83,  67] w/ P(a|s)=0.09345903247594833 and iou=0.25845253576072824 and reward=-0.014623544046331594 and discount=1.0\n",
            "   |->> t=7 Diff-Reward (-0.008) for SCALE DOWN:bbox transition: [312, 199,  83,  67] -> [313, 200,  80,  64] w/ P(a|s)=0.09149389714002609 and iou=0.25022381378692926 and reward=-0.00822872197379898 and discount=1.0\n",
            "   |->> t=8 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [313, 200,  80,  64] -> [309, 200,  80,  64] w/ P(a|s)=0.09117881208658218 and iou=0.2747603833865815 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.03396795 -0.08010166 -0.07699955 -0.07386689 -0.07182193 -0.03466119\n",
            " -0.01967885 -2.3949327 ]\n",
            "\u001b[31m>> Total frame loss: -2.718094825744629\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 73 with src: [309, 200,  80,  64] and target: [282, 206,  82,  70]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0076.jpg\n",
            "|->> Beginning tracking for bbox:[309 200  80  64]\n",
            "   \u001b[33m|->> #0/t=33-th Action selection: 1/2X LEFT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [305 200  80  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0904 0.0888 0.088  0.091  0.092  0.0914 0.0947 0.0944 0.0917 0.0891\n",
            " 0.0885], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09044018 0.08879129 0.08801136 0.09097839 0.09201194 0.09142199\n",
            " 0.09473137 0.09437712 0.0916879  0.0890732  0.08847526], argmax=6\n",
            "|->> Revisiting bbox: [309 200  80  64]. ACtion 3 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [309, 200,  80,  64] -> [305, 200,  80,  64] (Target was [282, 206,  82,  70])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [309, 200,  80,  64] -> [305, 200,  80,  64] w/ P(a|s)=0.08879128843545914 and iou=0.46006991126646946 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.4214668]\n",
            "\u001b[31m>> Total frame loss: -2.421466827392578\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 74 with src: [305, 200,  80,  64] and target: [265, 181,  91,  69]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0077.jpg\n",
            "|->> Beginning tracking for bbox:[305 200  80  64]\n",
            "|->> Revisiting bbox: [305 200  80  64]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=34-th Action selection: 8/STOP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [305 200  80  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0906 0.0877 0.0877 0.0908 0.0923 0.0916 0.0936 0.0949 0.0919 0.0891\n",
            " 0.0897], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09062853 0.0877405  0.0877375  0.09078701 0.09231576 0.09164248\n",
            " 0.09358866 0.09488776 0.09190702 0.08905941 0.08970544], argmax=7\n",
            "         |->> Hit a STOP on the 34-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [305, 200,  80,  64] -> [305, 200,  80,  64] (Target was [265, 181,  91,  69])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [305, 200,  80,  64] -> [305, 200,  80,  64] w/ P(a|s)=0.09190701693296432 and iou=0.2881681545937394 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.386978]\n",
            "\u001b[31m>> Total frame loss: -2.3869779109954834\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 75 with src: [305, 200,  80,  64] and target: [242, 172,  87,  67]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0078.jpg\n",
            "|->> Beginning tracking for bbox:[305 200  80  64]\n",
            "|->> Revisiting bbox: [305 200  80  64]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=34-th Action selection: 8/STOP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [305 200  80  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0905 0.0864 0.089  0.0891 0.092  0.0916 0.0949 0.0948 0.0934 0.0887\n",
            " 0.0896], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09049855 0.08640771 0.08895682 0.08906361 0.09204397 0.09163545\n",
            " 0.09492722 0.09479346 0.09336174 0.08872422 0.08958714], argmax=6\n",
            "         |->> Hit a STOP on the 34-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [305, 200,  80,  64] -> [305, 200,  80,  64] (Target was [242, 172,  87,  67])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [305, 200,  80,  64] -> [305, 200,  80,  64] w/ P(a|s)=0.0933617353439331 and iou=0.09347847797862778 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.3712738]\n",
            "\u001b[31m>> Total frame loss: -2.3712737560272217\u001b[0m\n",
            "Final bounding box: [305 200  80  64] reached in 34 timesteps (originating from [280 211  83  66]). Target was [242 172  87  67]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 76 in t=34 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[31m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 10.051867485046387\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 3.470594882965088\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/BlurCar3\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0069.jpg\n",
            "Starting bounding box=adnet_datasets/OTB/BlurCar3/img/0079.jpg for adnet_datasets/OTB/BlurCar3's frames (index: 0)\n",
            "src:adnet_datasets/OTB/BlurCar3/img/0069.jpg\n",
            "target:adnet_datasets/OTB/BlurCar3/img/0079.jpg.\n",
            "\u001b[34m>> Attempting to reach frame 67 with src: [284, 212,  87,  76] and target: [284, 231,  80,  75]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0070.jpg\n",
            "|->> Beginning tracking for bbox:[284 212  87  76]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 1/2X LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [280 212  87  76]\n",
            "         |->> Action Probabilities (Rounded): [0.091  0.0907 0.0909 0.091  0.0908 0.0909 0.0909 0.0909 0.0909 0.0911\n",
            " 0.091 ], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.0909792  0.09068799 0.09086986 0.09096114 0.09075192 0.09090307\n",
            " 0.09092505 0.09089679 0.09088544 0.09110457 0.09103498], argmax=9\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 6/DOWN (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [280 214  87  76]\n",
            "         |->> Action Probabilities (Rounded): [0.0905 0.0885 0.0914 0.091  0.0909 0.091  0.0911 0.0914 0.0916 0.0913\n",
            " 0.0912], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09052732 0.08846682 0.09138888 0.09104741 0.09094895 0.09098291\n",
            " 0.09114598 0.09135024 0.09159107 0.09131183 0.0912386 ], argmax=8\n",
            "   \u001b[33m|->> #2/t=3-th Action selection: 1/2X LEFT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [276 214  87  76]\n",
            "         |->> Action Probabilities (Rounded): [0.0913 0.0888 0.0921 0.091  0.0923 0.0911 0.0892 0.0917 0.0912 0.0909\n",
            " 0.0903], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.09133926 0.08877143 0.09205973 0.09098645 0.09234999 0.0911226\n",
            " 0.08923411 0.09170727 0.09115784 0.09092931 0.09034196], argmax=4\n",
            "   \u001b[33m|->> #3/t=4-th Action selection: 7/2X DOWN (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [276 218  87  76]\n",
            "         |->> Action Probabilities (Rounded): [0.0905 0.0865 0.0923 0.0914 0.0906 0.0913 0.0915 0.0918 0.0919 0.0912\n",
            " 0.0909], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.09046845 0.08652597 0.09229339 0.09136759 0.09063708 0.09132367\n",
            " 0.09149364 0.09184012 0.09191652 0.09124091 0.09089267], argmax=2\n",
            "|->> Revisiting bbox: [276 218  87  76]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [284, 212,  87,  76] -> [276, 218,  87,  76] (Target was [284, 231,  80,  75])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X LEFT:bbox transition: [284, 212,  87,  76] -> [280, 212,  87,  76] w/ P(a|s)=0.09068799018859863 and iou=0.5663189269746647 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.032) for DOWN:bbox transition: [280, 212,  87,  76] -> [280, 214,  87,  76] w/ P(a|s)=0.09114598482847214 and iou=0.5980739989863153 and reward=0.03175507201165062 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.012) for 2X LEFT:bbox transition: [280, 214,  87,  76] -> [276, 214,  87,  76] w/ P(a|s)=0.08877142518758774 and iou=0.5862155703685071 and reward=-0.01185842861780817 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-1.0) for 2X DOWN:bbox transition: [276, 214,  87,  76] -> [276, 218,  87,  76] w/ P(a|s)=0.09184011816978455 and iou=0.6518664047151277 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.          0.07606269 -0.02871744 -2.387706  ]\n",
            "\u001b[31m>> Total frame loss: -2.3403608798980713\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 68 with src: [276, 218,  87,  76] and target: [261, 245,  90,  72]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0071.jpg\n",
            "|->> Beginning tracking for bbox:[276 218  87  76]\n",
            "   \u001b[33m|->> #0/t=5-th Action selection: 4/UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [276 216  87  76]\n",
            "         |->> Action Probabilities (Rounded): [0.0906 0.0873 0.0923 0.0908 0.0919 0.0913 0.0908 0.0907 0.092  0.0914\n",
            " 0.091 ], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.09055594 0.08727241 0.09225538 0.09075768 0.09192038 0.09127591\n",
            " 0.09080451 0.09067234 0.09199812 0.09144725 0.09104001], argmax=2\n",
            "   \u001b[33m|->> #1/t=6-th Action selection: 4/UP (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [276 214  87  76]\n",
            "         |->> Action Probabilities (Rounded): [0.0904 0.0873 0.0923 0.092  0.0894 0.0912 0.0931 0.0911 0.0919 0.0905\n",
            " 0.0908], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.0904351  0.08728447 0.09233672 0.09199236 0.08941886 0.09119163\n",
            " 0.09306783 0.09111124 0.09189057 0.09050813 0.09076309], argmax=6\n",
            "   \u001b[33m|->> #2/t=7-th Action selection: 9/SCALE DOWN (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [277 215  84  73]\n",
            "         |->> Action Probabilities (Rounded): [0.0913 0.0886 0.092  0.0916 0.0889 0.0914 0.0915 0.0911 0.0919 0.0908\n",
            " 0.0909], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.09134714 0.08858227 0.09196925 0.09164002 0.08887265 0.09144615\n",
            " 0.09149954 0.09105518 0.09192751 0.09077684 0.09088347], argmax=2\n",
            "|->> Revisiting bbox: [277 215  84  73]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [276, 218,  87,  76] -> [277, 215,  84,  73] (Target was [261, 245,  90,  72])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.022) for UP:bbox transition: [276, 218,  87,  76] -> [276, 216,  87,  76] w/ P(a|s)=0.09192037582397461 and iou=0.3684540608341173 and reward=-0.02179761167305061 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.021) for UP:bbox transition: [276, 216,  87,  76] -> [276, 214,  87,  76] w/ P(a|s)=0.08941885828971863 and iou=0.3473294226613152 and reward=-0.02112463817280208 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [276, 214,  87,  76] -> [277, 215,  84,  73] w/ P(a|s)=0.09077683836221695 and iou=0.3374337221633086 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.05202725 -0.05100383 -2.3993511 ]\n",
            "\u001b[31m>> Total frame loss: -2.502382278442383\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 69 with src: [277, 215,  84,  73] and target: [252, 242,  91,  71]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0072.jpg\n",
            "|->> Beginning tracking for bbox:[277 215  84  73]\n",
            "   \u001b[33m|->> #0/t=8-th Action selection: 4/UP (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [277 213  84  73]\n",
            "         |->> Action Probabilities (Rounded): [0.0895 0.0886 0.0918 0.093  0.0902 0.0916 0.0929 0.0918 0.0923 0.0861\n",
            " 0.0921], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.08953343 0.08856206 0.09175958 0.09297623 0.09021345 0.09164708\n",
            " 0.09292301 0.09181927 0.09229746 0.08614085 0.09212758], argmax=3\n",
            "|->> Revisiting bbox: [277 213  84  73]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [277, 215,  84,  73] -> [277, 213,  84,  73] (Target was [252, 242,  91,  71])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for UP:bbox transition: [277, 215,  84,  73] -> [277, 213,  84,  73] w/ P(a|s)=0.09021344780921936 and iou=0.2997213334709464 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.4055767]\n",
            "\u001b[31m>> Total frame loss: -2.405576705932617\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 70 with src: [277, 213,  84,  73] and target: [261, 227,  92,  72]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0073.jpg\n",
            "|->> Beginning tracking for bbox:[277 213  84  73]\n",
            "   \u001b[33m|->> #0/t=9-th Action selection: 7/2X DOWN (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [277 217  84  73]\n",
            "         |->> Action Probabilities (Rounded): [0.0906 0.0893 0.0917 0.093  0.0894 0.0914 0.0935 0.0921 0.0915 0.0873\n",
            " 0.0902], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09060916 0.08932371 0.0917237  0.09301302 0.08939597 0.09135543\n",
            " 0.09346846 0.092072   0.09151509 0.08731755 0.09020586], argmax=6\n",
            "   \u001b[33m|->> #1/t=10-th Action selection: 0/LEFT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [275 217  84  73]\n",
            "         |->> Action Probabilities (Rounded): [0.0899 0.0898 0.0908 0.0928 0.0912 0.0913 0.0924 0.0911 0.0913 0.0882\n",
            " 0.0912], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.08986315 0.08981938 0.09075561 0.09282944 0.09121655 0.09128444\n",
            " 0.09240143 0.09107187 0.09129379 0.08824153 0.09122275], argmax=3\n",
            "   \u001b[33m|->> #2/t=11-th Action selection: 10/SCALE UP (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [273 215  86  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0828 0.09   0.0966 0.0934 0.0915 0.0922 0.0938 0.0919 0.0914 0.0861\n",
            " 0.0903], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08279379 0.08999703 0.09662187 0.09335221 0.09148721 0.09224906\n",
            " 0.09377995 0.09191386 0.09143087 0.0861231  0.09025104], argmax=2\n",
            "   \u001b[33m|->> #3/t=12-th Action selection: 5/2X UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [273 211  86  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0917 0.0913 0.0873 0.0942 0.0924 0.0916 0.0934 0.0925 0.0913 0.0891\n",
            " 0.0853], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09168335 0.09129466 0.08733751 0.09415453 0.09235279 0.09161721\n",
            " 0.09343092 0.09246282 0.09127168 0.08912463 0.08526997], argmax=3\n",
            "   \u001b[33m|->> #4/t=13-th Action selection: 3/2X RIGHT (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [277 211  86  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0883 0.0905 0.0923 0.094  0.092  0.0908 0.0934 0.0922 0.0918 0.0873\n",
            " 0.0876], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.08826359 0.09047349 0.09225988 0.09399994 0.09197037 0.09075197\n",
            " 0.09344367 0.09219169 0.09176832 0.08731204 0.08756498], argmax=3\n",
            "|->> Revisiting bbox: [273 211  86  75]. ACtion 1 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [277, 213,  84,  73] -> [277, 211,  86,  75] (Target was [261, 227,  92,  72])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.059) for 2X DOWN:bbox transition: [277, 213,  84,  73] -> [277, 217,  84,  73] w/ P(a|s)=0.09207199513912201 and iou=0.6009036144578314 and reward=0.05883398196266698 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.026) for LEFT:bbox transition: [277, 217,  84,  73] -> [275, 217,  84,  73] w/ P(a|s)=0.08986315131187439 and iou=0.6266258607498087 and reward=0.02572224629197739 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.001) for SCALE UP:bbox transition: [275, 217,  84,  73] -> [273, 215,  86,  75] w/ P(a|s)=0.09025104343891144 and iou=0.6273338312173263 and reward=0.0007079704675175824 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-0.062) for 2X UP:bbox transition: [273, 215,  86,  75] -> [273, 211,  86,  75] w/ P(a|s)=0.09161721169948578 and iou=0.5649988029686378 and reward=-0.06233502824868853 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [273, 211,  86,  75] -> [277, 211,  86,  75] w/ P(a|s)=0.093999944627285 and iou=0.5220023282887079 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 1.4032991e-01  6.1976910e-02  1.7027823e-03 -1.4898922e-01\n",
            " -2.3644612e+00]\n",
            "\u001b[31m>> Total frame loss: -2.309440851211548\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 71 with src: [277, 211,  86,  75] and target: [271, 222,  91,  70]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0074.jpg\n",
            "|->> Beginning tracking for bbox:[277 211  86  75]\n",
            "   \u001b[33m|->> #0/t=14-th Action selection: 6/DOWN (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [277 213  86  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0931 0.0915 0.0889 0.0924 0.0923 0.0908 0.0931 0.092  0.0903 0.0884\n",
            " 0.0872], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09308644 0.09147404 0.08891665 0.09241002 0.09228551 0.09081474\n",
            " 0.09307116 0.09197287 0.0903292  0.08839365 0.08724561], argmax=0\n",
            "   \u001b[33m|->> #1/t=15-th Action selection: 5/2X UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [277 209  86  75]\n",
            "         |->> Action Probabilities (Rounded): [0.092  0.0911 0.0904 0.0919 0.094  0.0908 0.0911 0.0935 0.0903 0.0877\n",
            " 0.0872], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.09197956 0.09113242 0.09041829 0.09191363 0.09402333 0.09075712\n",
            " 0.0911347  0.09347046 0.09027556 0.08773679 0.0871582 ], argmax=4\n",
            "   \u001b[33m|->> #2/t=16-th Action selection: 3/2X RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [281 209  86  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0922 0.0912 0.0895 0.0923 0.0909 0.0906 0.0924 0.093  0.0907 0.0891\n",
            " 0.0881], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09215845 0.09117071 0.08950648 0.09234319 0.09092578 0.0905984\n",
            " 0.09238081 0.09295941 0.09067772 0.08913334 0.08814578], argmax=7\n",
            "|->> Revisiting bbox: [277 209  86  75]. ACtion 1 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [277, 211,  86,  75] -> [281, 209,  86,  75] (Target was [271, 222,  91,  70])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.041) for DOWN:bbox transition: [277, 211,  86,  75] -> [277, 213,  86,  75] w/ P(a|s)=0.09307115525007248 and iou=0.7780859916782247 and reward=0.040958620404511925 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.08) for 2X UP:bbox transition: [277, 213,  86,  75] -> [277, 209,  86,  75] w/ P(a|s)=0.09075712412595749 and iou=0.6980132450331126 and reward=-0.0800727466451121 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [277, 209,  86,  75] -> [281, 209,  86,  75] w/ P(a|s)=0.09234318882226944 and iou=0.6440112849448577 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.09725178 -0.19214003 -2.3822434 ]\n",
            "\u001b[31m>> Total frame loss: -2.4771316051483154\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 72 with src: [281, 209,  86,  75] and target: [276, 221,  89,  68]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0075.jpg\n",
            "|->> Beginning tracking for bbox:[281 209  86  75]\n",
            "   \u001b[33m|->> #0/t=17-th Action selection: 6/DOWN (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [281 211  86  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0914 0.0915 0.089  0.0906 0.0926 0.0906 0.0924 0.0928 0.0912 0.0899\n",
            " 0.088 ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09141172 0.0914952  0.08896669 0.0905853  0.09263498 0.09064145\n",
            " 0.09240576 0.09276314 0.09119961 0.08990869 0.0879875 ], argmax=7\n",
            "   \u001b[33m|->> #1/t=18-th Action selection: 9/SCALE DOWN (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [282 212  83  72]\n",
            "         |->> Action Probabilities (Rounded): [0.093  0.0908 0.0897 0.0902 0.0935 0.0906 0.0903 0.0928 0.0909 0.0907\n",
            " 0.0876], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.09298433 0.09081835 0.0896859  0.09023235 0.09348419 0.09061027\n",
            " 0.09025485 0.09280166 0.09085847 0.09067987 0.08758976], argmax=4\n",
            "|->> Revisiting bbox: [282 212  83  72]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [281, 209,  86,  75] -> [282, 212,  83,  72] (Target was [276, 221,  89,  68])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.041) for DOWN:bbox transition: [281, 209,  86,  75] -> [281, 211,  86,  75] w/ P(a|s)=0.0924057587981224 and iou=0.7753479125248509 and reward=0.04136733000057902 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for SCALE DOWN:bbox transition: [281, 211,  86,  75] -> [282, 212,  83,  72] w/ P(a|s)=0.09067986905574799 and iou=0.7690836887777615 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.09851903 2.40042   ]\n",
            "\u001b[92m>> Total frame loss: 2.498939037322998\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 73 with src: [282, 212,  83,  72] and target: [282, 206,  82,  70]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0076.jpg\n",
            "|->> Beginning tracking for bbox:[282 212  83  72]\n",
            "   \u001b[33m|->> #0/t=19-th Action selection: 0/LEFT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [280 212  83  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0922 0.0912 0.0888 0.0926 0.0915 0.092  0.0928 0.0929 0.0916 0.0855\n",
            " 0.0889], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09221496 0.09119372 0.08878245 0.09259171 0.09154031 0.09203749\n",
            " 0.09275026 0.09285631 0.09163647 0.08545194 0.08894434], argmax=7\n",
            "|->> Revisiting bbox: [282 212  83  72]. ACtion 2 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [282, 212,  83,  72] -> [280, 212,  83,  72] (Target was [282, 206,  82,  70])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for LEFT:bbox transition: [282, 212,  83,  72] -> [280, 212,  83,  72] w/ P(a|s)=0.09221496433019638 and iou=0.7936313533374157 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [2.383633]\n",
            "\u001b[92m>> Total frame loss: 2.3836328983306885\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 74 with src: [280, 212,  83,  72] and target: [265, 181,  91,  69]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0077.jpg\n",
            "|->> Beginning tracking for bbox:[280 212  83  72]\n",
            "|->> Revisiting bbox: [280 212  83  72]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=20-th Action selection: 8/STOP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [280 212  83  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0843 0.0909 0.0953 0.0925 0.0924 0.0926 0.0922 0.0946 0.0919 0.0857\n",
            " 0.0877], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08432704 0.09088546 0.0953087  0.09253697 0.09236405 0.09257165\n",
            " 0.09215501 0.09458453 0.09187937 0.08571655 0.08767069], argmax=2\n",
            "         |->> Hit a STOP on the 20-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [280, 212,  83,  72] -> [280, 212,  83,  72] (Target was [265, 181,  91,  69])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [280, 212,  83,  72] -> [280, 212,  83,  72] w/ P(a|s)=0.09187936782836914 and iou=0.30831643002028397 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.3872788]\n",
            "\u001b[31m>> Total frame loss: -2.3872787952423096\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 75 with src: [280, 212,  83,  72] and target: [242, 172,  87,  67]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0078.jpg\n",
            "|->> Beginning tracking for bbox:[280 212  83  72]\n",
            "|->> Revisiting bbox: [280 212  83  72]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=20-th Action selection: 8/STOP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [280 212  83  72]\n",
            "         |->> Action Probabilities (Rounded): [0.092  0.0907 0.0877 0.0916 0.0916 0.0917 0.0939 0.0941 0.0919 0.0855\n",
            " 0.0893], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09203988 0.09065529 0.08769076 0.09155361 0.0916241  0.09166116\n",
            " 0.09392335 0.09411936 0.09187215 0.08552848 0.08933187], argmax=7\n",
            "         |->> Hit a STOP on the 20-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [280, 212,  83,  72] -> [280, 212,  83,  72] (Target was [242, 172,  87,  67])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [280, 212,  83,  72] -> [280, 212,  83,  72] w/ P(a|s)=0.09187214821577072 and iou=0.12621637092157986 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.3873575]\n",
            "\u001b[31m>> Total frame loss: -2.387357473373413\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 76 with src: [280, 212,  83,  72] and target: [216, 168,  87,  67]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0079.jpg\n",
            "|->> Beginning tracking for bbox:[280 212  83  72]\n",
            "   \u001b[33m|->> #0/t=20-th Action selection: 10/SCALE UP (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [278 210  85  74]\n",
            "         |->> Action Probabilities (Rounded): [0.0871 0.0904 0.0911 0.0919 0.0915 0.0926 0.0928 0.0943 0.0936 0.0848\n",
            " 0.0901], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08712744 0.09039202 0.09107543 0.09187052 0.09146826 0.09260523\n",
            " 0.09275915 0.09429498 0.09356869 0.0847711  0.09006725], argmax=7\n",
            "   \u001b[33m|->> #1/t=21-th Action selection: 7/2X DOWN (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [278 214  85  74]\n",
            "         |->> Action Probabilities (Rounded): [0.0898 0.0901 0.0876 0.0939 0.091  0.0938 0.0926 0.0951 0.0941 0.0865\n",
            " 0.0856], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.0898442  0.09014332 0.08757034 0.09385936 0.09099508 0.09377604\n",
            " 0.09261013 0.09505648 0.09408519 0.08647089 0.08558898], argmax=7\n",
            "|->> Revisiting bbox: [278 214  85  74]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [280, 212,  83,  72] -> [278, 214,  85,  74] (Target was [216, 168,  87,  67])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.007) for SCALE UP:bbox transition: [280, 212,  83,  72] -> [278, 210,  85,  74] w/ P(a|s)=0.09006725251674652 and iou=0.05437619627631808 and reward=0.0074623970567366665 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for 2X DOWN:bbox transition: [278, 210,  85,  74] -> [278, 214,  85,  74] w/ P(a|s)=0.09505648165941238 and iou=0.045282042435742624 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.01796347 -2.3532841 ]\n",
            "\u001b[31m>> Total frame loss: -2.3353207111358643\u001b[0m\n",
            "Final bounding box: [278 214  85  74] reached in 22 timesteps (originating from [284 212  87  76]). Target was [216 168  87  67]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 77 in t=22 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[31m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 9.074036598205566\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 3.245060920715332\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/BlurCar3\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0070.jpg\n",
            "Starting bounding box=adnet_datasets/OTB/BlurCar3/img/0080.jpg for adnet_datasets/OTB/BlurCar3's frames (index: 0)\n",
            "src:adnet_datasets/OTB/BlurCar3/img/0070.jpg\n",
            "target:adnet_datasets/OTB/BlurCar3/img/0080.jpg.\n",
            "\u001b[34m>> Attempting to reach frame 68 with src: [284, 231,  80,  75] and target: [261, 245,  90,  72]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0071.jpg\n",
            "|->> Beginning tracking for bbox:[284 231  80  75]\n",
            "|->> Revisiting bbox: [284 231  80  75]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 8/STOP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [284 231  80  75]\n",
            "         |->> Action Probabilities (Rounded): [0.091  0.0907 0.0909 0.091  0.0908 0.0909 0.0909 0.0909 0.0909 0.0911\n",
            " 0.091 ], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.09098122 0.09068099 0.09086778 0.09096088 0.0907502  0.09090363\n",
            " 0.09092449 0.09089739 0.09088396 0.09110914 0.09104033], argmax=9\n",
            "         |->> Hit a STOP on the 1-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [284, 231,  80,  75] -> [284, 231,  80,  75] (Target was [261, 245,  90,  72])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [284, 231,  80,  75] -> [284, 231,  80,  75] w/ P(a|s)=0.09088395535945892 and iou=0.48695341355891814 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.398172]\n",
            "\u001b[31m>> Total frame loss: -2.398171901702881\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 69 with src: [284, 231,  80,  75] and target: [252, 242,  91,  71]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0072.jpg\n",
            "|->> Beginning tracking for bbox:[284 231  80  75]\n",
            "|->> Revisiting bbox: [284 231  80  75]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 8/STOP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [284 231  80  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0906 0.0904 0.0916 0.0905 0.0905 0.0907 0.0913 0.0913 0.0921 0.0899\n",
            " 0.0912], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09055241 0.09035991 0.0916147  0.09045213 0.09046343 0.09074105\n",
            " 0.09133138 0.09130578 0.09208073 0.08988515 0.09121329], argmax=8\n",
            "         |->> Hit a STOP on the 1-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [284, 231,  80,  75] -> [284, 231,  80,  75] (Target was [252, 242,  91,  71])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [284, 231,  80,  75] -> [284, 231,  80,  75] w/ P(a|s)=0.0920807272195816 and iou=0.43477259643062754 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.3850896]\n",
            "\u001b[31m>> Total frame loss: -2.385089635848999\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 70 with src: [284, 231,  80,  75] and target: [261, 227,  92,  72]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0073.jpg\n",
            "|->> Beginning tracking for bbox:[284 231  80  75]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 2/RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [286 231  80  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0898 0.0903 0.0911 0.0913 0.09   0.0913 0.091  0.0922 0.0934 0.0885\n",
            " 0.0911], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08976214 0.09034027 0.09111039 0.09127595 0.08999486 0.09132668\n",
            " 0.09098896 0.09218691 0.0934163  0.08851212 0.09108543], argmax=8\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 5/2X UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [286 227  80  75]\n",
            "         |->> Action Probabilities (Rounded): [0.096  0.0905 0.0828 0.0932 0.0895 0.093  0.0911 0.0929 0.0937 0.0873\n",
            " 0.09  ], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09599703 0.09048741 0.08283921 0.0932332  0.08954305 0.09295914\n",
            " 0.09108338 0.09291988 0.0936888  0.08728558 0.08996337], argmax=0\n",
            "   \u001b[33m|->> #2/t=3-th Action selection: 2/RIGHT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [288 227  80  75]\n",
            "         |->> Action Probabilities (Rounded): [0.087  0.0918 0.0934 0.0914 0.0898 0.0911 0.0914 0.093  0.0938 0.0873\n",
            " 0.0898], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08703709 0.09184634 0.09344265 0.09144877 0.08980326 0.09109792\n",
            " 0.09135893 0.0930426  0.0937955  0.08729989 0.08982704], argmax=8\n",
            "   \u001b[33m|->> #3/t=4-th Action selection: 7/2X DOWN (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [288 231  80  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0983 0.091  0.0823 0.0931 0.0895 0.0924 0.0922 0.0934 0.0935 0.0858\n",
            " 0.0884], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09832574 0.09098604 0.08228514 0.09307967 0.08950825 0.09244646\n",
            " 0.09218863 0.09343234 0.09354562 0.08579054 0.08841155], argmax=0\n",
            "   \u001b[33m|->> #4/t=5-th Action selection: 3/2X RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [292 231  80  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0874 0.0922 0.0941 0.0908 0.0907 0.0918 0.0915 0.0925 0.093  0.0869\n",
            " 0.0892], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08740612 0.09222114 0.09412534 0.09076799 0.09066607 0.09175451\n",
            " 0.09149836 0.09245458 0.09304184 0.08685149 0.08921262], argmax=2\n",
            "   \u001b[33m|->> #5/t=6-th Action selection: 6/DOWN (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [292 233  80  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0946 0.0925 0.0876 0.0902 0.091  0.092  0.0919 0.0927 0.0918 0.087\n",
            " 0.0886], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09462975 0.09253275 0.08759759 0.09023777 0.0910274  0.09199831\n",
            " 0.09186694 0.09270762 0.0918297  0.08697878 0.08859333], argmax=0\n",
            "   \u001b[33m|->> #6/t=7-th Action selection: 7/2X DOWN (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [292 237  80  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0914 0.0925 0.0911 0.0909 0.0928 0.0921 0.0896 0.0931 0.0909 0.0868\n",
            " 0.0888], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09141788 0.09247679 0.09113272 0.09086091 0.09279318 0.09207544\n",
            " 0.08958079 0.09308545 0.09091235 0.08682983 0.08883463], argmax=7\n",
            "   \u001b[33m|->> #7/t=8-th Action selection: 3/2X RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [296 237  80  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0938 0.0923 0.0907 0.0906 0.0909 0.092  0.0921 0.091  0.0901 0.0876\n",
            " 0.0889], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.0938423  0.09228512 0.0906653  0.09061147 0.09090326 0.09195138\n",
            " 0.09212198 0.091031   0.09010184 0.08758378 0.08890254], argmax=0\n",
            "|->> Revisiting bbox: [296 237  80  75]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [284, 231,  80,  75] -> [296, 237,  80,  75] (Target was [261, 227,  92,  72])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.027) for RIGHT:bbox transition: [284, 231,  80,  75] -> [286, 231,  80,  75] w/ P(a|s)=0.09111039340496063 and iou=0.564700049578582 and reward=-0.026827938318543576 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.054) for 2X UP:bbox transition: [286, 231,  80,  75] -> [286, 227,  80,  75] w/ P(a|s)=0.09295913577079773 and iou=0.6184615384615385 and reward=0.05376148888295651 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.029) for RIGHT:bbox transition: [286, 227,  80,  75] -> [288, 227,  80,  75] w/ P(a|s)=0.0934426486492157 and iou=0.5891238670694864 and reward=-0.029337671392052123 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-0.05) for 2X DOWN:bbox transition: [288, 227,  80,  75] -> [288, 231,  80,  75] w/ P(a|s)=0.09343233704566956 and iou=0.5387615797172112 and reward=-0.050362287352275215 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (-0.049) for 2X RIGHT:bbox transition: [288, 231,  80,  75] -> [292, 231,  80,  75] w/ P(a|s)=0.0907679870724678 and iou=0.48938178386031145 and reward=-0.04937979585689972 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (-0.021) for DOWN:bbox transition: [292, 231,  80,  75] -> [292, 233,  80,  75] w/ P(a|s)=0.09186694025993347 and iou=0.46824842986741105 and reward=-0.021133353992900394 and discount=1.0\n",
            "   |->> t=7 Diff-Reward (-0.041) for 2X DOWN:bbox transition: [292, 233,  80,  75] -> [292, 237,  80,  75] w/ P(a|s)=0.09308545291423798 and iou=0.42773128251526804 and reward=-0.04051714735214301 and discount=1.0\n",
            "   |->> t=8 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [292, 237,  80,  75] -> [296, 237,  80,  75] w/ P(a|s)=0.09061147272586823 and iou=0.38877887788778875 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.06427124  0.12771554 -0.06954223 -0.1193847  -0.11848428 -0.05045407\n",
            " -0.09619732 -2.4011745 ]\n",
            "\u001b[31m>> Total frame loss: -2.791792869567871\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 71 with src: [296, 237,  80,  75] and target: [271, 222,  91,  70]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0074.jpg\n",
            "|->> Beginning tracking for bbox:[296 237  80  75]\n",
            "   \u001b[33m|->> #0/t=9-th Action selection: 10/SCALE UP (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [294 235  82  77]\n",
            "         |->> Action Probabilities (Rounded): [0.0929 0.0928 0.0889 0.0895 0.0935 0.0929 0.0923 0.0913 0.0883 0.0882\n",
            " 0.0894], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0928943  0.09276871 0.088931   0.08948292 0.09352609 0.09288161\n",
            " 0.0923057  0.0913429  0.08827042 0.088234   0.08936234], argmax=4\n",
            "   \u001b[33m|->> #1/t=10-th Action selection: 1/2X LEFT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [290 235  82  77]\n",
            "         |->> Action Probabilities (Rounded): [0.0934 0.0929 0.0878 0.0894 0.0933 0.0933 0.093  0.0924 0.0894 0.0912\n",
            " 0.0839], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09339911 0.09291815 0.08775172 0.08944971 0.09334163 0.09326715\n",
            " 0.09303762 0.09236914 0.08937898 0.09116732 0.08391944], argmax=0\n",
            "   \u001b[33m|->> #2/t=11-th Action selection: 6/DOWN (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [290 237  82  77]\n",
            "         |->> Action Probabilities (Rounded): [0.0905 0.0897 0.0883 0.0904 0.0929 0.093  0.0928 0.0922 0.0931 0.0901\n",
            " 0.0869], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09053715 0.08969145 0.08831693 0.09037942 0.09289006 0.09302089\n",
            " 0.09277143 0.09223942 0.09310809 0.09010725 0.08693787], argmax=8\n",
            "   \u001b[33m|->> #3/t=12-th Action selection: 5/2X UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [290 233  82  77]\n",
            "         |->> Action Probabilities (Rounded): [0.091  0.0898 0.0897 0.0903 0.0939 0.0924 0.0906 0.0917 0.0923 0.0924\n",
            " 0.086 ], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.09102211 0.08980709 0.08971611 0.09028368 0.09391891 0.09238229\n",
            " 0.09056241 0.09165702 0.09226959 0.09235206 0.08602873], argmax=4\n",
            "   \u001b[33m|->> #4/t=13-th Action selection: 9/SCALE DOWN (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [291 234  79  74]\n",
            "         |->> Action Probabilities (Rounded): [0.091  0.0895 0.0897 0.0901 0.0924 0.0912 0.0933 0.0919 0.092  0.0915\n",
            " 0.0873], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09103072 0.08951211 0.08968507 0.09006745 0.09243121 0.0912374\n",
            " 0.09325068 0.0918936  0.09199535 0.09154874 0.08734754], argmax=6\n",
            "   \u001b[33m|->> #5/t=14-th Action selection: 7/2X DOWN (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [291 238  79  74]\n",
            "         |->> Action Probabilities (Rounded): [0.0899 0.0902 0.0888 0.0921 0.0935 0.0919 0.0923 0.0923 0.0922 0.0871\n",
            " 0.0895], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.08990381 0.09022551 0.08879769 0.0921484  0.09351669 0.09190174\n",
            " 0.09226249 0.09232851 0.09224705 0.08712111 0.08954706], argmax=4\n",
            "   \u001b[33m|->> #6/t=15-th Action selection: 1/2X LEFT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [287 238  79  74]\n",
            "         |->> Action Probabilities (Rounded): [0.0908 0.0895 0.0894 0.0917 0.0928 0.0912 0.0933 0.0913 0.0918 0.089\n",
            " 0.0893], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09076159 0.08952363 0.08940508 0.09166738 0.09278196 0.09123353\n",
            " 0.09326902 0.09126037 0.09184901 0.0889786  0.08926979], argmax=6\n",
            "   \u001b[33m|->> #7/t=16-th Action selection: 1/2X LEFT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [283 238  79  74]\n",
            "         |->> Action Probabilities (Rounded): [0.09   0.0885 0.0892 0.0923 0.0932 0.0913 0.0933 0.0909 0.0924 0.0892\n",
            " 0.0895], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09004296 0.08851347 0.08924989 0.0923471  0.09315962 0.09130212\n",
            " 0.09330132 0.09091932 0.09243568 0.08923344 0.08949509], argmax=6\n",
            "   \u001b[33m|->> #8/t=17-th Action selection: 1/2X LEFT (P(a|s) = 0.0860000029206276)\u001b[0m\n",
            "      |->> Bounding box moves to: [279 238  79  74]\n",
            "         |->> Action Probabilities (Rounded): [0.0889 0.086  0.0902 0.092  0.0925 0.0914 0.0931 0.0918 0.0933 0.0907\n",
            " 0.0902], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08885697 0.08602887 0.0902207  0.09197582 0.09249277 0.09136688\n",
            " 0.09314438 0.09180202 0.09325241 0.0906885  0.0901707 ], argmax=8\n",
            "   \u001b[33m|->> #9/t=18-th Action selection: 5/2X UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [279 234  79  74]\n",
            "         |->> Action Probabilities (Rounded): [0.088  0.0835 0.0911 0.0923 0.0933 0.0915 0.0941 0.0937 0.0926 0.0898\n",
            " 0.0899], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08799642 0.08350532 0.09114952 0.0923204  0.09333564 0.09150343\n",
            " 0.09410004 0.09374823 0.09261204 0.08982303 0.08990591], argmax=6\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [296, 237,  80,  75] -> [279, 234,  79,  74] (Target was [271, 222,  91,  70])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.025) for SCALE UP:bbox transition: [296, 237,  80,  75] -> [294, 235,  82,  77] w/ P(a|s)=0.08936233818531036 and iou=0.44005449591280654 and reward=0.02472268813248618 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.038) for 2X LEFT:bbox transition: [294, 235,  82,  77] -> [290, 235,  82,  77] w/ P(a|s)=0.09291815012693405 and iou=0.4783216783216783 and reward=0.03826718240887178 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.024) for DOWN:bbox transition: [290, 235,  82,  77] -> [290, 237,  82,  77] w/ P(a|s)=0.09277142584323883 and iou=0.45392022008253097 and reward=-0.024401458239147356 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.05) for 2X UP:bbox transition: [290, 237,  82,  77] -> [290, 233,  82,  77] w/ P(a|s)=0.0923822894692421 and iou=0.5035561877667141 and reward=0.0496359676841831 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (0.005) for SCALE DOWN:bbox transition: [290, 233,  82,  77] -> [291, 234,  79,  74] w/ P(a|s)=0.09154874086380005 and iou=0.5085206223758952 and reward=0.0049644346091811675 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (-0.051) for 2X DOWN:bbox transition: [291, 234,  79,  74] -> [291, 238,  79,  74] w/ P(a|s)=0.0923285111784935 and iou=0.4574087329992842 and reward=-0.05111188937661104 and discount=1.0\n",
            "   |->> t=7 Diff-Reward (0.039) for 2X LEFT:bbox transition: [291, 238,  79,  74] -> [287, 238,  79,  74] w/ P(a|s)=0.08952362835407257 and iou=0.49595885378398236 and reward=0.03855012078469816 and discount=1.0\n",
            "   |->> t=8 Diff-Reward (0.041) for 2X LEFT:bbox transition: [287, 238,  79,  74] -> [283, 238,  79,  74] w/ P(a|s)=0.08851347118616104 and iou=0.5366037735849056 and reward=0.040644919800923274 and discount=1.0\n",
            "   |->> t=9 Diff-Reward (0.0) for 2X LEFT:bbox transition: [283, 238,  79,  74] -> [279, 238,  79,  74] w/ P(a|s)=0.08602887392044067 and iou=0.5366037735849056 and reward=0.0 and discount=1.0\n",
            "   |->> t=10 Diff-Reward (-1.0) for 2X UP:bbox transition: [279, 238,  79,  74] -> [279, 234,  79,  74] w/ P(a|s)=0.09150343388319016 and iou=0.6002095886822112 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.05970668  0.09092421 -0.05801731  0.11822394  0.01186939 -0.12176909\n",
            "  0.09303118  0.0985477   0.         -2.3913789 ]\n",
            "\u001b[31m>> Total frame loss: -2.0988621711730957\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 72 with src: [279, 234,  79,  74] and target: [276, 221,  89,  68]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0075.jpg\n",
            "|->> Beginning tracking for bbox:[279 234  79  74]\n",
            "   \u001b[33m|->> #0/t=19-th Action selection: 7/2X DOWN (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [279 238  79  74]\n",
            "         |->> Action Probabilities (Rounded): [0.0879 0.0846 0.0919 0.0928 0.0926 0.0905 0.0952 0.0929 0.0919 0.0899\n",
            " 0.0899], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.0878928  0.08460832 0.0919037  0.09283686 0.09257346 0.09046346\n",
            " 0.09522763 0.09289052 0.09187997 0.08986565 0.08985759], argmax=6\n",
            "   \u001b[33m|->> #1/t=20-th Action selection: 3/2X RIGHT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [283 238  79  74]\n",
            "         |->> Action Probabilities (Rounded): [0.0873 0.0852 0.0924 0.0927 0.0928 0.0897 0.0946 0.0917 0.0926 0.0891\n",
            " 0.0919], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08728903 0.08523747 0.09243026 0.0927265  0.09275476 0.0896935\n",
            " 0.09458593 0.09165273 0.09255779 0.08914414 0.0919278 ], argmax=6\n",
            "   \u001b[33m|->> #2/t=21-th Action selection: 0/LEFT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [281 238  79  74]\n",
            "         |->> Action Probabilities (Rounded): [0.0895 0.0876 0.0903 0.0904 0.0926 0.0902 0.094  0.0916 0.0923 0.0898\n",
            " 0.0918], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08947644 0.08759499 0.09025471 0.09040031 0.09256736 0.09018148\n",
            " 0.09399591 0.09160236 0.09232955 0.08981528 0.09178163], argmax=6\n",
            "   \u001b[33m|->> #3/t=22-th Action selection: 6/DOWN (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [281 240  79  74]\n",
            "         |->> Action Probabilities (Rounded): [0.082  0.087  0.0966 0.0926 0.0922 0.0915 0.0934 0.0929 0.0927 0.088\n",
            " 0.0911], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08198749 0.08695626 0.09660483 0.09262191 0.09215668 0.09151098\n",
            " 0.0934277  0.09288231 0.09270207 0.08803407 0.09111565], argmax=2\n",
            "   \u001b[33m|->> #4/t=23-th Action selection: 1/2X LEFT (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [277 240  79  74]\n",
            "         |->> Action Probabilities (Rounded): [0.0906 0.0873 0.0884 0.0925 0.0934 0.0921 0.0913 0.0921 0.0918 0.0892\n",
            " 0.0911], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.09064756 0.08734762 0.08841716 0.09249934 0.09340581 0.09210639\n",
            " 0.09133418 0.09213619 0.09184262 0.08915401 0.09110909], argmax=4\n",
            "   \u001b[33m|->> #5/t=24-th Action selection: 6/DOWN (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [277 242  79  74]\n",
            "         |->> Action Probabilities (Rounded): [0.0864 0.0854 0.0934 0.0917 0.092  0.0923 0.0932 0.0928 0.0918 0.0905\n",
            " 0.0907], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08640641 0.08535217 0.09340612 0.09167816 0.09196395 0.09230594\n",
            " 0.09317613 0.09276796 0.09177918 0.09051173 0.09065216], argmax=2\n",
            "   \u001b[33m|->> #6/t=25-th Action selection: 2/RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [279 242  79  74]\n",
            "         |->> Action Probabilities (Rounded): [0.0901 0.0861 0.0905 0.0917 0.0944 0.0919 0.0907 0.0939 0.091  0.09\n",
            " 0.0898], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.09007508 0.08606013 0.09051535 0.09167367 0.09435323 0.09192946\n",
            " 0.0906901  0.09392831 0.09097052 0.0899736  0.08983056], argmax=4\n",
            "   \u001b[33m|->> #7/t=26-th Action selection: 2/RIGHT (P(a|s) = 0.08399999886751175)\u001b[0m\n",
            "      |->> Bounding box moves to: [281 242  79  74]\n",
            "         |->> Action Probabilities (Rounded): [0.0956 0.0867 0.0836 0.0936 0.0915 0.0932 0.0937 0.0936 0.091  0.0886\n",
            " 0.089 ], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.0955605  0.08670906 0.08364839 0.09356756 0.09150158 0.09320839\n",
            " 0.09368695 0.0935975  0.0909555  0.08855001 0.0890146 ], argmax=0\n",
            "|->> Revisiting bbox: [281 240  79  74]. ACtion 4 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [279, 234,  79,  74] -> [281, 242,  79,  74] (Target was [276, 221,  89,  68])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.063) for 2X DOWN:bbox transition: [279, 234,  79,  74] -> [279, 238,  79,  74] w/ P(a|s)=0.09289052337408066 and iou=0.5120091498284407 and reward=-0.0632589555601466 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for 2X RIGHT:bbox transition: [279, 238,  79,  74] -> [283, 238,  79,  74] w/ P(a|s)=0.09272649884223938 and iou=0.5120091498284407 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.0) for LEFT:bbox transition: [283, 238,  79,  74] -> [281, 238,  79,  74] w/ P(a|s)=0.08947644382715225 and iou=0.5120091498284407 and reward=0.0 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-0.03) for DOWN:bbox transition: [281, 238,  79,  74] -> [281, 240,  79,  74] w/ P(a|s)=0.09342769533395767 and iou=0.4822474149744612 and reward=-0.029761734853979482 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (0.0) for 2X LEFT:bbox transition: [281, 240,  79,  74] -> [277, 240,  79,  74] w/ P(a|s)=0.0873476192355156 and iou=0.4822474149744612 and reward=0.0 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (-0.029) for DOWN:bbox transition: [277, 240,  79,  74] -> [277, 242,  79,  74] w/ P(a|s)=0.09317613393068314 and iou=0.4536346976175932 and reward=-0.028612717356868045 and discount=1.0\n",
            "   |->> t=7 Diff-Reward (0.0) for RIGHT:bbox transition: [277, 242,  79,  74] -> [279, 242,  79,  74] w/ P(a|s)=0.09051535278558731 and iou=0.4536346976175932 and reward=0.0 and discount=1.0\n",
            "   |->> t=8 Diff-Reward (-1.0) for RIGHT:bbox transition: [279, 242,  79,  74] -> [281, 242,  79,  74] w/ P(a|s)=0.08364839106798172 and iou=0.4536346976175932 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.15032439  0.          0.         -0.07055221  0.         -0.06790552\n",
            "  0.         -2.481133  ]\n",
            "\u001b[31m>> Total frame loss: -2.7699148654937744\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 73 with src: [281, 242,  79,  74] and target: [282, 206,  82,  70]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0076.jpg\n",
            "|->> Beginning tracking for bbox:[281 242  79  74]\n",
            "   \u001b[33m|->> #0/t=27-th Action selection: 2/RIGHT (P(a|s) = 0.08399999886751175)\u001b[0m\n",
            "      |->> Bounding box moves to: [283 242  79  74]\n",
            "         |->> Action Probabilities (Rounded): [0.0947 0.0891 0.0837 0.0913 0.0935 0.0937 0.0925 0.0935 0.0911 0.0881\n",
            " 0.0888], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09467133 0.0891076  0.08368048 0.09128422 0.09352274 0.09369237\n",
            " 0.09251936 0.09353465 0.09110389 0.08807701 0.08880632], argmax=0\n",
            "   \u001b[33m|->> #1/t=28-th Action selection: 3/2X RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [287 242  79  74]\n",
            "         |->> Action Probabilities (Rounded): [0.0971 0.0897 0.0826 0.0917 0.092  0.0942 0.0938 0.0935 0.0909 0.0872\n",
            " 0.0873], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09707288 0.08974074 0.08257665 0.0916642  0.09198911 0.09424081\n",
            " 0.09384437 0.09349768 0.09088486 0.08722292 0.08726578], argmax=0\n",
            "   \u001b[33m|->> #2/t=29-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [288 243  76  71]\n",
            "         |->> Action Probabilities (Rounded): [0.0912 0.0912 0.0891 0.088  0.0937 0.0948 0.0926 0.094  0.0897 0.0875\n",
            " 0.0882], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.09117471 0.091162   0.08911612 0.08795013 0.09374312 0.09476545\n",
            " 0.09257848 0.0940149  0.08972992 0.08752093 0.08824422], argmax=5\n",
            "   \u001b[33m|->> #3/t=30-th Action selection: 1/2X LEFT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [284 243  76  71]\n",
            "         |->> Action Probabilities (Rounded): [0.0945 0.0897 0.0866 0.0907 0.0924 0.0952 0.0943 0.0947 0.09   0.0828\n",
            " 0.089 ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.09453117 0.08969848 0.08662324 0.09068366 0.09240396 0.09518494\n",
            " 0.09427623 0.09469096 0.09002663 0.08283772 0.08904307], argmax=5\n",
            "|->> Revisiting bbox: [284 243  76  71]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [281, 242,  79,  74] -> [284, 243,  76,  71] (Target was [282, 206,  82,  70])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.005) for RIGHT:bbox transition: [281, 242,  79,  74] -> [283, 242,  79,  74] w/ P(a|s)=0.08368048071861267 and iou=0.30179775280898874 and reward=0.0049542336686260735 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.01) for 2X RIGHT:bbox transition: [283, 242,  79,  74] -> [287, 242,  79,  74] w/ P(a|s)=0.09166420251131058 and iou=0.29192685102586974 and reward=-0.009870901783119002 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.001) for SCALE DOWN:bbox transition: [287, 242,  79,  74] -> [288, 243,  76,  71] w/ P(a|s)=0.08752092719078064 and iou=0.2906815020862309 and reward=-0.0012453489396388462 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [288, 243,  76,  71] -> [284, 243,  76,  71] w/ P(a|s)=0.08969847857952118 and iou=0.2906815020862309 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.01229021 -0.02358774 -0.00303352 -2.4113014 ]\n",
            "\u001b[31m>> Total frame loss: -2.4256324768066406\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 74 with src: [284, 243,  76,  71] and target: [265, 181,  91,  69]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0077.jpg\n",
            "|->> Beginning tracking for bbox:[284 243  76  71]\n",
            "   \u001b[33m|->> #0/t=31-th Action selection: 1/2X LEFT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [280 243  76  71]\n",
            "         |->> Action Probabilities (Rounded): [0.0919 0.0885 0.09   0.0908 0.093  0.0944 0.0945 0.0945 0.0905 0.0838\n",
            " 0.0882], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09187855 0.08851139 0.09002762 0.09080266 0.09297516 0.09436934\n",
            " 0.09449062 0.09446657 0.09053702 0.08376172 0.08817932], argmax=6\n",
            "   \u001b[33m|->> #1/t=32-th Action selection: 4/UP (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [280 241  76  71]\n",
            "         |->> Action Probabilities (Rounded): [0.0912 0.0877 0.0886 0.0899 0.0936 0.0938 0.095  0.0945 0.0904 0.0861\n",
            " 0.0892], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09123941 0.08771455 0.08863065 0.08993146 0.09355492 0.0937672\n",
            " 0.09496947 0.09445941 0.09041368 0.08608861 0.08923066], argmax=6\n",
            "   \u001b[33m|->> #2/t=33-th Action selection: 5/2X UP (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [280 237  76  71]\n",
            "         |->> Action Probabilities (Rounded): [0.0916 0.0874 0.09   0.0898 0.0911 0.0937 0.0956 0.0946 0.0914 0.0858\n",
            " 0.0891], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09164491 0.08738101 0.08995366 0.08981381 0.09107064 0.09366656\n",
            " 0.0956105  0.09457638 0.09136996 0.08577541 0.08913714], argmax=6\n",
            "   \u001b[33m|->> #3/t=34-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [281 238  73  68]\n",
            "         |->> Action Probabilities (Rounded): [0.0919 0.089  0.0889 0.0906 0.0919 0.0921 0.0943 0.0946 0.0907 0.0867\n",
            " 0.0891], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09189927 0.08899837 0.08890186 0.09061137 0.09191102 0.09214766\n",
            " 0.09428931 0.09462803 0.09074462 0.08674561 0.08912293], argmax=7\n",
            "   \u001b[33m|->> #4/t=35-th Action selection: 4/UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [281 236  73  68]\n",
            "         |->> Action Probabilities (Rounded): [0.0902 0.0887 0.09   0.0914 0.0916 0.0922 0.0965 0.0946 0.0914 0.0821\n",
            " 0.0913], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09024789 0.08865528 0.08998245 0.09141877 0.09161179 0.09222192\n",
            " 0.09650418 0.09463532 0.09140337 0.08205808 0.09126098], argmax=6\n",
            "|->> Revisiting bbox: [281 236  73  68]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [284, 243,  76,  71] -> [281, 236,  73,  68] (Target was [265, 181,  91,  69])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.003) for 2X LEFT:bbox transition: [284, 243,  76,  71] -> [280, 243,  76,  71] w/ P(a|s)=0.0885113924741745 and iou=0.047742977654132636 and reward=0.0026261573157564805 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.014) for UP:bbox transition: [280, 243,  76,  71] -> [280, 241,  76,  71] w/ P(a|s)=0.09355492144823074 and iou=0.06223273587480666 and reward=0.014489758220674026 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.03) for 2X UP:bbox transition: [280, 241,  76,  71] -> [280, 237,  76,  71] w/ P(a|s)=0.09366656094789505 and iou=0.09244876953307757 and reward=0.030216033658270906 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-0.008) for SCALE DOWN:bbox transition: [280, 237,  76,  71] -> [281, 238,  73,  68] w/ P(a|s)=0.08674561232328415 and iou=0.08449889071090962 and reward=-0.007949878822167952 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (-1.0) for UP:bbox transition: [281, 238,  73,  68] -> [281, 236,  73,  68] w/ P(a|s)=0.09161178767681122 and iou=0.09999021622150475 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.00636744  0.03432923  0.07155199 -0.01943567 -2.3901954 ]\n",
            "\u001b[31m>> Total frame loss: -2.297382354736328\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 75 with src: [281, 236,  73,  68] and target: [242, 172,  87,  67]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0078.jpg\n",
            "|->> Beginning tracking for bbox:[281 236  73  68]\n",
            "   \u001b[33m|->> #0/t=36-th Action selection: 3/2X RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [285 236  73  68]\n",
            "         |->> Action Probabilities (Rounded): [0.0913 0.089  0.0906 0.0917 0.0897 0.0917 0.0948 0.0946 0.0922 0.0846\n",
            " 0.0897], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09134845 0.08898637 0.0905697  0.09172194 0.0897442  0.09172112\n",
            " 0.09480017 0.09464423 0.09218951 0.08458435 0.08968996], argmax=6\n",
            "   \u001b[33m|->> #1/t=37-th Action selection: 10/SCALE UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [283 234  75  70]\n",
            "         |->> Action Probabilities (Rounded): [0.0914 0.0895 0.089  0.0902 0.0915 0.0919 0.0937 0.094  0.0916 0.0861\n",
            " 0.091 ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09143063 0.08951112 0.08896519 0.09023213 0.09149766 0.09193935\n",
            " 0.09370085 0.09400772 0.09157885 0.0861045  0.09103207], argmax=7\n",
            "   \u001b[33m|->> #2/t=38-th Action selection: 5/2X UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [283 230  75  70]\n",
            "         |->> Action Probabilities (Rounded): [0.0899 0.0889 0.0881 0.0917 0.0918 0.0919 0.0947 0.0951 0.0922 0.0898\n",
            " 0.0859], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08993091 0.08893049 0.08808915 0.09168662 0.09179026 0.09192523\n",
            " 0.09466761 0.09505844 0.09221531 0.08983113 0.08587479], argmax=7\n",
            "   \u001b[33m|->> #3/t=39-th Action selection: 6/DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [283 232  75  70]\n",
            "         |->> Action Probabilities (Rounded): [0.089  0.0899 0.09   0.0921 0.0916 0.09   0.0945 0.0944 0.0926 0.0879\n",
            " 0.088 ], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08899444 0.08990658 0.09004652 0.0920965  0.09162463 0.09001739\n",
            " 0.09447562 0.09443992 0.0925641  0.08787045 0.0879639 ], argmax=6\n",
            "   \u001b[33m|->> #4/t=40-th Action selection: 3/2X RIGHT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [287 232  75  70]\n",
            "         |->> Action Probabilities (Rounded): [0.0896 0.09   0.0901 0.0929 0.0933 0.0904 0.0922 0.0932 0.091  0.0902\n",
            " 0.087 ], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.08955181 0.08998898 0.09013534 0.09293258 0.09328178 0.09038809\n",
            " 0.09224801 0.09322694 0.09104453 0.09020919 0.08699274], argmax=4\n",
            "   \u001b[33m|->> #5/t=41-th Action selection: 0/LEFT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [285 232  75  70]\n",
            "         |->> Action Probabilities (Rounded): [0.0918 0.0914 0.0897 0.0897 0.0917 0.0906 0.0934 0.0935 0.0907 0.0896\n",
            " 0.0879], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09179606 0.09139383 0.08973932 0.08966418 0.09169926 0.09059441\n",
            " 0.09335215 0.09353971 0.09068728 0.08963463 0.08789925], argmax=7\n",
            "   \u001b[33m|->> #6/t=42-th Action selection: 7/2X DOWN (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [285 236  75  70]\n",
            "         |->> Action Probabilities (Rounded): [0.0836 0.0922 0.0944 0.092  0.0924 0.0917 0.0924 0.0946 0.0916 0.0878\n",
            " 0.0872], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08355854 0.09218319 0.09443304 0.0920343  0.0923817  0.09171171\n",
            " 0.09244817 0.09464431 0.09158651 0.08780801 0.0872105 ], argmax=7\n",
            "   \u001b[33m|->> #7/t=43-th Action selection: 3/2X RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [289 236  75  70]\n",
            "         |->> Action Probabilities (Rounded): [0.0925 0.0912 0.0869 0.0917 0.0911 0.0917 0.0928 0.0927 0.091  0.0895\n",
            " 0.089 ], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09251641 0.09116784 0.08686249 0.09173771 0.09114177 0.09165398\n",
            " 0.09283302 0.09265155 0.09098984 0.08945343 0.08899192], argmax=6\n",
            "   \u001b[33m|->> #8/t=44-th Action selection: 10/SCALE UP (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [287 234  77  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0894 0.0914 0.0894 0.0891 0.0929 0.0929 0.0933 0.0927 0.091  0.0898\n",
            " 0.0881], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08938798 0.09144017 0.08939303 0.08910499 0.09291162 0.09285692\n",
            " 0.09331608 0.09267583 0.09104741 0.0898067  0.08805919], argmax=6\n",
            "   \u001b[33m|->> #9/t=45-th Action selection: 0/LEFT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [285 234  77  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0924 0.091  0.0862 0.0905 0.0928 0.093  0.0931 0.093  0.0915 0.0928\n",
            " 0.0836], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09242237 0.09100581 0.08621825 0.09045325 0.09284869 0.09295343\n",
            " 0.0931253  0.0930457  0.09152649 0.09277483 0.08362582], argmax=6\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [281, 236,  73,  68] -> [285, 234,  77,  72] (Target was [242, 172,  87,  67])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.001) for 2X RIGHT:bbox transition: [281, 236,  73,  68] -> [285, 236,  73,  68] w/ P(a|s)=0.09172193706035614 and iou=0.012381577713160116 and reward=-0.0011408187559919167 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.009) for SCALE UP:bbox transition: [285, 236,  73,  68] -> [283, 234,  75,  70] w/ P(a|s)=0.09103206545114517 and iou=0.021200110609272745 and reward=0.008818532896112629 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.018) for 2X UP:bbox transition: [283, 234,  75,  70] -> [283, 230,  75,  70] w/ P(a|s)=0.0919252336025238 and iou=0.038818565400843885 and reward=0.01761845479157114 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-0.009) for DOWN:bbox transition: [283, 230,  75,  70] -> [283, 232,  75,  70] w/ P(a|s)=0.09447561949491501 and iou=0.029933996467416565 and reward=-0.00888456893342732 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (-0.003) for 2X RIGHT:bbox transition: [283, 232,  75,  70] -> [287, 232,  75,  70] w/ P(a|s)=0.09293258190155029 and iou=0.02726008344923505 and reward=-0.0026739130181815153 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (0.001) for LEFT:bbox transition: [287, 232,  75,  70] -> [285, 232,  75,  70] w/ P(a|s)=0.09179606288671494 and iou=0.0285953022003528 and reward=0.0013352187511177505 and discount=1.0\n",
            "   |->> t=7 Diff-Reward (-0.017) for 2X DOWN:bbox transition: [285, 232,  75,  70] -> [285, 236,  75,  70] w/ P(a|s)=0.09464430809020996 and iou=0.012058098109070978 and reward=-0.016537204091281822 and discount=1.0\n",
            "   |->> t=8 Diff-Reward (-0.001) for 2X RIGHT:bbox transition: [285, 236,  75,  70] -> [289, 236,  75,  70] w/ P(a|s)=0.09173770993947983 and iou=0.010949904188338352 and reward=-0.001108193920732626 and discount=1.0\n",
            "   |->> t=9 Diff-Reward (0.008) for SCALE UP:bbox transition: [289, 236,  75,  70] -> [287, 234,  77,  72] w/ P(a|s)=0.0880591943860054 and iou=0.018812147272238646 and reward=0.007862243083900294 and discount=1.0\n",
            "   |->> t=10 Diff-Reward (-1.0) for LEFT:bbox transition: [287, 234,  77,  72] -> [285, 234,  77,  72] w/ P(a|s)=0.09242236614227295 and iou=0.019725634358468573 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.00272541  0.021134    0.04205137 -0.02096237 -0.0063529   0.00318875\n",
            " -0.0389886  -0.00264728  0.01910325 -2.3813863 ]\n",
            "\u001b[31m>> Total frame loss: -2.3675854206085205\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 76 with src: [285, 234,  77,  72] and target: [216, 168,  87,  67]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0079.jpg\n",
            "|->> Beginning tracking for bbox:[285 234  77  72]\n",
            "   \u001b[33m|->> #0/t=46-th Action selection: 7/2X DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [285 238  77  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0834 0.0906 0.0947 0.0927 0.093  0.0939 0.0932 0.0941 0.0919 0.0875\n",
            " 0.0851], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08339672 0.09055185 0.09468106 0.09270422 0.09298133 0.09385646\n",
            " 0.09321754 0.09409215 0.09186647 0.08751326 0.08513888], argmax=2\n",
            "   \u001b[33m|->> #1/t=47-th Action selection: 3/2X RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [289 238  77  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0928 0.0902 0.0869 0.0918 0.0925 0.0932 0.0932 0.0914 0.0911 0.0906\n",
            " 0.0862], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09278944 0.09015584 0.08694598 0.09182305 0.09253535 0.09321586\n",
            " 0.09322634 0.09136989 0.09110614 0.09060942 0.08622268], argmax=6\n",
            "|->> Revisiting bbox: [289 238  77  72]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [285, 234,  77,  72] -> [289, 238,  77,  72] (Target was [216, 168,  87,  67])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.002) for 2X DOWN:bbox transition: [285, 234,  77,  72] -> [285, 238,  77,  72] w/ P(a|s)=0.09409215301275253 and iou=0.0 and reward=-0.001585204755614267 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [285, 238,  77,  72] -> [289, 238,  77,  72] w/ P(a|s)=0.091823048889637 and iou=0.0 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.0037466 -2.387892 ]\n",
            "\u001b[31m>> Total frame loss: -2.3916385173797607\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 77 with src: [289, 238,  77,  72] and target: [205, 167,  85,  68]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0080.jpg\n",
            "|->> Beginning tracking for bbox:[289 238  77  72]\n",
            "   \u001b[33m|->> #0/t=48-th Action selection: 6/DOWN (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [289 240  77  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0901 0.0908 0.0908 0.0894 0.0928 0.0934 0.0932 0.0921 0.091  0.0892\n",
            " 0.0873], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.09008337 0.09078161 0.09077797 0.08937877 0.09279627 0.09342258\n",
            " 0.09317517 0.09214118 0.09097812 0.08915827 0.08730666], argmax=5\n",
            "   \u001b[33m|->> #1/t=49-th Action selection: 3/2X RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [293 240  77  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0936 0.0905 0.0865 0.0906 0.0948 0.0935 0.0901 0.0928 0.0908 0.0895\n",
            " 0.0873], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.09357417 0.09046133 0.08654448 0.09064605 0.09482487 0.09352102\n",
            " 0.09006848 0.09283938 0.09080189 0.08945221 0.0872661 ], argmax=4\n",
            "   \u001b[33m|->> #2/t=50-th Action selection: 0/LEFT (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [291 240  77  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0943 0.0901 0.0879 0.0891 0.0918 0.0937 0.0925 0.0925 0.0909 0.0894\n",
            " 0.0878], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09433232 0.09005722 0.08788656 0.08908456 0.09180537 0.09369215\n",
            " 0.0925318  0.09254318 0.09086257 0.08939552 0.08780876], argmax=0\n",
            "   \u001b[33m|->> #3/t=51-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [292 241  74  69]\n",
            "         |->> Action Probabilities (Rounded): [0.0864 0.0898 0.0941 0.0909 0.0931 0.0946 0.0921 0.0929 0.0912 0.0877\n",
            " 0.0872], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.08635502 0.08982307 0.0940581  0.09086195 0.09313948 0.0946072\n",
            " 0.09211129 0.09287661 0.09122822 0.08773719 0.08720192], argmax=5\n",
            "   \u001b[33m|->> #4/t=52-th Action selection: 10/SCALE UP (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [290 239  76  71]\n",
            "         |->> Action Probabilities (Rounded): [0.0934 0.0904 0.0857 0.0915 0.0926 0.0942 0.0934 0.0935 0.091  0.0846\n",
            " 0.0896], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.0934495  0.09037788 0.08573272 0.09149285 0.09264976 0.09415419\n",
            " 0.09339967 0.093532   0.09103079 0.08460762 0.08957301], argmax=5\n",
            "|->> Revisiting bbox: [290 239  76  71]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [289, 238,  77,  72] -> [290, 239,  76,  71] (Target was [205, 167,  85,  68])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for DOWN:bbox transition: [289, 238,  77,  72] -> [289, 240,  77,  72] w/ P(a|s)=0.09317516535520554 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for 2X RIGHT:bbox transition: [289, 240,  77,  72] -> [293, 240,  77,  72] w/ P(a|s)=0.09064605087041855 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.0) for LEFT:bbox transition: [293, 240,  77,  72] -> [291, 240,  77,  72] w/ P(a|s)=0.09433231502771378 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.0) for SCALE DOWN:bbox transition: [291, 240,  77,  72] -> [292, 241,  74,  69] w/ P(a|s)=0.08773718774318695 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (-1.0) for SCALE UP:bbox transition: [292, 241,  74,  69] -> [290, 239,  76,  71] w/ P(a|s)=0.08957301080226898 and iou=0.0 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.         0.         0.         0.        -2.4127011]\n",
            "\u001b[31m>> Total frame loss: -2.41270112991333\u001b[0m\n",
            "Final bounding box: [290 239  76  71] reached in 53 timesteps (originating from [284 231  80  75]). Target was [205 167  85  68]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 78 in t=53 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[31m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 8.43055534362793\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 2.1185200214385986\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/BlurCar3\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0071.jpg\n",
            "Starting bounding box=adnet_datasets/OTB/BlurCar3/img/0081.jpg for adnet_datasets/OTB/BlurCar3's frames (index: 0)\n",
            "src:adnet_datasets/OTB/BlurCar3/img/0071.jpg\n",
            "target:adnet_datasets/OTB/BlurCar3/img/0081.jpg.\n",
            "\u001b[34m>> Attempting to reach frame 69 with src: [261, 245,  90,  72] and target: [252, 242,  91,  71]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0072.jpg\n",
            "|->> Beginning tracking for bbox:[261 245  90  72]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 0/LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [259 245  90  72]\n",
            "         |->> Action Probabilities (Rounded): [0.091  0.0907 0.0909 0.091  0.0907 0.0909 0.0909 0.0909 0.0909 0.0911\n",
            " 0.091 ], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.09098299 0.09067467 0.09086574 0.09095924 0.0907486  0.09090422\n",
            " 0.09092493 0.09089866 0.09088163 0.09111421 0.09104512], argmax=9\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 7/2X DOWN (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [259 249  90  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0839 0.0908 0.0975 0.0919 0.0906 0.092  0.0912 0.0919 0.0912 0.0887\n",
            " 0.0903], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.0839429  0.09077908 0.09749036 0.09189005 0.09055256 0.09198467\n",
            " 0.09124814 0.09187879 0.09123362 0.08865412 0.09034574], argmax=2\n",
            "   \u001b[33m|->> #2/t=3-th Action selection: 9/SCALE DOWN (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [260 250  87  69]\n",
            "         |->> Action Probabilities (Rounded): [0.0927 0.0902 0.0893 0.0918 0.0908 0.0915 0.0912 0.0903 0.0912 0.0899\n",
            " 0.0911], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09273946 0.09020376 0.08931243 0.09179246 0.09082551 0.09146204\n",
            " 0.09121308 0.09027872 0.09118259 0.08989403 0.09109592], argmax=0\n",
            "   \u001b[33m|->> #3/t=4-th Action selection: 6/DOWN (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [260 252  87  69]\n",
            "         |->> Action Probabilities (Rounded): [0.0885 0.0907 0.0932 0.0925 0.0914 0.0921 0.0919 0.0914 0.0918 0.0845\n",
            " 0.0922], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08849486 0.0906956  0.09322559 0.09248433 0.09136746 0.09207445\n",
            " 0.09185686 0.09137249 0.09176648 0.08445293 0.09220897], argmax=2\n",
            "   \u001b[33m|->> #4/t=5-th Action selection: 9/SCALE DOWN (P(a|s) = 0.0860000029206276)\u001b[0m\n",
            "      |->> Bounding box moves to: [261 253  84  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0928 0.0906 0.0905 0.0928 0.093  0.0917 0.0892 0.0914 0.0911 0.0865\n",
            " 0.0905], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0927761  0.09062772 0.09046792 0.09278822 0.09297179 0.09165069\n",
            " 0.0891694  0.09139834 0.09113429 0.08646893 0.09054654], argmax=4\n",
            "   \u001b[33m|->> #5/t=6-th Action selection: 3/2X RIGHT (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [265 253  84  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0911 0.0908 0.0917 0.0937 0.0912 0.0922 0.0918 0.0918 0.0922 0.081\n",
            " 0.0926], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09107133 0.09076259 0.09167109 0.09369773 0.09115458 0.09223474\n",
            " 0.09179251 0.0917789  0.0922165  0.08097091 0.09264915], argmax=3\n",
            "|->> Revisiting bbox: [261 253  84  66]. ACtion 1 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [261, 245,  90,  72] -> [265, 253,  84,  66] (Target was [252, 242,  91,  71])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.033) for LEFT:bbox transition: [261, 245,  90,  72] -> [259, 245,  90,  72] w/ P(a|s)=0.09098298847675323 and iou=0.7901507815742149 and reward=0.033056416333210215 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.08) for 2X DOWN:bbox transition: [259, 245,  90,  72] -> [259, 249,  90,  72] w/ P(a|s)=0.09187878668308258 and iou=0.7106411103767349 and reward=-0.07950967119747998 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.012) for SCALE DOWN:bbox transition: [259, 249,  90,  72] -> [260, 250,  87,  69] w/ P(a|s)=0.08989402651786804 and iou=0.7227366966136834 and reward=0.012095586236948508 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-0.039) for DOWN:bbox transition: [260, 250,  87,  69] -> [260, 252,  87,  69] w/ P(a|s)=0.09185685962438583 and iou=0.684096743683286 and reward=-0.03863995293039746 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (0.01) for SCALE DOWN:bbox transition: [260, 252,  87,  69] -> [261, 253,  84,  66] w/ P(a|s)=0.08646892756223679 and iou=0.6944248412138321 and reward=0.010328097530546088 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [261, 253,  84,  66] -> [265, 253,  84,  66] w/ P(a|s)=0.09369772672653198 and iou=0.6389078498293516 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.07923897 -0.18981224  0.02913977 -0.0922538   0.02528287 -2.3676813 ]\n",
            "\u001b[31m>> Total frame loss: -2.516085624694824\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 70 with src: [265, 253,  84,  66] and target: [261, 227,  92,  72]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0073.jpg\n",
            "|->> Beginning tracking for bbox:[265 253  84  66]\n",
            "   \u001b[33m|->> #0/t=7-th Action selection: 0/LEFT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [263 253  84  66]\n",
            "         |->> Action Probabilities (Rounded): [0.092  0.0912 0.0902 0.0911 0.093  0.0926 0.0911 0.0916 0.0916 0.0846\n",
            " 0.0911], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.09204323 0.09116743 0.09019909 0.09112494 0.09296916 0.09259292\n",
            " 0.09112148 0.09158369 0.09156587 0.08455037 0.09108177], argmax=4\n",
            "   \u001b[33m|->> #1/t=8-th Action selection: 5/2X UP (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [263 251  84  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0844 0.0906 0.0958 0.0931 0.0921 0.0936 0.0926 0.0935 0.0915 0.0823\n",
            " 0.0906], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08437242 0.0906233  0.09584205 0.09307833 0.09206852 0.09359168\n",
            " 0.09258616 0.09353233 0.09147595 0.08226416 0.09056511], argmax=2\n",
            "   \u001b[33m|->> #2/t=9-th Action selection: 2/RIGHT (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [265 251  84  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0931 0.0901 0.0878 0.0924 0.092  0.0921 0.0927 0.0929 0.092  0.0843\n",
            " 0.0907], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09306437 0.09008739 0.08782864 0.09237262 0.09202733 0.09209255\n",
            " 0.09266866 0.0928871  0.09197345 0.08432505 0.09067275], argmax=0\n",
            "|->> Revisiting bbox: [265 253  84  66]. ACtion 7 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [265, 253,  84,  66] -> [265, 251,  84,  66] (Target was [261, 227,  92,  72])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for LEFT:bbox transition: [265, 253,  84,  66] -> [263, 253,  84,  66] w/ P(a|s)=0.09204322844743729 and iou=0.4653179190751445 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.03) for 2X UP:bbox transition: [263, 253,  84,  66] -> [263, 251,  84,  66] w/ P(a|s)=0.09359167516231537 and iou=0.49557522123893805 and reward=0.03025730216379352 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-1.0) for RIGHT:bbox transition: [263, 251,  84,  66] -> [265, 251,  84,  66] w/ P(a|s)=0.08782864362001419 and iou=0.49557522123893805 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.          0.07167391 -2.4323676 ]\n",
            "\u001b[31m>> Total frame loss: -2.3606936931610107\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 71 with src: [265, 251,  84,  66] and target: [271, 222,  91,  70]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0074.jpg\n",
            "|->> Beginning tracking for bbox:[265 251  84  66]\n",
            "   \u001b[33m|->> #0/t=10-th Action selection: 3/2X RIGHT (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [269 251  84  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0957 0.09   0.0843 0.0935 0.0917 0.093  0.0936 0.0938 0.0912 0.0837\n",
            " 0.0895], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09568824 0.08999719 0.08434535 0.09352986 0.09165344 0.09303259\n",
            " 0.0935937  0.0937895  0.09118598 0.08371653 0.08946757], argmax=0\n",
            "   \u001b[33m|->> #1/t=11-th Action selection: 2/RIGHT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [271 251  84  66]\n",
            "         |->> Action Probabilities (Rounded): [0.091  0.0915 0.09   0.0899 0.0928 0.0924 0.0938 0.094  0.0905 0.0844\n",
            " 0.0897], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.0910411  0.09149949 0.08996074 0.08989606 0.09284575 0.09243695\n",
            " 0.0938222  0.09396826 0.09045065 0.08435109 0.08972766], argmax=7\n",
            "|->> Revisiting bbox: [269 251  84  66]. ACtion 0 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [265, 251,  84,  66] -> [271, 251,  84,  66] (Target was [271, 222,  91,  70])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.026) for 2X RIGHT:bbox transition: [265, 251,  84,  66] -> [269, 251,  84,  66] w/ P(a|s)=0.09352985769510269 and iou=0.3931244153414406 and reward=0.026212988081229516 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for RIGHT:bbox transition: [269, 251,  84,  66] -> [271, 251,  84,  66] w/ P(a|s)=0.0899607390165329 and iou=0.4066115702479339 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.06211101 -2.408382  ]\n",
            "\u001b[31m>> Total frame loss: -2.34627103805542\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 72 with src: [271, 251,  84,  66] and target: [276, 221,  89,  68]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0075.jpg\n",
            "|->> Beginning tracking for bbox:[271 251  84  66]\n",
            "|->> Revisiting bbox: [271 251  84  66]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=12-th Action selection: 8/STOP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [271 251  84  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0996 0.0909 0.0788 0.0922 0.0923 0.0937 0.0933 0.095  0.091  0.0842\n",
            " 0.089 ], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09963733 0.09091564 0.07878087 0.09221202 0.09225952 0.09371097\n",
            " 0.0932546  0.09500505 0.09104204 0.08416972 0.08901221], argmax=0\n",
            "         |->> Hit a STOP on the 12-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [271, 251,  84,  66] -> [271, 251,  84,  66] (Target was [276, 221,  89,  68])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [271, 251,  84,  66] -> [271, 251,  84,  66] w/ P(a|s)=0.09104204177856445 and iou=0.349313474517105 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.3964338]\n",
            "\u001b[31m>> Total frame loss: -2.3964338302612305\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 73 with src: [271, 251,  84,  66] and target: [282, 206,  82,  70]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0076.jpg\n",
            "|->> Beginning tracking for bbox:[271 251  84  66]\n",
            "   \u001b[33m|->> #0/t=12-th Action selection: 4/UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [271 250  84  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0877 0.0921 0.0912 0.0889 0.092  0.0932 0.0943 0.0945 0.0914 0.0842\n",
            " 0.0905], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.0877353  0.09205461 0.09116132 0.08892577 0.09201669 0.0932043\n",
            " 0.0942506  0.09452611 0.09144802 0.08420902 0.09046821], argmax=7\n",
            "   \u001b[33m|->> #1/t=13-th Action selection: 1/2X LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [267 250  84  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0945 0.0913 0.0854 0.0912 0.0891 0.0936 0.0938 0.0956 0.0918 0.0856\n",
            " 0.0881], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09454663 0.09132025 0.08535039 0.09119633 0.08913351 0.0936003\n",
            " 0.09377647 0.09556869 0.09181923 0.0855591  0.0881291 ], argmax=7\n",
            "   \u001b[33m|->> #2/t=14-th Action selection: 5/2X UP (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [267 248  84  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0908 0.089  0.0902 0.0905 0.0904 0.0936 0.0932 0.0951 0.0923 0.0858\n",
            " 0.0891], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09083112 0.08900493 0.09018096 0.09048507 0.09043929 0.09357878\n",
            " 0.09322333 0.09505128 0.09230562 0.08578355 0.08911598], argmax=7\n",
            "   \u001b[33m|->> #3/t=15-th Action selection: 1/2X LEFT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [263 248  84  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0942 0.0888 0.0888 0.0911 0.0901 0.0914 0.0942 0.095  0.0912 0.0872\n",
            " 0.088 ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09421807 0.08875751 0.08884231 0.09106468 0.09011527 0.09143095\n",
            " 0.09416229 0.09500597 0.0912177  0.08719786 0.0879874 ], argmax=7\n",
            "   \u001b[33m|->> #4/t=16-th Action selection: 5/2X UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [263 246  84  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0912 0.0865 0.0912 0.0918 0.0908 0.0915 0.0942 0.0949 0.0924 0.0866\n",
            " 0.0888], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09120425 0.08654033 0.09124535 0.09177466 0.09083903 0.09146316\n",
            " 0.09415925 0.09490189 0.09244121 0.08663797 0.08879291], argmax=7\n",
            "   \u001b[33m|->> #5/t=17-th Action selection: 3/2X RIGHT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [267 246  84  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0923 0.0879 0.0909 0.09   0.0911 0.0899 0.094  0.0945 0.0922 0.0887\n",
            " 0.0884], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09234859 0.08790934 0.09090938 0.09001472 0.09112146 0.08994535\n",
            " 0.09402519 0.09448011 0.09217345 0.08870134 0.08837104], argmax=7\n",
            "|->> Revisiting bbox: [267 246  84  66]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [271, 251,  84,  66] -> [267, 246,  84,  66] (Target was [282, 206,  82,  70])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.009) for UP:bbox transition: [271, 251,  84,  66] -> [271, 250,  84,  66] w/ P(a|s)=0.09201668947935104 and iou=0.20221606648199447 and reward=0.009278123781920472 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.013) for 2X LEFT:bbox transition: [271, 250,  84,  66] -> [267, 250,  84,  66] w/ P(a|s)=0.09132024645805359 and iou=0.18904109589041096 and reward=-0.013174970591583512 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.018) for 2X UP:bbox transition: [267, 250,  84,  66] -> [267, 248,  84,  66] w/ P(a|s)=0.0935787782073021 and iou=0.20658682634730538 and reward=0.01754573045689442 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-0.014) for 2X LEFT:bbox transition: [267, 248,  84,  66] -> [263, 248,  84,  66] w/ P(a|s)=0.08875750750303268 and iou=0.19230769230769232 and reward=-0.014279134039613062 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (0.017) for 2X UP:bbox transition: [263, 248,  84,  66] -> [263, 246,  84,  66] w/ P(a|s)=0.09146316349506378 and iou=0.20891364902506965 and reward=0.01660595671737733 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [263, 246,  84,  66] -> [267, 246,  84,  66] w/ P(a|s)=0.09001471847295761 and iou=0.2246581289342305 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.02213561 -0.03153275  0.04156498 -0.03458188  0.03971844 -2.407782  ]\n",
            "\u001b[31m>> Total frame loss: -2.3704776763916016\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 74 with src: [267, 246,  84,  66] and target: [265, 181,  91,  69]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0077.jpg\n",
            "|->> Beginning tracking for bbox:[267 246  84  66]\n",
            "   \u001b[33m|->> #0/t=18-th Action selection: 1/2X LEFT (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [263 246  84  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0916 0.0878 0.0899 0.0897 0.0921 0.0907 0.0947 0.0943 0.0912 0.0885\n",
            " 0.0895], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.0916011  0.08784734 0.08988707 0.08972295 0.09206359 0.09065297\n",
            " 0.0947407  0.09434358 0.09117599 0.08849902 0.08946571], argmax=6\n",
            "|->> Revisiting bbox: [267 246  84  66]. ACtion 3 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [267, 246,  84,  66] -> [263, 246,  84,  66] (Target was [265, 181,  91,  69])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [267, 246,  84,  66] -> [263, 246,  84,  66] w/ P(a|s)=0.08784734457731247 and iou=0.028534145280556762 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.4321547]\n",
            "\u001b[31m>> Total frame loss: -2.432154655456543\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 75 with src: [263, 246,  84,  66] and target: [242, 172,  87,  67]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0078.jpg\n",
            "|->> Beginning tracking for bbox:[263 246  84  66]\n",
            "   \u001b[33m|->> #0/t=19-th Action selection: 2/RIGHT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [265 246  84  66]\n",
            "         |->> Action Probabilities (Rounded): [0.091  0.0858 0.0904 0.0904 0.0915 0.0904 0.094  0.0946 0.0915 0.0901\n",
            " 0.0903], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09097418 0.08581582 0.0904215  0.09043521 0.09152163 0.09037067\n",
            " 0.09401    0.09459732 0.09147555 0.09005031 0.09032782], argmax=7\n",
            "   \u001b[33m|->> #1/t=20-th Action selection: 4/UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [265 245  84  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0968 0.0859 0.0832 0.092  0.0916 0.0915 0.0952 0.0946 0.0916 0.0886\n",
            " 0.089 ], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09675519 0.08591989 0.0832098  0.09196481 0.09155218 0.09154642\n",
            " 0.09518701 0.09464376 0.09160424 0.08857043 0.08904626], argmax=0\n",
            "   \u001b[33m|->> #2/t=21-th Action selection: 0/LEFT (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [263 245  84  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0883 0.0879 0.0925 0.0908 0.0905 0.0916 0.0951 0.0947 0.0895 0.0894\n",
            " 0.0895], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08827014 0.08793809 0.09246303 0.09079058 0.09053761 0.09164932\n",
            " 0.09513176 0.09471384 0.08954491 0.08941668 0.08954406], argmax=6\n",
            "   \u001b[33m|->> #3/t=22-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [264 246  81  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0845 0.0878 0.0952 0.0915 0.0908 0.0922 0.0941 0.0955 0.091  0.0883\n",
            " 0.0891], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08453008 0.08784026 0.09515322 0.09148077 0.09084944 0.09220526\n",
            " 0.09411754 0.0955056  0.0909741  0.08827373 0.08906994], argmax=7\n",
            "   \u001b[33m|->> #4/t=23-th Action selection: 1/2X LEFT (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [260 246  81  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0896 0.0878 0.0884 0.0933 0.0912 0.0922 0.0956 0.0952 0.0918 0.0836\n",
            " 0.0913], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08956604 0.08781543 0.08844858 0.09327497 0.09121876 0.09217842\n",
            " 0.0956283  0.09524535 0.09179114 0.08357084 0.09126213], argmax=6\n",
            "   \u001b[33m|->> #5/t=24-th Action selection: 2/RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [262 246  81  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0884 0.0868 0.0924 0.0922 0.092  0.0922 0.0939 0.095  0.091  0.0861\n",
            " 0.0899], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08839536 0.08682045 0.0924415  0.09220494 0.09203081 0.09215941\n",
            " 0.0939465  0.09499856 0.09098229 0.08608852 0.08993162], argmax=7\n",
            "   \u001b[33m|->> #6/t=25-th Action selection: 4/UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [262 245  81  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0979 0.0864 0.0813 0.0928 0.0921 0.0937 0.0955 0.0952 0.0913 0.0848\n",
            " 0.0891], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09794648 0.08637194 0.08126448 0.09276826 0.09207579 0.09366433\n",
            " 0.0955259  0.09518885 0.09125428 0.0848496  0.08909019], argmax=0\n",
            "   \u001b[33m|->> #7/t=26-th Action selection: 5/2X UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [262 243  81  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0893 0.0885 0.0926 0.0907 0.0908 0.093  0.095  0.0953 0.0913 0.085\n",
            " 0.0885], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.0893373  0.08850785 0.09258163 0.09072416 0.0908483  0.09295358\n",
            " 0.09496157 0.09529768 0.09131008 0.08495216 0.08852568], argmax=7\n",
            "|->> Revisiting bbox: [262 245  81  64]. ACtion 7 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [263, 246,  84,  66] -> [262, 243,  81,  64] (Target was [242, 172,  87,  67])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for RIGHT:bbox transition: [263, 246,  84,  66] -> [265, 246,  84,  66] w/ P(a|s)=0.09042149782180786 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for UP:bbox transition: [265, 246,  84,  66] -> [265, 245,  84,  66] w/ P(a|s)=0.09155217558145523 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.0) for LEFT:bbox transition: [265, 245,  84,  66] -> [263, 245,  84,  66] w/ P(a|s)=0.08827013522386551 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.0) for SCALE DOWN:bbox transition: [263, 245,  84,  66] -> [264, 246,  81,  64] w/ P(a|s)=0.08827373385429382 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (0.0) for 2X LEFT:bbox transition: [264, 246,  81,  64] -> [260, 246,  81,  64] w/ P(a|s)=0.08781543374061584 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (0.0) for RIGHT:bbox transition: [260, 246,  81,  64] -> [262, 246,  81,  64] w/ P(a|s)=0.09244149923324585 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=7 Diff-Reward (0.0) for UP:bbox transition: [262, 246,  81,  64] -> [262, 245,  81,  64] w/ P(a|s)=0.09207579493522644 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=8 Diff-Reward (-1.0) for 2X UP:bbox transition: [262, 245,  81,  64] -> [262, 243,  81,  64] w/ P(a|s)=0.09295357763767242 and iou=0.0 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.         0.         0.         0.         0.         0.\n",
            "  0.        -2.3756552]\n",
            "\u001b[31m>> Total frame loss: -2.375655174255371\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 76 with src: [262, 243,  81,  64] and target: [216, 168,  87,  67]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0079.jpg\n",
            "|->> Beginning tracking for bbox:[262 243  81  64]\n",
            "|->> Revisiting bbox: [262 243  81  64]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=27-th Action selection: 8/STOP (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [262 243  81  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0939 0.088  0.0884 0.0917 0.091  0.0916 0.0944 0.0952 0.0899 0.0861\n",
            " 0.0898], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09385318 0.08804686 0.08840052 0.09166694 0.0910292  0.09160685\n",
            " 0.09440993 0.09517389 0.08994499 0.08605401 0.08981363], argmax=7\n",
            "         |->> Hit a STOP on the 27-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [262, 243,  81,  64] -> [262, 243,  81,  64] (Target was [216, 168,  87,  67])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [262, 243,  81,  64] -> [262, 243,  81,  64] w/ P(a|s)=0.089944988489151 and iou=0.0 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.408557]\n",
            "\u001b[31m>> Total frame loss: -2.4085569381713867\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 77 with src: [262, 243,  81,  64] and target: [205, 167,  85,  68]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0080.jpg\n",
            "|->> Beginning tracking for bbox:[262 243  81  64]\n",
            "   \u001b[33m|->> #0/t=27-th Action selection: 5/2X UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [262 241  81  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0897 0.0884 0.0923 0.0924 0.0904 0.0915 0.0959 0.094  0.091  0.0848\n",
            " 0.0896], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08972635 0.08836915 0.09226025 0.09235714 0.09044652 0.09145167\n",
            " 0.0959347  0.09400947 0.0910142  0.08479326 0.08963729], argmax=6\n",
            "   \u001b[33m|->> #1/t=28-th Action selection: 4/UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [262 240  81  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0922 0.0898 0.0902 0.0927 0.0907 0.0903 0.0927 0.0948 0.092  0.0851\n",
            " 0.0895], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09215785 0.08981044 0.0902219  0.09274268 0.0906537  0.0903132\n",
            " 0.09267949 0.09482358 0.09196515 0.08514937 0.08948259], argmax=7\n",
            "   \u001b[33m|->> #2/t=29-th Action selection: 7/2X DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [262 242  81  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0913 0.0896 0.0922 0.0936 0.0884 0.0906 0.0946 0.094  0.0919 0.0853\n",
            " 0.0886], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09125259 0.08959451 0.0921562  0.09360906 0.08842537 0.09061095\n",
            " 0.09464119 0.09398918 0.09186278 0.08530493 0.08855321], argmax=6\n",
            "|->> Revisiting bbox: [262 241  81  64]. ACtion 4 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [262, 243,  81,  64] -> [262, 242,  81,  64] (Target was [205, 167,  85,  68])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X UP:bbox transition: [262, 243,  81,  64] -> [262, 241,  81,  64] w/ P(a|s)=0.09145167469978333 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for UP:bbox transition: [262, 241,  81,  64] -> [262, 240,  81,  64] w/ P(a|s)=0.09065369516611099 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-1.0) for 2X DOWN:bbox transition: [262, 240,  81,  64] -> [262, 242,  81,  64] w/ P(a|s)=0.09398917853832245 and iou=0.0 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.         0.        -2.3645756]\n",
            "\u001b[31m>> Total frame loss: -2.3645756244659424\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 78 with src: [262, 242,  81,  64] and target: [211, 168,  83,  69]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0081.jpg\n",
            "|->> Beginning tracking for bbox:[262 242  81  64]\n",
            "   \u001b[33m|->> #0/t=30-th Action selection: 4/UP (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [262 241  81  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0925 0.0902 0.0913 0.0926 0.0894 0.0905 0.0925 0.0932 0.0919 0.0862\n",
            " 0.0896], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09251641 0.09019426 0.09133536 0.09263919 0.08938424 0.09051549\n",
            " 0.09252851 0.09317434 0.09193871 0.08620119 0.0895723 ], argmax=7\n",
            "   \u001b[33m|->> #1/t=31-th Action selection: 2/RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [264 241  81  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0901 0.0906 0.0915 0.0929 0.088  0.0896 0.0946 0.093  0.0926 0.0876\n",
            " 0.0895], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09009459 0.09061148 0.09151162 0.09286774 0.0879847  0.08963931\n",
            " 0.09460462 0.09299812 0.09261332 0.08759553 0.08947895], argmax=6\n",
            "   \u001b[33m|->> #2/t=32-th Action selection: 5/2X UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [264 239  81  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0977 0.0918 0.0824 0.0937 0.0894 0.0911 0.0922 0.0925 0.0923 0.0879\n",
            " 0.089 ], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09771526 0.09175621 0.08243521 0.09371104 0.08937936 0.09114717\n",
            " 0.09216035 0.09248148 0.09232661 0.08786085 0.08902647], argmax=0\n",
            "   \u001b[33m|->> #3/t=33-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [265 240  78  62]\n",
            "         |->> Action Probabilities (Rounded): [0.0887 0.0923 0.0927 0.0915 0.0908 0.0888 0.0932 0.0932 0.0914 0.0885\n",
            " 0.0889], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08871131 0.09226734 0.09269417 0.09150284 0.09082486 0.08884617\n",
            " 0.0931862  0.09322712 0.09140669 0.08847447 0.08885889], argmax=7\n",
            "   \u001b[33m|->> #4/t=34-th Action selection: 2/RIGHT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [267 240  78  62]\n",
            "         |->> Action Probabilities (Rounded): [0.0926 0.0923 0.0894 0.0939 0.0909 0.0898 0.0936 0.0928 0.0911 0.0832\n",
            " 0.0904], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09260741 0.09229004 0.08940707 0.09393278 0.09093241 0.0898343\n",
            " 0.09356041 0.09277242 0.09112184 0.08318463 0.0903567 ], argmax=3\n",
            "   \u001b[33m|->> #5/t=35-th Action selection: 4/UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [267 239  78  62]\n",
            "         |->> Action Probabilities (Rounded): [0.0973 0.0915 0.0838 0.0936 0.0914 0.0901 0.0939 0.0939 0.0908 0.0852\n",
            " 0.0884], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09730487 0.09151455 0.08382521 0.09356841 0.09142911 0.09011393\n",
            " 0.09385804 0.0939091  0.09083106 0.08521681 0.08842893], argmax=0\n",
            "   \u001b[33m|->> #6/t=36-th Action selection: 10/SCALE UP (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [265 238  80  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0915 0.0932 0.0911 0.0927 0.0902 0.0913 0.0942 0.0935 0.0893 0.0844\n",
            " 0.0887], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09147386 0.09320517 0.09105226 0.09270594 0.09017258 0.09128908\n",
            " 0.09418786 0.09351873 0.08927175 0.08438755 0.08873519], argmax=6\n",
            "   \u001b[33m|->> #7/t=37-th Action selection: 10/SCALE UP (P(a|s) = 0.08399999886751175)\u001b[0m\n",
            "      |->> Bounding box moves to: [263 237  82  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0936 0.0925 0.0881 0.0924 0.0909 0.0906 0.0934 0.0938 0.0924 0.0885\n",
            " 0.0837], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09357781 0.09249662 0.08814611 0.09244476 0.09087472 0.0906056\n",
            " 0.09336451 0.09380274 0.09242295 0.08853496 0.08372927], argmax=7\n",
            "   \u001b[33m|->> #8/t=38-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [264 238  79  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0913 0.0928 0.0896 0.0926 0.0916 0.0921 0.0937 0.0936 0.0918 0.0892\n",
            " 0.0815], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09130998 0.09281908 0.08960068 0.0926457  0.09157445 0.09213609\n",
            " 0.09367524 0.0936421  0.09182541 0.08923196 0.08153934], argmax=6\n",
            "   \u001b[33m|->> #9/t=39-th Action selection: 0/LEFT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [262 238  79  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0923 0.0931 0.0885 0.094  0.0923 0.0929 0.0937 0.0939 0.0917 0.0831\n",
            " 0.0845], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09229717 0.09310509 0.0885222  0.0939698  0.09226356 0.09293781\n",
            " 0.09373772 0.0938933  0.09170449 0.083091   0.08447785], argmax=3\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [262, 242,  81,  64] -> [262, 238,  79,  64] (Target was [211, 168,  83,  69])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for UP:bbox transition: [262, 242,  81,  64] -> [262, 241,  81,  64] w/ P(a|s)=0.08938424289226532 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for RIGHT:bbox transition: [262, 241,  81,  64] -> [264, 241,  81,  64] w/ P(a|s)=0.09151162207126617 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X UP:bbox transition: [264, 241,  81,  64] -> [264, 239,  81,  64] w/ P(a|s)=0.09114716947078705 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.0) for SCALE DOWN:bbox transition: [264, 239,  81,  64] -> [265, 240,  78,  62] w/ P(a|s)=0.08847447484731674 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (0.0) for RIGHT:bbox transition: [265, 240,  78,  62] -> [267, 240,  78,  62] w/ P(a|s)=0.0894070714712143 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (0.0) for UP:bbox transition: [267, 240,  78,  62] -> [267, 239,  78,  62] w/ P(a|s)=0.09142911434173584 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=7 Diff-Reward (0.0) for SCALE UP:bbox transition: [267, 239,  78,  62] -> [265, 238,  80,  64] w/ P(a|s)=0.0887351855635643 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=8 Diff-Reward (0.0) for SCALE UP:bbox transition: [265, 238,  80,  64] -> [263, 237,  82,  66] w/ P(a|s)=0.08372927457094193 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=9 Diff-Reward (0.0) for SCALE DOWN:bbox transition: [263, 237,  82,  66] -> [264, 238,  79,  64] w/ P(a|s)=0.0892319604754448 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=10 Diff-Reward (-1.0) for LEFT:bbox transition: [264, 238,  79,  64] -> [262, 238,  79,  64] w/ P(a|s)=0.09229717403650284 and iou=0.0 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.        -2.3827417]\n",
            "\u001b[31m>> Total frame loss: -2.382741689682007\u001b[0m\n",
            "Final bounding box: [262 238  79  64] reached in 40 timesteps (originating from [261 245  90  72]). Target was [211 168  83  69]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 79 in t=40 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[31m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 9.093600273132324\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 2.603769063949585\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/BlurCar3\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0072.jpg\n",
            "Starting bounding box=adnet_datasets/OTB/BlurCar3/img/0082.jpg for adnet_datasets/OTB/BlurCar3's frames (index: 0)\n",
            "src:adnet_datasets/OTB/BlurCar3/img/0072.jpg\n",
            "target:adnet_datasets/OTB/BlurCar3/img/0082.jpg.\n",
            "\u001b[34m>> Attempting to reach frame 70 with src: [252, 242,  91,  71] and target: [261, 227,  92,  72]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0073.jpg\n",
            "|->> Beginning tracking for bbox:[252 242  91  71]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 3/2X RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [256 242  91  71]\n",
            "         |->> Action Probabilities (Rounded): [0.091  0.0907 0.0909 0.091  0.0907 0.0909 0.0909 0.0909 0.0909 0.0911\n",
            " 0.0911], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.09098454 0.09066881 0.09086281 0.09095648 0.09074795 0.09090474\n",
            " 0.09092635 0.09089967 0.09087852 0.0911197  0.09105048], argmax=9\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 2/RIGHT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [258 242  91  71]\n",
            "         |->> Action Probabilities (Rounded): [0.0916 0.0912 0.0901 0.0892 0.091  0.0913 0.091  0.0911 0.091  0.0914\n",
            " 0.0911], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09160154 0.0911888  0.09013044 0.08916909 0.09100587 0.09130815\n",
            " 0.09103794 0.09114143 0.09100012 0.09135821 0.09105846], argmax=0\n",
            "|->> Revisiting bbox: [256 242  91  71]. ACtion 0 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [252, 242,  91,  71] -> [258, 242,  91,  71] (Target was [261, 227,  92,  72])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.043) for 2X RIGHT:bbox transition: [252, 242,  91,  71] -> [256, 242,  91,  71] w/ P(a|s)=0.09095647931098938 and iou=0.5990468043504827 and reward=0.04334593643941387 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for RIGHT:bbox transition: [256, 242,  91,  71] -> [258, 242,  91,  71] w/ P(a|s)=0.09013044089078903 and iou=0.6216383690667988 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.10391643 -2.4064972 ]\n",
            "\u001b[31m>> Total frame loss: -2.3025808334350586\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 71 with src: [258, 242,  91,  71] and target: [271, 222,  91,  70]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0074.jpg\n",
            "|->> Beginning tracking for bbox:[258 242  91  71]\n",
            "   \u001b[33m|->> #0/t=3-th Action selection: 10/SCALE UP (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [256 240  93  73]\n",
            "         |->> Action Probabilities (Rounded): [0.0983 0.0904 0.0819 0.0905 0.0912 0.0923 0.0917 0.0919 0.0914 0.0902\n",
            " 0.0901], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.0983199  0.09041993 0.08193881 0.09051948 0.09119196 0.09230017\n",
            " 0.09170513 0.09192315 0.09140655 0.0901897  0.09008519], argmax=0\n",
            "   \u001b[33m|->> #1/t=4-th Action selection: 4/UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [256 238  93  73]\n",
            "         |->> Action Probabilities (Rounded): [0.0888 0.0922 0.0911 0.0896 0.0919 0.0925 0.092  0.0927 0.0922 0.0922\n",
            " 0.0849], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08875887 0.09218223 0.09110696 0.08960728 0.09186028 0.09253971\n",
            " 0.09202084 0.09265406 0.09218481 0.09222935 0.08485559], argmax=7\n",
            "|->> Revisiting bbox: [256 238  93  73]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [258, 242,  91,  71] -> [256, 238,  93,  73] (Target was [271, 222,  91,  70])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.009) for SCALE UP:bbox transition: [258, 242,  91,  71] -> [256, 240,  93,  73] w/ P(a|s)=0.09008518606424332 and iou=0.4455673953641657 and reward=0.008886172656742075 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for UP:bbox transition: [256, 240,  93,  73] -> [256, 238,  93,  73] w/ P(a|s)=0.09186027944087982 and iou=0.47077232591930257 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.02138901 -2.3874865 ]\n",
            "\u001b[31m>> Total frame loss: -2.3660974502563477\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 72 with src: [256, 238,  93,  73] and target: [276, 221,  89,  68]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0075.jpg\n",
            "|->> Beginning tracking for bbox:[256 238  93  73]\n",
            "|->> Revisiting bbox: [256 238  93  73]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=5-th Action selection: 8/STOP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [256 238  93  73]\n",
            "         |->> Action Probabilities (Rounded): [0.0937 0.0914 0.0881 0.0905 0.0895 0.0925 0.0923 0.093  0.0924 0.0901\n",
            " 0.0866], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09368172 0.09135412 0.08814434 0.09047297 0.08948144 0.09254129\n",
            " 0.09227349 0.09298668 0.09238701 0.09007536 0.08660156], argmax=0\n",
            "         |->> Hit a STOP on the 5-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [256, 238,  93,  73] -> [256, 238,  93,  73] (Target was [276, 221,  89,  68])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [256, 238,  93,  73] -> [256, 238,  93,  73] w/ P(a|s)=0.09238701313734055 and iou=0.40831322658477737 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.381769]\n",
            "\u001b[31m>> Total frame loss: -2.3817689418792725\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 73 with src: [256, 238,  93,  73] and target: [282, 206,  82,  70]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0076.jpg\n",
            "|->> Beginning tracking for bbox:[256 238  93  73]\n",
            "   \u001b[33m|->> #0/t=5-th Action selection: 9/SCALE DOWN (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [257 239  90  70]\n",
            "         |->> Action Probabilities (Rounded): [0.0913 0.0914 0.0913 0.0898 0.0901 0.092  0.0919 0.0929 0.0922 0.0902\n",
            " 0.087 ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09129659 0.09138833 0.09125977 0.08975345 0.09007703 0.09202465\n",
            " 0.09192295 0.09293516 0.09217975 0.09016918 0.08699308], argmax=7\n",
            "   \u001b[33m|->> #1/t=6-th Action selection: 7/2X DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [257 243  90  70]\n",
            "         |->> Action Probabilities (Rounded): [0.091  0.0919 0.0885 0.0926 0.0907 0.093  0.0928 0.0939 0.0924 0.0846\n",
            " 0.0886], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09098429 0.091856   0.08845791 0.0925502  0.09072173 0.09301633\n",
            " 0.09284206 0.09390961 0.09242696 0.08460677 0.08862806], argmax=7\n",
            "|->> Revisiting bbox: [257 243  90  70]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [256, 238,  93,  73] -> [257, 243,  90,  70] (Target was [282, 206,  82,  70])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.005) for SCALE DOWN:bbox transition: [256, 238,  93,  73] -> [257, 239,  90,  70] w/ P(a|s)=0.09016918390989304 and iou=0.24961079398028022 and reward=-0.005422763066699671 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for 2X DOWN:bbox transition: [257, 239,  90,  70] -> [257, 243,  90,  70] w/ P(a|s)=0.0939096063375473 and iou=0.21677614957049016 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.01304753 -2.3654225 ]\n",
            "\u001b[31m>> Total frame loss: -2.378469944000244\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 74 with src: [257, 243,  90,  70] and target: [265, 181,  91,  69]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0077.jpg\n",
            "|->> Beginning tracking for bbox:[257 243  90  70]\n",
            "   \u001b[33m|->> #0/t=7-th Action selection: 6/DOWN (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [257 245  90  70]\n",
            "         |->> Action Probabilities (Rounded): [0.0907 0.092  0.0898 0.0916 0.0912 0.0928 0.0923 0.0921 0.0926 0.0868\n",
            " 0.088 ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.09067643 0.09198426 0.08982456 0.09162369 0.09124157 0.09278779\n",
            " 0.09231349 0.09211284 0.0926313  0.08679456 0.08800955], argmax=5\n",
            "   \u001b[33m|->> #1/t=8-th Action selection: 1/2X LEFT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [253 245  90  70]\n",
            "         |->> Action Probabilities (Rounded): [0.092  0.0924 0.0892 0.092  0.0929 0.0929 0.0905 0.0927 0.0916 0.086\n",
            " 0.0876], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.09203751 0.09238158 0.0892424  0.09201707 0.09290484 0.0929125\n",
            " 0.09053742 0.09272198 0.09161051 0.08603677 0.08759743], argmax=5\n",
            "   \u001b[33m|->> #2/t=9-th Action selection: 0/LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [251 245  90  70]\n",
            "         |->> Action Probabilities (Rounded): [0.0911 0.0893 0.0897 0.0916 0.0915 0.0927 0.0921 0.0927 0.0929 0.0877\n",
            " 0.0888], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09112184 0.08928534 0.08968929 0.09159561 0.09150447 0.09271002\n",
            " 0.09209904 0.09269673 0.09288257 0.08766393 0.08875113], argmax=8\n",
            "   \u001b[33m|->> #3/t=10-th Action selection: 10/SCALE UP (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [249 243  92  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0829 0.0893 0.0967 0.0934 0.0921 0.0937 0.0925 0.094  0.0922 0.0854\n",
            " 0.0877], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08294213 0.08931891 0.09665447 0.09341893 0.09208138 0.09369257\n",
            " 0.09249181 0.09403177 0.09224841 0.08539332 0.08772632], argmax=2\n",
            "   \u001b[33m|->> #4/t=11-th Action selection: 0/LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [247 243  92  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0914 0.0891 0.088  0.0948 0.0928 0.094  0.0935 0.094  0.0913 0.0879\n",
            " 0.0832], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09135844 0.08913323 0.08798004 0.09475911 0.09279631 0.09396069\n",
            " 0.09353648 0.09404866 0.09130214 0.08787632 0.08324863], argmax=3\n",
            "   \u001b[33m|->> #5/t=12-th Action selection: 10/SCALE UP (P(a|s) = 0.08500000089406967)\u001b[0m\n",
            "      |->> Bounding box moves to: [245 241  94  74]\n",
            "         |->> Action Probabilities (Rounded): [0.0807 0.0897 0.0999 0.0944 0.0928 0.0946 0.093  0.0954 0.0911 0.0838\n",
            " 0.0846], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08066504 0.0897389  0.09991875 0.0943829  0.09284305 0.09461027\n",
            " 0.09298466 0.09537426 0.09113123 0.08379434 0.08455656], argmax=2\n",
            "   \u001b[33m|->> #6/t=13-th Action selection: 1/2X LEFT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [241 241  94  74]\n",
            "         |->> Action Probabilities (Rounded): [0.0923 0.0889 0.0879 0.0951 0.0929 0.094  0.0937 0.0948 0.0909 0.0881\n",
            " 0.0815], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09229446 0.08891067 0.08793479 0.09514288 0.09285624 0.09395422\n",
            " 0.0936897  0.09475324 0.09087377 0.08807692 0.08151309], argmax=3\n",
            "   \u001b[33m|->> #7/t=14-th Action selection: 2/RIGHT (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [243 241  94  74]\n",
            "         |->> Action Probabilities (Rounded): [0.0882 0.0868 0.094  0.0944 0.0939 0.0947 0.0936 0.0948 0.0891 0.0858\n",
            " 0.0849], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08820698 0.08679435 0.09395257 0.09435944 0.09389687 0.09467664\n",
            " 0.09358604 0.09478516 0.08905703 0.08575933 0.08492562], argmax=7\n",
            "|->> Revisiting bbox: [243 241  94  74]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [257, 243,  90,  70] -> [243, 241,  94,  74] (Target was [265, 181,  91,  69])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.014) for DOWN:bbox transition: [257, 243,  90,  70] -> [257, 245,  90,  70] w/ P(a|s)=0.0923134908080101 and iou=0.03369216862519517 and reward=-0.014121242453522032 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.002) for 2X LEFT:bbox transition: [257, 245,  90,  70] -> [253, 245,  90,  70] w/ P(a|s)=0.09238158166408539 and iou=0.03199606202313562 and reward=-0.0016961066020595508 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.001) for LEFT:bbox transition: [253, 245,  90,  70] -> [251, 245,  90,  70] w/ P(a|s)=0.0911218449473381 and iou=0.031150094270022133 and reward=-0.0008459677531134843 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.012) for SCALE UP:bbox transition: [251, 245,  90,  70] -> [249, 243,  92,  72] w/ P(a|s)=0.08772632479667664 and iou=0.04300379920782475 and reward=0.01185370493780262 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (-0.001) for LEFT:bbox transition: [249, 243,  92,  72] -> [247, 243,  92,  72] w/ P(a|s)=0.09135843813419342 and iou=0.041824788050060555 and reward=-0.0011790111577641982 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (0.011) for SCALE UP:bbox transition: [247, 243,  92,  72] -> [245, 241,  94,  74] w/ P(a|s)=0.08455655723810196 and iou=0.052987508950592725 and reward=0.01116272090053217 and discount=1.0\n",
            "   |->> t=7 Diff-Reward (-0.003) for 2X LEFT:bbox transition: [245, 241,  94,  74] -> [241, 241,  94,  74] w/ P(a|s)=0.08891066908836365 and iou=0.049980166600555334 and reward=-0.003007342350037391 and discount=1.0\n",
            "   |->> t=8 Diff-Reward (-1.0) for RIGHT:bbox transition: [241, 241,  94,  74] -> [243, 241,  94,  74] w/ P(a|s)=0.09395256638526917 and iou=0.05148168745531104 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-3.3644781e-02 -4.0398338e-03 -2.0265644e-03  2.8846385e-02\n",
            " -2.8213321e-03  2.7575655e-02 -7.2781388e-03 -2.3649652e+00]\n",
            "\u001b[31m>> Total frame loss: -2.358353853225708\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 75 with src: [243, 241,  94,  74] and target: [242, 172,  87,  67]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0078.jpg\n",
            "|->> Beginning tracking for bbox:[243 241  94  74]\n",
            "|->> Revisiting bbox: [243 241  94  74]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=15-th Action selection: 8/STOP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [243 241  94  74]\n",
            "         |->> Action Probabilities (Rounded): [0.0979 0.0865 0.082  0.0942 0.0929 0.095  0.0945 0.0938 0.0907 0.0884\n",
            " 0.084 ], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09793056 0.08646511 0.08203809 0.09419473 0.09291133 0.09498924\n",
            " 0.09454458 0.09383292 0.09069802 0.08840822 0.08398719], argmax=0\n",
            "         |->> Hit a STOP on the 15-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [243, 241,  94,  74] -> [243, 241,  94,  74] (Target was [242, 172,  87,  67])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [243, 241,  94,  74] -> [243, 241,  94,  74] w/ P(a|s)=0.09069801867008209 and iou=0.0 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.4002197]\n",
            "\u001b[31m>> Total frame loss: -2.400219678878784\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 76 with src: [243, 241,  94,  74] and target: [216, 168,  87,  67]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0079.jpg\n",
            "|->> Beginning tracking for bbox:[243 241  94  74]\n",
            "   \u001b[33m|->> #0/t=15-th Action selection: 7/2X DOWN (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [243 245  94  74]\n",
            "         |->> Action Probabilities (Rounded): [0.0872 0.0876 0.0938 0.0919 0.0934 0.0943 0.0943 0.0948 0.0913 0.0865\n",
            " 0.085 ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08718763 0.08763781 0.09375355 0.09186199 0.0933999  0.09427955\n",
            " 0.09427763 0.09479421 0.0912988  0.0865417  0.08496725], argmax=7\n",
            "   \u001b[33m|->> #1/t=16-th Action selection: 3/2X RIGHT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [247 245  94  74]\n",
            "         |->> Action Probabilities (Rounded): [0.0918 0.088  0.0883 0.0927 0.0928 0.0945 0.0938 0.0941 0.0912 0.0877\n",
            " 0.0852], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.09178855 0.0879814  0.08833835 0.09271675 0.09275597 0.09448192\n",
            " 0.0937721  0.09410028 0.0911829  0.08767984 0.08520199], argmax=5\n",
            "   \u001b[33m|->> #2/t=17-th Action selection: 3/2X RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [251 245  94  74]\n",
            "         |->> Action Probabilities (Rounded): [0.0905 0.0879 0.0906 0.0919 0.092  0.0942 0.0942 0.0939 0.091  0.0878\n",
            " 0.0859], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.0904738  0.08793241 0.09062684 0.09188896 0.09204129 0.09420775\n",
            " 0.0942449  0.09391328 0.09104606 0.0877728  0.08585185], argmax=6\n",
            "   \u001b[33m|->> #3/t=18-th Action selection: 2/RIGHT (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [253 245  94  74]\n",
            "         |->> Action Probabilities (Rounded): [0.0932 0.0895 0.0883 0.0901 0.0925 0.0944 0.0928 0.0939 0.0915 0.0879\n",
            " 0.0859], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.09324474 0.08948249 0.08830855 0.09010793 0.09245622 0.09441181\n",
            " 0.09284187 0.09385797 0.09152115 0.08786396 0.08590342], argmax=5\n",
            "   \u001b[33m|->> #4/t=19-th Action selection: 4/UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [253 243  94  74]\n",
            "         |->> Action Probabilities (Rounded): [0.0977 0.0889 0.0809 0.0915 0.0922 0.0953 0.0939 0.094  0.092  0.088\n",
            " 0.0855], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09774102 0.08886544 0.0808909  0.09149042 0.09224305 0.09533688\n",
            " 0.09392777 0.09403596 0.09196356 0.08804084 0.08546419], argmax=0\n",
            "   \u001b[33m|->> #5/t=20-th Action selection: 2/RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [255 243  94  74]\n",
            "         |->> Action Probabilities (Rounded): [0.0899 0.0908 0.0905 0.0895 0.0909 0.0942 0.094  0.0945 0.0917 0.0874\n",
            " 0.0865], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08988952 0.0908446  0.09054541 0.08952245 0.09085638 0.09423397\n",
            " 0.0940167  0.09446517 0.09168863 0.08741283 0.08652437], argmax=7\n",
            "   \u001b[33m|->> #6/t=21-th Action selection: 1/2X LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [251 243  94  74]\n",
            "         |->> Action Probabilities (Rounded): [0.0997 0.091  0.0787 0.0903 0.0916 0.0944 0.0931 0.095  0.0907 0.0884\n",
            " 0.087 ], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09971214 0.0909659  0.07872859 0.0903343  0.09164364 0.09435662\n",
            " 0.09313729 0.09498738 0.09068666 0.08840118 0.08704624], argmax=0\n",
            "|->> Revisiting bbox: [255 243  94  74]. ACtion 3 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [243, 241,  94,  74] -> [251, 243,  94,  74] (Target was [216, 168,  87,  67])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X DOWN:bbox transition: [243, 241,  94,  74] -> [243, 245,  94,  74] w/ P(a|s)=0.09479420632123947 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for 2X RIGHT:bbox transition: [243, 245,  94,  74] -> [247, 245,  94,  74] w/ P(a|s)=0.0927167534828186 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X RIGHT:bbox transition: [247, 245,  94,  74] -> [251, 245,  94,  74] w/ P(a|s)=0.09188895672559738 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.0) for RIGHT:bbox transition: [251, 245,  94,  74] -> [253, 245,  94,  74] w/ P(a|s)=0.08830855041742325 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (0.0) for UP:bbox transition: [253, 245,  94,  74] -> [253, 243,  94,  74] w/ P(a|s)=0.09224305301904678 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (0.0) for RIGHT:bbox transition: [253, 243,  94,  74] -> [255, 243,  94,  74] w/ P(a|s)=0.0905454084277153 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=7 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [255, 243,  94,  74] -> [251, 243,  94,  74] w/ P(a|s)=0.09096589684486389 and iou=0.0 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.         0.         0.         0.         0.         0.\n",
            " -2.3972707]\n",
            "\u001b[31m>> Total frame loss: -2.397270679473877\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 77 with src: [251, 243,  94,  74] and target: [205, 167,  85,  68]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0080.jpg\n",
            "|->> Beginning tracking for bbox:[251 243  94  74]\n",
            "   \u001b[33m|->> #0/t=22-th Action selection: 3/2X RIGHT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [255 243  94  74]\n",
            "         |->> Action Probabilities (Rounded): [0.0875 0.0903 0.0914 0.0894 0.0918 0.094  0.094  0.0947 0.0906 0.0881\n",
            " 0.0882], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.0874816  0.09027985 0.09135986 0.08936006 0.09184423 0.093951\n",
            " 0.09402597 0.09470741 0.09061024 0.08814583 0.08823387], argmax=7\n",
            "   \u001b[33m|->> #1/t=23-th Action selection: 10/SCALE UP (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [253 241  96  76]\n",
            "         |->> Action Probabilities (Rounded): [0.0954 0.0906 0.0854 0.0881 0.0923 0.0935 0.0935 0.0945 0.0901 0.0882\n",
            " 0.0883], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09536452 0.09059578 0.08542274 0.08812771 0.0923457  0.09353772\n",
            " 0.09345931 0.09452917 0.09006404 0.0882232  0.08833009], argmax=0\n",
            "   \u001b[33m|->> #2/t=24-th Action selection: 7/2X DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [253 245  96  76]\n",
            "         |->> Action Probabilities (Rounded): [0.0925 0.09   0.0875 0.0889 0.0934 0.0945 0.0948 0.0943 0.0896 0.0907\n",
            " 0.0837], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09252849 0.0900273  0.08753583 0.08887497 0.09339174 0.09445287\n",
            " 0.09482194 0.09429839 0.08959135 0.09073197 0.08374511], argmax=6\n",
            "   \u001b[33m|->> #3/t=25-th Action selection: 9/SCALE DOWN (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [254 246  93  73]\n",
            "         |->> Action Probabilities (Rounded): [0.0945 0.0906 0.0867 0.0884 0.0927 0.0936 0.0936 0.0922 0.0909 0.0904\n",
            " 0.0862], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09451304 0.09063065 0.08673462 0.08843621 0.09267123 0.09363884\n",
            " 0.09359634 0.09220702 0.09089982 0.09043813 0.08623412], argmax=0\n",
            "   \u001b[33m|->> #4/t=26-th Action selection: 0/LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [252 246  93  73]\n",
            "         |->> Action Probabilities (Rounded): [0.0913 0.0898 0.0874 0.0903 0.093  0.0931 0.095  0.0936 0.092  0.0864\n",
            " 0.0881], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.0912807  0.08980224 0.08741032 0.0903118  0.09304481 0.09307972\n",
            " 0.09498867 0.09364786 0.09196919 0.08635905 0.08810566], argmax=6\n",
            "   \u001b[33m|->> #5/t=27-th Action selection: 10/SCALE UP (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [250 244  95  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0852 0.091  0.0945 0.0914 0.0929 0.0947 0.0938 0.0935 0.0908 0.0853\n",
            " 0.087 ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.08516929 0.09097669 0.09454118 0.09140097 0.09285516 0.09466904\n",
            " 0.09378167 0.09352652 0.09080322 0.08525912 0.08701719], argmax=5\n",
            "   \u001b[33m|->> #6/t=28-th Action selection: 5/2X UP (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [250 240  95  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0921 0.0903 0.0859 0.0933 0.0935 0.0943 0.0945 0.0942 0.0917 0.0874\n",
            " 0.0828], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09213199 0.09028481 0.08585145 0.09333435 0.09352051 0.09429365\n",
            " 0.09447386 0.0942159  0.09168733 0.08738897 0.08281717], argmax=6\n",
            "   \u001b[33m|->> #7/t=29-th Action selection: 0/LEFT (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [248 240  95  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0878 0.0907 0.0915 0.092  0.093  0.0928 0.0938 0.0941 0.0919 0.0872\n",
            " 0.0852], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08780286 0.0907207  0.09151227 0.09199267 0.09300854 0.09281732\n",
            " 0.0937891  0.09409067 0.09185194 0.08724044 0.08517352], argmax=7\n",
            "   \u001b[33m|->> #8/t=30-th Action selection: 5/2X UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [248 236  95  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0837 0.0896 0.0954 0.0938 0.0923 0.0927 0.0948 0.0945 0.0919 0.0869\n",
            " 0.0845], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08366884 0.08955558 0.09537038 0.09384365 0.09227034 0.09273115\n",
            " 0.09484532 0.0944675  0.09186783 0.08685166 0.08452769], argmax=2\n",
            "   \u001b[33m|->> #9/t=31-th Action selection: 10/SCALE UP (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [246 234  97  77]\n",
            "         |->> Action Probabilities (Rounded): [0.0922 0.0888 0.0882 0.0937 0.0923 0.0911 0.0941 0.0938 0.0917 0.0875\n",
            " 0.0866], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09222281 0.08883296 0.08824417 0.0937233  0.09229226 0.09107246\n",
            " 0.09410012 0.0937677  0.09165946 0.08751771 0.08656704], argmax=6\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [251, 243,  94,  74] -> [246, 234,  97,  77] (Target was [205, 167,  85,  68])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X RIGHT:bbox transition: [251, 243,  94,  74] -> [255, 243,  94,  74] w/ P(a|s)=0.0893600583076477 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for SCALE UP:bbox transition: [255, 243,  94,  74] -> [253, 241,  96,  76] w/ P(a|s)=0.08833009004592896 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X DOWN:bbox transition: [253, 241,  96,  76] -> [253, 245,  96,  76] w/ P(a|s)=0.09429838508367538 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.0) for SCALE DOWN:bbox transition: [253, 245,  96,  76] -> [254, 246,  93,  73] w/ P(a|s)=0.09043813496828079 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (0.0) for LEFT:bbox transition: [254, 246,  93,  73] -> [252, 246,  93,  73] w/ P(a|s)=0.09128069877624512 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (0.0) for SCALE UP:bbox transition: [252, 246,  93,  73] -> [250, 244,  95,  75] w/ P(a|s)=0.08701719343662262 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=7 Diff-Reward (0.0) for 2X UP:bbox transition: [250, 244,  95,  75] -> [250, 240,  95,  75] w/ P(a|s)=0.09429364651441574 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=8 Diff-Reward (0.0) for LEFT:bbox transition: [250, 240,  95,  75] -> [248, 240,  95,  75] w/ P(a|s)=0.08780285716056824 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=9 Diff-Reward (0.0) for 2X UP:bbox transition: [248, 240,  95,  75] -> [248, 236,  95,  75] w/ P(a|s)=0.09273114800453186 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=10 Diff-Reward (-1.0) for SCALE UP:bbox transition: [248, 236,  95,  75] -> [246, 234,  97,  77] w/ P(a|s)=0.08656703680753708 and iou=0.0033320711851571373 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.        -2.4468362]\n",
            "\u001b[31m>> Total frame loss: -2.446836233139038\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 78 with src: [246, 234,  97,  77] and target: [211, 168,  83,  69]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0081.jpg\n",
            "|->> Beginning tracking for bbox:[246 234  97  77]\n",
            "   \u001b[33m|->> #0/t=32-th Action selection: 7/2X DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [246 238  97  77]\n",
            "         |->> Action Probabilities (Rounded): [0.0886 0.0903 0.092  0.0942 0.0927 0.0917 0.0939 0.0945 0.0913 0.0894\n",
            " 0.0814], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08863435 0.0902956  0.09195838 0.0942124  0.09267239 0.09174895\n",
            " 0.09386648 0.09447575 0.09134696 0.0894032  0.08138546], argmax=7\n",
            "   \u001b[33m|->> #1/t=33-th Action selection: 4/UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [246 236  97  77]\n",
            "         |->> Action Probabilities (Rounded): [0.092  0.0904 0.0901 0.0942 0.092  0.091  0.0933 0.0922 0.0919 0.0885\n",
            " 0.0845], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09195216 0.09037205 0.09008095 0.09418364 0.09197459 0.09100775\n",
            " 0.09325668 0.09222428 0.09193215 0.08853479 0.08448099], argmax=3\n",
            "   \u001b[33m|->> #2/t=34-th Action selection: 1/2X LEFT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [242 236  97  77]\n",
            "         |->> Action Probabilities (Rounded): [0.092  0.0901 0.0914 0.0944 0.0898 0.091  0.0932 0.0928 0.0926 0.0879\n",
            " 0.0847], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09204538 0.09012537 0.09140201 0.09443381 0.08983208 0.09095768\n",
            " 0.09323198 0.09275294 0.09261789 0.08786353 0.08473732], argmax=3\n",
            "   \u001b[33m|->> #3/t=35-th Action selection: 5/2X UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [242 232  97  77]\n",
            "         |->> Action Probabilities (Rounded): [0.0919 0.0881 0.0911 0.0939 0.0911 0.0917 0.0929 0.0928 0.0912 0.0886\n",
            " 0.0866], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09194986 0.08814479 0.09106108 0.09392214 0.09109578 0.09168857\n",
            " 0.09290472 0.09284187 0.09116674 0.08864801 0.08657643], argmax=3\n",
            "   \u001b[33m|->> #4/t=36-th Action selection: 5/2X UP (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [242 228  97  77]\n",
            "         |->> Action Probabilities (Rounded): [0.092  0.0876 0.0917 0.0932 0.091  0.0895 0.094  0.0935 0.0914 0.0904\n",
            " 0.0858], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09204744 0.0875654  0.09169614 0.09323252 0.0910129  0.08946413\n",
            " 0.0939607  0.09347028 0.09135927 0.09042916 0.08576207], argmax=6\n",
            "   \u001b[33m|->> #5/t=37-th Action selection: 4/UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [242 226  97  77]\n",
            "         |->> Action Probabilities (Rounded): [0.0902 0.0887 0.0918 0.0939 0.0912 0.0884 0.0938 0.0924 0.092  0.0907\n",
            " 0.0868], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09018803 0.08872864 0.09183182 0.09385327 0.09123681 0.08839417\n",
            " 0.09382808 0.09243099 0.092016   0.09067039 0.08682171], argmax=3\n",
            "   \u001b[33m|->> #6/t=38-th Action selection: 5/2X UP (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [242 222  97  77]\n",
            "         |->> Action Probabilities (Rounded): [0.0923 0.0884 0.0921 0.0931 0.0892 0.088  0.0943 0.0929 0.0922 0.09\n",
            " 0.0874], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09233267 0.08841094 0.09213921 0.09311946 0.08920834 0.08802345\n",
            " 0.09428941 0.09292224 0.09215237 0.08998546 0.0874165 ], argmax=6\n",
            "   \u001b[33m|->> #7/t=39-th Action selection: 5/2X UP (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [242 218  97  77]\n",
            "         |->> Action Probabilities (Rounded): [0.0923 0.0886 0.0916 0.0935 0.0899 0.0875 0.0931 0.0929 0.0922 0.0903\n",
            " 0.0881], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09228738 0.0885824  0.09158824 0.09346748 0.08993023 0.08745374\n",
            " 0.09310937 0.09294932 0.09219757 0.09030135 0.08813285], argmax=3\n",
            "   \u001b[33m|->> #8/t=40-th Action selection: 0/LEFT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [240 218  97  77]\n",
            "         |->> Action Probabilities (Rounded): [0.0902 0.0898 0.0922 0.0932 0.0897 0.0854 0.0939 0.092  0.0918 0.0926\n",
            " 0.0891], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09017377 0.08980165 0.09216632 0.09323517 0.08970361 0.08541974\n",
            " 0.09391427 0.09202211 0.09184771 0.09264366 0.08907203], argmax=6\n",
            "   \u001b[33m|->> #9/t=41-th Action selection: 9/SCALE DOWN (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [241 219  94  74]\n",
            "         |->> Action Probabilities (Rounded): [0.0834 0.09   0.0978 0.0943 0.09   0.0878 0.0934 0.0923 0.0923 0.0897\n",
            " 0.089 ], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08339716 0.09002941 0.0978459  0.09429432 0.08998334 0.08782551\n",
            " 0.0933631  0.09228883 0.09227394 0.08968363 0.08901485], argmax=2\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [246, 234,  97,  77] -> [241, 219,  94,  74] (Target was [211, 168,  83,  69])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.011) for 2X DOWN:bbox transition: [246, 234,  97,  77] -> [246, 238,  97,  77] w/ P(a|s)=0.09447575360536575 and iou=0.0 and reward=-0.011032791909285933 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.004) for UP:bbox transition: [246, 238,  97,  77] -> [246, 236,  97,  77] w/ P(a|s)=0.09197458624839783 and iou=0.0036507453605111044 and reward=0.0036507453605111044 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X LEFT:bbox transition: [246, 236,  97,  77] -> [242, 236,  97,  77] w/ P(a|s)=0.09012536704540253 and iou=0.003956177723676202 and reward=0.00030543236316509783 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.016) for 2X UP:bbox transition: [242, 236,  97,  77] -> [242, 232,  97,  77] w/ P(a|s)=0.09168857336044312 and iou=0.02009894867037724 and reward=0.016142770946701038 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (0.017) for 2X UP:bbox transition: [242, 232,  97,  77] -> [242, 228,  97,  77] w/ P(a|s)=0.08946412801742554 and iou=0.036769327467001886 and reward=0.016670378796624644 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (0.009) for UP:bbox transition: [242, 228,  97,  77] -> [242, 226,  97,  77] w/ P(a|s)=0.09123681485652924 and iou=0.04531051964512041 and reward=0.008541192178118523 and discount=1.0\n",
            "   |->> t=7 Diff-Reward (0.018) for 2X UP:bbox transition: [242, 226,  97,  77] -> [242, 222,  97,  77] w/ P(a|s)=0.08802345395088196 and iou=0.06282216494845361 and reward=0.017511645303333198 and discount=1.0\n",
            "   |->> t=8 Diff-Reward (0.018) for 2X UP:bbox transition: [242, 222,  97,  77] -> [242, 218,  97,  77] w/ P(a|s)=0.08745373785495758 and iou=0.0809305373525557 and reward=0.018108372404102097 and discount=1.0\n",
            "   |->> t=9 Diff-Reward (0.003) for LEFT:bbox transition: [242, 218,  97,  77] -> [240, 218,  97,  77] w/ P(a|s)=0.09017376601696014 and iou=0.08430566967953985 and reward=0.003375132326984151 and discount=1.0\n",
            "   |->> t=10 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [240, 218,  97,  77] -> [241, 219,  94,  74] w/ P(a|s)=0.08968362957239151 and iou=0.08133685736209395 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.6030904e-02  8.7115653e-03  7.3503942e-04  3.8570851e-02\n",
            "  4.0240917e-02  2.0450149e-02  4.2555958e-02  4.4123679e-02\n",
            "  8.1206253e-03 -2.4114671e+00]\n",
            "\u001b[31m>> Total frame loss: -2.2339892387390137\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 79 with src: [241, 219,  94,  74] and target: [224, 162,  83,  67]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0082.jpg\n",
            "|->> Beginning tracking for bbox:[241 219  94  74]\n",
            "   \u001b[33m|->> #0/t=42-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08399999886751175)\u001b[0m\n",
            "      |->> Bounding box moves to: [242 220  91  71]\n",
            "         |->> Action Probabilities (Rounded): [0.0923 0.0899 0.0889 0.0942 0.0911 0.0886 0.0937 0.0936 0.0922 0.0843\n",
            " 0.0913], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09232678 0.08989321 0.0888611  0.09417829 0.0910707  0.08861414\n",
            " 0.0937227  0.09356239 0.09220384 0.08428642 0.09128034], argmax=3\n",
            "   \u001b[33m|->> #1/t=43-th Action selection: 2/RIGHT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [244 220  91  71]\n",
            "         |->> Action Probabilities (Rounded): [0.0873 0.0904 0.0931 0.0947 0.0915 0.0896 0.0944 0.0947 0.0915 0.0816\n",
            " 0.0911], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08734354 0.09042624 0.09313414 0.0946607  0.09148867 0.08964514\n",
            " 0.09436294 0.09473004 0.09147821 0.0815963  0.0911341 ], argmax=7\n",
            "   \u001b[33m|->> #2/t=44-th Action selection: 2/RIGHT (P(a|s) = 0.0820000022649765)\u001b[0m\n",
            "      |->> Bounding box moves to: [246 220  91  71]\n",
            "         |->> Action Probabilities (Rounded): [0.0978 0.0896 0.0819 0.0952 0.0912 0.0898 0.0948 0.0948 0.0921 0.0826\n",
            " 0.0903], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09779217 0.08963189 0.08193681 0.09518031 0.09116765 0.08975402\n",
            " 0.09482393 0.09477206 0.0921023  0.08258677 0.09025213], argmax=0\n",
            "|->> Revisiting bbox: [242 220  91  71]. ACtion 1 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [241, 219,  94,  74] -> [246, 220,  91,  71] (Target was [224, 162,  83,  67])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.005) for SCALE DOWN:bbox transition: [241, 219,  94,  74] -> [242, 220,  91,  71] w/ P(a|s)=0.08428642153739929 and iou=0.051149777039433415 and reward=-0.004513544205400857 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.002) for RIGHT:bbox transition: [242, 220,  91,  71] -> [244, 220,  91,  71] w/ P(a|s)=0.09313414245843887 and iou=0.049498035792230465 and reward=-0.0016517412472029508 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-1.0) for RIGHT:bbox transition: [244, 220,  91,  71] -> [246, 220,  91,  71] w/ P(a|s)=0.08193681389093399 and iou=0.04785147738167873 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.01116441 -0.00392076 -2.501807  ]\n",
            "\u001b[31m>> Total frame loss: -2.516892194747925\u001b[0m\n",
            "Final bounding box: [246 220  91  71] reached in 45 timesteps (originating from [252 242  91  71]). Target was [224 162  83  67]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 80 in t=45 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[31m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 8.029340744018555\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 3.0560951232910156\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/BlurCar3\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0073.jpg\n",
            "Starting bounding box=adnet_datasets/OTB/BlurCar3/img/0083.jpg for adnet_datasets/OTB/BlurCar3's frames (index: 0)\n",
            "src:adnet_datasets/OTB/BlurCar3/img/0073.jpg\n",
            "target:adnet_datasets/OTB/BlurCar3/img/0083.jpg.\n",
            "\u001b[34m>> Attempting to reach frame 71 with src: [261, 227,  92,  72] and target: [271, 222,  91,  70]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0074.jpg\n",
            "|->> Beginning tracking for bbox:[261 227  92  72]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 9/SCALE DOWN (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [262 228  89  69]\n",
            "         |->> Action Probabilities (Rounded): [0.091  0.0907 0.0909 0.091  0.0907 0.0909 0.0909 0.0909 0.0909 0.0911\n",
            " 0.0911], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.09098688 0.09066335 0.09085814 0.0909551  0.09074721 0.09090602\n",
            " 0.0909286  0.09090043 0.09087465 0.09112447 0.09105514], argmax=9\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 5/2X UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [262 224  89  69]\n",
            "         |->> Action Probabilities (Rounded): [0.0905 0.091  0.0909 0.0918 0.0911 0.0914 0.0915 0.0916 0.0918 0.086\n",
            " 0.0924], argmax=10\n",
            "         |->> Action Probabilities (RAW): [0.09051448 0.09096995 0.09092765 0.09177803 0.0910799  0.09139461\n",
            " 0.09151442 0.09161811 0.09175755 0.086013   0.0924323 ], argmax=10\n",
            "|->> Revisiting bbox: [262 224  89  69]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [261, 227,  92,  72] -> [262, 224,  89,  69] (Target was [271, 222,  91,  70])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.003) for SCALE DOWN:bbox transition: [261, 227,  92,  72] -> [262, 228,  89,  69] w/ P(a|s)=0.09112446755170822 and iou=0.6927344067108646 and reward=-0.002724883477026818 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for 2X UP:bbox transition: [262, 228,  89,  69] -> [262, 224,  89,  69] w/ P(a|s)=0.09139461070299149 and iou=0.7693395559326828 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.00652754  2.3925688 ]\n",
            "\u001b[92m>> Total frame loss: 2.3860414028167725\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 72 with src: [262, 224,  89,  69] and target: [276, 221,  89,  68]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0075.jpg\n",
            "|->> Beginning tracking for bbox:[262 224  89  69]\n",
            "   \u001b[33m|->> #0/t=3-th Action selection: 1/2X LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [258 224  89  69]\n",
            "         |->> Action Probabilities (Rounded): [0.0913 0.0909 0.0912 0.0916 0.0911 0.0898 0.0916 0.0916 0.0919 0.0881\n",
            " 0.0909], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09128141 0.09085438 0.09115475 0.09164064 0.09111383 0.08983303\n",
            " 0.0916243  0.09157261 0.09189985 0.08809157 0.09093365], argmax=8\n",
            "|->> Revisiting bbox: [262 224  89  69]. ACtion 3 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [262, 224,  89,  69] -> [258, 224,  89,  69] (Target was [276, 221,  89,  68])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [262, 224,  89,  69] -> [258, 224,  89,  69] w/ P(a|s)=0.09085437655448914 and iou=0.6089997360781209 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.3984973]\n",
            "\u001b[31m>> Total frame loss: -2.3984973430633545\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 73 with src: [258, 224,  89,  69] and target: [282, 206,  82,  70]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0076.jpg\n",
            "|->> Beginning tracking for bbox:[258 224  89  69]\n",
            "   \u001b[33m|->> #0/t=4-th Action selection: 10/SCALE UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [256 222  91  71]\n",
            "         |->> Action Probabilities (Rounded): [0.0904 0.0887 0.0917 0.0923 0.0912 0.0899 0.0923 0.0916 0.0921 0.0877\n",
            " 0.0919], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.0903832  0.08871326 0.0917316  0.09232985 0.09118345 0.0899439\n",
            " 0.09231351 0.09161414 0.09209987 0.08774672 0.09194054], argmax=3\n",
            "   \u001b[33m|->> #1/t=5-th Action selection: 0/LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [254 222  91  71]\n",
            "         |->> Action Probabilities (Rounded): [0.0909 0.089  0.0911 0.0917 0.0916 0.0905 0.0925 0.0927 0.0933 0.0907\n",
            " 0.086 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09090994 0.08904471 0.09105317 0.09165452 0.09157807 0.09051428\n",
            " 0.09248228 0.09269912 0.09333278 0.09073915 0.08599196], argmax=8\n",
            "   \u001b[33m|->> #2/t=6-th Action selection: 6/DOWN (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [254 224  91  71]\n",
            "         |->> Action Probabilities (Rounded): [0.083  0.0891 0.0978 0.0936 0.0912 0.092  0.0927 0.0937 0.0929 0.0866\n",
            " 0.0873], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08297134 0.08912578 0.09780192 0.09358753 0.0912446  0.09199324\n",
            " 0.09274464 0.09371378 0.09294126 0.08657814 0.08729779], argmax=2\n",
            "   \u001b[33m|->> #3/t=7-th Action selection: 5/2X UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [254 220  91  71]\n",
            "         |->> Action Probabilities (Rounded): [0.0925 0.0891 0.0893 0.0935 0.0926 0.0915 0.0906 0.0935 0.0915 0.0887\n",
            " 0.0872], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09247757 0.08910026 0.0892816  0.09354321 0.09256913 0.09151275\n",
            " 0.09057091 0.09348173 0.09154725 0.08868584 0.08722968], argmax=3\n",
            "   \u001b[33m|->> #4/t=8-th Action selection: 10/SCALE UP (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [252 218  93  73]\n",
            "         |->> Action Probabilities (Rounded): [0.0883 0.0889 0.0945 0.0926 0.0909 0.0904 0.0927 0.0937 0.0918 0.0878\n",
            " 0.0883], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.0882962  0.08888069 0.09451276 0.09259686 0.09091816 0.09042234\n",
            " 0.09271675 0.09368351 0.09179693 0.08784195 0.08833382], argmax=2\n",
            "   \u001b[33m|->> #5/t=9-th Action selection: 10/SCALE UP (P(a|s) = 0.08399999886751175)\u001b[0m\n",
            "      |->> Bounding box moves to: [250 216  95  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0909 0.0897 0.0902 0.094  0.0923 0.0912 0.0925 0.0932 0.0917 0.0907\n",
            " 0.0835], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09085239 0.08968382 0.09022898 0.09401634 0.09233616 0.09122773\n",
            " 0.09245142 0.09323444 0.09173562 0.0907091  0.08352408], argmax=3\n",
            "   \u001b[33m|->> #6/t=10-th Action selection: 10/SCALE UP (P(a|s) = 0.07999999821186066)\u001b[0m\n",
            "      |->> Bounding box moves to: [248 214  97  77]\n",
            "         |->> Action Probabilities (Rounded): [0.0897 0.0897 0.091  0.0943 0.0921 0.0921 0.0933 0.0947 0.0921 0.0906\n",
            " 0.0803], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08969128 0.08966302 0.0910383  0.09429756 0.09210776 0.0921388\n",
            " 0.09326035 0.09473579 0.09212191 0.0906276  0.08031762], argmax=7\n",
            "   \u001b[33m|->> #7/t=11-th Action selection: 3/2X RIGHT (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [252 214  97  77]\n",
            "         |->> Action Probabilities (Rounded): [0.0899 0.0902 0.0899 0.0939 0.0932 0.0928 0.0938 0.0945 0.0932 0.0916\n",
            " 0.077 ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08989631 0.09024029 0.08991712 0.09391204 0.09316285 0.09280753\n",
            " 0.09384808 0.09445326 0.09318116 0.09160928 0.0769721 ], argmax=7\n",
            "   \u001b[33m|->> #8/t=12-th Action selection: 4/UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [252 212  97  77]\n",
            "         |->> Action Probabilities (Rounded): [0.0897 0.0903 0.0907 0.0922 0.0926 0.0925 0.0937 0.0937 0.0921 0.0926\n",
            " 0.0798], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08970828 0.09029672 0.09074485 0.09224617 0.09261206 0.09246868\n",
            " 0.09374005 0.093747   0.09211478 0.09256816 0.07975329], argmax=7\n",
            "   \u001b[33m|->> #9/t=13-th Action selection: 7/2X DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [252 216  97  77]\n",
            "         |->> Action Probabilities (Rounded): [0.0909 0.0899 0.0899 0.0922 0.0919 0.0927 0.094  0.0943 0.0918 0.0921\n",
            " 0.0803], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09087227 0.08989099 0.0898921  0.09216777 0.09191296 0.09273095\n",
            " 0.09397425 0.09434798 0.09181138 0.09209573 0.08030368], argmax=7\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [258, 224,  89,  69] -> [252, 216,  97,  77] (Target was [282, 206,  82,  70])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.006) for SCALE UP:bbox transition: [258, 224,  89,  69] -> [256, 222,  91,  71] w/ P(a|s)=0.09194054454565048 and iou=0.4038660683465654 and reward=0.006265786026838305 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.017) for LEFT:bbox transition: [256, 222,  91,  71] -> [254, 222,  91,  71] w/ P(a|s)=0.090909942984581 and iou=0.38663484486873506 and reward=-0.01723122347783035 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.02) for DOWN:bbox transition: [254, 222,  91,  71] -> [254, 224,  91,  71] w/ P(a|s)=0.09274464100599289 and iou=0.36705882352941177 and reward=-0.01957602133932329 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.04) for 2X UP:bbox transition: [254, 224,  91,  71] -> [254, 220,  91,  71] w/ P(a|s)=0.0915127545595169 and iou=0.4067796610169492 and reward=0.03972083748753741 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (0.005) for SCALE UP:bbox transition: [254, 220,  91,  71] -> [252, 218,  93,  73] w/ P(a|s)=0.08833381533622742 and iou=0.4117183098591549 and reward=0.0049386488422057395 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (0.004) for SCALE UP:bbox transition: [252, 218,  93,  73] -> [250, 216,  95,  75] w/ P(a|s)=0.08352407813072205 and iou=0.4160704457897633 and reward=0.004352135930608403 and discount=1.0\n",
            "   |->> t=7 Diff-Reward (0.004) for SCALE UP:bbox transition: [250, 216,  95,  75] -> [248, 214,  97,  77] w/ P(a|s)=0.08031762391328812 and iou=0.4198645598194131 and reward=0.0037941140296497977 and discount=1.0\n",
            "   |->> t=8 Diff-Reward (0.039) for 2X RIGHT:bbox transition: [248, 214,  97,  77] -> [252, 214,  97,  77] w/ P(a|s)=0.0939120426774025 and iou=0.4587520706791828 and reward=0.03888751085976966 and discount=1.0\n",
            "   |->> t=9 Diff-Reward (0.022) for UP:bbox transition: [252, 214,  97,  77] -> [252, 212,  97,  77] w/ P(a|s)=0.09261205792427063 and iou=0.4806636027351194 and reward=0.0219115320559366 and discount=1.0\n",
            "   |->> t=10 Diff-Reward (-1.0) for 2X DOWN:bbox transition: [252, 212,  97,  77] -> [252, 216,  97,  77] w/ P(a|s)=0.0943479835987091 and iou=0.43747959516813584 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.01495401 -0.04131851 -0.04654992  0.09498352  0.01198429  0.0108047\n",
            "  0.00956787  0.09198439  0.05213489 -2.3607655 ]\n",
            "\u001b[31m>> Total frame loss: -2.162220001220703\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 74 with src: [252, 216,  97,  77] and target: [265, 181,  91,  69]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0077.jpg\n",
            "|->> Beginning tracking for bbox:[252 216  97  77]\n",
            "   \u001b[33m|->> #0/t=14-th Action selection: 10/SCALE UP (P(a|s) = 0.0820000022649765)\u001b[0m\n",
            "      |->> Bounding box moves to: [250 214  99  79]\n",
            "         |->> Action Probabilities (Rounded): [0.0922 0.0913 0.0894 0.0919 0.0917 0.0932 0.0931 0.0922 0.0905 0.0924\n",
            " 0.0821], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.09223478 0.09125237 0.0894393  0.09191781 0.09169757 0.09320698\n",
            " 0.09312619 0.09218265 0.0905052  0.09236383 0.08207329], argmax=5\n",
            "   \u001b[33m|->> #1/t=15-th Action selection: 10/SCALE UP (P(a|s) = 0.07900000363588333)\u001b[0m\n",
            "      |->> Bounding box moves to: [248 212 101  81]\n",
            "         |->> Action Probabilities (Rounded): [0.0912 0.0913 0.0883 0.0923 0.0923 0.0925 0.0939 0.0931 0.0917 0.0943\n",
            " 0.079 ], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.09123195 0.09128411 0.08830892 0.09234608 0.09232391 0.09253729\n",
            " 0.09391466 0.09305103 0.0917234  0.09431068 0.07896803], argmax=9\n",
            "   \u001b[33m|->> #2/t=16-th Action selection: 1/2X LEFT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [242 212 101  81]\n",
            "         |->> Action Probabilities (Rounded): [0.0899 0.093  0.0877 0.0925 0.093  0.0926 0.0932 0.0932 0.0928 0.0948\n",
            " 0.0771], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.08987262 0.09304583 0.08771344 0.09254362 0.09304889 0.09262142\n",
            " 0.09319826 0.09318107 0.09281898 0.09483755 0.07711831], argmax=9\n",
            "   \u001b[33m|->> #3/t=17-th Action selection: 4/UP (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [242 210 101  81]\n",
            "         |->> Action Probabilities (Rounded): [0.089  0.0892 0.089  0.0935 0.0935 0.0925 0.0931 0.0933 0.0929 0.0945\n",
            " 0.0795], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.08903011 0.08921173 0.08896834 0.09349708 0.09354741 0.09247232\n",
            " 0.09306706 0.09332148 0.09289168 0.0944985  0.0794943 ], argmax=9\n",
            "   \u001b[33m|->> #4/t=18-th Action selection: 3/2X RIGHT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [248 210 101  81]\n",
            "         |->> Action Probabilities (Rounded): [0.0905 0.0892 0.0897 0.0927 0.0915 0.093  0.0944 0.093  0.0915 0.094\n",
            " 0.0804], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09051471 0.08922794 0.08969286 0.09268168 0.09149721 0.0930067\n",
            " 0.0943936  0.09304343 0.09151728 0.0940281  0.08039639], argmax=6\n",
            "   \u001b[33m|->> #5/t=19-th Action selection: 4/UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [248 208 101  81]\n",
            "         |->> Action Probabilities (Rounded): [0.0907 0.0901 0.0883 0.0903 0.0926 0.0929 0.0935 0.0938 0.0908 0.0942\n",
            " 0.0828], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.09074826 0.09006795 0.08833814 0.09031581 0.0925999  0.09287107\n",
            " 0.09345786 0.09377859 0.09081633 0.09416626 0.08283982], argmax=9\n",
            "|->> Revisiting bbox: [248 210 101  81]. ACtion 6 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [252, 216,  97,  77] -> [248, 208, 101,  81] (Target was [265, 181,  91,  69])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.011) for SCALE UP:bbox transition: [252, 216,  97,  77] -> [250, 214,  99,  79] w/ P(a|s)=0.08207329362630844 and iou=0.27302275189599134 and reward=0.010811954980824268 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.01) for SCALE UP:bbox transition: [250, 214,  99,  79] -> [248, 212, 101,  81] w/ P(a|s)=0.07896802574396133 and iou=0.2832800851970181 and reward=0.010257333301026739 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.025) for 2X LEFT:bbox transition: [248, 212, 101,  81] -> [242, 212, 101,  81] w/ P(a|s)=0.09304583072662354 and iou=0.2578288100208768 and reward=-0.025451275176141264 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.017) for UP:bbox transition: [242, 212, 101,  81] -> [242, 210, 101,  81] w/ P(a|s)=0.09354741126298904 and iou=0.2751322751322751 and reward=0.017303465111398297 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (0.028) for 2X RIGHT:bbox transition: [242, 210, 101,  81] -> [248, 210, 101,  81] w/ P(a|s)=0.09268168359994888 and iou=0.3027027027027027 and reward=0.027570427570427603 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (-1.0) for UP:bbox transition: [248, 210, 101,  81] -> [248, 208, 101,  81] w/ P(a|s)=0.09259989857673645 and iou=0.3227222832052689 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.02703143  0.02604042 -0.0604382   0.04099688  0.06557859 -2.3794672 ]\n",
            "\u001b[31m>> Total frame loss: -2.2802581787109375\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 75 with src: [248, 208, 101,  81] and target: [242, 172,  87,  67]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0078.jpg\n",
            "|->> Beginning tracking for bbox:[248 208 101  81]\n",
            "   \u001b[33m|->> #0/t=20-th Action selection: 1/2X LEFT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [242 208 101  81]\n",
            "         |->> Action Probabilities (Rounded): [0.0918 0.0898 0.0879 0.0908 0.0902 0.0927 0.0943 0.0939 0.0913 0.093\n",
            " 0.0844], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09175491 0.08975992 0.08792701 0.09077228 0.09017275 0.0926809\n",
            " 0.09426473 0.09391987 0.09134786 0.09297843 0.08442137], argmax=6\n",
            "   \u001b[33m|->> #1/t=21-th Action selection: 0/LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [239 208 101  81]\n",
            "         |->> Action Probabilities (Rounded): [0.0913 0.0875 0.0886 0.0914 0.0916 0.0919 0.0932 0.0937 0.0917 0.0924\n",
            " 0.0866], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09132323 0.08750103 0.08862701 0.0913931  0.0916106  0.09194366\n",
            " 0.09317812 0.09368312 0.09171893 0.09241571 0.0866055 ], argmax=7\n",
            "   \u001b[33m|->> #2/t=22-th Action selection: 4/UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [239 206 101  81]\n",
            "         |->> Action Probabilities (Rounded): [0.0831 0.088  0.0957 0.0919 0.0917 0.0931 0.0941 0.0939 0.0908 0.0911\n",
            " 0.0865], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08314417 0.08800228 0.09570689 0.09194589 0.09173169 0.09308162\n",
            " 0.09406856 0.09385604 0.09083334 0.09113358 0.08649598], argmax=2\n",
            "   \u001b[33m|->> #3/t=23-th Action selection: 4/UP (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [239 204 101  81]\n",
            "         |->> Action Probabilities (Rounded): [0.0923 0.0877 0.0877 0.0931 0.0904 0.093  0.0943 0.0941 0.0904 0.0905\n",
            " 0.0866], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09230456 0.08769558 0.08766466 0.09305578 0.09038684 0.09295364\n",
            " 0.09426942 0.09413176 0.09036883 0.09054308 0.08662578], argmax=6\n",
            "|->> Revisiting bbox: [239 208 101  81]. ACtion 7 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [248, 208, 101,  81] -> [239, 204, 101,  81] (Target was [242, 172,  87,  67])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.02) for 2X LEFT:bbox transition: [248, 208, 101,  81] -> [242, 208, 101,  81] w/ P(a|s)=0.08975991606712341 and iou=0.23839830283744365 and reward=0.020031488331834463 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for LEFT:bbox transition: [242, 208, 101,  81] -> [239, 208, 101,  81] w/ P(a|s)=0.09132323414087296 and iou=0.23839830283744365 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.019) for UP:bbox transition: [239, 208, 101,  81] -> [239, 206, 101,  81] w/ P(a|s)=0.09173168987035751 and iou=0.2577430649070832 and reward=0.01934476206963956 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-1.0) for UP:bbox transition: [239, 206, 101,  81] -> [239, 204, 101,  81] w/ P(a|s)=0.09038683772087097 and iou=0.2777017783857729 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.04828824  0.          0.04621246 -2.4036567 ]\n",
            "\u001b[31m>> Total frame loss: -2.3091559410095215\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 76 with src: [239, 204, 101,  81] and target: [216, 168,  87,  67]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0079.jpg\n",
            "|->> Beginning tracking for bbox:[239 204 101  81]\n",
            "   \u001b[33m|->> #0/t=24-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [240 205  97  78]\n",
            "         |->> Action Probabilities (Rounded): [0.0886 0.0883 0.0922 0.0927 0.0895 0.0928 0.0942 0.0954 0.0904 0.0894\n",
            " 0.0865], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08863341 0.08829492 0.09215902 0.09265004 0.08950479 0.09284019\n",
            " 0.09415573 0.09540328 0.0903873  0.0894314  0.08653987], argmax=7\n",
            "   \u001b[33m|->> #1/t=25-th Action selection: 6/DOWN (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [240 207  97  78]\n",
            "         |->> Action Probabilities (Rounded): [0.0916 0.0881 0.089  0.0931 0.0907 0.0922 0.0947 0.0949 0.0902 0.0849\n",
            " 0.0905], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09159747 0.08811258 0.08901018 0.09311725 0.0907269  0.09223366\n",
            " 0.09465949 0.09493483 0.09017459 0.08488682 0.09054617], argmax=7\n",
            "   \u001b[33m|->> #2/t=26-th Action selection: 0/LEFT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [238 207  97  78]\n",
            "         |->> Action Probabilities (Rounded): [0.0919 0.0889 0.091  0.093  0.0922 0.0917 0.092  0.0942 0.0897 0.0862\n",
            " 0.0891], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09194871 0.08892739 0.09101458 0.09300784 0.09223588 0.09170582\n",
            " 0.09195966 0.09420893 0.08968566 0.08620719 0.08909831], argmax=7\n",
            "   \u001b[33m|->> #3/t=27-th Action selection: 6/DOWN (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [238 209  97  78]\n",
            "         |->> Action Probabilities (Rounded): [0.0855 0.0897 0.0958 0.0934 0.091  0.0935 0.0931 0.0944 0.0897 0.0839\n",
            " 0.0899], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08553355 0.08971683 0.09583833 0.0933916  0.09100002 0.0935102\n",
            " 0.09306286 0.09437383 0.08974359 0.08394931 0.08987989], argmax=2\n",
            "   \u001b[33m|->> #4/t=28-th Action selection: 0/LEFT (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [236 209  97  78]\n",
            "         |->> Action Probabilities (Rounded): [0.0939 0.0887 0.0883 0.0936 0.094  0.0928 0.0903 0.0944 0.0897 0.0853\n",
            " 0.089 ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.0939064  0.08874246 0.08825845 0.09361961 0.09400389 0.09283474\n",
            " 0.09029082 0.09437399 0.08966396 0.08527655 0.08902909], argmax=7\n",
            "|->> Revisiting bbox: [236 209  97  78]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [239, 204, 101,  81] -> [236, 209,  97,  78] (Target was [216, 168,  87,  67])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.001) for SCALE DOWN:bbox transition: [239, 204, 101,  81] -> [240, 205,  97,  78] w/ P(a|s)=0.08943139761686325 and iou=0.16427640156453716 and reward=-0.0006994840167034999 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.013) for DOWN:bbox transition: [240, 205,  97,  78] -> [240, 207,  97,  78] w/ P(a|s)=0.09465949237346649 and iou=0.15166365746711374 and reward=-0.012612744097423412 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.006) for LEFT:bbox transition: [240, 207,  97,  78] -> [238, 207,  97,  78] w/ P(a|s)=0.09194871038198471 and iou=0.1572354211663067 and reward=0.005571763699192961 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-0.013) for DOWN:bbox transition: [238, 207,  97,  78] -> [238, 209,  97,  78] w/ P(a|s)=0.0930628553032875 and iou=0.1443827424177702 and reward=-0.012852678748536517 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (-1.0) for LEFT:bbox transition: [238, 209,  97,  78] -> [236, 209,  97,  78] w/ P(a|s)=0.09390639513731003 and iou=0.1494894018707629 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-1.6887528e-03 -2.9734155e-02  1.3297150e-02 -3.0518433e-02\n",
            " -2.3654568e+00]\n",
            "\u001b[31m>> Total frame loss: -2.4141011238098145\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 77 with src: [236, 209,  97,  78] and target: [205, 167,  85,  68]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0080.jpg\n",
            "|->> Beginning tracking for bbox:[236 209  97  78]\n",
            "|->> Revisiting bbox: [236 209  97  78]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=29-th Action selection: 8/STOP (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [236 209  97  78]\n",
            "         |->> Action Probabilities (Rounded): [0.0821 0.0894 0.1007 0.0942 0.0907 0.0938 0.0932 0.095  0.0889 0.0834\n",
            " 0.0887], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.082053   0.08938705 0.10074325 0.09419707 0.09074799 0.09379196\n",
            " 0.09317781 0.09495594 0.08891166 0.08336424 0.08867007], argmax=2\n",
            "         |->> Hit a STOP on the 29-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [236, 209,  97,  78] -> [236, 209,  97,  78] (Target was [205, 167,  85,  68])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [236, 209,  97,  78] -> [236, 209,  97,  78] w/ P(a|s)=0.08891166001558304 and iou=0.1175682465248702 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.420112]\n",
            "\u001b[31m>> Total frame loss: -2.420111894607544\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 78 with src: [236, 209,  97,  78] and target: [211, 168,  83,  69]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0081.jpg\n",
            "|->> Beginning tracking for bbox:[236 209  97  78]\n",
            "   \u001b[33m|->> #0/t=29-th Action selection: 0/LEFT (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [234 209  97  78]\n",
            "         |->> Action Probabilities (Rounded): [0.0945 0.088  0.0881 0.0941 0.0919 0.093  0.0927 0.0944 0.0901 0.0836\n",
            " 0.0896], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09445956 0.08802499 0.08810733 0.09407329 0.09194237 0.09295537\n",
            " 0.09269968 0.0944168  0.09010711 0.08360562 0.08960788], argmax=0\n",
            "|->> Revisiting bbox: [236 209  97  78]. ACtion 2 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [236, 209,  97,  78] -> [234, 209,  97,  78] (Target was [211, 168,  83,  69])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for LEFT:bbox transition: [236, 209,  97,  78] -> [234, 209,  97,  78] w/ P(a|s)=0.09445956349372864 and iou=0.14466546112115733 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.3595834]\n",
            "\u001b[31m>> Total frame loss: -2.3595833778381348\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 79 with src: [234, 209,  97,  78] and target: [224, 162,  83,  67]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0082.jpg\n",
            "|->> Beginning tracking for bbox:[234 209  97  78]\n",
            "   \u001b[33m|->> #0/t=30-th Action selection: 0/LEFT (P(a|s) = 0.0820000022649765)\u001b[0m\n",
            "      |->> Bounding box moves to: [232 209  97  78]\n",
            "         |->> Action Probabilities (Rounded): [0.0822 0.0894 0.1001 0.0958 0.0904 0.095  0.0924 0.0958 0.0905 0.0803\n",
            " 0.088 ], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08223656 0.08940063 0.1001431  0.09584349 0.09040792 0.0949851\n",
            " 0.09243464 0.0957599  0.09046046 0.08027883 0.08804943], argmax=2\n",
            "   \u001b[33m|->> #1/t=31-th Action selection: 10/SCALE UP (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [230 207  99  80]\n",
            "         |->> Action Probabilities (Rounded): [0.0861 0.0895 0.0946 0.0953 0.0918 0.0949 0.0931 0.0953 0.0895 0.081\n",
            " 0.0889], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.08613906 0.08948176 0.09459088 0.09534754 0.09180576 0.09489049\n",
            " 0.09305759 0.09532189 0.08951513 0.08095786 0.08889202], argmax=3\n",
            "   \u001b[33m|->> #2/t=32-th Action selection: 4/UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [230 205  99  80]\n",
            "         |->> Action Probabilities (Rounded): [0.0897 0.0892 0.0912 0.0958 0.0913 0.0959 0.0932 0.0959 0.0909 0.0833\n",
            " 0.0835], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08966451 0.08924176 0.09122623 0.09581743 0.09134029 0.09590232\n",
            " 0.09322391 0.09593186 0.09091152 0.08326361 0.08347651], argmax=7\n",
            "|->> Revisiting bbox: [230 205  99  80]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [234, 209,  97,  78] -> [230, 205,  99,  80] (Target was [224, 162,  83,  67])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.004) for LEFT:bbox transition: [234, 209,  97,  78] -> [232, 209,  97,  78] w/ P(a|s)=0.08223655819892883 and iou=0.1290100627848972 and reward=0.0038707810500896445 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.015) for SCALE UP:bbox transition: [232, 209,  97,  78] -> [230, 207,  99,  80] w/ P(a|s)=0.08889202028512955 and iou=0.14371765504369222 and reward=0.014707592258795005 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-1.0) for UP:bbox transition: [230, 207,  99,  80] -> [230, 205,  99,  80] w/ P(a|s)=0.09134028851985931 and iou=0.15885842001203473 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.00966981  0.03559727 -2.3931632 ]\n",
            "\u001b[31m>> Total frame loss: -2.347896099090576\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 80 with src: [230, 205,  99,  80] and target: [225, 154,  90,  70]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0083.jpg\n",
            "|->> Beginning tracking for bbox:[230 205  99  80]\n",
            "   \u001b[33m|->> #0/t=33-th Action selection: 5/2X UP (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [230 201  99  80]\n",
            "         |->> Action Probabilities (Rounded): [0.0902 0.0885 0.0935 0.0949 0.0904 0.0955 0.0932 0.0957 0.0911 0.0814\n",
            " 0.0857], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09021254 0.08854889 0.0934725  0.09485438 0.09037523 0.09548013\n",
            " 0.09319106 0.09567732 0.09111617 0.08140919 0.08566261], argmax=7\n",
            "   \u001b[33m|->> #1/t=34-th Action selection: 5/2X UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [230 197  99  80]\n",
            "         |->> Action Probabilities (Rounded): [0.095  0.0886 0.0911 0.0946 0.0907 0.0927 0.0929 0.0949 0.0903 0.0846\n",
            " 0.0847], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09502934 0.08856144 0.09106611 0.0945765  0.09066412 0.09272512\n",
            " 0.09288951 0.09492956 0.09025142 0.0845894  0.08471742], argmax=0\n",
            "   \u001b[33m|->> #2/t=35-th Action selection: 4/UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [230 195  99  80]\n",
            "         |->> Action Probabilities (Rounded): [0.0937 0.0883 0.0937 0.0943 0.0908 0.0911 0.0938 0.0942 0.0898 0.0841\n",
            " 0.0862], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09369135 0.08827914 0.09367888 0.09428208 0.09077471 0.09107958\n",
            " 0.09382015 0.09422819 0.08979069 0.08413602 0.0862392 ], argmax=3\n",
            "|->> Revisiting bbox: [230 195  99  80]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [230, 205,  99,  80] -> [230, 195,  99,  80] (Target was [225, 154,  90,  70])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.031) for 2X UP:bbox transition: [230, 205,  99,  80] -> [230, 201,  99,  80] w/ P(a|s)=0.09548012912273407 and iou=0.15939665715450468 and reward=0.03127289674196998 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.033) for 2X UP:bbox transition: [230, 201,  99,  80] -> [230, 197,  99,  80] w/ P(a|s)=0.09272512048482895 and iou=0.19245283018867926 and reward=0.033056173034174574 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-1.0) for UP:bbox transition: [230, 197,  99,  80] -> [230, 195,  99,  80] w/ P(a|s)=0.09077470749616623 and iou=0.20969800085070184 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.07345494  0.07861141 -2.3993745 ]\n",
            "\u001b[31m>> Total frame loss: -2.2473082542419434\u001b[0m\n",
            "Final bounding box: [230 195  99  80] reached in 36 timesteps (originating from [261 227  92  72]). Target was [225 154  90  70]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 81 in t=36 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[31m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 9.140697479248047\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 4.274764060974121\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/BlurCar3\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0074.jpg\n",
            "Starting bounding box=adnet_datasets/OTB/BlurCar3/img/0084.jpg for adnet_datasets/OTB/BlurCar3's frames (index: 0)\n",
            "src:adnet_datasets/OTB/BlurCar3/img/0074.jpg\n",
            "target:adnet_datasets/OTB/BlurCar3/img/0084.jpg.\n",
            "\u001b[34m>> Attempting to reach frame 72 with src: [271, 222,  91,  70] and target: [276, 221,  89,  68]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0075.jpg\n",
            "|->> Beginning tracking for bbox:[271 222  91  70]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 3/2X RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [275 222  91  70]\n",
            "         |->> Action Probabilities (Rounded): [0.091  0.0907 0.0909 0.091  0.0907 0.0909 0.0909 0.0909 0.0909 0.0911\n",
            " 0.0911], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.09098749 0.09065805 0.09085456 0.09095478 0.09074389 0.09090871\n",
            " 0.09093135 0.09090079 0.09087081 0.09112945 0.09106015], argmax=9\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 0/LEFT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [273 222  91  70]\n",
            "         |->> Action Probabilities (Rounded): [0.0916 0.0912 0.0901 0.0892 0.091  0.0913 0.091  0.0911 0.091  0.0914\n",
            " 0.0911], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09160384 0.09117297 0.09011541 0.089166   0.0910033  0.09131217\n",
            " 0.09104231 0.09114468 0.09099565 0.0913716  0.0910721 ], argmax=0\n",
            "|->> Revisiting bbox: [273 222  91  70]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [271, 222,  91,  70] -> [273, 222,  91,  70] (Target was [276, 221,  89,  68])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.058) for 2X RIGHT:bbox transition: [271, 222,  91,  70] -> [275, 222,  91,  70] w/ P(a|s)=0.09095478057861328 and iou=0.9232079269236724 and reward=0.0580427617585072 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for LEFT:bbox transition: [275, 222,  91,  70] -> [273, 222,  91,  70] w/ P(a|s)=0.0916038379073143 and iou=0.9034630707937481 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.13915129 2.3902822 ]\n",
            "\u001b[92m>> Total frame loss: 2.529433488845825\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 73 with src: [273, 222,  91,  70] and target: [282, 206,  82,  70]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0076.jpg\n",
            "|->> Beginning tracking for bbox:[273 222  91  70]\n",
            "   \u001b[33m|->> #0/t=3-th Action selection: 3/2X RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [277 222  91  70]\n",
            "         |->> Action Probabilities (Rounded): [0.0845 0.0906 0.0963 0.0907 0.0911 0.0924 0.0915 0.0924 0.0915 0.0888\n",
            " 0.0903], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08445487 0.09064459 0.0963119  0.09066762 0.09107186 0.09239771\n",
            " 0.09148768 0.09238505 0.09145618 0.08881301 0.09030952], argmax=2\n",
            "   \u001b[33m|->> #1/t=4-th Action selection: 2/RIGHT (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [279 222  91  70]\n",
            "         |->> Action Probabilities (Rounded): [0.0938 0.0907 0.0872 0.089  0.0911 0.0924 0.0918 0.0922 0.0911 0.09\n",
            " 0.0908], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09379895 0.09072183 0.0872108  0.08902676 0.09109293 0.09240411\n",
            " 0.09178038 0.09216647 0.09107449 0.08996028 0.09076302], argmax=0\n",
            "   \u001b[33m|->> #2/t=5-th Action selection: 6/DOWN (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [279 224  91  70]\n",
            "         |->> Action Probabilities (Rounded): [0.0962 0.09   0.0829 0.09   0.0917 0.0937 0.0922 0.0934 0.0911 0.089\n",
            " 0.0897], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09618035 0.09002996 0.08291275 0.09003926 0.09166718 0.09371509\n",
            " 0.09219982 0.09338622 0.09113381 0.08902639 0.08970908], argmax=0\n",
            "   \u001b[33m|->> #3/t=6-th Action selection: 10/SCALE UP (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [277 222  93  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0909 0.0913 0.0904 0.0891 0.0931 0.0929 0.0901 0.0935 0.0903 0.0891\n",
            " 0.0895], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09087791 0.09129436 0.09037149 0.08909323 0.09310118 0.09288023\n",
            " 0.09010915 0.09349389 0.09026417 0.08905267 0.08946172], argmax=7\n",
            "   \u001b[33m|->> #4/t=7-th Action selection: 0/LEFT (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [275 222  93  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0939 0.0908 0.0871 0.0908 0.0913 0.0936 0.0921 0.0939 0.0917 0.0906\n",
            " 0.0841], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.0939099  0.09083585 0.08712158 0.09075119 0.09134861 0.09363659\n",
            " 0.09207366 0.0938741  0.09174899 0.090609   0.08409053], argmax=0\n",
            "|->> Revisiting bbox: [275 222  93  72]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [273, 222,  91,  70] -> [275, 222,  93,  72] (Target was [282, 206,  82,  70])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X RIGHT:bbox transition: [273, 222,  91,  70] -> [277, 222,  91,  70] w/ P(a|s)=0.09066762030124664 and iou=0.5764123926060921 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for RIGHT:bbox transition: [277, 222,  91,  70] -> [279, 222,  91,  70] w/ P(a|s)=0.08721079677343369 and iou=0.5764123926060921 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.033) for DOWN:bbox transition: [279, 222,  91,  70] -> [279, 224,  91,  70] w/ P(a|s)=0.09219982475042343 and iou=0.5434616365026765 and reward=-0.03295075610341558 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.009) for SCALE UP:bbox transition: [279, 224,  91,  70] -> [277, 222,  93,  72] w/ P(a|s)=0.08946172147989273 and iou=0.5529470529470529 and reward=0.009485416444376393 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (-1.0) for LEFT:bbox transition: [277, 222,  93,  72] -> [275, 222,  93,  72] w/ P(a|s)=0.09390989691019058 and iou=0.5529470529470529 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.          0.         -0.07854791  0.02289727 -2.3654194 ]\n",
            "\u001b[31m>> Total frame loss: -2.421070098876953\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 74 with src: [275, 222,  93,  72] and target: [265, 181,  91,  69]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0077.jpg\n",
            "|->> Beginning tracking for bbox:[275 222  93  72]\n",
            "   \u001b[33m|->> #0/t=8-th Action selection: 0/LEFT (P(a|s) = 0.08500000089406967)\u001b[0m\n",
            "      |->> Bounding box moves to: [273 222  93  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0848 0.0912 0.0963 0.0908 0.0921 0.0948 0.0917 0.0944 0.0908 0.0867\n",
            " 0.0865], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08475982 0.091163   0.09631122 0.0907516  0.09214021 0.09480836\n",
            " 0.09168767 0.09437817 0.09084012 0.08669595 0.08646386], argmax=2\n",
            "   \u001b[33m|->> #1/t=9-th Action selection: 7/2X DOWN (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [273 226  93  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0877 0.0904 0.0926 0.0931 0.0913 0.0952 0.0932 0.0947 0.0901 0.0867\n",
            " 0.0848], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.08772218 0.0903867  0.09261233 0.09313373 0.09133023 0.09520746\n",
            " 0.09321281 0.09473754 0.09013665 0.08671764 0.08480272], argmax=5\n",
            "   \u001b[33m|->> #2/t=10-th Action selection: 4/UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [273 224  93  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0919 0.0896 0.0896 0.091  0.0929 0.095  0.0931 0.0932 0.0904 0.0867\n",
            " 0.0867], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.09194537 0.08957179 0.08959487 0.09100992 0.09286278 0.09500255\n",
            " 0.0930659  0.09316038 0.09035262 0.08673513 0.08669868], argmax=5\n",
            "   \u001b[33m|->> #3/t=11-th Action selection: 2/RIGHT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [275 224  93  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0935 0.0891 0.0904 0.0923 0.0899 0.0946 0.094  0.0937 0.0897 0.0869\n",
            " 0.086 ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.09347665 0.08913925 0.09035127 0.09227806 0.0899166  0.09455182\n",
            " 0.09397402 0.09368236 0.08973112 0.08689947 0.08599942], argmax=5\n",
            "   \u001b[33m|->> #4/t=12-th Action selection: 7/2X DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [275 228  93  72]\n",
            "         |->> Action Probabilities (Rounded): [0.1018 0.0891 0.0814 0.0934 0.0914 0.0943 0.093  0.0941 0.0897 0.0854\n",
            " 0.0863], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.10182635 0.08914964 0.08139714 0.09336552 0.09144046 0.09433238\n",
            " 0.09296634 0.09414259 0.08971942 0.08537754 0.08628264], argmax=0\n",
            "   \u001b[33m|->> #5/t=13-th Action selection: 1/2X LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [271 228  93  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0896 0.0908 0.0922 0.0914 0.0919 0.0937 0.0937 0.0917 0.0898 0.0879\n",
            " 0.0873], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.08961124 0.0908446  0.09219941 0.09137006 0.09190179 0.09373544\n",
            " 0.09365924 0.09170929 0.08982594 0.08785582 0.08728714], argmax=5\n",
            "   \u001b[33m|->> #6/t=14-th Action selection: 7/2X DOWN (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [271 232  93  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0937 0.088  0.0889 0.0931 0.0923 0.0934 0.0931 0.0917 0.0905 0.0875\n",
            " 0.0879], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09365828 0.08799125 0.08887307 0.09307253 0.09232476 0.09343874\n",
            " 0.09314346 0.09167841 0.09045328 0.08745427 0.08791202], argmax=0\n",
            "|->> Revisiting bbox: [271 228  93  72]. ACtion 5 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [275, 222,  93,  72] -> [271, 232,  93,  72] (Target was [265, 181,  91,  69])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.006) for LEFT:bbox transition: [275, 222,  93,  72] -> [273, 222,  93,  72] w/ P(a|s)=0.08475982397794724 and iou=0.21819547460332364 and reward=0.006371434255887376 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.037) for 2X DOWN:bbox transition: [273, 222,  93,  72] -> [273, 226,  93,  72] w/ P(a|s)=0.09473753720521927 and iou=0.18137121005189838 and reward=-0.03682426455142526 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.018) for UP:bbox transition: [273, 226,  93,  72] -> [273, 224,  93,  72] w/ P(a|s)=0.09286277741193771 and iou=0.19950078580012942 and reward=0.01812957574823104 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-0.006) for RIGHT:bbox transition: [273, 224,  93,  72] -> [275, 224,  93,  72] w/ P(a|s)=0.09035126864910126 and iou=0.19376207562793266 and reward=-0.005738710172196765 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (-0.035) for 2X DOWN:bbox transition: [275, 224,  93,  72] -> [275, 228,  93,  72] w/ P(a|s)=0.09414259344339371 and iou=0.15920664701152507 and reward=-0.03455542861640759 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (0.009) for 2X LEFT:bbox transition: [275, 228,  93,  72] -> [271, 228,  93,  72] w/ P(a|s)=0.09084460139274597 and iou=0.1683926159387663 and reward=0.009185968927241245 and discount=1.0\n",
            "   |->> t=7 Diff-Reward (-1.0) for 2X DOWN:bbox transition: [271, 228,  93,  72] -> [271, 232,  93,  72] w/ P(a|s)=0.09167841076850891 and iou=0.13368283093053734 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.01572428 -0.08678171  0.04308734 -0.01379615 -0.08165256  0.02203351\n",
            " -2.3894684 ]\n",
            "\u001b[31m>> Total frame loss: -2.490853786468506\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 75 with src: [271, 232,  93,  72] and target: [242, 172,  87,  67]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0078.jpg\n",
            "|->> Beginning tracking for bbox:[271 232  93  72]\n",
            "   \u001b[33m|->> #0/t=15-th Action selection: 1/2X LEFT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [267 232  93  72]\n",
            "         |->> Action Probabilities (Rounded): [0.091  0.0888 0.0913 0.092  0.0929 0.0927 0.0928 0.0912 0.0908 0.0887\n",
            " 0.088 ], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.09099399 0.08876354 0.09129193 0.09195127 0.0928828  0.09271084\n",
            " 0.09276962 0.09115086 0.09077802 0.08865983 0.08804731], argmax=4\n",
            "   \u001b[33m|->> #1/t=16-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [268 233  90  69]\n",
            "         |->> Action Probabilities (Rounded): [0.0931 0.0859 0.0905 0.0929 0.0925 0.0928 0.0931 0.0916 0.0909 0.0886\n",
            " 0.0882], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09308773 0.08586088 0.09048748 0.09287234 0.09254302 0.09275649\n",
            " 0.09314771 0.0915883  0.09087    0.08863205 0.08815397], argmax=6\n",
            "   \u001b[33m|->> #2/t=17-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08299999684095383)\u001b[0m\n",
            "      |->> Bounding box moves to: [269 234  87  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0926 0.0867 0.0914 0.0931 0.0924 0.0924 0.0941 0.0922 0.0917 0.083\n",
            " 0.0905], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09260086 0.0866758  0.09141289 0.09306191 0.09235483 0.09237207\n",
            " 0.09410587 0.0921601  0.09171748 0.08303675 0.09050135], argmax=6\n",
            "   \u001b[33m|->> #3/t=18-th Action selection: 7/2X DOWN (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [269 236  87  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0912 0.0874 0.0902 0.0938 0.0934 0.0924 0.0941 0.0924 0.0926 0.0813\n",
            " 0.0913], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09119662 0.08738671 0.09018269 0.09376269 0.09336761 0.09240114\n",
            " 0.09413684 0.09239563 0.09256058 0.08127302 0.09133651], argmax=6\n",
            "|->> Revisiting bbox: [269 234  87  66]. ACtion 5 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [271, 232,  93,  72] -> [269, 236,  87,  66] (Target was [242, 172,  87,  67])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.002) for 2X LEFT:bbox transition: [271, 232,  93,  72] -> [267, 232,  93,  72] w/ P(a|s)=0.0887635350227356 and iou=0.03589446695889505 and reward=0.002393353005598571 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.005) for SCALE DOWN:bbox transition: [267, 232,  93,  72] -> [268, 233,  90,  69] w/ P(a|s)=0.08863205462694168 and iou=0.03135440760729889 and reward=-0.004540059351596154 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.005) for SCALE DOWN:bbox transition: [268, 233,  90,  69] -> [269, 234,  87,  66] w/ P(a|s)=0.08303675055503845 and iou=0.026616981634282673 and reward=-0.00473742597301622 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-1.0) for 2X DOWN:bbox transition: [269, 234,  87,  66] -> [269, 236,  87,  66] w/ P(a|s)=0.09239563345909119 and iou=0.015801948907031866 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.00579617 -0.01100175 -0.01178895 -2.3816755 ]\n",
            "\u001b[31m>> Total frame loss: -2.398669958114624\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 76 with src: [269, 236,  87,  66] and target: [216, 168,  87,  67]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0079.jpg\n",
            "|->> Beginning tracking for bbox:[269 236  87  66]\n",
            "|->> Revisiting bbox: [269 236  87  66]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=19-th Action selection: 8/STOP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [269 236  87  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0907 0.089  0.09   0.093  0.0935 0.0924 0.0933 0.0904 0.0916 0.0842\n",
            " 0.0918], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.09072191 0.08896204 0.09002014 0.09299944 0.09350075 0.09242588\n",
            " 0.09327338 0.0903708  0.09164932 0.0842448  0.09183149], argmax=4\n",
            "         |->> Hit a STOP on the 19-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [269, 236,  87,  66] -> [269, 236,  87,  66] (Target was [216, 168,  87,  67])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [269, 236,  87,  66] -> [269, 236,  87,  66] w/ P(a|s)=0.09164932370185852 and iou=0.0 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.3897858]\n",
            "\u001b[31m>> Total frame loss: -2.3897857666015625\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 77 with src: [269, 236,  87,  66] and target: [205, 167,  85,  68]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0080.jpg\n",
            "|->> Beginning tracking for bbox:[269 236  87  66]\n",
            "   \u001b[33m|->> #0/t=19-th Action selection: 6/DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [269 237  87  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0885 0.0888 0.0902 0.0923 0.093  0.0917 0.0943 0.0916 0.0933 0.0843\n",
            " 0.092 ], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08852458 0.08880016 0.09022252 0.0922952  0.09302443 0.09167746\n",
            " 0.09425084 0.09160167 0.09333425 0.08428463 0.09198423], argmax=6\n",
            "   \u001b[33m|->> #1/t=20-th Action selection: 2/RIGHT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [271 237  87  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0884 0.0895 0.0901 0.0935 0.0935 0.0927 0.09   0.0917 0.0938 0.0851\n",
            " 0.0917], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08840027 0.08947365 0.0901262  0.09345803 0.09352475 0.09274915\n",
            " 0.08998009 0.09174112 0.09379976 0.08505698 0.09169002], argmax=8\n",
            "   \u001b[33m|->> #2/t=21-th Action selection: 5/2X UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [271 235  87  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0946 0.089  0.083  0.0947 0.0911 0.0934 0.0932 0.0918 0.0931 0.0852\n",
            " 0.091 ], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09459197 0.08904393 0.08296847 0.09466225 0.09106538 0.09341656\n",
            " 0.09318034 0.09181783 0.09309254 0.08520585 0.0909549 ], argmax=3\n",
            "   \u001b[33m|->> #3/t=22-th Action selection: 5/2X UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [271 233  87  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0854 0.091  0.0927 0.0926 0.0925 0.0917 0.0921 0.0927 0.0935 0.0851\n",
            " 0.0906], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08541126 0.09104415 0.09272853 0.09263121 0.09253011 0.09167312\n",
            " 0.09210727 0.09269071 0.09352709 0.08506548 0.0905911 ], argmax=8\n",
            "   \u001b[33m|->> #4/t=23-th Action selection: 4/UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [271 232  87  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0903 0.0911 0.0899 0.093  0.0914 0.09   0.0929 0.0932 0.0924 0.0856\n",
            " 0.0902], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09029607 0.09110341 0.08987784 0.09303778 0.09141914 0.09003515\n",
            " 0.0928991  0.09320535 0.09236594 0.08557059 0.09018961], argmax=7\n",
            "   \u001b[33m|->> #5/t=24-th Action selection: 4/UP (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [271 231  87  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0893 0.0911 0.0921 0.0932 0.0893 0.0905 0.0936 0.0931 0.0925 0.0852\n",
            " 0.09  ], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08933622 0.09112646 0.09206159 0.09319097 0.08932522 0.0904882\n",
            " 0.09364899 0.09313038 0.09247749 0.08524849 0.08996592], argmax=6\n",
            "   \u001b[33m|->> #6/t=25-th Action selection: 5/2X UP (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [271 229  87  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0924 0.0921 0.0903 0.0935 0.0882 0.0902 0.0924 0.0933 0.0922 0.0861\n",
            " 0.0894], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09237968 0.09205358 0.09028012 0.09351889 0.08818679 0.0902488\n",
            " 0.09243736 0.09326185 0.09218302 0.08606563 0.08938427], argmax=3\n",
            "   \u001b[33m|->> #7/t=26-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [272 230  84  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0913 0.0921 0.0915 0.0928 0.0896 0.0884 0.093  0.0926 0.0917 0.0878\n",
            " 0.0893], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09128977 0.09213947 0.09150936 0.09280498 0.08955697 0.08843343\n",
            " 0.09295677 0.09261999 0.09167255 0.08775339 0.08926334], argmax=6\n",
            "   \u001b[33m|->> #8/t=27-th Action selection: 2/RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [274 230  84  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0916 0.0923 0.0914 0.0933 0.0901 0.0888 0.0936 0.0928 0.0905 0.0846\n",
            " 0.0909], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09163431 0.09232201 0.09141684 0.09327678 0.09012486 0.08876159\n",
            " 0.09357621 0.09284882 0.09054831 0.08460084 0.09088945], argmax=6\n",
            "   \u001b[33m|->> #9/t=28-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08500000089406967)\u001b[0m\n",
            "      |->> Bounding box moves to: [275 231  81  62]\n",
            "         |->> Action Probabilities (Rounded): [0.1001 0.0916 0.0823 0.0936 0.0914 0.0907 0.0939 0.0935 0.0892 0.0849\n",
            " 0.089 ], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.10005172 0.09158519 0.08227801 0.093572   0.0914195  0.09067672\n",
            " 0.09389116 0.0934577  0.08922543 0.08489214 0.08895044], argmax=0\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [269, 236,  87,  66] -> [275, 231,  81,  62] (Target was [205, 167,  85,  68])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for DOWN:bbox transition: [269, 236,  87,  66] -> [269, 237,  87,  66] w/ P(a|s)=0.09425083547830582 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for RIGHT:bbox transition: [269, 237,  87,  66] -> [271, 237,  87,  66] w/ P(a|s)=0.09012620151042938 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X UP:bbox transition: [271, 237,  87,  66] -> [271, 235,  87,  66] w/ P(a|s)=0.09341655671596527 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.003) for 2X UP:bbox transition: [271, 235,  87,  66] -> [271, 233,  87,  66] w/ P(a|s)=0.0916731208562851 and iou=0.0033089515848136537 and reward=0.0033089515848136537 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (0.002) for UP:bbox transition: [271, 233,  87,  66] -> [271, 232,  87,  66] w/ P(a|s)=0.09141913801431656 and iou=0.004971652856519843 and reward=0.0016627012717061892 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (0.002) for UP:bbox transition: [271, 232,  87,  66] -> [271, 231,  87,  66] w/ P(a|s)=0.08932521939277649 and iou=0.006639874191857418 and reward=0.0016682213353375747 and discount=1.0\n",
            "   |->> t=7 Diff-Reward (0.003) for 2X UP:bbox transition: [271, 231,  87,  66] -> [271, 229,  87,  66] w/ P(a|s)=0.09024880081415176 and iou=0.009992987377279102 and reward=0.0033531131854216845 and discount=1.0\n",
            "   |->> t=8 Diff-Reward (-0.002) for SCALE DOWN:bbox transition: [271, 229,  87,  66] -> [272, 230,  84,  64] w/ P(a|s)=0.08775339275598526 and iou=0.008133020061449486 and reward=-0.0018599673158296165 and discount=1.0\n",
            "   |->> t=9 Diff-Reward (-0.001) for RIGHT:bbox transition: [272, 230,  84,  64] -> [274, 230,  84,  64] w/ P(a|s)=0.09141683578491211 and iou=0.007222824124232575 and reward=-0.0009101959372169108 and discount=1.0\n",
            "   |->> t=10 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [274, 230,  84,  64] -> [275, 231,  81,  62] w/ P(a|s)=0.084892138838768 and iou=0.005585552038726494 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  7.9068262e-03\n",
            "  3.9776810e-03  4.0295413e-03  8.0648577e-03 -4.5257183e-03\n",
            " -2.1774850e-03 -2.4663737e+00]\n",
            "\u001b[31m>> Total frame loss: -2.4490978717803955\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 78 with src: [275, 231,  81,  62] and target: [211, 168,  83,  69]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0081.jpg\n",
            "|->> Beginning tracking for bbox:[275 231  81  62]\n",
            "   \u001b[33m|->> #0/t=29-th Action selection: 1/2X LEFT (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [271 231  81  62]\n",
            "         |->> Action Probabilities (Rounded): [0.0881 0.0936 0.0911 0.0928 0.0923 0.0908 0.0944 0.0942 0.0913 0.0811\n",
            " 0.0904], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08811793 0.09355293 0.09106081 0.09282552 0.09231416 0.09080963\n",
            " 0.0944161  0.09417679 0.09126378 0.08107568 0.0903867 ], argmax=6\n",
            "   \u001b[33m|->> #1/t=30-th Action selection: 0/LEFT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [269 231  81  62]\n",
            "         |->> Action Probabilities (Rounded): [0.0923 0.0894 0.0885 0.0927 0.0915 0.09   0.0945 0.0946 0.0922 0.0844\n",
            " 0.0898], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09234174 0.08940557 0.0884814  0.09265799 0.09153376 0.08998915\n",
            " 0.09447661 0.09464516 0.09222898 0.08441404 0.08982553], argmax=7\n",
            "   \u001b[33m|->> #2/t=31-th Action selection: 9/SCALE DOWN (P(a|s) = 0.0820000022649765)\u001b[0m\n",
            "      |->> Bounding box moves to: [270 232  78  60]\n",
            "         |->> Action Probabilities (Rounded): [0.0829 0.0896 0.0979 0.0937 0.0909 0.0909 0.0944 0.095  0.092  0.0823\n",
            " 0.0903], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08293068 0.08959164 0.09786835 0.09372066 0.09086515 0.09088275\n",
            " 0.09443967 0.09502844 0.09202497 0.08232734 0.09032042], argmax=2\n",
            "   \u001b[33m|->> #3/t=32-th Action selection: 1/2X LEFT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [266 232  78  60]\n",
            "         |->> Action Probabilities (Rounded): [0.0923 0.0893 0.0876 0.0948 0.0919 0.0921 0.095  0.0947 0.0916 0.0794\n",
            " 0.0914], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09226126 0.08932569 0.08755649 0.09476165 0.09194422 0.09207759\n",
            " 0.09502146 0.09466359 0.09155799 0.07938728 0.09144282], argmax=6\n",
            "   \u001b[33m|->> #4/t=33-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08100000023841858)\u001b[0m\n",
            "      |->> Bounding box moves to: [267 233  75  58]\n",
            "         |->> Action Probabilities (Rounded): [0.0873 0.0876 0.093  0.0934 0.0929 0.0928 0.0944 0.0959 0.0911 0.0814\n",
            " 0.0902], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08729417 0.08759349 0.09303331 0.09342581 0.09289263 0.0928266\n",
            " 0.09442671 0.09589299 0.09106501 0.08138866 0.09016065], argmax=7\n",
            "|->> Revisiting bbox: [267 233  75  58]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [275, 231,  81,  62] -> [267, 233,  75,  58] (Target was [211, 168,  83,  69])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.002) for 2X LEFT:bbox transition: [275, 231,  81,  62] -> [271, 231,  81,  62] w/ P(a|s)=0.09355293214321136 and iou=0.013005371783997738 and reward=0.0022860487938707996 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.001) for LEFT:bbox transition: [271, 231,  81,  62] -> [269, 231,  81,  62] w/ P(a|s)=0.09234173595905304 and iou=0.014152278516841211 and reward=0.001146906732843473 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.002) for SCALE DOWN:bbox transition: [269, 231,  81,  62] -> [270, 232,  78,  60] w/ P(a|s)=0.08232734352350235 and iou=0.011665208515602217 and reward=-0.0024870700012389942 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.002) for 2X LEFT:bbox transition: [270, 232,  78,  60] -> [266, 232,  78,  60] w/ P(a|s)=0.0893256887793541 and iou=0.013635920911658713 and reward=0.001970712396056496 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [266, 232,  78,  60] -> [267, 233,  75,  58] w/ P(a|s)=0.08138865977525711 and iou=0.010833584110743304 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.00541617  0.00273223 -0.00621034  0.00476019 -2.5085194 ]\n",
            "\u001b[31m>> Total frame loss: -2.501821279525757\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 79 with src: [267, 233,  75,  58] and target: [224, 162,  83,  67]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0082.jpg\n",
            "|->> Beginning tracking for bbox:[267 233  75  58]\n",
            "   \u001b[33m|->> #0/t=34-th Action selection: 7/2X DOWN (P(a|s) = 0.09600000083446503)\u001b[0m\n",
            "      |->> Bounding box moves to: [267 235  75  58]\n",
            "         |->> Action Probabilities (Rounded): [0.0909 0.0877 0.0893 0.0938 0.0929 0.093  0.0955 0.0958 0.0914 0.0772\n",
            " 0.0926], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09089387 0.08768541 0.08925156 0.09381047 0.09289019 0.09295919\n",
            " 0.09554084 0.09575923 0.09140649 0.07720643 0.09259634], argmax=7\n",
            "   \u001b[33m|->> #1/t=35-th Action selection: 10/SCALE UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [265 234  77  60]\n",
            "         |->> Action Probabilities (Rounded): [0.0893 0.0876 0.0916 0.0935 0.0928 0.0928 0.0942 0.0941 0.0918 0.0806\n",
            " 0.0917], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08927708 0.08756199 0.09155899 0.09354226 0.09279226 0.09284665\n",
            " 0.09418528 0.09407842 0.09183554 0.08059972 0.09172185], argmax=6\n",
            "   \u001b[33m|->> #2/t=36-th Action selection: 3/2X RIGHT (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [269 234  77  60]\n",
            "         |->> Action Probabilities (Rounded): [0.0894 0.089  0.0896 0.0939 0.0935 0.0943 0.0953 0.0938 0.0921 0.0828\n",
            " 0.0864], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08938436 0.08896657 0.08962256 0.09389684 0.09346112 0.09429811\n",
            " 0.09530944 0.09378999 0.09206088 0.08283606 0.08637403], argmax=6\n",
            "   \u001b[33m|->> #3/t=37-th Action selection: 4/UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [269 233  77  60]\n",
            "         |->> Action Probabilities (Rounded): [0.0895 0.0889 0.0894 0.0918 0.0932 0.094  0.0944 0.0942 0.0926 0.0835\n",
            " 0.0886], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.0894686  0.08887626 0.08941341 0.09177015 0.09321793 0.09401468\n",
            " 0.09440102 0.09418065 0.09255179 0.08351479 0.08859066], argmax=6\n",
            "   \u001b[33m|->> #4/t=38-th Action selection: 5/2X UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [269 231  77  60]\n",
            "         |->> Action Probabilities (Rounded): [0.0896 0.0885 0.0903 0.0926 0.0911 0.0932 0.0942 0.0941 0.0926 0.0856\n",
            " 0.0881], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08955274 0.08852836 0.09033339 0.09258511 0.09114013 0.09322638\n",
            " 0.09423895 0.09411963 0.09259569 0.08558293 0.08809673], argmax=6\n",
            "   \u001b[33m|->> #5/t=39-th Action selection: 4/UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [269 230  77  60]\n",
            "         |->> Action Probabilities (Rounded): [0.0913 0.0889 0.0901 0.0923 0.0916 0.0919 0.0941 0.0928 0.0916 0.087\n",
            " 0.0883], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09126774 0.08885699 0.09012391 0.0923392  0.09155032 0.09194215\n",
            " 0.09413642 0.09283153 0.09161041 0.08704984 0.08829153], argmax=6\n",
            "   \u001b[33m|->> #6/t=40-th Action selection: 0/LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [267 230  77  60]\n",
            "         |->> Action Probabilities (Rounded): [0.0906 0.09   0.0903 0.0926 0.0892 0.0912 0.0946 0.0944 0.0917 0.0875\n",
            " 0.088 ], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09060592 0.08995952 0.09031787 0.09255521 0.08924536 0.09116624\n",
            " 0.09461139 0.09439422 0.09171022 0.08747739 0.08795658], argmax=6\n",
            "   \u001b[33m|->> #7/t=41-th Action selection: 3/2X RIGHT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [271 230  77  60]\n",
            "         |->> Action Probabilities (Rounded): [0.0833 0.0915 0.0959 0.0926 0.0908 0.0921 0.0931 0.0944 0.0916 0.0867\n",
            " 0.0881], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08327846 0.09147353 0.09591471 0.09259662 0.09081623 0.09208956\n",
            " 0.09308712 0.09436024 0.0915537  0.08673901 0.08809086], argmax=2\n",
            "|->> Revisiting bbox: [269 230  77  60]. ACtion 0 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [267, 233,  75,  58] -> [271, 230,  77,  60] (Target was [224, 162,  83,  67])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X DOWN:bbox transition: [267, 233,  75,  58] -> [267, 235,  75,  58] w/ P(a|s)=0.09575922787189484 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for SCALE UP:bbox transition: [267, 235,  75,  58] -> [265, 234,  77,  60] w/ P(a|s)=0.09172184765338898 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X RIGHT:bbox transition: [265, 234,  77,  60] -> [269, 234,  77,  60] w/ P(a|s)=0.09389683604240417 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.0) for UP:bbox transition: [269, 234,  77,  60] -> [269, 233,  77,  60] w/ P(a|s)=0.09321793168783188 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (0.0) for 2X UP:bbox transition: [269, 233,  77,  60] -> [269, 231,  77,  60] w/ P(a|s)=0.09322638064622879 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (0.0) for UP:bbox transition: [269, 231,  77,  60] -> [269, 230,  77,  60] w/ P(a|s)=0.0915503203868866 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=7 Diff-Reward (0.0) for LEFT:bbox transition: [269, 230,  77,  60] -> [267, 230,  77,  60] w/ P(a|s)=0.09060592204332352 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=8 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [267, 230,  77,  60] -> [271, 230,  77,  60] w/ P(a|s)=0.0925966203212738 and iou=0.0 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.         0.         0.         0.         0.         0.\n",
            "  0.        -2.3795028]\n",
            "\u001b[31m>> Total frame loss: -2.379502773284912\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 80 with src: [271, 230,  77,  60] and target: [225, 154,  90,  70]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0083.jpg\n",
            "|->> Beginning tracking for bbox:[271 230  77  60]\n",
            "   \u001b[33m|->> #0/t=42-th Action selection: 9/SCALE DOWN (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [272 231  74  58]\n",
            "         |->> Action Probabilities (Rounded): [0.0924 0.0905 0.0857 0.0916 0.0915 0.0916 0.0938 0.0939 0.091  0.0895\n",
            " 0.0883], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09243877 0.09049765 0.08574415 0.09163616 0.0914825  0.09161063\n",
            " 0.09382088 0.09393869 0.09102456 0.08951362 0.08829241], argmax=7\n",
            "   \u001b[33m|->> #1/t=43-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08399999886751175)\u001b[0m\n",
            "      |->> Bounding box moves to: [273 232  71  56]\n",
            "         |->> Action Probabilities (Rounded): [0.0887 0.0912 0.0898 0.0921 0.0922 0.0924 0.0935 0.094  0.0915 0.0843\n",
            " 0.0903], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.0886991  0.09124445 0.0897711  0.09206554 0.09222187 0.09242376\n",
            " 0.0935237  0.09399725 0.09153074 0.08425702 0.09026552], argmax=7\n",
            "   \u001b[33m|->> #2/t=44-th Action selection: 5/2X UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [273 230  71  56]\n",
            "         |->> Action Probabilities (Rounded): [0.0927 0.0908 0.0873 0.0923 0.0924 0.0921 0.0942 0.0945 0.0912 0.0827\n",
            " 0.0898], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09268356 0.09083034 0.08731555 0.09228174 0.09239974 0.09213465\n",
            " 0.09423081 0.09449846 0.09116483 0.08269768 0.08976267], argmax=7\n",
            "   \u001b[33m|->> #3/t=45-th Action selection: 6/DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [273 231  71  56]\n",
            "         |->> Action Probabilities (Rounded): [0.0921 0.0907 0.0883 0.0925 0.0925 0.091  0.0941 0.0943 0.0912 0.0838\n",
            " 0.0895], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09213698 0.09074549 0.08825022 0.09253304 0.09249952 0.09101259\n",
            " 0.09408268 0.09425772 0.09118745 0.08379085 0.08950352], argmax=7\n",
            "   \u001b[33m|->> #4/t=46-th Action selection: 5/2X UP (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [273 229  71  56]\n",
            "         |->> Action Probabilities (Rounded): [0.0923 0.0906 0.0899 0.0926 0.0934 0.0903 0.0924 0.0939 0.0901 0.0837\n",
            " 0.0909], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09227958 0.09057596 0.08993091 0.09261008 0.09335276 0.09028604\n",
            " 0.09244481 0.09386055 0.09005428 0.08373764 0.09086739], argmax=7\n",
            "|->> Revisiting bbox: [273 231  71  56]. ACtion 7 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [271, 230,  77,  60] -> [273, 229,  71,  56] (Target was [225, 154,  90,  70])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for SCALE DOWN:bbox transition: [271, 230,  77,  60] -> [272, 231,  74,  58] w/ P(a|s)=0.0895136222243309 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for SCALE DOWN:bbox transition: [272, 231,  74,  58] -> [273, 232,  71,  56] w/ P(a|s)=0.08425702154636383 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X UP:bbox transition: [273, 232,  71,  56] -> [273, 230,  71,  56] w/ P(a|s)=0.09213465452194214 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.0) for DOWN:bbox transition: [273, 230,  71,  56] -> [273, 231,  71,  56] w/ P(a|s)=0.09408267587423325 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (-1.0) for 2X UP:bbox transition: [273, 231,  71,  56] -> [273, 229,  71,  56] w/ P(a|s)=0.09028603881597519 and iou=0.0 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.         0.         0.         0.        -2.4047725]\n",
            "\u001b[31m>> Total frame loss: -2.4047725200653076\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 81 with src: [273, 229,  71,  56] and target: [229, 161,  91,  72]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0084.jpg\n",
            "|->> Beginning tracking for bbox:[273 229  71  56]\n",
            "   \u001b[33m|->> #0/t=47-th Action selection: 4/UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [273 228  71  56]\n",
            "         |->> Action Probabilities (Rounded): [0.0917 0.0907 0.0897 0.0931 0.0907 0.0892 0.0931 0.0936 0.0919 0.0853\n",
            " 0.0909], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09173635 0.0907165  0.08973554 0.09312735 0.09074187 0.08918059\n",
            " 0.09310865 0.09355201 0.09191818 0.08530299 0.09088   ], argmax=7\n",
            "|->> Revisiting bbox: [273 229  71  56]. ACtion 6 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [273, 229,  71,  56] -> [273, 228,  71,  56] (Target was [229, 161,  91,  72])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for UP:bbox transition: [273, 229,  71,  56] -> [273, 228,  71,  56] w/ P(a|s)=0.09074187278747559 and iou=0.0228310502283105 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.3997364]\n",
            "\u001b[31m>> Total frame loss: -2.3997364044189453\u001b[0m\n",
            "Final bounding box: [273 228  71  56] reached in 48 timesteps (originating from [271 222  91  70]). Target was [229 161  91  72]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 82 in t=48 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[31m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 8.691353797912598\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 2.5300345420837402\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/BlurCar3\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0075.jpg\n",
            "Starting bounding box=adnet_datasets/OTB/BlurCar3/img/0085.jpg for adnet_datasets/OTB/BlurCar3's frames (index: 0)\n",
            "src:adnet_datasets/OTB/BlurCar3/img/0075.jpg\n",
            "target:adnet_datasets/OTB/BlurCar3/img/0085.jpg.\n",
            "\u001b[34m>> Attempting to reach frame 73 with src: [276, 221,  89,  68] and target: [282, 206,  82,  70]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0076.jpg\n",
            "|->> Beginning tracking for bbox:[276 221  89  68]\n",
            "|->> Revisiting bbox: [276 221  89  68]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 8/STOP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [276 221  89  68]\n",
            "         |->> Action Probabilities (Rounded): [0.091  0.0907 0.0909 0.091  0.0907 0.0909 0.0909 0.0909 0.0909 0.0911\n",
            " 0.0911], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.09098884 0.09065392 0.09085199 0.09095424 0.09074065 0.09091092\n",
            " 0.09093463 0.09089975 0.09086707 0.09113242 0.09106551], argmax=9\n",
            "         |->> Hit a STOP on the 1-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [276, 221,  89,  68] -> [276, 221,  89,  68] (Target was [282, 206,  82,  70])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [276, 221,  89,  68] -> [276, 221,  89,  68] w/ P(a|s)=0.0908670723438263 and iou=0.6193353474320241 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.3983576]\n",
            "\u001b[31m>> Total frame loss: -2.398357629776001\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 74 with src: [276, 221,  89,  68] and target: [265, 181,  91,  69]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0077.jpg\n",
            "|->> Beginning tracking for bbox:[276 221  89  68]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 5/2X UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [276 217  89  68]\n",
            "         |->> Action Probabilities (Rounded): [0.0905 0.0903 0.0916 0.0904 0.0905 0.0907 0.0914 0.0913 0.092  0.0899\n",
            " 0.0912], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09054963 0.09034188 0.09160654 0.09044136 0.09046467 0.09073716\n",
            " 0.09135187 0.09131643 0.09202481 0.08991677 0.09124891], argmax=8\n",
            "|->> Revisiting bbox: [276 221  89  68]. ACtion 7 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [276, 221,  89,  68] -> [276, 217,  89,  68] (Target was [265, 181,  91,  69])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for 2X UP:bbox transition: [276, 221,  89,  68] -> [276, 217,  89,  68] w/ P(a|s)=0.09073716402053833 and iou=0.2724177071509648 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.3997881]\n",
            "\u001b[31m>> Total frame loss: -2.3997881412506104\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 75 with src: [276, 217,  89,  68] and target: [242, 172,  87,  67]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0078.jpg\n",
            "|->> Beginning tracking for bbox:[276 217  89  68]\n",
            "   \u001b[33m|->> #0/t=2-th Action selection: 10/SCALE UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [274 215  91  70]\n",
            "         |->> Action Probabilities (Rounded): [0.0904 0.0906 0.0907 0.0918 0.0901 0.0901 0.0908 0.0919 0.0928 0.0899\n",
            " 0.091 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09040729 0.09059693 0.09071086 0.09182478 0.09005766 0.09006006\n",
            " 0.09079587 0.09187694 0.0927506  0.08990481 0.0910142 ], argmax=8\n",
            "   \u001b[33m|->> #1/t=3-th Action selection: 6/DOWN (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [274 217  91  70]\n",
            "         |->> Action Probabilities (Rounded): [0.0899 0.0909 0.0916 0.0926 0.0902 0.0906 0.0919 0.0919 0.0934 0.0914\n",
            " 0.0856], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08994175 0.09087642 0.091627   0.09255081 0.09024174 0.09059047\n",
            " 0.09193673 0.09189367 0.09339673 0.09137843 0.08556631], argmax=8\n",
            "   \u001b[33m|->> #2/t=4-th Action selection: 10/SCALE UP (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [272 215  93  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0909 0.0913 0.092  0.0924 0.0917 0.0909 0.089  0.0925 0.0931 0.0892\n",
            " 0.087 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09088663 0.09130164 0.09197461 0.09244952 0.09166289 0.09086941\n",
            " 0.08904169 0.09247189 0.09314197 0.08919805 0.08700176], argmax=8\n",
            "   \u001b[33m|->> #3/t=5-th Action selection: 0/LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [270 215  93  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0908 0.0913 0.0914 0.093  0.0902 0.0916 0.0911 0.0928 0.094  0.0925\n",
            " 0.0814], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09079048 0.09127256 0.09144107 0.09295129 0.0901968  0.09156489\n",
            " 0.09112851 0.09277652 0.09399024 0.09247052 0.08141714], argmax=8\n",
            "|->> Revisiting bbox: [272 215  93  72]. ACtion 2 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [276, 217,  89,  68] -> [270, 215,  93,  72] (Target was [242, 172,  87,  67])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.013) for SCALE UP:bbox transition: [276, 217,  89,  68] -> [274, 215,  91,  70] w/ P(a|s)=0.09101419895887375 and iou=0.12133468149646107 and reward=0.01251526945726368 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.011) for DOWN:bbox transition: [274, 215,  91,  70] -> [274, 217,  91,  70] w/ P(a|s)=0.09193672984838486 and iou=0.11011011011011011 and reward=-0.011224571386350954 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.013) for SCALE UP:bbox transition: [274, 217,  91,  70] -> [272, 215,  93,  72] w/ P(a|s)=0.0870017558336258 and iou=0.12261360580801291 and reward=0.012503495697902794 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-1.0) for LEFT:bbox transition: [272, 215,  93,  72] -> [270, 215,  93,  72] w/ P(a|s)=0.09079048037528992 and iou=0.12746421820145828 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.02999584 -0.02678918  0.03053137 -2.399201  ]\n",
            "\u001b[31m>> Total frame loss: -2.3654627799987793\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 76 with src: [270, 215,  93,  72] and target: [216, 168,  87,  67]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0079.jpg\n",
            "|->> Beginning tracking for bbox:[270 215  93  72]\n",
            "   \u001b[33m|->> #0/t=6-th Action selection: 10/SCALE UP (P(a|s) = 0.08399999886751175)\u001b[0m\n",
            "      |->> Bounding box moves to: [268 213  95  74]\n",
            "         |->> Action Probabilities (Rounded): [0.0833 0.0915 0.0979 0.0935 0.0915 0.0926 0.0908 0.0937 0.0932 0.0877\n",
            " 0.0843], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08328611 0.09153175 0.0979014  0.093473   0.09149688 0.09262856\n",
            " 0.09078985 0.09369987 0.09319702 0.08774311 0.08425242], argmax=2\n",
            "   \u001b[33m|->> #1/t=7-th Action selection: 10/SCALE UP (P(a|s) = 0.07900000363588333)\u001b[0m\n",
            "      |->> Bounding box moves to: [266 211  97  76]\n",
            "         |->> Action Probabilities (Rounded): [0.0923 0.0911 0.0886 0.094  0.0917 0.0927 0.092  0.094  0.0921 0.0922\n",
            " 0.0793], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09231004 0.09107617 0.08857467 0.0940212  0.09167692 0.09269801\n",
            " 0.09203181 0.09402881 0.09207169 0.09218056 0.07933011], argmax=7\n",
            "   \u001b[33m|->> #2/t=8-th Action selection: 9/SCALE DOWN (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [267 212  94  73]\n",
            "         |->> Action Probabilities (Rounded): [0.0881 0.0916 0.0928 0.0938 0.0929 0.0942 0.0928 0.0945 0.0918 0.0905\n",
            " 0.0771], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08812685 0.09157541 0.09279569 0.09380239 0.09286104 0.09418978\n",
            " 0.0927847  0.09451358 0.0917927  0.09046756 0.07709024], argmax=7\n",
            "   \u001b[33m|->> #3/t=9-th Action selection: 7/2X DOWN (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [267 216  94  73]\n",
            "         |->> Action Probabilities (Rounded): [0.0906 0.0911 0.0898 0.095  0.093  0.0935 0.0935 0.0948 0.0917 0.0861\n",
            " 0.0809], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09063426 0.09106697 0.08979033 0.09504372 0.09300049 0.09352511\n",
            " 0.09350924 0.09478705 0.09166142 0.08609575 0.08088566], argmax=3\n",
            "|->> Revisiting bbox: [267 212  94  73]. ACtion 5 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [270, 215,  93,  72] -> [267, 216,  94,  73] (Target was [216, 168,  87,  67])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.008) for SCALE UP:bbox transition: [270, 215,  93,  72] -> [268, 213,  95,  74] w/ P(a|s)=0.08425242453813553 and iou=0.06369426751592357 and reward=0.00806847737685909 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.008) for SCALE UP:bbox transition: [268, 213,  95,  74] -> [266, 211,  97,  76] w/ P(a|s)=0.07933010905981064 and iou=0.07211889872492487 and reward=0.008424631209001304 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.002) for SCALE DOWN:bbox transition: [266, 211,  97,  76] -> [267, 212,  94,  73] w/ P(a|s)=0.09046755731105804 and iou=0.06979684734047037 and reward=-0.0023220513844545015 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-1.0) for 2X DOWN:bbox transition: [267, 212,  94,  73] -> [267, 216,  94,  73] w/ P(a|s)=0.09478705376386642 and iou=0.056966769384525696 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.01996091  0.02134917 -0.00557934 -2.3561225 ]\n",
            "\u001b[31m>> Total frame loss: -2.3203916549682617\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 77 with src: [267, 216,  94,  73] and target: [205, 167,  85,  68]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0080.jpg\n",
            "|->> Beginning tracking for bbox:[267 216  94  73]\n",
            "   \u001b[33m|->> #0/t=10-th Action selection: 5/2X UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [267 212  94  73]\n",
            "         |->> Action Probabilities (Rounded): [0.0909 0.0912 0.0911 0.0944 0.094  0.0935 0.0942 0.0929 0.0894 0.0878\n",
            " 0.0807], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09094898 0.09115423 0.09106141 0.09437206 0.09400605 0.09347386\n",
            " 0.09418862 0.09286965 0.08939338 0.08780938 0.08072247], argmax=3\n",
            "   \u001b[33m|->> #1/t=11-th Action selection: 4/UP (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [267 210  94  73]\n",
            "         |->> Action Probabilities (Rounded): [0.0907 0.0911 0.0901 0.0936 0.0936 0.0915 0.0939 0.0924 0.0909 0.089\n",
            " 0.0833], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09065122 0.09108171 0.09006892 0.09363833 0.09356342 0.09150635\n",
            " 0.09388474 0.09237386 0.09093197 0.08902635 0.08327319], argmax=6\n",
            "   \u001b[33m|->> #2/t=12-th Action selection: 4/UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [267 208  94  73]\n",
            "         |->> Action Probabilities (Rounded): [0.0901 0.0912 0.0906 0.0945 0.0907 0.0919 0.0942 0.0921 0.0917 0.0891\n",
            " 0.0837], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09006844 0.09124213 0.09058171 0.09453572 0.09072179 0.0918997\n",
            " 0.09422342 0.09214594 0.09173153 0.0891475  0.08370212], argmax=3\n",
            "|->> Revisiting bbox: [267 212  94  73]. ACtion 7 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [267, 216,  94,  73] -> [267, 208,  94,  73] (Target was [205, 167,  85,  68])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.008) for 2X UP:bbox transition: [267, 216,  94,  73] -> [267, 212,  94,  73] w/ P(a|s)=0.09347385913133621 and iou=0.04367208783951127 and reward=0.007867089887852112 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.004) for UP:bbox transition: [267, 212,  94,  73] -> [267, 210,  94,  73] w/ P(a|s)=0.09356342256069183 and iou=0.04765061738626005 and reward=0.00397852954674878 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-1.0) for UP:bbox transition: [267, 210,  94,  73] -> [267, 208,  94,  73] w/ P(a|s)=0.09072179347276688 and iou=0.05165959570751186 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.01864558  0.0094256  -2.3999577 ]\n",
            "\u001b[31m>> Total frame loss: -2.3718864917755127\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 78 with src: [267, 208,  94,  73] and target: [211, 168,  83,  69]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0081.jpg\n",
            "|->> Beginning tracking for bbox:[267 208  94  73]\n",
            "   \u001b[33m|->> #0/t=13-th Action selection: 4/UP (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [267 206  94  73]\n",
            "         |->> Action Probabilities (Rounded): [0.0917 0.0913 0.0903 0.0936 0.0899 0.0914 0.0931 0.0932 0.0919 0.0888\n",
            " 0.0848], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09169972 0.09128708 0.09029204 0.09359751 0.08991091 0.09135618\n",
            " 0.09312773 0.09318821 0.09192518 0.08882345 0.084792  ], argmax=3\n",
            "   \u001b[33m|->> #1/t=14-th Action selection: 0/LEFT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [265 206  94  73]\n",
            "         |->> Action Probabilities (Rounded): [0.0927 0.0906 0.0906 0.0945 0.0882 0.0914 0.0941 0.0929 0.0913 0.0891\n",
            " 0.0848], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09266345 0.09060875 0.09056788 0.09451926 0.08816066 0.09137872\n",
            " 0.09411857 0.09285048 0.09127718 0.08907814 0.08477695], argmax=3\n",
            "|->> Revisiting bbox: [265 206  94  73]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [267, 208,  94,  73] -> [265, 206,  94,  73] (Target was [211, 168,  83,  69])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.005) for UP:bbox transition: [267, 208,  94,  73] -> [267, 206,  94,  73] w/ P(a|s)=0.08991090953350067 and iou=0.0712219196732471 and reward=0.00489971062699944 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for LEFT:bbox transition: [267, 206,  94,  73] -> [265, 206,  94,  73] w/ P(a|s)=0.09266345202922821 and iou=0.07690333618477331 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.01180309 -2.378781  ]\n",
            "\u001b[31m>> Total frame loss: -2.3669779300689697\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 79 with src: [265, 206,  94,  73] and target: [224, 162,  83,  67]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0082.jpg\n",
            "|->> Beginning tracking for bbox:[265 206  94  73]\n",
            "   \u001b[33m|->> #0/t=15-th Action selection: 1/2X LEFT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [261 206  94  73]\n",
            "         |->> Action Probabilities (Rounded): [0.0845 0.0912 0.0969 0.0947 0.0895 0.0915 0.0926 0.0946 0.0911 0.0872\n",
            " 0.0863], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08447234 0.09124281 0.09687915 0.0947376  0.08949769 0.09146072\n",
            " 0.09256168 0.09462932 0.09108885 0.08717435 0.0862555 ], argmax=2\n",
            "   \u001b[33m|->> #1/t=16-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [262 207  91  70]\n",
            "         |->> Action Probabilities (Rounded): [0.0917 0.0889 0.0882 0.0939 0.091  0.0912 0.0932 0.0938 0.091  0.0894\n",
            " 0.0876], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09174512 0.08887476 0.08822445 0.09393564 0.09097678 0.09120958\n",
            " 0.09324835 0.09382872 0.09098937 0.08941127 0.08755594], argmax=3\n",
            "   \u001b[33m|->> #2/t=17-th Action selection: 6/DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [262 209  91  70]\n",
            "         |->> Action Probabilities (Rounded): [0.0883 0.0892 0.0921 0.0941 0.0917 0.0922 0.0936 0.0945 0.0909 0.0832\n",
            " 0.0901], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08829832 0.0891938  0.09214286 0.09410287 0.09171472 0.092233\n",
            " 0.09359312 0.09451939 0.09085977 0.08322944 0.09011266], argmax=7\n",
            "   \u001b[33m|->> #3/t=18-th Action selection: 5/2X UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [262 205  91  70]\n",
            "         |->> Action Probabilities (Rounded): [0.0921 0.0886 0.0898 0.094  0.0937 0.0912 0.092  0.0937 0.0901 0.0851\n",
            " 0.0896], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09208207 0.0885711  0.08984698 0.09399796 0.09371553 0.09123341\n",
            " 0.09199511 0.09369925 0.09010334 0.08513504 0.08962024], argmax=3\n",
            "   \u001b[33m|->> #4/t=19-th Action selection: 1/2X LEFT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [258 205  91  70]\n",
            "         |->> Action Probabilities (Rounded): [0.0922 0.0893 0.0911 0.0936 0.0908 0.0897 0.0933 0.0932 0.0907 0.0854\n",
            " 0.0907], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09219418 0.0892894  0.09111506 0.09357858 0.09081304 0.08971439\n",
            " 0.09331068 0.09315821 0.0907209  0.08539336 0.09071217], argmax=3\n",
            "   \u001b[33m|->> #5/t=20-th Action selection: 2/RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [260 205  91  70]\n",
            "         |->> Action Probabilities (Rounded): [0.0905 0.0866 0.0923 0.0936 0.0921 0.0896 0.0934 0.0933 0.091  0.0868\n",
            " 0.0908], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09050755 0.08658444 0.09227885 0.09355393 0.0921379  0.08964265\n",
            " 0.09336835 0.09328038 0.0910288  0.08677947 0.09083779], argmax=3\n",
            "|->> Revisiting bbox: [260 205  91  70]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [265, 206,  94,  73] -> [260, 205,  91,  70] (Target was [224, 162,  83,  67])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.009) for 2X LEFT:bbox transition: [265, 206,  94,  73] -> [261, 206,  94,  73] w/ P(a|s)=0.09124280512332916 and iou=0.09309282886053674 and reward=0.00877756308415549 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.003) for SCALE DOWN:bbox transition: [261, 206,  94,  73] -> [262, 207,  91,  70] w/ P(a|s)=0.08941127359867096 and iou=0.09048533040855497 and reward=-0.002607498451981771 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.009) for DOWN:bbox transition: [262, 207,  91,  70] -> [262, 209,  91,  70] w/ P(a|s)=0.09359312057495117 and iou=0.08158825129181398 and reward=-0.008897079116740994 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.018) for 2X UP:bbox transition: [262, 209,  91,  70] -> [262, 205,  91,  70] w/ P(a|s)=0.09123340994119644 and iou=0.09952999723527785 and reward=0.01794174594346387 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (0.01) for 2X LEFT:bbox transition: [262, 205,  91,  70] -> [258, 205,  91,  70] w/ P(a|s)=0.08928939700126648 and iou=0.10934449093444909 and reward=0.009814493699171242 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (-1.0) for RIGHT:bbox transition: [258, 205,  91,  70] -> [260, 205,  91,  70] w/ P(a|s)=0.0922788456082344 and iou=0.10441544015551235 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.02101552 -0.00629583 -0.02107539  0.04295854  0.02371057 -2.3829403 ]\n",
            "\u001b[31m>> Total frame loss: -2.322626829147339\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 80 with src: [260, 205,  91,  70] and target: [225, 154,  90,  70]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0083.jpg\n",
            "|->> Beginning tracking for bbox:[260 205  91  70]\n",
            "   \u001b[33m|->> #0/t=21-th Action selection: 6/DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [260 207  91  70]\n",
            "         |->> Action Probabilities (Rounded): [0.0982 0.087  0.0834 0.0938 0.0915 0.092  0.0939 0.094  0.09   0.0866\n",
            " 0.0897], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09822426 0.08695095 0.08341506 0.09375989 0.09146284 0.09202247\n",
            " 0.09390128 0.09399828 0.08998654 0.08657789 0.08970051], argmax=0\n",
            "   \u001b[33m|->> #1/t=22-th Action selection: 10/SCALE UP (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [258 205  93  72]\n",
            "         |->> Action Probabilities (Rounded): [0.088  0.0884 0.0933 0.0924 0.0943 0.0924 0.0915 0.0944 0.0902 0.0868\n",
            " 0.0885], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08797099 0.08836011 0.09325395 0.09239791 0.09429708 0.09238235\n",
            " 0.09153209 0.09437636 0.09016431 0.08675276 0.08851212], argmax=7\n",
            "   \u001b[33m|->> #2/t=23-th Action selection: 5/2X UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [258 201  93  72]\n",
            "         |->> Action Probabilities (Rounded): [0.093  0.0886 0.0892 0.0926 0.0912 0.0929 0.0933 0.0951 0.0914 0.0887\n",
            " 0.0839], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.09300201 0.08864418 0.08915126 0.09259548 0.09124262 0.09285618\n",
            " 0.09332978 0.09508468 0.09141155 0.08874266 0.08393955], argmax=7\n",
            "   \u001b[33m|->> #3/t=24-th Action selection: 10/SCALE UP (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [256 199  95  74]\n",
            "         |->> Action Probabilities (Rounded): [0.0894 0.0884 0.0925 0.0929 0.0928 0.0907 0.0932 0.0944 0.0917 0.0872\n",
            " 0.0868], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.08936529 0.08841967 0.09254594 0.09292952 0.09281733 0.09071492\n",
            " 0.09315998 0.09439299 0.09172013 0.08715246 0.08678179], argmax=7\n",
            "   \u001b[33m|->> #4/t=25-th Action selection: 2/RIGHT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [258 199  95  74]\n",
            "         |->> Action Probabilities (Rounded): [0.09   0.0899 0.0902 0.0939 0.0919 0.0917 0.0941 0.0932 0.0912 0.092\n",
            " 0.082 ], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08995424 0.08993429 0.09018287 0.09388378 0.0918897  0.09171365\n",
            " 0.09411588 0.09316029 0.09119081 0.09201989 0.08195464], argmax=6\n",
            "   \u001b[33m|->> #5/t=26-th Action selection: 7/2X DOWN (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [258 203  95  74]\n",
            "         |->> Action Probabilities (Rounded): [0.096  0.0903 0.0827 0.0934 0.093  0.093  0.0941 0.0933 0.0921 0.0884\n",
            " 0.0838], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09597086 0.090275   0.0826968  0.09338561 0.09295823 0.09302516\n",
            " 0.09407589 0.09332161 0.09208132 0.08836271 0.08384681], argmax=0\n",
            "|->> Revisiting bbox: [258 199  95  74]. ACtion 5 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [260, 205,  91,  70] -> [258, 203,  95,  74] (Target was [225, 154,  90,  70])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.01) for DOWN:bbox transition: [260, 205,  91,  70] -> [260, 207,  91,  70] w/ P(a|s)=0.09390128403902054 and iou=0.07967618236046016 and reward=-0.010216290757819407 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.011) for SCALE UP:bbox transition: [260, 207,  91,  70] -> [258, 205,  93,  72] w/ P(a|s)=0.088512122631073 and iou=0.09090909090909091 and reward=0.011232908548630752 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.021) for 2X UP:bbox transition: [258, 205,  93,  72] -> [258, 201,  93,  72] w/ P(a|s)=0.09285617619752884 and iou=0.11219512195121951 and reward=0.021286031042128603 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.012) for SCALE UP:bbox transition: [258, 201,  93,  72] -> [256, 199,  95,  74] w/ P(a|s)=0.08678179234266281 and iou=0.12442007591733446 and reward=0.012224953966114949 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (-0.005) for RIGHT:bbox transition: [256, 199,  95,  74] -> [258, 199,  95,  74] w/ P(a|s)=0.09018287062644958 and iou=0.11969760604787905 and reward=-0.004722469869455417 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (-1.0) for 2X DOWN:bbox transition: [258, 199,  95,  74] -> [258, 203,  95,  74] w/ P(a|s)=0.09332160651683807 and iou=0.0986565564988049 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.02416675  0.02723549  0.05059059  0.02988217 -0.01136186 -2.3717036 ]\n",
            "\u001b[31m>> Total frame loss: -2.2995240688323975\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 81 with src: [258, 203,  95,  74] and target: [229, 161,  91,  72]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0084.jpg\n",
            "|->> Beginning tracking for bbox:[258 203  95  74]\n",
            "   \u001b[33m|->> #0/t=27-th Action selection: 9/SCALE DOWN (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [259 204  92  71]\n",
            "         |->> Action Probabilities (Rounded): [0.0878 0.0924 0.0918 0.0911 0.0927 0.0918 0.0935 0.0922 0.0918 0.0916\n",
            " 0.0834], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08776392 0.09235983 0.09175705 0.09111276 0.0927441  0.09184492\n",
            " 0.09347466 0.09218106 0.09177124 0.09159458 0.0833959 ], argmax=6\n",
            "   \u001b[33m|->> #1/t=28-th Action selection: 5/2X UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [259 200  92  71]\n",
            "         |->> Action Probabilities (Rounded): [0.0911 0.0913 0.0886 0.0927 0.093  0.0919 0.0944 0.0934 0.0915 0.0857\n",
            " 0.0865], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09111334 0.0912751  0.08858068 0.09266119 0.09298357 0.09186377\n",
            " 0.09438818 0.09343101 0.09146003 0.08572392 0.08651924], argmax=6\n",
            "   \u001b[33m|->> #2/t=29-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [260 201  89  68]\n",
            "         |->> Action Probabilities (Rounded): [0.0897 0.0918 0.0903 0.0922 0.0926 0.0912 0.0938 0.0925 0.0918 0.0885\n",
            " 0.0858], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08966482 0.09175866 0.0902889  0.09218143 0.09262271 0.09118076\n",
            " 0.09377339 0.09245831 0.09180158 0.08849021 0.08577928], argmax=6\n",
            "   \u001b[33m|->> #3/t=30-th Action selection: 7/2X DOWN (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [260 205  89  68]\n",
            "         |->> Action Probabilities (Rounded): [0.0902 0.0923 0.0894 0.0943 0.0926 0.0916 0.0946 0.0924 0.0919 0.0823\n",
            " 0.0884], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.0902003  0.09234833 0.08938961 0.09431522 0.09262816 0.09157922\n",
            " 0.09455404 0.09239458 0.09188902 0.08233942 0.08836213], argmax=6\n",
            "   \u001b[33m|->> #4/t=31-th Action selection: 0/LEFT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [258 205  89  68]\n",
            "         |->> Action Probabilities (Rounded): [0.09   0.0921 0.0897 0.093  0.0935 0.0906 0.0939 0.0911 0.0923 0.0864\n",
            " 0.0873], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.09002542 0.09212691 0.08972572 0.09303074 0.09346361 0.09063113\n",
            " 0.09387967 0.09106589 0.09234022 0.08639169 0.08731896], argmax=6\n",
            "   \u001b[33m|->> #5/t=32-th Action selection: 9/SCALE DOWN (P(a|s) = 0.08399999886751175)\u001b[0m\n",
            "      |->> Bounding box moves to: [259 206  86  65]\n",
            "         |->> Action Probabilities (Rounded): [0.0832 0.092  0.0955 0.0947 0.0923 0.0917 0.0938 0.0927 0.0924 0.084\n",
            " 0.0877], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08321324 0.09204852 0.09547262 0.09468951 0.09231085 0.0916791\n",
            " 0.09376327 0.09270962 0.09241375 0.0839606  0.08773886], argmax=2\n",
            "   \u001b[33m|->> #6/t=33-th Action selection: 2/RIGHT (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [261 206  86  65]\n",
            "         |->> Action Probabilities (Rounded): [0.091  0.0916 0.0875 0.0945 0.0923 0.0918 0.0934 0.093  0.0927 0.0809\n",
            " 0.0913], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09104727 0.09155345 0.08753594 0.09454898 0.09225837 0.09177612\n",
            " 0.09342673 0.09297143 0.09272619 0.08090328 0.09125227], argmax=3\n",
            "|->> Revisiting bbox: [259 206  86  65]. ACtion 0 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [258, 203,  95,  74] -> [261, 206,  86,  65] (Target was [229, 161,  91,  72])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.002) for SCALE DOWN:bbox transition: [258, 203,  95,  74] -> [259, 204,  92,  71] w/ P(a|s)=0.09159457683563232 and iou=0.15634114007954042 and reward=-0.002334853778163032 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.025) for 2X UP:bbox transition: [259, 204,  92,  71] -> [259, 200,  92,  71] w/ P(a|s)=0.09186376631259918 and iou=0.18182639327973987 and reward=0.025485253200199454 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.002) for SCALE DOWN:bbox transition: [259, 200,  92,  71] -> [260, 201,  89,  68] w/ P(a|s)=0.08849021047353745 and iou=0.17970797454137027 and reward=-0.0021184187383695985 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-0.026) for 2X DOWN:bbox transition: [260, 201,  89,  68] -> [260, 205,  89,  68] w/ P(a|s)=0.09239457547664642 and iou=0.15378982057854265 and reward=-0.025918153962827623 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (0.006) for LEFT:bbox transition: [260, 205,  89,  68] -> [258, 205,  89,  68] w/ P(a|s)=0.0900254175066948 and iou=0.159735001840265 and reward=0.00594518126172236 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (-0.003) for SCALE DOWN:bbox transition: [258, 205,  89,  68] -> [259, 206,  86,  65] w/ P(a|s)=0.08396060019731522 and iou=0.15693187232015246 and reward=-0.0028031295201125517 and discount=1.0\n",
            "   |->> t=7 Diff-Reward (-1.0) for RIGHT:bbox transition: [259, 206,  86,  65] -> [261, 206,  86,  65] w/ P(a|s)=0.08753594011068344 and iou=0.1510095743672386 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.0055812   0.06084473 -0.00513688 -0.06172893  0.014314   -0.00694449\n",
            " -2.435706  ]\n",
            "\u001b[31m>> Total frame loss: -2.43993878364563\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 82 with src: [261, 206,  86,  65] and target: [230, 181,  88,  73]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/BlurCar3/img/0085.jpg\n",
            "|->> Beginning tracking for bbox:[261 206  86  65]\n",
            "   \u001b[33m|->> #0/t=34-th Action selection: 3/2X RIGHT (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [265 206  86  65]\n",
            "         |->> Action Probabilities (Rounded): [0.0942 0.0913 0.0841 0.0946 0.0925 0.0935 0.0938 0.0937 0.0922 0.0816\n",
            " 0.0885], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09424514 0.09132984 0.08412121 0.09457684 0.09248564 0.0934687\n",
            " 0.09376829 0.09369565 0.09215199 0.08160811 0.08854856], argmax=3\n",
            "   \u001b[33m|->> #1/t=35-th Action selection: 9/SCALE DOWN (P(a|s) = 0.0820000022649765)\u001b[0m\n",
            "      |->> Bounding box moves to: [266 207  83  63]\n",
            "         |->> Action Probabilities (Rounded): [0.0891 0.0925 0.0896 0.0915 0.0931 0.0931 0.0941 0.0927 0.0914 0.0818\n",
            " 0.0911], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.08911068 0.09253816 0.08955936 0.09148429 0.09312682 0.09308499\n",
            " 0.09407654 0.09268188 0.09144171 0.08184231 0.09105324], argmax=6\n",
            "|->> Revisiting bbox: [266 207  83  63]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [261, 206,  86,  65] -> [266, 207,  83,  63] (Target was [230, 181,  88,  73])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.026) for 2X RIGHT:bbox transition: [261, 206,  86,  65] -> [265, 206,  86,  65] w/ P(a|s)=0.09457684308290482 and iou=0.2686378035902851 and reward=-0.02625333674168301 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [265, 206,  86,  65] -> [266, 207,  83,  63] w/ P(a|s)=0.08184231072664261 and iou=0.26539255076555546 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.06191437 -2.502961  ]\n",
            "\u001b[31m>> Total frame loss: -2.564875364303589\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "model, losses = epochs_train(adnet_model, Adam(learning_rate=LEARNING_RATE), \n",
        "                             datasets, epochs=N_EPOCHS, retry_count=N_RETRIES, \n",
        "                             randomize=RANDOMIZE_TRAINING)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LF9uTq5yY31"
      },
      "outputs": [],
      "source": [
        "# Plot losses\n",
        "fig = plt.figure()\n",
        "all_losses = np.concatenate([v for _, v in losses.items()])\n",
        "plt.plot(np.arange(len(all_losses)), all_losses) \n",
        "plt.xlabel('Number of Episodes')\n",
        "plt.ylabel('Avg Trajectory Loss')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "REWARDS_DIR_PATH = \"reward_csv_25678\"\n",
        "\n",
        "with open(\"{0}/{1}.csv\".format(REWARDS_DIR_PATH, REWARD_SCHEME),'w') as f:\n",
        "    wr = csv.writer(f)\n",
        "    wr.writerows(list(enumerate(all_losses)))"
      ],
      "metadata": {
        "id": "RX2AbeOKyaYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYQ1oThc1c_2"
      },
      "source": [
        "### Save Weights for Reproducibility"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ugPrvvmi0yI3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4zv5sM_K0yTD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZTaifbPkHeS",
        "outputId": "7570e3ed-dd9d-4fc3-ff93-ef2a13a415f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: derek_models/19-12-2021_225315/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: derek_models/19-12-2021_225315/assets\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p derek_models\n",
        "\n",
        "dt_string = datetime.now().strftime(\"%d-%m-%Y_%H%M%S\")\n",
        "model.save('derek_models/{0}'.format(dt_string))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "dt_string = datetime.now().strftime(\"%d-%m-%Y_%H%M%S\")\n",
        "model.save_weights(\"checkpoints/derek-{0}.h5\".format(dt_string))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1SsVnMeg8Up"
      },
      "outputs": [],
      "source": [
        "%debug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbUe72jpsol6"
      },
      "outputs": [],
      "source": [
        "# UNTESTED; uncomfirmed if works\n",
        "\n",
        "def move2Frame(model: ADNET, img: np.array, src_frame: int, src_bbox: np.array, \n",
        "               target_frame: int, target_bbox: np.array) -> np.array:\n",
        "  \n",
        "  bbox = src_bbox\n",
        "  actions = []\n",
        "  img = getFrame(dataset, target_frame) \n",
        "  target_bbox = gt[i]\n",
        "  for t in range(model.K):\n",
        "    patch = getPatch(img, bbox)\n",
        "    probs, conf_score = model(patch)\n",
        "    a_prob = tf.reshape(probs, (model.ACTION_DIM)) \n",
        "    a, bbox = selectMaxAction(np.array(img), bbox, a_prob)\n",
        "\n",
        "    actions.append(a)\n",
        "    model.updateActionHistory(a)\n",
        "    if isStop(a):\n",
        "        break  \n",
        "  \n",
        "  target_iou = calculate_IOU(bbox, target_bbox)   \n",
        "  return bbox, target_iou, actions\n",
        "\n",
        "\n",
        "def predict(model: ADNET, d: str, start_frame: int, end_frame: int):\n",
        "  gt = get_ground_truths(\"%s/groundtruth_rect.txt\" % d)\n",
        "  frames = sorted(glob.glob(os.path.join('%s/img' % d, '*.jpg'))) \n",
        "\n",
        "  ious = []\n",
        "  bbox = gt[start_frame]\n",
        "  model.clearActionHistory()\n",
        "  for i in range(start_frame+1, end_frame+1):\n",
        "    img = getFrame(dataset, i) \n",
        "    bbox, iou, actions = move2Frame(model, img, d)\n",
        "    ious.append(iou)\n",
        "  return model, ious\n",
        "\n",
        "\n",
        "def predict(model: ADNET, d: str):\n",
        "  gt = get_ground_truths(\"%s/groundtruth_rect.txt\" % d)\n",
        "  frames = sorted(glob.glob(os.path.join('%s/img' % d, '*.jpg'))) \n",
        "  return predict(model, d, 0, len(frames)-1)\n",
        "\n",
        "\n",
        "\n",
        "rand_idx = 11\n",
        "d = ALL_DATASETS_LIST[rand_idx] \n",
        "model, ious = predict(adnet_model, d)\n",
        "\n",
        "fig = plt.figure()\n",
        "for e in losses:\n",
        "  plt.plot(np.arange(len(ious)), ious) \n",
        "plt.xlabel('Frame')\n",
        "plt.ylabel('IOU')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMtzZ9r5nu8A"
      },
      "source": [
        "### Observations\n",
        "\n",
        "* The paper sums all sequence rewards. However, we found this to produce too much variance. We reduce_mean instead to address this. If we had"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmQvTRA7j9ET"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkTBunYkHcUQ"
      },
      "outputs": [],
      "source": [
        "print(erroneous_datasets)\n",
        "\n",
        "# !ls adnet_datasets/OTB/Diving/img/\n",
        "# ! wc -l adnet_datasets/OTB/Diving/groundtruth_rect.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0g-v8GupB9y"
      },
      "outputs": [],
      "source": [
        "def predict(model: tf.keras.Model,img: np.array,bbox: np.array) -> np.array:\n",
        "  ACTION_DIM=11\n",
        "  K=10\n",
        "  \n",
        "  action_hist = np.zeros((ACTION_DIM * K, 1))\n",
        "  seen_bboxes = set()\n",
        "  for t in range(K):\n",
        "    #model.setActionHistory(action_hist.reshape((1, 1, 1, ACTION_DIM * K)))\n",
        "    model.setActionHistory(action_hist.reshape((1,ACTION_DIM * K))) ### For ADNET_v2\n",
        "    patch = tf.image.resize(img[bbox[1]:(bbox[1] + bbox[3]), \n",
        "                                bbox[0]:(bbox[0] + bbox[2])], [112, 112])\n",
        "    patch = tf.reshape(patch, (1, 112, 112, 3))\n",
        "    a_prob = tf.reshape(model(patch)[0], (ACTION_DIM)) \n",
        "    a, bbox = selectAction(np.array(img), bbox, a_prob)\n",
        "    if isStop(a) or tuple(bbox) in seen_bboxes:\n",
        "      break\n",
        "\n",
        "    action_hist[t * ACTION_DIM + a] = 1 \n",
        "    seen_bboxes.add(tuple(bbox))\n",
        "  return bbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03dOCNAKz6sg"
      },
      "outputs": [],
      "source": [
        "def plotNpImageBBoxGT(img: np.array, bbox: np.array,gbbox: np.array) -> np.array:\n",
        "  '''\n",
        "  Plots the bounding box on an image and returns the bounding box\n",
        "  '''\n",
        "  fig, ax = plt.subplots()\n",
        "  x_pre,y_pre, w_pre, h_pre = bbox\n",
        "  x_gr,y_gr, w_gr, h_gr = gbbox\n",
        "  predicted_rect = patches.Rectangle((x_pre, y_pre), w_pre, h_pre, linewidth=1, edgecolor='r', facecolor='none')\n",
        "  gt_rect = patches.Rectangle((x_gr, y_gr), w_gr, h_gr, linewidth=1, edgecolor='b', facecolor='none')\n",
        "  ax.add_patch(predicted_rect)\n",
        "  ax.add_patch(gt_rect)\n",
        "  plt.imshow(img)\n",
        "  return bbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAvwFremUHsQ"
      },
      "outputs": [],
      "source": [
        "ALL_DATASETS_LIST = glob.glob(\"adnet_datasets/OTB/*\")\n",
        "j = random.randint(0, len(ALL_DATASETS_LIST)) \n",
        "dataset = ALL_DATASETS_LIST[j] \n",
        "frames = sorted(glob.glob(os.path.join('%s/img' % dataset, '*.jpg')))\n",
        "gt = get_ground_truths(\"%s/groundtruth_rect.txt\" % dataset)\n",
        "\n",
        "predicted_bbox = gt[0]\n",
        "for i, frame in enumerate(frames[1:]):\n",
        "  img = cv2.imread(frame)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  print(img.shape)\n",
        "  predicted_bbox=predict(model,img,predicted_bbox)\n",
        "  print(predicted_bbox)\n",
        "  gtbbox=gt[i]\n",
        "  plotNpImageBBoxGT(img,predicted_bbox,gtbbox)\n",
        "  #print(gtbbox)\n",
        "  #print(predicted_bbox)\n",
        "  break\n",
        "  #bbox = \n",
        "  #print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhMMozN6J64i"
      },
      "outputs": [],
      "source": [
        "def test_metrics( model: tf.keras.Model, model2:tf.keras.Model  ):\n",
        "    all_boxes = []\n",
        "    all_gt = []\n",
        "    time_perframe_for_each_video =[]\n",
        "    test_list = glob.glob(\"adnet_datasets/Test/*\")\n",
        "    d = ALL_DATASETS_LIST[rand_idx] \n",
        "    gt = get_ground_truths(\"%s/groundtruth_rect.txt\" % d)\n",
        "  \n",
        "    for  i in range(len(test_list)):  # start with 1\n",
        "      dataset = test_list[i]\n",
        "      print(dataset)\n",
        "      #frames = sorted(glob.glob(os.path.join('%s/img' % dataset, '*.jpg')))\n",
        "      gt = get_ground_truths(\"%s/groundtruth_rect.txt\" % dataset)     \n",
        "      all_gt.append(gt)\n",
        "      frames = sorted(glob.glob(os.path.join('%s/img' % dataset, '*.jpg')))\n",
        "      print(frames)\n",
        "      number_of_frames = len(frames)\n",
        "      #start_frame = random.randint(0, number_of_frames) maybe to test robustnes do not start always with first frame TRE\n",
        "      start_frame = 0\n",
        "      boxes_m1 =[]\n",
        "      boxes_m2 = []\n",
        "      time_perframe = []\n",
        "      predicted_box = gt[0]\n",
        "      predicted_box2 = gt[0]\n",
        "      start = time.time()\n",
        "      for f in range(len(frames) - start_frame):\n",
        "        img = cv2.imread(frames[f])\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        predicted_bbox=predict(model,img,predicted_box)\n",
        "        #predicted_bbox2 = predict(model, img,predicted_bbox) if we want to compare 2 models\n",
        "        boxes_m1.append(predicted_box)\n",
        "        #boxes_m2.append(predicted_bbox)\n",
        "      end = time.time()\n",
        "      time_perframe = (start-end)/len(frames)\n",
        "      all_boxes.append(boxes_m1)\n",
        "      time_perframe_for_each_video.append(time_perframe)\n",
        "    return all_boxes, all_gt , time_perframe_for_each_video\n",
        "\n",
        "\n",
        "\n",
        "all_boxes, all_gt , time_perframe_for_each_video = test_metrics(model , adnet_model)\n",
        "print (all_boxes)\n",
        "print(all_gt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9712yCAxLmtI"
      },
      "source": [
        "# TESTING & DEBUGGING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Me8c91RVoLvD"
      },
      "outputs": [],
      "source": [
        "# Update this with the appropriate dataset\n",
        "TEST_IMAGE_PATH = \"adnet_datasets/OTB/Couple/img/0082.jpg\"\n",
        "TEST_BBOX = get_ground_truths(\"adnet_datasets/OTB/Couple/groundtruth_rect.txt\")[82]\n",
        "TEST_IMAGE = cv2.imread(TEST_IMAGE_PATH)\n",
        "\n",
        "\n",
        "# Update the following two vars\n",
        "src_bbox = np.array([143, 131, 34, 87]) \n",
        "pred_bbox = np.array([138, 41, 32, 89])\n",
        "print(plotNpImageBBoxes(TEST_IMAGE, src_bbox, TEST_BBOX, pred_bbox))\n",
        "\n",
        "\n",
        "print(\"IOU: {0}\".format(calculate_IOU(pred_bbox, src_bbox)))\n",
        "\n",
        "print(\"Test bbox is: {0}\".format(TEST_BBOX))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzbeopDmi6q_"
      },
      "outputs": [],
      "source": [
        "# VERTICAL MOVEMENT TESTING \n",
        "TEST_IMAGE_PATH = \"adnet_datasets/OTB/Skater2/img/0005.jpg\"\n",
        "TEST_BBOX = get_ground_truths(\"adnet_datasets/OTB/Skater2/groundtruth_rect.txt\")[4]\n",
        "TEST_IMAGE = cv2.imread(TEST_IMAGE_PATH)\n",
        "\n",
        "# Test move down\n",
        "print(\"Down-shifted bounding box\")\n",
        "bbox = move2(img, TEST_BBOX, \"down\")\n",
        "print(plotNpImageBBox(img, bbox))\n",
        "\n",
        "print(\"Down-shifted bounding box\")\n",
        "bbox = move2(img, bbox, \"down\")\n",
        "print(plotNpImageBBox(img, bbox))\n",
        "\n",
        "print(\"Down-shifted bounding box\")\n",
        "bbox = move2(img, bbox, \"down\")\n",
        "print(plotNpImageBBox(img, bbox))\n",
        "\n",
        "print(\"Down-shifted bounding box\")\n",
        "bbox = move2(img, bbox, \"down\")\n",
        "print(plotNpImageBBox(img, bbox))\n",
        "\n",
        "\n",
        "print(\"Down-shifted bounding box\")\n",
        "bbox = move2(img, bbox, \"down\")\n",
        "print(plotNpImageBBox(img, bbox))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNBblMU8d4qh"
      },
      "outputs": [],
      "source": [
        "# HORIZONTAL MOVEMENT TESTING \n",
        "TEST_IMAGE_PATH = \"adnet_datasets/OTB/Skater2/img/0005.jpg\"\n",
        "TEST_BBOX = get_ground_truths(\"adnet_datasets/OTB/Skater2/groundtruth_rect.txt\")[4]\n",
        "TEST_IMAGE = cv2.imread(TEST_IMAGE_PATH)\n",
        "\n",
        "img, bbox = TEST_IMAGE, TEST_BBOX\n",
        "print(\"Original bounding box\")\n",
        "print(plotNpImageBBox(img, TEST_BBOX))\n",
        "\n",
        "# Test move left\n",
        "print(\"Left-shifted bounding box\")\n",
        "bbox = move2(img, TEST_BBOX, \"left\")\n",
        "print(plotNpImageBBox(img, bbox))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1MXfEC2IDNk"
      },
      "outputs": [],
      "source": [
        "# MOVEMENT TEST\n",
        "\n",
        "print(\"IOU between {1} and {2} is {0}\".format(calculate_IOU(np.array([143, 131,  34,  87]), np.array([138,  41,  32,  89])), [143, 131,  34,  87], [138,  41,  32,  89]))\n",
        "\n",
        "for i in range(11):\n",
        "  print(selectAction(np.zeros([300, 300, 3]), np.array([252, 65, 25, 30]), i))\n",
        "\n",
        "print(selectAction(np.zeros([300, 300, 3]), np.array([131,7,117,168]), 5))\n",
        "print(\"The following UP should do nothing because 0.03 * 168 * 2 is too large\")\n",
        "print(selectAction(np.zeros([300, 300, 3]), np.array([131,7,117,168]), 5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1j-Ud5nXofHE"
      },
      "outputs": [],
      "source": [
        "print(selectAction(np.zeros([450, 450, 3]), np.array([315,  0, 32,  35]), 5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBBRcPEAohhe"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Copy of safe_reinforce.ipynb",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}