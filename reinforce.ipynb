{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/da2985/e6885-adnet/blob/main/reinforce.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c1BWwgpSXW9"
      },
      "source": [
        "# Imports & Starting Configs\n",
        "\n",
        "Please use the following two lines to load from Google Drive\n",
        "\n",
        "If your file is not there, upload it to https://drive.google.com/drive/folders/1tsPKyB2E1nW8Qw--kZ9GaeGW2u2-XoV6?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqT6TJ9DLT5v",
        "outputId": "f9856018-06b9-41f6-c99e-06e2759ba3dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# This must be run within a Google Colab environment \n",
        "from google.colab import drive  \n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2sTHMZwqNPlW"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "sys.path.append('/content/gdrive/EE6885')\n",
        "\n",
        "os.chdir(\"/content/gdrive/My Drive/EE6885\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvlhZxrmdezd",
        "outputId": "f835072c-3ccc-4800-cc70-69703821cc6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Basketball   Car24\t Dog1\t      Human5\t     MountainBike   Surfer\n",
            " Bird2\t      Car4\t Doll\t      Human6\t     Panda\t    Suv\n",
            " BlurBody     CarDark\t DragonBaby   Human7\t     RedTeam\t    Sylvester\n",
            " BlurCar1     CarScale\t Dudek\t      Human8\t     Rubik\t    Tiger1\n",
            " BlurCar2     ClifBar\t FaceOcc1     Human9\t     Shaking\t    Tiger2\n",
            " BlurCar3     Coke\t FaceOcc2     Ironman\t     Singer1\t    Toy\n",
            " BlurCar4     Couple\t Fish\t      Jogging\t     Singer2\t    Trans\n",
            " BlurFace     Coupon\t FleetFace    Jump\t     Skater\t    Trellis\n",
            " BlurOwl      Crossing\t Football1    Jumping\t     Skater2\t    Twinnings\n",
            " Board\t      Crowds\t Freeman1     KiteSurf\t    'Skater2 (1)'   Vase\n",
            " Bolt\t      Dancer\t Girl\t      Lemming\t     Skating1\t    Walking\n",
            " Bolt2\t      Dancer2\t Girl2\t      Liquor\t     Skating2\t    Walking2\n",
            " Box\t      David2\t Gym\t      Man\t     Skating3\t    Woman\n",
            " Boy\t      David3\t Human2       Matrix\t     Skiing\n",
            " Car1\t      Deer\t Human3       Mhyang\t     Soccer\n",
            " Car2\t      Dog\t Human4       MotorRolling   Subway\n"
          ]
        }
      ],
      "source": [
        "!ls adnet_datasets/OTB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNOHmxvDD8wD",
        "outputId": "0cf23fd4-bfc3-496f-ea00-a1034d88d67c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hdf5storage in /usr/local/lib/python3.7/dist-packages (0.1.18)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (0.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from hdf5storage) (1.19.5)\n",
            "Requirement already satisfied: h5py>=2.1 in /usr/local/lib/python3.7/dist-packages (from hdf5storage) (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.1->hdf5storage) (1.5.2)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n"
          ]
        }
      ],
      "source": [
        "pip install hdf5storage tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gNmhYpyeDLrQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "import tensorflow_probability as tfp\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow.experimental.numpy as tnp\n",
        "\n",
        "import cv2\n",
        "import glob\n",
        "import hdf5storage\n",
        "import math\n",
        "import random\n",
        "import re\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.patches as patches\n",
        "import scipy.io as sio\n",
        "\n",
        "import linecache\n",
        "\n",
        "from typing import Dict, List, Tuple\n",
        "from operator import add\n",
        "import copy\n",
        "\n",
        "from numpy.random import seed\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UsXgP5KrEGNW"
      },
      "outputs": [],
      "source": [
        " %load_ext autoreload \n",
        " %autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdgRU7dpw6t4"
      },
      "source": [
        "# Configurations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "G3xZrSk9XdEA"
      },
      "outputs": [],
      "source": [
        "#@markdown Network configurations\n",
        "LEARNING_RATE = 1e-4 #@param {type:\"number\"}\n",
        "GOAL_IOU = 0.7 #@param {type:\"number\"}\n",
        "\n",
        "# The length of the action buffer\n",
        "L = 10 #@param {type:\"number\"}\n",
        "# Max Trajectory Length \n",
        "MAX_TRAJECTORY_LENGTH =  10#@param {type:\"number\"}\n",
        "POLICY_TYPE = \"stochastic\" #@param [\"deterministic\", \"stochastic\"] {type:\"string\"}\n",
        "DROPOUT_4 = 0.5 #@param {type:\"number\"}\n",
        "DROPOUT_5 = 0.5 #@param {type:\"number\"}\n",
        "N_EPOCHS =  1#@param {type:\"number\"}\n",
        "\n",
        "# Number of retries to collect sequence loss sum (to reduce variance)\n",
        "N_RETRIES =   1#@param {type:\"number\"}\n",
        "\n",
        "# Randomizes the order in which frames are trained on from a video clip\n",
        "RANDOMIZE_TRAINING = False #@param {type:\"boolean\"}\n",
        "\n",
        "# The paper uses sum. I thought avg would help address giant swings, but the training was taking way too long\n",
        "# with negligible updates\n",
        "GRAD_ACCUM_SCHEME = \"sum\" #@param [\"avg\", \"sum\"] {type:\"string\"}\n",
        "\n",
        "# Use to avoid overly long trajectories. \n",
        "# During trajectory collection, we were not receiving \n",
        "# enough positvie signals\n",
        "PREMATURE_BREAK = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Loss/Reward Constants\n",
        "# This is a probability offset for adding noise since log(P(a|s)=1)=0\n",
        "PROB_OFFSET = 1e-5 #@param {type:\"number\"} \n",
        "# This is the discount factor\n",
        "GAMMA = 1 #@param {type:\"number\"}\n",
        "\n",
        "# final_bbox is used in original Ad Net where  the final bounding box placement \n",
        "# is used in reward calculationfor all actions in a trajectory\n",
        "# individ_bbox individually assign rewards per each bounding box.\n",
        "# only_final_bbox only gives a reward to the final action\n",
        "REWARD_SCHEME = \"only_final_bbox\" #@param [\"only_final_bbox\", \"final_bbox\", \"individ_bbox\"] {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Bounding Box/Patch Constants (probably avoid touching)\n",
        "ALPHA = 0.03 #@param {type:\"number\"}\n",
        "MIN_WINDOW_SIZE = 10 #@param {type:\"number\"}\n",
        "PATCH_X = 112 #@param {type:\"number\"}\n",
        "PATCH_Y = 112 #@param {type:\"number\"}\n",
        "N_CHANNELS = 3 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown ---\n",
        "RANDOM_SEED = 6885\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AQ4YPvJCt9Dg"
      },
      "outputs": [],
      "source": [
        "seed(RANDOM_SEED)\n",
        "tf.random.set_seed(RANDOM_SEED)\n",
        "\n",
        "DATASET_PATH = \"adnet_datasets/OTB/*\" #@param {type:\"string\"}\n",
        "ALL_DATASETS_LIST = glob.glob(DATASET_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCB-wEWrfk6N"
      },
      "source": [
        "### Successful Configurations (Minimize Me Please)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "mKjyrVB3fdcT"
      },
      "outputs": [],
      "source": [
        "### SUCCESSFUL CONFIGS\n",
        "\n",
        "# 12/18 4:41 PM\n",
        "# #@markdown Network configurations\n",
        "# LEARNING_RATE = 1e-4 #@param {type:\"number\"}\n",
        "# # The length of the action buffer\n",
        "# L = 10 #@param {type:\"number\"}\n",
        "# # Max Trajectory Length \n",
        "# MAX_TRAJECTORY_LENGTH = 20 #@param {type:\"number\"}\n",
        "# POLICY_TYPE = \"stochastic\" #@param [\"deterministic\", \"stochastic\"] {type:\"string\"}\n",
        "# DROPOUT_4 = 0.5 #@param {type:\"number\"}\n",
        "# DROPOUT_5 = 0.5 #@param {type:\"number\"}\n",
        "# N_EPOCHS =  1#@param {type:\"number\"}\n",
        "\n",
        "# # Number of retries to collect sequence loss sum (to reduce variance)\n",
        "# N_RETRIES =  4 #@param {type:\"number\"}\n",
        "\n",
        "# # Randomizes the order in which frames are trained on from a video clip\n",
        "# RANDOMIZE_TRAINING = True #@param {type:\"boolean\"}\n",
        "# GRAD_ACCUM_SCHEME = \"sum\" #@param [\"avg\", \"sum\"] {type:\"string\"}\n",
        "# # The paper uses sum\n",
        "\n",
        "\n",
        "# #@markdown ---\n",
        "# #@markdown Loss/Reward Constants\n",
        "# # This is a probability offset for adding noise since log(P(a|s)=1)=0\n",
        "# PROB_OFFSET = 1e-5 #@param {type:\"number\"} \n",
        "# # This is the discount factor\n",
        "# GAMMA = 0.99 #@param {type:\"number\"}\n",
        "# REWARD_SCHEME = \"final_bbox\" #@param [\"final_bbox\", \"individ_bbox\"] {type:\"string\"}\n",
        "\n",
        "# #@markdown ---\n",
        "# #@markdown Bounding Box/Patch Constants (probably avoid touching)\n",
        "# ALPHA = 0.03 #@param {type:\"number\"}\n",
        "# MIN_WINDOW_SIZE = 10 #@param {type:\"number\"}\n",
        "# PATCH_X = 112 #@param {type:\"number\"}\n",
        "# PATCH_Y = 112 #@param {type:\"number\"}\n",
        "# N_CHANNELS = 3 #@param {type:\"number\"}\n",
        "\n",
        "# #@markdown ---\n",
        "# RANDOM_SEED = 6885\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8s6YHABjUG5"
      },
      "source": [
        "## Model Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfRbj1tuEIyA",
        "outputId": "f1bccd96-4161-45d5-ddd9-5046bd092550"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  0\n"
          ]
        }
      ],
      "source": [
        "class ADNET(tf.keras.Model):\n",
        "\n",
        "    ACTION_DIM = 11\n",
        "    K = 10\n",
        "    CONF_SCORE_DIM = 2\n",
        "\n",
        "    def __init__(self):\n",
        "        super(ADNET, self).__init__()\n",
        "\n",
        "        self.action_history = tf.keras.layers.Input(shape = (1,1, ADNET.ACTION_DIM * ADNET.K))\n",
        "\n",
        "        self.conv1 = tf.keras.layers.Conv2D(filters = 96, kernel_size = (7, 7), strides = (2, 2), padding = 'VALID', activation = 'relu', name = 'conv_1')\n",
        "        self.max1  = tf.keras.layers.MaxPooling2D(pool_size=(3,3), strides = (1, 1), padding = 'VALID')\n",
        "        self.conv2 = tf.keras.layers.Conv2D(filters = 256, kernel_size = (5, 5), strides = (2, 2), padding = 'VALID', activation = 'relu', name = 'conv_2')\n",
        "        self.max2  = tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides = (2, 2), padding = 'VALID')\n",
        "        self.conv3 = tf.keras.layers.Conv2D(filters = 512, kernel_size = (3, 3), strides = (2, 2), padding = 'VALID', activation = 'relu', name = 'conv_3')\n",
        "        self.max3  = tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides = (1, 1), padding = 'VALID')\n",
        "        \n",
        "        self.fc1 = tf.keras.layers.Conv2D(filters = 512, kernel_size = (3, 3), padding = 'VALID', activation = 'relu', name = 'fc1')\n",
        "        self.fc2 = tf.keras.layers.Conv2D(filters = 512, kernel_size = (1,1), padding = 'VALID', activation = 'relu', name = 'fc2')\n",
        "        self.fc3 = tf.keras.layers.Conv2D(filters = 11, kernel_size = (1,1), padding = 'VALID', name = 'fc3',activation=\"softmax\")\n",
        "        self.fc4 = tf.keras.layers.Conv2D(filters = 2, kernel_size = (1,1), padding = 'VALID', name = 'fc4',activation=\"softmax\")\n",
        "\n",
        "        # TODO: ADD A SEED\n",
        "        self.dropout1=tf.keras.layers.Dropout(DROPOUT_4)\n",
        "        self.dropout2=tf.keras.layers.Dropout(DROPOUT_5)\n",
        "        \n",
        "\n",
        "    def build(self):\n",
        "      super(ADNET, self).build((None, 112, 112, 3))\n",
        "      self.action_history = np.zeros(shape = (1,1,1,110))\n",
        "\n",
        "\n",
        "    def call(self, input_tensor, training=False):\n",
        "        x = self.conv1(input_tensor)\n",
        "        x = self.max1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.max2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.max3(x)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = tf.keras.layers.Concatenate(axis=-1)([x, self.action_history])\n",
        "        action = self.fc3(x)\n",
        "        confidence = self.fc4(x)\n",
        "        return [action, confidence]\n",
        "\n",
        "\n",
        "    def compile(self, optimizer):\n",
        "   \t\tsuper().compile(optimizer, loss={\n",
        "         'output_1':tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "         'output_2': tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "         })\n",
        "     \n",
        "    def getEmbedding(self,input_tensor):\n",
        "        x = self.conv1(input_tensor)\n",
        "        x = self.max1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.max2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.max3(x)\n",
        "        return tf.reshape(x,(-1,))\n",
        "\n",
        "    def getFC1(self,input_tensor):\n",
        "        x = self.conv1(input_tensor)\n",
        "        x = self.max1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.max2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.max3(x)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "    def setActionHistory(self, action_history):\n",
        "      self.action_history = action_history.reshape(\n",
        "          (1, 1, 1, ADNET.ACTION_DIM * ADNET.K))\n",
        "\n",
        "    def updateActionHistory(self, a: int=8) -> tnp.ndarray:\n",
        "      '''\n",
        "      Left-to-right FIFO queue of actions\n",
        "      '''\n",
        "      ah = np.array(self.action_history).flatten()\n",
        "      ah[ADNET.ACTION_DIM:] = ah[:-ADNET.ACTION_DIM]\n",
        "      ah[:ADNET.ACTION_DIM] = 0 \n",
        "      ah[a] = 1\n",
        "      self.setActionHistory(ah)\n",
        "      return ah\n",
        "\n",
        "    def clearActionHistory(self):\n",
        "      self.action_history = tf.zeros((1, 1, 1, ADNET.ACTION_DIM * ADNET.K))\n",
        "\n",
        "    def getPrettyActionHistory(self):\n",
        "      action_hist = tf.reshape(self.action_history, [-1])\n",
        "      sbuffer = \"[\"\n",
        "      for i, x in enumerate(action_hist):\n",
        "        if i > 0 and i % ADNET.ACTION_DIM == 0:\n",
        "          sbuffer+= \"\\x1b[35m,\\x1b[0m\"\n",
        "        if x == 1:\n",
        "          sbuffer += \"\\x1b[35m{0}\\x1b[0m\".format(int(x))\n",
        "        else:\n",
        "          sbuffer += \"{0}\".format(int(x))\n",
        "      sbuffer += \"]\"\n",
        "      return sbuffer \n",
        "\n",
        "\n",
        "    def debugModelSummary(self):\n",
        "      '''\n",
        "      call model.debugModelSummary().summary() to get around the inconvenience \n",
        "      from model.summary() returning 'multiple' for each layer's output shape\n",
        "      '''\n",
        "      dummyInput = tf.keras.layers.Input(shape = (112,112,3))\n",
        "      return tf.keras.Model(inputs=[dummyInput], outputs = self.call(dummyInput))\n",
        "\n",
        "def setAllWeights(model, weights):\n",
        "  model.layers[0].set_weights([weights[\"conv1f\"], tf.reshape(weights[\"conv1b\"],(96,))])\n",
        "  model.layers[2].set_weights([weights[\"conv2f\"], tf.reshape(weights[\"conv2b\"],(256,))])\n",
        "  model.layers[4].set_weights([weights[\"conv3f\"], tf.reshape(weights[\"conv3b\"],(512,))])\n",
        "  model.layers[6].set_weights([weights[\"fc4f\"], tf.reshape(weights[\"fc4b\"],(512,))])\n",
        "  model.layers[7].set_weights([weights[\"fc5f\"], tf.reshape(weights[\"fc5b\"],(512,))])\n",
        "  model.layers[8].set_weights([weights[\"fc6_1f\"], tf.zeros(11)])\n",
        "  model.layers[9].set_weights([weights[\"fc6_2f\"], tf.zeros(2)])\n",
        "\n",
        "\n",
        "def setWeights(model, weights, weights2):\n",
        "  model.layers[0].set_weights([weights2[\"conv1f\"],tf.reshape(weights2[\"conv1b\"],(96,))])\n",
        "  model.layers[2].set_weights([weights2[\"conv2f\"],tf.reshape(weights2[\"conv2b\"],(256,))])\n",
        "  model.layers[4].set_weights([weights2[\"conv3f\"],tf.reshape(weights2[\"conv3b\"],(512,))])\n",
        "  \n",
        "  model.layers[6].set_weights([weights[\"fc4f\"],tf.reshape(weights[\"fc4b\"],(512,))])\n",
        "  model.layers[7].set_weights([weights[\"fc5f\"],tf.reshape(weights[\"fc5b\"],(512,))])\n",
        "  model.layers[8].set_weights([weights[\"fc6_1f\"],tf.zeros(11)])\n",
        "  model.layers[9].set_weights([weights[\"fc6_2f\"],tf.zeros(2)])\n",
        "  \n",
        "  return model\n",
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "WwHHmGrxq-b6"
      },
      "outputs": [],
      "source": [
        "class ADNET_v2(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(ADNET_v2, self).__init__()\n",
        "\n",
        "        #self.action_history = tf.keras.layers.Input(shape = (1,1,110))\n",
        "        self.action_history = tf.keras.layers.Input(shape = (110))\n",
        "\n",
        "        self.resnet=tf.keras.applications.ResNet50V2(include_top=False,weights=\"imagenet\",input_shape=(112,112,3),pooling=\"max\")\n",
        "        #self.resnet = tf.keras.applications.ResNet50V2(include_top=False,weights=\"imagenet\",input_shape=(112,112,3),pooling=None)\n",
        "        #self.conv1 = tf.keras.layers.Conv2D(filters = 128, kernel_size = (4,4), padding = 'VALID', name = 'fc4',activation=\"relu\")\n",
        "        \n",
        "        self.fc1 = tf.keras.layers.Dense(512,kernel_initializer='glorot_uniform',activation = 'relu', name = 'fc1')\n",
        "        self.fc2 = tf.keras.layers.Dense(512,kernel_initializer='glorot_uniform', activation = 'relu', name = 'fc2')\n",
        "        self.fc3 = tf.keras.layers.Dense(11,kernel_initializer='glorot_uniform', name = 'fc3',activation=\"softmax\")\n",
        "        self.fc4 = tf.keras.layers.Dense(2,kernel_initializer='glorot_uniform',name = 'fc4',activation=\"softmax\")\n",
        "\n",
        "        self.dropout1=tf.keras.layers.Dropout(0)\n",
        "        self.dropout2=tf.keras.layers.Dropout(0)\n",
        "        \n",
        "\n",
        "    def build(self, action_history):\n",
        "      super(ADNET_v2, self).build((None, 112, 112, 3))\n",
        "      self.action_history=action_history\n",
        "      self.resnet.trainable = False\n",
        "\n",
        "\n",
        "    def setActionHistory(self, action_history):\n",
        "      self.action_history=action_history\n",
        "\n",
        "\n",
        "    def call(self, input_tensor, training=False):\n",
        "        x = self.resnet(input_tensor)\n",
        "        #x = self.conv1(x)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x=  self.dropout1(x)\n",
        "        x = self.fc2(x)\n",
        "        x=  self.dropout2(x)\n",
        "        x = tf.keras.layers.Concatenate(axis=-1)([x, self.action_history])\n",
        "        action = self.fc3(x)\n",
        "        confidence = self.fc4(x)\n",
        "        return [action, confidence]\n",
        "\n",
        "     \n",
        "    def debugModelSummary(self):\n",
        "      '''\n",
        "      call model.debugModelSummary().summary() to get around the inconvenience \n",
        "      from model.summary() returning 'multiple' for each layer's output shape\n",
        "      '''\n",
        "      dummyInput = tf.keras.layers.Input(shape = (112,112,3))\n",
        "      return tf.keras.Model(inputs=[dummyInput], outputs = self.call(dummyInput))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcjMuA1EjRsE"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xY2WCmjC2gLN"
      },
      "source": [
        "### Plotting & Debugging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "NtQ22_87T8MQ",
        "outputId": "43913722-7cf8-4df0-e7a4-a95b88c7d8fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[171 128  99 316]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAAD8CAYAAAARze3ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9y69nWXbn9Vlrn/P7/e4zIjKrKh/1clZ14XbZxpgW7hlCSIiHWvIMASNGPWKO/wKExAiBhNSDFvQI5mCJQQNihLDbGES7yuV6V1Zl5SMyIm5E3Ht/v3P2XgzWWvuc383ITAu53FFS7FTkvff3OOfs13d913OLmfGqvWqv2qv2qn1603/RD/CqvWqv2qv2srdXQPmqvWqv2qv2Oe0VUL5qr9qr9qp9TnsFlK/aq/aqvWqf014B5av2qr1qr9rntFdA+aq9aq/aq/Y57VcClCLy74jIX4rI90Xkj34V93jVXrVX7VX722ryNx1HKSIF+B7wbwHvAn8C/Idm9hd/ozd61V61V+1V+1tqvwpG+QfA983sh2Z2AP574A9/Bfd51V61V+1V+1tpw6/gml8Gfrb6+13g73/WF7bbrZ2eniEigCxv3P01/ifrL8vRX3ziE5942z75mfW1zI6uKZbf8NdrbdTWUJXV5QWwO1eU/sNWv/RL373Pne8c/20IwhH3/0QXX3j3uJbceSeeSAREENXen+XLsnxvNS6S37dVn2W5n0XXYDVu/TX7xHMuT2TLF1n/akdj3F8XQUT96mZLt0SWHvbP9hnoT7R+irs6lcQ183Of1LnsBS8uvV2eYPVtOx6PT3xz1YV83rsfXZ77Bdf4XMXQPvuvz/x+H8g793vxl+zoej5n+ZodXe14vYsIn9y7cvfXz2jyyYm9szaPLt374u988P4vPzKzL77oyr8KoPxrNRH5h8A/BNjuTvjX/81/G9WBokopBcEQMSgFRCkagxgbAYOi6vgTgCPiG/5oAkQIPGABCMAEFQ1w9sHK31V8dM0Aa6goLT6jojx7es1shpaCxUQUFBGjSNxAhGaGaN5coS3PA34/fwb1haISrwmKrD7rP1vvB32mDe+/X8O/533wvqqq3xvt/W1WMauIFsZx668Bw7hBy+D9LAPNDKiUeM4cO7EG1VDUxyqewVRpBg3xvsTPZeTBYtxbaxgNRVAN0KZh1rAmtCao5DrwQa42U6v1DdDHrn+33yXmjgBTv670wbvbGiAdbBx+a7+emcW/RWaAoXfezwFSVSTmurXW//XrSazt/v14BIxGw8SwBBhrrLe6rCSRHQmW9kKw7J+xhrV6NBdtmZVPfGe9L/wZYmQs79VW9/Rnbc0/15phzaLfRm2NWivN4vfWUFVKGRmGgXEcKEPxda8xn31uQcRiLywCKIX8+tH9T//u0q9j4G3Wen+t+RyY+Xj/V//Ff/aTT46gt18FUP4c+Orq76/Ea0fNzP4R8I8ALi7v2dXTJ5ydncMwgpgDnoGYIRit5SbF3xMnNYZ/pmgBhFZt+X5nIAtTFZEgIMtCuNvWkt23TKOU4ou5NS4uzthPB5op4ruc0q0YLZ5PMMyfWZd7y/pZAgQkxF4yahHpmxDxcVDR2EB+D+KzlgAKAa7q/U8G1teJ0STRw2j4uM5WHXAotLliDQRlniekCCKNhvpYN1AFpHSmmoLJWYMvXgswUVVatc7QwOesERu2NUz9ukEGfdE2wcxoVlEEo1LNqAFWxDpADZHm82KfZIwONvN6zX3KnC+vi/i3ffO0/vv6yiKxyZYLAy5gpTNao5mDRW0Va9aFHrEx+3fF15qrLwswrkE51+2nUz8XFuv+5zMnkHec4ZjZuUBZMXGW+7ZVP81SeDh4rsEfpAOjAyXU6n/nZ5s1aI2CsB03lHFLKQUtQY5UY30BUj5BKnxPtVjbsZNSq8inCKKyjNd6msxXfR/HmFvR1Xi9uP0qgPJPgG+JyDs4QP4HwH/0WV9Q9QF4fv2M3e6E7W6LmvgAmgNKsiLwSZAuTXzTercborEIVqpTBy1YrSJZfu0f9Ocxac6GRBbFrz+CYK0xjgOiBZESQLFsIv9KCyD0L6/Z8KJe5GQnyJA01oVi3yQEMCWbcrblPfaFqCu1eK2mBAQQYqMzUgsGY636phXDTBBqH2uhOFios9B4ZIIrYkBrDs7NJUpnlgJYrUuXcsxrXTEDB5wqLONgAWTmz9tSVFnDArAlBQQtsYEBIbeMb4RkQYvGkS0B+bhZH99G7esi2dQn2KgIrdUOivkZUXEQ1WSFieKWqkz0McY/7iuxZgimmeMmefV4TUL42dI9kgt0EDvqlS2vS34ul9ZKPTFZ9o3Z8bUsrtOCRYZkSqBMNumg6EDZDGprvleDmBQRdPD9Og7CsBko6gApKvFzmaO+JYSuuUhqZzFjCfB9HIIy0Pvq45Ysd7VAYknKJ+f2Be1vHCjNbBaR/wT4n4EC/GMz++ef9R3Rwtn5Bfv9xHRoqFbGsQRrbMtCF42pa6gkTHRoiHdCpTVxlTTvYYaodSnUrDnImTiLSNxVc+ZmMMiw0Hs1TGr2EpohKCqtS7pYDgsYQTCUYJbk5CRryKW/gu2jz2W//N6SrDWEQG72IRVuTeEgseGJ7+SCkr6rxGLhyMIm+maTBuJQD9pBVSSvnfDrC9AX9fJsIg0JWtm6GieYxAy1lWrX/5dj0PCN4AKoWQLOwuxElz6uEIVG6wxk2eCBKl16JKgt668161sv0LELYrPWPyxxLwuk6xqDsKiM5qBYzZlka3nvUPtW913YWc4nYG35SCJqCn2RAKrsV4Cb2ArAcrkuvFKwUDnjr2TmCFj2PK+xgHtXuZt2kOyqqzR/rTUHxVqpdfl+QzBpNIyiQ5hpghQJlFEpBUpxgAQ9MpPlthOJfXyEAUE6zBbSEes4H9kk+imECck6UWmxnrUUSjf7fHb7ldgozeyPgT/+635eRTg7OWMsE9NhotVKU7dBtuLcRcUQm7sNLxliglyqTJL2OgkABAfVZHMxCxrsL1X8lLa+3/OPLsO9X/gWFlkt2oarDDGZLdRiubMgXSXuhDDaIguXOxyNZH82cz7l3woG3uIZNWxFYm4GSBuT9zlti3ftscHOc8PEv/yc9c85cKXa2FqC0aLyNGsBLgGWtTnzMzp4ZL9zmy+bOO9tqzldmE1nntZIB1IyiuWbvvj9HosNanEO5pNaH5sOurE5LUw8vqFic8XaggD8nCJbrkXMfdp/zdwe50C5Vk37IyyCcH0dH8kAWuGY2S3jkasxhyZ5X/881tceQRqW96WvvT62qfobK3PD6nrWkBB4mK3UbWeOtbrga6FeL46ohqhRFIoYbuWvEEJlKEopihaNdbOsz84mxW2WXcjJiggEUKbSnMYMn4NOj/p4H+8769cu8RyfFyb5L8yZs24iwjg4um9G4XA4UFtjOkzoqMimoAYlHBbJLNsiT6IlQOQ71jdCd47g6rStvgM5Fys2EStZLG2IFgw1FmJuJgs1HVldtSv65GStTI4r28lqcnKBdeyU/iPVM10vlL6xl36m4X8tIc3SgO99ccbqIGAt1cCKh78uwBmWYXwBt9hkC/vR44GP506gFmfc3a6Eg2VLA0CyshRGCVorhmU1+sIKFXLVL0xuGbIE9QS9HHeL2xwDT45RbnxZXwcCINYQS7BjFxBiLrDcWUa/bnfehBqdwCarz/jmXQktWt/cR46hO21xsixrZS0G/H4sY4XFdf0JPmmjjXWwBl0z0jG2OGxCpbZFvTYzJzQNmiUQKU2cETsvMPcfUKFVVBoqBRVlUEOHhqr1NbE4cWKBJSFhWUd9awqIOeFJJxIxb8m4rV+Xxckr2plyOpAWR9Gnt5cGKKUMvvnU2OqW6TAxT5XD7Z42K7I9gVLQUhBrnVVJsMOWGyBUQYsRzUXdCWJCmLjDJGFSIIDEN7CCe3f7JzQ4XWxW9YmttR05Xtbgt2YusJLi+dEVk+tbZ9lLy3VQ51CW22uBZIFumkgQDatX7/zCtGLBCdCsq0aN4kASLDzhzPsZTM4crjWQvkmL+wW7MwGpHfzSmF5rDZbqwCxhrE+tUiR9ryshRQJ4RA3QMGpoiRqgRTebrEEqbcutg0U8+x2QWINFyzWxmiuN+3cAkQQS32SqgmqhIQwimLmaPQebdGFtAWbhnKKtQFLizus1lvbethKo1uctBnoRHH0NuMBOvTMBr2sW4FqPLdqGs9eVJz4FVEQItOqv9cEOtbxZpa4cNglwx4QkQLISAr3FP3cclsGjMoq4YEWDHUqsDxTLaJGuGYWd0sBjNFonESatm5H6/IFHF+hCkJy5lhj1BiUcRpj38TPaSwGUADoMzlqaUrR5p/RAPVSub/dMrXF6esqgPliKuKe7Nec9EuqvAWUlx0MdQTRImw+IitJWVLyEJMtl05AOLgt0rK2hfnkt2pkLqa6lqppALMkG+teOfi684O5kxaIzWKu6va2vn9funvHs2YpdrlC4f4/YHOtQHxYbqDRZDOl+S1+EzQVKjm3/gKbtU8BKH5sIDuh97LakAPNF3T4amPhg5wZudjGHNl3lS7g3s7tzuvrWAfju2PUhtNW4LDavZJCrG/RxEQ1H4/IW1Yy5VUwNU3EzyB01QjL2NPZ0MWgmqz77RA6yshuS66vPQP+vz+rd69xhzV0Qrfln/7pfvCWLDO2/pYfbFwKt1Qj18QgUizXp928UFUpJG6GHIgnpF0jnZDg/AyBFFbRgPQxIwrHrIWNA2LVtATR8J5jBbAGWIv1zrMwg3W7cx8LHSNW1nmSTrEwSn9ZeCqAUgUGFRsGKG46HouhYoAhN4PmzZ+z3ey7OztluNpiWRVqoL4AWqplkKJEuG6m11uP10m4TlIZ0GiS4aYCkoZ2RkR5WWQMmpK0PMw+FUf8HgpiEuWBhe6v13fueQLrs5hdJtyWWrS+cvhEWh4NRaWkuSJC/w2zvqhlud2yr99NgTqhcK3CPDa3dS+p/WwelBBihBI13RtWOepWMcw0AULp5AzWke00F1aFvKPrmsQDOnMq1CFrAV7CjPqvqinF5AFJ3ShPfMdzbT6ypkIGi6rG+WvoctFZp0kBdgFtS0KP+rm2nIH2tJsvzOe4sLj/Y16gtrKlrI65ad/Yfz77+uTSje4tDrc4J7LbPMCXFh5yEWDhr5lS5U9U2oKJiDEWcDdYZrLqTRUKiiofzpF2xlIJq6SBmqiADIu7s8Y8pBfMIk94XI81b1kIwoLHnhQwTUSmUMnSTyHrNemuU6t0skvbR1duf0l4KoARhKEMQamg6xy/GVrYAzNPEs6snXD97yr3zCy4vLhEtYRAeQBRTH+ycTAk1ozOlADokA7NjEUrpgbyuNoS6qbm5nR2ohbMmYS/VxGahnbZV7Gdu0lSFzaVeqDCyNl7HPZa1ndcPIMmFEpvJmWTosMkmbbkSrH9fmERfU8mbVLrXenF8rFheLG7anUvHvVQkpHnyYYsh7Sue3NlmqQL6A3crB9YD/DsKiLnZo78OKgVLu5eGo85cHWumoSrHwwVouy057Myr4TBY9TkcFgtKLqaaLjD9mkWUYSgRd+oX8wDq2RkiUHL9sbChPjpdbW5987r9LJhZxBnk8xFgnXNiuXzjhe5972+uZr9fwFbgmxpSBOB3PSlMHS1B1LDWwlHTqMFWWwrBAH0V73NXXVtjCEGm4fU0cZOaho2xDIqWYHulIFowKSgRGtQ7mII+iUoAuhmmJeJTvR/DOFK0UFQRGWLYZNXv1cKNNVMCF0QziP5F5GRpLwVQCu7hVhNqM5RCUw+kVlFkVzAT5mnm+uoJP/7RD7m8uMcbb77FyckWqTNaBkoZyFQZQTB1Kk9KbyEofzCv8Oi6OumZKxZRdGmLC8Slx1Raqk5BMSK2L61Nas4kNd3oOCN2cAyQlMXW6Z+oLyCRd0FPQlonG6uYKGZ657N5obZIS4uYTkDbotZkqIfI0O+zOLz8qopmlHn8sCV4OrNvRGI/h6otYQ8KVuVDKQvudWEv7uBxA+zCFk2dKYm5fkpDy2q8wtDZmkfAq0X2TQg+ByMNtmmIKRLzuATtB7CLdnUzEUo0xsVwpmIVUVwgR1C0xUZt1pbQohAYTdxu1h10AMHyTdIi6iCnHQiVOQE6wLR7oZOtK9AEo8a/DPtJRkUHfOtmoIAb11GDPS/hP8kS62yhDaS91Xp2TQq/dLz08Dxz1u/2RUG1deD3KfI14ObG4v0W9fhjCsoIWmIdBaMMi3ELkHTboa2HMdaD24ZbEzZDMPxkoEli1jbZMNdYUygD1ia/78pL/1ntpQBKwjbRTCgJPmY0cwdKKWAb4d555UQL57sdP/3JT3n8+Alff+cdLi4uYj+ZT0IEr2osxp4SVnzifCIqjg/NBWTCQ2Zm9Ji0xRvXfZjBqERys0lnOSLOMugqPrFILfwcikT/8lmQXEx3hyVZjnQhayv7Vc8+CI/1kYotd6/r38vsHQfuEoszwG5tmojLqCjpgVGFDEAXEbquRJo/slm/blJH7Z0L00GCv1MSh44El1jczTILy9XjTFnM4H5VH8u4ZX+m9IKKuhknEaxrslhPoRQc+HI/mlUHVKuYCCXiZFWVIskmjWqzX3s13mt752IFaGDdQOurzJYUOyHZjOsIbblCCPecbwe3mdU9cxwjy0L7ektTgzuGcv2lev2if26HbNSIlUznk2mObaNI2AfbjLXana8QIT897TAy1kLV0SIIxedew4aoISA1TVmx7wwyzcA7k9EPKSW1z4VZY5omBh08c863Co3M1lj8AhlIJMVjTNMsJ7mPV6r6i9rLAZSAlJD6EMHKSmGgqYNXqYXNZsPACednG+7fP+OnP/s53//ed3jr7bf5whe+ANstlAE1xR0JCWKxTpuFw0ddas/4pojN1lrrWTn9uRDXvDE89cS6XpSeNMvPiXTWWP1dz2Ve8C6AeMn2WKvfdxOp1o6FNFoLCbgOQnqknsT34n2/XXiCuwEoAd+3Zd5BJH+2vtghPYXar9s3cM/JlX7TrqrjAGu2YpUxB7LQyQ7sfRykhQcT6tzCQceiqiWqWj6HRLaFUTTUwxabLlSvFkKM1HpNqNVoaXNrwZFa801rQrMZM3dO7DaFYRCvKxCT2FpFIkg9HYK2YmjCSsjFTK41OwfrfKZE6MUDraElpEa9/OJz2vrq0AVMA5TS3tkdY2kXgf58/rt/NsOjqjk7rW2OfbBeT+GsseZs1FbrLdaVakFDM3ENo3QNwllzCTaZ7NQZqIW9uLXm+zLXkkV2VApEVfdS61IbobWG1UYT7bUI3BG0jIWPY0YRpE9jDZKyGt9Pby8HUMbGKxHT5Xs2JK81ijQGE2oLqTTPjGPhm+98lXsXZ/zkpz/j6sljvvyVr3JxcY4OxW1TLUIKGogKpeE2kWQsNdQ5TRUnFi8JFt2aF2rZynvac0x7KkDAjzscWhrMVw4nl410BpUMNK+fc7W+b2eskpzXlsdJ46EkKIf6JyuVIuyELdXKBJgYeGuplgdj67ZTWe7rdC/YnUtuXYVvQHoqy7JxW7LgjDv0Be8exwwtkqUnmSmFQSm0tuSdFytoKwFqvlHcGQA6umXACYWGo6CggzCOhc1uZLfRCHIeKOF1VSnBEEObiWBpL3RiPL++4a++/30O+yu0eOB0rTO1VjJbJ0RJzDXBdlusiuxhoTshckpstW5WqZYa42ykuhkaUSYUyPIZkgnFglqZ3yObicVj3BdMst64s2XhisZk81EwuSSbx4PiJOyDigVxiJhZ4llM+p5RlV4UxTVwBSLLTV1tTm0s7aLYTEYt6KDB9N0NVCIs0P0Qq1Ujvp8RRUoSltjzK+GU+erL96RvjU4gPptQvhxAmcwruXFfKM0dKBiMQ6ENBWYfGG1eAeeNLz7g/OyMH/34Xb7/vb/izbff5PXXX2O721EGibxj8VAMiAnHgS0YmqvFFawE3BhH+dnBTgJHfdnnrJAkKplExhWG5K2uwqV9Ju0nkrPWVY5YgELPOBDRbgBwLWeZVHcWONj2RWO5iOK/zvYyeNEXt8bztmARKor3fARZTBeucxWKjNHPJewp5LHv5cxKaUIZBlqN6jkNVAd0GJFSGMoQQcZEEQRxpjI4iG02hd1uZNxsKIM/06aMbHRg0AEpXnFm3GwYx0IpQhkM7ep7Amhs1iLBBsOsEGusjxdpADBYzWfDOEzGZmx857vfcTWcCjVYSmwwaeEoMhbtRdJeGoLWHMa6rtEFbgiZdKCQyRSuceQmtwxcTwktaT+nJxB4NJbFa0S+Oat1voJe8dVUoc//XGcaLgAkbYpkEqnHPKY9VcU9zdUac23M84yZMWih7E4oUQEsw+a8T8X/hRVHi2IitBog5vFmABGDOjKMW8YykHHSBNlI9yjgVQl0CnmtadXpJCOZtQY5WgNpB/O0Ef/axFEGQznKiNBYu00oFIYyQtnQ6oRSXX2qjYvTE779m9/i/Q8/4kc/+QnPn13x1a/+Bqfno4NFgKRKBJriXq8EK7dLLU6RblPsywtS+T7aUesWLyez6Hwwshlc4i0qLp0drrZrV+shnVJ553WqXTOiYtALngP68wlEkLd1VTrVDE2batiGbydhHEasFWxyVXYoG4ZhyzieMJTRDeijl7wbBmW7GdjsNmx3G05OtoyjstmMjDowUNhogONmDW6pSkvMOx3YSlGGIWLqNBd19KRrGtGxHJtkSGFqsKPpSQoXb6ztt4TmEB/oqZahNWw2yu/+9re4vn7Muz//OYfDFHY56+ExSUZMlKXqT8NM6flanQG6et3C0dTT7EqCXiJjW2Iwrbo3P2c1NRoLhxq+Vlf+ymV4ctzW6UXRd8uccxXabJ0lJyiq+bgPkqFVOb4FAlirGftD5cnVU+Z64GSzYRxKzN8Q6bTxPYHuzZZcy0oF12hEgxi4xPO1UCjD0GOfJWzVHiHlCQw9JiVVc0lH60Jk0raZHnONNbMEyUvc89cAKEVY7AqBXr6ufQVIUZBCHYxa9uhQUKuIjMxTxVqlqPL2m1/k7OyEH/zwR/zld7/L21/7Gq+99ppv1ghkNxt84ZRQF3BWUHy3xRPpyiyUKpAcPe8Lm2mP6fTNrr3MFGmLygV8B4RF0yYoy4bO+yUkpr1RSNP4AgxrdpoQnIsqe9a9oP1XxnHk/OI+J2f3+crbX+fy4oKT3cimFDbDht3uhN1uyzAkg1tKYaUqXcKGlxtC4pnvglrXH7sQivldOYIyjAhj+Uw+e3SqdW9yMI2Fnq/mKIWP3zdttn5pW32OPl50tuJ9mOdbDtMNrR1odQIaRTzRoTWBKJISvCuu6IxSbFlffdPmUjLx+Mk+BsvTt7o4byzsemvAN22RVeXA7yUVbVHJmz+Pitf1XAtbT8YJtTqf3KDVitU5asEqg4oLxeJhbKg7VVs1DofKzb4yt8Zhavziwyc8fvyQy7Mdm+2O7W7nF9eV2UZwRx3mdmA1hkFRfC8WHWJ9jRzmGS3KMAw9bGyt2fX5ETmKx/RiG8Hul0wSFwwLnz5aJ2ug/Lz2UgClM7zBbTGZDSNZ+664kZ6GDp4RYa0grSADFHVbpNWZ1uC1yzPOfue3+Mm77/KTH36f2+dv8Nabb7Pd7mJXuBfQ7SLhYTChNY9UgGQaYcvs9qDcsAvDWzZWdmPxWabjxoISeDpeOIBsKbAr+MY3c5VAWoBHpFKmQVwapNOps4/+SIuRX2JDZhiRBJNxcHKpjLlKnyz+G9/8Bt/+7W/z9S+/yaAZpnFn+YRUzpi9Yy83HdxXUW/0h18uQRcWiZmfuMTKlHDnivSNs3iN11c4The9I9DWDoijb8V457UMEOXR4yf8n3/6z/jle+8xz7OPsvhaJGy1tfl8FpGI+3SIbTkHAU6Oae7xLUTR4s5+fO7T02yKq/iS4V3rTkifR3dChlvHgslm+FM6akIgZdGSJchcQArDYCgj0/VzDodbyjBQdONeZI04wyK4yUg5TBNPb265evaMeZ7ZbLbUqXL15DmH/YEv39zypSiZpqLuv0kBwSIYsuCzbgqDFNAIONfBAUlWmVwSMbiBZxmjLHg4oZKB/2nO8CSVRTanUWOlkqhFWJJ6SnTEQX9WeymAUoi82U4ULJWYvq9UhNIapSitqsf3Cd1WZOJxlvN0oJTC33nnHe7fe8APfvADnl1d8RvvfIOLi8tYa+lsaEtRA0kPrC0AI2umoaufrBhP9iE2qoV9T7yGooZ+VlOSp80l0GDhlFlgLG2hFjF3LIu7T/ZxCwjMoesf8XXmfzVbivX66y6NUWGulddev+/ZUAmGHDM6WV+1j9XRJN753Asnevm1G9RfwNSPVEW7c8UX3PTONY9fsxd/Nm/V++rfb8DjJ1f86Z/9Ob/4xXvUWlfXXjabgRc2thz/RenIMB0Btzu3ZVwch5VuF41jReqc5fqS7slqTMNubiBW8oIh6FviJxlqlvY+kXCKmUQ9T3fYqSoUca1fYBiVw8EJAtK8/Nnga0OKM7+GUpn5+PEVDz/+GFHh9ddeZxjdm+Y2c+lsMjXv1Ja6eUkyjdFtlVIGTII5i7jnW1IjS7aXrx2zwW67lEy/lXD2LI6cjKzoK1oi1jmBN4fs1yKOEg/zRlyda6l2GKi4NCwqWCnUUnqQcaobHuDrdgqtLcI/Jr7w4D4Pfv9f4Uc/+Sl/+d2/4Ktf+zpfevMtBh3AhggT0s7yJIO3xSDi53xfSB/oF27G/M4a9fovC/PUYCACZIDwESasv9Y3igG6AqWV53tFmxJHe4EHyVxWDYbKqlLKUhaulMFVr7bEjcbXV090F8yO1dy/bnsxZL3gAy984/PVo/8/3/VN5YK2GTy5esaf/rP/i3d//i7zPEdhYsErKAUrI2P/oj5Aayx57wmb0dN0fOki9ImNnCaZzB7L2p1eWT7mdfHqkFa5bsJUINJsaeIquS128eNsk5j3LCyTUSYYw7DpUQRZI7IMnjaKDIgOXeje3Ox5+vQ5JycnEedagiSEjTPMMVnl3x1DCV4r50knJbhBNByCNYSEXyfDpHxxL2pypK5mQsmd9+i/xdj3vSkQQAzr/Q5L5v6L20sBlLVVamsMQ8ZhRYJhlGwiPNW+sYunKhIG4PAiC+MAACAASURBVOZGWrddeXD6NDUO05467RnGkW998+vcf3CP7/3V93ly9YRvfPObnGzPFjtoqEw9Vy9fMwOtwfBisjNCMtQii3S0Pj2pEpn4ggwGOhSFGipQ9C/jEA2vUK5hBtAknObHPyDLtSUkdA8qFvFYQUvs9c25nAdkITmlP3cP3sUYirK/vXb1sc+IsYL0vuHWQuJYtc3QlzW4+9/Ln9bHcb1//RHzYsZaEIjkJonF3u+TV2f1+cU5t+7F4hRbPdMRblqPs/zw40f8yZ/+Ge+9/0ss1G3iGstzZMB8PGWnLq4T5GvSvdi5rnIKY2PH/6MoGcM4MGf1d1uYUMtUQ6Mfh5K1IWlL5aVUsf1fPSo9Voog4ja/QQtSPIyrxLAMw+jqthijFoZSwnmX+fVCRRi3I2UsjsniMbdDUfd4489T8PoGRZR0n2tGY4i49y7PulqtqSPnnSUGyNG6EMkVFXNq1gHeA9z7lMa059wv1bfS76Hh0/es8rtC5ZPtJQHKxsNHH3Nxccl2uyXHs/M4E4qp2y1LwUpxSUdDxCiNAAev4jKOhhShTjN1ntBBeeP1Bzy4/H2+9/0f8v/8+Z/zzje+yZe+9EYsPmUTgOXw4DXDexxv2ItUNOyLMdG5eTMm2wRpYRIg7DS5nQVM85CrqNoei7BkehcLk5P+hyz405mlZDKGN6GnalqUoPP1FbYwKXRPwkqNc0dH5enjj7l99gzOT4ORSmc662ar1zoIp5pHKPXhfl0r7bmojx44/4isKELlT9A6Zgb5HHF/W3/mDupKPuvy9gKRLsTaPNPmmTp7ybCpGQ8fP+L//c53+fCjh50heqqerbqQTDD6n/nomoJIlye23Kgr80qvQ9FjpzANQ556Bou/twScLweYgTR3DqplZhFRYXxJp2zxTFIySSCzipzNDbIKoYohHAbPbCkYKqOH+AwDFLcbuudb2W436DB0s40oDOPAOG7ZjYWCUnSkyBh51L5Herxpi30Sa0glVG/CbomPyVyTrZfYBysElFUqVzHKIK7qx/2ktSjYIrRuypaeijyok4pBsqybuBnuswnlywGUwzBwcrLj0aOPGTcjl5fnbDYjkupv2C+GYcBqoeqAJyqljcbImJm0ZbgwC2Mtzgp32w2/8+3f4t2f/4Iffv+vePL4CW9/5SucnJ1Ri0+nphHb/woWlmrEwgCRLAm1Stli2TSQITneMiMgD1rKxZo55NlPgQgJWSIAYFHFus3xSE9NVZB+zSNyJcsvyRUza6EB1zfP+Yu/+Atef/01xnHo6mKypaNrBftrHSDvRurG9zrjje90227mlzvgJRt3ptkiVpGFrgpEMh1WG3WaqNOEVY81zLjAZsbcGvu58ny/5/r6lsN+Yjp4kHirB1o7YG3PfLhlPhwCKIWpGbMZN/vb7nwRr+DnGUYhnF5ckWd5LasRZRWebjeLIXAyE0UmknGa9KyldFMsB3qtjRUL8i/q9RxHMGQg/IrghvZVouaiY3aUE8y1F/cYxuKZcWboMFDGER0HdCghZGEsI5NN3Lu85OryaZyKCtvNwOXFGfcvzzi/OKeMg9stg2BkN9Km3VpDR2dCJXLnM2PGKzJ5ibcsm9jJwmo8WmgnzjxLOELTqVOXUev7T8iqKUZU39dktP72moG/qL0UQKmq3Lt/n9PTM549e8ajj58wjMrl5blLMR26QTYlpOfLRh5ogFPablqNgOsSeaZZF7F58OlXvvIVHjx4jR//9Gf8/N2f8ZWvfZ1xs8Fr47mE8oPDPEK2MzQBVqqs20p9slI16O+tWgc3AQkvXS77NEqn0hl7sv9codzRdbsNKxdNvLYUmzW6cyDaUU1McdvuVGdMC3/+f/85b731Jr/5rW9FqM8xMEj2j2Rr0lWWhSzaigUZtR2wNjEdDmEHNaxpeHmNGWNqjf088/T6miePnzs4mcR5LBMwYzZR54n5MDHPB+Zp74BZG7UptcEccXW1GYfZUxAzMNs3al2cFBYl9yLtricJ4CxSAtB6rKcsqZY5Ggn263zpRUCmWu3XWVIFfYzSGy2hlgsa9T1dA3AHDMvY2nLsQmbSzPPkAqBFdEisFS9j5uE13VTV7aAO/M7AAsu0ULZbdByweXbnzVgYt1uGzeiMUgc8EWTiweXrPLu8pVnlZHfKeC6cnuy4d3HOF16/5PTkBC2jA1LzMKk6T7TqJoFKYzvuAKMU30NZMCTVHDdZhvNGpAvD7KN0QWu+Vxuh6UHX4UM4dKHbUqiGgM94XZHIzPvs9lIAJUARYdjuONnsuL295emzKx5++JDdbsPFxSWbDO+JgfCzbhZVy0MwvNLxNE/c7m+prVKKsh3HkK4SKozx4PKci9/+LX7xy1/y5PFDhqFwdnZJ0Y0vDM34MZbybR0kfboKXgklQ2H6gg16nylljisLQyqiPRPAWNRmupd7DYj5m3XJ6wxlsTl6/7N827KZ0wt6vMkradC0AKQZ42a/53/5X/8prR54/cEDtCUhUJoJVWCmMVGZauNwqOxvb7m9nZgPM9Ncu1NI7ABWadOBOh+oNZldozao1ZhapQKzGVOtzHNDolZhZrr4UJr3zdqiXmnrqrALHnXLsdDBsWjw5dg0FsU5/FxwZ7gCoEarM61lTKS31mbS4UbMfd6TmL8sutJCp07GuG4OcpW59gTWRTvA7euVONIWMOoClhH36DnpFuq1g+40HToLSuZYojiEFj3SWBopkOlVxX2JNYaxsN1uKWUIIqGM44aT0xO2J6cOpGVH0ZF2IWBbHtx/ndpmwA8CFIyz0x273YbNMGAY07T3I4YnF3JtnjlMBxrGMBSGbXEGK6UTBt9rfoieOKrTtQ98LUKAvS1zIrqUUkzrh4T9J22+SXLS0nOkeaU57TPaSwSULglVYBzO2O22PL854erJIz744ENOzk45PTmNjJrICV0FjRuGVa8XeZg9jOH5s2u22y1npzvOz884OzmlqNHmGasTArz15hd4drvHqEzzgWHYdEulQoT60DeNrKK8895IlFmLufUsIBazYM6VCHlynKsYEe+GdTVFwJ0zOTAGnnHgm9t7ulIpIoXOeWmEmAjdaA0rLfboohb+ByOLYzx8/DH/4x//T2yGgYJRRPAc3ZGmhVlhskalZfVWVAZf7G1hLdiMijsL8phbKc5K1ja7VDY91s3vp3gIh4eXpOpVMFNqMmJbFnlWVjKy4g3QGrWybB5Ju6ybTFqdkdkBxiIlz4F5ZWqIqjUZTtBYytbVKN6geexICKLaauSs+8Zbh6Ucphkz2GyGIEJKrevDsTzrZG5EOqE4SNZkWdrtkZmWVyLFbxgGxnGMQrRun5RV31NfKRJpiR0ole1mpO52DFqYZUZUuXd5ny+88Qab0zOGzZahDAiF1uDy4h7X19dM88TNzbWfc7XdgFUH73lmmm5ptTIf9ky3ew77PfN+z6FOzLUyjIXN7qRrOHlyqROOdGCmL0ACFFeg1xl9sv1c3LKo1qv/utZlAs0ZtspAOhfSC/5Z7aUASkEi6NQptzWjDAMXl5ecn5/w+MkVz55f88FHH3B+csp2kAgd8Kom6ZxQdWeKUri+2fPTd99jHAa+9MUv8ez5nvv3Jh68dsGwGaE1pttbprmy244M444qcDvdMmJsNhuQ4sZhTS91EH9ZbGM+bz5xSwx2lraSO+N/TPDTdtQSrLq9kjWqHTFHk5Sri30s08WkM86gspIhQnzyvrEowXrdQVVlRqhx9owXoXVWLhHapAnTBuviFD3vXH3TY3GOkbl6Z53BZpyqO/GUqBwjSptb1ntYTkFMts3ieTZjCTMJVuddyvFIgZPlmZczyRFX1adpYtjEhy1zwYFa41ot2GIKS1mmTzMMS7s5V9LWpngxacgkbAyhjCcOCOprprWGFhgCAGt1ZjqWQrWwZdtMK7ODthrbQfFzZ9bhM4R9Moua5Fws0rFaPrYDs4ciudPv9PSU3TDyy5+/68+t8OC1B7zzzjcZT86Q4qFB89yYp8oXvvhFbm6vqXXmsN9Ta+XZs6dcPXnMPM/sr6+ZDrfc3lyzv7nh5vq5A+XhwFRnUOFsOl/WrqzqPPSt5F5pTQ/L2uSRsivBv0icy2RhTpLEUTLSI+3xRKC7qZEmMBfGS13QT2svBVCmImuR2aKD2xS94s3IxeUlJ2dnXF8/5+GHH9E2ysm2+NnfkS5GSI4S0falFBqN28NMNaW2wsePn1OGDQ8eXDBsjF2B+ekz6jyx3Z0wjFsOc+Nmf0sTGBmjxl6MfDd6OADUONtnYSI+2M2cAVqwzrsA6R8WsgpzVkJP43+fQL9octv+d+a0Zt6shj7hT2axmPKe1q8JHNkd26pgF7gToZi4/Vfo9SCbNAeOGp7KBmrq8au10iQdXJEZgjvVCq7ae0JAePZbZbWWmWI4M+fc/wjBYUAe0kXioBdUqNUCEFLd9c9omi0scoAl6pISzjQRdNgy6uCOvvAwZ5JBKSFcLElKjg0ULczz7NVtxKMjHCSFoThblpAiqTWknbuUMbzLQ5z+Z54LL4rULEYhlGHEQgCZGlObOdSJq+dPeXL1mCKHCPdZbMiHw4FpmqLAxmJu6II3NJcMzhCRkAOe+vvVr32NH3z3e9zOB8xmTk4Kb771BXQ8pTYXALVWnj+/ppTCMA7s99fs9zc8fX7Fzc0NNzfXPL264tnVE55dPWF/c+Pq9zy5wJkreTLlPB1iC6T5SOJ5EzxteZ3QjoA8wiOFvISAomXB4OPQstx2i+MKZ6zVi5xoZ5ML6fi09lIApXcyOljC/U+EtZgyjIJqZXtvw8XuhGdXHyMt4tyiaC1mbgDWRinCZjswbEYON2E3E2OaDlzfXHPvYotuRpSB7WbH/jCjMjCOG3RQhuL54/P+gG4GL+yaz5lphGswY5kY7ZPPSkp6JcUqIb1SjReQOMIViD5ov+7CCtK6EuOCODMJ72eVjMuzfk+N66WN8ji9b2F1bipd7F/Ms0cXxPVqaKwQBI8M1qkcdTKfN4BLhP5JWaV2NsvIQZfw/lgVrC5y6AXrI+9v0mhdi3B64apshmN73r475fzhVZV5BkxR2zCUESlGGQoiA6WMnaENg7IZB8ZxoBRlLJ73PqAMwUKGYeye4XEz9kpGGqlz7iAI1jf4GdY6jGw3g+cwRzWjBC36KMrdIY0KP/D+hx/zz7/7Xa5vn3TGmgDpTF/Dzrk4ljIIu7RKTZd42LIttRSrvPGlL3J2dsH+5hopwlT3bE9GyrhjPxl1qiQbe/78GTc31zy5esTV1WOePHrI0ydPefzxQx599BFXjx9xe33NdrOhKDSbQVK78Hsf9jfQZrzmZAOKHxRIhtrF3EVAvYRqLaE1NYmygYqHF9UW34HCggcJqkljUskDn5sWanzRsSdcfFp7KYASkg/6b+DOnfR0mbl/26wyDAOnp+fU6QYPgw2V1RrFhFo8i2csA0MZ2LeZVmsvq+TszYsCixibYaTV/I6XlB/U0yRrbdTZvbXj6CESCT699b9DPeRoneeS9I0Di1Nn6XjQfzzNMY90ha6S9IKwsfhbFKuVULGysnYy03wuV2kXyfzJltdxh1QNh4N126v/a/FAebY64SjJ0KDex/hck7zuEoOxMORQxxHEavxuS1zo6lnX1dqT9RqtF5ToWR/hHZZgd5l1ZOA5yw3efvNt3njjbc7P7rE7OWUcC8PoLDOLK5TBqyJtNiPjZnTvv0a54NW0d3uZLD97DvzqM305S+92clsWS0Ey/hfPjwsn4Y03XuP28HV+/LMfh8AWWruitRae/BIFfznywncGlvZNHGEaDW2Nw2HPuBm5d3Gfhx99iAhc31xzc/Oc0UZup8b++pbb2wPPnz3j0ccf8+jxQx59/BGPPn7Iw/ff5/HHj7h+/gyrs6fA1pn54NXRmzU/1sVaP45jmiZ3llnrfoZUMzzjLolSjuHyvht2loSNWTxe2U82iILcsQmbHI/lYrqRYKQtTjn4NWGUgJ/jC31jK/Tq1akgNhloKohuKEPD2gGx2ZlYKFheAmz0WK7cXKGyee6rb6oi7jjalIGqMwPKWAZMByYxT5WMenuHeWY2t3SVcDitwy7WbQ1OPaMFQVrYT5ZYmo6vafdseT5PHKGjmplCdnSvvPYaBNescR22kn9nW/+eaWQZZuUmr0atflhWkL4uwhBxNSdOA5REBkuPfBrna1c701Pf7x/e7BaKv4UJombM6mq9JsvKl5bID7cOq3hZ3H4SYwlgM/HIA3F2+Zt/91/iX/uDP+D84rwLJQlwy6N1F/NKztjy1xJ9E+o9q621msMuIc2fsVtd0vkneV3r7P/4ThzNWdqcpzrz6NHHPLn6iGYHNsOImLHdbvwEyFoRKxRaj29Nu+XRNdU1NK8nLYzBcJ8/v+bk5Cxsgsbz5895/4Nfsj05cLOfeXr1jCePn/D0yRM++vAD3v3Jj/ngg/d49vQx2uI0Q3WyMs2VOs+06lk7hmGahYUNLUqrPVbHe65eSKSol1PMmOWe6p1rIISpmseDZsELkmDk3Mky3h01aeHuDEerRK5D2JttvfBe0F4aoEzvnIaEINSsfA9Wm0SF2jwXVaK4RbfbVWNQY7c9Zbfdcs1tnDTotRDNYrDUbRpalaLuuS0yYDqCNIpWmipF/Cjdw+HA/uaGUgrjOKzYjgPCXTDy+c2Z9n54oGzETa43RLyXub55nEAa61NVzVS9I5C0YHQhbV8kGJdNfCyM/OOxmPKYALX+PE4MNYof+2dbslbDJfKKP1swA8HIEjrpPOgoEmyzmEcoeD+DDUQX1k/ewUQl4mWVnr9OBCnHWGrYCX2D+Tj/zrd/m7/3936f3cnWhaT4hk0DwDqAYN1aMN3uSEpAlMU84L6wdvRliz761Y/dbvmcy9pYsWbSprlQ0v3+locfP+RnP3+Xjz7+kP18C2ps7j+gDCPjtlDbSKsNweMUu7fdlmMeSinU6nOlxR1Tc23sxsJ2HHn//Q85zAef9Wo8efSEv/zOX7LZXXJ9feDhBx/x3s9/wfvv/YKnV0+o856hKJuifp6cWcR0eujXYWqMcey0iHmWkApZHNCPGlqcsB4KtGQLqRSixvkyTtDLqHkc5UJCUqJ7PHPrgk8wzHLtenaaipMyKeIWn+T3q+SQF7WXAyglzr82I48WdYa5HMKFuGOAUKHdFrgYYyUkqRccVc52O85OdjzSRxzmKUIpHFRmW6UQliX3VVQ8bcsssnxiYyqIbNjv99ze3DAdlHGzIY3QPjHa+9JtakeOoN7Z/vexWlwDZFxIFBHM8tgBv66zszw3ZlFNDItFGZsxNomz35UXPJxCFv3qVYzyuYyIbbKeneQ38Gfwyi7Lhj5i07qyzfrjJkfMZdx779XP3Xljqh54jANhhtSkozIjCwRDGlG3sCxnXCczCwbpbMRZ8te//nV+7/d/l+1uS+b0A5GYcFe4rFldjGqGXiXbiLnMA7c82mjtKFh+8WduQQBCMLblGkTcZgorA6Z55uZmz2G65eHDj/jgw/d4/PgR03TAqMxtclvs+Tm62TEglLkxjBVsolV6BENqPKnhjGMEoEfWzHCYGNSB68njpzx9+gRrE4fbmXlqfO/Zd7i9nnj40SOeXT1lnvYIsB0Utpt+dK2v0QDlprQmzHMDJkS9jFqPjijKMA5ebCPWaVbz18xUin2TQjKLhfT1GFEDSTGPCUqElqX7rmg4uHKphGZmLsQ8jlVXTqJPby8HUOIxkdQ0qMZmjJ9WY9BCDWzqLgU/UrOFPdOXZ1Fog7E7GfnKl9/m6skV83TL7c0zHrx2n3ne+4CxOk5BYzOIO4Q0ACkHb8BZrpnRqkWmSaMMpYOkhF7YWUEyoQ4qGgZk6zPn30vJ2BaQIc/b9n9ZJSgrTPcmKXADjsKz2cztQFWEoUjPtGEVL5a2KlhYjLOlKOjRASBldgqEfDWhj66DJkvNuVuKa4GGPaFgqPmhUCkypOlKoLuMb1ETtLaZmptfxe2HY+FwcM+phQOsRRylH1XQKGLMdeqGm6UnhPOHztwl5YUtYG79+MF4qpbscmU6MWc5JlAN5lbZT5VpalhmzLSIGKBhdWaa9uxvrpn2t8zT5OeCG0wNnu8PXN/cMO1vOBxuaW3ylWGN1iZqm0Aatbq3ujUYSuEg8Zla+xzVWt3uWgrD4Cp2ax7Ub4AMrr6CMEfWk9XGYb+ntQNXz664vd5j1dfUyckWwah1joD4WCuSDqxkf3GaYwXZbtCx9Grl/iyFcRgREz/NkbrKwgkBWxYCgkg/O4cgOuncybWbH9VQ8XuzFUPPtbK6Zo0iJG73/zVw5nQ1JTrbwwXSOqYWYTaxeCPMo5nn8Eopoa77Ci5F2W3gS194gH777/LLX37AZhA2Rbg8v3SpKGHILyUqqAcwqdP1u6lpIsY4jg7OGHWuHOY5Bj3AksgIuauGxz+PJVwmt89w9HG53xK3mePjP4M9d6+5hdRNlAnbnSo3NzfsD3tOt2OwiJK1FkKlySS7XOgSrCB8x5In2y2A6Rga42ELiKxcNf5MTRfhk6E7AS7N68yEA8VVIFPpqXi5+SxMCpgxTxPzPFGKstkMnJ2dUOvE7e3e7xkbxAh7tFWg8oMf/ZC3v/xl3vn6N3B7qfenVmN/mJkOM+MQz7FyTLkIbSAV2uR1Tg8T8zR5emxLW6zHalZRZoxDaxymSquuwmZWTqsTvbpQnSP90p0ZHqTuZ8VMNXrRGsNGqFXjNErxWNRpxlarYY4c7xZlhWqo2uM4Mo4ejjRNUwdN71/8vzN/32VNKrVV5smzlMYyMpyNWF3O1cm15eaXqGpEOhGNhkcNODDCuB3YjBsPMB/HXnxjtxtdi8iljxztEw3hI3nEQ7bQWiJu0F/SjKletLRs6WRcbLTSVZX1/fzvXwfVmwAPlSPsKOZZKs3dxb6JSqQNRlze4XbP9XTL6faEcdxSyggYQxm52Aknb73Ja5f3uLm9pQzKdjcyboYw6HpldT+9w1WEoRQaHn5grWJSQn1pHiDSjMGMxoF22AOGtWSM0vPJk0F2NY7WHRkEW03hALiEJdlXH5UV28vJ9OWZZ4jEpxawVAEam83orKUeKMVL/C8VbVoAnQeG9//EvM+Yn4GebKrbMn0esDhRMgojeKaIdEaWuUMNixg3wdBwsvihVIqgzalcZXJWRoau0A89a7MxzY3bwx4T43Z/YK4e6nVze+ulxsxo4rnU0zQzTQfmuTLPM3/53R9wdnnZNZDa4DA1pnmmiPCv/t6/zLe++Q3GcUvG5mmJ1EkMpXVGvvzLQHsXuCagRTmVgdPTJZ1OxB1003QAxIV7c2dHqqu1TrTI2a6tUueJ2mbmeN2qp13WOjNut1ib3CY4z1Edq/b8b1exR05PTzur7GCg4qm5YddIEtIkhYzSWiGr7+uw9VUbQKxhczSg1oaq74M51otrd0IpxlxHhuI54NvtlnH00LtSnNlut2MIZll8BrGGXWSlvTrU8yjMkeehiyx58zkffW4Qj+XtKcLHKrXEOtWiSPUKQhra3We1lwMoBVh5Cfsg4awk8kd6CpsHBYfct8bjx494NH/A+dkll5f32J6eOvsalLHA5XDGxcUposnApEurZhYbwWvoDVqYSXXXA9p7xWrz40zLMFJaqlKHYKeQKYaLhEqgS5ZCqEbe6SO7WtTTE/FDtvyjsvrO6t/d18AzGbxzNBrb7ZZ5f8s83dJKpchAo3bwFqm+cViOss2KNHlgVZwBi2/y/C2U6ZVak1k9aZxPwBdxdlRk8IPhRCkzPm7WPOg7mOwkcDvvefL0KiIA3A9eq3E4TMzWvLAC8MMf/ZRa8xTAynSYmOYDIuJ/R8GMeZ7ZH/Y0LdSWZ7JH+S4V7l+c8nd+4y2++IXfY3ty7h74sJmqqNt4dZmLnj8dM1rSySUpIOL/lrZWj7DYH/ah2jl4TfVAbeEAmQMo47jYeTowt4l59oLKfvjX7H+3SluFALmavKQwmhnzPLOYgVasKY8ZjnlsU4114KXUio5osP3si0GvNIQs/exhYK15wRnJY2/BmlDbzGZTOD87ZTNuGAcvz6Zl8Dz0SGf15ATrhTo6aViKUsbTNLDS943bJv0pF9W7sICdh/607MWicIWdMn+GXX/FQj+tvRxAyYL0PscrpiLuQLUw3mIVtPiREHGUgSjsD7c83u+5fvaU88sLzi8u2WxP3CuqQMkAXwdLiw2gEaRuzDFwSkljvUGWRfMBXRvJC9TB48GIDRZ5cCXOll4WqisBmZJVAoCO1Y04/1myarP0Bbr+bJae6o6TWCglvu/qSaO0gTIOHPbGfu+2LhXPme4LQ+eV+uHNK9N4eEeC32Ln1gg/CYltzphqfGCuzX+vjd244eLyHGplu9+zLSO7ndcapbnzbQvQhFuBJzjwfe8HP+HR4yfhyfW1cJgPGEKtnho61Ypq1vCU2NFLGmaWFhuGES1eqcbjIvPIAcXazMlmx3YcuH/vgt3JOUTl785rulBKc4iSle+9kMLCVnpCUJpsWHL5RYiiGGA2MMyFOZjaXDSKchTMGnMpzHWkDs48a6nMdUJ1plY3LWxGj/EchhERZ2nzXHl+c0s1Y4j5rHgWf8MjN6IrPpMeDU7a9jJNtyu1IvTyhXgSRxO3pKQ27A5BHHREseLmmTYPbIaB3XbLJrW8rG2p9HsVdwv0cB2LFNg2G0XoWp/jw4udLT2FNpMc4pqW+2OZodhTnrNOrp3wln9OBuNLBJSSrCW9AYmOYYA1Q+PgsSbVgUWysOgi6Q/7PY8eHrh6/ITTk3Pu3b/P7uSEMgx+0JePzWJ5Uz9ZsIbktta8TNTRoshBdUeHFaOUERsqpWWZ/NIzM0rRrp5537xPCZTaQXr5jKdTLSpEvh4X+ARDSDWjP1p62JNhBkuuZlw/f8rttPE0O6IAcV9FQvcGijDNnsPbKyeZq35zVAbK6jVtnjur61O4JwAAIABJREFUq+YgObfGNM20OvPg7ILf/e1v89p2y1tWePsgnOALvpixRdk2Q3XkelN4eDLyy9MN7330kPc/eAjmBY0xYxxOQQzdDiCeLphnR5cyoOJlxcqwjB/EOdQa0QNEjjPK7f7Ao0ePGIqzlN1uy263AYlzpEVJP30mNCwtS9BxtLlyrJY6oVHUIkKFirpAbdY8jXF2W+CgQq3FVfDmDiwvjOtrXGVegYX7hoZxZLvd0ppwmGrXQoahMM2rJICIbyTiJnsoWCwZk1iDpTjhzKM9014b8ahqJXuIreoYrNNke6ZUEebZ90IZlDKGDTgATVU8UwmPfVTLEi8pjCQy2HK9+9N2MtlHO2ZD/Z+Il86zYPN9bfc1vnxPEFTLSrrxue2lAEpfSL74WrNe8KCH3xA1v8KuJ2UMB0wMZqitdXY1DxPaPHPz7Iqb62ecnp9xce+Sk7PTHojuFYgMUEYtmPkGf379jHF3xjCOrn6VAbKoQrArNV+YtYyU0QNgj71vuvp9ZUu8Y+c6DrVx1bnkpvAveHzZakeuVcHuJFLvBxKn25kwA3OdmWrj0ZOn3N7ceupeeO/zJLdm5ipts86Apmlif5g41DkOuIc6zwvARnk2xFUzQxmGDbWZg4A2boZbFOW18/u8Uypfuz4wIGxq4/QwsRlK2KIKN7XwPlum7ZavfeVtnl89xWoLBogfhxtZU5qZNEWjpFhhHDfhmHMhoJobzFmEF8u1bta5uZ344XQgS+eN48hm2JAZSssMHLPtozUrdxhLroF1mEkJS2AZg436s8xtpqjQauEgLqwlvLCGA2NpShVhjnA4Csgk1KygH+tKJYK4cQEyiBuAkhCkuQAi9z5CYSxOL82CEGUYEG29sEbLCIociozCiL2Wfc7A+QQot1gVL8+mnhoq2Yc7aq6GMA655MtdfH7NZjJKw/dIJs8KWO19WmIrQrgFM+1zEu9m5f6GIYW+VmiCDrLa4y9uLwVQLhTYeuFRCMmgFtIrbHoZcRVxWVqyEG5KuxrnGTsdtAZXT2eub56z251yeXmP8/NzysY9rhA0vSjb7Y6mA8+ePkXLwOnpGWUzBkP0z6oaqkYpRikVs+JSMTxvC/AtrHCpDViOAA4+yRIhSmCILEWERVYLnv497SXg3J6qqQrhwdfuSJg57Cfee+8Dbm/2UeMwDsqSqKWIhlruG2YoQ2e7gjOV05NdnLWcQJRFYp2pDcXtjUU8w2dzumUYYdwUTveNU4E2KidNOL+dGQ4NGQpVjIP5kQulFB7cu8/XvvwWbZoo6lEEWjy1MFl6xuSN48gw+vNS3FlQoqZlpvEYUNvENE08v34OZpwcjI8f3uPZzVP3PuNe+JXRJ8Y6vamLp5RYMazYWc5HX7PQwUYQxmEJH8OMYp4e29RDY+bqIFnn2cNWIrvFcJVZVJDZ1z5tctMBbsKZ51CwU7kQ6WFSyar7+U7JO4JR9eLEpQQhyPUXXgEhwKViJbjKut8hGIQ44I8wSViJYtl54mJEpXSg9PqiDa+QtAr/73vIHflDz7py7SnOiorzbvylBjrg4kG7baHPlC1+CTMozQfBA9tX+26twb2gfS5Qisg/Bv4B8IGZ/U689hrwPwC/AfwY+PfN7JH4KPyXwL8HXAP/sZn92efdw9XSONd7pep4qE68r+51U/DT18pSakrU06LabCA1glLbUgtRlBZG/2dPrzjZnXD//j0uHtyjbHfoWOJoAeH07Jzd2TnPrq95/vwpetiw3e46OOQ9PSbMDegSHlq/lx0B2wKYx2C4BtSYSXoQeI5J0b5YPw0o8yXVsgoTooOdXycWrBaGsfhhUMWLNYi4TXUpDBExb+HM8Mo4zujGofTFhehysJTIYk9qAXpj4WzjYSIOXIVJB/YC54M4wxsG6ihMo9I2A2U7csoJl5entOlAiRCmfMasCqXFVe1hHNlsNozbLVI8AWAYBsbNFtOl2rfhYTgPH37M0ydPGQbh5GTH0+sr2ryUYFuHWR0HM99llZ/2+gKY60D1ZsaQQIUgTVC8uIdIhNyUwqyKzJUijTkcHAnkuSZsSmdmibJoMyZRZkyP113JYxK0dq0GCT9AVb92MGMfW2VWD/DuxSOCY4sRgfZOXIQMu1lpf4mfavRTTMNEJnHMQ85nz8CLccxY5B6T7MeUIau9kvq3bxnpjDGPXe4aJosIS8GxxMwG4enrOAjJp2gOfT995rve/lvgvwb+yeq1PwL+qZn95yLyR/H3fwr8u8C34t/fB/6b+PmZLaCjd642Nx7HuCwSK7IrNNSMKY9rwDdeazUmVUBCtUDwVLsWmSVwfVO5fv6M8uEHvPbFL3J+fg+VIRaRMA4j9zeeiXN97TX1RITNuHVVUD0zZIgzxtMonir12hmzXripTq/ZZMdFzSBHl+gaFu4WGziZSp7L3BcPobKodrXJgDHsWGe7LYeTEy7PTznbbdluN4wa5b40ytINAZC6/CyU8FQ3sqDIkPctpT9nEYm8eR9zT5trbEphDHBrA7RBoXjc4WEUhmboVpgGZ5o6+PV3mw277YZZqquRsaH8DGilRGbOMAxsNlvGzYZh3KDD2O1tZSjh5EtW7Ccc7rY7boZrB/lx7NXWwT3Yx8D36Wr357XOYjJDxFZHH5PeculZaNK0FyQBpUrNTRGPsqSspnNII05VFSo+9noHKMWyNsHCkjuIqtLC4Uhx84YM6SeIWFZxO2WeoeaCcNmzRFzwUo0hPMwaYV66Jg2pyIf2F3vFs59ST8w1nCYo13byjirqRaNZhFA8BtK1uVDIo6ZD55c5npFxmhEnEE6kz5nqzwVKM/vfReQ37rz8h8C/Eb//d8D/hgPlHwL/xHxX/x8icl9E3jKz9z7vPirhPQ370lI0IP7lweh4mELpzhz3VNYout1aC5thLChcDRNKX8BmjUELNjc++sUvebq54sHrX2S3PXerWRl9eLdeXr/W6gHct7cgboz2rDv3zlkfdCEr0cCa9UkXBhLqdL5vIR2PHDxr6R/v98DbvthXjFTDxhlgpRRaG9hud+y2J5ye7jndbaFVzk5PGYeRUUf+P+reJda2LEvP+saca629zzn3GTfekRn5cGSmKafLZZVkIyEZJCMECMk9I7cwAlUHaCAj2T267lpCQjISEpYswD1o0LFs/BCWy8imylQ6K7MyKx/xjhsR93Fee++15hw0xhhzrn3iRkS67DTXO3Tinsd+rDUfY/7jH/8YI7zLEKIP2Q2oJE/tkiNtayBOOy28Lakv6rimWiu6LO3EzsNA3SR2+8XK3+UBJmXZ75mGRJ2EMg7UMZPHgSkr0zSSKaZllC7oT8nQ1DBYTcRhcOMOoMU8iFLQmpr8y6pOWbCplupJnJVhG1q+6iW2utv9DKD4z/VoGzB+TtIq++DX03d1ZswuWZKCYCjPwkLeZsSNuaoyDibHSKqe3GCcod4IOokYGgyjo2EoYyWug41qaxp6TnvyAKQVLs5BQtIahiHHSQerSHOvAKpYT5EcuNPH1/UCfo3HWkab71I8U63VpvTX+z4zaZNxvuIJItEaJsBtzIIgFL9/jXKOnrSi8uVFe+EPzlG+sjJ+HwCv+PdvAG+vnveO/+5LDWUYi1YePixkCKItrIhVAQnk4+lR2YS0Wj2P00uExGQIwW850szJWk9EdFqE/fXOsyXsclTEMn50hJQ5GwbG6cDl5QUXFxeM4+gbN1m/F+mL7ybv2FzwZvlXqNKRY3vOKvKNOPkckqkj3umG65C6my5iFeJN3LvhZHvCdrOlzAeGcWAzTFYyLkVgQMlJTefmKCNF1FjCbZdGtBvw8WBKGEqfRiuKKqhYdgw5cbi1Za9wa17I44YDA3JywjIkrjeJ3XZiP2aKB2zGaQRdOMpkc0QRARwz2rGBPKG32niZrKX3qMGzXspyQBwhT0NiWazpWUiRfpmPYyMGZmgSKVsLiWiBXJMyiBJb06RGhtJNVuYwyXsLmXEVIKLfnQeP19tnrhCzdqMZXJ8VFDYFh/XlNhNTrSWoBUjUhOVCGCkoGrVEk2ti7b1KZBmt0hO7kkDcqFZS1pXcaO2C+36S0Bd7Rlfcx8oTa33uj6RCXftrBwt+BtovQ7Ypq6v6ose/cDBHVVXWOPgXfIjIbwC/AXD/hQeQB8vEKaWjyQSEHAEgXGvBdJCuVxzzyJAHVBYS7kZZe0TTUXph0ORyEJKXShtyQ0iFyuKFCpJn55hUyPK5axWGaeTOcJeT7YbHjx9zcXHl6WKTL1KLvKUVrD8K2nwBogxD3rlOsxDJ/xZrI9qNNo4Fk1PE88XHLakyjCN5HCwgNY0UXYx/nKKznqGxnK0Ih2Rb5IZgq7ujHr2UvHJlbeNJtnH086dVdS+qzFoodWYReLzJKCP7y4WLVNBpQEcrDrwbYBkTh5S40gIJxs0EdfbFrO0+h9Y8a0VlNFcsr9ZKJK/ZYVlLoSwVarUiDSmx3WwNaS6zidEDhvwSHp9x4dU2Z2Cz7IEVlFbAttaeqx3BD1Wl6mCRDgLp2xxITc1APOMCCKlQGLh+0Lq3MGT7SskqrvuFRuvkCGrlCEo5OkxYm4/g1u0aFMV5U7p318ySG7OW1qm1cdydz3R0GeizGTJhldDmxZvEI/ChlZZVLUqBGu1LIu+r+w++/b4UVf5BDeWH4VKLyGvAR/77d4Gvrp73Ff/dZx6q+leBvwrw5te+0TC8eSVRlMG1VWKTVfxADcmCuCEchoFxGIzAdxcNEYY0uiGkEfvNoDgCU/HSbilO76ieLDZh6gjOGDlmVYZpw9379xmniavLS2ot7q4LSaojWLvP1JBgWJRjI5raYnWhw9qwSn9+uLZrxNmNqb8+DJlgRm8YGMbEOGbGITHvjVYwfrJHYpv7nhKSPHsi+HGnOHJEwsOgA+IBJHeGEJSSFmBBl8z+es/lxTnL9sCTUtjkmWW5JucNy6GS8oBqoi5AytS9IIM5bsMwOKrRduonwRpkBSWggTSH5s62DVmhnd8KSSuDCNXR8ehR+qWWVo4s0NW/kkeyDdwDyLYGM3jbCStvpylRNZvaQpQhJUNxVjPfD0WrmHXAEJ0lHbhHIu6DqZBqaioKOUJxplqIRAm0UqUE7oPw6KQnBBpQtX3R2kbbG1rhjbJY/VXnYy3NtZs8l+8b2vM9EACptRmmtEBLpw7q0YGQfA9Fsel2ENCnsvkLblMUrO1MeGOs1srnPP6ghvJ/B/4T4C/7v//b6vf/pYj8L1gQ58kvwk/iG8DIY7voRkB7to4hzH7qZ+/JnCQzDRPbaYPuDx6Q8E3PCgGtXGL/yIbS2qDW2hFMwjgPTVZQ1yPwRigbzzJuNtxOFj0MQ8bK8NkHubGjL8pnfbH6e3z/LM3k+vdNHsQxkW951xb4GPPANIxspg3L7sCY7He5+R79Pa0Vgh08XSDs7xkaxUjvc/qjZa/EaZ1MsTZoos4zj95/17IyBCiF88tLJFkN0P1+5t79+6Sc2Jxs2G421mJhyIzZ3lu95mUGCyClZLKuGGeP7FvmRhjK2MgQwjGV6p0lYcjCdkwWeS7F64DSIqO/9IdglJIkVEorGWcHl1EDtUpTdKSaXT6loIsHQlYHrarNh1Mzdrhn723mrmwEOH3O0wphCkJO1mlRyGhyry5S/IJTDdlQc+cDoWYiG8nWevJj0w2phNbxBrpWjgI5cdCltsa71xRfva+Ov0e1OERdGXWaL7GaU4noNw1ht6SO5p18/uMXkQf9z1jg5kUReQf4bzED+TdE5D8Dfgb8WX/6/4FJg36EyYP+0y97/9UHtaENFBkAWYgsgNp+n/PoHKN4BHTi4BxLytJT0RqkbzbLP8+NcUqE+rBWay1hRjt1dJs89Q9B1crdW03EgVJXE7IyLDeN49og3TSMX2Qs28n5OdwnREJFnNAmrEh5YEjWyW7IRg8Mw+BCbY8qJtqBkvNgWUo5m7TIC7xmpytCepIjK4ahRTPFNxUoMoPUypxtgdZ5Dwc71VM2+UspM8PpaMZcBrbThk1KjAKmJFprSYMiMPI5ZGERNSWJd8HtaybmQ9GeXVWtuEpOJpfabiYSeAGNpZP/PQrwS330czSMlUWMk9ouCL7eDjB1WseCKqo4ou6CavyAHFLyDJ9ew9FomrX723nLqHGaHVHiRrUhSSC0ib1ave1FM5rdG7IC/X2Pej3tI7c2sIS992B6y+o8oXtLcf997yTQXnfgyEtOtq4sBtb3BERFKj+A2qQW39c34glfMl+/SNT7z33On/70M56rwH/xZe/5zM/xk8PSDLUNmgffPCc0d27Dx48syJhIYyaNXu06+eJwF7ilOK6QnkUJk3NCyQve1uZqazI4j9L6fWgKwblxYZaHLg3phgsb7Q1gDe2PDaP9bj2xn2MkG/TtBpfVKRuBnghMCf0z7DAZDKFN1gwrDckzJ1xq5CL4cMdTMgMrvgBbOTR/jklwArn2dEhR9ehxJekWsBxmXZZmuBFhXipSK9uz2wynCcYtebNhGIRxMt5TBkOsKFR33cw9K0YJxEEYygdJRGZHGILgta1wihifWjIipnUxXjmx3x1Y5sUR8Wou1p7YL9lwxvjhIMESANRpoURKleqkW8tyoaNqPE3RQIKhUrNn9p450HKKQn14YMM+K1Bn9AlvDnIziqmt7152EEvuUBrQCBlTPD94w44G43SIyw7wQVvr4okQhv76wLfCNI1l9PFK4lSb9t8FX02nbkKeFF6hegzjywr2xuO5yMwRDBXFD1HwVHK4B1YF2eQ9JhMK3VkUo5imkTFn6+ey0oE5vcs6ZTABJfkJpmFMrZpIUW28ovW4Ecv0SdWi6ik18l1ShlwRGRphLB6V7K1nc5c+tEVIu76okRdEdqDgEIs3vRmGcsMYt4Ucx6sHefySDSUOo+kLx4lhmkxj6EqBJL5NUhhOM6g5SUNdEgLv5n73n3GhdPb7soaHzh0ly5LRUltB1DxYEEWHicNhz627dxk2W/I4AYvl/ya1HOGcfRO75DhcyiRIdpohh5FOrbfM+tBxPGlIagAWJQ+VXIQ0DAyjBUuWuXDYWbk8e5W7qf4u/6oeYlbCjabfr5hMJw5nqwVp2TyGlD3iuxj1U0Wd0zOlgl29BSSXUs1+Vc/aEUC0AZN4rziYwyUvYO9VaetbtbQgZIw0iLVlSZmcuhGLNhBCBGiqZdOIeoDK636KRc7Vo9w0D3Lw8Vm51l4zwcCMGtAWbc9qRUw0E1GdI5dd4sCQjpL1X5cUxnZ6+Zf0GxQ/glJK1IhMJ+nIxiVCKXsF8JUx6QsvUJozJxr8Sd9UQer7FTlq6sJVC/gINXmaVrIqNqL0/j5BOsvaONtXdSNIuBNuQLVVp/ET8gZ6zNKDGWbUpb+FL+hAVka72OsHzx7K+cA4RFpiGErHAUl8LANBpoYkJVzt6EUTwaLU0WRK8fmCqGkhRWEskyGaiLwlQ4vT9sD5+VNOz87Y3rrF2e07nD99xEAhu3G42bI3xswi7T73SVzKZEa1I2mfBc/GqKIsqjAkqOIFYyubKTNOiWU+WLX0xsP9//i4EYQAnul92GGkXge1X7b6Gmud0AVfJLW9cXedOwUU3tkwpL7uxYxIDq8o2VyGgcFdWvOu/G2SWJcC/6yq8ezVwSNBi/ihGtW8/ClR1/TmwRfgRwggII0aa7x8jM16zGzT+r7W9ndRfcZnfP7j+TCUgpPxFrw5ki8Q9905PqX6ph2QPDT9X0qD5c9KoIluQNpsumsWKV/qsD2K1lKiBa4baZEWYVUVz0E95htFxFPqPy990R5DuBchpoh7dF5MpBuGbiiPjWFfFLJCqqnpMYOysNeZYD7LwDBMpDQY/+M5tJIcSWRr1RpubZKuVbyJKLvhpwUDmqRpZeQHdd7J703BtJ5DYn+48oCMMm5Gxs1EqjOWbSxA7wOeEv1+U/LDIZQK4X7nPlcrd8rkNBWpkxWxHZRlKWiyDoQ5C0s5tLYS9tpfygr/537cpGTiX1mtmXrjYtedC5PvmaPmZYTb3gOdrZGdRNUrNyTYOqiNfxZHpA4wPFzjERnjUyUyycLQRszBP1MEoz4cXSYz7g2ThmH31zUDLND2rGBIkXD/9TP7rTZ3WyI6jL0DxK8aiGrj/MUG8/kwlNCGPrkhiSbx0lznCP1345Oz1SSUNJDG0VCDrtob+OAmKq3Ln83Z6kRLbbOLQmquiRtZF9xC8t5QnquaIETP1VZHW3AdTa5ObdaGcIWSoLs8EvrI1UERQSkC4cpRlo4JGf29khtNpyfyytiN42Dcq1as8a7xU4oXXvDFbQbU33qVlROLlXZ9iVakQlaGG/FAWsyCL3CMaliq+Fwoy7xn3l+3XPHerTEQS3gOPp6Ib2bbT+b6+6ZbHUrrNh7WB9Xd6jKQUkFTYkiJcRo4HA7evCs2/i8HVT6LC1v/rvtSXYID7axsSPDoEE0hn7M5sSwpe11avX9K7hY7/+kJcCSEorWN85AHItMnZgLtxkT8cFVvNhXzqwETfF4iNRMtFtwxf40w1v2eTfIk6s30IpgjCTyI1w59IOQvpq308fCDNa/2vN27j8EKbCneZ4swA9K+C2P6eY/nwlD6rbQNqITovLtg0bw8BttsgqO9lJDcJS1xugmQkxVWcDNsFXOS0laLCkmdl6qWeQCYJRSxDCxx4TLZslhy9afYQlUPENhtVNa5uWAICPDr+/yo9xFa8w3RI5c9/7shJ1uVBJcWUei8Qt85WSHiiF6XslgD+pyRat35ltKj4MYDx3bt720LtJ++R//5ISPtOTEW4sZ5Jf+W4JHMaM/zwXk4n2nLhWvjEGmUKdk8JS+uEHKo6LNOVGZKvhm019gEr9ru9IJiXNh2u2V3fc3hMP/CpP6/rMfamEcDDEVvXIdn5azmYG3IRde/d1AgHmD08auOqMwc2H7qiGu1BlPXyoZYO4JbFgxtrJ6HSTryjKBpRKujp7ho9eyq7n7H8rBL9/TRNfIMmiykcWld2VxaxN/uX4iom/XmrrYn/KBtq1fw56U2WgFo7Jq61/d5j+fCUEIYyJ5HerQoAqk0YxSugW3wIlaGa8jC7BMalcBbTTs8AhbrrGXPtCm0moy1toigGSMn0astwlQTKgMiCy2bpvGCrKQVx4awRwtvnNDN6EG40HFI0GQwHdZJ8t9D5ygbwhOPZDvCyLkR3eKpcktxJO2bNHmaY62F7XbDyckpm5QYkhIdYVNzU3oGxtF9+P/aWd2nqY2vsEZQTuKrVX0apgGWpbnYazG00QGueZPU2i8YRWByGJK0IBji5596irQAml0KZfUdl6rkLGw3ExdPz9nv97axfkm28kuN8A1k+bl/d/BjEW4la2z9rmG0zBpLZ7TK/J4jT0K8eEvUPE2SqKbfoTXykqY8tbHX9WV0hKoaxr6vzVan1I2o/dszq8SNZnuJrs2+UwApWWA0tq6L5Nei9Gju5vbQgjpisvdelR7/zBWAgRY8RUNv/ItpZ58rQxnuWV8tcWrRFoFtMG1Gz9L+rG3nkDOLENS+vycrhBIuriPMZig90ha7RXyzRoYDJk5WF/JCcCN1ZSjVtWC5f/YRSvxiQ4mjITzCGy60GUQrKrCuTxlooLn8EWhx9BtBGk3WtGs3HziUwu7yit3B+rRAYr/fc3p6wn6/t3qQ9+9z795d7t6+1QxQVOkW14oKxyewq1DcfQKcQ6ZjjyahShqo2K5/XhYrbuHW8Wb6Zwu+SfKUyY40G3cq7gD4kvGzzpePmPudQHIhJ6WoZb6cbLbM88Lueuctbn95xjLWzLODB4au18/z747F3SuPSrDRbRRHBBNj/v01MQbVvG5fo31cBHEsEeqHftKYTCfmO67jmJ4Qsarx68/shTrsHlBFUmTTGKaNaw1e1K7DNn/nOOO+g0vVDp88wqqpBzlDuKl6LMuzp4fBDGTstj2e8yXz/lwYSkXcXYgNWBtvp8GL4d+3OevGiLZ5bDB7HjRYBzcfCYmBH9zljpMut1M0InXxXHXS2Tzygkhf0G1ReBiitJ47wave+GrRWXOZaxiAlDB62hGkHxAKRBVoS8/siBGRXkdPOMo88j1hVW8RDvuZp0/Oubi45urqmmks1k96scyUi+vrJjgvIlzvDyyq3D47QThlSs4Uq8/LKhUt0Gly9IB6e1Ur/tWCCzaHtrFzIGKsSC2KScFiPThnFTKtHO6XnyM59JspeNXUDw6EnN0oVYsBqwvV55qt0lO1OZ6mibpUdtc7n2DnUxvN8y/3ccRJhutNoCvxospOfWhpLreIuJvt9FFzyWOjm2usKZv7mYxa0AbuI9RoKZGB9MnG6duas2BoBAdVovgJoLUZ5whPR7qh+hxbH3rvY1XtmqyvUvfYOsJzSq0dvH3uNIIvTjRaicTYk/5kNZ0kWqAmpGZLgJBhBba8t6P2dVW1tmkNI6zVCh83i/o5j+fCUBowMmMWEc2epdOhtDh8D2dacvaGUFbkwVpEuJvbysWvDOqNE1mo3mSs+GdUS0fUSnYXoYl5s0BNJHXRakNwLmI2s0eIVWJi14gx8vfts5M1fFJMFpNMtxnoeV0vL7hYkwj19/yP/8J/w+2PP/lXOlf/oo+LBy/wP/7F/7oZgWWe/QB0ZYLWzjtHMMmLYLSiyWkdSKJ7Ck6BgEI1Js4kNKYxbAL7bBrKzTgxzzPXuz1LKYyO+FbU17+UR1Av8Aw3XO1wtrTvaEBWjzjMFphSWgsPxYByYCwTb5eG4oK5Q0K1kLpb6jxfO1gFK5s3JI9rKC3SHYYFwlSyDjhFVpZICMSdommgR1b7gAb77R3CgFcCnMQHRvDK4MQKEIj1HeqBt7j33DwbQTxCnxpsDM0kblcaCKmVCBh/0eO5MJQQXMvqoRaTDZccaMgpRMyDR1wtsjuSk31pnX1cu/Fdu3OxvBrSVHPx1PssU6vrxwzyF3c9SYJoJmlZuX0hsxBv4mTIlphCPNFxAAAgAElEQVQsWaGGJj73+dPIaY+T1IyrOsFmPZ2iq2BIg0ITCrc//oT/4a//Na90bemKOSUvnGSi/J/97Gf89v/zW3zvd77H408fs91uuXv3LoXaCt9qdukPLhORxO3btzg9OWG+uuJrX/kqX339NRON+4LNK8nOWuMZGU/NJRYPvPkm/XP/+X/VDEdKicO8OGLJtIwrr5UX/JqkaveXpX2+OLqMtrKauo4VcNkJ7ZBSxKiEYYCDobFpu2GplcN8sOZpvpG1lZ4J5Pwvhi5vGsm4/4YogRApttTLtYFcv9a/PPDsCBkLOiK0upaiaNRpFMNwOQbNb828UG3UVOhraZ8U34rTXe3bhsCaON+pg+T/G5yOqu5NmAfUYwQBhfpHqEfxDaA0NQl9DsPgxkFwREf4WzVrIdkSRkRaOEwFzHezaHuW7K1QVlzm5zyeG0PZxtOyRlu/kRS7oj2vHUu2qZv42VvEYr24GzKLF7oQPdpakszVNF43FpBEynLL9tCU0FpQHDlq8JOYcUlulCXZhm7wdzWxvvgGCVLaNvHusKfU6ovNprNElN1RhQi89NJLJG9Q1fKbfUxy6n1rAjF0HrRweXnBu+++zePHn1JK4bCHR48WhnFAT6wj4GFndSrLsrAsMzlnzp8+4YX795Baef/9d3n1pQcMeUNv7WmGrHG9wcyrISIT4VuqWK14tDnm0FzLlJTqpdGyiHUtjKyPKFybvOZlEhObS0Qs1akWb3LWJB6W8YGAZEcM6vxvNuAaS2iaJhTlsMyUOhOHpi+Yts7+oI+brvazv+9zXRVaN2rtqG39vV2Ztg0T60AJLpd2iMfVB52k6mzMOjUw7lKEIY+2zlxnix/mrFxWi6Kv71F87EOw4/3TU8jQwiL73o39RgJXmwR6F4msnfW42/5RnJMM474CP6uLWQFT9z49ImkFVgSCv1SzESFE52iEP/t4bgxlnPqNY6mVJuiT2IPGpbSbkoGUN0g6IENCBtBc7FRRCyZYcCP4jX7yKFF52ReaozUti/MWfnIntVBO8ZJP5qm3wY+yZqZVy5RmI1fZJYT7n5q0Aa3M+z0ffvgRtcJHH3/IPM+IJOZDQRTmeQYqv/Zrf4zvfOfb5DFDGuxaPeczJxhcQIzSXPMIMO121zx6/IR5LpY/DZR5hjqjOTHWLfPhwPnjJ5RarSyXKEMeWXYL05iYD9dc7i7ZnmxIrk2UZO2De/awi/FRevkC6+4YRjIWdsoZKdbqwesCWefIqiyHA0IhJSFPJ4ySGEbXj/r92bj3HPQ4mCQOKQtB2ZcA0hFIErF+0pgqoFRlt99bxpcKpkbsbt0foNTqZ9zrNSoMJB0sY3S+LCskWbW231fVJiyvqlSKvVLVy7RpN5w4B2wftr4Aovq9owQiAKTY+NDUBW74tHjRDRtTS7ao1KLOkhRSFqyqljqf6DjR3BJKM7CuUVXXQfrOSGqMa6K6IfOUA+2fiWS7qzgQIvIugTTx1Flv9YLVaWg2IgshhW4xEC1WSCVD9Pf518dQ+mQHImoVR1aloWiBlpgUK+Y65KFFvY2vqPSqyt3NjtzvOIOTBiR3JKY26CVylumTcaRPSxYIqik2rEf5QoIQUlaJe8n9HgIJeKTw4ccf8+TxOReXl7z7zntM04Zp2pCSWKmxJFycX1iUenS02Ah5WEfXw4UwLs/+ttvtuL6+JKFshsx2GpFaGHLi7jhwbxrY1Eq9uuJqXri+3pE3IzrC+X5hmjInm8k6ON6x/Ps4uQOZhMbOoptC0oh6K0stJqdKXT+aUkbLTLNrYUhqZX99xXzYgcD2pHBydsbJdmpKhuzznlirG0DTuqM2PcpJQrSQzLPzSkv2zDEP1FLZ73bM8+wIvht+/NK+xCvz5z3bOK5/PvrChNuq1f6lG8bPcJNf8v5xQPQOAXLk3sd+inHTsFlJWtpjINGGRhUChcaoXu9nlmVGtYAu3Lq1bc+3ugl2yJgRy/4qq85l66HTRgbutKPWFWCJOY37ktSj7vb6zvs3XjI47RS/t3ns1EAbueaxhZRPtXzpgfjcGEpJfWBAqNH/IsxOnDIokRSPKINHZLMkq4AtiUoxzViKBQOQUF2JvVMEcDpFbba4Olz3yQ/DljLRL9nLVBqikkCLgHhfZOlVzvvfpRnrNlE5QzJ/8OT0jFdeeY35MBOTOQ5W63I+HHoQJ67Z57+jWmmLMwzlOI7M88J8mBmHgbPNxP3bt9gOmSHB6Thw93RDOTnhtfv30TTww5/8hA8efoTWwpKN76VivJ32RRyfLRJqkk6852QyHFKCxTV5dEQ5DIm5VG8XrERV7Ijwl1IoWsmbmW07EEwsTmQmOQVBQ5TaBBGKWBQ5AgHJ0Yna99V2J8M4Igl2zVDW9g725dHk1R5qru7NoMyN332edrIbPh+zqiu30hFioMn62aDOZ9/bLEUcymsjeXS90NZeyL4glBSG+HLjgNXZIjOYRgkIj84v+OTTR4xjZtlf8ZXXX+bevTPfiqH0SN6SJaL4hgr7QW5Xo06sptw5xPAGYg2Xou35vuz9WdLGrE1/Dk46OFY/zAmJEz62i/8cQSDAu79+0eO5MJRCF4qqrKJR7TDo6FDbwjf+o2ZBLfXEI+CB5kJehHtmcZ72RWWWkeaaIeb2lGrvbYk7jgKxPFZLsyrtb0MSlpSoGqXXvNqLxMnpJx0dLSNCJZOGgd3umk8ffsR2c0qqle3oFdmTldoij9R5sbYUYugtxgtYNfbqxjnSK3PObLenZEmcnY7cOTnl7tkJt6aR0zGxGRJpEFKeGKctr7z2Ct/5xqv8vX/wD/hnb7+HTqcUye62S6sUZKR8y+8AMilVtLjBy+76B53R0k4dUYpHLlNybtJ4qZysDW0ZBqRWlrn4etegkNvBFXZPPRsl3MqQ9qgY/aJu8JCInoZcrDKMxm3v93sOe6sg1PWMHli40Z7vywzks34v0FzoumqG1bJy3NWuWv3n469mMOmR5W69jWQIbnP92cdG0xGlOO3k/GAidUojRam1DFiQrem7auLqas9Pf/4em83E4fopw5C4c/fWKgDUlSpJXHqjocHtRrJxpG7BmtELzCsRgHUVTARH15QIMQRCAIt4uGNviFX7NgfsYKrWvjdJtMce+ZwpbI/nwlDC2iGOxeURrTgxJJzoCistI67KV89YkegSKHi1nhWPFYjQB1I0+QYr/teFUvbUOjcXIjJVk7/OjFe2t0qKJo8414om6wCZ22c66KGf7AnbNNZ8CaY8cLi8QubSka16N0k3Ij/94Q/5ymsv89Z33mJzduqb3stPJctBT244JOEauoQk5fatM+6cnXF7ytw52TJl4WQzcGszMk2JfVmsu6TC/vIx3/rG13j5P/r3+e/++t/gk6uFNIxeALUaUhfc8IsfW+nIPVuWyjzPDCmRU3VtXmznmDJZzbFSahRTdXSMI5QiHkdIziGv0bl/okiTTHRzEOtotYkaaW9zU6mM2eiNwz7yvSutVsDnIMn144uMZmx++11cincabcgxgjifNY6fKw9SVjrPleHQfp3rr/hdyO9Q52KbkYkFqvQCK8kyYug9uFVp2VHDNJI5pSxLpyaaNVKfYy9eE670amYQSJYv28dJwwb0OVqNvo9jGP74W/CzqwOhDY3RYzFF7RV1QHWxjp0xrzLQZfrPfjwnhvLmxEPjMxwim4tc23ar7ioPrtlKIq1DX0nHrkecZNKPIatAkmjI0D7ZjGxdSsujFbfSId6NNZFStaKyzfXNCGU1wT240BetIaMyF957710uLy6ph5m6LFxcXbpwt34mb/r86QV//+/+Xyxl4Y/8se8ybodubBwhGeLyBqUSvA48uH+fF1+4y4lUbm+2sFjHv5RHps1ImfdcXl6SDsI0DOi84803XuVP/ck/yd/8e7+JCkw5k3Nqi9KFWwQPrM7rqYKkgTydoFW42u9Y5gN3zs4Y1AJAgAe0uoFYlqUb4EYxmKmrNQyWocQosdWdR454KNurKwhh79K/DxurSsqZaTOw212x319ZSo9nnuiRMfrs44vSEo/4w5XZVtTTCgui4ve/cq/dDa+11/Fcv9/aNbdbimwVbYbi87jMKFEYf9ajvYahf8/MaQeOu+ENkabE4XBgu0zNsDTO3L21GtclUAIxi/SsMnoKVdAPkTRp7+fgxVlokzh1xKrazC2NVmsR8EChbbaJIzl+EXtSa21zHK74Fz2eE0PpXEaKm6VNPFHWDP8dNpiiFhXPKTcSOvtES05I9R7OEoR2MFh+AmdDkjS4L1h/nERdjhP1K37AYkhH/P3EOcpWRUjXQRz8pPvsKZ9S5eLpBb/9W79F2R24d+uOIc+cvLzZwDCMbE9PGceRnCcqcH49c31YGE9klQ+NRSgiqh5BLBFSFl548QEvvPiAadlzK2fKbmaTBl554WXOTgcWLdzbXlGLcv/WLV68e5dB4Lvf+iY//MHvc77bc/tkyzQMJLL3p24w2dMb+2duT8/4xne+jaTM06cXfO+f/lMWhE0rbgCt5ahaERJD1z5oLXinTYYUX6rSDshY2BbcjyylsJRhnPoGbB9uPzSjMwyZw2HHfr+j6uJIPUwFfY/9Aoaxu7ndLa5a22Y1Y1jR5BW46w1Xm88RmrfP0GbkW0nzG4+b6+342tdITVZG015o62+gyXF8bAOxnZ5umcaB/X7Hre3YWuP2z/Z1YScmWmn9iFIOo+QFMmSFuteoT7St47aPbo73ygSaSU3OaYY30O6q/z9iHsn2xVJrXyorb+fzHs+FoXSQ4tVwoKG/UHDHSNbORWhIHVK0JjCUlCR3hJH6RlHvjkhyB75tRnMdtUY9PmUpluI3JKH6NSWf9EjHtoCPcaNSFlKyIgX2WeIno7W9DYOZsLSyIWe+8eZXkGXm+skFwwyvvPEK17UwbLaMmxOmcWK72ZgkZ7CajcMwsDndQhpNTAvgOsMQdkM3mInM2dkZL73yKucfvcvJaG2YUqnI4YpXv/p19oeZ+6e32e+uOU0JijIK3Brgm2+8zMMnV7zw8stM42iVmCKyL4Qoqbl11WUmb7zxGtvTU3a7hY8++ID9xRMbK69WPWTjBm0/+UGkQo7zSitCYRis+DDQlAbR59lU9WZCxfUfjZvSWEP2VY8MhV1nrZYBlPPE7jCz2+8Mm7XX0ryP47V60/j0x/p31d/HotvdlTfj59W0paK1dClQ7Sg73u8YWUKlUKlUsQwx4y2Lv8aoA1GaK25CKQ9KoZgeOEBHJYazqtV3zSlbVloEfFQtl1vg3p1bfPOrb7C73lkwcHPmUrHkvKufl26MtPSMm86ZeropkDQxYAY1VZPhWcA1kXPlmKNso+AOgx9mnn3TAqTNIzBAFZ+Lj1fKCeoAuqA4166FFiD+nMdzYSjBAqRNbOsuauTf9wo6QWaIQTw3lFG+LKeMJCuBb/nEtsgaPhBW0D/KcwmWmbPKDarWO0cUS59TaBHw4GCSyYNs0SWvqNIzISJqaJszotJYxDEJd+7c5lf/6B+FuXB4fMluWXjrza8wSyJvJmvDm2GzGcnD4FlC1QrQpr5h431jEQZqEGxcpmnLN9/6Ft9/8hBhYdpkyn7m8ZOPuTh/gXv37nNxdcnZ2Za63/PRRx+yPKxcHmbu37uFTFtefOVFNqMJ7sMYSeyKhrysdueyLCYQz9ae4/TkhN3Tx2vg4Bk2NvbTNHlf7R65j6QDAbJkrPbN4C6mWYHGefqmcV8khhwzGuobxFw2VUtpDFVDSgM5D+wPVrzXxtYOwN5N+hhrHEe2n7WSnTJQe4JlZlmiQsXF9yY4fUZUu/+8dr+PJEXrfw0Ud57QHWJLEvP2KdIRo2uA2jxokpY5o4SMyLWIGtbWDLFI4mSbeeubX6XOxtwPSRnFYwJrV1yNu/Yc4LZmAgU2vaV7AFFdsuE/1ZUKJtbZatxjZkQ6VdC80I6obfZi/oxzRQw1S0qIB5tinr7o8dwYymazuDkucbPxxzAM7ceenZKTocJkG62x/O1duktSG3oFms7LPqf4xpIUOavJEam7P24czUBmUirNSPaNFBu/G8mUwgNIiIxIVubdYgGi3YF6sef0/j1mTA2rSZgrLLPJbSThmsw1UX88ip0K8M/NAy88eIl7L7zI/uF75KqUouwOe37ww9/jtddebTzdNGSKVmYtHIpyerbl9oM75JMTpk1IZZyqSF4oYfX5UdV6KUby5zSwmbaOEKWPt0ItUdMzucrAx9RNlEWAQzjiwYQbi/+za4X2AR1thXsXptoMQl0sbXIcB64ur1jm4gE0zyrCqBX9bHJte9Qbn2sfYyiqfVoN6kdcMF6NogmDqMcyoPj+Wb+jIdK1O+73e0QxOIoTmsGIC5ZU288ZK0ajajxitP5odANh1AAp5KzcuXsK1UTcdZk97dMOrl4U17PEjsZH2/qMK67NkzQPUeMQTNYrsYr9awHRlYvv/4/DUeI6j/aEOLe5vgh3/WMtNQ2oNM7/8x7PjaFEosCBT3uNTr225OJ0FDHIHjnUlvRvBskCOp6aeBQYD2S34gmbCxXGLMXKBpcHSeAW8xMw3tLSJjUlahKGbBVTtEh3s2FlHJ2jcQNmJiO5awPDOHClyr37d1gOO7alMCXLBEoKgw4wuEvpzc3WBipKsEXZseRwtrk4GcbNwCuvvsK7jz5mvtqx3y3oXNG648OPH/LG66+yPTthd33tAZfMftmzlAP37m+YTrfkcWhSqS4wB7DS+9kU7pRiaZDUSimVPFq2RSB3CLdPqcVSKPf7vbtNyXWOtkkqykwxV5lq1czDtW5VtFfoGg+QEEbSAUP4ov5lmSUWkd9sNpQni3GUxRUVoiQiiPT5+rr6DBTSDFk7FALBYsjFs59SGM4wjFo9wODuN/oZg9nGfIUk7cbVli3mfdnY4as31q+jSU+OiAMjeNWMVY7K0TPdlzz0XCUNo4q/RY73qm3cbe1bLnVU+LEEkGiv0kXngTVNleBAJA62Bm3a0MXNtr21LnJhXkhud909HY7ez44xo/REY58cH/jPejw3hrKvrdAv+mRruFvVT8lVkIfIjIkgjkVnU3Ml+iZSn0Ub4HDdkhs3RSmEIo16IJXFTsUkjeOStil7MQypmSFlqgxtQ4ckokmDCD7Po4qSvNsjnN65y8n2lPn6mpwGyjIjGtFCrG3BNDGennilI6MeGone0K1XF8IlHk4xiBvzW7fuMG5PubrcUVVZlmrcriYuzi+4c/8O47RhWXYoyn6vfHT+lOn+62zvTEREvdXyjGUcm82vp5bCfr9jWQ7M3nEi8pXaYnSqpNbCMIy+AOJZEJHOWoBCC8zhbqwdauqZFbF4wqX0bSzuyka6X/A4teXzoLWw2UzM88L19TXzsmfKI9XdNNNh3thBqx9vmskj3lIViYCBatvogSQLjppr5PgvDg7WrnZ8jq3PqMV687OU7JrBhrFX637FceLAoJs62zd1lTyQIyXXvLJoYNYNzSp4F++qkNLQeFJb93YoRBHefGOdtLYUgSZ9pKN0oOWAe7qjB4B0ZfDQ0IS6l6AC1VBkEETG0yfwil9277UdRIYk8y9UKeq5MZSha22Lw9NfJAZB1rKFUF0K1prBOjBGJeyA0xE5a7yhdCGC0NGFOwIeFIFaFpZSffICuQRPas+34EKipCgLJkj1m1jp/cK4WmqVEtRBzsaXFQHNCdlMLNWQTA7jZx9FXQpldyBvRmSQhk5tBOIUj69wcewPOQ2kNDJtz9ic3eH80ROKwH6ZrX6mnnNxecH59SV37t5G60yRzMXhwNsffcyDr1UeDCcoC634MLSc6+b8OCIsZeH6ek+pdhDlnK21cI3AnF9nEkpdGMVIeDsYrHq8kkEXi7gVRYqPrbtlDYVE7UagpQM3tGUrqYa7WpVagquMVSecbE+oWtntd5Ri7rfxenYorfFkzEc81vurRXAbgoni0BDyleAdI72zudC1u+G29gNFxr2sUSUdTmqPsrdosvbI+DrCbciixF0c3YS/lR22Tl1FAQlztMy4qmq7vXabLR1KHVRYxFxSCNctmxvxGpdAm8QbF7LOIgrkqCvj36CUZ9hpM9hqWV7hvRHiMr+vlNqYaCt77zSPzj4nN6/n+PHcGMrOOXZdkxVR9bJdAaXD8EREC1pL1ZTSqhSY0CVBNIoq+oRHMrx9ZqKl6oscRR4Dvxv5q27M1TOIMjV5n47gPJr/ESJNN46+Oaykh0c4S2HxkzJKZpWGSlOrYZBQallIs7IZtm6o7PKCroiag21jpr64Us7MqjCN1ipjEMbTAdFEmkaGKXF9OLA8OTctfR6ZyVzsCz/4yTu89NrrnJ249+Zo2sa0klNeHXC2pa4urymLGbFhGKygiK5yscUCOrVagYdai9UBZaD1znH0YjVoPKIeLmFbK/4/oRkW/8EOGO/HEgVxNWosYtlCCmy2G2opHPYH7/VSaRmsqw1HW0nPfnQjtjLSywHKbEEDhGGzBa3m4qeOKM04+2uqc5w3DGXnKVdGNTzxFRo34YG7n+2CO4IEWt61AVT14KXTN6u9Zku/B0XN24p94Qd/IMFY57IuaJOIfkArnuR4T67Gz6R4q4P+6G+puduRI96goOsh15zx2pOsAZYI78u7dnqwqWr5DN988/GcGEphTZq3rCl3mUJv2pP+MWPgLlkKlOntayUnSrGwgLiLptVgvS7rYMx6kdkAqmIZB3UmKjuHvWtXK2vDnoynzNl5Jiexg5OTOKH9EGgbULje7RiSu/hqqX9FK2WxCkhVDd3k5JHgnbCUhXv37rRDNg6F2Aoa0XsvTBHymyeXV3z85CkffPIJ97eTuUK1sl92kEeyCqUeyOPIdHbKV958nZ89Kjw6X/j9nz/kO2+9wsTCkI2eSO7+2P5IzZ1LCfa7S3PhZSTlwTe1FSHxwUYFluIoFfW2BMn4X1VbzATarE7DgLrkS6Q65SluMPxNrcKEoSG/PsUGRwKBuXEAS1JYloXdfseyLHaAhSu4ruxNR1I4pxYuo/1N2zNVK0kTu4tLDo8fs51ntC7cevkVppNTFuJ6oVUyr4Jl5Tr6My+WTjH0lEADUlHjHL8fdcS2CpgcrVsvWhwm0PnilJKlAGPGKEcpPVdNqHqAK+4t9ff0mevgUILTDwSZjq4nMn/CuBqFYkUz3NSZbExCZB7CfzvY1tKidkrExKjbzaqk3D7BZ6ZH2GPPRCEbcbVKbTVIn/14TgylYa3QTbU714J6oYljttWflyzIY9Hu3FyH7Nk5YGLmy4trlIGqZpBOtxNDnoi2BU3jhUuba7FqPW6oRRKS3dBqIVKpwmCaMXTe0nWGvRJ5Wi2UOOkS0yiUceTi4pJhcOpALP87p8Qmjx4RNrfg1tmpGY/IBorqLC13mYZK2rVhB0AtyqNHT/jRj3/OT37vZ7z54gNee3CfVGd0mSHBmK05G3nk69/4LtP9F/jKkwO/88O3+cnbH3L/3m1eenCKamWUypQGryZPQ/mIodfd9RXzYY9kZZoGyOLQ1/sNoUhOLLNzjyh1KVBhnAZOTk890JPZTKOhsAXS6MZFHBk6KjQuke42VF87RIAEImBSowiF+5zDYNe03+/dUJausbXRPPYSJQzucSGFWEPdEBs/dvnpU5bzSwZfF2dffYPdrpCGkaIFMlaOTKN1Qu9y2GVDNPfc7itAhWeXaL/34BMboJR22UTIo92KxFpZuaPJikS7dNs8p1Yp3A9D6QaohjuEIfZjYxZIM/ZR+AqCRMyhoXc7GYIc68W21199/9u1dBf8qHq757EH3hXMg9TWatoAV63G09/M53/W4/kwlEcTRh8XJ4edkrU/CTSWUawzi7rbm1J2Ti6bfEErBeHR+RUfPzon5YnD9RW3tiNvffMbnJ1t49BpiyY5SlhKOUZthG4vWj8YchDNJrmQjMrSF2oszRV6FRe4RyOt0xde4O7tOyylcOfOPQ61MNdifbglsR0nUNjvr9ieTEzjhrlEAEDatam7oF0jqkSv64oyH3Z8+tHH/Pzt98nTLT59uuPe2cLpaJ0nl2UhycQ4TXzjW7/C1779R3gyL9x78BKH+ad8/PiSf/TbP+Ktt77Gi/fPuHeSOdtYjHFIyrBy9XNKXF9c8PTTT5FpYlkWzs5ObJAbR2mH2WG/NFQYGRxDGrl7/x6qtqDHcWAIOoVEBPKi4VnDF8kLsXqfHMt4ieXk/FpdbTlfHzmbF7EcZpZ5drdYXG9oW03bGsCBTEh+6DxjM2rduKXNxObOXcpuYZBKXSp1t2P3+Jx5gZKUsxfuIOOAUgyR1do/V6N9cq+XWMNIOO+6BhA3s3mkvao/OgLs40M71KUf8O0Vqa1/Xb1B44EFF/zHl/09dZVR27esDGi7bglOOFx0u3KhF8MwlUK7WL/XMLBdA9quc3Xj5oXE6xIh3qqE9Cs5ZfqvCaLEo3qRU52CbGVNSrth8JmyEzNB8r45MrSWEDb5GdFKEeH9jz+lVmEU5enTyksPXuTs9IQmMwGiSTtq/a8DKUkSnGZqvJhIMm7H9Y2SeqWcOHW7HMleZ0bSN70a6txsJpbLK3aXF4wnGw5lZnfYwbQBLUzThAyZUkDHHsTpRtwXk8TCiTVorSAOhz2Xlxe8/8F7lKK8/tqbXHz8Ebv9zK3NxJQHxmFkM53x4KU3+M6v/nFOXnqRJ58+5r0PH3J1fc2wucUnFzOXP3yX26cnvHzvlJdeOOWFu2fcOR04nZSNWDbGkAbqvPDu2z9Dswnlb51uGSJajd334K0nxN2fUg2p55S5desUBmt0NebsqL9Sy8E3dxeOhc+1rvrTi0zUHlmuVveRqlaCT0Gq1aQUlMN+T/EqTepzm9S8CENWcVB2pLc2OA1JSqBX48a2L7zABx8/4f0PP+Ds6cTZ4wuePHnK+w8/Zrx7ypu/8m3uvPzAmnKtjLASee5dGmQf4Wt/xYlCNxzt8SwLuR7NJBoAACAASURBVPom+Nxeh9EWUMjPYoGZjXFpz4obNQ/CtKZrXipK2wUiDP+wxQCa+RaCJpH1/ThgUiLoVlD1pmf04E4EO+sayTcj73RdyIfiZAxbosHj+pWoUTBf9Hh+DGUr7GoLPpLp0ezpbeG2AYGc1J5pSMT6xUQEPM4IEWUaEycnGw4HYRpGUjmwFEvgH1I/S9Q5kaqweC+XJK6PTJ5fDv7e1YsLJysrlgWKSRGcKjfjCA79g9yOiuTuBuTM5mQDpbC/vmSZC5eXV2zvP+Dk3m1rMzsXZJOpKRyo7nxF+9cUZ6ujzf1h5vp6x+Onj/nok0d8+PAR07Tla29+g8cnpzx9/6c8uLdlmAamvGGzOeN6r3zy5IKvv7nlnY8+5Hvf/2doHlhUEDK7feFwuOTRk2t+/71PuX/7hFcf3OK1l+7y+iv3uJUTiRmRwvXlBRVhGCfnSodWXUvE+7doccpKWdR0iSrCuN0ynp5RCkxpZBgnFl24fvIJSWdau9MmvLVMKvNA41+oVdAioImqglUHL25YXcQ+CCThcFgoi6cCVttoRStSV3nPzR1cGa0VeunZhmI9xatpQM/3e77/uz8mnT/mxdunjNPIo8tzhss7vPiVVzi9fwcdR0IrW2tHlGGC7L2lgYcuFSo+no6WbiDKvraVWoslUWg+Qq0mR7MnD9lSSWsysFKpzvE7ely56YbKYwBce+xDUjEPb9Ur0i63eY3O/tbIvjLDi8RKzohkD26l1Z14CbcYatVWdMNmtzKEeXCOl7ICW0lXVLb65VRay4DPeTwnhnINfLtINk6k4OGazMcnqjUkinzT0DZ6EEPxgr5jBlWKuyo1WeFYddidIliwYjVqsehkQw7u2sbpLi6Qt7Ova/NSnL7xW0ekcSJmPwnj3hAYhoFhs+W9t9/hg3ff4/rJUz45u8Wv/5t/AknCMh+4rgvTxoyOiYrNVEbnxqIgVK6vr7m4uOL8/JJPP3nE22+/w/d/9/u8++57bNMGIfOrv/br/OPrc+ai5DSRh4lhe8a1Jv7BP/rH7MYN/+ff/lt88uknnN152a6hLlQxuZGoUpbEwyd7Hj6+4kfvfMzXX3+BX//uN3jx1oRiPcKHGxHUWN52yATyUo8AW6m1ipDGidNb93j65ILDUplORs42W5bdJfNuIZoLm/7PkFxjO5sX6FpLwm2L4hpuNMQinWNKDJK8yvnShN+R8hadEf2Fve6G+jps7sjKsAVvp5WiMJM4VPj0/Yf8/IeP2JydMo+JVzZvcnl1zr1l7/KU7Bs4ujG6O+qbWXX1OTdQpRmhz7qPXWJzTB+s916gOFuiNh8p4YHQSq/Jqu0lR/dKR3UW9Q73eBWgUlpaYqDzJuVjfVlhiLtqRQPBHqHD8AR9daV+rw1dC254O/e5sh52mBF7+CYEP348J4bST51o/OWWPpaqJ30gYoGWxmdGhfEkRkJ7gYzkLWzVKySPeUS1cnF+znLYc+tkZKkHFimMYoi1cx0uP6m1oUPczahloWNaG9rkLrU1N1uIQM8660BWk5PERbbV6lYC7K533Dq9zcn2lO/9v/+UvBTu3L7NG6+/wpvf/raVfUvJSpWJtNM/Ri4W2+XlNQ8ffsR7733Aj3/8Y773O9/n7Z/9nHmeGVOipoWfv/MOd+7d51d//U/w0U9+gOSCjBNycsb1tfK7v/f7/O1/9Js8Oj9n3J5RyoKmmQQULajsQTLURB225DxwvQg/euchT84f8af/rT/OS6dDO0RiEcZ3ANHgrdYFpfYSYBhlsVSYCxRNPHzvfU5PnvKVN1+HlBvqp4mHOkhRbgRAGpKpfFaLaL8fUmKUxLw/MM+zUQCBUmPu149mF9VlRNJ+bqvZAw2qpWUZzbWSthvunr1CQbncX3F92HN9dcVhd8UmJTv0Sf1+wuq3LXKTB437C77xs4ayXXbj8I7t5MrOW1TcQsa2jn3VpnYydN1mA4rt9FhztnZoZa9PYDZOSSoOYLTloCu0EmzRkiWM4NrI98EP4BI/uqGHlSQuJsLfi9W/4pe78m60ylHxkWc9ngtDabKo1E62SkSW8dP5Rse/tiAiHcomgGTIMntSdWIAUc5Oz3j95ZfJaoGY7WYAFts8DG0oU4iMa6VUi4DGIIexRDtxbJ0io9Qa5l5rpwgSPe9anVu1eU2OopTRg1DLYebe3bv8oW+/xScfvc/pdstv/c5v8eDVVzg7u43kwYNAidbdjuCKYJ73fProE37/Jz/l7/6dv8/v/u4PKKWQVVu63H6Z+dFPf8Tl7ppvffPrfOMP/WFkf8X1xQUHBi6Xax5fX/HpkycosJTCPO8ZJFsx45QomHSHlL3q+mjC+xE+LHv+79/+Af/un/jDduC4x2Qe6vGCz2kEzKUTLPdbS4XB9JVQGcaR0zu3kVq4uL6059ARgIShcGdP6EJuC7RaZRjxVLqWqePXoOp1AnJitz8wL7O5mEcVtY+RRtu32v9yM/fa8GvB64yR1bJVtBSmaeTk7i0OT5Xd7orDvOdw2JM3G/dA6MJzg62r91255I7GbYvEIa83L/f42iQq/MjK6LnpaeXUkh2Ervg1bjL2W+hQzYh2ZWz197M50LYfzFVPeMfMxvNG7N0PUC3eLbNXG7J9ZjKwKGfYrKPP7w1Ab4bYn6dt6nrcQ9oIOshtb1fRlePwrMdzYSihb3g8B1rVoT8QExRRucbXrAbAOsKBpMyQR8aUKFjk+my74a2vfZXXX3wRFWUYhXEYGQfPDZU4jbShlVIcXagZm4D/GnIfDQOdkFxJalXOU+j4wsR63rXi+elxzRIzlRiniWEYySK89OorXB8uuH3rjCGPfPLpJzzII2nagDdQo7+9j8fCxflT3n33HX7zH/4mP/zd30M0Ow9oBSoswFFYLp5w9ZMr3v/gXT745h/i3/tT/zY6POKd9z/go6dP+eTTTzjMi1VYqUqtC3XZEdkV0bzJqINCZmQplWUZqCXz83c+4NG3v8brL99GdHZvV93dCh7Is5bstKD1WQFUF6gHqAemaeDszhk5G/qc58gJNyNp+j6LWkedygismDazotUOxECgVpQihtBkSmkY2c0z+3m2dhaqaDK+a50PfYxujh8G+I6DEmFVY21myVw9fkrOwHKAAsvhwHKYrZaiy+NU9MjA9Syj2rSC5oBpSwlUCcBh69jWhXpVq048tOCoxDXaAe9Js6TBUV/TAK/v0veLbU43UsmNpqkFGs1R6dku8dwWOOoHUehItVaSo9NgZpvkZ2WgAxLK+qbB4wK0TDgz/tVdfT9IHAFrOy5rd8vLF1vK58JQ+jJo34VrrdWj31GxJgawaaqDH3FBduQ8ZyGt2miqwq2TiVsnW8Aj1UQebyTrW7qV2WpDjlpqi16r9rVlF+kgk86zdHehG8OedK9+Dqe2QAO9XlxcsNluuXvrDi+88BKfPHyIKDx48DJ3779AQfn44UNee+0NUlbPw/WxUjsRHz9+zPd+5/v88Ac/xhZ0uBK9PmMszFKUi8uFH/7eD3nh7j3+2K/+Gtfvvsfb777L5eWVD7CNe1mUWmZSHsgDxv15OqKWA6XOzIcdpVY4u8NlFX7v99/lxfvfYTMYoVGr2IaLKgurzArVSs6JQ/HmXiqUw55lbzpM0cqyLCZBUvcCHP1UD+qpeMKIevmyMAliMdii9mUB47Cm0pbctJmY57l1YkTVeUo9Knxx01BGoZYeQOp/F21Z0cg4UocRhg1VDnz86RM4G0gklnmhOJquSb26D5/5zBZpr2u3FxohF4tOuxEVn3Zb070/T4jdxRe0rU3bXwYgBhPFt9qW0t3qeF3jKGnubIKeEICylAPLko7Hre0VAwmObgiBeCKCh7634qtRHI5euek+g8a+kIqI5b+HTM4OyzAcBanFeufQwcwXPZ4LQ7me+UbExsZeQelmQOPP8TqhaShLEgtgJV8s4i61tmHyTVBJrqGz2nmObMRiyqVWR5Q+yZ43F8yNfWftHyIlLNzsGhkd0rmWIJ47CnY3QYST01POL865dXLG6eaUelB++JMfURblW299h832lKvLPVkS0zgxl30LXiCwLDOPHj3mJz/5GfNh8c9JlDpb8EhoC62U2hDSbnfNj3/+U/LJCQ+fPObTJ59iRWU9XKIVLQtpsHaxIYh2Z43lYMqA/e4cVWUeJko65Sdvf8R3f+WbjHdyz1KSPseiniiQhKrFq1MXqpomYJlnrp8+QUnMy0LR2aKxsUEVR/axacITAKLMmeK1JxMsYrniatO4YIkMVQxh5pzZ7ffsdpajniVQx8qTfQaaLCv/+6ah7G4lpClzcv8u+6dXlM3ANMAwwXBrYhbhUBfmujDqQlKvtrR+pxUnWQJdok17qnhf8HXJrDAOPu/rzEMDF8lVG9JaUCS1Bm85WfJDr/zTDzhxRKmsU3Q6Jab+fzPOq92yuqX13YXxBe2GuN+ho8tEpwJi/eLPjewfvAj3TJT1C6lTjdNUg7ayg0xqaWf20QU+4/FcGMoA1UTJMAUkUaWAGCEuMWBxuhEnjr2DiE2ypEQaJsgDWhZCaJzcKCkZK+m2rnwdkxscilWe1rK0C4wATe2W3H6PpT7mtFCKI1LPGBLClfKUv1at3a0lSk7C6cmJ3Z8WttPE7dNbvPby67z903d49N1HvPqVU1577VWilJykwY2Kvdvl9Y6PP3nE4yfnXljC3E6LUPfNY1xqbuhABuH8+pyfvfszHn78Cbv5AGKGIiex4EKCNEREWdspXDRRdYayoLMVFijTjnma+PTpOQ8fPubB7ZeBXgy3+XHi81wNCqYk1OJFKzCbur++JORiU7YJ1zZ2Hk0PlIM2S2A/pUY34DxmVfUsp4FSDsZBq6VQTkPm0ZNLDofZAlaafJ3QAjY3zaRN33FmzhGiNIGolVQbMyd3TtA3X+bq/ARZDmxGYbo1sTk5beXWllpcKZA+876fCeIEvRD7RyKKa2DCWOz+HOPwkt1PizZ34xbBGyGT84BmcW4yHPY4OMK5x7+LVE6AhHhHTUHJ2cKx4u1rG2kt2PsmQAqIBU5Vq2UppZGWiy3Z7Wi8LuR6VvHeuE05+uwk2RFl7QApdQNftbBUWtQ7vMovenypoRSRrwJ/DXjFx+evqupfEZEXgP8V+DrwU+DPquojsRn4K8B/CFwBf15V/8kXf8p64ldyV7EaeSuYecPNtYmI39sCsMidaSkdUSZbDvGfD83K4Em7Dt+KVlexRbkjgANRTCE+s0mWmosNFkiKkzF89B51g0Cm9r45JzbDwOGw5+zWLd767q/wLf03+PD993l6cc7Z+VPyMHHnds/xDm6mauXy8pIP3v+Qq4srd4HW99pwtOWhE+hWXaifubi4ZLfbEQdOtNhNnjJpC6xHjQ1duhu8zCzLAqqUxXjdQxHe+/AD3nrzBfIQh1AlhVZNQseX0aJMmwGN9MKwhaIoxQtxrKpyrw/NFZxrkUy9adSE4tHny90eGNjtrKK5AVRlmDLzvHg7iOCv1Kkd36A3EGUgpyMUeRN1upeyPd1y5/5tpmlgezpQDnuGAYYpM203tuKrooshXEl9nbfATRTF8HUUP0cKn5UO60ZMMSOf/DlNgKd9CbVDZjW6to9ymFcz2hIJjX04nOvwEXaxvBoP3Qy5DC4V8i8JqiQUIdADO8YNt83fKgyV1ZoIwx67tF+39ebWdkWNm1yhVfu2GKf/9KkrW4yH/7LHL4IoF+AvqOo/EZHbwD8Wkb8J/Hngb6nqXxaRvwT8JeAvAv8B8C3/+pPAf+//fsEj0F5ULwlDYsC5GZcbZt9qGvrAe/SYMJhpIMngBri7HC1cpsfcIm2Q4wRWrybj1xefvyLpW+aNyx6Sn2ZVVnfgXIyoeiAE0NTyZeMjhzyam4ny0huvkVPixVdf5tEnH/PeBx9wdXnNm1/9Gi+/+urqfaGWwvmTp3zwwXscDnu0rrJ5FVpojx6QiutXxTsgHliW4j2dPWLZRG9Q6oKnOlguNJhIuVaT+JTFDrW6sGhlrsLHnz7h4nrHndtbpxuUMi9+WV6OX4TDPDOlU4ZpYKmL6StbwKVHU6mgKdaJ4QrbmL5xtJvQkMtUKxvkRtein1e7HY8ePUH1wO3TEwDGcaBWy2KqtbhcKeZ4nRFy89HXyvpf6Ga81sI0ZO7eu43WA3k4pVbjylOGvBnMUVILUJkbHKXYnvGJtZsDdS7V1BbhHt+0150zb+/RXOX2lHBwWgHoFmyDTmtIBNy6Sy8r1zmOxAA9KeWWXqtRx0FW4nEF8eIX4q5EtPqIohgW+bbCplanVCKm5IeGOC1rXTWjWr7NnY9HXJ46Sq3Kk0ePePTxp4go4zggnzPe8fhSQ6mq7wPv+/fnIvJ94A3gzwD/jj/tfwL+DmYo/wzw19RWzT8UkXsi8pq/z7M/w4bV4DJCNGRcZz50nq8Ng/0/6jJKQlw/mfNATgOqubueK1K+H0YrdCWyWkx+mru2LwrldrH56pmNhzTOx8qxrcFqiOa7dIG1kURNllIqpyengFAOB9I4QhLuv/iAy+tr3nvvA062H3HvwQPy0CVNpRSePn3Cw48+Zplnsrjspq1fI7Y7EqVdXK3K1fWeYbb8zJytA2H07UalVURCi2/C4tXX4yBx9IWhnFoqpSpPL6652s3cuXOCqlBK5XDY2zXkkaUcIGUur66ZTk/Zbk84zBb9TT4nNrXSDENHQx6QWJ814f457WCgxusOqV23UvnaN7/OMI288/ZP7bOGzGaaKMvC9dW1I+XcjJ4Z5O5xrBfRZ1pBrCxU+EbWuErZbCfObp9y2O0otVCrWlBxGNGUKX6nCSsYbG1t17rQ1Rd4sY8amM/Wb+OPA432q+mCbUeCgTRFWrGXxqsnR3O+jqvEPNA5xdCZrhBpcOEN7TbooZYR41lReNUg3MDZIaftNf26ZfXe2hF0nAnh5WGJF9Z4yznIAF/ixlwcKKiQdOD68sBPf/IzlnlHzlae8Yse/1wcpYh8HfjjwG8Cr6yM3weYaw5mRN9evewd/92RoRSR3wB+A+DFF18CQvLRnQejOCw4kpRWg9FIbJ/8EvteEBkQMimNpDQ0N1SSiX6D0xTUK+30CBoxAWL9QFClzAUt9eiEDmMXAQibrOwZOZksFVLnD7W5s3j0sAd2YhEc9nuefPqIr7zxFZIk5t2BeV6YphHJwv0XHvDtb43cuXuX7O0e4pqW/Z7Hjx/z5Mkjq1mZe0UVvx2/cBpqt9+bO7uU0rZ/SoOR+I6CQxXcJR/FZBTFtnXUkwQQb9pV60ItC5dXey4u9uiLtieWolztu6Gcy0xl5OrqKePFjrv37zMMA4elsh0SQ1R4WXm/yb2DNddbI9smYMP/R927xFqXJfldv1hr733Oufd+j8qsqnxUZ7e7+iXjAbJsISEzshkw8wwjJAshS57AADFkAkOYwAQEQmKAJaQWNiAYwMRYCCwLaNuCtumH27Tr0dVVmfm97+Ocs/deKxhExFr7fPlVdkkg9PXO+ureex77sR4R/4j4R4SGrzl8a0GNUu7vbrm/fcWv/NIv83B3z3o+ktXyvZd15nx8ML92HoHBZIUjnQsZ2WZ389dbiLNs31dhHCfGaWfsgDKTanHrJ7t4pFFWkgpfQX3gpqKjebUiw0gGqU2oJZL5J5ugD385jUrU0mrpSLIGBzEn0pA9MUI639CcVZb/Xt0iU2MY6HaNETSnaqmQumnxAJ5qWlvZwWChILaS+g6N+3W0qU5Id2FHzEsz62NWzCdq951MQEJ3J2eQPKDVfPUffOOxFepev978/nq8uTlE5Ab4r4B/Q1XfXExgd3b8zIeq/qeq+mdV9c8+evIYJApJxOZWv0ETXD13P4SNf3bTQjWEQZLMMGTSoLaIYhm2lAczK6Q5zrOblm4WuOO3ris4r65de4s7/T62RXO7EJT2mhsRTSDHP0nWEmJ/dcV5mXnx6jl5HCgKp9PCm9sHzufCNO354MOnHA47a7fp/C+A0/nI8+fPOR5P7i5wuslXpqRr7Xb/KNTVUJRvwoa0SV0euc9JS4Xai82iVnTXaDn25Vory1q5P648f3VPqbbBy7rycDwCcNgf2O33yGDR5vvbO3bTxPX1DTmbkmv+Sm2XJ/KzL/759MbMSFWkKMb3Fu9lZKXT5rXyN//m/8T/+Zu/yf3dG9Z1ppbCmBKUammM62qBKQ2/H27G6+W/KLj7LsTnpr9q+DmtqtIwhLWT25ppdT2rm9Xlqw3G2nXAuaG1m7zhD2xjFdHvi5j9xiURCK27b2JJR7DGzFzHi9KzzKKGlwimkHMQ3nyPBnVJEjVlNGVnKTorBEOS4dPcXNpNffsZzcQi2h5UrTDIos6qpfLqppCOCXLbXqZ0otlbc6+pBXZLKTz78hnLMpubI2TITzl+JkQpIiMmJP8LVf2v/eXPw6QWkU+AL/z1HwGfbb7+c/7a1x72WF57su1Y9+sZHNz4FC/NrjhSSuQs1GwRcOtiHYtmszC0D7qIlUts+Rr+RlWlrNbCIEyaRky/gP7Srh1hqNbR7UKop6blAulVz9iowKeffUYtK0stjI4krWq79cHWvAOssK9S23UfTkdevnzB4pFnNtd6S6zb7xvhTmzoKi6AgxJkaMD8uLTnh94EywJBoEuhqHFXLeBTqFo4F3j+5pa1wqS22NfF7uTF8+c8evyEPAws68qb29f86Ec/4rvf/WV2uz2sZ0Q6zSpMtAjWuJO0m27YtQNNWoQblqVSCsxFKSR2u0eQMr/7j36bupz47NPvMOZEGgbWWjmdzlaHFEwg+XjZkrkUOm2tvMM/2T73lmDK2RS41gQ1AlrOE9Zm4xoXsZmZb/3uyi4ENvQCKZ3s3s1SNiuAtz7XPq89up+G7CnAlrOdSIgU04XG5m7yGQGyo98qLihlI/QG1rK48M0Iue0ve3K/vgtYE3ae1OH/pW1a4tY9Jn3uqWaNUrxKFMbHDTabyQu/gFqAbZp2nE4nXr16zbe++eE7x2l7/CxRbwH+M+C3VfXf37z13wH/CvDv+s//dvP6vy4iv44FcV5/nX8yDqc+dt8C0GrVRZWYEHYNGLrWUavkk7P7CLPYvzQgNfoeutIQ8cwDFzaB7mKgPHwqWPsFc1xH34+4W6VV9XaTwTK/BEoX4i7WiRdC/4b2siiwI45xZJwmp7AkhijoJ1Bq2TQ6C1+hfe/29pbnL156oWEfP63uMw9tENoyFoxnKgTKdWQmTsPBTbtAB4ZUnIDt9TBjE5rfp/o4q5nnWliK8vr1HefTwtUwUgtEcOBv/Y9/i48/+YRvffNDR8HK7/z27/L82Ut+9Zd+kU+//c2OlupqFbjVcLT4Yo9kg9ivqnjxEWHYDVyNB/K4Mw5oHiENzPPKR598zBef/4g3r15QlpmqkIeBNGTO85laajRibENmw9ajreJXbu0tNgp4ewSqDPqJCUqrO1DEyO1508/Fnst4rBsZ3BWFo0hTbj04J1jvJaq5fxpJHG1LtkXGxfZNNIaEQMuVVv98U7NPXOiY4Im1bRQbGx435D0IY4tQNll12hIAkE3qYZjUjUCvF4LbOJiJEm0bQmGrtO83ulkCqZWcEiWEqcY+loa+o994rco07Xj06CnLvPLm9R3jOPJ1x8+CKP8c8JeBfyAi/4e/9m9hAvK/FJG/Anwf+Bf9vf8eowb9Y4we9K/+kVdQ8VJIlSSDCR6xZPxAX/a5iJj5gCWa30XiOynoQSNB9YhUqPZJEYK4Gu/0fSFtl6zNd+GTEjtS2yftmqKkuiGcV0Nn4otSxSbeIoBdyATSDMEbN6n+fko9qg62KVqXOr/f12/e8OLFSxd4impx5oBx+EzAqJNxNdaxbXrfDOpSXfCe5gV6ncEwd11QVu8rUxSrue+EZVG0WKAnChnfP5w4HhceXU0sWrHmVrDMM8++/JKbw55pHFAVTucFSZnPv/iCb3/4AUmtaZsVqu3rILmidGvMzVKvBZCDarVnt79i3B/I02RKQQZ2+z15+A5X+4nbbzzle7//+1j7iQlV4bwsrEsh6FBCaqaz+vjHcrVx6eZaSzryv8Nst+/a+OacGcex/Y2aSR7oHv9O5LBDFx5d6DbvM+H764Wcu29TcJSlrhgVqljFf0m5+fvMtFdKLdYeBLyzafItZtaYSrQJtlOmVovBz+0kfvcK2/qVbvLiryvWlA/C30jzuWup6FrRrEQ/K/sXe1I36afSxzaEfgCDcKv5Pu0nCuvAlMHjx99AyxFhBf16H+XPEvX+25v5f/v4C+/4vAL/2h913q98T2IJGBWgo69udvRrGI3BNkAPwoRJmdzMyUNyJLNxjEsXqsZLoyHODXywya+lRXbF0Uw0NpKGPO0In1M7hcSExWndl9O0YTfL33VsCcESTmw/jyli26QvX77k7u7egktYhW4ZvAOeU4Ms+ipN2thmFJomiut56qahyUBCpoFrtYhl801qaqXSVK3HjxuGRiGqAw/HmdvTwjfTAMOIuNZ++o2n/Nqv/Rq3r1+BKjllDoc9H338EdeHPdV5nBK1Qn3TahZKsbkp0ZxtNb8sPjfTOJGkMOZCqUfm2zfc3r7h7v7I8WHm+bPnvHjxBUkrT588MRQtXjTkvFiQSbVvekctHb/SxqzNlW42a8g4X05vE9FzzgzVtl2tG8pMpPE5Wuw+tfiutVmNNhThlojf231u5xMurj1ItrXtiq15MZMBlaiyFDS2MPWFQKguZDbP1uDHxsVQlRaJD39tDIxs9kLsveBdBk/U1re254+l2xWmNNSq2lEzDS1bT4Qo6humt0XUHYAkQaWyO0yWSlrOX9mD2+O9yMwBL5IqIKn2SjsuEFsGlQS6dHWMoyw/R5KE1z0jDxbyL0vYMG4ShKCkB1s0BN5bQktd04ZPUwIV+j2aRo74pjbQae6BHphqZHR6qf14oPBn1v5SO/q52KiqDXcQePblc44Pp1aIVFUtHzYO0AAAIABJREFUKh2N1uJM7rO5yMio4o5ysP5D9rN3I7Sxiw2ptboQ7RWv4560xr+CyoqqFZoYpj3T1SOGw55xfwXAx59+h5tHjynrzHy8Iyfhg8fXnE9HPvr422jKSJZOkcFanUoy+pKWwqpW0HhZFit/pwvLavSiL9dqjcxEWXWh1AUhcz5XXr96jc4zN4+uDbVSrR8SyrLOLF68V+1FYvG9JRu39RhaFZ+2NNlsbEd8sVZFrK9QFkFKaeuyCQMXQC2Q0czW6MJ4SRnCS5mZ0PHKVRegIhAmSNULxkSN6zkKMxSYPbMlfI1W9zWQ9Vuj0FBagww+Fi2bzoVgAI0YIHtWaUmK+HeqAyZzMymrFrIKg1cCu8BsYkGkJmA34xj9ytvcBMhQwF1Yt29uSU8O3FztKcc/BkUxYqqq51+mpCAD4BSF5KiB2hupa3WyqgtIxHhUyRugi3jPjdJzOBQi2u2wz1GDtkmwSbb6kurZEgn/CNqQpNHzAoua70OwoIgEjYNAq07WbtcIW8ADO5GK2VCoeG9v/0SDKk6fiNsFXnz5jLpEzqoFNapWkvfe0UDj4aKIsfO6g15801GhpROuFIoWSglEG6mHJuy7r6qQtLJWW5jGo7TzkJW6Lnz+kz/kV777MdNu3xzzP//JxyQqh2HgNiWmaeL66op5PrIbrGJNcfSgtVDKmWVZmVc7f12dquIoYRCjkk3jiE7uClCvHCQJrTtqgUEW0pNHrOuOcRybO2TKVnN+mVc7v6cxbh02X12yUYk8VvDle02FaA++tDlIzihI4q0nzLQ1W8qFozoYaEguzPNKNB+rrhhFcUpRb7cR1+7I0twVjVpXwUrlBSG9z3EeIqocvnmFjI9LwJQQntVHyfOqHY23YjPN7wp9CMJ9oKQ0eDajgOfZF3f7JGAQn8/qFkaCC1qfu/kVQQvmEiqgUr16llkaxQVmKIokmePxSJKV692AXM7gV473RFCaNslEGqALkOQitGVHQAiSZgxphPwduaVMksEL+Q5YgQcPbrD53pYY5ZoufIoWQNVNN8YQMGBE2dDg4hsKUnSLBGLbBIcyFEEI57f3nlvE7X3p326/4YhW/JzF6UEvXr+mVK+5GGPpBT2yFkQchUUjqlisblbZ6q2oRq1JW/YWQbfx7pHbPlsN2bR5cCqGVlRXVFdKWXj+7Et+57d/iyFnioe9v/jDH7LbTSasgP048vjxY47nEz/+wQ+Y9nsz33xT5WRRdUnGZphG43sGUggEb/cjViOATFG8VYEpuXFUah0Zx9za1GpVBhEGyazn2ehBwSwg9WoS0ITOxdzpuzfYthDshdCMGRUlafWMlRZWa2Nq5nfYDqE1ogKQnbT1BkqxD3wNv4Uom4nsy18cybWAVfu4EC1KYrK3T9fqfQYOjD0Abl11dBluMXPBu8831nD4JP3+hMAq2qy3wI4p9bKKfePYeuXi3vqzBlpVtyq231Rsj4/TyP6w5zzf8+LVS/bTH4tWEHaYVor4N20TxtEGttngTiyWAt6zOEdmTh49UydqHW4m/l1rWzY/BJ/qwrKcUF2APWDBorgPCAGqzbxO0aUx1X6dyN1tgnTrm4zfN1F1kZ4GuTGVoQvNQDO3t3d2WmvSgnpubK1CKdbmwJ24NqpasLJ0vlKda1bFChKMeUKGAS0zquF2SO051XNqg7tqQbFYkIHkrBBrKYVSVhKwG4VhmgC4eTR5AMWqYOecOBwmDoeR1YnYkeI4ZCF6fxtvz7l4IrZW/L1ITKhSndVAS+e0/VfafBmNLHvTMUPe0zgxzzPreW7VpfQtwfjThOL2vR65DZHYN3GYpd1ACAXYP9k2+sb/1oVApGViiqGa37Jms662/sm373XrTwyfu2Uz9Wc0A8OsokD/Ao2eF9ItKHzGS04tR1vAqhvFtbynfBWzpqqjTzRt6GkbwUbs+a+OqzsB6F7TzWeqrz+XCxVLpAjKnqqGzUa0tRiGkcdPn3C6t4SUZf3/gEf5/9fRtF8IQ/XgjmsGdzA0bSSu0QIdWRvUwQI53rY2Up0jUokj1O6il83CxTWuullXKPVMVevTEsIZumbcpppFXTuD99L8THZaF+zhJ41iABt1d8l9k83r/lrzLwlLMXR2Pp+gGm3HPptRigdUirssAg2ZKSVhssV9u2OnlMo4CnmckGVG14h8Vy5VTWxqA1yWjme/l1IQhkbILhUjk+8Hxmxn2F/t0ZooS0UGIQ2JYTLhnWryXP3cikM0mot4UkB1VOIbx1Bs+AItbVGrRXir4v2PihXH3RwpJYpYb+dpGlnXlXX1YsM+1xcVpv4owbkxud9WxrFm+4RL/5zG2vClTg/i9CrmGxO+xt/1QmlvOZfbew2kbZeTvnkIQLDZB6Hsg2aunTHRRK2vQUE2pfc65Swizr27YgRxYp9aALANnz+LrRmFpM091vdWHz9xNBtjWMMyasOpzWqKTzUk7/tq2o1cHa4o85GcKmWZ+brj/RCUgkfVbOCTGL9Mqe5bsNfCn1LDXNGgGFhdyTwIg8CMQEoMw+gTVL1bofk8o9S/ulCUtvG76eC2TRcWrvljXauq8c7aREbbB/dsiWvAMGXBfY5WxRK1ArwmhnrNyHC8b4W4qLYAV/hT19UmdpnnyLPDCWW0fF4s+NKDSfax7f5uvq9iDbdUlWHYMYzGhYTVS6vZ+JlyivQ1ULKbcUHxUCorpZwoRTidFiCxm8zkBRiHnUWv64okYdWVtdY2bls/W2tHWsMn1htvxc/qvbAjMGXZLbZJTVgWQ17r2qL3WqUR6VNK7PY7lnWxfHPtZunXEcnjft/1uS3qqVXDcu7mYQg6j1hLM6kvESna2+8CFrRTuh8Wr34zjO+8l+aflrC/bAFktkFSq+2pavtkSCOi22TCyNmpvn58vQW31GBnQ3uB/sw7n02xEdQu20SR+qrqrhKxdhHqjfiiTXBD2YGCK5A726RZmO1ZTHEK2QWwZxFJMEUM2Fxf7/nss894tttzf/uK3aOvF4Xvh6BUPKQfJqrXfWQT392o6kBVsfNDcAW6Q8SrCSUvzrvtfeOnie+6Vt5Y8xuJCOta0KJEj3cRT8DHPredMJMlVvNRI6IZz5S6f3Gr7cWzEAhS7eacLRPJbyb8kKLSMkiW8/krm/QiowNpY6LtIfsg2AKy8xvqKqQBxnGirLPRjXwDF9fsKYkFWcKP1tLFVqewwLJWlmXg4eGBeV6QtCNF9W657Ic+e2OvUC4isenCz2WCUrT7gAPhaDWydKAKIXl+vr0fBYGreiCoWtUeYwiYiyBJYr/f8/r1K+bz7AIsKiZtlulb5vW7TNx4v9ULvRCMm3JpsTq88EhwfaMt7NsocfvdLlDdX6iRUpouLIW2BvyzFsFpYZQwsy7uJ7LPGptEAqElwu8X6a66YeY3gdzqA6ROhYvMmaZc+qp2oNmQqsRm1y1q3Fbp5xK549fwfZVEGu8dgkYYIxU4WNjvd/z8n/gFnjx5zOef/5jD4fCVedwe74egdP+dNpGAax2l+R5o1sIGikfuaRcleKk1RJuvxUo4yCZ5X0A3pq9VM20mhV3ezriui5GoHdmqC9EmbrbmOF0YhhDVdkn3r0nfYI1A/s4h6c/cdevm9t2MXKN02WYjbTew63J6XvumtmMIUpr1xLqu5KGQx4GxTJyPixPmU6/f1y2dr6IXH0JVSyE8nVbO8+oO+fisVeRRNXLzuhbO55VhSEbrIQokqys8cVRSv3qt+D0Ffab/a64MNRQc5eN6b2oXwsVQ5TzPXmot/JzKdnouo8jKV7xasYFdULbQzVbYaXUZ0N0ogRq367sHYbj4va3Pdj5Fcw8SvT027X7ZIlqwqkZWhgLpdJ7kICOqchlu8PsJpoe7dzQEsO/V7c7ZSj/1Z+62ewcA0vYOTYg2wBr7PPid0hv3XQCUzdIyYa/2WM1CxIW04P3ryEPigw+fcvPoisOjw2URk3cc74WgjAGyNDE3gSUGsCfQx8SI+6qiEVgWQ4agbZLFM3Ss4IUjiHadTatRtSITqPmstj6VKhjKWldXxhYYypKbkIknMIHWEZZ6LnLzSeLIS3q72fjZp7NNfzunIWZfGtLfn930LjX6muBuXM95bqgjhG2iF8zdXCUCJdh362r0m5wG75MzUlegrKRmHroycN+gVUVyxsEweiDG3CHzuphwEG1KoXpOsFYXwDpTymzXEveZNnSttHJ7EsSYTQBMjdcAoE6gr0XpdJeolWObXKujIKUhDVCGnFlWK+irDQFB1LMxX2gIt40A247nO5RG+7gLKZTNuqGtW3xsI8L9dlCno8O4/X4u0UQmcps3iBK31ASiWViDbrFyRS+eCTVEmTwdmHDNtJUeq9QRow2LZyIFbvMAjxdLsUryNL8jDUK4pdPGxOY0pdzcDWbBKBf1GnwNQh/LUJJWVNpRbFhP2sGUEH7n0rKndrsrqzT0Ncd7ISghhKX7pyTAnQmjKPm0NsqFDUBA6RjgNoXJ0JOkoQ1WBBtwZChSHPlBQINIJ9zeVakVLUoEQgBHDm4GNwHIW0VPxVHvVgDa6aM1RKAKt8zbUwQMak2d2l15AEkLp/MpbmUzIrgDPS7U68HEWSQKSnjEM7ZzaN1aC2VZkJwZxolaVuZI43TTCedNqqqR8xyNi1i/lZwnE5wqLMvqgSZpwitQjWNdEGUYkwdvUmvdEeaepD63fcz7uDb/lRptqfn7COW1McUVWsHQNk9CHow3ezwezY9ZVzxHtgvUzdJoQYn2Qg92tOH3t8JfGggy5qf7KWnA4G1h+/a/ME0V7UVCFC/oK21BhJDc/my1xlRplRV8cYn0YUngFXVCEG8W7/aIRA3dyt90MQZWL2FL5pbLn67cK7aWQuC16kXqQr7NuXYhuXExtA+LSQZx8CNiSZhx6wl1RSNdeedNIZufcrw3grJNrzgaaIpn85qjC/Hd2vhzgYnUInTJI955ML5caT7FQIHahFurdiKOLOOSfu11sXzvQAN2ns2gbswlSZsJDRO95R4GmdgXQCvLZuZOagGdUBhfvUagU+vceP+VMezC4xIxhD5A1TKg+gnbBbTJu8pazsgq5GHPOI6UZWSJnOrQKi6QiKo9ukERao3bBvECw2pFtnp/6FAOJgRrKdbUKmcXXGkzBi4oU+c0hiKK+QzkFRFqCTOxGiUlkbzQraCNl9dRm4jViyy1GqLcoJmqPy1jowvjOFd7MI3gjb0WnMpuurtf0QWlKSEXeA1dXgrOECDVn7V9UpRVK1kdyW2sDscFbby2rgMJXyi09dWaKcTYt/XeRL6vFl9jYkJOBVJ194HvRRVjnESCQ0fOl2Po2t23i5Xts37soVTlQlj6MFxswTiam0EE6ybeFUej5tW+5gVHz2lo+/KnHe+PoFRr/iQ1b+4qNn1o7g08losfnsHi9R+zpTImRzgbOenWh3iSvw2PccZcnSKbSajUulDqjFVnLhufogP5cKjAZoNbFDECUV18+QJ0bW0eBpvUKoGN+38Xz9nuyShJR6/t2EjH8Y+Nv8tKGoFky/yoOJE7BI2fvklSX/is1LpQ18wwjoy7vVXl1uIuiKh6bhunlBUVIdVMKUHrABkErSulbE2vzfx5ZelAWuMwgkfUL9oAp+TP0tMtQ0C2sZXU6iGqgianTKXkkXjftBvnvvFJPdI/Dlbmbl1Z18I4xBxzIWC2aPAiyuw3cxEYeYcpHhSmnmkdQbeNi2lz3S48/e1WNUnjIgSpWrf3pbZbynadNmTZFmRDjQ3hxk1sctyTvPUsDc2qdwgJBUZXEkAHIMLm6+3yvIXSm4JwulmADisOE0qFy3EPmb1V+ghVstUm9WfX0EUipkixvRdNqmsToO8+3gtBqRjNpdbCzc0NkicIn0Lk3NKjyEiw6N33ZaqVlLq/SmTwvFVxRFE8pclTGN33Isl5WESLS/HgTkQarW81ntMdjZEaQVwdnXKJKvpiCSOnmpZlo6CRrun8z27MbQS2iAtZWyy1Vh4eTFCGg90ShnwBJ5qADCHZUuKkPSnZd4GAZ3eEzBSPgK/kPDRUOddCz/t188/zvhNC779ukdxSK2spVtVbUlPmWZJ327P6h0aYSh7xxpWci0DpJntHjyHkHfWIItXpWAE5AkkFCiVyiT2V1M3x6v7kaZqoFda1dlN5u4u1uym6WRgqLYSWvw+oFDYiY7PavfWb0tattSvpyNUeqZvZ7fQbgyECQ3b1beCovIXAfF4dhUabDAjkhc+Xi26xXPSUM5KtJqWGym8+5k0YS13ZSxeeAFK6pdbuhVj8qZ1LfTzDGAl3WJRBTEl78RBCOUUswZMCso8Hammh6lfzPWwtpO08if7MSPj/M+8IzV0c74WgLGXl9esXHO8fuD9c89HHnzAeDu6j2nZX88FiYz6GsDHb0pGCDXZKVtbeiu2K58Q5evLB3xLP+2KHqPxT1SLLtQT5+hJRbn82HmTY0LG4UheOYVrbnTuK/IrJvDEPJASYo1+s2+Hp/sFvQ5vQ6KaO+neTtZ11VdD8MMnT88K86rZ5mxOthdUpO+O4Y9ofTPgtseEKzf8qlkkzjKOT/F1AO5IoHhBzmGY+QUe1ech9HNr/mzLbLmgRRxptxONZINwvQkyjbUZxs9YQkEGsBBdFb6OwxzAMTWFfIrkICkH4FHFBh9g1BFq9hhZE6bV52qh25G+CTP36HW31da6OFpuIdUkSgh9VYwj42kja209UV2RBiuvKo7sAymYHtRWnnRuag87WnqB/+jKfvG5qW2pfUz5HISgv51RpEK8te7tH1XpxX/060UNpO6L91sJnvH25MT/U7iXT1Hu3yP0D2+++63gvBGWtlR9873ucbh94/Ogxh92eD8bBNpZ4Z8ZUrYk9G+2ioYESxV+rCJoztOh3+DsDoQIKKW8c5JvAAL6IxWvKa1XWtVM6LgWaC0dfIOoINRbShS9F+mKMBSVoR2ESwm07Mj7RIcg8ALMuK6foP/OOZdX9extkJfZcvSl9ZFtsrrH5mUSQWlnOM2himCbGaW8ZP1qtLPy6Ev5hkeTCckLzaJYAYiXaimt2H7ZWm9MjnKCOOqXDphqCLwIGLTYPLoARWsJWuD9rCKLI8oiRFJxP6a0rqhUbjvMNg22F4/FI8XYQuhmTCwEZ94AH9ULA1O4Cu6DOKBdr7ZL6E8IsIor0iHsI1kBqrZ2vz1pD3TgdKe43AjtcXLOpeHUFsTVhEQ90tBmNGydcWv2zl0v0cl+EUJW21FsTulAujgoTtve1dPQsWN0C5TL3+sL36v5YN5rZ6I52/Vg7tHF25RiEaBfWKry15959vBeC0jSPmaXrOnvWSSWnqEbiGzHFA8Ykb1FdfzkQneX0Dm5ixM5yvR0Lp5kHdi9KbSFo8YEuy5lSVoZm4jQV2gUkETTZSEY2xF+iWx5tIYafMCq5S6AnunCL52wmMXBaFl6+7m2LYlM2DeqL0epIVoaU3bVlArT5ShtCsvG/aJHqgq8W5XQ8MpXKMGSmacesimqxijJYw7HoXWJyznyKtjdSc/K3FRm+YCC7Nl/XhU65ijGjZSV1oBKb0vObxdHbZrPEnsRdFSreIiBKwWkIBBpqyl7Obz6fPe3TA4dsx+gSY2kTKNCwSmxMz2vuKtXv5Ss4rguWeID2it+T+tms3QYdifpmryKeDBCCr69x8yfbmmvrRd5awoqjzRCu7lt829JpArwLxcsx6M8QYKBVr6K91J9TdbPG/bVqxUJIXVC+zSm1w1vY+oyEgmy3unnesEkrkTyBP2dt93zhZnnH8V4ISgTG3cSwH1gpLGWllEIOn4VvoLb5taOSBpnFhMLbNUWsDUAGsXJropZZk3xipfExbfOr5xcH+hTUMlTq+SIToUGYWDgSQrqT4FullxoC0Cc7hKE/uwV+uvgk/D0hToPr6Bt39kZk8YlYpJGzbWW8rNxcJz6LoWwJYWnR6dDOXcjGJrFIc0JhmVnPlcTUCkiUslLUUJRkacVColSekcXD2MGize35o0SBxbXS4ItWDFOosBmrzVaNtdzmSNmu76Yw2tYIYeKIpaq7ugPp2XuJxOQFn6330HqxifqchwCKmwr0EkqntHUQ6yNaLIXVEfcdbhAlBEmrF0YU/UiuIGv81Hg2+2j1vj7iirBZWBuVQq3NDa4xv0ofk81eaSEmwddKtr3hAs29PM0CC9qPoiRvGtZYAlK946GaZecqovFDKc1VFM99wV911LNRIQ3cxNv2W1DHunUQTA+ExoiKaWzINl7X2NN/DHyUAMtyZhwGI86uxX2C1ty9z2c3FRprPzbUZmPRBJYl+GdJrNLGPhSKn22jBZsw26IHYV0LZa2MiiOR/h1b0P3wNYZ4ulj06ejZQ36Olh3SEYVszhIVWdg+F1a44v7hnoeT0YNscXUUK+6qSGnwlNAuBK3Ulaei1Y4x1OkY4iicELBayDk54jvb39PoOe2ZKsXaBmBFSAzJZse9pQkcSwesUB0lBNMebeNcPD9bvOpSbOqmsQh0iTMF2s2DMwdibbzrMJmWzPSqGdW1oztV7+yXOM+zRfFbncgGT7uLxpWYut80mrAlyah0H1tnQ+mmBJ/PlAYe83vu8sILX7igFrMjwrRWT3qo1RqntWDabmzC+yIqvPn5dmrjNnJftSeo2QnTZp9sUbCGODWh3SwzZ0LE85lkN2HlXNGmuIj572fkrXuyr/a51I0rpFeEr22cAjAJ7upp9rhfoaHSTTsJF5xav15IwnskKB/u73nz8jWffvRJlHtsSnvjH/Y9s10AHW2KayCjBSVqSpYQ72pdCC7ZW9PkC9Q6Ir5lGom1tiy1b+CLqRZxv1Q4woN+k5DWgGmrFbFF5VlFYa/aHtz4h6ChSFtsJlCqKsfTiefPX9jpXDKHWSeCVTb3KtW9cK+ZfqUkUhoJP6WkHsUMQdkJ0rYIU4KVStWVuthncx7oqWXJnf+GqrqZbQ74nKCX0HMl7oIhkY2VoLG44/uBGjoCD78bjuq2M9XXA18RBiEEdDN/6mNp7gk12lAWTutic+2IqstGYet7DsmWUggSNcUuFqiqBOdPfRmF8OpuAvtWRK/xivpW/cjyo+3zVQutSK/zQ8MHa+g0I4O2llJbZbHl476LrhRHCtChhnaHTfrv9pkN+XdqU6z5FkyMIFVTbmLdTGPxOwrvOkq90IfPVaBk/0ZUoepZcxCuKgjFiVtTtkdMgIes2Jj+smUuaKtLoLwVyX/H8V4IShEhTxP3p3uev3jGB0+fUlerehOl8Ho5BJ8AHwSaaFFSVci2iWVISPQejn42RFCjGgrYCKSA7qkRVWk7tdbCssw0h7vHh2rdOL9jZlMsoc6VswVd3QTBSolJ2fjz7C6SivueIqgTNpM1agJFa2E+npiPHsxxAUsDJfa8mhwV6BaRh5wp0Mxf809CX6wpCaUqWhQVtYbxnK1AsNOTyuItIahNaOIVr6uFlhnHHbtpYhoHJGg5fs8REaca6q9LaVJMmyvCUYJ6NZlw4quj4g3qDv9g8PBAG0xSLZ1GhrkoattYxqxIGYbB8s6VTM4jKoNNj3bMr0D0mxHMxYFaQRETruo9wft4x6Y0oNiDSd23TLvfopUiltdc4/5jKSpIVA1SF6iOsqsuUL1NsQyEqNmixrYGvuLvMwRX3GJqFpXTyoIraZQl240qjrhTnyvZok2FRLX1svZIfLRCUbcKkkS/b2x+3R0Se8KogIVWWk/Cf2170ZRMams4SPx1E9fXLjVsmKu1iVapVty5KrW8rXYvj/dDUKbEzeMbDtcHqq7My4lSVk/U7xFh6MivSQYcrQis5tCxwAR5E/UWV2JhgrQz+dh1IyMEFu1qPvDr2pHARms3U6JpsI44m+YSNlSOiKC616ZW54ENjXTe7yVuyVWBV8C5v7tjmdd2/UAmCtzc3LAsK5qif14PQABmwiS1Rblx1oeQKcUK2YKy1hU8nTBJpixzQ+1FVxw3eRHW7Yy6yVUrVGuoJeEgjvGJwIYHlyz7yRH29mRusuEKTrZTI2w+r833hptTYVbpNtgTCNJN9pYvJeZnPT4cOZ9P5Jyo6tXxRd3XZWNctbL6HDYKTlXPKLE6oA3Ru5Asjg7tw+E7re2+e/aOCz+KlyCQ/hwaKX5esNc7YooWBh0Y0thQbDNhHY319ic0tF41Eg7d8pDSimME97Ep4hhD3y/dlG4ueJuOaANUbe+2rgVby0lpa1JDUNWKZp/jzd7ymmJth2r7Ev0ewQWjAZTqyDSn1JFi9VYl8SmN1FKfj0uA/ZXj/RCUwG7a8eTxE+rpwYRkiYK99oluuoYp07V1OM+bg1+8QjZDS2fsENwExZbWYl+JQqWe792sA+MtrutidRnVFlGP5PW6y+p/bwztvmjxCGYSE+h+gaSQCpZJ0vw99nwpFzO5FYqaH6aUwul05nye23CoF8ZIkvj5zz7jPC98/4c/hGw1+Vr+fJw/FvxbqyNMn8hXr16lHDEzrIq0lhJNQ0Mz2aU1q5cu0CSKjXRBocWFtFgNTDIsZW3phnbe6Hnu6CFiK1qI4Jeti+xjFCipj3nnD4pvhoh9uoCKOpDVrJdxzCzLwt3dHafTEZJxRTvSofuKN3PcLuxZN3bf4V4xwUrdoMwmKDfjH/u5hnCP54h5Wds5tRqZP5q9iQi73Y4hj36Oy945Vlrukianm/VtP0yQNS6AhH1C4272qnNClE7L28hzSwvGhGvFLCaNgh2Xwi0UIEJzEQXxXdigQ69RG4U3wBW+J49EOmjyNFeNsfF/4oi5rc0YZ6etqVcH+7rj/RCUIgxJOOxGCnvWeaasi5N5c6czxCRXAlYSqV+Nt+Y54CZIEyIDKY0Nd8UWrylKy9OkbrwbiLM5umtlXWaoYR7GZLs2xhd1CB+/leqUFNNzXtyD2hzlVqBCDG252QpYJo10Wr1NoW1CE5Qz87y0sbPrV/b7PZ988gkvSMIzAAAgAElEQVTf/e4v8et//a/zcJpNs0dbWt0gL2KhdmFni9LeS8lSAq3QbXU3RrKYawtw4OOGC8RsJqObPUZWHxvi7II5eKnZx818c30OXQsa067Jk/BAuUay/3lGUdXaxwLbeGaWiheM8CcOPiSBjOydnBLTtOd0PrMsM8sykwYjzTfnxfaxHRG3ntxxDcUr9riwpAu26r9HqTVDT7UpO3Alol5j08ckAmv+wG5ZeJtaR9m6rDDaWLSYx1smd9Uwj6E/iY/DptalQKtboO2jbwtYAxXZx6L69WpMW/jgCQHp34lDJPRXd6uFcsMdV6oUtRiBaEV0oGj1NsniAcZwaxhH2KpVWfvkWkwBWidXa3FhFfjdP126O+SPhY8SbGE/f/mCx4dr8jixFnfi+sapm8FDe4WZmMltGhc4QvSGVCkborRAS/LCELmvKN7KalFp68gDgJR1hlJIvvnaJu8GQTNHGjxoKANTws7j0uJoJiVaUQMxJFeLmGASMb/MxqxVXZnn2Sry1J7yJgYn+eYHH/Dpxx/xp/7Un+TP/v6f4X/5O3+nadt4Fm1j6Ly88El5kEAkUddiFB61CuGW1maFkLUGjcc3QXtusTJrKbJyjL83psyQsvsLnTqlZuqF0BWMv7guCzntCNNUYGNuhzIzxN+IwiEorDXaBoFtUKV9bLNZXfVoNZRULLXt+uqau9t71vNq91jtrJEv3R4Y2vhX66/qwkw3CiEEmSGWtwNMF8GLhobVfPO1tLUVBIHi6yi7C0OzjWeSbMGy6HzoxUdEkpnB8bzauxIKYTlEMmtq45aSZ/xgyD3I7ZG30awCsb1VKe211LK9nP9Mcr/pFjk2VWbrLn5XD+oUc3MtWB+b87xyf3cPVRlSopalrblaKmtZrfMiwjCOlLJyXk5M49T2R8rZ6giItwr2djGovYeqAaGvOd4LQRlpcud55fM3XzLlA6fTTK1eM6htdGnCTDcQvWuq+JxXonGTMEn3jWhMkF7oN3q1FMecIpu0tMrq2RrZzTfxSK20Tb1BABuftDoMsaW0ItVRJYJqbhHdQESIOCXH0i+DbycilGIpdvP51JCxMVQSu3Hkk08+4dNPP2YcM7/yq9/lf/27/xuLa90gmhvieLv/swUgqNJQloghyUAZVc3XmLOwlnI55I6klUrKownbWlBdrYpQzhjxOYoMB5rYFhq2ohtWuzBvtpAGrqELy46k+5z252mBHf9ZHZWF+R2f3QpSVNntdszrwvlkQltrcD9tl0dnSjPdjLOrTdDZAjPd2FGhKi1AV9bVNqUWDzDKRVQ3BUvDy361SPcGGUZB4yquDNbaDJz2TC4IAwhUX4yB3Hql9Bj7irWmNV+qsQ48qCmJqDt6MeFt2wlh8tlTbkg9ojAkajW3Smk2kgnr8JOHYlu0sL655zgL96eZh+OJ+/sjz5695PTwwOCdA06ne5ZlIYmtxVqV+/sHxmHkcLM3quE4siyruSWmiWEcubq+ZtrtmaaJw2HHbrdnHHfkbP2Svu54LwQlCFeHK54+fcqrL77k9vbWSvjXgup4sQig/x7+tmYqx9/qyTW+UFLKzmML/1EXYFvO2UWeNBszQ3EictASLheltI1Z27m9xVW/nldEsc/hwgSGcWQYBqbBJnMYB68F6FHBlNhNE6JmBo85G0ptpoJxMq+u9vyJX/wFnj55wu3tG5Zl5XA4MN+fUC2uOS3CHRk4m72EYgUvQKneIiHybpvAr8UYBUCSoVUpSmJ0JDMLE5JGHxMYx9H6i+MBCszxTpg/CpIGlIHqPZFsat6KfEsXiD4Bmx8x9o4onWUQKGk7VwgtO6fNO7YOpmlkmRfO5zPH44k8BWIOukkXbP4gJkToeiN4q4o2n20o4WmcUK0Mabp4Fgue+SnVSo2VUhpdSGtlWRbWtbAshbVYW915WSjLimjhV3/lu0y7awzLupaWEF+bcXvriPWuXhxE1XCpWTwD4SO/QBXty+7PjHH3lRTBHxFBkvZiydL3iGw3rwu8++OJh/MDp+U5z1+85sc/+Zwvnz3jD374I+7evEJLMQaFU9oOh4PPhfFwQXny+BHn88kCkClTamntPYZhZBgTh8Oex48f8eGHH3Bz84RvPP2Qadr/1DGC90ZQwuHqiuvrG05XdwxDYl1m90s4JYQQaB29GFetmv+hFbxQy6DBK9pgUDvlbBqd+Jjwtg9ne+hmcZg/Y9PjW0MrVjdX6b4S3AHd/FAmfBOAGnVpnHbs9wd2+4n9YU8eRlIemcYdgzfgWteV0+lMqZXrR49NWFJ59Pgxv/TLv9SE3RYV3Nxc8/QbT/md3/s9/vff+LvcvbmzjeB+MUmZlMXGU7L7erTZpY0jt+V/OiXD+JyWjpiyVSQS97/mPHixZENYKZlpL8A4JnI2BBEk4EDkoM6ZTSYkC6TilStiE+lGWNJrTkbEXv2+2yYtGsHkvl42c2qNx6o/c2kCWFWZxh11LazLynI+U6rzSrXSAloaZeyMO5pTdpTpVcE9KKiiXmvTosXJI7DLYr7ldSms60rxTpmqyrJYc7N1XcD/fng4cj6dOZ/PzPPCw8OJ29tb7h7uOd4fOR2PwMJf/Iv/Av/0n/7T9CBYxcLIToFqGWgb8zm0kheucNlqQn5TZo0NiT6srhhUJ+b5e6G8XTBGbKuVvxPP4BFELLU0id1jWZXXr+/5w8+f8eMff8Ef/PDHlHAblRO7SdiNO4+um2A97BPjcGA+LyzLylpWTsd7BGubO+w8wDhmtFqwTsvK7Ytn3L34ktdf/oT94YanT7/F/nD9U2UBvCeC0jbUyP7qylqlDom1Rq+a4E+JQXehmVLJa9GHQDLNVmzikhj/T7zwgkTDsktEGUfLc3YkJxcro1DLapkmtRKVD6ImY2vO5STgGiE+nMLh6GLaH7i+fsLNzROur2+YdiPjNCEk5rJu6B4mKJdl5bwsiBxJj0aGIVNJPPnGN5imXb9vN5dKLdw8viGNA9//wQ825oQJS/WCFnmgO9wjaNAQZCBtQJLnG6tXGbdxVUfnkV0k2f7hrINaCykJ437i6npPylYdvrigrEUtUBRBHbUmaWUp6A60WM8anKsXm7dPmNg5XOGpCiRHiS4ZDQnH32/RchzdKsX3sCneqI1ZS+H66gqGqZXoClNZVa3NiEgTemaKW1JC9XJ8dbWKU+vifuXZXDelVk7nM/OyMM8zp/OZ+4cHHo4nzqcTx+OJu9eveTg+sK4rDw9Hbt/c8nB3z7oWs1QiQQCr4D/tK69uX/ozOeHH/bcafuFWaMD90DVQcoCQYIB4a5FA8BqujxCycmHJ9cg8RFhGw9/YQs21AZqg8oma01NMB5HSwKuXr/n8xz8hIXz4jccsrkhEV+4fCkNODEOmLCvrsqJlab70sLJO88lcPUkYq5WKMxPTFtowZLLsEFGmcSIPg6HOPw4+SsQ0826353BzzZOrG6bDFQuww1vMhg0Y2qwawmk+SjXju6h4fr9FaUliLTCjjSxbpn43vdutEOZWd8EA3vN57VoYR5GltghnLbVvTvuAC26laoKUuXr0mP3hhjzuUMmcZuNGLrUgCW5fvSblxDhMnObKoycfst8dSNnMtrUob97c9jQsQKVy/eiKaRo4n0/83Gef8smnH/EHP/xDyrKiq/kMa6noWlCdkWTtHdRNZDauDOhmv6TEgLg33zZV9kiv+VZDiARn1QI+eUgcdhOPH10bmt9U8qEqBaM+xX2VWjmvK3unu4g6MZ8wDa32aAs8BJIPMzNKsEU0NXyHTs2xaTGyd6lro400U12VcRzQpNze31vLiCrMxVHn2hXKPHuB37papaHV/KvzPHNerO/Oei4c7x84nk7c3d3zcP/A6XTm/v6e+4cH7o4PzKcjx+OR4+lkG9/XTnbFPg4D0zSBGH1uyFaAJA/mmrG+UIk0WIrtlowPtBxrU9ZgOdDd1RSuEsJoi9fdgusEI+kbYbNLQjiGwgw3SCuP6PSKoOJ0E17chZVbWmIeE9N+x8tXr0mSefL4mtdv3jAOo9Ge1DLGpnFEMV+l8XutJNyQMzlFTKN6xXxjlBQpPiQepByyuTNqhXXh4XzPsP5xEJTA/nDg05/7jm+wPU+/8U3Gw977/ELAhJQsrG/C0qKf1nelm1DBHtLUi5DizvKobgzhHonZ6xtZNgtDHV6W1UykqtFPBUdoUVDYAhGm2Cq1WJBFdXCfX+L2bmGtr8nDiTRMSE6kYWIYJsZpYr/fwe5DvveDH/Dtb3/E1fVH3J4rr48LdTkyn+85Pjznxas7C6gQSEu4vn7EzaMnKMI8Fz799Of44ovnzJIse2ItWI/u4Jh5zyB/zrTZCJGbXqGZ1SqpsQfM35tdCK1WBg/MVRJ0nHVlTInrw8iYfSz9/KWqZf4IlLVwnhfWUjmejlxf7ywqKRAVzePO1P1cAS7DB6yqpGIQJyy94OCFQJBaPSFGrdJ7MXRUS3USOgzDSM4D3//hD/ntf/T77K8foetqZu+ycJpnTqcT9/cPnGZDf6fjkYe7e+bzmYfTA6fziePpxHKamc9nUwLB4IiC06IkD9gkSezGgcM4kpOZpeGjNptdGKeR/X5HksRyXsjZXE1JBu9JPsACx/sT42SUOEN7wRd1t4qjuRaX8ZTZLTFGA+LHBvEZaLqfnsBgiFRR7emFxuF014v7H+ObOHpvkDcwh5jr51sffhPRxPe//wO+9a0bHj15yu3tPZaZljgdHzgd79nv9mZxpETyOqKWsSSM2dwdeXDlrREtL56iXJtCLaqU+cSi68X+f9fx3gjKYdjx5PGHXB0eWRR8GBiGwXxqHm3MlhRlJp5azToxT2EbexEz3chWGMI0rmmlBYkExYYmVekTj5PXo8q5+5pA0XVhOZ3MTzl4UMJNDGuV6htOYa2wamZVOJfEsiaQEerIsxeF+9Nr5hWQAUnG1RNJ7A5XDNOB87Lnt378E7797W/zcDpTV+UwDkha+PIPv+Qf/O6PWEvo+0QS5dGjG24eP6Kq8PLFK968uSfnHXlIVLECEEmgrlZFqTg5OnmBVt0UxSVh45dtIQ6j2erDMNmYkJxAXMjFPpeD2C8JzYJI4erqiqvDjiFB2tCU1mqoLgxhcZqSgFOnzCtQk9JK4EXKqVjBDmh1dKhUMhmtJoSrVo+GmnlZPBCy1pV19d9LZVnCjFVLBFhXpmnPj37yjO/9jf8GkYFlnjnPZ0pZWJaF83xmWcwkVE0u3EwobZvL5ZQYciY5jzQCNrWY+yinbN/Nyfm1lkI5eOBRkjjLwHo/xX4wCo/7Q0kMw8BuN3B9c8PDwwM7TUxVGMeh+6Cbaa1NuLVe7GxN6GhfUluRXPFWwYEgI0gXLoyinZcraoXPYn6QLg+rpyPnZDNmE2yCV1OGajzqTz/9Js9ffMGb23tII+d5ZT4vqChpyJzPM8vdA9NuQlVYlqN3bYwgkZCGRAHqYtleta6IOpfVrSJVRVaLisu8fG28At4jQYlXvMnZEKSZcfnC7wTG1WrVcrrrpP3R6Qe2AEVswaWILDaH86UpsaVhqPbwUUG9EZOyzouh2OILpqib21AKrDWz1MTDDKdFeFgSp1k4LQllRPJASYk35zNvHmbOc6EWGIeJ3e7A6dnCUh9IKTHmPd9//cZIsqsyDJXHjw8c5w95cb7mXC0LI7sAvDrsuTocqHXl2fMXvHlzTxr2ZDKVGYpvLI+VSFkpdTW3h0fEgUYclpSRnMnZfLy2CQzFgFDE7l2Fxp0kWcHeJIUMPHnymEc31+Ts/MuGREy7FyfwT7vM/rAj52QbKcFaC1KyRzjtzmqxNNKq1WpGipX1sgixNALxshZz7i+VUgvH85l5MZL+PM8cPbPpeD57gM8yW3ZXB3bTNed15dmXX/BwPFmBlZw8UANDSkxXB8/2MkFp9LNeISh7tDsEnaoyDOZPDMpazrlRgoZxNNeQnytLuvhM/LSxE69O5Ug6JVJWHj1+xPX1NedlZdYzpRSmKRM5250O5NtAg0vZd0/41oMWFBXJVTZpsmFeY5sk+d8mkDttzFI57b3i0ftSPRLuFxQ3wQO41FoZp4mrm2vu3qy8ePECITEvq9ls1dgSCJS1Ugcsg4oAPW51SurJH6hn1BnYSnloPtWchpZ7LhvmwbuO90ZQNlqOmGM8O8EZXTslp/Ro9rZk/JbjFUUOmmRV23mWyphaIOad90CQ2N3AMN93m9gyL0YITu5UL8q8KDUlljpwf4aHMnB3TtyeM/dr5lwyD6eViqEFFeFhVu7uC8ezBYbGIXGQkaubD6wZGmrmlbiPDWVG+OJugXli1T14JZ79OHG43vH48SPGcaBUePnqDfenEzKMjCmTh4lZzmhZ0VKtOswI83p2FN03VMaUVPKIT5TSAqgbpkBqPcLV8upNNTW/0TgM3FxfW+3K1RkBPvSlWtbE6r7BtSjLXHlz+8A07dA6g3h5u2rIvZRKLWai11JY1oUlkOG8UEqxqPE5XrfK9OtqHL5lXVlm23ApD709BSbob+/PyKs7Uh7ZTyMffvABN+dze57ItzfFMpCTPX92YRddJJMEmus83lDWefAe8yHgkrkzIv2zjS1fXaOdP+woj8gjU1Ku1LUyjgP7ww21CsfjiXX1+UnDhaDu+2W7/6S7TQJ0RAR/61t007VZZC203RGnAR1LYrDn73u0Wf0bU1cx1JeSMJ8WgqlyGCbubu+smLL7nANJB6/56uqKu7s7VkeHgXZTVLfC+jFaBqfLjaawwjOgF/fzruO9EZTdHIgFY2lboYFMW/Sc3hZx2Swqe6sjRnHBFBWbhcymkwjbxWbuum5WKG4zuNliTvyZsiykYUSprKVyd6q8eqic5cD9nHlYMscycFxGjsXMiuNSWdbC4NoupYkpK4tW0jAwTgdSmjjPxr0UgbP7ltbV+mqvy4IeH9gdvySfjzzdGaJ8cr3nV//kr/LZp99hTAPzeeG8rJZEmEfXsJVpl5nnE4MXyRWEyakvYTol6UGClK0johKpgWrZNF6vMoX2TsIuZ7JAzkoehLoa8j8dF47ngpYHarEIPsD3v/9jM2erspaVeV65vbtjTMKrl/fMy2yms5qZ3qPGhVKMl1eKCUlVkJxagMP8U555kRJpGkmijLsdemV6J1gI6u6VFo1XUG9BsT/sPHhTmsDDlUpKiSEPFsVNsek8UQATIDkyQcS+F9ZN41hGIHKzzFoNVOVCuCTvHFnW1YU1Pq8WpU/ZLJplKSArKU3c3NygWjnPZ87zzLquDG6+57fQU2yjRLJK9bF/xFCzAYdI1exmeL9R91drpQSzQBxoyCZdIEWFBTt/lEqLf+M4kXL2Bm+w1pmcB6aJ7rZZF2q1gNeyLOx2E9M0tmIuu93eLDfMRVPXBdQCrlbj1VxF/bkddX69eHp/BGUcLb4guFCL+ibSkhQ1RWFPR3wR5Qt/SPUSS8n+xcTHgpAoahGmyNb8iHyfSvseLqyX+cx8PpPHHVXMpJjXld/7/k/40cvCcPiQvHtKGq6pIixWip2kgs4L9+cHChYYERGG8crb6U6sc+F8f2KtlbUslGLXOj0cWZeFKSmTnvn565U/8a0b9s+ewPfhg/3Ebl35tc9+npvdFT9+9YrTeWGcdlAHmicqCzBTUSefV3KayBgdxpCEoSVELHiahcRA9mILq3bSfF0rKSuDKh9e7cjLmaonHl89pZbE63nh1atX/OY//F1Q8+1Fmthv/P3fdLTopefEAinTmHn28hVCYllXJFkPHknWpVGSIblhymSt7BAvNOIoa4OYLqo0BbFe3LRUzLQ0Z4L7az1aq9m7EFhmUvW1F77SaG2cXIikbIV0c5hwgQxdiBkY7RXNIRS6u2+gFzFiy8wIIrtnAynm4NO+RwSQnD3npVO8VFdKsVJt+8MVKc9oLZxOJ3LOjOPYXVKemxg57SlMYR9PrZDUrJwuTULgx81DlPNruDEEqe/VqkbzsT3a04cbYkVBKo+fPLKun+XAoJV0PTIMI5IsweH29o7729eU+YQILMuJcUiUyRgX1zc3XD/+kCKjdQBdzixlMdBVo8OmCXWTEwYc8luFld8+3htBaeYIBMfLFvSGvgIuKNXlmBdgcrRDaDK2jupNRkb7rAdo4pxBLRFppmGswsgMsYIEwrrOLMsZnVevAKTsdsKnHz/hD37yT/jeDz/nWPaoTMhwYJUMOTMMkyE0EZaiSBrJYqb8Mq+cl9LuNQGlnBEWdmNiN+3Y54HdMLCTlTGf+YXPPmT9yQGAKxHWN7d8/sMf8uEnn/Dq9paXr9+Qs0Vwz4ttHEnWP2hdz+6ZUOMeIsYlW4ttfucNUhUDZZEnn8jNNWyEYkOjK492mQ9uHvH65TO+c2WE+s/vjzykyqtXL3B70WhFwG53xeHK/I+m3W2GLINHrHVs6XOUc3bubEdbUQQ49OoFPIskBTUkqCmQWVglUGoXgOZ/7FaHIeUBxWtM4hFUR0kRUImq8FG9SYRmarvoBV/XzZwWDMmGbw9oPZriMRC6S7ebi5ZrD+1i6pYYli5q5eQMcYvTtNZaGVJimEYO+z3H45HT6YRlIk1tfMWvHymSzeLydf41O/fi50VFfS3uORLQyMOnsVLCAA/zF608ffqUT79jFbBsQDNpGEnjiIpwPJ350fd+n9sXzynlZKR+Va6vbzjPC2mAx994xHj1AbWaiX46n9xnurTqTHVdKMsCzl0Ot95PO/5IQSkie+B/Bnb++b+hqv+2iPwi8OvAh8DfA/6yqs4isgP+GvBngOfAX1LV7/1R19ma0E349fFvzugwzS/4YBtHovk4taltaQsq0IZfKpzK0IRUj34LtIK3of6FqitlXWCdOdfqpkXi57/9mKd/7p/iN/7+7/DjVwu397fcH1+RyJzmhaMKy6KITKgkDvsD19dXHA4jJz1zuxw5r1Y8dMgDY85MU2KaRvI4wLCnkCmSWIfMd37xO7z4J/8QgP0wIMvC7/5fv8X+6QfcH42bl2RA0kiqC/NazIRMBizLuthmSslMRBKDc01tANUwiiNzCVqVj2FOGYpxQ7UqdV25enSA6z2DrhxS5unNaP1phj2k4MvZWB6udub08KBHL59lgqoVUfWARSlO4lbDgIFCqZvgRCwhgeg5Y0gOd9SbcItq9yk2sACO2lIgagCtqDuxIkslqmzbywJkR4+2+ZKb4EgIN7uxnLIjUV9RiQseqI1FmN52XyLSIrnhEonaApaHbdk0tRo30EGxpwsKePHf5PeyrkrOmevra/YuMC3bZ2aaJpJYlF7BmCZiSR7NbN7swW2EuNXYjH3rG0zbFhRP/NrsX58we0Y3fdV4l7v9gW9/9AkzRuzPeYA8UN1FcjqdWU4Ly1y4v3vJqlCXmd00cnW1MwpYsRjHuNuxY8/u+hGIeqUmCwTWWtDiGVjF2BBfd/wsiPIM/HlVvROREfjbIvI/AP8m8B+o6q+LyH8C/BXgP/afL1X1l0XkXwL+PeAv/VEXuQzPhx9Ee7ksZSPIaD8FWlHVZt54AMAi3xaUkNRbqLblKUKUabOrOgJwNCIbcyjMzXVZKcvC3flIksxu2DHUEzeT8iufPWJdv+Bbj6/RmpiXQq3Cm9sj51Ph/ryyLAJzZbdPfPz0KZquuL3f8fr2yN1xcVaSQNoh4zVrHtB04KRCYuEsC3V8xD/9z/xz8Nf/Gtc3N6CV5bTwj3779zjt9pQFSINp42wFF6zG59oyhWyhLKAF8kCS7B4Ix0I1OGfKOEhb1EksYKM5oasFv0pZOR+P3Oyu2A8TkeExjpmaMpqGqO3T50+koaLUUIgrwEixI4SEkZqTVq+I7bgreUKBOh8wzhnro2IVc1yhmTcmfnbEJ63jX+50KZ+HqEof1dktCOMSWWnuG03RqyiEvCHlSr+lOJcqbtVE0ePwI/UdYAIueZZTZ3+IVXl2F1NYXVBmz2KLlE/prQ7AvM3FC0iICNfXN1xfw8PDPff392RxxZwS47hrdUFdjnmlJ7oAVFcQba/W/rv/3f1aYqwEFRfw9lovKmQQPw2wmwauH10zydCU51os60ZSYj9NfPitjzk+nEEy8/GePA2c15XHhxuWdeXh/sjhpmDdCY2epYRFUa18nhqbJY87Cyz+vy2KobaC7/zP0f8p8OeBf9lf/8+BfwcTlH/Rfwf4G8B/KCKi7wq1ba9TpfkKzWzqRQ48wmIa0xeVWS6eLhibUHomhxXGUPM9SEbSgKSBThAzhILnwXaUqk0CV1F3XtvnalXm+YyMJ968fkMtwtNHj9kfJsjK1dXIo+uJV6/PVAbmtfJwX3nz5szxYeFhrcyLUErm1Tnx5ekLisLD8UzOIzLsqClDmhAdyYwmxIZMRdjlld1uR6Xw6Xd/AYBHH38K85mUJt4cT3zx8hZL0rDnymlgyJNFKobK6ggtAh/LMpsGHkaSeoFjINoJhKtCspAlm5ByXisCu2H0kndD8z9VSaTBUYWboULqVJQUSKxNhQVXNKyFtvhQMbqN7UujzrQyeH4PJvuspUCL1GKuhYQ2v6HqZVAlrA3bSCFQTTiq8/yyC9EkXqk+LJMqJEeisbTFLRXcNMeAHYLn2UeRDHcrWVaTmaVbcCCiDewmX3f4Kg+3SATXSrFsoxfPX3B/+8CjJwOSs1G/EmTMv9h3nwcsPVHicDhwdX3Nw8MDx/s7q1pUMIqS+2GbTzW2h4al1u/L87T8GsWtvERr3eA+11IjQNtzz2PPhYfWwFFqJWyMZxwukczh+oqPfu7nmA4Hbl+9Yl1OiBYqhWG/Yy0rpcwM7DdKsSNX8WvV8E16xtfXHT+Tj1IMiv094JeB/wj4v4FXqhpi+A+A7/jv3wF+CKCqq4i8xszzZ2+d868CfxXgW9/+yMfLTSlV8+P4YEMC8V4j7tuw1pjhj6SbJs0U68RX6+SY0DyhyegiEuf14AokitDSrqIYQ1K8fINQUmYphT0SdMkAACAASURBVLQsVpDgYWYggyjDKEitDEk5Lwv3C9weB/7gD+94+fIWGJBpZwhAMumcmfLAeS3UunNajJCnHSIDWhJpBkYll0JCGfOZvCZ26apVm/5n//m/wG/93d/g6ZOn/OPPv+DN8xcU5/PavnQaiiSqmODUYaSsUMVcCcqClpVxtEwoTVbjMGchDeI1PTvKUgRdbWtMw8jV1RVIYkW5nWfS/0Pdu/zalmVnXr8x51pr7/O47xuRkenIdNrOLJdFBwRCogkSPZog6CAa9QfwT9ChVf2SqgF0SnQQiDbVQoiyyxaUVEDZadJOZ4YzIu7znH323mutOUY1xhhz7ZtkRhpZsm7u0I1777n7sfZcc47HN77xDanM+zHsWZTjpHh0B5v0Xd6pgD0snJpHWdGyeGEIPdWtPRJ14QlAvArqIjVZocYNld8eerRKt2WBy8Wh9dB2ex2CDNKfoyTjIgjiwSHcaDu2wTvivEqptUd2OXAOLLinIFZCg9Q/VgM7lhrGVgSpXtiKl7oSfghOaBYcRXh3d+CP/+RP+MEPfo+Xn37K7mrvR19bGP4tTkmcNdWQzIz9zRU3N1esy8r5tLigShp+DVxftuhxO2Xbz/0I5ywIyM4fSCV2P9Mbw2WrNlv8z6zEvfW9G8edHsCUQp0qt09uGaaJ/c0tp/sjbVm4u79DWJBxYDWP6ESUjHv9u7vjyGi8B2XfGMb9DQ2l+bf/N0XkKfA/AH//b/K6X/Oe/wj4RwA/+OHve1AuvtBma7TYQam1f8mUzkq9xx5hwqYQbTF/JbzbYrBaQcsOxmvEHK9ySnQJHb6MnHLjezHADIZIOV0ct7BSkWVhXRbu7g7sxj3jVEJ8wCfi3b0/8OV95e58zVqeUW9usG4s/HvU6Zphf8N8PCHSWFbXcmzLSjGvwLqGYkXL7Ckunro7NuWr8u3f+px6OrEsZ+arib94/Zbj+8XpQRGoOGnaMU5EYhiYUdS5h9ZWb/GrBWTXIzYh6wz+9yp+1BugVaAWztpoFE6rMlQ3XoMVmhWkDj4wDVzgNe5jRpNbZJHr7pGEP8k7jkRsi/is9ijQowvPQgxXYK9h9hLh9qaFDD0j/U7IJT6/h6XhZB2HbP3PFKEzL2J2tWfLKfIgHbv8AD6KdbPijFcB1x7QS8eQxjAq3MU2hXkpke57ddqPuw/FQn2ZxCQKYG5SXn39mq++/IrPvv0Zv/27v8Mnn36L3bSjTEMY81TZ2qLqvNHrskT0Xnny+AlF4f7tG7oxU/sF0d38lfeUCxFi/7n28+mfdUlwd2wyskZAJQRZSvJtDULB0rVKo9haHKcdxsKeiVKesNvtmc8zdTdxPh0ZxoLKeIGxRrbZdVBjm5kXvPJKvunx/6vqbWZvReSfAv8e8FREhogqPwd+Gk/7KfBd4K/E87cneFHnV78vGQFm2lfAmlvE0jpH3AKDKRjNQr49UmONFkLDgmMX6i2tcWrCico6XNOYuue69Gm9OGcSxto/c0GoVUK5ZGSRkbYay2qczzPv37/n6maiyISa8uT2mtPxwKvXA4uMwMmHHJl6YKwr2haWtsb5rbQ1qpTMiAmrClIHsOgcqJVhHJnGEjqqW9oznx44n46U6hHjeXE+wFgnj3qkUVRYV5BaKUyYDVSpZGX0fFxYdaWsixuDmuGod/1UiltHMVohoAxBB+W4nPnr44knuz3FlMe31+x2I0Qvc0Ylg5QtfggHmClnjcr6ZTqtqtSaeGLwC3va6/c5W/3cqBa0ZqPA1lYoEgYqjX/oK3qWEdGQNwG7sTQhyfydR+gfTTW3UsmbhBpFsTCmsgU/PYINOpXj3S4Gku2Y3UyLG01VjzQ1I6qAIwh+JtF5VMtACn4kv9goTPtHWFO++OIVX375mu985zO+81uf8fKTFzx68oToC+2ZfmLwKcVm2lhsZW1H6uitqzlfKAe0RcKHdGOffNSAvHIaomaqG5ldzNjZMogYZGbSpday+p/OIN2eV7+2FltXUnfy+bjzezlMLqVIje9XRlTFmzwIOhAu82aZtQatSoti5W9f9f4EWMJIXgH/IV6g+afAf4xXvv8L4H+Ml/xP8ff/Lf79f/l1+KSQxZd8+IKqQu091EGfaeEBgm+ouMDBEiTVZW3dUJ7XlWVdnFqiYDIi4+jRZwwWSrTbmf/pgaqfjygmWSlYGUAGmol/hhoqynF2EYRxdDL7IMaLp7f8+Ks72vKA6kOIY0SiokpbG0r1uSy7G0oZUKsgI1UqlAEZJ2TaOWF6GBiLcCsrez0hywFpF7qVhwdEhOPhwHw6oa0yDrvYeBXR2gsfOSrAv2hhnIx1WVjOB0pbvaqcld3i41t9zECIiuAYGGXFrNJ04M2ycrKF/W5kKCPj4EUB5MPoLu9vlUoNGo52fI4woFlhjqivZIruz0vjI9BT7KzhxN8uUuw4eCE24eN3pUeFTuNxQ+NkaD+l5eJa05B1RkDu0zSCmibPI8okmHvRRBMgoxRPcyXmt6Qx9f22RbphbnrxrEfhEbFaqaSBtpDAK3grp/+9cH19g64LP/vpF/zkJz/hxScv+L0f/h6fvHzJzc0jak0cUPCRJgE5xTyeD6AExCdO2iUX9GIQSOdR+t97Km3077ZNOwzDH3tsgz7yBQlRQCLbotIREcONbagb9ns8jEPPTlTcBuTeUrWQ+dOegW4FKSJDtY4D/6rH3ySi/Dbw30h3r/z3ZvY/i8i/BP6JiPxXwJ8A/zie/4+B/05E/gx4Dfxnv/YT0hP3kD0nEhq6+gbN0H1dPZJctbGgzGvzPuvFWFeLbg1//aqCMrpsvqiH9QZqqxtIydYrcxJ4RDW9Il4KQ3VsrQ7ZLx4eVA1aYzXlfDyy7iakwDqfGWthEENs8XbLPLihmScIrYxxKBQpjo+VoVKGCeoIZaSUEWREBK5t5RM78czuGddKbde+dqUwn49IKczLmaYrbVXOdmS89jTa3Fp4p5J5pOXjVDw9HsYR1cF7sk2xtqI6erECLg6O7y7BGMQVpKkVM+VkyhiRTbaN5s3tFJjEKKNQJOIFkY4r96JIHKZol+u0LjLKTX6rdd6iJO58QRz21kyiBdFDqIg5vRehSESJ28PJ62nk6VzdTgMKC+Bpoj9vMxgeeQkExJKhGwH5xHNS9Tughi1KzoyG/nn5LoZHpQUjhZV7nzJAFIdSl7OUyjTuWbXx9ddvefv2/+CTly/4/PPf4vPPP+fq5ir2g6HkBM3YkZbXE2RxrFf6E/dPEZNkSSRv2f8tT7MEtFUiW+wr2vdUUrPSsgbkfJnVf+Aw0kp45pnsgMCFa4nOnBbnjJ5d5H7cQja/lksn/E2Pv0nV+/8E/q1f8vM/B/7dX/LzE/Cf/Lr3/fA1sS75v7T4GGuo2jQz1wBcmkd0eNatVFYN8aQg9jZVV8sOvNFUKRG++4GP4Vf9CtrW/+OhSo8OXNLKAeam4HqGeUe9ipcyXMNQYtpecxxLnJ4goatouHqJ1IFSd9i4R8roVJ5aXXWnFiyFKNzMMqnySE58Uu95NhwZZY+Zd8uUYaRMI6fTA7vJ0/9pmliWlYeHxm7a9VxOLNkEYXyiUlWnketyy83VzqXDzjOtLVStwOi0IhOPmIuFiHaukVe505B5ihwKOJGHurHxfyd+89TZ/9oZqz1vzY2bRO8wTLYZyuQ2uv1LCtGHGz7tI0lp6hXvi0gx/uJwT0ScRbpgcF5vAr6ZGQjecSW9BzzpOsEUl7pt5/6aEpFSRLOW7+nfVaNY1CMeihcjzI1OEcfrvc3V9/zWIhhDwdScioP0tbva39Ba42c//Tk/+Yuf8Fuff5vf//t/j88++5YLZUvFMsKPukZTumNJZ6cfnM2M8PSDNepGMgpOpiCRUak5fGFb3AxSYp79h+tt4SZjtbqz7VN3OkYc10uc1wFGJIQw/JocBQgzLsQ9t74/kxD/TY+PpDMnhlvFzY4OI5ppDNqCeZk5z664M6/qLYxDoQ4DpbioLbZGNJiGqfnSBp6ZBZ9MezpYE2fTHZuFodwiTG1GWz21qSU8Y+JKrXE6n1jmmVr3qEEZjBLCuKs5PuaRy+hRSJmg7PCSbPVKX/d4eXA93RFdeGQrn92ceXn7wDg+sMg1s3lnjpaB2xcvePPjO8q0o44jy0m53l1zaGfW+Rwk9sElzCBEf5V1da7bMExc7a949uiW+Xrmr/76Z5iuLqKxzGgBxbU1U8jBsic48EHMos/XIzmykGIB4MtmGGu0lZYyxEFXNhuX1WHnS4pIVIE1NveHqTGSVe7aI1aLA33ZmNBnjgskoTsyaYSsxGY0l8+zSPPDgfaoiK2o5OFl31KEUYstwobubLlexkdu9KJwmNuyk+DT/GW4XS8+zveiv3npaasQFe6LyN4nL7oE3NX1Dl0rP/vpz3jz+jXf++73+MHv/5Dbx48ZJte7dDaJX10a7Lwu05iKakCMxRDiNidJPpygWirmC1h0v1wIrPTv1lPtACAk19P4xWw4183bKlPA2X+Q0WX1aKlDAxZMGUtj6+NGCfYpIUzKr0EHPw5DabDpApp6HGUuzYR4v/d8Xnj75q0rmOMUG1uEUldqnaKjQmhNaWHY1FZXiQltwi6hL2XzjEJP4dLlWLVecU0sRVHHuFTYDQOPHz3i7auvHApYGst5Zr/zoVpDFcYCog1hcK9JjY6SAZMRL4hsqVvwj1EVSsuiljKtjSd24JMnM8+fe/q/2MzKJtx7+8mnPPz4L/jqq9cUKmtbmWrl0fVj5vOpayBKCb8c0bbjW66DeHt9ze31NeOTRxzPR169edNFfl2UOCCDVpB1xUqlz7aWpMFkuuVUkBKaaZnWJcZV4l7VUgP7i4jRrZsbyouKstSMQjbNxw8fWUwJQ5khI5ux7FXeTO/xyrKhXsAKg2jRmtnFoDUpQn59VVKKLvZucFaLiFep80aa9qwoI61u+sJogGtSpm7mRlOJPRGfm9xJIko0tvQ0qS++tqVHRiX3V4voOPDBWoWb68eoKn/6Z3/OT//65/zeD3/It7/zHZ4+ecw4DWHcVoiBcxYR2Uar8XOkXcErPEWsrYWRNPF9s+oZZYmYdEUYUlGB5Ev3bO/iz3ED+/fcjJnQZ7BKfqzfO4t1cF5uFmjSyfr+lMTObfv16x4fhaF0o+V3vqtSx5/b6gd0Xc7c37/n9Zt31GGCUpE6IONIlSnwQy/8rDFgypVGcoSsH54SqVUtFymeQEqN+U0oFPFxpCVeExRfT/GKcPv4EZ9/73v85Y9/7CNOlzNXbd+pNgWN+ciBf5bqnSMxP8aiQyT7dl0vz6lLTkhWYGVqK4/Pd7wEnj3ecdKZUoJoDIAy3dzy/Nuf8S/+1f+KLY1xHJmXM4/2E3J102dmlyq91zWl+asIN/sd1/uJq2lkmAa+/dmnHA73XrBSxYdwDd4Xq4KaQwMlohbJqiyNMriSj1SPPC8LK6nX6D937MLnhedzQslIqhuvfG3NUbHZGLCl0HlYL/HNS0J5/iqZomaa18PGwDWjh7oT3rvIbRZnsmVVekLY8ReTKNht/EKgFwy2bZ784HhtZg8kyHJhaImqcjfuSsd9s8qshjPahSwDZdBh6jJipeTgsLg+1X6v9tMtp4eZP/xnf8zjxz/iBz/4Pr/9/e/y5OmTSHI3KnlqJqSL0gvSe+K23u0Cqj6W16q5pJ5GkwOGmffPb9lcVsYbxVykIrnR3SFIt4bdCWamnBFvpvMUT9g7K0Dblkl+YHA+uDW/9vFxGEoItZ4EuUNBZ10gNvW8Lj4EqK3cv7snmMZucMyxFU/Tt0pir7BFFFJKKEbXQqnRLyLF9ReLbQfRcOI1BKPCU5JxcE1BKZXW4PrmEc+ePefrr77kfD6zrgumDdpCtRlRN3xWLAo2Pr3QLHO0YA2HMERRkOqRcA3pqkHPPJ7vmd7PTMtL5jaz299QujSYc+s++853ePTsGV+//4Kh+hCyeV4Zxj1j3WEtWGnF3B6rG+hpHLzvfD+5kauVx7fXPHv6iK9ev0XNjVopuOaieK9HRbZpjHVwnUtgKANjnaIrqvaWQQkMC7yynSn05dxy6VF36bs41W2gnxXyTLg9c8Nn2a8dkUQH+rfktRvkpEED20GPqN4fF+pUkq15yVwoTs8iozl3rFtkYr390OL+fECuTrk22CKajgoEq1yyK83HSCBeWOyLIBKRbjh2i+G+5ka+lOCtmlOoTHOdygVz0btmxnHitlYeHu75wz/65/zo//1z/t4Pf8D3v/e5dyNZ41IpaL0QYG4aUZtGAVaNpo11mXufuhrMc+Pu/ZGXLxQbPAiQgBL8O6TyUSTIXTlpc0SSAUTfAJmeb9cmAYp2KcWOG4QjSUwzoIKkjBWMar9oTD98fDyGMtKUDO3XmFWShnJZVxdtVXU9vZCx8ldZV6D2zeE3sGMcVvr7Onm1BBDvitoewSV1UCLdEGQolDoi4tW0aT92D6WmHB9cgMK0cTw9MJ+vvRm/wK4a1XcQsMaRGvyQmkZ/cWCGzisPteiG9Z50odjKuNwzzQvv/vrI24fXXH9/ZLj28Zpq4jQzqTx68hTlZ5H+F8QcXzW8170O2g+miKsF7caJ692eq93INDigP42Vx49uefX6DdpWr1IXvCpfqwvBZmulFCgDSgvKlVDHSo37IL2hV7rByxQyO4aAUPTx5w4RZVrSSjK9j6jeC8JO55IIOyQNqohjpJaYo/W0S2oYlrZ1eKVClV+EfAjDgItXkEUKfy/fqhEN+sWQ82n85Dm+qhrpvTVf8yK0gDCKXKSNlmn19hY9YiIvVXqElc0LWKTlRYJb6+8lEUm2PgyvBEtJkdIimmqbgxBjN47sdxMP7+744//9D/n6i5/xe9//HsvSfBRD8iIVHwiXYzY0RCbMtVOXdeU0z97IYMqyLrSlcTrP3N7e8vTpY/b7X8gMSDeyKX7l+itZRY/nmfVz79eejg6wkDQkC7eOWRrNaUUXLI4PDE9ABd/0+GgMpap2WX9X8/Axn+vaKKX0iM1TRy/UNN0Wqo/dDOzN07JMx9QPe1IoNAo+pZ/cjvOUUqhDZRqHDWMLwzVUH6l7uH/H669f8f7tax4Od+i6sDZXMallYhwKQzWEhSIr3kyl/ksbPlg+pwBuY1+TXpeJVjU3nrIsnE/v0XPl7asvefHkJdcvXvR1M4HzsnB/eCAkMENrcMSksKr33kotsEQBQfwQj+PkYxCmCTGNjlHh+uqaaRg5LRcznUPfU/L3WqhSsCyuaAtjU4Klo5k7RVTk3M+kndDMHYRINyQliPBZle+4VYYC0I1UlkUku3nCiFTJNNYt0UUwGzd7oxfl3rnEqhLLNjOfxRPXt6kVGUjr1yDU7qTz7glRUY/PkzCwnWpuSXnawuQ02F77cszXDWMnGkU0lPta+uv74LzLA58RPN72KKY+Jtg8ai3d+IR4iBlX+wl04Odf/AxbG1dXe46HB58SqdqVxX2AnnJuzfUe1QVj1lWZF1ecV5yWJ6bszgPtT3/Ct7/1Cc+fPeHx4xum3d7XuNcHLtYw8MT0FNnl0++TbWuYw8088g1MM6JHXzRvYMkRMr5fXK3LnKCG5h76FY+PwlA6hhjA79qY5zOn04GHw4F5XhiGgWVd/QbE8/KwJWbhTQbq4bpk22HkfEZMwSuggVESs0nCYJZaGcfJhzXtJ8ax9j7c1pyKcLi7581XD7x9/RWvvv457968Yn645/pqx+31NW1ZmPZjGJuGsWB4b7lpo0ikvuYSWH5Osojl0Ut2xJC4kgrNCvfnhcfjnt2zp9g0sCRxIqLb8/nM6Xz2Q2CFVQvTNCAM7l09wUDqiKyNpo2hOIdyGEbHFKPjwUQYRtezZHGct3qehEVlEyDpHc7HFKxtBisAPSR6nbHA5/D0tbMkNdLukj9JHuwGxlsC+hdR3EWW3P/QI44LbFKiI8hFLpKGslHFuhxav26/D6WPIiHDvp5qe6GgBq6c0EEh59j4OW4hIBRprvl3LTJsVttalxlzmtHloSADWH+Pfo4vKvkiWLM+i6ZUgTQa0Pe+GwslIzAJEYhSahCto2hqUfAoRh0HXr9/h759i67K+XSKWfPzpkKE03IsZOZSai7Xyi/d98Fpbnz16o7DYebRzSs+/fQZL1484/HjR0zTyFjGXGZfrwwXBLIQ5kwLi71wGRleRoiQyk25dJmVhCe9eP3m1vQX3+MXHh+FoQScKN0ayzJzfDhwuL/neH/gdJ4Zpgm1FrNRVrqIaxxU97RhOEpuEveYUjIqTEVnn2g3VW95suIYpRPKvRAxlJH9tGMaK/f3B+7ev+dwOHB39473796yzgvvXn/FT//yR1Qaz54+pXzyLc5Pzuxvr5ESIhnSkHWliDptojREK0VcxNfJTA2pLbycb/SyeqSlBWYpvBr27GbjKYXHzz/Brq9Z4lS11mhFmc9nzqdT3HzDUoigeKQmGlJlEbGp+nzo3TjGUPjoXsDTnTrsqOMOmbV3m5i6FJZjg4Tjr4gMpLhxr1SL9PO5UYn8mp1fn+GzYtUPLiXTww3Hw+gccre/Xgzzex/YL/TUHPEUq2Z1OKNFBJr1Tp+UgoOs/ks36I5I+jWqKalhmcIQ+do0+FvhqHTuIFUuDGem1oXEy0wUKYpo6wd5S8Mj46n+vcwyi/LPL5JiFn7Eq8UcmDBKSQMTtS6IkT0SycUUCRy3eLFFbBMbrsMI6p1urRnNhCbFxVLGHZQ1Jsz69YM7+N5aGSm6xAp5L75zoe+PJ+Zz43B/5uuv3/HsxVNexK+6mxzPR3pfNsi2fnGv3OcldhoFpYR4sOS/kbtmK8RuEb5P+wxHjTM7vunx0RhKjdkox6MPjD/c3XF6eOB4mqEUV71Wo5YBra5I7Bs2T19UVXsFdehgd5Ftmp0PhnIj6ZjbQI0WKMyY55nD3QPz+cR8fuAQw41OxyMPD3fcv3+HrgtPY8Kg6co47WitMc8++a9IYayFKkrx/qFw7CEgiybbw6MyNWSQiLpaiCT4zJhTqXz96CV7PfD9s/Lpt57SdjuI6O1hnTFbOZ6OLMuKqjFIATSMVxa9/BBEUEathWHyqHOoAUNYqoYXxkmYdjs4nAACL7QP7le1uH4ch8tpl5fqQBZGKD/f781FRNTTz4Qf0ihJ2D3rBqBXeNPIQo8eujENY5PlAB8hQVxDVEOTlVVcHSo1Gt0AbXBOVmo3MY241sxWoufe0vCJ+KjU5kbGe7hrfw7RteNjjnXrte4wgF/xFmXKFj0HJ9UiGwHPdBxv1d5oltfubyFhuN1YmWmigA5xZldMXFsWwlqLyFe1r9tut4vv7mm3T7lcqebiwU11a9JBqGKYlYA5XPTaObE+YfPuYeG0rLy9O/DVq9d859uf8Pt/8ENPmYtHkdpTal+HFqMctmveHm7zMnyMSvpWpCBZDARE4qGE9Z56LmC4X/b4KAylYbTAJI/HBw6HA4eHA6fDA6fzGRM4nSeGcYdJqrfQU7xLYjGRGmXbWpEwjjntTrzy3VrjePAILPHQZZ5p68K6rByPD6zLkdPDgft377i/e8/pdECs8ezZM26+85JPPv0D3r17h0QaPweYLTh2N6QHRKE4Id49pEAZAiZIn9cXA2Xrrz6Xga93j9npS766f83w1ZEX334Esysyzw8nlmXh7t2DU6mi8unD3yHHxIqZt1AGm3+ohav9xG5XqUP8O27Ga3Eps+vrG96+uwtcMjf9ZjDTU+fhn4aBcRi2dDUNCkYtY/fZnbITHMLc9JdqPmnwJDqKIm6M53lkZRbfM9Mqtqy2G7WLAyUSuLVFoh68xWwhvORndvwvcb+01Xg05gr4IfggskWncY1NretgekECCMpNb1PsBjKMpHiG1HFGu1hK0tFpp4blazM610ydDTbeIGyUo21NNieV0fXlgdzuSSzWB2vsQ9QGisRETQ1uLY5/F8MJ6S2iv9wv5hkN1RkEc2ucDieO5wdUF377d75LGa8jqhd3YhepvEfB4QA/DBrBfOU1gdzOaY21yKdevC4duekGC/2qx0dhKDFYmnKeZx4ejpxOR46nM8fzmfP55EWDphwejkgdqUPK9Qf4fzFVrVbHIVfLnK1hNmPqLZBLYG66rrQYcGXWXGZqXZhPJw4Pd5xOD5weDiynU7D3lVqFq6srPnn+jKv9jjoMXN3eenVRlaUtLOuCARULekX4cI2IiAbSOnaTD+eRSVRv/CAKTs89MvG6POf/uVt4e3rg6osf8du/+ykAX3zxJQ+HB/7iJz/j+HB2gY0GYwyiovnw7aKOA5egJFWB/TgyDnU7GOItcwgMBfa7CQ94vSMjklYPHNxi+KFXV3+vQ2WsW+SXjyQR95bF+OoJx6ZQhySnkZDcSy6y4NeWqXpUoMOk+p8tSfqyfaavbESopRsRUyPFYS0jqYuun3RbXcdRwyCHQc0I0op1e9IPW4c1Pf0sspHnc3yqMzIMaZvBz8i6dwhBT69Vs6AVzQ/RJy4iEJqXiUu6YQwGSGCHBNc0p0Q21X5P0mhqRB9CpupuIDuJPgqg+X1rda9RVGgxztuqR7nJqtVimK40lcDkI6TDyAFMUgYWPfNw8umb+9ElCb0QFIzVy0g+/ljC2bTwJPndL0wiPQSxcHKWziWj+mA0/MYYSmBdGvOysCwLy+y/5mVhXheqCmUHh/s75qWxn65DMCJ5dlvXQ4mbua6rYyvN529rU1pbWNfZRTWWmbWtrMtMW860ZUHXmTbPrOZtTQVjyrNLoQyV58+e8+zpc25uHmOlBLnd31+bG1xE0LaArYgsbO2IF3y4Lonin+OzTzLdrGhLD6qoVO7klr9i4M3pHU95xf2PXAf5z370Z5yPJ7589YbzfKaOV7Er3ImsawvlJd8kiUOtsQOrFMaQorJIeUsc1mkctg2mCfYH9lcHSp2Awdd4XRmlei846t9FiAKGW71L9ZncsKVcZAN5wBPzq6Uf4lVtywAAIABJREFUArfLmeZnZAGScar58SzZd96jpTBEmfaT+GdEx9Fmk6pFl4Y2OZKJ/xUpNGv9ejohyHx/IBY6h5AgrgZftSQrI6IdF/GQ2AIBNwQzIo2dNxb4enoLaNTY6yb22w2PqFf7g4NI9KFbRGBZbVeLUSewOQ6gawB0u2ibmEv8z683sGC0j8XwTM1pR6WG4W1KKYo1AS0XezwjS6euIT63yXDdhI5xRhS+rbF5MS6iRzIKz+d0hTG8WcGi9z33W3YUOWgOZsG08fW5jDR/2eOjMJRmxrz4eNa2rOhqtEVZZ/VZIENFdj7T4+c//znLaWaqU8wojvGqPYCwji/Na3PcrjXWefEBQtoAZW2rA9BsEEXepKFsbWEWBmUYRx49fsLLz77F8299yvXtI87LytycMmGyxqiIGTDOxwfacqbY5BQhWzANhe5A/EVclbtHYOUiLcztLCClMiO8rzvW3Q2qI+vDjwA43R9oNJ9PoyvjIHEePWptlsRgYgxEKAz2KKZ4i2PZoqY4tUzjSBHpk/w6xFEKpQzU0PzTttLaShn2vV0xU8m0gZdprQWg2Ekvkphm2QxYZAdm1gtdHl9vB9wfG2aZBjILLP3zCGJ/yX0SIQaBVPWCYLxjikGYm5iEF6ynrNmuGcUWMgUPI1C2AoQ3BHghTSKN9feOqnq8c1Pts138NfVi3QIf9X5JihSU5llIOMUkU+f7ubjHADjnsZAReURmOQQt1LY8Wtb+DpBbUjIuw0zdoZgb9+KcLqT6vtZmAYsZYj70zEqhtljDltXo6HSyELMxzyg0pA8LOAcZ/xyVrYpOv7d+V7p4STGvxxju1Cw5mC2vHjoDg+6IrAVk8ZsRURpNF5qtrNp8trU2FnWlnmJK08a0GxkG4c3dW+cYEgo1mao090gCIcWWbP9QL1HtOodDcRJuyY0VIH52uoh4qx1SGMaJx0+f8fLTT3n5rW/x+PkzyjCyHk8hylFoePR6fzi4LP3796xLA/aYziADUlegghXncEX7nzVFAk5Ism0J0QNrhtpCGQaaVE4UJhlYZYzn+2Ha73fsr5yXRmgfGq1XLs0sZol495Cg8Zw8uOGaawakwm63YxgGzuu58+YwYxgqQ4gIa9uk7wpeHHN8NfYjG4a82TaPCptZzDX3IlzH8crlYZWeemVaeFn48FLR1turRhjrfN0WxUF262zv7VFRRIi2XbX/KrSoiIYYWThlr7yLZgeN9cKMO4aMFiWMfVwCW4Sb907wMb5WfFKmj3XKSjfhUPNQmzsmJ1oyjjkUTYI253+2MJ4Wxtf3Uetp7BY1J5OybcUwtUiZgwtatshfs8ItdGOTnTVSJBomiELW4HuG6L4y50smxm3a0BqQlAk1SQsE/BAG0zuOuEiv/acZTuQd25KIjMr9V4vP62ujJWxm3JS2UlQR/VsOF/u7eJgZ67oE1udDgpqu6HJGW0MHTxtqqezH0UcOqAPjpUdG5vPhLcjMkapo52uEAGgHvtT7xaNDxBfTPa9FalbKyNX1DU+fvuDZJ5/y8tNv8fTFM4b9SFsbwjm6SAqKMS8zy/HM8fDA3ft30HZIWRHx2ybmYrfE3A4/gO4/sajuUgPbys3gBkgUpDUc4ySiBdDVqFUYy8jT28e8PxxpalipqHl3RlvVNTnbiuqK6BKKSqGcIkIO1Mq1tOLjPq9vrnl//4DYgthMHSemq2uGwWf7ND2yrmdnadYBSfoJAf9L1Holf4JTeiwjM78GiUhJYkNLRvNi3p+coWn0KpeIAjNlNUkuXETlYVw22CH6/INGpJpjGIQusBBG0rqICEjJ9Cx2RXTEdEWgxPs6VajRMUmsX7fXjbLDSFFd8J84hUdKQDhRuSb2o/bv7hiQj6Y1WoMxi4ESpiPJ/YZXNdTfNylAWyTtUZf7p4I1NzGOBTs+Dlv7ZTerdeiRu8bPpVxQbUoKz0TUSowPCYX/ZH0k17WpQXWcu5R0DLnWSk5t9N3UNoxaCOw/DaR2w+pfvdBEfHYU9I6cTNySOmfSUFFWVvRvq3D+d/HIVHltKykM6geouQJPq0hzbtzN/oppGF0Vxy6qxdDxlq1zIdr4UOhUmc2zS1QUJNrl4sUUqex3Vzx6/ISnz1/y9PlLnn3yKTePHzPspn4Ii1SKVMZh5GTC6Xjk3du33N/dczovUCulLpSy0MqChR6kdcHgMOK19uv3Rn7f5xIVjRw72j2oeuUUQLN6gDCNE+O4MM8tDKXSVu9ySmdkulB0ZahOYXK8r2wBmGWS0xgGePrklq+//BLagpbKfD5QHipD3TGOgxvf9cRYYjb4hZHKsqtEZGfd1mWUmXeu+OHMSIg8+OKGKPqdLaKhTIMzfc49RP7cktLj/16qY31qWxEkI9xuhHJj4NGht0haYHZxeM3XJb+IZSptRNXc3yvTcLqJyf9tRcfNGFlE+BHFmuOKCVVcdgnBppJe69h/7rN0HKrR1KOM9s8a309KNB58sE70vWOm6JrV9rzu+D1sbz5Xio+NaKoM5o0M/t4lAcN8qt/dWhHd1sWdQ/WgSB0+yLEfef8sLiPxZU1HlviK/n8LO5s6u2SoE+5KL6CmsC9Blwprz0X/2S99fBSGEugcKbPYPBE8ezBi5IyOsY6MdWK2GfqGTG9IVJeDM9cy3XIv409Meyi9mpmVcxFjHEeurh7x6Mkznr54wdMXL3n89Bnjfu9EXEm/FZqVkcqrrpxOJw539xwPB0wqqjPKjNqM4aMktjzsQ0zED3EQzy2wlThQW5N/gXUlh68BPpYB7RHbUCttOaHNWyWlKNjiDmM+oTGrZ9ztYo5zxEOBU61sfMFaKzc31wxDYTkrOUBebeV8PrKuGkWrFGDwyECK9XVJ/CuxK/AZPCWwvix0lIiEWkRFKXUW8JtnA2F8t9ZU/99l+2E+LtvdOqa1nXa6OlDQfDKVdEOZBsK9R4nrMWukKnh+L89UCi1hn4RiL/qT8yOz4r29Ni4lI+g45Bi01aPcWlySLr+T2OrNAyX05yOzqmmNwwH5oDLHd0UcGjIiSo77q6GU7rgDveCUmKv09Ygz2UHcdIZlc2rhaV1k5MLobDlxGK4wgBFNl0IYTB+R4v4vBIuRQITisyXoPx1PDMzTLu5l7EWxiF8t2x/zi26wg/YMyv/+TY+PxlBm/6inKy5LRlY+A4R3ufdKGVyoQk0jApVts0mW+tPUBool26JlvuIhf2Wc9ux2O6Zx4urmmv3tU548e8Gjp0+4urllGKdQHA/XGlFo4p1qjdP5yP3hPef5iKBRXFswXUFcml6jVSxxFErIQOEbH9Xo2MC5aWqUohRdqaYUVYrNFI6YnoFIO8hgSIMvuXikF0R30+a2VBvL6YQMTrjfRcsm1qIaH3OzM6oz4er6lml/zbweoQzUYWIYdhiuFAP0gfLNgicSOCxxhRIpa6JKpXoE5FXnFFHNKCCoOpGa+6TFBC0vDFgY2W5gYPsZycPM13iE1lqKHySB5aKwEAYvb3EWXvI5HpVEhCtbNJh96pkOFotoWkvHJd0pbqld8iovJeGAzittuom/CElrcuda7cIxJH7bPyizJf+8Un1/ELBDpucJ4aKyLZE4Wd7ASexJXiccXXwDd1pCzmvHJAWRLu6FbH3VsgnSOBsiHaY7y6YrSfEyK5Ge51iJdC7b6lmY2NwPubKGda0EScenYYz9RDoEFsVejY4PMy6I6b/68VEYSjOD5pugUH1AVR0p1TUcpQyEsBdSCxqzepNf1lvDRBjE+VeZUppcLrG4KnoZGMaJWiu7qytubh9x++gxNzePuL19xPWjW66ur6l1dGBdpW/EpEzk0DE1WNaV+4cHDveHMPbRgdFWVg40RtQGkB0lojKL6DFJ4D4i1WkfxkCpBmtDdAnsThmY2XNkJ+8Yy318Lw0MyCOhOuCRbHM5/2auTagxRREJWsRqUAdy9IHbIgGp23c0mMaJ/dUVh4cz1EIdp+AkOjHdZSMKxZbeZ45l+6Ag0shZzxltFVEH9k1oJdLX4geKSDGxTD9la4E0810QWZhrVLoik+NjYQS6MfHP88MaWKM6bSYLDxJMg66sbVvkKxpiE2IUhgyMtkjSTxmI+vG2Ron/HAfTjgUC4cCFgo+i/UD5pq9XZkSOtTvlJ+JBMUcpLIZKqDt67zCxLpDibA3pa2a+6J7AWnTxJAwSn6sl1iBMT+pA+rnzz5YwmuKAj9+bqPAXwfey+D7swwKj6t9bji8wY1MvrpSisf55rf7Z1mLLxoV22CCicsejPBz2n4FLrYVrk8xQL+xMdCOZbFQ5sULR35CIMnlqJVLhoYyhq5jUHTeO09We/dUVd+/e9bQrHaRE6uGQXyU7GUpoHE7TjjKMjNOecX/Fbr9nv7/i6uqam5tb9vtrptHHKWRaHUp/7u1c7SLSCV/w8/nM3fs7DneH6ETwWltOdvObtKMMO1QmvDc9R8XmVReo5qIZ4FMTV6MW/zUUozJzXc7clAO35cROPKIUDaPUV8Dnmq/NueZrS94YgDIM/h1WhHldMZn8EMlGBPd50wM5e+X25pbXr9/FRizU4FCO0x7KQFlXii6xbhLGRyP4dkxrv98zz+d+r7dhWpmuedSRxRwI11bo/Mtt6By9RVKD9uMzvwO07xhk9hpLKOP7d88I5ZIELkjHA1Vzz1wezrDORAocDrqj5GIhHm09qtLEG+O+pPDCNk53S8G3353sX+LaMOvtjkW857rf6WzLMy8C9ZUTvx7TqKC3oMgE2NiNab8e6Xs9/z4MYy8k9QpxzwzceaCZ0W1rIBIJsdGztu4LsuvI/N5GDR3BNTOXtXGez2grwWXwog8bwhbfTzoUoLrVKSwj1jDUWcNQuDCsm2NKabzERb/p8ZEYSomNBRDq2bU6YG0NofWQfBwHXnzyElXjdDii0V2TLYq1VoZhcJrKUKmlMkSP97TbM0w76jAxXt0yTZNTjkphHAYX9i1jECvdC/qYg5gjot6nXbJtpK2cjve8ff2K8/EYDt9FIuqAc7N0oa0HzCqLKrQZGRfEdkiZQEYEF8lgMWotoWzUmEQZtLGTlV1d2dfGvpyZasvGBgfCxY3AGh0bQx05nU5YSOyCeSdSW5yGJJXVhMNp5lG7YizbzJbc6BL8wmU5uwHFWJcz63Jm1B3UkTIODNO1i8jNB8ZppA4eIWRqQ3TMPH701LmruKEw+/CQOF87pFrTAW4WLdLsAtbi+YGJaaax7oBK8hWNHtWRaT6e1HWYBnrKeIkZXu5LkRSg2Iyaak5/rNthMzySCgUdY8MLE8rIZLIbFgh4ofQ/d7UR/6qxSD60rqug+6VFKpksDuuk+S2SjshRsoKdBbQwwnFtjjL4e7gjKj3idAw/AmfCrZfAIaPCmPcSk26wt+IJIOpkc9scIqJ9xEfCbXeHI3W6Zl4FLbv4tOjSylWzLLCxGX8/CGiLarhtv3duaDiU1usaAQVcGstveHwkhjIX1u9sqZU6jJRhRNclDk/pHLj9tOeTTz5lfaaX9ZwYfDVQxspQB+o4MgyTG8vANembeHKl7SyO5r8VTwvT9abaPsVxKs9CQhNlXXn75hVv3nzNuvqIhqIVCy7igDCaC5oq9wzSgBPogdJ2FCakDD7zZ/COmKEUptEhhGmEaRCm0igsFIuZMRdnuuSoW4kRqefVjXik8iUoJFp8jhCrV4GX+cTxWDmfb9kNO6RHzpJnpx/a0/EBDd1BDu8RMXbXxlncaEz7K+rgitmuzlM22lbgXl9+/YbvfvdzwElRkO194SatBObn36u3D+Ke32XBgsLUsShfM1WNNtaMZANXk4IF7l3D2WWs6pESvRWzG0oTatm0Sltql3bDkXF7vk9EuiQ9ZRMiISguxbbMIWlo+Q4aGK1/30wb6R/mBRs3CKtaN1RCfIwaUFDNCNx1DkoYcYlzQecUZ/Fx20MZNXYoi2SBePulbWFqN4y+96oXDcnoLiPw7bnkS9NNWcSS0anl2LyfxzdvDig7VjWunzzFGOiMhDSpEeVnWp2PjB7TGPt1blbbA9Nkmmz/lpeml2/2Sx4fiaG0+DJBu6k+R3sYB9pc+gJ5/FGoMiAEAX2cPBqMAlCp0SlQLjsf4tDEZ0hEIsXM02CisV8SQwmcRpI+s6VFfjM2l30+n1FdQ3U9Ik08unWeZp7qGqNqoVYFWSnFKHVF6sxQhKFUxlqYhih8iMXYBANt3fN+wMgOA56V5WEoLPPJq9GFAO8LpYIMQlsVazPzGe7vjbvra272e4ZxdDw3Dn4WMyYHPbHmLYzrcuJ4UHSdmR92qLxmur7h2dPH0HyuTkYxOdbBDE7nmX/5f/8rv2TcKKo2p46Yd3IQtJhSiKmcucxbhJndQym+4K9VJGgzlqlvRGoSVbzSZyIZ4BG5FOfade3SCyOwKRZZBHWV3je4PanjlWKXlXDtjl3VSAHPjdjkhTAvMgaebmlot+q8xCnOsSTIpm6k1gIm8c83gVWj+m0X6X7ihuJttqtZ36vJBugzodQbABKndQhWwxF790ww+iEmm2aMa5BiSn7t0QBgcS2EgZbwTi626zCb80UL79+fuX/4ktsnt0yPbp1hEFmJb6jICjpXLr5j/3PdYLqgCHkRLkSW7YJqFXsnObK/IYbSH66bGHSVbixrVIN9QZwkPFBqEk41AOkCpWBR+HEv6942aQwE/uaf5YteujhFvH9MrUMyTcONeIvnFg/Vi3h3z1RHduM+qrTxPQBK6apFIolvGkOIekiMas3DazhGOdXig88i2lFTT/nD+1ockCp+6ySxs0j5rvdXTMPAkaBPEQZIKlOdaERRw5qrDt0fePn8GeMo1Ni0ZkrQ2ihFeHT7iKG+isDb19PXRSmirOcj83FkePEUkYJK607P4otUqYw75/5pCjqkAey/Z+9375eKQ3I5uCsOcf57Ro6JS/aUnng/r3ZneOMfKz2CTgedVCDPUBL7lu6QEv/WjPrMwkltFd7sGzdKfI9Myz+kA4GFQMUvpvuhBCTRIhmdUEB39FnY8qh0iEJRFFrUupHrztSS2uNhhuFTBLZCUgYEHjwoCSvkdTgB3aPNGjSuMM6dL7nVCi6BhW5CpUS3EU5X03AmfgJ7V5aZsSwz+6ALFckUehMjdiPXGZ5B27Ttgy3dUd6TjC7z9xJrmphO7qPfAMJ5piWZU5USxZxhog0TuoasVKTHPorAgiC1grgAr0Uq5qlcHhcQlYhWYgm7wVSUlULtKXX33nllRqRxW7GjiCvrFG64ub1lv78KIdN4finBy3QenEhx9ekSMbHU6KyRjnf2jlSxblSFqFNE5EExtqJCUHPEBS0yZSoCz54+5e5wJHEFaxJpuIBovKd/3rwu3D8cmKZHjCFi7AfGI795WanDRB0ntGkY/5E67IPOgqfl88y8zKyqEQUXUoFegKFCC4xS0W6chLKJgZCdKdYjQ6fsuHJTuThQnqJeUI+i+BI7qe8roN/3mqFurG4aRS6MmAdkkc4HrEGsuISjzpnaWTGWTKsxVJxpcNlh9MGGis/22edpYOyD9tueXYnQ4lpc+8U/RZJjatajaMRYLQUvMkjInvTtGooM0czhhm7r/BFKCO/6r+aRfbS/YhoalsY2Z2iLSi9bVLf7E05OKlaiKk8Mh7ItgyulsOqKv7vP4OmG16wLXqQlzhOgwTXOYKPgakJqxf9NJbp7tmwhldk3fVVzip79JhhK89TaDYNv85Lhfp0Qc1Iz6urXNbDFVd27+ERCZagV0Y2rVYp30SRk5I6weKQmkZxkKi6hZC3m/2aBBYr0g6sCu2FkXyp1UW6ub/nsk0959fOv0HXdrr+UIILHRhjSQ5c4xlGRFTphuFycJxV6f6zE3BgVYSgDhSE2QWAsxY2w6UbfeP78GV+/esXxNGMyepoWHtVTtjC86oIe7+/ueXx7DWN8ZhyGFeM8L7y7O3g3jQWuF4dGhurp3KycHo6084Kt7nikOG7YFWiKRVumxwFeY8khauDdI54ipqEyMzTw1wj4+rpZvibuY+KMNdLT7SBvPLsS6tmOPWdm4QanxL5AgseJoNE251SZ0jFNiREKRgh3tK7G4F1VCitxgGPkxzYyNa/BC29ZlPBoKQxAU0qpQL0oongxs4hrCqRhtnAsYZL8wEuJllX/NJ8H4/3q+W5+JR7XOa5be7q8BLex849pHRPM6xPx+d8Wc5LSGWHqrYJl64OTNMbRSlmq46ettd6KWsjhclta3mlQpNHMVPsX+dPesJLaqwbbHpDN+YBF9J/XSnCMxenN3/D4OAxlpkOyeeBSCtM40trCYgrtAisMaaekoZptBtYrkgnebt4yA/J8vkR24usVXQDafGOoR5b5WVILYxX2u5HraccwN2qbuX/zlisqkwht8ANREpcMzNTxQ7a04DJ6kSgQEQOWKJ1zpxip8OI4o/TvKAgyRNtjcS6dD1TOwzvy7PkLjl98QencyZjPYm4EGwo6cj4V7uuRw+HEze4RdQhqBe5s1nXleDyyrmvHxopCW1fqtAu+q0IzHh7O3io4tK3glNdsDlUA0YPtBlfNjcJGVzE+CPICE9O4nw5BRAYQT7qMPrYttUUR3RbHZ0gpsF6EeRLxiEGareQUZqrnf4bevtidme+9Zo22egTax+L2j8h9F8Y5ldabV879wKY8nJJYJBEtb0WtSH/FTUuLnvTsYCmkSAYOVaVjKkGqju/n0V62+23cyPDN/ZJ7BZks8oWTiQUwI5ghmQ0aFJcNLLX0PeOiMW5EE0oivlcLB6gmPWN0oYwIKGzL/vzSLziy+XusTf48tSWTEJaRIxGJx2nHC29e/WY7lr/08VEYygyfpXg3SkY8XsWuFFm6cnF2JMjlZrTNi5Qk5EZ0GJ/g2ERPkrZKXpjD+JNs3kcNGYoT0q+uuNlP3Ox3DE2ZVmUHLF+c+Olf/mUfDWtkFJFGP5LDoLKUjMaIKAOLjp/oICiQw86aJYDvjSnJLHNsSbiwRIG7Vb/xkZre3t5QS3U8EIck3MM2MswyWVkXeDgW3r59z9Pba3bDFIbdD44PktK+4SW+aFtX2jJTd1dM05UfrFJYzI23Q4t+sBxWudBfFNe5tKiSqnmByu9962mm34qwdBaKQ5EtZG9w4oi/KLy6tQSm0SNscKbqfo8vC3OdkycSjQZ4VBl7T+Lg5qHq0zNNKDJixQVdyC6evA4+PIddiTyr1VZ65Jb7MCGGfvhj30MWJnN9tpQxJdksDKIbvpxlZP04WN+H9Pym47n4XspxtIp1Za0ebEicqeTC4sZTm2Y8EOvu4xskmAMaLBLv7679O1AELU4hcjWl7axrEMNber2L9sgsfF06SOuUH00cxYOR7AOPK1Y0WjjzZ78JqTdbVAD4ASg+DKyWgVaqtwKmRyYMShwQjbA7I7oE3UtwrT3ldf3HbaSB9rDF276ty6U5/gPTMPD08ROePXvK4+s91+PIev+Anc5oW/jhv/EHvFuO/LM/+kOkrSChK4in3ok/xdanVgnjoLG5pEegRbaOAu+sCDpHjngVgnzvxabuAzJ1SMuDz8W+3u3YjQP3x9lxx3QCvdk3Z6g4JvTu3Xvunz3hapqCOO1rej6fWZbFB6+VGFpfpOOSVkam/c6/Q3X+qsZpqdnGJ+nIIsLJVEwKpaQ2YWJcod4UjiwPo6dXHuU4aZ4g91k4lxJO4pLzmOnWtm8MsKZUShxaheKf30VWJAtEdmHgU5VqS167welqvdkh4nvNLp9fgnZjBrbht+7kW+zdrICH8TcjCfHuEGMdszMlU9J8RuCVSdPJ/wSo5SIS+6WPzTH7ZW3YHjkD/LJwJH6t0UQDQDPXJEg9zjToue4ePERfvCT9/mJP10Ix31ti4XBwNF5t47/2gOmDy5d+rjO4xbKJecsSsjBEYJ9xE/mGhfEz9Y3/+nf46Dh7ILJZNClVvJe4OagP9FQ7uxdMXcW8ODc8IidQcU6b97n6DathRA3ioPlt1FJYzbmP4BHpgHCz2/Ps0WP204A9PHB69YrbaY9NA02N60eP2F3tOT7ce/QnIfoqyRP0m+D0lIrUTfW6ike9voFSbMHFdjtVKmGJ5ODRtqozEbRld0pE4iIuHnK933P/8AA2Ro9rtBeKFxxIdsDaOOoDb9+95dnjW6bqlClrjWU+05YzZtDwJoCkTemqWFuAEGklogcSO0uSStyPDN7UvXzer6QxpX6hqXThDETDgMXB0YbpgLULRxkAk8AHBrKTrNkizDWruJnKqRfEmlpANcRaK4kjNt2iNSLq7YbLhLU1jy6lS0+QQhoS5M0NcQkj3iL9zfnacV2XXejd0JcYEWzR/ogXH4pEpVvE23bxbCpVkgiSUKbcmSn4vgnHElX0HrERQheahi2MpgUVSLb3yp7xpitDHbE6dJ0FxCPYKp5KWWDPpVi0b3IR6ce+xfF2p8MFfa/DY1G51zw/cbTIDpx0F/T39DQ8LjKj83xefh91lbLfmIjyA7xJxPsvSyXHq1JKZ9X7NvRIS4ODpuHFm7mQBOIakTkyAEnNZO0RisTvW7zhv/f2OHPsMAm7y8ORtz/7a94cjnz3h7/L+eT9vuM0cjz6GxVkK1IYFymyp1ouPpGeN6rbkpXZxGXisAfBfKNP+LsAm8JNScWU/C5e3ZXB2F/vsFeKthWj9O/pBYcQd1CfzLe2lffv37O2hQnvVm7zynyeO2ZZRWji81LEBFqjLSvrPDNMu3heguyJf20RZV+HwMz8sG90jWxV7ARm4rurba2MmRVg/Zb5xvc1cDqWr5cE7mhsh0Qi3GhpREvcc/zeqXoBTc1Cmk26kfW+Y78REhFXVuk1oqn8guo3x52yuuFw/mLs8QxCLQ0YHdawjDzx79N7R3oRYzO8UiSixYiOnS8T+0g3CAJXbbLiEV3ekILrIbRwHIRUcb8+LKr90WQReqAS65Hh9WqtQ0yapG4x10cJJopGBO0ACyOjAAAgAElEQVQjcwVj7Z9R4jzkaBfFhZ1759V2syOat7DHeVZIy5nhpK8t7kzFHPpq8W/5VMU711sXcfnlj4/GUG5YDBt2gRcAVgGVjSoxFIlO7nithJpxpKEUqIF7uc5hbHDJFIYeWeUmkr54ccDNuooLZrTFVSZevnzOn37xL7j5+Q3Do1tGhd0wpfMH8mMiFYjPQEBZI03z51oL1Z68sUENKpIgNu7t1CODKmxRZpo9Va8iYlvqhlHFuLm5CpxxxcgU3tejpAFKzBdY5rMbVa1QYNHG3JatVxaCWA21jF6BV1jOK7VOZG9vrEK/h100Nq65QYdANvGE2PhFLrC0xBj9MFSi6BVRjfNLLyMFLwq40Sn9GlbdfFYBKFFZDn6rSBiMPERqFxzncDwkPjlsa5FFBoxeoIk1UUmxkr5J/bDm/e7pn0bKmOaa7lxyDbj4szXtWHHOyHHnTqj+aBDXN44jGKsaLeJV7RFCRN5xv/xHqbSVCjthCy/2di5/IdTWsY47SnQLJSFeykU/fDiyEmeL3n6q2zmIe97VY9Mgd5ji4owllHBhJPPawlVvcEvskRStIb6fCyV5FvdNj4/HULJVvS+JrO4xK018BGzafaneaubDvTzy6JPyLDANky7QkDSBHOean2lxqLxPO6IWNTRmg7Tm1WJZV5bWuHr6jH/nP/j3+fKrr5CxIkthGMqFB45Uk0iZiOp78PwQpVjCBhENSe2jXCsRLTbr918u+nQtHEF+CU/vYjNKagT6sdvtdtQ6Mq8zKV4qJQyjfHgArHilsqkGTQPO2jivzblp6od6qBOIp+xUAW2orkgzx/3UYxd3DBl99bvmnyVEyht4cKRaneIfYX7+JA+QJLZscQBDEci/V73gWOd9lc0+mzct0Dt1/GdJa7F+XRt+7ZxJ3z+1DqxB1i+1hpHxddQomPiX2woMPuvbjc/GdkjuZLxFhGQZSzsm6mr966r08SUQkEXyKANrDzxbE3fOQlKHIAAissULhpAY30WmcgHv5LWUgLHkojgVsaE7LPNpnpRsrwTU23CdwmP93PVOKQo6NGRtrr7Ui15+pS63SFB9LK6+j8PpgU2PsuNniXj6kga2a2kQwTRHU6y+HyPqzY6qD9L2X/L4iAxl3oQ8KBJRh9NsXMJfIqMN11EgpfebFsQcIylFglwd793TpjQQsYnUMLkgvuKHwqJooRbK2M2QuTE/nCm7HbtHNzz/fM88H/nq8C4GQ0nvzPBD7hw8nxOSCj8lUvN0gHGBNTaAeqEiW67UW5HYYqM0jkkncoORaaT/W0Z/xjjuGKeBw8NDrG11RyO1V+mREspoBYaBc1MmBawxLyvzsnajocuClpFh2NS1Fccql/Mp0if8cKS2YmuUMrgaTeuxix/pwKLTjpoZqAsOa7ShpW4lWDBGIvoSorou5AiFLPDlblI1aqSm65oFiDx8W5qfkEWOotWw0iVSSTSNTGFtaz9SfRKipCH09yzVDUAWLy4r10l4TlbEpQH16whsUxyfD1Te92wBsWRMeNqv4WN8f2/ydv07ZidKRPW5Bh4UlM1BJMfStnuEWMfxvVIfjR2WTAA/Sa4zkM+hU7h01cB088z5OcvCZom2YUvMMbP/+GKC9I63DH76VwGsz1Zv3S70Qk18j7W54S0Xs+ElMtMMoBL7/qbHx2EoI7QRYowl/ncCy7FiZE+z2w6P4LxzQkECmG3NDWvyatPokt57e2TEkVGV5DWI9tC9qbIsjqPY2pjv72kPD+zGkUbj/uGOqQw8urnl9etXZGSS74tlFTU+0IKMXkJA4gJT6b2+milhjWhFgoyfPMqABtim9FmLa2wuKLJFBsrN9RVv37yhtcDeCN4lHrmr+EweKxXqxLkZdVXGIpyPM+sSVdisXqqiayPnoKiuaFPOeuRwfwf6shtqP7AeZWrbfHaNkRiqxoJrHG3jOHTDsNy7kD3TUQPDLLCmX7jHYYEi6cq4I7DubMtje48aQhpdTkwuh4H51Q6SwhQailbVq+a1+ujaxNGKU3y8kWjTa4QMAKLKKhqFL8GrWbE3LfuNvbDXCdXJ54yMwY2DG7sWFJ7ubVJk04L7GHulR64W4iKSdK2LCDwMeleej0i+aesNHmard5xZfEjPXbbikNsdDxxqr8Q0N7K2YccmoWYfnFpBomW3sbQWIstcnN8tCs5sI7+rsa1f0xbdYgRDqCA01Jbe996sobZ2ipDpSh97/CseH4ehJNKw4hFcelyAzJZyBot1L+Apala5m3rkksPMLXPpi7Rn455FdImEkdxAfqc8+IZCG231uR7TUFiWE3UYOd69gypMUl1cFO+icOOQhy65br5BA2X0iE+tn23wymXNFjzBB6pZiwHwcc0lsVZvz2rNb2wK0navHVFLqQWxwvXVtaeNzTdKYY3Nt7X8OT2pUurIeWmUeUWL8XA4sC7LxXEXTB3DbMFrVF0xU9YVjscDrS3AlReMLCv6gLRO07nInTCMtRkl+og9E26dnpOCxphCcwy0q39nm6TqxecEdGMWuKNEhG5Bbt+yFk8HLwZv+a662C90qomZ9oNvliyLkBXrhiNeW4QUwshIsQXWncwFuRRMwdcq6VO11ggAty6zvl38CgJmiLQ7cpNqXgRVNpGHJGinuHNekyWGa9tZ2gjovje6PmcYrAv7GDBIcjNDcYk0aBunEvFovta0aJE+RARepGDFWNcshkmc59XvWxTkkhCvW8zfjWMhCr3x/hZOOIMdy/lbqRMb76DJt7Q12Bu/+vE3NpTiue8fAT81s/9IRH4H+CfAC+CfA/+5mc0isgP+W+DfBl4B/6mZ/fjXvb+JA8PqOVUHpB1+LBQqlbpt6oJ7KQo5rMqHKijNmg8c8uK3U4OC1OuorblKei3hefPztmtBlYrTB6w1rFZOa+P58+fsH91yXlZSVefh/buNGxgpRlKERCQwRE9fa2BH2dLWg0pVJ66LR8olNmPqYa3m42IlD3lcrYXCiqe4yoAgQ/GvWStXNzdcXV+zrHcBXHsBJHvFU7DDx4vC8XT26xthjc0qoqEM46ODLdJPC66lE6aVdT0zz0cqOxJ1a7G6WYjy9W2oqc8bz5hGPLVLhSCz4Nf5VbrRlDBWcSBUs/LsWOIo0p1FiXVS8wqqr5k7nhrdMKqhsqOx10yi156t80Z9n3mhMNXr/aANVGqV3uSTkmyGd3Z5UuQOQiIiVPPDWyUjpIuAOGCDDukqPvcp8VlV1oAAROlzjpIDmil41LM6F7fGGveor1R0DTWquB9tdUPv4xh873bx4sC+q6oXk4LKploCFgruMrpR7/wWOYxQ6R05RVwMRjV00oO+Y9GR5Hhhfh8XXekkfLwBgPRFGgcoo8yMIjPzwDmyyTow4jng91y9OLauyrp887jab66Jf/j4L4H/6+Lv/zXwD83sB8Ab4B/Ez/8B8CZ+/g/jed/46Jx/8zYsMR+/4ByogtTB05RSUYQ1NkXHIs0Ni7WYu2PqIxDwNxV1CfxMhS1uQlONYovEL/y9AfDK56qNZV0ZdhNlGPjir37Gi6fPuHn+lLYbuH76iJff+iSgAU+vncjsCuMOy9XYpE6kLTgIXsKwi7nBzVEBick4pSG6KgIayHRBLQQmVGOtiBMigQUapitXux2Pb29czNhz5y46kClZEpXn+czxeOJwf+B0PPvhMY9KLtV+VBvaFlRTiNenAg51pK2OF9Kdhh+S1lrHKDOl6hFMKf2ANUtjYixNWdVYjcCSB4QBqP1gZyW0txoDZiXGYCThOJxhpN8bBdoLbRopYBm8RbNZ65Hy9v1qT8/DjsRbyIXzyvtdLjDI7d5JSbpU7vt8H9vuMZ5RJB82H6nYjRnaNBgg1nuaezQX7xmDU9xISm6N6HIxbx3MXyoZ0dqm+BRp+1Cr50vmHGMXlY5zF7/+dXtvG6trdp4HXfda63n3Pp9zZjyOZ2q7cZyM41Q0NKG0tRqFtKEVhKrwI0ipKpEfoEjADxBCJRYSEhJ/4AdqkRAlakAVAlqatjSYfhCaVhWouCR1EqdxbI/jrxmPPZ4Zzzn7nLP3+z5r3Tc/rutezzvOfNhtNWeP2Ms6nn323mfv52Ot++O6r/u68+xOeCBjPuNd1rIgh6E5stuGffxD/7ZaEeUoZMQgKEZ7W04jRCtLLQDovtM6RxSE19n1xavaCqM6QXPe9xiB3gP7w5vzKL8lQ2lm7wPwrwD4c/q7AfjDAH5O3/LnAfxr+vhf1d+hr/+oHb/xN/odiW9EMFWV15ivohiiGkKCE0Vhe1ap86HNlwAywtLgmMesGrrAJGI99PAJikd6ZycGdFhX8rmK4Xf8zvfji88+iy//xm/iVltw0hqnGZ5ew253CkDYY+JkIcqS6AgzbfNtkBo9N9CqzYhiBHDofRKZmxmaFc4Ucm5YE5/B146cER0jEIMbzPtg73ox3Lx5E4/duomTkx2q1Ipmp5OI1REd67rHxcU5Hj64j4cPL7DfrzCN5N2oK3nwKkpZUBrnD51eu4Ybt26h7XaMqIStwkhuX7ujj9wGlYavGrtiJLjQgy2KD9cDDoN8Pp8hd6bAIckudcGAs85NVfl1BIg4FcwGtVDhI6OInOFjGX5gZg7VJNIXPrMEOzJak+crKCRkwHrP3+PT0YUcJoUtqDYfQUikosg4YOLT+ZSDRFfu/Ylpi2qm7eQBdN2buU0mRSkk6y9WsNSq6jSUzZTZnx5BozUs2BWT3U1H95qpd85bz2KoK92nY8Oc8IhgVbtZw4KG4hXVDTGYVVgxBENhEu3DJtOkSgSniOe5Hg6IwYyF/l1Z2JFxfKM/06DovPFgV4Qrgu1A9IEYdDosRv7TSb3/NIA/BeCW/v4uAK9GRMarzwF4rz5+L4Av62a6md3V97/0Vr+E8E4gqg7IoHdJI0oCMcPlMNIZzERFSQDaQ1qVLmVpIjgbHGT5rGk0E9RWT3IolVGCjO6dBxjArSefwA985J/HP/z7/w/O7t/DE9/xFBAd5sCynOL84oARUjEymZajyEpicXK0icgkrUmHDsSLSk0NPodHqhmZ1IS2iIhsl60KmSLCDir0FADXTk9x5/ZtBICz+w8IG2SkIfzGh6PDAV/hpWBpBUPtg8TXGN0TQqiECSpba6oVnF7b4bFb13H9dJnEYmTkpjR3KEJbx9aCl5ELkFkCgJJtjEkET2qQ+HpSkAoQJzSUrP0xuyiNOKBgjlIKfOTvE36c716GLnmXzACJJ2cKGJEFn3SuEL3L1ASh1DEIZSh54X6aWCzf+RhdnMPCCZhIXNDm80hcfWKKuXnFfzJBNEwjj6hjtmGHmU2lMzZFgW7MyErZOrQ8NEqFuTKN4bxnyLmGmhxsM9qWbZ2b8VX/5GzagFXk1OxqDWG+aSNk14wHyG7hv11qwWF/jv3FBU6utw1z1fsKFStzvDWNKLZoM4RLKjcUDsELFJSBAcQ64IcV3g+Ivn9T2/SWhtLM/hiAFyPil83sR97q+7/VZWY/BeCnAODO409A231iYfomGhEowhRKEZAXBKMaKHLkEKaC4kCBUwNSL3Igq55lFm4yKiCjZeZtjDYNCBBL8zHgMOwt8OSHn8H3n+7wtc9+DhefP4edLLjROB8b4vYN4UKku8igFRGaCyMGMQjBwxlAa4yDtTmL0qRAmQfUw5jCHcXnTPdFOi6gsIBmm2ef8rXTU/hwrO5KZ88VLWSLH/vix1gRlTShvjb00XVYyxQRKZWzhawZUDiZsNSK05MFN65fw8myMEL0mM8+W1G3koSiFgHx4Y6cG2MRaDqY1ERk9d+ODcrE9rhrCFElNcSBGNKtB1BY3ECJzRkCArlEQBbv0Ihwg73zWezgKxzO9ru89pBBHMNF29nuycBIBfoZ6SAYORW2HhrflfsmopujarMpwI8ypdQoRUkwITuVfOIARboApr03hiNVkDxC70shgFMGL48IjfzR3B0H2M3GvUyMUaIWygCgdH4kJlxoYIspvRZEltfEH1zgQ5V9dKTzhRwLecCOsQ7cPzvDOoC2u8YAQoZ/Sr5FzGJaMiZm95KyQ1NY7z7m7PVQbcHHwBgdo28w0hutbyWi/IMA/riZ/RiAUwC3AfwZAHfMrCmqfB+A5/X9zwN4P4DnzKwBeAws6rxmRcTPAPgZAHjf7/xAoGys+y3WkOcqIDgujIkiCjw0tQQgKYt8eLPqnQ+wZmQpWk0KQ2SbQWSKzqJPj45aC0oUjN7R14HhgNWKEcC7P/gMnnr6d+Du176Gu3e/gbNvfB3oPGAFFeGSOTBMYV6OUj3i1Dll92kEOwsnUIXfjJjsYOcAQ9PcEVlJzih1oNb2mkiiO6MAK0Xahg3Xrt/Aqp9nSm9sVleJa/YOLK1R3s4H+lgZtbWCJI0baBiRvNZw7FrFjRvXsSwa6ardy4IWOXPANngqTw+D1LJ1B6XTMuMhDcc6BlqO2TjCAyG4pMjRjKEoKQ9JpqXCMNmJo2cmA5IOJ5WZoGwCeacyNoas6oosrq2TJG6IaVGkQTp8sCAohzFFLAywyjR5jlzV/SbndHbi2PZzSfAWq0KEe1Kl5Dz1sXoJjs/YBknpaxmD5Ls0haIRNHiQtumk7DjTc5ihOzvJTNiv5dESB3PrQAMQcUTE39qAEYA5qUyz1TTx3SCtyoPv57Ducbg3sOwOqG2RbCGURRqNXyi9tnQOeb74fH0QgnIxWBh9DvT1gHXdo68r1nX/T24oI+KjAD6qF/ojAP7DiPiTZvaXAPw4WPn+SQB/Tf/k5/X3v6+v/2LE8et5nXWMAeX/MiqfKbMoRALjlSihFvokqkpnCqZQXD2wRcbGcnfkz4ciScV3BSz8ADRw2cY4uitvpqF68OAcpV+gnZxgv19x/+4DRHdVWit6DKX0+tmm31MSdCcuOmKgVQkFcLcr0ktBW6Vfw2cqmry6jMBGZzGiLYomCsfVcqgVjYDLKF+/cR1RgOs3r2HZLSjtBOf7Ff3QcXbvDP0wcHqyw8nJgvOLc3SNOa11G2uxv9jj4rAHpCFpMYBdwc2b17A7qaxo6x6nUrsVVIH5+cxD15opacw0Wy+8EBtzo9Pha5PBMuN8d1cBTCktB7UZUkIsKUqQetKM3qehUbQP0zMqm8Pl2ZtKOIbsVNH+s4JeYqarHqwIW8u2RWFmCFilI3IkJzUzB8szJrX4I6UiydshY8DES3UaWO1PTuZG6TnG8ADM6Aq1TFxx1qVDohVmsKoij3rmoUwGx8YWgA2fbaY5MiTpJVlPzHR8OCNhFoh8tjdaDMD1fiPmdVlJznAhDU0C1RcPBlAaRbxrRbO2KSWBhVvo70M0o2QLjOHoMpBjdNKOxkBf1zlVtPeDjPobr38SHuV/BOAvmNl/BuATAH5Wn/9ZAP+DmT0L4BUAP/Gt/TiNSAi2NiXOtdFXpJZtRSmxbF6pKIX0DctUl4g4RgzUyChj+zkIqB9bXk2pG1d6OlcFNrCOFf3igoZ0v8d4+BBnL72EZoad7XB67QaWG9ewXlxoz4iHFq7o1pTikwKzgj97+EBgYLFMI1ntHfLEqrOoKJXpdfI/c7PT6KfIRN6GB+CdVA7lwNhZxentOygnO9y4dROwhouLA87un2N4wTh0LNVw88Z17HYVX3/xBZhVnFy/jps3b+Gpp59CrYbPfOazuHnjFmqteOH5F+DDsdMYYLY/KvFNiHJgptB8ZTRymZ1n5RulIIwGo0QBLB2CImnBFpCxLEqjiVlKuaZVTps8wv0sHIaBbR6Nz64bZsXkWrqiz6zeMrwXrYaxjpwtMfAK7qFhVEKCICKZRGTffoGh1q2vvQ9F0NpvtEzECJnxHkUH0PUBwktTuCOFflVdDydNSkad91Bm4DELRbq/sCw6Jd1KlWFuM2ZB4SKxb1V/Cmqk+nlVNiYooBnGANgAntMsIYoPFbTW3pHIkGjOE0rkns9Iu6pVM+DRsR4OcNvDSkNn+5fOroIJM7FBuOd9KMgZpHX56Eg5xtE71nWFj5VwUzhaq3iz9W0Zyoj4uwD+rj7+LQC/73W+5wLAv/7t/Ny0XEnUTm/MaX0u3IfbymzziHSGLOhQW5Fe0cSbKuqBLUmbcUP65Gwq3MjHiip0KLI66SOAPnBx91VcPDjD4eVXsL93hmKG3bVr+I4PvB/Lk7fxlfN78G+8Al9dB6Ow2A1GNB6sSqewcLhNsnygIDS9MCOnCSHERtuoKvD4GJg9soCmZMypO1taFw5USvbneIE7T9zBrSeewI3bt2FWsb9Y8dUXX8aDBw+x7g+4fnKCWzdPgbiGr3z583j48IDHblzH+973Xnznd30nPvjBD+Ajv/+fw6c/+yweu30Hn//c5/HlL34JfX+Bdlu1PuFvVZGxh2Fd03DR8FsxRmAz/dV/a2pYqjtlRuagUdL7LWXrUPFBUvq6cu4KcwOmYCUdIkCDWWymetaEV7sMMJKAnvlrHBGxWRE3ZSTkNQKJo7tOuyM/l5QlVrRNHVTDfd5ssgOg1lUUIMaKgjY5pHQk87HCdW/JC2Y0qa8NOeYjmKrWjE4xo0OfoytUKDRyUhGYYlehZzF6SGNBHUo6c9tFURbPtV9pvDbCe4mEn3RWCzMuUuP4toizZ9txTsY07Qo+hVqkaOVd7xlAFKXeSXHb4LURR6I2PtQokYZywDuLapmdlbfg/1yKzhymNQR33UQBAvlkcG00AHMOsLHoYzpwVrMDI2CF/pyO2qa3yo2XOJlrw2O+73y5rLTXTNWGYz0cMIrh/ssvY5y9isdu3cKN23cQbcE3HjzEcvsGTtqpSOTalDoNQ4c4q5hjrCgwtDpjF2I/EYx69MZ8YnBA4reb0vgGRFHiPyvKIktDgDUCPQ5oVmFhuH79Oh6/cwfvfs97cOvOnVmpX4fjwcOHePjwIU6XihvXr2F/8QBPPfU0vviF53DYH/DdH/ggnnj8cdy5cRsf/tCH8L0f/jAuzs/xu/+Z78Nf/9j/jmu7BYjOgkJR2W1I2chJ8J+0k97R2iJ4Q5gnlJEOHqgxNsOfrYEbNSiE56XzpKMjFMDnUmfauJH0j5Xaay3EP0tDqbNYy39bZYBjU9DpfcBqY9FOBpDfz0NqTjglZWiSShODjIlSAasN4Su29kQotKro7nLhhE6m3Njsj+dq6SB0wEOFClMhhUUPTNrNpDNpP2/hm2WtiT/bM8pNZxYzKi+WqYHgBKOGASluiY2HqEyADYhaVUjL0/ybvgY8GBQ4L/CIAiayvsd2v5YarHyPrL2mrgLT7t7V/CAxk5zD4wlfqMCTxhLOIKkWDRu0Re/+HdHCyAo2kssl0rht/nNyrGb3SwRFEkqgNKZIPljZHLrpEg5WBbVBIslCdRYnAExMKgsGqq0hLWsfA+36NTz2vqdh6xO4fu0U1x+joXnxhRfx/JefQ+kDOxQcrLNS7gRGe6fhrKpqC4FSNkxjGK4kUpGz+2D1EwFXwQextbgd41u9d+Gb8uhKzbX36OnNsbSGG7du4fZjd3D79h3cuHELy+kJltOO27cfw63bZ1jXFctJw4iBQ+94/M6TePDuA0Z3vPjiS3j3k+/Gfn/A/uEed27dwXlb8NjNm/jw934Izz//FaWWjKSzGk0jRWB/zjUCp/vlQa5WZgNAyFnkSFWo+t8gJzl3jByCIJplt5upZxoxFi/SoNHwVUt8WL3B6Bw3ot/JMSLteMvM6OgI7eC7yQKdgd0+tmGDxNE5KyaNfthQZAmJkowZbQEgjhaJz9sUFolpRBwLSKFyhZobBMG91WRccCRAQvEL8ewi8XbAQGL2EMeYuDAFS7JFFjDNtVG46UyPHUArjSzWIC7dJrZrcvgSyY6kU7kCH/4MZPVa9zvUrZRq9S7aUJizCGYMmpLiZLApxgEZUGp7h6ADwXiKHA2gYAnEEAk6q1HadLpvtC6JoZSVB/G5wpOmqC/5hDb/FBQM78iuB/qPfgSEc0xsPjALg6XAnXHudCqoADrM2qCBBORjRoHuDjvZ4cZjN7FrDbWRNvHg/IDTaye4cbLgwav34CtxnSzMEMBWgamzG6A2pgsQfumKApNjOUafBychhq2nmDiTD5/XPqsOmoceQ90g4KYpLDdgtzTcuXOLw+WvnaLtTtDaDoiKVhoev/UYXv7aC7gYexwQWM8fwsLxxON3cO/+Q3zlq1/FM888g/MHD3HrxnUs105n1feD3/MMvvTcV8ivE7le5Q/kkCzouvWyCao7iyeHsb3vAgL4Bc77LdQh7QMcp2uZslM0OZTajdXF85OFFEQzwgEHWqnMVoJY9xhshbNg90+xqghGkXvBjNwt1LXl3CNFsEHieWYGVJtNC4wGVfWVfsHog2r9pWBXKvoqseU5hpcdQYUokVJgOZHJIsg9oY/VMpljgxN/zQpwNmKkXimM5Ayowg8V/DwcPb9Y89kSkQ2AUxl1tjY9TZtfV1bPbpdJh5PjMN/ee/CZUIehzHb4MKr3FBWEEOxbp3K/z46m7DyKwhZRHwBsQS0B967GjarnAkavCQEAU/jDDDAPNOIx5FRuJ+oN7NOlWEp5bWPaHX8FADL/ZmVsS5FTyixTVkQQk1RLxMT5JoIRk4/12haoSDeN2UoIboLVuyprFd2BdT/Qz85x+MYZzl56GSet4GRXxP8zhfKJrYV0CR01AjbYAdJHx/CB0XmNrPZmMSfQM63xIEVJFTu3IK1nYkn6QAB5LRuOFiDNIorh9No13Hn8Xbhx8zZOTq+jLgvasoO1BaVVnJwuuNif4+6rr+DB/TPsD3usfUUtwOO3b6EfDvj8538LVpiyPvnkk3j8iSdQlwXf/cyH8NTTT2MdiakOHPMCkx6TEXFM8D6wjsN8Fjn6dLa/CTmxGV0JTlF/u6mIUzJ3HoOYZBB6MKVrVOdWicNIRs4RImNQlKMrSgoEVh9Yh3rR3ShgUcXvc8cYpGD1cKwxMCzQc8ql1vCYhH0zGk7e8TEZ2piTVDAAACAASURBVI+eVUyHfRyZVnXmQOm0e/4bn89wtuppzMKA85qCyuWuPmeFwjMt59iOPCeuvU5qUA6IM8NM75O07cECFlV44gjfTaxPER4CzVhIY2topveFo5462SnZsug9YC4HbxtbJJkulpziENyCwBFzjBG/HE0IrimV2H6qGTErzTEjOjq2sW7eaF2aiNIsLxjANFGKIc1RItRaBvWDhig/hpwhw8wigKp0S94yQWGDq3f6qHsB+dChdCCrXzRUHgO9H4A+EPsDZ1cfOi5evYuL+w/R+wX6MnDz1i0sJyfw9VypvKI6pRbcP1sBwwLIDpQxtHlLQYeKHnpvxVgdh4pVdMYVsKarZNUzW9MQGz+QuBUxupvXb+KxW4/j+rVbuHZyDWVZAFsABG7dvo2L8wfYnz9E9JURQDEK1frA6WnDbmnYX5zj5OQUZw8e4vzigFuP3UHd7WAw/It/5I/ir/zcX8b+4kL8UIbwkygtxgKfdwUktlFrIDCQQ5+qIvnptBShEbNSlxASILGN3lIKuXC+pcapn0GuKlSdVVouSxxp0Kpr35nSPj67WqgsbyZZNhHNnYEqUz/IrmckB0VYLt3F2jDGipyvzj2bnS82I8PE2V0k9pKVbQBbZmismutSqXifIhM+eanu+awC3oFWRC1Ti28Fi0cZfZkKMCNRIUW5tRbUfCzKFPI9DEPSxXm+gkWXIVqPga23DkePmHvbDOy6C59ZEub501nO1kU4qPCf32NTmWjez3BxdaHzm8VOvplqZImEZm75NNg4MpCbk3u9dUkiSlBbMo0EMNuxWKVUtwDsNcY0Encwk5BtfBNtJqZMlX7ATGAS9M+uVWJIsjXGf0tUmhHgON/j/tdewt0vPY/nPvlJvPqlL6GfnaHVBltOUa/fwNAEQvYu+4Yhharqec0m74ZQqkWPjkypQ6o2Zqokbq1zErFRVZD/jdiq95YUG7bDaJMAt2/dxvVrN7C0HWppTDUVyS51wegrDvs9QhEO941h7R13791D1Vzz2gpu3rqFw0odyuvXr2N3coLveeZD+Bd+5EeocoSsvHs+9PlOeNF+VNW16VgSUzV109DBZI+yCnzB/vn51oy4LCviPnl5mQa/ZrwCMN/LJPbnTork3HVQ+zIj4oG1r6STKAottkU0OalxVp8nLmrow0mHUWSbkWN2rHBv0mDnvk81IKSjn9F1Qk+F3WhWaRydcIKHUtEBNU4oCQsoBeco84x0+QxFPas2o24dk+MwRdjwUZ1AYVuoxbga0AphDGSAkO81CmBVhj7fODReQ3lbOFo55oFqCJzJyel5uTPjYlF0zIAgVepzr7HVmc8hxTtmbcM2G8LiU4XNKXdvvC5JRJk8uqxackNABy1KsKplhpABcKOoQ4bbJLVy7KepldEjhHUoQBPYm9VU7iSmGFnLMTMU37qEIOMUBjzcX2A9uwsfeyzXT2HXT3A4PcG+Bs7WjtUDI9IAMhdIknExpjOIzQcjoLY4sKUqkv9m04WRapHUJrUyuk8DkFXIOKpYZscCChXN+whpTa6ohxX1JLC0iu4d+8MeF/uHePmVl7E/nAONQgo1YmKD98/u4+H9c7S2YH/oiCg47FccTjtOyikhgwH87u//Z/GJX/kEXnrxJaZhMtKWjdhpDKLDosLne86eYRbk3NSJoveRh4dFIEa7iEzL2GhQC+TcQtG2HGdRKq9nF/PdhtKTI4dWCsY4HuDFIpMpC/GudFkdQA1U1aGOqkaGlDyIUpEaxIeaMTrtEjAmj1fXMqEIZUczsowtktTvNM9Is2/QThxroOo8zUhJQs0lO2cMJg7lUNEto252hGl8BVQ0EXxQrIhmF6jggLehoisL9Ir/dH6JfHFSJL2EH2V+R0ZUjiB0j0AqIkF4O+sEJZ1FzIMqpgCQ/2cFKuiqdlFVBJVlcO1DPqvs8hE74c0DystiKPmkarDOXUBjF96xkXwzpUyiq0jhhfM7Ss1xr8I6PZgyqJ2RL5tWNV9qKq+wnzo3rVMZR448KodsjVrw+NPvxv1mqP44caC64Oyw4t75fawYsIbZMZCYYQZUntEV6BXnCakSq838LjBTb/lC/SvbIhbPCJw/I42/28ZFi56tejRC+3XglbtnOEQF2ikWFOz3F7h39x7u3T3DKy9ToZ0q6Cy0jK5uExjun53h85/7An7rs5/Hu9/9NEYYStlhPQAnu2tAa6jlFM9894fx9Rf+3oQwitK6rGDzdWueSmmSnzNVXzszg8HnmLSUHjmOVnJ1ZqqYJ/Y5aEZrvlfCLaHf7yPgGEoDVeBI7A+YqtimB0xhXmLMBcF0UIY0IrAeDjCwcEB4Bvqvi2Rh08jPAkQaYyuK6DKqDqo+JcRgnHWerIesPlvT/nYJWBQR4GckCmyhu8kvlWlME6JCxOxe4wbXJs3sLWfEA3qWMbuW8tmE921/yzjW0qZIhZUCN7IxfNBQssnAp1iG9w3igM53KWqdlLNgo0UgA82iG50EdxylznkwMjPU/XneZzqSLDaZyO2+jcV4s3UpDCXvg/y7LdhyYShJ+bDtgMhHeAwUL5T6KlV9unQPBvAtKMrgoRJOAz3TIr7YcKCyc4T9pkw3ijDGi8OKe/cf4mR3gnF6jRqV6wEvvXIXF31FXQJtMSw7Q22Jj0be2UyNK8aMNOb9pAG1MtvRAJBikxEuDFv0sKV3AFBLRTVITIEpC4FrEot7BMILHj48x4tfexHnFyvCCtr5KS7ODzg7u4+XXnwFL7/0DSxtp86fxOH43HZLAa4tWJrh6197AV/+8pfxnvFe3H31Pl69ex+jBz78fd+HmzdP8OS7vgPXr51gPRzAaKbNlHoKX1g+F0Z0ZgWtVfha0D1QmyHnqFjBpIghHMM7ijW05QT9cGAqWxyBvqXzkdi2UjBjpBhV6a7uK6vWRYPkAExjmJHhXIFJPs/vmeo5iuDSaDKdjA2zjNhaLlHkBOggiFXH0b8Va+C4eg2mqmQVFGzDynKP5X4IbCr+W0RpJjZFSXiGbIg5LSAyFzk6k2bqFJJQ7/xZBWED03pZUtoYtTuOBiObYYqSxBbJl2IoS+FceDVaBES1EtSUsJsfFQPzKst0TCpKmanTa2sBJcztyMAoq90ZNEWGH4Ji3mpdCkPJKFE3ZJi8qkk/CCA1/DwsEzbebBipMaXCikaF6mBaprL6QzENm3JR3KhZPHCl9vkwNYYhAut6wJeeew4Pz8+BCDx4cB99XdmWJ0AcKFiWHZrlNZOG0oP19qVURYWMNroPYUg8pGEpDOtUEZehDT2XVhN4j9cc4KQCVdBYEpOCcCSSu/sIPP/88zjffxHvevI9+O4eWHY7rKPj7P49fPGLn8P5+T0sragDoiEs0Kqh1QJfDAvH7eH6zVOc3XsVF31FsR0+9anP4P/6e/83vueZ78Ef+kM/jFID1nYYe8pWxVjRStswNADhTKv7GNRjLkxLWys47AfQDFYLhh8m5lQqKVlLbUAA48CvDT37UhaR7yGcmkXAxDNh7NpKXLF7vmGbPMpjsV4oS7GR8I4cngOlNKZ0oeFxM52jgyef1FWgk1OwQnk5BFqphArGdmRzfzpCgTGLUU20JYprkvFhNYNz/RsZoVldNxmT0GZQUDX6wEYgT1xS2gSM3zRDiTgk8eGKDqr5W7PtfsBrZNTOLIlQSyBHnQQoOTiCezORjgbpTtahaDqDA2YdI1TNLobqFeiKTEOiGcIXxetAugzkKGjnfoqOia9GsHhU0whDVCUIsnmLdUkM5YyOZ8oCYPPGWVyQAywoAn83LUrOzzH46DAAPYqKKNgMJs9UPlXtKVNaHygUwkQUGjfilgWGwP5wjq+88DyVwmtR+hPasVtKH2DEweqfuoQMyNnFaSyzy4D/UumnNrQLVuBmzcgyZsdI9n3nM8rENORJEztycQQvDgc8+Nrz+Mard/Hi17+K4StOTq/jsF7gxa+/gP35A+wWUihaVk0j6R7Ec3ptuDh0fOZzz8JOTnF4MfDqK3fx+Wd/C4fzu/jkJz6OL33hU3jq6e/AU089iWunJ9zIIadQlpkYrt1RW6Ox7B3NOEpiaRXeA2s/IJZKANDJHWko2NUKH32O07VMhcegqLHZ7Kgqigg56pqkcgY4FasgmqSBDRHHE2tLFaLeO5a6oB9WtKUhu3XyuWdrX4BR6uQ1akPz+0WJGqG0W1QaKO2OIEapZIpdTLoHT0NMc9CK4TAMY7D4we6YpLrRqbdWBBsArRb0rojJsjoe4hNy/zEwFVoc5JPGUWperHA2lGcBTJtU2NDwImgC0D9E/i+/rdUKP3AMMilihsUqC5KWtYgMZ/iHjIFCBMcVTESWYiWwYQU2jkakhKFkMUljQrKIWgxqEOD9BlTXMCCmoPQbr0tkKI+jpK0wgTSaEy85At9TfUSafqUW4CAfLWUVKOWeeRxA3O1IpEG/QJs/X0YgJQUcgdqq8L8jQz6PPh96W3aIUjW/hp9vArJTxRpKadIzQ1FgaC4N5f1pPKvphSdhVFHAxHXAFGtEMgEKPPr0kCMNqjsQA4/dug73Fc/+5q9Jtgq4du0UN6/teA9KQwsMXjcsi2kQR3HcvfsN/M2/+TGs64B3eu7Hbt/AyckN3Lp9A+96/Dp2Fdhi+SKi99aemUanVhUaAHgMNDOc7grODytW0YNKAvBjUEXIjG8nQApKSaEGY+urCgZDLXluxM8iOCc7KSO0HXQ8tXC3xWCEkQZiREfvHTkhMill+fZL9ZmG8xrS4glHL6GoEVM6b/QBuc+58ynxxX9XFQEhDQ2AUiu6KorNKrHcWmk/PKcBMOKP7IPXOam1cnSEc8+Xwv2f+3fi3kMpq5ztpr1A+AuligdZVFiKSX4vimRDQU3OW6dYjauN0eaZ7AhRuVigK4VnqzubLVrl7KSS8M/QGdG1FWcWWQ00+iriwJRbTWYDI/CZJSSsp0Dpt+ENb7IuhaGcHsg23UPaJHmFBL3BBxtmQGX0lx4s03eqh2RyQH4eT1XhKIkAUvAiSacZbboPhCICDmwybU6ljeJtbl2RxuJHGrbaUOsJ1vWCiUtJrhYwB0xh6z2W1aWGnmleSc3IOA80ib0oSZXSn6S9FHrVjFQzgkrMCubYnez4mwWmN5FwW9uhtaaomaH2EFHeoI2nKKHAcNoadrsFN29ex8X5BYoBy7Kg1YobN27i5NoJdrvdJB3XskxwvpjIzQCAgdoq34u6X8YYCC9obUFzzi6yqCTxa0BUD0Y9yus4umFpJI47wEFe0JC2smFWwvNMkEw6RW0zpaAb/us6ZNUMYx1orTHCN2U+4Es1C1CV29j5FUcYqWmmuPDR0fs0hCUzA/V3W63a15hFmghphwofHIJSTFBE72M+5xngKWK0vLOI6dxdkaJpTxBrzestUzDbDNPwyl5yf5eGiIEY2e3ClsKBwRRZTmcMJWwQziyHhgAKKHQiHzaNK1QAJS6qbWvbgDFXJMlnESjgyOC82FINA0lrC0waS9FDjRzJkg4oqXbimU4X+MbrUhhKADOl2QoYUg5yaGiYJgIqFTTuJ8A71VKsoNQFZueADN4AU96KlmdFRheS3tKGNUwjnW1OcfRg6fUw04nQRk4scxKp2w51WTYpKsu0v4ieAaUDAwUN5JcVRE0ZsE0F/Vh7M5SiTCMZG6m81UIcVNEj1W8SX2B6WJetsEAVIkOr5FJaqai1bV0k6pGdVXgPzqk2jlGNYtidnOLG9VuICCxLQy0FJ6c0knyXvG+zxqjcNT88C2kD7DDS+yiFUUUXZtdKRfSBEkmVyVchgr4yCPZNj1nESS3J7iIg67D30bWvaJxd0a2pPdBFrNYLIpFIKWPmxNlSmIFI7lODSV9A+F1ieIW0tmbSGFV0lmk5zDhLHTY5tMDG9zOA3S/ogmaGulXr7JEfnQbMkNEci3shh5gV3wBn0kQGA6E8SQWfvA9i+44RzISabcUbZnKGHCobMdQiOjT7RnslD7QJLWPoT1jLjOcqGGmXAIo5xvCtXVTPK0r+Hu4JOjQW/sYIuBfK0cmhw6jGXwXTJg83VEizrO77cYIPRqMzOn7jdWkM5QaIp/DFluK6D/TepwK0sq/pPCKYolVhTMPVxhjZu5vyWYEorDyT56gKY6YaSIWZIqeUD1RKKFGydsQUXekw3IES2NXKooSEPTa6Sc5tUcoIQgisMIfET/OgbtQV0zOgKlGlpy+Vvd+ijRSYChFjHoJMB90pM1drgbWcO85UyaTGDatwpU48yDz4ecDMhJmZwdqCWrMqzn+z2zUJ+xbNr6GCd7430rY4Pje34oCx3VBCDy4jE04q1rLbbfegXDgipuJTdxcOrIzDKSGX2pVrP0ynwmXzzxyXMDuGsKVglmn7gHfuk1TJoRHmfiBsUIAsLgraIQSkkxo+mwEARa0mR83wiNcXQK0LxjhsUEBi3fpej2RLdDioY2BYcOid2Gylo2TBpCJi4wbS+Tr3eFppN+T8b4IjedYo5lLVL+0sjyNpd6VUKr4rhC3FJocURqrU1hGDGZFmVmiCJDykNK4gIF/TrEwH20f5OcwzlEUyoEyiPzxUxZdRDc2tV/TvOqORzwNgJmCOsEGOszLMN1uXxlBuK+aLyT9jcN6Fu/827pQHED5QC9DIq0WX42D1eKsEAkCqhkawKyEjvST5AsnlUgSSVxUJEai1ymy2pBWlDLUUNCtYPavWmAfHUYRBkkxN3QRhRGCVF2BxA+4qPnBz1RzZAGxyWhH46uk1/MIv/G9vx0v5p7a+fuOW5rLIIUpYOdWEMv0XUx0JwSiHA6PkLdporXI0McNhFCs66Eka5+G1kqrxW5Eq06+s8yaZfyiyQrDyL/M/SX8m41FLxeiuyIiKjYmHTbI9MMe7FuN41u6deKGKOymWMQb7wKtEZGvZUtV0oB7AOvqM6CLABjLt72OyfBqXAFSJjpmetlpnl1Pm9IGc11QEZwwUY8Q6fBtiNvmh4ZPkTadalXVJvVJG34u9ppmiiD3AWlpWodl8YTojPTd8PvBMjgNACRKX1CmVs5As215L7iWbWqWZ5nOaAM99CbIJyKl88317aQxlvgDa/Czp5zxohY7C9CaPC8LSGPQxLZmiEBvGx66eOgF8S5qFbZ4+0w8F5PzjQ8rViWHo2gLsOdW1l8pqdmsNdSkIDbJSPohU4m6VykFmGdEIHQmKFNdSsDR7DfgcCB7ytBvpfQ34Ez/0o5gite5Sax6zGgrBArVWRXbbxL3WKjKpqaWBPbd8kBFsPk+KfC0VI+tJKGi1atIkZ+yUQodVK7dTVsp5zXQAy7KQUQAJPdgGtwDiGGaqlCTrNDY6oKFon5zXbRREKZrj7T5hFNehSSaCK0KjwKyyhRAeGWzrY8rGqB3STQRc6ayKAsV0vY6x7xMCcP3uHE0By6FiG9k7lHuHl2n88h2X1tD9QOK9DC8DXps7shQyOYYPzVhStAT6kKozkfqOjF49fw0dRirqCH8vqMgizGSBuCtizmPHvTqFO0Q5mlMUj85MKEqnMDP/bTEA7hNuSRyMjyD3enKkde3a8LxuwVj6XcNTZ3KrojdRvProEsg+PtccWNdTxAOm50WtA1i8VQfjZTGUx2n3dsXZa0vsRunyEZdi0isUEdbSYFZJB1HdOrOB0Fwaev/8DZuM/GZ0KS5QCaWw8d+SnqD43YFhksBCkVYrKUqkDbHQRKdm08jVYmi7hrVr1AMKEkouwKSr1LqDK2IoVS2PGWErMimakJfgwCQxi1JSTYbdZMBrgaNuxkkpD499Uj94vV2OqYkAP9PGCFirUtMhFGDFsCwL1t6RpJA5oCsw8TQDNA6BX2q1YcgRAjROmSnsDwcstQlPJUs8cSQDB0ihSMTWMt7UwZnGI8fL6tD54GRAHzzwOWnRAQQ7d+RJYYVQjhO3QZ6iNK6CbmHwKYrRo8upsYjBQl7DGF0HmMaH2UqVY2ME54MhYasVHRznu7Qm42XSWASsUKEqnLxcMUR1+BldTppRQA4sdwjEr1Wk6kkpUnqreU50SGMWljbVHzkLc6W52P4tTI0A21lyMRJIfxJnNbaBcCY2SAibHZ5CZzGjYf7kWdLF7M1XZJ7wRTpDBo7KFhNCYLqIVhoQmjTgpt9bdO6kOvUm61IYysQRzdScI9Y0tR0HnMKKSLAeJRCenSxAtlkhjZoLVwEz7cmdLIGQLFZNTCIwNyIw7drssWWKkUmb/KccKfelZqHIkIaKNLAU79XkOqUzjOCqMMq5NeTpQWM2TAR6ppvTIThUncwznYovQ8Zf2KYBlgKlxt7tPOBsu+MhYCSyiQnzoNDhMJVKIjMjyIEB9lFvD8A9VXBUmAAdXM4gyTTtcDjgZLdsxlMFB0ZeYjxoWuaSh5JlFT07Sos5QvPEBfoDaE0E5iMMOyvPgL0mDYuMmnQwDOmgMGlmOW+7VBUOLFAqDVcfY/ahpxO2/Fg4e+J6NPJVR30T2sj+9Sw00OD4PPAdDoyBpWy4tQEoRxF5jtkdEVI957vMFtbX7OdIbJz3nvsv+9qrREVmB4uq0CGhkZHaApbMEBUmHdMhMTpX0ark3hh6d1lMSxhDEbaLuab9TwI4UxeK+yZkkiru4r1kNfsook6GQ6mFtKMj6IXPPqN7YHqMyUcO4bdvvC6FoWSKnC+UbWrD19nDS6I1Uy0gQXpFCzKE3Vd09edmMWw4yEEUh6sUg9tg25IOvPzoxCALymuqygDwGkUiTypOptACw5VSWNlGwJpOksfRfJDYWvk88SljlT/oH9Ajh0EpaXSfBZIYgRzHm1EU74IKO5HdJqrSkzSPyafLwtbwQcqH2cbqk5BFbSwIpEFGiBtYjrDSjOOGY0XX1xfxMLlBYaT9LI0zwvO0zomC08JAMIg6Q0qRVkWmzEoDxlZsg7kmZuaoCEak2yTD492liHVeuZS3PVNzRo1FBZveB1qrjNIVs0cE2rKQuhViSmjfAAUcUcGP61HFlsaSfez90Df8NLZ9M4tEoKOvhTszUkhCKX2mpUmKTwEIzkMiv9YtR1kMjfC1GUhkxdwNZIo0A3qo0FInvS4Nz+g+6TmG5EvaltrDFBUHmoa7ZTqc9YWpSRAZmQcwcfuQw4MaRgqjTnWtuWg+I3LPg5i0mko8lHFlVikDns0GubLOYQCasVsue7sDjiiknr3ZuiSGkp7BnQer93XKXc0m/QnoZnKVYyKCxOBDx/7igP26zlY/WlFuVFZSyOWCGRyDL98bIIoOf4NoI+n5QnywsZFoQz2piaJ7pRFk5KGNja06mFw4V+QEM9TWkPNuIgKePMkYqEaCOLNSQ/fC1MEcYR2OgWIVS1nQB/veKTUHpXk0l6U0YLZjhqb7qVNBIgcuUu9SK6o1OqMYbCHMaDrYUtYUYRnAdrBakLqYxOoyWpRhsQoHBXlLCayj80BBzmfQMSp7Iz1FCu118mmZBaSxAgx9HchplMViFipme56iLECGJB1BFX0mqBDl+XPl8NjVwjlN3snRhBH09869x6p5CucqQgQN1dCMh4hCGEiZSEb5YY5VqWWtZeKerudVjJzdmvaEFUnuehGn2zFIHVvGk9nN0OAwsj8cKAXWGrBymFaoiKNHjpRXi6OfRS6yzZbYAhrRpP8Q3kzeMotQtW4skTS0FWWqHfmImQ5RWFgV6+B8Kjr5wXedbZhiQhjENonAcFPpTY53jqygATbLUTBiZ4Qi0/TGVjZIIJG8b2FdEkO5pZMAH87obKeymmkGH1gPZ7gefGAjCBrvDwfcv38f5/sDdienqHUBkYyMRp2qNIC8nFJUkErETsQ0xNTPGwrZi+llKiI0CSp4KRufMwYlwLA15s/oUalk3icjEKrE9M50sXt6/+ROSl4N3Lzd1cIoakQPzNQz+ZEsKgUNWrbTJa4z4jWzYeAGqza9MJ83q6FjrDyEwBY9g8LJrdV5sArbXqQWA3bg8BWSzoWBqghsDgVDpnjZkSQKh8kglwoLYKxdlC7AahHpO2jEVGYqhXugmrES6rwG9kzTsAOB6mV2Yx0Oew4zK5WHVSkkB00xvTQdSozNsbHJK9+hjHNCJxk9JW5jQM7+SSoYFJH1yGoxK8Thmf4lGrD93k2TgEZwdceqYtzwxGxt4suuyNNFl+JkSrXOlgo2u+rFbrk4/5PPLfVIlV0EKJrN/EEpsZwRM5cqe6VZRzLOHCqXNs/UiqksIejcs8WaUShl41hw7DPrAlSFN7Ut6jl6abAY0+CFun+yyWM6g4jZ+x8RGJMBI+K5pTDHa7OQb16XxlCOsWoQl6MtDSexQ+9D5G1oQ7EYE7pZVxR66APn53vcv38fhwOnHNqJwWpjhAIeaMQRRQQZrkutLmyOtZ28L+Egm7dVMuupSQhGSyCROXrAh7CAnOCEbfNW4TQAfluKWC2hF/5cks1d6JaBbZAawGby2zPoKpphTmKx6UtFPycs0xeoKwSzS4dMAT2VyDY/I88RNHDbULAjZRgUpaGbCo+hwExpjYoO4tIAglV8gMWlQixpptcJ5cfA0nbwcKzrKnkxksbJ8DG0wued3TO1mVKoMvGyMQKhSj+fEWBuqKiq1opShDyoLmdU0VqDu35/BbJyS/5fWpZMysvsPYelMQAOhxW7ZWEWUwx97TCr2FXOoA9FfluaTuNDupJP3DVneLtgAo9BvLCwIJEFJAcj1yxgJGPBxcNJQncrimSd1eNa2VZZVCOYle90+AEWR49afqf2pjES7EhTr6/3jtLqNMIpXEHHzYfugqqYew1kywAFagpxehODJZTlRHmNAQUY2WpDUkwjtqIkItS9JKBoGun5r5UNAHb02ddbl8RQ0qOM0VUlBJZFKjE5mCjB+4ijqKtgoODi4oD7Z/dx/vCcEcduwGtHhKlFLx9EqsWUWTgacfSQFDl4cGREKP3eLjPSGRFchjAOGKIP7M/3OFysnP0BRowpZVWK8KVMFZ5ZdAAAEaNJREFU3QCw8qwIQxid1cpsIgZycDwnU5LQzF/akeRdHgYeNHZ1qXo6VhpxSeRz3wwZPsNhDPSDKwoFclcPyV41/ZuijGUoRTSNnS0oKKFKdRoj5y71IC7pISXrUshZxeZwMI2Tz+dO+IW/vNQGdFfahJmCm1U09dNjfj6J3eLnDR66w9qx2y2KlOSoqI5A/mNh4apHRqEB80zlpVgUatMTq5k/S6FY4WGEJQdXO8J53b0Lg/QAlW1YMCvY2iEnPUyR7OGIExoWOPS9IldmL1M8t2juDDi/xwyAKs1bBOXcdyBOb3JoFcbIPsTbBVQQpHNrS51OBGYozVDUQk36kGTVPGANwmF9RuMZH8/ijQHeR7p88iXBlHjO3Iktda61YfQ0qOJSGARTALCyOYNIxy1OrGhS1Y5qGIKDoN+ZFCYPnw0bEe8AQxlBikSGwIaGsAIrASuraFvbg4R3hFf4OOCwP+Di/AIXD88xDgdYKVj7AWUwDS2loRQSdKstMrAiF0d2OIewioCpTTLb8MIKsitjZO+wWgq5NwZGrOj7Ay7OH6Af9myP5OlGVvCpUsa/F/HyMgsCWP2rTXScxpduGcWGChjCupjWJOjNWMxlZDqUQtZF7Wimwo9Sj7FqQ8d0PqIHy2HoiRiUdir1VMTHPuiiuepKW+W9UaR2AxqbWnU/paGAFBnOYBceqZ9XrcJccmVQ9mDGHmhlBD6YQjKzcD24Ao+CQ6bIAFIXkupLglaMw7BC0W0qOiFCEWnDRV/pyAxUoCqFfD1T2iuaT4os0ARkhpIklqysOioMliN3RWf3MdAKhHcreirCEuXAa6VOI1wKP6VhjmOFzkaIIgWFgEHaUynkskaYJnXGhmmFCpWqBheAEXjuf6XiqbBO6AhKazenxDTa4J3Gku2HEBMtfw+2QhUAuAnvdg2/Cxky/tqs4hcFBUSuSHJPy+vz949ZAIvEuANodVHBa8CL2mLNZjQb+j/TMzNFoNC9z3t8g3UpDCWmMYAwLUhZG6pCM32IEUjueYDFgYfn57j/4AHOL87hGrfZ1hV1t0iQgCmPgSNuq0lL0BQ1mpK+gNLbMg0zxzDwa6a0e5SiXcYDGxI8OFw8xMX5OXysMpLpUYuCD1WNR3J8tJlKwYBhHYOGRB6Yfl8KRjIskdinZcQwgErJuTFChTA9t2IqtmAjchce2VrZTsle+DKjuxxUZYI2Qt48wCo52wSZUhWIs1mTsIzJ+TO1umWFNwworcHGiuyM8i5Iw3W/iuTcmP6X2sD56z6jgWLEGslHdCntsBiVKug5+z0x0fXQabBDr8zoKJPc3HunmImlc2SFuAAzHU9HUKuwQxPe6izw1crPWYACuUrFuU/JH0wseziQ+pE0QpwCabWgRCpBcrRGrcoaos8CYqpOjSHdg7DpNNOZ1Sp61RhYhHXmrJ4UBE7s+TiSOqYthaJkZj6F2a/MKmKLHJPjyABkIGXY+DVsg8ASC0jjWZMV8lph4ISF5EZFESqYDww44lZnQG86b9juU40I2fOd8XtG2n5UM8h7fLN1KQxlJNojNZNM5fhZ07B6zK+FD4y+Yn9xgQf37+P84UPKYQkDW9cV9XBACDMzI8+QvN7CxMMDocooPavMUqS2HYCRlVzI8TivJakr7hjrAX1/gb4/YIwuoF8pUEYbotr0BO4znXWlvkmUdWGgwn+qPCt7q4XrKPqbhjAGDOwxJ+7kAsYL09iwbNkgZHAURSUAX2GTx1rV9ZJYZBhmZEhoLjHSMukidnQyDn2gtkxbGbWPtaOEZrQIQDXfThspLdzkw4n11qBcE9NqiTw4WMkHpjPix4EUFGG6STxNfkUZS5Asndhy7q0xkMEZebtlRim1NaxSUWdEiG3aHzINdariGx1NmFTBpc6Q3Nl8lgFjlDiIbTNRkAVJmpJ6+Znd+sTI6YxEfyllVpb5DQUtjONPBrG6NCLFCsrOsB4OE1aI+UbjKOoFMuc2YBYSoZbDdJx0WmB3m75GxnYaWp7pKkcBNZLklAEE0GOQhaEIvVQ1FWho2MTnFXZm4UfeRfsoJpUvoGo5YmLGRVnURq3SYxb2mfPGM3B9s3UpDCWg5KUUVUgNpQbgA14U2SFTngDcsR72eHj/DA/O7uLi4QN47zSiEei2x1gbSmkYtgKQEgoMw5gWpcekmKdoMBjSL6Q+nvsBZqkGlBwzHtwYHWMd8HWFr3u9KBoSHHvAtLljHHk2IPOOWPdSutGBzqqlpZAF9GLT7CafTa2FSaI2Q2sVpSj9szwERSkHN+vwwFhXfn/Z+mxr5QVYAXbLDj5WRLjUybOTJiafLXmkx5s4TMIjo6NZY9Qm8nUfHQ5nMSUUlaawAQywirZUmPQfaRUzUhDUHzbFDQBFgPk9KAh0ZBEtQpqfqmzzUhVBTR6qopFBtZqsyrOXsaNImceH2hh5EZz/Mhjpcu42nVwXXmm1sTMqIzLk9So1nffD6ndV2TodQgBqjuj6naItyfCbFbRacOjrzEwYYREKoCNvmIXD4ZSvawvWtU9GzAwmQ9R+S4qPunp6l5GpiUwh8fzkwc7xGz5Et9L7kMJ/bnZ+mMxgZT1p+SOmc4vEfF0XGCEKZtU7JN7s5mgm1skMbtL9ySj6UKTr2/sfQfGWsp25rHu82bokhtKEMWULDXmAU3AXQD6AMToOhws8fHCG+2d3cTi/kLCnQHg4xrrCe8eoHWYH/XxFd0X4Vg0gu0nyrHqGjj5xmj44SGkEO2ACgPuKWA+sFoYpxmP6lKmIYkMa3Ow4yKlzSjGys6YEDWwIU1F8DVf1vPdVhs7m5jOo8GEFwKbKDYg2lAUWHUDLgWyOmbbS3qo4o06JTMOzf7mHMEJAtJCkgoQiXx7ISHBdvMYxBqIMlNLkE0IFqy0anBsWTFlJPdLB0ejfdDR5CDIKZtGNxSIaeNJYItip07uENiroKNIAGeZ0PmK9Y+LFhtSwzC23EePlajRVEUrhPbcm37gMD7ub+LzH2GhireZ+js0oiP0QasEdczwG0HvwTCiiDR+w2hTB8b2zU8WAVLbSDuse6iAKjN4R69BeqZiFJ93fGCtKYaEsydoGCo6svc8uoBDvF2DmUcVsMBMFKgDAZ8vvGFngYWdPsS2K5T3azJJYTCpH/E29E/XtGwJb7zH5mSZoKVN8wAShbO/FFAy4+yzy5flTrr41+bzJuiSGEjqYAEJFGNF1akDGiB659wPOHz7A/Xuv4sHZGQ59Ff+wiABLQ3HYH2CVU/5KWaheXcqUfZ9t20Tr1RYHAMR2BkRLCmIi4YlJUTuyFvYGG5rStoCNwNIkLZFpSmH6mP29k9yrn1Uqo7BU2W5SEh99SErNZ780oGPmKuggNOUutgNtaXgSz0p+pk/Ce8u+6kwNBeoXCWUcRhcksPXHFmSaQ6A8dQat6ncX8jKjFCB7mDMasMavm4QzEgdTJJxRhEdIXDmjyCMMjSEIJbFmGsX7Hz7Qok5jBwdaMVzsD4iRAiBqGLCKZVkw1o4RQ7it3FcAARoXZgE+cWR2T9Fh+HBwLPpg15SRpwhho72vWKOKx8mV0mzrunIWfFHqrj1LyEQUKTkqBCGDhHFKjh8W99Zy8ijoEMfIrqwCoHMuUDG4GZ16mY9tPmOmxIZ1HdjtKsaI2X6aQhRjMJPyJKAXbLlq0R4am0BFaTYjfbrimG2NIYOXYUQ+e8IM8RqHGkWVerBYla3k2coJ3yAXpLOWEzg+C5GhuGAPfh8j9DSS8RbM80thKAWREMxPEqlLwAIBswFOXew4rCvu37+Pe/fOcHF+oYdlNEiDkVKFofcVZT3IczQJOxiGWv9ap7ADKhBl0IAWI9k1SGdwdQ54HkoPRBQsrWDZ0SMHVgDEziIwixRD6VzJdNEdNTcByix4yGoCg3QmAyOB2sr8nXQgNBylZQV1JWk9N+PkZW5ReDFNplSFPiuUtRbURuyU15AG2HX4MA9FU191qPvCRHiO2TWh9LXQw4t2OMnzfXUEOmprigxNxY6KrOZHGlT3CS0U3VOOLTDRmAjBjG2+taWTYSWZUUNHbaLOBg971bwdRMB759C0vsp5QAW2TCX5zlYJMDer8/lgwg6G3U6wjDAw9ywcAOt6QLETIFM/y/8Gtqp9Ur/GjPRLKYjuqItw20GVfgY/Dm9swuidqELRtbmKn+u6IhW0WPAUNBM+HV0oOi2FDmRZKtZ9x7r2zbgEK9oMzopS2yR4J1eEc3Cy+MPim1H9KEO0dKjqADJxmUOGkZ0KGT3SEMRr+rQ39sLUwkznORxYks1BeIxp++Zg836yu284sQqT4IcOpPbNm9iot+IPvR3LzM4AfPpRX8c/xnoSwEuP+iK+zXV1zW/feide9/+fr/k7I+Ldr/eFSxFRAvh0RPzeR30R3+4ys196p1331TW/feudeN1X1/z6683JQ1fral2tq3W1rgzl1bpaV+tqvdW6LIbyZx71BfxjrnfidV9d89u33onXfXXNr7MuRTHnal2tq3W1LvO6LBHl1bpaV+tqXdr1yA2lmf1LZvZpM3vWzH76UV9PLjP778zsRTP79aPPPWFmv2Bmn9V/H9fnzcz+K93Dr5nZDz6ia36/mf0dM/sNM/tHZvbvvUOu+9TM/oGZ/aqu+z/V57/LzD6u6/uLZrbT50/092f19Q88iuvWtVQz+4SZfeydcM1m9gUz+6SZ/YqZ/ZI+d9n3xx0z+zkz+00z+5SZfeRtv+YpSPsI/gCoAD4H4IMAdgB+FcDvepTXdHRtPwzgBwH8+tHn/gsAP62PfxrAf66PfwzA3wD5138AwMcf0TU/DeAH9fEtAJ8B8LveAddtAG7q4wXAx3U9/wuAn9Dn/yyAf1sf/zsA/qw+/gkAf/ER7pP/AMD/BOBj+vulvmYAXwDw5Dd97rLvjz8P4N/SxzsAd97ua34km+voAXwEwN86+vtHAXz0UV7TN13fB77JUH4awNP6+GmQ/wkA/y2AP/F63/eIr/+vAfgj76TrBnAdwD8E8PtBEnH75r0C4G8B+Ig+bvo+ewTX+j4AfxvAHwbwMR3Oy37Nr2coL+3+APAYgM9/87N6u6/5Uafe7wXw5aO/P6fPXdb1noh4QR9/FcB79PGluw+ldj8ARmeX/rqVwv4KgBcB/AKYabwaEf11rm1et75+F8C73t4rBgD8aQB/CpiNwu/C5b/mAPB/mNkvm9lP6XOXeX98F4CvA/jvBXH8OTO7gbf5mh+1oXzHrqC7upSUATO7CeAvA/j3I+Le8dcu63VHxIiI3wNGab8PwIcf8SW96TKzPwbgxYj45Ud9Ld/m+qGI+EEA/zKAf9fMfvj4i5dwfzQQAvtvIuIHADwAU+253o5rftSG8nkA7z/6+/v0ucu6vmZmTwOA/vuiPn9p7sPMFtBI/o8R8Vf06Ut/3bki4lUAfwdMW++YWbbZHl/bvG59/TEAL7/Nl/oHAfxxM/sCgL8Apt9/Bpf7mhERz+u/LwL4q6BTusz74zkAz0XEx/X3nwMN59t6zY/aUP6/AJ5RpXAHgtw//4iv6c3WzwP4SX38kyAGmJ//N1Rx+wMA7h6lBW/bMjMD8LMAPhUR/+XRly77db/bzO7o42sgrvop0GD+uL7tm6877+fHAfyiooq3bUXERyPifRHxAXDf/mJE/Elc4ms2sxtmdis/BvBHAfw6LvH+iIivAviymX2vPvWjAH7jbb/mtxtMfh2w9sfA6uznAPzHj/p6jq7rfwbwAoAV9Gr/Jogp/W0AnwXwfwJ4Qt9rAP5r3cMnAfzeR3TNPwSmIL8G4Ff058feAdf9/QA+oev+dQD/iT7/QQD/AMCzAP4SgBN9/lR/f1Zf/+Aj3is/gq3qfWmvWdf2q/rzj/K8vQP2x+8B8EvaH/8rgMff7mu+6sy5Wlfral2tt1iPOvW+Wlfral2tS7+uDOXVulpX62q9xboylFfral2tq/UW68pQXq2rdbWu1lusK0N5ta7W1bpab7GuDOXVulpX62q9xboylFfral2tq/UW68pQXq2rdbWu1lus/w+oMBeqf+UCqQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "def get_ground_truths(ground_truth_file: str) -> np.array:\n",
        "  '''\n",
        "  Use me to convert a ground_truth_file to a numpy array\n",
        "  '''\n",
        "  with open(ground_truth_file) as f:\n",
        "    ground_truths = f.readlines()\n",
        "    to_nparray = lambda s: np.array(re.findall('\\d+', s), dtype=int)\n",
        "    truths = list(map(to_nparray, ground_truths))\n",
        "    return np.asarray(truths)\n",
        "  return None\n",
        "\n",
        "def plotNpImageBBox(img: np.array, bbox: np.array) -> np.array:\n",
        "  '''\n",
        "  Plots the bounding box on an image and returns the bounding box\n",
        "  '''\n",
        "  fig, ax = plt.subplots()\n",
        "  x, y, w, h = bbox\n",
        "  rect = patches.Rectangle((x, y), w, h, linewidth=1, edgecolor='r', facecolor='none')\n",
        "  ax.add_patch(rect)\n",
        "  plt.imshow(img)\n",
        "  return bbox\n",
        "\n",
        "def plotNpImageBBoxes(img: np.array, src_bbox: np.array, target_bbox: np.array, \n",
        "                      pred_bbox: np.array) -> np.array:\n",
        "  '''\n",
        "  Plots the bounding boxes on an image and returns the bounding box\n",
        "  '''\n",
        "  fig, ax = plt.subplots()\n",
        "  x1, y1, w1, h1 = src_bbox\n",
        "  x2, y2, w2, h2 = target_bbox\n",
        "  x3, y3, w3, h3 = pred_bbox\n",
        "  rect1 = patches.Rectangle((x1, y1), w1, h1, linewidth=1, edgecolor='b', facecolor='none')\n",
        "  rect2 = patches.Rectangle((x2, y2), w2, h2, linewidth=1, edgecolor='g', facecolor='none')\n",
        "  rect3 = patches.Rectangle((x3, y3), w3, h3, linewidth=1, edgecolor='r', facecolor='none')\n",
        "  ax.add_patch(rect1)\n",
        "  ax.add_patch(rect2)\n",
        "  ax.add_patch(rect3)\n",
        "  plt.imshow(img)\n",
        "  return pred_bbox  \n",
        "\n",
        "def plotImageBBox(img: str, bbox: np.array) -> np.array:\n",
        "  '''\n",
        "  Plots the bounding box on an image (from given filepath) and returns the \n",
        "  bounding box\n",
        "  '''\n",
        "  img = cv2.imread(img)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  plotNpImageBBox(img, bbox)\n",
        "  return bbox\n",
        "\n",
        "def plotDatasetImageBBox(dataset: str, frame_no: int) -> Tuple[np.array, int]:\n",
        "  '''\n",
        "  Plot an image's bounding box. Returns the ground truth and frame number.\n",
        "  WORKS FOR OTB100\n",
        "  '''\n",
        "  imgs = sorted(glob.glob(\"{0}/img/*\".format(dataset)))\n",
        "  gt = get_ground_truths(\"{0}/groundtruth_rect.txt\".format(dataset))\n",
        "  plotImageBBox(imgs[frame_no], gt[frame_no])\n",
        "  return gt[frame_no], frame_no\n",
        "\n",
        "\n",
        "# print(plotDatasetImageBBox(\"adnet_datasets/OTB/Basketball\", 50)[0])\n",
        "print(plotDatasetImageBBox(\"adnet_datasets/OTB/BlurBody\", 10)[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX5bfwFm2c80"
      },
      "source": [
        "### Movement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "VzDdHq04ERNg"
      },
      "outputs": [],
      "source": [
        "STOP_ACTION_INDEX = 8\n",
        "\n",
        "def getFrame(f_path: str) -> np.array:\n",
        "  print(\"Frame path: {0}\".format(f_path))\n",
        "  img = cv2.imread(f_path)\n",
        "  return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\n",
        "def calculate_IOU(bbox1: np.array, bbox2: np.array):\n",
        "    x1, y1, w1, h1 = bbox1\n",
        "    x2, y2, w2, h2 = bbox2\n",
        "           \n",
        "    i_x1 = max(x1, x2)\n",
        "    i_y1 = max(y1, y2)\n",
        "    i_x2 = min(x1 + w1, x2 + w2)\n",
        "    i_y2 = min(y1 + h1, y2 + h2)\n",
        "    if i_x1 >= i_x2 or i_y1 >= i_y2:\n",
        "      return 0.0\n",
        "\n",
        "    intersection_area = (i_x2 - i_x1) * (i_y2 - i_y1)\n",
        "    box1_area = w1 * h1\n",
        "    box2_area = w2 * h2\n",
        "    \n",
        "    iou = intersection_area / float(box1_area + box2_area - intersection_area)\n",
        "    return iou\n",
        "\n",
        "\n",
        "def move(image: np.array, bbox: np.array, action: str, \n",
        "         stride_magnitude: int=1) -> np.array:\n",
        "  '''\n",
        "  Returns the new bounding box after taking an action: \n",
        "  {\"left\", \"right\", \"up\", \"down\"}. Use stride to indicate the step size.\n",
        "  '''\n",
        "  if action not in set([\"left\", \"right\", \"up\", \"down\"]):\n",
        "    raise RuntimeError(\"Invalid action taken :(\") \n",
        "  \n",
        "  x, y, w, h = bbox\n",
        "  if action in set([\"left\", \"right\"]):\n",
        "    step = max(1, int(ALPHA * w)) * stride_magnitude * (-1 if action==\"left\" else 1)\n",
        "    x = min(max(0, int(x + step)), int(image.shape[1] - w - 1)) \n",
        "  else:\n",
        "    step = max(1, int(ALPHA * h)) * stride_magnitude * (-1 if action==\"up\" else 1)\n",
        "    y = min(max(0, int(y + step)), int(image.shape[0] - h - 1)) \n",
        "\n",
        "  return np.array([x, y, w, h])\n",
        "\n",
        "\n",
        "def scale(image: np.array, bbox: np.array, scaleUp: bool):\n",
        "  x, y, w, h = bbox\n",
        "  deltaW, deltaH = max(2, ALPHA * w), max(2, ALPHA * h)\n",
        "  if not scaleUp: \n",
        "    deltaW *= -1\n",
        "    deltaH *= -1\n",
        "  nw = min(image.shape[1], max(MIN_WINDOW_SIZE, int(w + deltaW))) \n",
        "  nh = min(image.shape[0], max(MIN_WINDOW_SIZE, int(h + deltaH)))\n",
        "  \n",
        "\n",
        "  x = max(0, min(int(x - deltaW / 2), int(image.shape[1] - w - 1)))\n",
        "  y = max(0, min(int(y - deltaH / 2), int(image.shape[0] - h - 1)))\n",
        "  return np.array([x, y, nw, nh])\n",
        "\n",
        "\n",
        "def selectAction(img: np.array, bbox: np.array, index: int): \n",
        "  if index == 0 :\n",
        "    bbox = move(img, bbox, \"left\")\n",
        "  elif index == 1 :\n",
        "    bbox = move(img, bbox, \"left\", stride_magnitude=2)\n",
        "  elif index == 2 :\n",
        "    bbox = move(img, bbox, \"right\")\n",
        "  elif index == 3 :\n",
        "    bbox = move(img, bbox, \"right\", stride_magnitude=2)  \n",
        "  elif index == 4 :\n",
        "    bbox = move(img, bbox, \"up\")  \n",
        "  elif index == 5 :\n",
        "    bbox = move(img, bbox, \"up\", stride_magnitude=2)\n",
        "  elif index == 6 :\n",
        "    bbox = move(img, bbox, \"down\")\n",
        "  elif index == 7 :\n",
        "    bbox = move(img, bbox, \"down\", stride_magnitude=2)\n",
        "  elif index == 8:\n",
        "    bbox = bbox\n",
        "  elif index == 9 :\n",
        "    bbox = scale(img, bbox, False)     \n",
        "  elif index == 10 :\n",
        "    bbox = scale(img, bbox, True)    \n",
        "  else:\n",
        "    raise ValueError(\"Invalid action provided: {0}\".format(index))\n",
        "\n",
        "  x, y, w, h = bbox\n",
        "  # some of the data is just invalid :/\n",
        "  # assert 0 <= x <= img.shape[1] - w, \"x:{0}, w:{1} is out of bounds: [0, {2}]\".format(x, w, img.shape[1])\n",
        "  # assert 0 <= y <= img.shape[0] - h, \"y:{0}, h:{1} is out of bounds: [0, {2}]\".format(y, h, img.shape[0])\n",
        "  # assert MIN_WINDOW_SIZE <= w <= img.shape[1], \"w:{0}, is invalid\".format(w)\n",
        "  # assert MIN_WINDOW_SIZE <= h <= img.shape[0], \"h:{0} is invalid\".format(h)\n",
        "  return index, bbox\n",
        "\n",
        "\n",
        "def human_readable_action(index: int) -> str:\n",
        "  '''\n",
        "  Map action numbers to human readable strings\n",
        "  '''\n",
        "  def _get_action(index:int) -> str:\n",
        "    if index == 0:\n",
        "      return \"left\"\n",
        "    elif index == 1:\n",
        "      return \"2x left\"\n",
        "    elif index == 2:\n",
        "      return \"right\"\n",
        "    elif index == 3:\n",
        "      return \"2x right\"\n",
        "    elif index == 4:\n",
        "      return \"up\"\n",
        "    elif index == 5:\n",
        "      return \"2x up\"\n",
        "    elif index == 6:\n",
        "      return \"down\"\n",
        "    elif index == 7:\n",
        "      return \"2x down\"\n",
        "    elif index == 8:\n",
        "      return \"stop\"\n",
        "    elif index == 9:\n",
        "      return \"scale down\"\n",
        "    elif index == 10 :\n",
        "      return \"scale up\"\n",
        "  return _get_action(index).upper()\n",
        "\n",
        "\n",
        "def getAction(img: np.array, bbox: np.array, action_probs: np.array):  \n",
        "  a = -1\n",
        "  if POLICY_TYPE == \"deterministic\":\n",
        "    a = tf.math.argmax(action_probs)\n",
        "  else:\n",
        "    action_probs = np.array(action_probs) + PROB_OFFSET\n",
        "    action_probs /= action_probs.sum()\n",
        "  \n",
        "    a = np.random.choice(np.arange(len(action_probs)), p=action_probs)\n",
        "  return selectAction(img, bbox, a)\n",
        "\n",
        "\n",
        "def isStop(action: int):\n",
        "  return action == STOP_ACTION_INDEX\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLxdpmQ5jOjL"
      },
      "source": [
        "# REINFORCE Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CP9qJBgVq5B"
      },
      "source": [
        "### Trajectory Loss Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "Id7dQxPDVtJ_"
      },
      "outputs": [],
      "source": [
        "def getNonStopScore(bbox1: np.array, bbox2: np.array, gt: np.array) -> float:\n",
        "  # Issues with this blowing up the gradient in the wrong direction\n",
        "\n",
        "  def _dist(x1, y1, x2, y2):\n",
        "    return math.sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2)\n",
        "  \n",
        "  prevIou = calculate_IOU(bbox1, gt) \n",
        "  nextIou = calculate_IOU(bbox2, gt)\n",
        "  x1, y1 = bbox1[:2]\n",
        "  x2, y2 = bbox2[:2]\n",
        "  xg, yg = gt[:2]\n",
        "\n",
        "  # if prevIou == nextIou: EXPERIMENTED WITH USING EUCLIDEAN DISTANCE\n",
        "  #   return -1 * (_dist(x2, y2, xg, yg) - _dist(x1, y1, xg, yg))\n",
        "  result = nextIou - prevIou \n",
        "  return result \n",
        "\n",
        "def seqLosses(action_probs: List[np.array], actions_taken: List[int], \n",
        "              bboxes: List[np.array], \n",
        "              target_bbox: np.array) -> np.array:\n",
        "\n",
        "    assertMsg = \"Invalid trajectory: actions taken ({0}) + 1 != Bboxes length ({1})\".format(\n",
        "              len(actions_taken), len(bboxes)) \n",
        "    assert len(actions_taken) + 1 == len(bboxes), assertMsg\n",
        "          \n",
        "    src_bbox = np.array(bboxes[0])\n",
        "    end_bbox = np.array(bboxes[-1])\n",
        "    print(\"\\x1b[34m>> Calculating frame loss : {0} -> {1} (Target was {2})\\x1b[0m\".format(\n",
        "            np.array2string(src_bbox, separator=', '),\n",
        "            np.array2string(end_bbox, separator=', '),\n",
        "            np.array2string(target_bbox, separator=', ')))\n",
        "    rewards = np.zeros(len(actions_taken))\n",
        "    discounts = np.zeros(len(actions_taken))\n",
        "    for i, a in enumerate(actions_taken):\n",
        "      prev_bbox = np.array(bboxes[i])\n",
        "      next_bbox = np.array(bboxes[i+1])\n",
        "      ###################### CHANGE REWARD CALCULATION HERE ####################\n",
        "      if REWARD_SCHEME == \"final_bbox\":\n",
        "        rewards[i] = 1 if calculate_IOU(end_bbox, target_bbox) > GOAL_IOU\\\n",
        "                      else -1      \n",
        "      elif REWARD_SCHEME == \"only_final_bbox\":\n",
        "        isFinalAction = i == len(actions_taken) - 1\n",
        "        if isFinalAction:\n",
        "          rewards[i] = 1 if calculate_IOU(end_bbox, target_bbox) > GOAL_IOU else -1      \n",
        "      elif REWARD_SCHEME == \"individ_bbox\":\n",
        "        if isStop(a):\n",
        "          rewards[i] = 1 if calculate_IOU(next_bbox, target_bbox) > GOAL_IOU else -1\n",
        "        else:\n",
        "          rewards[i] = getNonStopScore(prev_bbox, next_bbox, target_bbox) \n",
        "      else:\n",
        "        raise ValueError(\"Invalid REWARD_SCHEME={0} configured\".format(REWARD_SCHEME))\n",
        "      ###################### CHANGE REWARD CALCULATION UP ABOVE ################\n",
        "      prob_a = action_probs[i][a]\n",
        "      discounts[i] = GAMMA ** i\n",
        "      print(\"   |->> t={0} {1}-Reward ({2}) for {3}:bbox transition: {4} -> {5} w/ P(a|s)={6} and iou={7} and reward={8} and discount={9}\"\n",
        "            .format(i+1, \"Stop\" if isStop(a) else \"Diff\", \n",
        "                    np.around(rewards[i], decimals=3), \n",
        "                    human_readable_action(a).upper(),\n",
        "                    np.array2string(prev_bbox, separator=', '),\n",
        "                    np.array2string(next_bbox, separator=', '), prob_a, \n",
        "                    calculate_IOU(next_bbox, target_bbox), \n",
        "                    rewards[i], discounts[i]), \n",
        "            )\n",
        "    \n",
        "    gather_idx = [[i, a] for i, a in enumerate(actions_taken)]\n",
        "    p_a = tf.gather_nd(tf.stack(action_probs), gather_idx)\n",
        "    p_a = tf.clip_by_value(p_a, PROB_OFFSET, 1 - PROB_OFFSET) # done to prevent 0 reward   \n",
        "    \n",
        "    entropy = -1 * tf.math.reduce_sum((tf.math.log(action_probs) * action_probs), \n",
        "                                 axis=1) \n",
        "    \n",
        "    discount = tf.convert_to_tensor(discounts, dtype=tf.float32)\n",
        "    losses = -1 * (discount * rewards * tf.math.log(p_a))\n",
        "    \n",
        "    \n",
        "    print(\"   |->> Assigned losses: {0}\".format(losses))\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMujgGmUVu4k"
      },
      "source": [
        "### Tracking Procedure\n",
        "\n",
        "* This function collects trajectories either via argmax deterministic policy or sampling from a stochastic policy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "EqN0GHI5VlAM"
      },
      "outputs": [],
      "source": [
        "def getPatch(img: np.array, bbox: np.array) -> tf.Tensor:\n",
        "  def _patch(img: np.array, bbox: np.array) -> np.array:\n",
        "    x, y, w, h, = bbox\n",
        "    return img[y : (y + h), x : (x + w)]\n",
        "      \n",
        "  patch = tf.image.resize(_patch(img, bbox), [PATCH_X, PATCH_Y])\n",
        "  return tf.reshape(patch, (1, PATCH_X, PATCH_Y, N_CHANNELS))\n",
        "\n",
        "\n",
        "def tracking(model: ADNET, img: np.array, bbox: np.array,\n",
        "             t: int, target_bbox: np.array, \n",
        "             tracking_length: int= MAX_TRAJECTORY_LENGTH):\n",
        "    \"\"\" \n",
        "    Runs tracking until # actions > MAX_ACTIONS_SEQ_LIMIT, STOP is taken, or\n",
        "    oscillation occurs.\n",
        "    \"\"\"\n",
        "    print(\"|->> Beginning tracking for bbox:{0}\".format(bbox))    \n",
        "    patch = getPatch(img, bbox)\n",
        "    actions_taken = []\n",
        "    action_probs = []\n",
        "    bboxes = [tuple(bbox)]\n",
        "    prev_score = None\n",
        "    while len(actions_taken) < tracking_length:\n",
        "      prev_bbox = bbox.copy()\n",
        "      \n",
        "      probs, conf_score = model(patch)\n",
        "      probs = tf.reshape(probs, (model.ACTION_DIM)) \n",
        "      \n",
        "      a, bbox = getAction(np.array(img), bbox, probs)\n",
        "      prev_iou = calculate_IOU(prev_bbox, target_bbox)      \n",
        "      iou = calculate_IOU(bbox, target_bbox)   \n",
        "\n",
        "      if tuple(bbox) in bboxes:\n",
        "        print(\"|->> Revisiting bbox: {0}. Action {1} did nothing. Breaking action sequence\"\n",
        "                  .format(bbox, a))\n",
        "        print(\"   |->> Trajectory ending is FORCED\".format(iou))\n",
        "        a, bbox = 8, prev_bbox\n",
        "        if len(actions_taken) > 0:\n",
        "          # We observed too many trajectory STOPS were leading to gradient updates\n",
        "          # that reduce P(STOP|s) to near 0, which is undesirable. In this case, \n",
        "          # we allow STOPs if selected naturally by the policy or it's the only \n",
        "          # action on a trajectory (a trajectory MUST \n",
        "          # have at least one action). All other STOPs we just forego\n",
        "          # to prevent these harmful gradient updates\n",
        "          break\n",
        "      elif PREMATURE_BREAK and not isStop(a) and iou < GOAL_IOU  and prev_iou > GOAL_IOU:\n",
        "        # TRAJECTORY IS WORSENING\n",
        "        print(\"             |->> IOU declining: {0}:{1} -> {2}:{3}.\"\n",
        "                  .format(prev_bbox, prev_iou, bbox, iou))\n",
        "        print(\"             |->> Overriding with STOP\"\n",
        "                .format(iou))\n",
        "        a, bbox = 8, prev_bbox\n",
        "      \n",
        "      a_prob = probs[a] \n",
        "      print(\"   \\x1b[33m|->> #{0}/t={1}-th Action selection: {2}/{3} (P(a|s) = {4})\\x1b[0m\"\n",
        "                .format(len(actions_taken), t, a, human_readable_action(a).upper(), \n",
        "                        np.around(a_prob, decimals=3)))\n",
        "      print(\"      |->> Bounding box moves to: {0}\"\n",
        "                .format(bbox))\n",
        "      print(\"         |->> Action Probabilities (Rounded): {0}, argmax={1}\"\n",
        "              .format(np.around(probs.numpy(), decimals=4), np.argmax(probs)))\n",
        "      print(\"         |->> Action Probabilities (RAW): {0}, argmax={1}\"\n",
        "              .format(probs.numpy(), np.argmax(probs)))\n",
        "\n",
        "      if VERBOSE:\n",
        "        print(\"         |->> Overwriting action in buffer {0}\"\n",
        "            .format(model.getPrettyActionHistory() if VERBOSE else \"\"))\n",
        "        \n",
        "      action_probs.append(probs)\n",
        "      actions_taken.append(a)\n",
        "      model.updateActionHistory(a)\n",
        "      bboxes.append(tuple(bbox))  \n",
        "      patch = getPatch(img, bbox)      \n",
        "\n",
        "      # Stopping condition\n",
        "      if isStop(a):\n",
        "        print(\"         |->> Hit a STOP on the {0}-th action!\".format(t))\n",
        "        break  \n",
        "      \n",
        "      t += 1\n",
        "\n",
        "    print(\"    \\x1b[31m|->> Completed tracking\\x1b[0m\")\n",
        "    \n",
        "    return action_probs, actions_taken, bboxes, t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akOkB6DOxC_v"
      },
      "source": [
        "### Single Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "4w8_6oDV7900"
      },
      "outputs": [],
      "source": [
        "VERBOSE = True\n",
        "\n",
        "def train(model: ADNET, opt: tf.keras.optimizers.Optimizer, \n",
        "          dataset: str, start_frame: int, end_frame: int, \n",
        "          retry_count: int=N_RETRIES) -> float:\n",
        "  '''\n",
        "  Run training for a model on a frame sequence {start_frame, end_frame} \n",
        "  n_retries times.\n",
        "  :param: dataset: is the dataset path to train from\n",
        "  :param: retry_count: number of times to train on the frame sequence. \n",
        "  :return: returns the model and average loss\n",
        "  '''\n",
        "\n",
        "  gt = get_ground_truths(\"%s/groundtruth_rect.txt\" % dataset)\n",
        "  frames = sorted(glob.glob(os.path.join('%s/img' % dataset, '*.jpg'))) \n",
        "  loss = 0.0\n",
        "\n",
        "  train_vars = model.trainable_variables\n",
        "  accum_gradient = [tf.zeros_like(this_var) for this_var in train_vars]\n",
        "  for i in range(retry_count):\n",
        "    print(\"\\n\\x1b[36m####################### EPISODE # {0} ############################\\x1b[0m\".format(i+1))\n",
        "    bbox = gt[start_frame]\n",
        "    print(\"Starting bounding box={3} for {0}'s frames (index: {1})\\nsrc:{2}\\ntarget:{3}.\".format(\n",
        "        dataset, i, frames[start_frame], frames[end_frame], bbox))\n",
        "    \n",
        "    t = 1    \n",
        "    model.clearActionHistory()\n",
        "    for i in range(start_frame+1, end_frame+1):\n",
        "      with tf.GradientTape() as tape:\n",
        "        target_bbox = gt[i]\n",
        "        prev_bbox = np.array(bbox, copy=True)\n",
        "\n",
        "        print(\"\\x1b[34m>> Attempting to reach frame {0} with src: {1} and target: {2}\\x1b[0m\"\n",
        "            .format(i, np.array2string(bbox, separator=', '), \n",
        "                    np.array2string(target_bbox, separator=', ')))\n",
        "        img = getFrame(frames[i])\n",
        "        action_probs, taken_actions, bboxes, t = tracking(model, img, \n",
        "                                                          bbox, t, target_bbox)\n",
        "        bbox = np.array(bboxes[-1])\n",
        "\n",
        "\n",
        "        frame_losses = seqLosses(action_probs, taken_actions, bboxes, target_bbox)\n",
        "        total_frame_loss = tf.reduce_sum(frame_losses)\n",
        "        \n",
        "        loss += np.sum(total_frame_loss.numpy())\n",
        "        print(\"{0}>> Total frame loss: {1}\\x1b[0m\".format(\n",
        "              \"\\x1b[92m\" if total_frame_loss > 0 else \"\\x1b[31m\", \n",
        "              total_frame_loss))\n",
        "\n",
        "      gradients = tape.gradient(total_frame_loss, train_vars)\n",
        "      accum_gradient = [(acum_grad + grad) \n",
        "                        for acum_grad, grad in zip(accum_gradient, gradients)]\n",
        "\n",
        "    print(\"Final bounding box: {0} reached in {1} timesteps (originating from {2}). Target was {3}\"\n",
        "          .format(bbox, t, np.array(gt[start_frame]), np.array(gt[end_frame])))\n",
        "    print(\"\\n\\x1b[36m############# END EPISODE # {0} in t={1} timesteps ################\\x1b[0m\"\n",
        "          .format(i+1, t))\n",
        "    \n",
        "\n",
        "  print(\"Avg Loss Across Trajectories: {0}\\x1b[0m\".format(\n",
        "      \"\\x1b[92m\" if loss > 0 else \"\\x1b[31m\"))  \n",
        "  \n",
        "  \n",
        "  \n",
        "  accum_gradient = [g / retry_count if GRAD_ACCUM_SCHEME == \"avg\" else g \n",
        "                    for g in accum_gradient]\n",
        "  for i in range(len(accum_gradient)):\n",
        "      print(\"Layer Name: {}, GRAD NORM = {}\".format(\n",
        "      adnet_model.trainable_variables[i].name, tf.norm(accum_gradient[i])))\n",
        "  opt.apply_gradients(zip(accum_gradient, model.trainable_variables))\n",
        "  return model, loss / retry_count\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFKnC5VrgVhn"
      },
      "source": [
        "### Epoch Training Loops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "otMLmAPjVSiS"
      },
      "outputs": [],
      "source": [
        "def epochs_train(model: ADNET, opt: tf.keras.optimizers.Optimizer, \n",
        "                 datasets: List[str], \n",
        "                 epochs: int=1, retry_count: int=1, action_strategy: str=\"max\",\n",
        "                 seq_length: int=10, randomize: bool=RANDOMIZE_TRAINING):\n",
        "\n",
        "  print(\"TRAINING ON: {0}\".format(datasets))\n",
        "  # Collect list of datasets & trainable frames\n",
        "  dataset_frames = []\n",
        "  for d in datasets:\n",
        "    frames = sorted(glob.glob(os.path.join('%s/img' % d, '*.jpg')))\n",
        "    frames = list(range(len(frames) - L))\n",
        "    for f in frames:\n",
        "      dataset_frames.append((d, f))\n",
        "  if randomize: random.shuffle(dataset_frames)\n",
        "\n",
        "  # Train for n epochs\n",
        "  losses = {}\n",
        "  bad_data_log = []\n",
        "  for e in range(epochs):\n",
        "    epoch_loss = []\n",
        "    \n",
        "    for i, d_frame in enumerate(dataset_frames):\n",
        "      d, start_frame = d_frame\n",
        "      end_frame = start_frame + seq_length\n",
        "\n",
        "      print(\"\\n\\n#############################################\")\n",
        "      print(\"Dataset={0}\".format(d))\n",
        "      print(\"#################################################\")\n",
        "      adnet_model, l = train(model, opt, d, start_frame, end_frame, \n",
        "                             retry_count=retry_count)\n",
        "      epoch_loss.append(l)\n",
        "      print(\"#################################################\")\n",
        "      print(\"#################################################\")\n",
        "      \n",
        "\n",
        "      if i > 200:\n",
        "        # checkpointing :()\n",
        "        dt_string = datetime.now().strftime(\"%d-%m-%Y_%H%M%S\")\n",
        "        model.save('derek_models/{0}'.format(dt_string))\n",
        "\n",
        "    losses[e] = epoch_loss\n",
        "\n",
        "  print(\"Finished Training On: {0}\".format(datasets))\n",
        "  return model, losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5g5kT2HgaoO"
      },
      "source": [
        "# Training Procedure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "Isj57xK2FnN7"
      },
      "outputs": [],
      "source": [
        "adnet_model = ADNET()\n",
        "adnet_model.build()\n",
        "WEIGHTS_PATH = \"yifanweights.mat\"\n",
        "weights = hdf5storage.loadmat(WEIGHTS_PATH)\n",
        "adnet_model = setWeights(adnet_model,weights,weights)\n",
        "adnet_model.layers[-3].trainable=False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZt5PyM2Foj4"
      },
      "source": [
        "### To reload saved weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "P7aHgxIpCLpa"
      },
      "outputs": [],
      "source": [
        "# SAVED_MODEL_PATH = \"derek_models/19-12-2021_060516\"\n",
        "# loaded_model = tf.keras.models.load_model(SAVED_MODEL_PATH, \n",
        "#                                          custom_objects={\"ADNET\": ADNET}, \n",
        "#                                           compile=False)\n",
        "# loaded_model.compile(optimizer=Adam(learning_rate=LEARNING_RATE))\n",
        "# adnet_model.set_weights(loaded_model.get_weights())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEsOSSVhg-qp",
        "outputId": "1f8b4b80-857b-40ac-e303-7b3e6d585a39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on datasets: ['adnet_datasets/OTB/Doll']\n"
          ]
        }
      ],
      "source": [
        "N_VIDEOS = 1\n",
        "datasets = np.random.choice(len(ALL_DATASETS_LIST), size=N_VIDEOS, replace=False)\n",
        "datasets = list(map(lambda rand_idx: ALL_DATASETS_LIST[rand_idx], datasets))\n",
        "print(\"Training on datasets: {0}\".format(datasets))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41yhNXMygPIy",
        "outputId": "9ac1589b-bd2f-4fad-f99d-62fab3a41f1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAINING ON: ['adnet_datasets/OTB/Doll']\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/Doll\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Starting bounding box=adnet_datasets/OTB/Doll/img/0011.jpg for adnet_datasets/OTB/Doll's frames (index: 0)\n",
            "src:adnet_datasets/OTB/Doll/img/0001.jpg\n",
            "target:adnet_datasets/OTB/Doll/img/0011.jpg.\n",
            "\u001b[34m>> Attempting to reach frame 1 with src: [146, 150,  32,  73] and target: [147, 150,  32,  73]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Doll/img/0002.jpg\n",
            "|->> Beginning tracking for bbox:[146 150  32  73]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 7/2X DOWN (P(a|s) = 0.08500000089406967)\u001b[0m\n",
            "      |->> Bounding box moves to: [146 154  32  73]\n",
            "         |->> Action Probabilities (Rounded): [0.0946 0.0935 0.0922 0.093  0.0867 0.0875 0.0906 0.085  0.0886 0.0954\n",
            " 0.0928], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.0945623  0.09350529 0.09221968 0.09304571 0.08670739 0.08745024\n",
            " 0.09060416 0.08504791 0.08862237 0.09538811 0.0928468 ], argmax=9\n",
            "         |->> Overwriting action in buffer [00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000]\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 4/UP (P(a|s) = 0.08500000089406967)\u001b[0m\n",
            "      |->> Bounding box moves to: [146 152  32  73]\n",
            "         |->> Action Probabilities (Rounded): [0.0963 0.0951 0.0932 0.0937 0.085  0.0856 0.0904 0.0813 0.0874 0.0983\n",
            " 0.0939], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.09630251 0.09508816 0.09320811 0.09367196 0.08497576 0.08558577\n",
            " 0.09036937 0.08125537 0.08738996 0.09825531 0.09389769], argmax=9\n",
            "         |->> Overwriting action in buffer [0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000]\n",
            "   \u001b[33m|->> #2/t=3-th Action selection: 7/2X DOWN (P(a|s) = 0.08299999684095383)\u001b[0m\n",
            "      |->> Bounding box moves to: [146 156  32  73]\n",
            "         |->> Action Probabilities (Rounded): [0.0962 0.0947 0.0929 0.0941 0.0839 0.0865 0.0909 0.0828 0.0889 0.0962\n",
            " 0.0929], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09623079 0.09465217 0.09293962 0.09406514 0.08392467 0.08650559\n",
            " 0.09093387 0.08283224 0.08889654 0.09616377 0.09285558], argmax=0\n",
            "         |->> Overwriting action in buffer [0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000]\n",
            "   \u001b[33m|->> #3/t=4-th Action selection: 9/SCALE DOWN (P(a|s) = 0.09799999743700027)\u001b[0m\n",
            "      |->> Bounding box moves to: [147 157  30  70]\n",
            "         |->> Action Probabilities (Rounded): [0.0969 0.0956 0.0935 0.0939 0.0845 0.0855 0.0898 0.0807 0.0877 0.0982\n",
            " 0.0937], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.09690411 0.09557977 0.09350572 0.09389585 0.08448496 0.08551241\n",
            " 0.08983017 0.08071478 0.08767202 0.09821022 0.09369003], argmax=9\n",
            "         |->> Overwriting action in buffer [0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000]\n",
            "   \u001b[33m|->> #4/t=5-th Action selection: 4/UP (P(a|s) = 0.08500000089406967)\u001b[0m\n",
            "      |->> Bounding box moves to: [147 155  30  70]\n",
            "         |->> Action Probabilities (Rounded): [0.0962 0.0969 0.0931 0.0946 0.0848 0.086  0.0911 0.0815 0.0872 0.0937\n",
            " 0.0949], argmax=1\n",
            "         |->> Action Probabilities (RAW): [0.09623631 0.09689961 0.093058   0.0945795  0.08477958 0.08595818\n",
            " 0.09109649 0.08147434 0.08724442 0.09373198 0.09494161], argmax=1\n",
            "         |->> Overwriting action in buffer [000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000]\n",
            "|->> Revisiting bbox: [147 155  30  70]. Action 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [146, 150,  32,  73] -> [147, 155,  30,  70] (Target was [147, 150,  32,  73])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X DOWN:bbox transition: [146, 150,  32,  73] -> [146, 154,  32,  73] w/ P(a|s)=0.08504790812730789 and iou=0.8444532175286222 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for UP:bbox transition: [146, 154,  32,  73] -> [146, 152,  32,  73] w/ P(a|s)=0.08497575670480728 and iou=0.8907324969647916 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X DOWN:bbox transition: [146, 152,  32,  73] -> [146, 156,  32,  73] w/ P(a|s)=0.08283223956823349 and iou=0.8003853564547206 and reward=0.0 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.0) for SCALE DOWN:bbox transition: [146, 156,  32,  73] -> [147, 157,  30,  70] w/ P(a|s)=0.09821021556854248 and iou=0.8061889250814332 and reward=0.0 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (1.0) for UP:bbox transition: [147, 157,  30,  70] -> [147, 155,  30,  70] w/ P(a|s)=0.08477957546710968 and iou=0.8514190317195326 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.        0.        0.        0.        2.4677007]\n",
            "\u001b[92m>> Total frame loss: 2.467700719833374\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 2 with src: [147, 155,  30,  70] and target: [148, 150,  32,  73]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Doll/img/0003.jpg\n",
            "|->> Beginning tracking for bbox:[147 155  30  70]\n",
            "   \u001b[33m|->> #0/t=6-th Action selection: 7/2X DOWN (P(a|s) = 0.0820000022649765)\u001b[0m\n",
            "      |->> Bounding box moves to: [147 159  30  70]\n",
            "         |->> Action Probabilities (Rounded): [0.0969 0.096  0.0932 0.0953 0.0839 0.0863 0.0912 0.0821 0.0887 0.0936\n",
            " 0.0928], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09686777 0.09599849 0.09316523 0.09531496 0.08394556 0.08634933\n",
            " 0.0911703  0.08214489 0.08869936 0.09358171 0.09276232], argmax=0\n",
            "         |->> Overwriting action in buffer [0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000]\n",
            "   \u001b[33m|->> #1/t=7-th Action selection: 2/RIGHT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [148 159  30  70]\n",
            "         |->> Action Probabilities (Rounded): [0.0965 0.0967 0.0927 0.0944 0.0853 0.086  0.0905 0.0816 0.0876 0.0947\n",
            " 0.094 ], argmax=1\n",
            "         |->> Action Probabilities (RAW): [0.09654085 0.09668209 0.09272593 0.09444347 0.08529904 0.08599099\n",
            " 0.09049597 0.08156271 0.08758757 0.0946744  0.09399704], argmax=1\n",
            "         |->> Overwriting action in buffer [0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000]\n",
            "   \u001b[33m|->> #2/t=8-th Action selection: 10/SCALE UP (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [147 157  32  72]\n",
            "         |->> Action Probabilities (Rounded): [0.1029 0.0967 0.0841 0.0953 0.0858 0.0872 0.0915 0.0822 0.0872 0.0941\n",
            " 0.093 ], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.10291597 0.09674373 0.08409705 0.09529784 0.08583371 0.08715025\n",
            " 0.09149508 0.08216802 0.08718267 0.09412935 0.09298633], argmax=0\n",
            "         |->> Overwriting action in buffer [00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000]\n",
            "|->> Revisiting bbox: [147 157  32  72]. Action 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [147, 155,  30,  70] -> [147, 157,  32,  72] (Target was [148, 150,  32,  73])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X DOWN:bbox transition: [147, 155,  30,  70] -> [147, 159,  30,  70] w/ P(a|s)=0.08214488625526428 and iou=0.7193798449612403 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for RIGHT:bbox transition: [147, 159,  30,  70] -> [148, 159,  30,  70] w/ P(a|s)=0.09272592514753342 and iou=0.7631160572337043 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (1.0) for SCALE UP:bbox transition: [148, 159,  30,  70] -> [147, 157,  32,  72] w/ P(a|s)=0.0929863303899765 and iou=0.7887432536622976 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.        0.        2.3753028]\n",
            "\u001b[92m>> Total frame loss: 2.375302791595459\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 3 with src: [147, 157,  32,  72] and target: [148, 150,  32,  74]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Doll/img/0004.jpg\n",
            "|->> Beginning tracking for bbox:[147 157  32  72]\n",
            "   \u001b[33m|->> #0/t=9-th Action selection: 3/2X RIGHT (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [149 157  32  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0933 0.098  0.0937 0.0949 0.0868 0.0869 0.0919 0.0827 0.0875 0.0968\n",
            " 0.0875], argmax=1\n",
            "         |->> Action Probabilities (RAW): [0.0933134  0.09797519 0.09373441 0.09488188 0.08679473 0.08694492\n",
            " 0.09185515 0.08270875 0.08751845 0.09681437 0.08745876], argmax=1\n",
            "         |->> Overwriting action in buffer [0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000]\n",
            "   \u001b[33m|->> #1/t=10-th Action selection: 4/UP (P(a|s) = 0.0860000029206276)\u001b[0m\n",
            "      |->> Bounding box moves to: [149 155  32  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0997 0.0983 0.0891 0.0932 0.0864 0.0872 0.0916 0.0819 0.0865 0.0963\n",
            " 0.0898], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09973806 0.09826893 0.08907924 0.09320433 0.08640466 0.08716234\n",
            " 0.09164319 0.08187547 0.0865209  0.09627038 0.08983243], argmax=0\n",
            "         |->> Overwriting action in buffer [000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m00000000000]\n",
            "   \u001b[33m|->> #2/t=11-th Action selection: 5/2X UP (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [149 151  32  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0974 0.0982 0.0915 0.0944 0.0849 0.0873 0.0925 0.0826 0.0858 0.0963\n",
            " 0.0891], argmax=1\n",
            "         |->> Action Probabilities (RAW): [0.09742775 0.09822927 0.09152167 0.09435977 0.08487324 0.08733547\n",
            " 0.0925096  0.08257639 0.08582119 0.09627605 0.08906968], argmax=1\n",
            "         |->> Overwriting action in buffer [0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000]\n",
            "   \u001b[33m|->> #3/t=12-th Action selection: 10/SCALE UP (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [148 149  34  74]\n",
            "         |->> Action Probabilities (Rounded): [0.0968 0.0963 0.0903 0.0932 0.0871 0.0872 0.0925 0.0856 0.0885 0.0935\n",
            " 0.0891], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09676445 0.09630078 0.09027564 0.09323363 0.08705296 0.0871928\n",
            " 0.09254963 0.08557839 0.08845342 0.09345955 0.08913875], argmax=0\n",
            "         |->> Overwriting action in buffer [00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000]\n",
            "   \u001b[33m|->> #4/t=13-th Action selection: 9/SCALE DOWN (P(a|s) = 0.09600000083446503)\u001b[0m\n",
            "      |->> Bounding box moves to: [149 150  32  71]\n",
            "         |->> Action Probabilities (Rounded): [0.0951 0.0967 0.0903 0.0944 0.0876 0.0875 0.0933 0.0856 0.0891 0.0961\n",
            " 0.0844], argmax=1\n",
            "         |->> Action Probabilities (RAW): [0.09507091 0.09665378 0.09029975 0.09439738 0.08757434 0.08747657\n",
            " 0.09330904 0.0856323  0.08913307 0.09608752 0.08436544], argmax=1\n",
            "         |->> Overwriting action in buffer [0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000]\n",
            "   \u001b[33m|->> #5/t=14-th Action selection: 3/2X RIGHT (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [151 150  32  71]\n",
            "         |->> Action Probabilities (Rounded): [0.0956 0.0971 0.091  0.0948 0.0884 0.0878 0.0933 0.0868 0.0887 0.0889\n",
            " 0.0877], argmax=1\n",
            "         |->> Action Probabilities (RAW): [0.09556749 0.09707272 0.09097101 0.09483428 0.088426   0.08777352\n",
            " 0.09325277 0.08681259 0.08867078 0.08892237 0.08769647], argmax=1\n",
            "         |->> Overwriting action in buffer [000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0]\n",
            "|->> Revisiting bbox: [151 150  32  71]. Action 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [147, 157,  32,  72] -> [151, 150,  32,  71] (Target was [148, 150,  32,  74])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X RIGHT:bbox transition: [147, 157,  32,  72] -> [149, 157,  32,  72] w/ P(a|s)=0.09488187730312347 and iou=0.8003853564547206 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for UP:bbox transition: [149, 157,  32,  72] -> [149, 155,  32,  72] w/ P(a|s)=0.08640465885400772 and iou=0.8444532175286222 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X UP:bbox transition: [149, 155,  32,  72] -> [149, 151,  32,  72] w/ P(a|s)=0.08733547478914261 and iou=0.9147540983606557 and reward=0.0 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.0) for SCALE UP:bbox transition: [149, 151,  32,  72] -> [148, 149,  34,  74] w/ P(a|s)=0.08913874626159668 and iou=0.9167974882260597 and reward=0.0 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (0.0) for SCALE DOWN:bbox transition: [148, 149,  34,  74] -> [149, 150,  32,  71] w/ P(a|s)=0.0960875153541565 and iou=0.9024190241902419 and reward=0.0 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (1.0) for 2X RIGHT:bbox transition: [149, 150,  32,  71] -> [151, 150,  32,  71] w/ P(a|s)=0.09483428299427032 and iou=0.797752808988764 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.        0.        0.        0.        0.        2.3556242]\n",
            "\u001b[92m>> Total frame loss: 2.355624198913574\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 4 with src: [151, 150,  32,  71] and target: [148, 150,  32,  73]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Doll/img/0005.jpg\n",
            "|->> Beginning tracking for bbox:[151 150  32  71]\n",
            "   \u001b[33m|->> #0/t=15-th Action selection: 6/DOWN (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [151 152  32  71]\n",
            "         |->> Action Probabilities (Rounded): [0.0961 0.0962 0.0893 0.0931 0.0884 0.0884 0.0932 0.0869 0.0886 0.0936\n",
            " 0.0863], argmax=1\n",
            "         |->> Action Probabilities (RAW): [0.09608018 0.09620126 0.08931623 0.09306077 0.08839266 0.08840683\n",
            " 0.09322966 0.08687603 0.08855817 0.09357834 0.08629982], argmax=1\n",
            "         |->> Overwriting action in buffer [000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000]\n",
            "   \u001b[33m|->> #1/t=16-th Action selection: 5/2X UP (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [151 148  32  71]\n",
            "         |->> Action Probabilities (Rounded): [0.0958 0.0963 0.0897 0.0933 0.0895 0.0885 0.091  0.0867 0.0884 0.0927\n",
            " 0.088 ], argmax=1\n",
            "         |->> Action Probabilities (RAW): [0.09581591 0.09633145 0.08973339 0.09327399 0.08953541 0.08847486\n",
            " 0.0910332  0.086748   0.08835988 0.09271265 0.08798127], argmax=1\n",
            "         |->> Overwriting action in buffer [000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000]\n",
            "|->> Revisiting bbox: [151 148  32  71]. Action 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [151, 150,  32,  71] -> [151, 148,  32,  71] (Target was [148, 150,  32,  73])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for DOWN:bbox transition: [151, 150,  32,  71] -> [151, 152,  32,  71] w/ P(a|s)=0.09322965890169144 and iou=0.8077677520596312 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for 2X UP:bbox transition: [151, 152,  32,  71] -> [151, 148,  32,  71] w/ P(a|s)=0.08847486227750778 and iou=0.7675489067894131 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.       2.425037]\n",
            "\u001b[92m>> Total frame loss: 2.425036907196045\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 5 with src: [151, 148,  32,  71] and target: [148, 150,  32,  73]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Doll/img/0006.jpg\n",
            "|->> Beginning tracking for bbox:[151 148  32  71]\n",
            "   \u001b[33m|->> #0/t=17-th Action selection: 2/RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [152 148  32  71]\n",
            "         |->> Action Probabilities (Rounded): [0.0966 0.0963 0.091  0.093  0.0866 0.0866 0.0932 0.0855 0.0883 0.0946\n",
            " 0.0883], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09656674 0.09629119 0.09103508 0.09301654 0.08664433 0.08659264\n",
            " 0.09319845 0.08548325 0.0882595  0.0946359  0.08827641], argmax=0\n",
            "         |->> Overwriting action in buffer [00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000]\n",
            "   \u001b[33m|->> #1/t=18-th Action selection: 7/2X DOWN (P(a|s) = 0.0860000029206276)\u001b[0m\n",
            "      |->> Bounding box moves to: [152 152  32  71]\n",
            "         |->> Action Probabilities (Rounded): [0.1023 0.0959 0.0827 0.0947 0.0878 0.0875 0.0921 0.0859 0.0883 0.0942\n",
            " 0.0886], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.10227417 0.09592147 0.08272305 0.09468724 0.08779382 0.08751382\n",
            " 0.0920898  0.08590412 0.08830721 0.09421558 0.08856972], argmax=0\n",
            "         |->> Overwriting action in buffer [00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m]\n",
            "   \u001b[33m|->> #2/t=19-th Action selection: 0/LEFT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [151 152  32  71]\n",
            "         |->> Action Probabilities (Rounded): [0.0924 0.0961 0.0925 0.0926 0.0885 0.0874 0.093  0.086  0.0886 0.093\n",
            " 0.0898], argmax=1\n",
            "         |->> Action Probabilities (RAW): [0.09241553 0.09606279 0.09253972 0.09255336 0.08849365 0.08742248\n",
            " 0.09303816 0.08601917 0.08860976 0.093029   0.08981637], argmax=1\n",
            "         |->> Overwriting action in buffer [0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000]\n",
            "|->> Revisiting bbox: [151 148  32  71]. Action 5 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [151, 148,  32,  71] -> [151, 152,  32,  71] (Target was [148, 150,  32,  73])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for RIGHT:bbox transition: [151, 148,  32,  71] -> [152, 148,  32,  71] w/ P(a|s)=0.09103508293628693 and iou=0.7219730941704036 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for 2X DOWN:bbox transition: [152, 148,  32,  71] -> [152, 152,  32,  71] w/ P(a|s)=0.08590412139892578 and iou=0.7587786259541984 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (1.0) for LEFT:bbox transition: [152, 152,  32,  71] -> [151, 152,  32,  71] w/ P(a|s)=0.09241552650928497 and iou=0.8077677520596312 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.        0.        2.3814602]\n",
            "\u001b[92m>> Total frame loss: 2.381460189819336\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 6 with src: [151, 152,  32,  71] and target: [147, 150,  33,  75]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Doll/img/0007.jpg\n",
            "|->> Beginning tracking for bbox:[151 152  32  71]\n",
            "   \u001b[33m|->> #0/t=20-th Action selection: 3/2X RIGHT (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [153 152  32  71]\n",
            "         |->> Action Probabilities (Rounded): [0.0881 0.0961 0.0952 0.095  0.0885 0.0887 0.0929 0.0869 0.0892 0.0903\n",
            " 0.0891], argmax=1\n",
            "         |->> Action Probabilities (RAW): [0.08810007 0.09610979 0.09516427 0.09495082 0.08854512 0.08865626\n",
            " 0.0928752  0.08693255 0.08924548 0.09030144 0.089119  ], argmax=1\n",
            "         |->> Overwriting action in buffer [\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000]\n",
            "   \u001b[33m|->> #1/t=21-th Action selection: 3/2X RIGHT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [155 152  32  71]\n",
            "         |->> Action Probabilities (Rounded): [0.0947 0.0948 0.088  0.0924 0.0895 0.0897 0.0928 0.088  0.0895 0.0909\n",
            " 0.0898], argmax=1\n",
            "         |->> Action Probabilities (RAW): [0.09465893 0.09482338 0.08799948 0.09238789 0.08953906 0.08967371\n",
            " 0.09281424 0.08797727 0.08946948 0.09089853 0.08975811], argmax=1\n",
            "         |->> Overwriting action in buffer [000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000]\n",
            "   \u001b[33m|->> #2/t=22-th Action selection: 10/SCALE UP (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [154 150  34  73]\n",
            "         |->> Action Probabilities (Rounded): [0.0938 0.0951 0.0905 0.091  0.0893 0.09   0.0932 0.0877 0.0882 0.0917\n",
            " 0.0895], argmax=1\n",
            "         |->> Action Probabilities (RAW): [0.093762   0.0950912  0.0905102  0.09103681 0.08932275 0.08998507\n",
            " 0.09319905 0.08768599 0.08824964 0.09165915 0.08949819], argmax=1\n",
            "         |->> Overwriting action in buffer [000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m]\n",
            "   \u001b[33m|->> #3/t=23-th Action selection: 10/SCALE UP (P(a|s) = 0.0860000029206276)\u001b[0m\n",
            "      |->> Bounding box moves to: [153 148  36  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0964 0.0947 0.088  0.0917 0.089  0.0902 0.0936 0.0875 0.0893 0.0935\n",
            " 0.0861], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09638828 0.09474112 0.08798104 0.09171874 0.08899501 0.09021207\n",
            " 0.09363863 0.08746734 0.08927061 0.09347941 0.08610776], argmax=0\n",
            "         |->> Overwriting action in buffer [0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0]\n",
            "|->> Revisiting bbox: [153 148  36  75]. Action 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [151, 152,  32,  71] -> [153, 148,  36,  75] (Target was [147, 150,  33,  75])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X RIGHT:bbox transition: [151, 152,  32,  71] -> [153, 152,  32,  71] w/ P(a|s)=0.09495082497596741 and iou=0.6773851590106007 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for 2X RIGHT:bbox transition: [153, 152,  32,  71] -> [155, 152,  32,  71] w/ P(a|s)=0.09238789230585098 and iou=0.5972409152086138 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.0) for SCALE UP:bbox transition: [155, 152,  32,  71] -> [154, 150,  34,  73] w/ P(a|s)=0.08949819207191467 and iou=0.6204642039882314 and reward=0.0 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-1.0) for SCALE UP:bbox transition: [154, 150,  34,  73] -> [153, 148,  36,  75] w/ P(a|s)=0.0861077606678009 and iou=0.6151685393258427 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.         0.         0.        -2.4521558]\n",
            "\u001b[31m>> Total frame loss: -2.452155828475952\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 7 with src: [153, 148,  36,  75] and target: [147, 150,  33,  76]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Doll/img/0008.jpg\n",
            "|->> Beginning tracking for bbox:[153 148  36  75]\n",
            "   \u001b[33m|->> #0/t=24-th Action selection: 6/DOWN (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [153 150  36  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0968 0.096  0.0897 0.0922 0.0887 0.0895 0.0929 0.0864 0.0884 0.0963\n",
            " 0.083 ], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09682835 0.09597567 0.08970907 0.09222145 0.08868863 0.0894798\n",
            " 0.09292205 0.08639299 0.08838923 0.09634793 0.08304481], argmax=0\n",
            "         |->> Overwriting action in buffer [0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000]\n",
            "   \u001b[33m|->> #1/t=25-th Action selection: 0/LEFT (P(a|s) = 0.09600000083446503)\u001b[0m\n",
            "      |->> Bounding box moves to: [152 150  36  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0964 0.0952 0.0904 0.0927 0.0903 0.0902 0.0907 0.0875 0.0887 0.0936\n",
            " 0.0842], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09637665 0.09523289 0.0904009  0.09274787 0.09027541 0.09019142\n",
            " 0.09074459 0.08751429 0.08871298 0.09359913 0.08420383], argmax=0\n",
            "         |->> Overwriting action in buffer [000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000]\n",
            "   \u001b[33m|->> #2/t=26-th Action selection: 1/2X LEFT (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [150 150  36  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0879 0.095  0.0969 0.094  0.0889 0.0911 0.0929 0.0887 0.0889 0.0917\n",
            " 0.084 ], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08786193 0.09496094 0.09691204 0.09403446 0.08887599 0.09112728\n",
            " 0.0929092  0.08866406 0.08886835 0.09174639 0.08403935], argmax=2\n",
            "         |->> Overwriting action in buffer [\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000]\n",
            "   \u001b[33m|->> #3/t=27-th Action selection: 0/LEFT (P(a|s) = 0.09600000083446503)\u001b[0m\n",
            "      |->> Bounding box moves to: [149 150  36  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0961 0.0914 0.0886 0.0937 0.0906 0.0913 0.0922 0.0886 0.0892 0.0921\n",
            " 0.0861], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09614678 0.09137414 0.08863834 0.09371813 0.09060272 0.09132387\n",
            " 0.09215339 0.08857598 0.08921137 0.09213795 0.08611726], argmax=0\n",
            "         |->> Overwriting action in buffer [0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000]\n",
            "|->> Revisiting bbox: [150 150  36  75]. Action 2 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [153, 148,  36,  75] -> [149, 150,  36,  75] (Target was [147, 150,  33,  76])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for DOWN:bbox transition: [153, 148,  36,  75] -> [153, 150,  36,  75] w/ P(a|s)=0.09292204678058624 and iou=0.6361922714420358 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for LEFT:bbox transition: [153, 150,  36,  75] -> [152, 150,  36,  75] w/ P(a|s)=0.09637665003538132 and iou=0.6756756756756757 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X LEFT:bbox transition: [152, 150,  36,  75] -> [150, 150,  36,  75] w/ P(a|s)=0.09496093541383743 and iou=0.7606490872210954 and reward=0.0 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (1.0) for LEFT:bbox transition: [150, 150,  36,  75] -> [149, 150,  36,  75] w/ P(a|s)=0.09614677727222443 and iou=0.8064516129032258 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.        0.        0.        2.3418794]\n",
            "\u001b[92m>> Total frame loss: 2.341879367828369\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 8 with src: [149, 150,  36,  75] and target: [147, 150,  33,  76]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Doll/img/0009.jpg\n",
            "|->> Beginning tracking for bbox:[149 150  36  75]\n",
            "   \u001b[33m|->> #0/t=28-th Action selection: 0/LEFT (P(a|s) = 0.0860000029206276)\u001b[0m\n",
            "      |->> Bounding box moves to: [148 150  36  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0859 0.0916 0.0992 0.0944 0.0893 0.092  0.0936 0.0899 0.0881 0.09\n",
            " 0.0857], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08593027 0.09164146 0.09924785 0.0944212  0.08930601 0.09200759\n",
            " 0.09361137 0.08994507 0.08813799 0.09003092 0.08572026], argmax=2\n",
            "         |->> Overwriting action in buffer [\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000]\n",
            "   \u001b[33m|->> #1/t=29-th Action selection: 5/2X UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [148 146  36  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0909 0.0909 0.0938 0.0961 0.0895 0.0921 0.0936 0.0901 0.0879 0.0891\n",
            " 0.0861], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09085469 0.09092049 0.09383613 0.09606329 0.08948192 0.09210095\n",
            " 0.09356377 0.09005249 0.08793692 0.08909226 0.08609708], argmax=3\n",
            "         |->> Overwriting action in buffer [\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000]\n",
            "   \u001b[33m|->> #2/t=30-th Action selection: 4/UP (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [148 144  36  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0952 0.0922 0.0919 0.0952 0.0877 0.0891 0.0934 0.087  0.0861 0.0937\n",
            " 0.0884], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09517308 0.09219004 0.09192405 0.09522165 0.08767583 0.08914654\n",
            " 0.0934443  0.08696567 0.08612248 0.09369005 0.0884463 ], argmax=3\n",
            "         |->> Overwriting action in buffer [00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000]\n",
            "   \u001b[33m|->> #3/t=31-th Action selection: 0/LEFT (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [147 144  36  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0954 0.0921 0.0944 0.0967 0.0856 0.0884 0.094  0.0864 0.086  0.0928\n",
            " 0.0883], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09537552 0.09208883 0.09441857 0.09670603 0.08555756 0.08841543\n",
            " 0.09401878 0.0863926  0.08598049 0.0927558  0.08829042], argmax=3\n",
            "         |->> Overwriting action in buffer [0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000]\n",
            "   \u001b[33m|->> #4/t=32-th Action selection: 1/2X LEFT (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [145 144  36  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0899 0.0924 0.0999 0.0981 0.0863 0.0887 0.0931 0.0874 0.0866 0.0897\n",
            " 0.088 ], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08989092 0.09239399 0.09993435 0.09807952 0.08633473 0.08869078\n",
            " 0.0930822  0.08739509 0.08656227 0.08965123 0.0879849 ], argmax=2\n",
            "         |->> Overwriting action in buffer [\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m]\n",
            "   \u001b[33m|->> #5/t=33-th Action selection: 4/UP (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [145 142  36  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0964 0.0887 0.0921 0.0968 0.0877 0.0895 0.0939 0.0891 0.0878 0.0888\n",
            " 0.0892], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.09640996 0.08873365 0.09206013 0.09677386 0.08773113 0.08949406\n",
            " 0.09393138 0.08912231 0.08777852 0.08878219 0.0891828 ], argmax=3\n",
            "         |->> Overwriting action in buffer [0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m]\n",
            "   \u001b[33m|->> #6/t=34-th Action selection: 0/LEFT (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [144 142  36  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0944 0.0888 0.0957 0.0957 0.0864 0.0901 0.0943 0.0903 0.0873 0.0874\n",
            " 0.0895], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.09442644 0.08882246 0.09574372 0.09574246 0.08638792 0.09005591\n",
            " 0.09434426 0.0902617  0.08731395 0.08743133 0.08946985], argmax=2\n",
            "         |->> Overwriting action in buffer [0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000]\n",
            "   \u001b[33m|->> #7/t=35-th Action selection: 5/2X UP (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [144 138  36  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0901 0.089  0.0998 0.0972 0.0872 0.0899 0.0935 0.0903 0.0875 0.0863\n",
            " 0.0892], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.09010389 0.08899756 0.09978186 0.0972049  0.08721045 0.08994652\n",
            " 0.09352684 0.09025078 0.08745638 0.08631394 0.08920681], argmax=2\n",
            "         |->> Overwriting action in buffer [\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000]\n",
            "|->> Revisiting bbox: [144 142  36  75]. Action 7 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [149, 150,  36,  75] -> [144, 138,  36,  75] (Target was [147, 150,  33,  76])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for LEFT:bbox transition: [149, 150,  36,  75] -> [148, 150,  36,  75] w/ P(a|s)=0.08593027293682098 and iou=0.8547008547008547 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for 2X UP:bbox transition: [148, 150,  36,  75] -> [148, 146,  36,  75] w/ P(a|s)=0.09210094809532166 and iou=0.773841961852861 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.0) for UP:bbox transition: [148, 146,  36,  75] -> [148, 144,  36,  75] w/ P(a|s)=0.08767583221197128 and iou=0.736 and reward=0.0 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.0) for LEFT:bbox transition: [148, 144,  36,  75] -> [147, 144,  36,  75] w/ P(a|s)=0.09537551552057266 and iou=0.7768679631525077 and reward=0.0 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (0.0) for 2X LEFT:bbox transition: [147, 144,  36,  75] -> [145, 144,  36,  75] w/ P(a|s)=0.09239398688077927 and iou=0.7768679631525077 and reward=0.0 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (0.0) for UP:bbox transition: [145, 144,  36,  75] -> [145, 142,  36,  75] w/ P(a|s)=0.08773113042116165 and iou=0.7377377377377378 and reward=0.0 and discount=1.0\n",
            "   |->> t=7 Diff-Reward (0.0) for LEFT:bbox transition: [145, 142,  36,  75] -> [144, 142,  36,  75] w/ P(a|s)=0.09442643821239471 and iou=0.7377377377377378 and reward=0.0 and discount=1.0\n",
            "   |->> t=8 Diff-Reward (-1.0) for 2X UP:bbox transition: [144, 142,  36,  75] -> [144, 138,  36,  75] w/ P(a|s)=0.08994651585817337 and iou=0.6644295302013423 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.       0.       0.       0.       0.       0.       0.      -2.40854]\n",
            "\u001b[31m>> Total frame loss: -2.4085400104522705\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 9 with src: [144, 138,  36,  75] and target: [146, 151,  34,  75]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Doll/img/0010.jpg\n",
            "|->> Beginning tracking for bbox:[144 138  36  75]\n",
            "   \u001b[33m|->> #0/t=36-th Action selection: 3/2X RIGHT (P(a|s) = 0.09700000286102295)\u001b[0m\n",
            "      |->> Bounding box moves to: [146 138  36  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0993 0.0901 0.0921 0.0973 0.0859 0.0867 0.094  0.0872 0.0866 0.0899\n",
            " 0.091 ], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09934472 0.09005056 0.09212881 0.09726163 0.08586241 0.08669571\n",
            " 0.09400058 0.08717683 0.08659498 0.08992235 0.09096149], argmax=0\n",
            "         |->> Overwriting action in buffer [00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000]\n",
            "   \u001b[33m|->> #1/t=37-th Action selection: 3/2X RIGHT (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [148 138  36  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0975 0.0912 0.0955 0.0951 0.086  0.087  0.0938 0.087  0.0861 0.0903\n",
            " 0.0904], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09749563 0.09121981 0.09546007 0.09513121 0.08599008 0.08703945\n",
            " 0.0938254  0.08700074 0.08608107 0.09032703 0.09042958], argmax=0\n",
            "         |->> Overwriting action in buffer [000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000]\n",
            "   \u001b[33m|->> #2/t=38-th Action selection: 4/UP (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [148 136  36  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0999 0.0917 0.0905 0.0929 0.0871 0.0874 0.0935 0.0874 0.0869 0.0917\n",
            " 0.0911], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09994749 0.09173249 0.09045057 0.09290045 0.08705878 0.08736262\n",
            " 0.09347085 0.08736683 0.08686769 0.09172483 0.09111743], argmax=0\n",
            "         |->> Overwriting action in buffer [000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000]\n",
            "   \u001b[33m|->> #3/t=39-th Action selection: 5/2X UP (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [148 132  36  75]\n",
            "         |->> Action Probabilities (Rounded): [0.098  0.0935 0.0925 0.0938 0.0843 0.0868 0.0935 0.0857 0.0872 0.0935\n",
            " 0.0913], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09798131 0.09351902 0.09253104 0.09375837 0.08432711 0.08675876\n",
            " 0.09354127 0.08572257 0.08715371 0.09345289 0.09125395], argmax=0\n",
            "         |->> Overwriting action in buffer [0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000]\n",
            "   \u001b[33m|->> #4/t=40-th Action selection: 9/SCALE DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [149 133  34  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0996 0.0937 0.0919 0.0935 0.0844 0.0856 0.093  0.0854 0.0868 0.0943\n",
            " 0.0918], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09962322 0.0936678  0.09186751 0.09346451 0.08444133 0.08560022\n",
            " 0.0930418  0.08543108 0.08675347 0.09428632 0.09182273], argmax=0\n",
            "         |->> Overwriting action in buffer [00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000]\n",
            "   \u001b[33m|->> #5/t=41-th Action selection: 0/LEFT (P(a|s) = 0.09700000286102295)\u001b[0m\n",
            "      |->> Bounding box moves to: [148 133  34  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0973 0.0938 0.0921 0.0947 0.0861 0.0863 0.094  0.0863 0.0878 0.089\n",
            " 0.0927], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09733886 0.09381944 0.09211756 0.09472889 0.08607071 0.08631652\n",
            " 0.09396501 0.08625008 0.08776383 0.08897673 0.09265237], argmax=0\n",
            "         |->> Overwriting action in buffer [000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000]\n",
            "|->> Revisiting bbox: [148 133  34  72]. Action 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [144, 138,  36,  75] -> [148, 133,  34,  72] (Target was [146, 151,  34,  75])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X RIGHT:bbox transition: [144, 138,  36,  75] -> [146, 138,  36,  75] w/ P(a|s)=0.09726162999868393 and iou=0.6709102482495226 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for 2X RIGHT:bbox transition: [146, 138,  36,  75] -> [148, 138,  36,  75] w/ P(a|s)=0.09513121098279953 and iou=0.6074709124311084 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.0) for UP:bbox transition: [148, 138,  36,  75] -> [148, 136,  36,  75] w/ P(a|s)=0.08705878257751465 and iou=0.5765765765765766 and reward=0.0 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.0) for 2X UP:bbox transition: [148, 136,  36,  75] -> [148, 132,  36,  75] w/ P(a|s)=0.08675876259803772 and iou=0.5182186234817814 and reward=0.0 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (0.0) for SCALE DOWN:bbox transition: [148, 132,  36,  75] -> [149, 133,  34,  72] w/ P(a|s)=0.09428631514310837 and iou=0.5036101083032491 and reward=0.0 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (-1.0) for LEFT:bbox transition: [149, 133,  34,  72] -> [148, 133,  34,  72] w/ P(a|s)=0.09733885526657104 and iou=0.5284403669724771 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.        0.        0.        0.        0.       -2.329557]\n",
            "\u001b[31m>> Total frame loss: -2.329556941986084\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 10 with src: [148, 133,  34,  72] and target: [147, 150,  34,  75]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Doll/img/0011.jpg\n",
            "|->> Beginning tracking for bbox:[148 133  34  72]\n",
            "   \u001b[33m|->> #0/t=42-th Action selection: 3/2X RIGHT (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [150 133  34  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0888 0.0946 0.0975 0.0948 0.0871 0.0874 0.0934 0.0879 0.0884 0.089\n",
            " 0.091 ], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.08878794 0.09460066 0.09753947 0.09484483 0.08710048 0.08736902\n",
            " 0.09343006 0.08790887 0.0884032  0.08898505 0.0910304 ], argmax=2\n",
            "         |->> Overwriting action in buffer [\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000]\n",
            "   \u001b[33m|->> #1/t=43-th Action selection: 5/2X UP (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [150 129  34  72]\n",
            "         |->> Action Probabilities (Rounded): [0.1001 0.0949 0.0875 0.0938 0.0862 0.0871 0.0935 0.0865 0.0874 0.0905\n",
            " 0.0926], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.10005512 0.09492914 0.08747672 0.09383041 0.08618645 0.08709214\n",
            " 0.09350741 0.08645203 0.08736748 0.09051831 0.09258477], argmax=0\n",
            "         |->> Overwriting action in buffer [000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000]\n",
            "   \u001b[33m|->> #2/t=44-th Action selection: 5/2X UP (P(a|s) = 0.0860000029206276)\u001b[0m\n",
            "      |->> Bounding box moves to: [150 125  34  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0963 0.0945 0.0923 0.0935 0.0865 0.086  0.0934 0.0862 0.0882 0.0912\n",
            " 0.0919], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09628265 0.09449721 0.09229875 0.09347418 0.08654475 0.08601208\n",
            " 0.09338192 0.08621467 0.08815992 0.09120247 0.09193136], argmax=0\n",
            "         |->> Overwriting action in buffer [00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000]\n",
            "   \u001b[33m|->> #3/t=45-th Action selection: 5/2X UP (P(a|s) = 0.08500000089406967)\u001b[0m\n",
            "      |->> Bounding box moves to: [150 121  34  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0972 0.0941 0.09   0.0928 0.0868 0.0852 0.0937 0.0866 0.0891 0.0922\n",
            " 0.0924], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.09723818 0.0940768  0.09001575 0.0927566  0.08678644 0.08518054\n",
            " 0.09366721 0.08659486 0.08905368 0.09223655 0.09239342], argmax=0\n",
            "         |->> Overwriting action in buffer [00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000]\n",
            "|->> Revisiting bbox: [150 121  34  72]. Action 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [148, 133,  34,  72] -> [150, 121,  34,  72] (Target was [147, 150,  34,  75])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X RIGHT:bbox transition: [148, 133,  34,  72] -> [150, 133,  34,  72] w/ P(a|s)=0.09484483301639557 and iou=0.5177649559672032 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for 2X UP:bbox transition: [150, 133,  34,  72] -> [150, 129,  34,  72] w/ P(a|s)=0.08709213882684708 and iou=0.4626865671641791 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X UP:bbox transition: [150, 129,  34,  72] -> [150, 125,  34,  72] w/ P(a|s)=0.08601208031177521 and iou=0.41146568765885344 and reward=0.0 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-1.0) for 2X UP:bbox transition: [150, 125,  34,  72] -> [150, 121,  34,  72] w/ P(a|s)=0.08518054336309433 and iou=0.36371077762619375 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.         0.         0.        -2.4629822]\n",
            "\u001b[31m>> Total frame loss: -2.462982177734375\u001b[0m\n",
            "Final bounding box: [150 121  34  72] reached in 46 timesteps (originating from [146 150  32  73]). Target was [147 150  34  75]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 11 in t=46 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[92m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 0.7062897682189941\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.0004835197178181261\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 1.193392276763916\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.00029744862695224583\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 2.4836277961730957\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.0005556654068641365\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 5.156398773193359\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.0011028809240087867\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 20.73617172241211\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.016653260216116905\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 12.364849090576172\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 1.8945000171661377\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/Doll\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Starting bounding box=adnet_datasets/OTB/Doll/img/0012.jpg for adnet_datasets/OTB/Doll's frames (index: 0)\n",
            "src:adnet_datasets/OTB/Doll/img/0002.jpg\n",
            "target:adnet_datasets/OTB/Doll/img/0012.jpg.\n",
            "\u001b[34m>> Attempting to reach frame 2 with src: [147, 150,  32,  73] and target: [148, 150,  32,  73]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Doll/img/0003.jpg\n",
            "|->> Beginning tracking for bbox:[147 150  32  73]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 5/2X UP (P(a|s) = 0.07800000160932541)\u001b[0m\n",
            "      |->> Bounding box moves to: [147 146  32  73]\n",
            "         |->> Action Probabilities (Rounded): [0.1086 0.0987 0.0875 0.0904 0.0869 0.0779 0.0867 0.0846 0.0719 0.1159\n",
            " 0.0912], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.1085691  0.09869624 0.08746587 0.09037185 0.08687252 0.07785189\n",
            " 0.08670353 0.08457387 0.07186279 0.11585417 0.09117825], argmax=9\n",
            "         |->> Overwriting action in buffer [00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000]\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 5/2X UP (P(a|s) = 0.07599999755620956)\u001b[0m\n",
            "      |->> Bounding box moves to: [147 142  32  73]\n",
            "         |->> Action Probabilities (Rounded): [0.111  0.0998 0.087  0.089  0.0861 0.0759 0.0854 0.0857 0.0689 0.1205\n",
            " 0.0907], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.11098197 0.0997895  0.0870321  0.0889705  0.08608034 0.07591563\n",
            " 0.08543569 0.0856695  0.06892162 0.12049959 0.09070355], argmax=9\n",
            "         |->> Overwriting action in buffer [00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000]\n",
            "|->> Revisiting bbox: [147 142  32  73]. Action 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [147, 150,  32,  73] -> [147, 142,  32,  73] (Target was [148, 150,  32,  73])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X UP:bbox transition: [147, 150,  32,  73] -> [147, 146,  32,  73] w/ P(a|s)=0.07785189151763916 and iou=0.8444532175286222 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for 2X UP:bbox transition: [147, 146,  32,  73] -> [147, 142,  32,  73] w/ P(a|s)=0.07591562718153 and iou=0.7583741061347384 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.        2.5781326]\n",
            "\u001b[92m>> Total frame loss: 2.5781326293945312\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 3 with src: [147, 142,  32,  73] and target: [148, 150,  32,  74]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Doll/img/0004.jpg\n",
            "|->> Beginning tracking for bbox:[147 142  32  73]\n",
            "   \u001b[33m|->> #0/t=3-th Action selection: 7/2X DOWN (P(a|s) = 0.0820000022649765)\u001b[0m\n",
            "      |->> Bounding box moves to: [147 146  32  73]\n",
            "         |->> Action Probabilities (Rounded): [0.1097 0.1001 0.0893 0.0912 0.0852 0.075  0.0874 0.0816 0.0714 0.1172\n",
            " 0.0921], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.10969171 0.10005166 0.08929203 0.09115384 0.0851501  0.0749618\n",
            " 0.08743922 0.08161321 0.07139812 0.11719193 0.09205642], argmax=9\n",
            "         |->> Overwriting action in buffer [00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000]\n",
            "   \u001b[33m|->> #1/t=4-th Action selection: 9/SCALE DOWN (P(a|s) = 0.12200000137090683)\u001b[0m\n",
            "      |->> Bounding box moves to: [148 147  30  70]\n",
            "         |->> Action Probabilities (Rounded): [0.1112 0.1003 0.0879 0.0893 0.0859 0.0744 0.0856 0.084  0.0689 0.1215\n",
            " 0.0909], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.11119224 0.10032348 0.08789845 0.08933543 0.08589814 0.07436077\n",
            " 0.08564444 0.08397293 0.06892537 0.12152466 0.09092417], argmax=9\n",
            "         |->> Overwriting action in buffer [0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000]\n",
            "   \u001b[33m|->> #2/t=5-th Action selection: 1/2X LEFT (P(a|s) = 0.10100000351667404)\u001b[0m\n",
            "      |->> Bounding box moves to: [146 147  30  70]\n",
            "         |->> Action Probabilities (Rounded): [0.1108 0.101  0.087  0.0902 0.0866 0.0754 0.0858 0.0864 0.0697 0.1152\n",
            " 0.0917], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.11082327 0.10098547 0.08696991 0.09024587 0.08663389 0.07542079\n",
            " 0.08581955 0.08640926 0.06974023 0.11524852 0.09170323], argmax=9\n",
            "         |->> Overwriting action in buffer [000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000]\n",
            "   \u001b[33m|->> #3/t=6-th Action selection: 2/RIGHT (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [147 147  30  70]\n",
            "         |->> Action Probabilities (Rounded): [0.1104 0.0984 0.0871 0.0898 0.0871 0.0757 0.0862 0.0864 0.0698 0.1185\n",
            " 0.0908], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.11038763 0.09835815 0.08707711 0.08978535 0.08714443 0.07568599\n",
            " 0.08615727 0.0863616  0.06982011 0.11847169 0.0907507 ], argmax=9\n",
            "         |->> Overwriting action in buffer [0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000]\n",
            "   \u001b[33m|->> #4/t=7-th Action selection: 7/2X DOWN (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [147 151  30  70]\n",
            "         |->> Action Probabilities (Rounded): [0.1172 0.0985 0.0795 0.0908 0.0872 0.0767 0.087  0.0867 0.0704 0.115\n",
            " 0.091 ], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.11722256 0.09851664 0.0794755  0.09077096 0.08723731 0.07671808\n",
            " 0.08704336 0.08665035 0.07037761 0.11501741 0.09097015], argmax=0\n",
            "         |->> Overwriting action in buffer [00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000]\n",
            "   \u001b[33m|->> #5/t=8-th Action selection: 3/2X RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [149 151  30  70]\n",
            "         |->> Action Probabilities (Rounded): [0.1043 0.0987 0.0897 0.0906 0.0893 0.0772 0.0887 0.084  0.0731 0.1132\n",
            " 0.0912], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.10429199 0.09872686 0.08967772 0.0906352  0.08925842 0.07718729\n",
            " 0.08873654 0.08401558 0.07307228 0.11315066 0.09124742], argmax=9\n",
            "         |->> Overwriting action in buffer [0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000]\n",
            "   \u001b[33m|->> #6/t=9-th Action selection: 7/2X DOWN (P(a|s) = 0.08500000089406967)\u001b[0m\n",
            "      |->> Bounding box moves to: [149 155  30  70]\n",
            "         |->> Action Probabilities (Rounded): [0.1109 0.0992 0.0844 0.0896 0.0881 0.0778 0.0886 0.0849 0.0725 0.1133\n",
            " 0.0906], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.11090963 0.09918822 0.08444171 0.08959138 0.08814784 0.07776143\n",
            " 0.08861975 0.0849224  0.07247818 0.11329491 0.09064455], argmax=9\n",
            "         |->> Overwriting action in buffer [000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000]\n",
            "   \u001b[33m|->> #7/t=10-th Action selection: 6/DOWN (P(a|s) = 0.08500000089406967)\u001b[0m\n",
            "      |->> Bounding box moves to: [149 157  30  70]\n",
            "         |->> Action Probabilities (Rounded): [0.1119 0.0975 0.0844 0.09   0.0892 0.0776 0.0854 0.0901 0.0701 0.1162\n",
            " 0.0875], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.11191934 0.09748568 0.0843792  0.09003393 0.08916399 0.07760562\n",
            " 0.08544397 0.09011897 0.07008031 0.11624441 0.0875246 ], argmax=9\n",
            "         |->> Overwriting action in buffer [0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000000000]\n",
            "|->> Revisiting bbox: [149 155  30  70]. Action 4 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [147, 142,  32,  73] -> [149, 157,  30,  70] (Target was [148, 150,  32,  74])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X DOWN:bbox transition: [147, 142,  32,  73] -> [147, 146,  32,  73] w/ P(a|s)=0.0816132053732872 and iou=0.8339181286549707 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for SCALE DOWN:bbox transition: [147, 146,  32,  73] -> [148, 147,  30,  70] w/ P(a|s)=0.12152466177940369 and iou=0.8177379983726607 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X LEFT:bbox transition: [148, 147,  30,  70] -> [146, 147,  30,  70] w/ P(a|s)=0.10098546743392944 and iou=0.7237654320987654 and reward=0.0 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.0) for RIGHT:bbox transition: [146, 147,  30,  70] -> [147, 147,  30,  70] w/ P(a|s)=0.08707711100578308 and iou=0.7695049504950495 and reward=0.0 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (0.0) for 2X DOWN:bbox transition: [147, 147,  30,  70] -> [147, 151,  30,  70] w/ P(a|s)=0.08665034919977188 and iou=0.8326497128794094 and reward=0.0 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (0.0) for 2X RIGHT:bbox transition: [147, 151,  30,  70] -> [149, 151,  30,  70] w/ P(a|s)=0.09063520282506943 and iou=0.8868243243243243 and reward=0.0 and discount=1.0\n",
            "   |->> t=7 Diff-Reward (0.0) for 2X DOWN:bbox transition: [149, 151,  30,  70] -> [149, 155,  30,  70] w/ P(a|s)=0.08492240309715271 and iou=0.8632193494578816 and reward=0.0 and discount=1.0\n",
            "   |->> t=8 Diff-Reward (1.0) for DOWN:bbox transition: [149, 155,  30,  70] -> [149, 157,  30,  70] w/ P(a|s)=0.08544396609067917 and iou=0.8177379983726607 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.        0.        0.        0.        0.        0.        0.\n",
            " 2.4598944]\n",
            "\u001b[92m>> Total frame loss: 2.4598944187164307\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 4 with src: [149, 157,  30,  70] and target: [148, 150,  32,  73]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Doll/img/0005.jpg\n",
            "|->> Beginning tracking for bbox:[149 157  30  70]\n",
            "   \u001b[33m|->> #0/t=11-th Action selection: 9/SCALE DOWN (P(a|s) = 0.11500000208616257)\u001b[0m\n",
            "      |->> Bounding box moves to: [150 158  28  67]\n",
            "         |->> Action Probabilities (Rounded): [0.112  0.0992 0.0842 0.0896 0.0897 0.078  0.0842 0.0896 0.0705 0.1153\n",
            " 0.0877], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.11196721 0.09924747 0.08423104 0.08955594 0.08972064 0.07802338\n",
            " 0.08416358 0.0895613  0.07052765 0.1153278  0.08767401], argmax=9\n",
            "         |->> Overwriting action in buffer [000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000]\n",
            "   \u001b[33m|->> #1/t=12-th Action selection: 0/LEFT (P(a|s) = 0.10999999940395355)\u001b[0m\n",
            "      |->> Bounding box moves to: [149 158  28  67]\n",
            "         |->> Action Probabilities (Rounded): [0.1103 0.0992 0.0852 0.0907 0.0893 0.0799 0.0857 0.0909 0.0707 0.1097\n",
            " 0.0885], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.11026314 0.09918783 0.08516833 0.09066864 0.08933789 0.07986521\n",
            " 0.08574152 0.09088155 0.07072254 0.10965763 0.08850575], argmax=0\n",
            "         |->> Overwriting action in buffer [000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000]\n",
            "   \u001b[33m|->> #2/t=13-th Action selection: 3/2X RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [151 158  28  67]\n",
            "         |->> Action Probabilities (Rounded): [0.1031 0.1001 0.0898 0.0907 0.091  0.0811 0.085  0.0924 0.0703 0.1093\n",
            " 0.0871], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.10310917 0.10011201 0.08979165 0.09068242 0.0910292  0.08107436\n",
            " 0.08504252 0.09244738 0.07031381 0.10930345 0.08709398], argmax=9\n",
            "         |->> Overwriting action in buffer [\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000]\n",
            "|->> Revisiting bbox: [149 158  28  67]. Action 1 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [149, 157,  30,  70] -> [151, 158,  28,  67] (Target was [148, 150,  32,  73])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for SCALE DOWN:bbox transition: [149, 157,  30,  70] -> [150, 158,  28,  67] w/ P(a|s)=0.11532779783010483 and iou=0.7608695652173914 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for LEFT:bbox transition: [150, 158,  28,  67] -> [149, 158,  28,  67] w/ P(a|s)=0.11026313900947571 and iou=0.7608695652173914 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (1.0) for 2X RIGHT:bbox transition: [149, 158,  28,  67] -> [151, 158,  28,  67] w/ P(a|s)=0.09068242460489273 and iou=0.7608695652173914 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.        0.        2.4003918]\n",
            "\u001b[92m>> Total frame loss: 2.4003918170928955\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 5 with src: [151, 158,  28,  67] and target: [148, 150,  32,  73]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Doll/img/0006.jpg\n",
            "|->> Beginning tracking for bbox:[151 158  28  67]\n",
            "   \u001b[33m|->> #0/t=14-th Action selection: 5/2X UP (P(a|s) = 0.08100000023841858)\u001b[0m\n",
            "      |->> Bounding box moves to: [151 154  28  67]\n",
            "         |->> Action Probabilities (Rounded): [0.1133 0.0983 0.0811 0.0896 0.0895 0.0813 0.0856 0.0934 0.0693 0.1104\n",
            " 0.0881], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.11325891 0.09832563 0.08110057 0.08962037 0.08954954 0.08133738\n",
            " 0.08562968 0.09338    0.06930621 0.11036872 0.08812298], argmax=0\n",
            "         |->> Overwriting action in buffer [000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0]\n",
            "   \u001b[33m|->> #1/t=15-th Action selection: 0/LEFT (P(a|s) = 0.1080000028014183)\u001b[0m\n",
            "      |->> Bounding box moves to: [150 154  28  67]\n",
            "         |->> Action Probabilities (Rounded): [0.1079 0.0986 0.086  0.0896 0.0903 0.0788 0.0876 0.0896 0.0721 0.1111\n",
            " 0.0886], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.10785079 0.09863529 0.08595306 0.08958087 0.09025847 0.07875891\n",
            " 0.08758201 0.0896204  0.07205188 0.11109707 0.08861125], argmax=9\n",
            "         |->> Overwriting action in buffer [00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000]\n",
            "   \u001b[33m|->> #2/t=16-th Action selection: 10/SCALE UP (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [149 152  30  69]\n",
            "         |->> Action Probabilities (Rounded): [0.1031 0.0992 0.0899 0.091  0.0901 0.0794 0.0883 0.09   0.0724 0.1083\n",
            " 0.0884], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.10312949 0.0992419  0.08989982 0.09098088 0.09007065 0.07936963\n",
            " 0.08827654 0.08995055 0.07238974 0.10827296 0.08841786], argmax=9\n",
            "         |->> Overwriting action in buffer [\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000]\n",
            "   \u001b[33m|->> #3/t=17-th Action selection: 0/LEFT (P(a|s) = 0.11100000143051147)\u001b[0m\n",
            "      |->> Bounding box moves to: [148 152  30  69]\n",
            "         |->> Action Probabilities (Rounded): [0.1112 0.0989 0.0834 0.0925 0.0899 0.0794 0.0888 0.0877 0.0725 0.1112\n",
            " 0.0846], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.11115984 0.09887124 0.08338193 0.09247911 0.08990282 0.07935316\n",
            " 0.08882552 0.08772275 0.07253302 0.11118681 0.0845838 ], argmax=9\n",
            "         |->> Overwriting action in buffer [0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000]\n",
            "   \u001b[33m|->> #4/t=18-th Action selection: 5/2X UP (P(a|s) = 0.08100000023841858)\u001b[0m\n",
            "      |->> Bounding box moves to: [148 148  30  69]\n",
            "         |->> Action Probabilities (Rounded): [0.0991 0.0996 0.0941 0.0928 0.0897 0.0807 0.0896 0.0888 0.0724 0.107\n",
            " 0.0863], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.09910478 0.09960903 0.09405199 0.09277245 0.08968579 0.08067502\n",
            " 0.08960416 0.08882149 0.07237455 0.10702623 0.08627453], argmax=9\n",
            "         |->> Overwriting action in buffer [\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000]\n",
            "|->> Revisiting bbox: [148 148  30  69]. Action 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [151, 158,  28,  67] -> [148, 148,  30,  69] (Target was [148, 150,  32,  73])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X UP:bbox transition: [151, 158,  28,  67] -> [151, 154,  28,  67] w/ P(a|s)=0.08133738487958908 and iou=0.803082191780822 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for LEFT:bbox transition: [151, 154,  28,  67] -> [150, 154,  28,  67] w/ P(a|s)=0.10785079002380371 and iou=0.803082191780822 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.0) for SCALE UP:bbox transition: [150, 154,  28,  67] -> [149, 152,  30,  69] w/ P(a|s)=0.08841785788536072 and iou=0.8861301369863014 and reward=0.0 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.0) for LEFT:bbox transition: [149, 152,  30,  69] -> [148, 152,  30,  69] w/ P(a|s)=0.11115983873605728 and iou=0.8861301369863014 and reward=0.0 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (1.0) for 2X UP:bbox transition: [148, 152,  30,  69] -> [148, 148,  30,  69] w/ P(a|s)=0.08067502081394196 and iou=0.83889816360601 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.        0.        0.        0.        2.5173264]\n",
            "\u001b[92m>> Total frame loss: 2.5173263549804688\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 6 with src: [148, 148,  30,  69] and target: [147, 150,  33,  75]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Doll/img/0007.jpg\n",
            "|->> Beginning tracking for bbox:[148 148  30  69]\n",
            "   \u001b[33m|->> #0/t=19-th Action selection: 0/LEFT (P(a|s) = 0.11400000005960464)\u001b[0m\n",
            "      |->> Bounding box moves to: [147 148  30  69]\n",
            "         |->> Action Probabilities (Rounded): [0.1144 0.0992 0.0824 0.0918 0.0889 0.0777 0.0874 0.0895 0.0681 0.1145\n",
            " 0.0861], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.11438994 0.09921504 0.08239415 0.09179702 0.08888497 0.07770935\n",
            " 0.08736527 0.08948804 0.0681458  0.11450201 0.08610833], argmax=9\n",
            "         |->> Overwriting action in buffer [00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000]\n",
            "   \u001b[33m|->> #1/t=20-th Action selection: 6/DOWN (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [147 150  30  69]\n",
            "         |->> Action Probabilities (Rounded): [0.1003 0.0999 0.0953 0.0919 0.089  0.079  0.0881 0.0911 0.0685 0.1109\n",
            " 0.086 ], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.1002977  0.09993961 0.09532012 0.09185614 0.08902951 0.07896759\n",
            " 0.0881302  0.09110583 0.06847038 0.11085153 0.08603141], argmax=9\n",
            "         |->> Overwriting action in buffer [\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000]\n",
            "   \u001b[33m|->> #2/t=21-th Action selection: 7/2X DOWN (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [147 154  30  69]\n",
            "         |->> Action Probabilities (Rounded): [0.1174 0.0977 0.083  0.0918 0.0887 0.0786 0.0853 0.0914 0.0676 0.1125\n",
            " 0.0861], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.11737296 0.0977122  0.08295109 0.09183192 0.08869109 0.07859688\n",
            " 0.08528566 0.09144288 0.06760032 0.11245014 0.08606489], argmax=0\n",
            "         |->> Overwriting action in buffer [000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0]\n",
            "   \u001b[33m|->> #3/t=22-th Action selection: 7/2X DOWN (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [147 158  30  69]\n",
            "         |->> Action Probabilities (Rounded): [0.1099 0.0965 0.0896 0.093  0.0887 0.0787 0.0882 0.0888 0.0713 0.1099\n",
            " 0.0854], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.10989933 0.09652139 0.08964878 0.09297218 0.08871412 0.07868262\n",
            " 0.08816804 0.08878251 0.07125504 0.10992045 0.08543555], argmax=9\n",
            "         |->> Overwriting action in buffer [0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000]\n",
            "   \u001b[33m|->> #4/t=23-th Action selection: 0/LEFT (P(a|s) = 0.11500000208616257)\u001b[0m\n",
            "      |->> Bounding box moves to: [146 158  30  69]\n",
            "         |->> Action Probabilities (Rounded): [0.1146 0.0972 0.0849 0.0917 0.0894 0.0778 0.0853 0.0899 0.0698 0.1137\n",
            " 0.0858], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.11462306 0.09717833 0.08487858 0.09170148 0.08944631 0.07775179\n",
            " 0.08530551 0.08986273 0.06975346 0.11369979 0.08579894], argmax=0\n",
            "         |->> Overwriting action in buffer [0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000]\n",
            "   \u001b[33m|->> #5/t=24-th Action selection: 5/2X UP (P(a|s) = 0.07900000363588333)\u001b[0m\n",
            "      |->> Bounding box moves to: [146 154  30  69]\n",
            "         |->> Action Probabilities (Rounded): [0.1049 0.0975 0.0933 0.094  0.0889 0.0795 0.0863 0.0913 0.069  0.1106\n",
            " 0.0847], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.10485321 0.0975406  0.09326118 0.09404591 0.08886951 0.0794533\n",
            " 0.08633024 0.09129202 0.06898602 0.11064032 0.08472767], argmax=9\n",
            "         |->> Overwriting action in buffer [\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000]\n",
            "   \u001b[33m|->> #6/t=25-th Action selection: 10/SCALE UP (P(a|s) = 0.0860000029206276)\u001b[0m\n",
            "      |->> Bounding box moves to: [145 152  32  71]\n",
            "         |->> Action Probabilities (Rounded): [0.1149 0.0969 0.0848 0.0936 0.0897 0.0777 0.0873 0.0876 0.0709 0.1103\n",
            " 0.0864], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.11485513 0.09689088 0.08477074 0.09356646 0.08969793 0.07771032\n",
            " 0.08725351 0.08757957 0.07094194 0.11029001 0.08644349], argmax=0\n",
            "         |->> Overwriting action in buffer [00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000]\n",
            "   \u001b[33m|->> #7/t=26-th Action selection: 1/2X LEFT (P(a|s) = 0.09799999743700027)\u001b[0m\n",
            "      |->> Bounding box moves to: [143 152  32  71]\n",
            "         |->> Action Probabilities (Rounded): [0.1089 0.0983 0.0891 0.0936 0.0896 0.0779 0.0885 0.0864 0.0708 0.1148\n",
            " 0.0821], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.10885951 0.09827499 0.0891402  0.09359097 0.0895515  0.07791167\n",
            " 0.08854193 0.08640682 0.07082238 0.11477917 0.08212082], argmax=9\n",
            "         |->> Overwriting action in buffer [0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m]\n",
            "   \u001b[33m|->> #8/t=27-th Action selection: 4/UP (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [143 150  32  71]\n",
            "         |->> Action Probabilities (Rounded): [0.1126 0.0953 0.0875 0.0933 0.09   0.0773 0.0884 0.087  0.0716 0.1114\n",
            " 0.0855], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.11262167 0.09527262 0.08752263 0.09331203 0.09000154 0.07733005\n",
            " 0.08844309 0.08704668 0.07157585 0.11135225 0.08552156], argmax=0\n",
            "         |->> Overwriting action in buffer [0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000]\n",
            "   \u001b[33m|->> #9/t=28-th Action selection: 10/SCALE UP (P(a|s) = 0.08500000089406967)\u001b[0m\n",
            "      |->> Bounding box moves to: [142 148  34  73]\n",
            "         |->> Action Probabilities (Rounded): [0.1115 0.097  0.0882 0.0923 0.0867 0.0778 0.0882 0.0876 0.0701 0.1154\n",
            " 0.0852], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.11147099 0.09704295 0.08820055 0.09231588 0.08670031 0.07780094\n",
            " 0.088155   0.08755738 0.07012185 0.11541814 0.08521605], argmax=9\n",
            "         |->> Overwriting action in buffer [0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000]\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [148, 148,  30,  69] -> [142, 148,  34,  73] (Target was [147, 150,  33,  75])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for LEFT:bbox transition: [148, 148,  30,  69] -> [147, 148,  30,  69] w/ P(a|s)=0.11438994109630585 and iou=0.7928994082840237 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for DOWN:bbox transition: [147, 148,  30,  69] -> [147, 150,  30,  69] w/ P(a|s)=0.08813019841909409 and iou=0.8363636363636363 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X DOWN:bbox transition: [147, 150,  30,  69] -> [147, 154,  30,  69] w/ P(a|s)=0.09144288301467896 and iou=0.8363636363636363 and reward=0.0 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.0) for 2X DOWN:bbox transition: [147, 154,  30,  69] -> [147, 158,  30,  69] w/ P(a|s)=0.08878251165151596 and iou=0.7928994082840237 and reward=0.0 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (0.0) for LEFT:bbox transition: [147, 158,  30,  69] -> [146, 158,  30,  69] w/ P(a|s)=0.114623062312603 and iou=0.7467332820906994 and reward=0.0 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (0.0) for 2X UP:bbox transition: [146, 158,  30,  69] -> [146, 154,  30,  69] w/ P(a|s)=0.07945330440998077 and iou=0.7865566037735849 and reward=0.0 and discount=1.0\n",
            "   |->> t=7 Diff-Reward (0.0) for SCALE UP:bbox transition: [146, 154,  30,  69] -> [145, 152,  32,  71] w/ P(a|s)=0.08644349128007889 and iou=0.8139090561711884 and reward=0.0 and discount=1.0\n",
            "   |->> t=8 Diff-Reward (0.0) for 2X LEFT:bbox transition: [145, 152,  32,  71] -> [143, 152,  32,  71] w/ P(a|s)=0.09827499091625214 and iou=0.7205509242479159 and reward=0.0 and discount=1.0\n",
            "   |->> t=9 Diff-Reward (0.0) for UP:bbox transition: [143, 152,  32,  71] -> [143, 150,  32,  71] w/ P(a|s)=0.09000153839588165 and iou=0.7205509242479159 and reward=0.0 and discount=1.0\n",
            "   |->> t=10 Diff-Reward (1.0) for SCALE UP:bbox transition: [143, 150,  32,  71] -> [142, 148,  34,  73] w/ P(a|s)=0.08521605283021927 and iou=0.7104899930986888 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.        0.        0.        0.        0.        0.        0.\n",
            " 0.        0.        2.4625654]\n",
            "\u001b[92m>> Total frame loss: 2.4625654220581055\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 7 with src: [142, 148,  34,  73] and target: [147, 150,  33,  76]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Doll/img/0008.jpg\n",
            "|->> Beginning tracking for bbox:[142 148  34  73]\n",
            "   \u001b[33m|->> #0/t=29-th Action selection: 5/2X UP (P(a|s) = 0.07800000160932541)\u001b[0m\n",
            "      |->> Bounding box moves to: [142 144  34  73]\n",
            "         |->> Action Probabilities (Rounded): [0.1143 0.0979 0.0857 0.0919 0.0883 0.0782 0.0864 0.0893 0.0676 0.12\n",
            " 0.0805], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.1142775  0.09789565 0.08574925 0.09186684 0.0883036  0.07815091\n",
            " 0.08637898 0.08926964 0.0675938  0.11998212 0.08053166], argmax=9\n",
            "         |->> Overwriting action in buffer [0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000]\n",
            "   \u001b[33m|->> #1/t=30-th Action selection: 2/RIGHT (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [143 144  34  73]\n",
            "         |->> Action Probabilities (Rounded): [0.112  0.0989 0.0865 0.0918 0.0875 0.0767 0.0873 0.0884 0.0678 0.1195\n",
            " 0.0835], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.11202108 0.09889344 0.08654112 0.0918026  0.0875119  0.07672261\n",
            " 0.08725849 0.08841155 0.06778422 0.11951227 0.08354073], argmax=9\n",
            "         |->> Overwriting action in buffer [00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000]\n",
            "   \u001b[33m|->> #2/t=31-th Action selection: 6/DOWN (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [143 146  34  73]\n",
            "         |->> Action Probabilities (Rounded): [0.1195 0.0987 0.0794 0.0931 0.0875 0.0772 0.0868 0.0884 0.0681 0.1188\n",
            " 0.0826], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.11951687 0.09866112 0.07942192 0.0930649  0.08746483 0.07721549\n",
            " 0.08676497 0.08837084 0.06806958 0.11881097 0.08263857], argmax=0\n",
            "         |->> Overwriting action in buffer [00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000]\n",
            "   \u001b[33m|->> #3/t=32-th Action selection: 7/2X DOWN (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [143 150  34  73]\n",
            "         |->> Action Probabilities (Rounded): [0.1118 0.1002 0.0877 0.0899 0.089  0.0776 0.0844 0.0904 0.0653 0.1207\n",
            " 0.083 ], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.11183199 0.10020138 0.08773156 0.08985049 0.08900729 0.07760423\n",
            " 0.08441074 0.09042951 0.06526264 0.1206567  0.08301342], argmax=9\n",
            "         |->> Overwriting action in buffer [000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000]\n",
            "   \u001b[33m|->> #4/t=33-th Action selection: 4/UP (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [143 148  34  73]\n",
            "         |->> Action Probabilities (Rounded): [0.1133 0.0984 0.0851 0.0914 0.0889 0.0773 0.0881 0.0873 0.0699 0.1162\n",
            " 0.0841], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.11330958 0.0983993  0.08512825 0.09137525 0.08891304 0.07730651\n",
            " 0.08806781 0.08728623 0.06991409 0.11622916 0.08407079], argmax=9\n",
            "         |->> Overwriting action in buffer [0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000]\n",
            "|->> Revisiting bbox: [143 146  34  73]. Action 4 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [142, 148,  34,  73] -> [143, 148,  34,  73] (Target was [147, 150,  33,  76])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X UP:bbox transition: [142, 148,  34,  73] -> [142, 144,  34,  73] w/ P(a|s)=0.0781509131193161 and iou=0.6376764030193633 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for RIGHT:bbox transition: [142, 144,  34,  73] -> [143, 144,  34,  73] w/ P(a|s)=0.08654112368822098 and iou=0.674496644295302 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.0) for DOWN:bbox transition: [143, 144,  34,  73] -> [143, 146,  34,  73] w/ P(a|s)=0.08676496893167496 and iou=0.708904109589041 and reward=0.0 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.0) for 2X DOWN:bbox transition: [143, 146,  34,  73] -> [143, 150,  34,  73] w/ P(a|s)=0.09042951464653015 and iou=0.7821428571428571 and reward=0.0 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (1.0) for UP:bbox transition: [143, 150,  34,  73] -> [143, 148,  34,  73] w/ P(a|s)=0.08891303837299347 and iou=0.7447552447552448 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.        0.        0.        0.        2.4200964]\n",
            "\u001b[92m>> Total frame loss: 2.4200963973999023\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 8 with src: [143, 148,  34,  73] and target: [147, 150,  33,  76]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Doll/img/0009.jpg\n",
            "|->> Beginning tracking for bbox:[143 148  34  73]\n",
            "   \u001b[33m|->> #0/t=34-th Action selection: 3/2X RIGHT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [145 148  34  73]\n",
            "         |->> Action Probabilities (Rounded): [0.1097 0.1009 0.0866 0.0901 0.0867 0.0777 0.086  0.0894 0.0682 0.1203\n",
            " 0.0844], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.10968301 0.10090203 0.08663833 0.09007663 0.08670765 0.07770422\n",
            " 0.0860044  0.08938637 0.06818496 0.12028306 0.08442933], argmax=9\n",
            "         |->> Overwriting action in buffer [0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000]\n",
            "|->> Revisiting bbox: [145 148  34  73]. Action 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [143, 148,  34,  73] -> [145, 148,  34,  73] (Target was [147, 150,  33,  76])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for 2X RIGHT:bbox transition: [143, 148,  34,  73] -> [145, 148,  34,  73] w/ P(a|s)=0.09007663279771805 and iou=0.8359087564385578 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [2.4070945]\n",
            "\u001b[92m>> Total frame loss: 2.4070944786071777\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 9 with src: [145, 148,  34,  73] and target: [146, 151,  34,  75]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Doll/img/0010.jpg\n",
            "|->> Beginning tracking for bbox:[145 148  34  73]\n",
            "   \u001b[33m|->> #0/t=35-th Action selection: 4/UP (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [145 146  34  73]\n",
            "         |->> Action Probabilities (Rounded): [0.1122 0.1014 0.0853 0.0888 0.087  0.0774 0.0869 0.086  0.0681 0.1207\n",
            " 0.0862], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.11223631 0.101355   0.08529157 0.08882734 0.08700257 0.07740004\n",
            " 0.08686525 0.08602761 0.06807708 0.12073792 0.0861793 ], argmax=9\n",
            "         |->> Overwriting action in buffer [000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m]\n",
            "   \u001b[33m|->> #1/t=36-th Action selection: 9/SCALE DOWN (P(a|s) = 0.11800000071525574)\u001b[0m\n",
            "      |->> Bounding box moves to: [146 147  32  70]\n",
            "         |->> Action Probabilities (Rounded): [0.11   0.1013 0.0864 0.089  0.0859 0.0781 0.0887 0.0859 0.0693 0.1179\n",
            " 0.0876], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.10995743 0.10126898 0.08635093 0.08898185 0.08587999 0.07810964\n",
            " 0.08872442 0.0858621  0.06934012 0.11787705 0.08764739], argmax=9\n",
            "         |->> Overwriting action in buffer [0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000]\n",
            "   \u001b[33m|->> #2/t=37-th Action selection: 1/2X LEFT (P(a|s) = 0.10300000011920929)\u001b[0m\n",
            "      |->> Bounding box moves to: [144 147  32  70]\n",
            "         |->> Action Probabilities (Rounded): [0.112  0.1027 0.0853 0.0893 0.0879 0.0778 0.0872 0.0874 0.0688 0.113\n",
            " 0.0886], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.11195604 0.10274672 0.08533151 0.08926547 0.08793961 0.07784356\n",
            " 0.08715203 0.08743732 0.06875    0.11295272 0.08862502], argmax=9\n",
            "         |->> Overwriting action in buffer [000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000]\n",
            "   \u001b[33m|->> #3/t=38-th Action selection: 0/LEFT (P(a|s) = 0.11100000143051147)\u001b[0m\n",
            "      |->> Bounding box moves to: [143 147  32  70]\n",
            "         |->> Action Probabilities (Rounded): [0.1113 0.0999 0.0852 0.0888 0.0882 0.0778 0.0878 0.089  0.068  0.1167\n",
            " 0.0873], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.11128531 0.09989941 0.08524171 0.08881903 0.08818157 0.07781448\n",
            " 0.08781254 0.08900852 0.06799175 0.11669053 0.08725522], argmax=9\n",
            "         |->> Overwriting action in buffer [0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m]\n",
            "   \u001b[33m|->> #4/t=39-th Action selection: 0/LEFT (P(a|s) = 0.10400000214576721)\u001b[0m\n",
            "      |->> Bounding box moves to: [142 147  32  70]\n",
            "         |->> Action Probabilities (Rounded): [0.1041 0.1008 0.0915 0.0897 0.088  0.0802 0.0865 0.0913 0.0665 0.1132\n",
            " 0.0882], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.10408327 0.10084044 0.091543   0.08968875 0.08796182 0.08020891\n",
            " 0.08650749 0.09126139 0.06654233 0.11318706 0.08817562], argmax=9\n",
            "         |->> Overwriting action in buffer [\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000]\n",
            "   \u001b[33m|->> #5/t=40-th Action selection: 9/SCALE DOWN (P(a|s) = 0.1120000034570694)\u001b[0m\n",
            "      |->> Bounding box moves to: [143 148  30  67]\n",
            "         |->> Action Probabilities (Rounded): [0.104  0.1    0.089  0.0907 0.0892 0.08   0.0882 0.0911 0.0673 0.112\n",
            " 0.0885], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.10397916 0.09996676 0.08900827 0.09072392 0.08921598 0.07999452\n",
            " 0.08818401 0.09113511 0.06730417 0.11200855 0.08847951], argmax=9\n",
            "         |->> Overwriting action in buffer [\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000]\n",
            "|->> Revisiting bbox: [143 148  30  67]. Action 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [145, 148,  34,  73] -> [143, 148,  30,  67] (Target was [146, 151,  34,  75])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for UP:bbox transition: [145, 148,  34,  73] -> [145, 146,  34,  73] w/ P(a|s)=0.08700256794691086 and iou=0.8048780487804879 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for SCALE DOWN:bbox transition: [145, 146,  34,  73] -> [146, 147,  32,  70] w/ P(a|s)=0.1178770512342453 and iou=0.7886482449589246 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X LEFT:bbox transition: [146, 147,  32,  70] -> [144, 147,  32,  70] w/ P(a|s)=0.10274671763181686 and iou=0.7046263345195729 and reward=0.0 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.0) for LEFT:bbox transition: [144, 147,  32,  70] -> [143, 147,  32,  70] w/ P(a|s)=0.11128531396389008 and iou=0.6655076495132128 and reward=0.0 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (0.0) for LEFT:bbox transition: [143, 147,  32,  70] -> [142, 147,  32,  70] w/ P(a|s)=0.10408326983451843 and iou=0.628144119646499 and reward=0.0 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [142, 147,  32,  70] -> [143, 148,  30,  67] w/ P(a|s)=0.11200854927301407 and iou=0.6101694915254238 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.         0.         0.         0.         0.        -2.1891801]\n",
            "\u001b[31m>> Total frame loss: -2.1891801357269287\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 10 with src: [143, 148,  30,  67] and target: [147, 150,  34,  75]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Doll/img/0011.jpg\n",
            "|->> Beginning tracking for bbox:[143 148  30  67]\n",
            "   \u001b[33m|->> #0/t=41-th Action selection: 9/SCALE DOWN (P(a|s) = 0.10700000077486038)\u001b[0m\n",
            "      |->> Bounding box moves to: [144 149  28  64]\n",
            "         |->> Action Probabilities (Rounded): [0.1101 0.0993 0.085  0.0914 0.0897 0.0802 0.088  0.0913 0.0675 0.1073\n",
            " 0.0902], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.11009093 0.09934027 0.08498    0.09140175 0.08967234 0.08022279\n",
            " 0.08797614 0.09127307 0.06749119 0.10732017 0.09023131], argmax=0\n",
            "         |->> Overwriting action in buffer [000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000]\n",
            "   \u001b[33m|->> #1/t=42-th Action selection: 2/RIGHT (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [145 149  28  64]\n",
            "         |->> Action Probabilities (Rounded): [0.1098 0.0989 0.0871 0.0919 0.0894 0.0807 0.0882 0.0927 0.0676 0.1042\n",
            " 0.0896], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.10980076 0.09891393 0.0870969  0.09186743 0.0894103  0.08065849\n",
            " 0.08816627 0.09272946 0.06760279 0.10415283 0.08960085], argmax=0\n",
            "         |->> Overwriting action in buffer [000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000]\n",
            "   \u001b[33m|->> #2/t=43-th Action selection: 6/DOWN (P(a|s) = 0.0860000029206276)\u001b[0m\n",
            "      |->> Bounding box moves to: [145 150  28  64]\n",
            "         |->> Action Probabilities (Rounded): [0.1223 0.0979 0.0772 0.0917 0.0882 0.0823 0.0862 0.0949 0.0661 0.1056\n",
            " 0.0876], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.12225609 0.09793074 0.07719504 0.09172717 0.08816122 0.08228918\n",
            " 0.08623778 0.09492422 0.06606505 0.10563439 0.08757915], argmax=0\n",
            "         |->> Overwriting action in buffer [00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000]\n",
            "   \u001b[33m|->> #3/t=44-th Action selection: 10/SCALE UP (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [144 149  30  66]\n",
            "         |->> Action Probabilities (Rounded): [0.1109 0.0991 0.0871 0.0902 0.0899 0.0827 0.0838 0.0957 0.0654 0.1076\n",
            " 0.0877], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.11088962 0.09905907 0.08712735 0.0901541  0.08992712 0.08271026\n",
            " 0.08384921 0.09569528 0.06536556 0.10755443 0.08766807], argmax=0\n",
            "         |->> Overwriting action in buffer [000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000]\n",
            "   \u001b[33m|->> #4/t=45-th Action selection: 5/2X UP (P(a|s) = 0.08299999684095383)\u001b[0m\n",
            "      |->> Bounding box moves to: [144 147  30  66]\n",
            "         |->> Action Probabilities (Rounded): [0.1158 0.0992 0.0838 0.0909 0.0883 0.0826 0.0859 0.0947 0.0658 0.1108\n",
            " 0.0822], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.11584128 0.09919421 0.08383734 0.09086277 0.08827987 0.08259014\n",
            " 0.08588864 0.09474719 0.06575856 0.11084557 0.08215445], argmax=0\n",
            "         |->> Overwriting action in buffer [0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000]\n",
            "   \u001b[33m|->> #5/t=46-th Action selection: 4/UP (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [144 146  30  66]\n",
            "         |->> Action Probabilities (Rounded): [0.1096 0.0997 0.0883 0.0921 0.0894 0.0803 0.0871 0.0912 0.0687 0.1076\n",
            " 0.0861], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.1096323  0.09971709 0.08829211 0.09206677 0.08941437 0.08027619\n",
            " 0.08708722 0.09117001 0.06865238 0.10763524 0.0860564 ], argmax=0\n",
            "         |->> Overwriting action in buffer [00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0]\n",
            "   \u001b[33m|->> #6/t=47-th Action selection: 9/SCALE DOWN (P(a|s) = 0.10899999737739563)\u001b[0m\n",
            "      |->> Bounding box moves to: [145 147  28  64]\n",
            "         |->> Action Probabilities (Rounded): [0.1136 0.0994 0.0878 0.0928 0.0858 0.0792 0.089  0.0893 0.0689 0.1092\n",
            " 0.085 ], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.11359489 0.09939905 0.0878007  0.09284709 0.08579868 0.07915721\n",
            " 0.08895669 0.08933183 0.06892356 0.10923921 0.08495104], argmax=0\n",
            "         |->> Overwriting action in buffer [0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000]\n",
            "   \u001b[33m|->> #7/t=48-th Action selection: 4/UP (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [145 146  28  64]\n",
            "         |->> Action Probabilities (Rounded): [0.1119 0.1008 0.088  0.0927 0.0876 0.08   0.0883 0.0903 0.0702 0.1028\n",
            " 0.0872], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.11185601 0.10084457 0.08802277 0.09272895 0.08758462 0.0800204\n",
            " 0.08833745 0.09029644 0.07024163 0.10283766 0.08722955], argmax=0\n",
            "         |->> Overwriting action in buffer [000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000]\n",
            "   \u001b[33m|->> #8/t=49-th Action selection: 9/SCALE DOWN (P(a|s) = 0.10700000077486038)\u001b[0m\n",
            "      |->> Bounding box moves to: [146 147  26  62]\n",
            "         |->> Action Probabilities (Rounded): [0.1119 0.1016 0.0871 0.0924 0.0856 0.0791 0.0892 0.0892 0.0701 0.1072\n",
            " 0.0865], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.11190899 0.10156646 0.08707047 0.09243201 0.08555885 0.07913476\n",
            " 0.08924838 0.08924926 0.07013341 0.10723042 0.08646693], argmax=0\n",
            "         |->> Overwriting action in buffer [0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000]\n",
            "   \u001b[33m|->> #9/t=50-th Action selection: 3/2X RIGHT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [148 147  26  62]\n",
            "         |->> Action Probabilities (Rounded): [0.1087 0.1028 0.0866 0.0932 0.0877 0.0793 0.0883 0.0902 0.0708 0.103\n",
            " 0.0893], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.10874168 0.1027725  0.0865789  0.09319036 0.08768865 0.07931115\n",
            " 0.08832082 0.09023353 0.07081858 0.10302267 0.08932115], argmax=0\n",
            "         |->> Overwriting action in buffer [000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0]\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [143, 148,  30,  67] -> [148, 147,  26,  62] (Target was [147, 150,  34,  75])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for SCALE DOWN:bbox transition: [143, 148,  30,  67] -> [144, 149,  28,  64] w/ P(a|s)=0.10732016712427139 and iou=0.5692085290928803 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for RIGHT:bbox transition: [144, 149,  28,  64] -> [145, 149,  28,  64] w/ P(a|s)=0.08709689974784851 and iou=0.6057692307692307 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.0) for DOWN:bbox transition: [145, 149,  28,  64] -> [145, 150,  28,  64] w/ P(a|s)=0.08623778074979782 and iou=0.6213592233009708 and reward=0.0 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.0) for SCALE UP:bbox transition: [145, 150,  28,  64] -> [144, 149,  30,  66] w/ P(a|s)=0.08766806870698929 and iou=0.6324324324324324 and reward=0.0 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (0.0) for 2X UP:bbox transition: [144, 149,  30,  66] -> [144, 147,  30,  66] w/ P(a|s)=0.08259014040231705 and iou=0.601272534464475 and reward=0.0 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (0.0) for UP:bbox transition: [144, 147,  30,  66] -> [144, 146,  30,  66] w/ P(a|s)=0.08941437304019928 and iou=0.5861344537815126 and reward=0.0 and discount=1.0\n",
            "   |->> t=7 Diff-Reward (0.0) for SCALE DOWN:bbox transition: [144, 146,  30,  66] -> [145, 147,  28,  64] w/ P(a|s)=0.10923921316862106 and iou=0.5754716981132075 and reward=0.0 and discount=1.0\n",
            "   |->> t=8 Diff-Reward (0.0) for UP:bbox transition: [145, 147,  28,  64] -> [145, 146,  28,  64] w/ P(a|s)=0.08758462220430374 and iou=0.5607476635514018 and reward=0.0 and discount=1.0\n",
            "   |->> t=9 Diff-Reward (0.0) for SCALE DOWN:bbox transition: [145, 146,  28,  64] -> [146, 147,  26,  62] w/ P(a|s)=0.10723042488098145 and iou=0.5489393375511723 and reward=0.0 and discount=1.0\n",
            "   |->> t=10 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [146, 147,  26,  62] -> [148, 147,  26,  62] w/ P(a|s)=0.09319035708904266 and iou=0.5837138508371386 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.        0.        0.        0.        0.        0.        0.\n",
            "  0.        0.       -2.373111]\n",
            "\u001b[31m>> Total frame loss: -2.3731110095977783\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 11 with src: [148, 147,  26,  62] and target: [148, 151,  33,  75]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Doll/img/0012.jpg\n",
            "|->> Beginning tracking for bbox:[148 147  26  62]\n",
            "   \u001b[33m|->> #0/t=51-th Action selection: 5/2X UP (P(a|s) = 0.07999999821186066)\u001b[0m\n",
            "      |->> Bounding box moves to: [148 145  26  62]\n",
            "         |->> Action Probabilities (Rounded): [0.1092 0.1023 0.0855 0.0896 0.0875 0.0796 0.0884 0.0901 0.0706 0.1092\n",
            " 0.088 ], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.10921786 0.10228253 0.08546212 0.08960093 0.08747422 0.07964044\n",
            " 0.08837094 0.0901276  0.07060087 0.10920159 0.08802085], argmax=0\n",
            "         |->> Overwriting action in buffer [000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0]\n",
            "   \u001b[33m|->> #1/t=52-th Action selection: 0/LEFT (P(a|s) = 0.11100000143051147)\u001b[0m\n",
            "      |->> Bounding box moves to: [147 145  26  62]\n",
            "         |->> Action Probabilities (Rounded): [0.1115 0.1022 0.0849 0.0897 0.0878 0.0768 0.0872 0.089  0.0687 0.1135\n",
            " 0.0887], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.11145309 0.10215411 0.08488006 0.08971874 0.08775954 0.07679613\n",
            " 0.08723204 0.0890319  0.0686878  0.11353838 0.0887483 ], argmax=9\n",
            "         |->> Overwriting action in buffer [00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m00\u001b[35m1\u001b[0m00000000]\n",
            "   \u001b[33m|->> #2/t=53-th Action selection: 1/2X LEFT (P(a|s) = 0.10300000011920929)\u001b[0m\n",
            "      |->> Bounding box moves to: [145 145  26  62]\n",
            "         |->> Action Probabilities (Rounded): [0.1018 0.1029 0.0916 0.0906 0.0875 0.0781 0.0885 0.0898 0.0687 0.1121\n",
            " 0.0884], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.10178635 0.10285959 0.09157248 0.09059687 0.08748248 0.07809722\n",
            " 0.08854103 0.08977206 0.06873458 0.11213601 0.08842134], argmax=9\n",
            "         |->> Overwriting action in buffer [\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000]\n",
            "   \u001b[33m|->> #3/t=54-th Action selection: 0/LEFT (P(a|s) = 0.1120000034570694)\u001b[0m\n",
            "      |->> Bounding box moves to: [144 145  26  62]\n",
            "         |->> Action Probabilities (Rounded): [0.1124 0.0987 0.084  0.0917 0.0876 0.0772 0.0882 0.0886 0.0694 0.1132\n",
            " 0.0891], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.11237369 0.098679   0.08395464 0.09173005 0.08763514 0.07718909\n",
            " 0.08816811 0.08856466 0.06938574 0.11321566 0.08910429], argmax=9\n",
            "         |->> Overwriting action in buffer [0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m]\n",
            "   \u001b[33m|->> #4/t=55-th Action selection: 6/DOWN (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [144 146  26  62]\n",
            "         |->> Action Probabilities (Rounded): [0.0993 0.1001 0.0957 0.0923 0.0876 0.0784 0.09   0.088  0.0696 0.1089\n",
            " 0.09  ], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.09929743 0.10007811 0.09569115 0.09231228 0.08761418 0.07843705\n",
            " 0.09003022 0.08800914 0.06956593 0.10894949 0.09001496], argmax=9\n",
            "         |->> Overwriting action in buffer [\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000]\n",
            "   \u001b[33m|->> #5/t=56-th Action selection: 1/2X LEFT (P(a|s) = 0.09799999743700027)\u001b[0m\n",
            "      |->> Bounding box moves to: [142 146  26  62]\n",
            "         |->> Action Probabilities (Rounded): [0.1131 0.0979 0.0834 0.0934 0.0892 0.0784 0.0871 0.0883 0.0694 0.11\n",
            " 0.0897], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.1131281  0.09792153 0.08340149 0.09344497 0.08919165 0.07837311\n",
            " 0.08707105 0.08830646 0.06938358 0.11004873 0.08972932], argmax=0\n",
            "         |->> Overwriting action in buffer [000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000]\n",
            "   \u001b[33m|->> #6/t=57-th Action selection: 10/SCALE UP (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [141 145  28  64]\n",
            "         |->> Action Probabilities (Rounded): [0.1055 0.0961 0.0915 0.0921 0.0881 0.0802 0.0898 0.0878 0.0704 0.1081\n",
            " 0.0904], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.10552783 0.09612722 0.09149738 0.09207269 0.08806201 0.08024182\n",
            " 0.08984294 0.08776064 0.07043613 0.10805978 0.09037159], argmax=9\n",
            "         |->> Overwriting action in buffer [0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0]\n",
            "   \u001b[33m|->> #7/t=58-th Action selection: 7/2X DOWN (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [141 147  28  64]\n",
            "         |->> Action Probabilities (Rounded): [0.11   0.0961 0.0874 0.0922 0.0889 0.0805 0.0893 0.088  0.0706 0.1122\n",
            " 0.085 ], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.10997259 0.0960661  0.08735596 0.09221216 0.08886147 0.0804886\n",
            " 0.089305   0.08796494 0.0705932  0.11222161 0.0849584 ], argmax=9\n",
            "         |->> Overwriting action in buffer [0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0000\u001b[35m1\u001b[0m000000]\n",
            "   \u001b[33m|->> #8/t=59-th Action selection: 0/LEFT (P(a|s) = 0.1080000028014183)\u001b[0m\n",
            "      |->> Bounding box moves to: [140 147  28  64]\n",
            "         |->> Action Probabilities (Rounded): [0.1077 0.0958 0.0897 0.0927 0.0889 0.0806 0.0901 0.0867 0.0714 0.1095\n",
            " 0.0869], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.10765987 0.09580436 0.08970312 0.0927413  0.08891907 0.08056042\n",
            " 0.09012646 0.08668198 0.07135599 0.1095323  0.08691513], argmax=9\n",
            "         |->> Overwriting action in buffer [0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0]\n",
            "   \u001b[33m|->> #9/t=60-th Action selection: 0/LEFT (P(a|s) = 0.0989999994635582)\u001b[0m\n",
            "      |->> Bounding box moves to: [139 147  28  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0991 0.0966 0.0954 0.0934 0.0887 0.0821 0.0903 0.0869 0.0727 0.1081\n",
            " 0.0865], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.09912022 0.09664555 0.0954443  0.09343676 0.08871938 0.08213735\n",
            " 0.0902929  0.08694075 0.072682   0.10811386 0.08646698], argmax=9\n",
            "         |->> Overwriting action in buffer [\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000]\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [148, 147,  26,  62] -> [139, 147,  28,  64] (Target was [148, 151,  33,  75])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X UP:bbox transition: [148, 147,  26,  62] -> [148, 145,  26,  62] w/ P(a|s)=0.07964044064283371 and iou=0.5534017483846446 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for LEFT:bbox transition: [148, 145,  26,  62] -> [147, 145,  26,  62] w/ P(a|s)=0.1114530861377716 and iou=0.5210271678451805 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X LEFT:bbox transition: [147, 145,  26,  62] -> [145, 145,  26,  62] w/ P(a|s)=0.10285959392786026 and iou=0.4601643444087174 and reward=0.0 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.0) for LEFT:bbox transition: [145, 145,  26,  62] -> [144, 145,  26,  62] w/ P(a|s)=0.11237368732690811 and iou=0.431523642732049 and reward=0.0 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (0.0) for DOWN:bbox transition: [144, 145,  26,  62] -> [144, 146,  26,  62] w/ P(a|s)=0.09003022313117981 and iou=0.4426403106247794 and reward=0.0 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (0.0) for 2X LEFT:bbox transition: [144, 146,  26,  62] -> [142, 146,  26,  62] w/ P(a|s)=0.09792152792215347 and iou=0.3868340685442823 and reward=0.0 and discount=1.0\n",
            "   |->> t=7 Diff-Reward (0.0) for SCALE UP:bbox transition: [142, 146,  26,  62] -> [141, 145,  28,  64] w/ P(a|s)=0.09037158638238907 and iou=0.39947523778287963 and reward=0.0 and discount=1.0\n",
            "   |->> t=8 Diff-Reward (0.0) for 2X DOWN:bbox transition: [141, 145,  28,  64] -> [141, 147,  28,  64] w/ P(a|s)=0.08796494454145432 and iou=0.41902228134353176 and reward=0.0 and discount=1.0\n",
            "   |->> t=9 Diff-Reward (0.0) for LEFT:bbox transition: [141, 147,  28,  64] -> [140, 147,  28,  64] w/ P(a|s)=0.10765986889600754 and iou=0.3912618193674601 and reward=0.0 and discount=1.0\n",
            "   |->> t=10 Diff-Reward (-1.0) for LEFT:bbox transition: [140, 147,  28,  64] -> [139, 147,  28,  64] w/ P(a|s)=0.09912022203207016 and iou=0.36456667732651105 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.        -2.3114219]\n",
            "\u001b[31m>> Total frame loss: -2.3114218711853027\u001b[0m\n",
            "Final bounding box: [139 147  28  64] reached in 61 timesteps (originating from [147 150  32  73]). Target was [148 151  33  75]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 12 in t=61 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[92m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 3.3420560359954834\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.0022619832307100296\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 4.69468879699707\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.0012420661514624953\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 9.022404670715332\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.0021696097683161497\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 19.29900360107422\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.0042438567616045475\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 73.89268493652344\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.05669781565666199\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 58.51008987426758\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 3.0551819801330566\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/Doll\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Starting bounding box=adnet_datasets/OTB/Doll/img/0013.jpg for adnet_datasets/OTB/Doll's frames (index: 0)\n",
            "src:adnet_datasets/OTB/Doll/img/0003.jpg\n",
            "target:adnet_datasets/OTB/Doll/img/0013.jpg.\n",
            "\u001b[34m>> Attempting to reach frame 3 with src: [148, 150,  32,  73] and target: [148, 150,  32,  74]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Doll/img/0004.jpg\n",
            "|->> Beginning tracking for bbox:[148 150  32  73]\n",
            "|->> Revisiting bbox: [148 150  32  73]. Action 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 8/STOP (P(a|s) = 0.07599999755620956)\u001b[0m\n",
            "      |->> Bounding box moves to: [148 150  32  73]\n",
            "         |->> Action Probabilities (Rounded): [0.0968 0.0998 0.0928 0.0872 0.0854 0.087  0.0891 0.0821 0.0757 0.1085\n",
            " 0.0957], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.09676968 0.0997506  0.09275506 0.08723717 0.08536714 0.08695103\n",
            " 0.08912767 0.08211233 0.07573821 0.10850827 0.09568293], argmax=9\n",
            "         |->> Overwriting action in buffer [00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000]\n",
            "         |->> Hit a STOP on the 1-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [148, 150,  32,  73] -> [148, 150,  32,  73] (Target was [148, 150,  32,  74])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [148, 150,  32,  73] -> [148, 150,  32,  73] w/ P(a|s)=0.07573820650577545 and iou=0.9864864864864865 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [2.5804725]\n",
            "\u001b[92m>> Total frame loss: 2.580472469329834\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 4 with src: [148, 150,  32,  73] and target: [148, 150,  32,  73]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Doll/img/0005.jpg\n",
            "|->> Beginning tracking for bbox:[148 150  32  73]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 5/2X UP (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [148 146  32  73]\n",
            "         |->> Action Probabilities (Rounded): [0.0962 0.0993 0.0935 0.0869 0.0852 0.0871 0.0895 0.0827 0.0771 0.1068\n",
            " 0.0958], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.0961906  0.09925913 0.09345199 0.08691736 0.08521198 0.08707565\n",
            " 0.08951715 0.08265282 0.07713047 0.10680524 0.09578758], argmax=9\n",
            "         |->> Overwriting action in buffer [00000000\u001b[35m1\u001b[0m00\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000]\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 10/SCALE UP (P(a|s) = 0.09600000083446503)\u001b[0m\n",
            "      |->> Bounding box moves to: [147 144  34  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0969 0.101  0.0925 0.0871 0.0847 0.0861 0.0888 0.0826 0.0751 0.1094\n",
            " 0.0958], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.0969163  0.10096675 0.09252284 0.08706375 0.08471424 0.08613241\n",
            " 0.08881984 0.08255239 0.07511935 0.109356   0.09583601], argmax=9\n",
            "         |->> Overwriting action in buffer [00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000000\u001b[35m1\u001b[0m00\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000]\n",
            "   \u001b[33m|->> #2/t=3-th Action selection: 1/2X LEFT (P(a|s) = 0.10000000149011612)\u001b[0m\n",
            "      |->> Bounding box moves to: [145 144  34  75]\n",
            "         |->> Action Probabilities (Rounded): [0.096  0.1005 0.0934 0.0884 0.0853 0.087  0.0898 0.0835 0.0774 0.109\n",
            " 0.0898], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.0960429  0.10047399 0.09336714 0.08835457 0.08530377 0.08697775\n",
            " 0.08977585 0.08351447 0.07738351 0.10897075 0.08983522], argmax=9\n",
            "         |->> Overwriting action in buffer [0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000000\u001b[35m1\u001b[0m00\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000]\n",
            "   \u001b[33m|->> #3/t=4-th Action selection: 7/2X DOWN (P(a|s) = 0.08399999886751175)\u001b[0m\n",
            "      |->> Bounding box moves to: [145 148  34  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0961 0.0984 0.0943 0.0879 0.0856 0.0872 0.0899 0.0838 0.0773 0.1074\n",
            " 0.0922], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.09608573 0.09838535 0.09427217 0.08787648 0.08560877 0.08718144\n",
            " 0.08992358 0.08378305 0.07733667 0.10738445 0.0921623 ], argmax=9\n",
            "         |->> Overwriting action in buffer [0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000000\u001b[35m1\u001b[0m00\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000]\n",
            "   \u001b[33m|->> #4/t=5-th Action selection: 7/2X DOWN (P(a|s) = 0.0820000022649765)\u001b[0m\n",
            "      |->> Bounding box moves to: [145 152  34  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0958 0.0989 0.0942 0.0877 0.0859 0.087  0.09   0.0824 0.0766 0.1096\n",
            " 0.0919], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.09579117 0.09893286 0.09417548 0.08774057 0.08585811 0.08695891\n",
            " 0.09000399 0.082392   0.07658026 0.10964224 0.09192437], argmax=9\n",
            "         |->> Overwriting action in buffer [0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000000\u001b[35m1\u001b[0m00\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000]\n",
            "   \u001b[33m|->> #5/t=6-th Action selection: 0/LEFT (P(a|s) = 0.09600000083446503)\u001b[0m\n",
            "      |->> Bounding box moves to: [144 152  34  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0962 0.0985 0.0935 0.0892 0.0865 0.0864 0.0904 0.0818 0.0777 0.1078\n",
            " 0.0923], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.09619273 0.09853832 0.09346635 0.08915421 0.08646092 0.08635946\n",
            " 0.09035274 0.08177101 0.0776675  0.10778026 0.09225652], argmax=9\n",
            "         |->> Overwriting action in buffer [0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000000\u001b[35m1\u001b[0m00\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000]\n",
            "   \u001b[33m|->> #6/t=7-th Action selection: 3/2X RIGHT (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [146 152  34  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0886 0.0988 0.0992 0.0906 0.0872 0.0879 0.0907 0.0838 0.0782 0.1034\n",
            " 0.0916], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.08857311 0.09875774 0.09921438 0.09059358 0.08723156 0.0878927\n",
            " 0.09067206 0.08384586 0.07816736 0.10344099 0.09161063], argmax=9\n",
            "         |->> Overwriting action in buffer [\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000000\u001b[35m1\u001b[0m00\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000]\n",
            "|->> Revisiting bbox: [145 152  34  75]. Action 0 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [148, 150,  32,  73] -> [146, 152,  34,  75] (Target was [148, 150,  32,  73])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X UP:bbox transition: [148, 150,  32,  73] -> [148, 146,  32,  73] w/ P(a|s)=0.08707565069198608 and iou=0.8961038961038961 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for SCALE UP:bbox transition: [148, 146,  32,  73] -> [147, 144,  34,  75] w/ P(a|s)=0.09583601355552673 and iou=0.8244958924570575 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X LEFT:bbox transition: [147, 144,  34,  75] -> [145, 144,  34,  75] w/ P(a|s)=0.10047399252653122 and iou=0.7786676374226429 and reward=0.0 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.0) for 2X DOWN:bbox transition: [145, 144,  34,  75] -> [145, 148,  34,  75] w/ P(a|s)=0.08378305286169052 and iou=0.8627525733892489 and reward=0.0 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (0.0) for 2X DOWN:bbox transition: [145, 148,  34,  75] -> [145, 152,  34,  75] w/ P(a|s)=0.08239199966192245 and iou=0.8197392923649907 and reward=0.0 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (0.0) for LEFT:bbox transition: [145, 152,  34,  75] -> [144, 152,  34,  75] w/ P(a|s)=0.09619272500276566 and iou=0.7728592162554426 and reward=0.0 and discount=1.0\n",
            "   |->> t=7 Diff-Reward (1.0) for 2X RIGHT:bbox transition: [144, 152,  34,  75] -> [146, 152,  34,  75] w/ P(a|s)=0.09059358388185501 and iou=0.8691660290742158 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.       0.       0.       0.       0.       0.       2.401372]\n",
            "\u001b[92m>> Total frame loss: 2.401371955871582\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 5 with src: [146, 152,  34,  75] and target: [148, 150,  32,  73]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Doll/img/0006.jpg\n",
            "|->> Beginning tracking for bbox:[146 152  34  75]\n",
            "   \u001b[33m|->> #0/t=8-th Action selection: 0/LEFT (P(a|s) = 0.10000000149011612)\u001b[0m\n",
            "      |->> Bounding box moves to: [145 152  34  75]\n",
            "         |->> Action Probabilities (Rounded): [0.0997 0.0995 0.0901 0.0889 0.0867 0.0871 0.0905 0.0828 0.0751 0.1076\n",
            " 0.092 ], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.09967452 0.09951866 0.09012324 0.08886085 0.08672833 0.08714218\n",
            " 0.09047764 0.08282624 0.0750578  0.10758433 0.09200615], argmax=9\n",
            "         |->> Overwriting action in buffer [000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000000\u001b[35m1\u001b[0m00\u001b[35m,\u001b[0m00000000000\u001b[35m,\u001b[0m00000000000]\n",
            "   \u001b[33m|->> #1/t=9-th Action selection: 9/SCALE DOWN (P(a|s) = 0.10300000011920929)\u001b[0m\n",
            "      |->> Bounding box moves to: [146 153  32  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0878 0.0996 0.1009 0.0894 0.0876 0.0891 0.0914 0.0845 0.0753 0.1031\n",
            " 0.0913], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.08777992 0.09955675 0.1009462  0.08937576 0.08763958 0.08910371\n",
            " 0.09139517 0.08449572 0.07532375 0.103054   0.09132945], argmax=9\n",
            "         |->> Overwriting action in buffer [\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000000\u001b[35m1\u001b[0m00\u001b[35m,\u001b[0m00000000000]\n",
            "   \u001b[33m|->> #2/t=10-th Action selection: 3/2X RIGHT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [148 153  32  72]\n",
            "         |->> Action Probabilities (Rounded): [0.1001 0.0991 0.0889 0.0903 0.0886 0.0895 0.0921 0.0854 0.0748 0.0982\n",
            " 0.093 ], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.10010381 0.09907521 0.0889394  0.09032659 0.08856136 0.08945867\n",
            " 0.09214602 0.0854068  0.07484275 0.09816524 0.09297417], argmax=0\n",
            "         |->> Overwriting action in buffer [000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000000\u001b[35m1\u001b[0m00]\n",
            "   \u001b[33m|->> #3/t=11-th Action selection: 0/LEFT (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [147 153  32  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0953 0.0996 0.0932 0.0883 0.0882 0.089  0.0912 0.0854 0.0758 0.1022\n",
            " 0.0917], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.09530142 0.09959756 0.09321348 0.08829512 0.08824655 0.0890473\n",
            " 0.091199   0.08536658 0.07584566 0.10216147 0.09172584], argmax=9\n",
            "         |->> Overwriting action in buffer [000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000]\n",
            "   \u001b[33m|->> #4/t=12-th Action selection: 5/2X UP (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [147 149  32  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0917 0.0993 0.0958 0.0895 0.0881 0.0904 0.0923 0.0862 0.0755 0.0986\n",
            " 0.0926], argmax=1\n",
            "         |->> Action Probabilities (RAW): [0.09173744 0.09926611 0.09580233 0.08952464 0.08810723 0.09037017\n",
            " 0.09228668 0.08621796 0.07547902 0.09857468 0.09263375], argmax=1\n",
            "         |->> Overwriting action in buffer [\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m0000000000\u001b[35m1\u001b[0m]\n",
            "   \u001b[33m|->> #5/t=13-th Action selection: 5/2X UP (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [147 145  32  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0993 0.0987 0.0893 0.0886 0.0877 0.0887 0.0919 0.0844 0.0753 0.1013\n",
            " 0.095 ], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.09925094 0.0986535  0.08928391 0.08858714 0.0876544  0.08872029\n",
            " 0.09193    0.08439798 0.07526086 0.10129301 0.09496795], argmax=9\n",
            "         |->> Overwriting action in buffer [00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000]\n",
            "   \u001b[33m|->> #6/t=14-th Action selection: 6/DOWN (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [147 147  32  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0965 0.0996 0.0941 0.088  0.0874 0.0876 0.0915 0.0841 0.0753 0.1013\n",
            " 0.0946], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.09646569 0.09964433 0.09414347 0.08796573 0.08736909 0.08756784\n",
            " 0.09152235 0.0841442  0.0753286  0.10126026 0.09458848], argmax=9\n",
            "         |->> Overwriting action in buffer [00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000]\n",
            "   \u001b[33m|->> #7/t=15-th Action selection: 1/2X LEFT (P(a|s) = 0.10000000149011612)\u001b[0m\n",
            "      |->> Bounding box moves to: [145 147  32  72]\n",
            "         |->> Action Probabilities (Rounded): [0.1016 0.0996 0.0916 0.0881 0.0875 0.0873 0.0894 0.0847 0.0735 0.1028\n",
            " 0.094 ], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.1015913  0.09957998 0.09155748 0.08808643 0.0875085  0.08732314\n",
            " 0.08935852 0.08468371 0.0735175  0.1027685  0.09402502], argmax=9\n",
            "         |->> Overwriting action in buffer [000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000]\n",
            "   \u001b[33m|->> #8/t=16-th Action selection: 7/2X DOWN (P(a|s) = 0.0860000029206276)\u001b[0m\n",
            "      |->> Bounding box moves to: [145 151  32  72]\n",
            "         |->> Action Probabilities (Rounded): [0.1006 0.0972 0.0935 0.088  0.0861 0.0871 0.0909 0.0859 0.0733 0.1041\n",
            " 0.0934], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.10057388 0.09719887 0.0934843  0.08800764 0.08605219 0.08710016\n",
            " 0.09088516 0.08594193 0.07331076 0.10409115 0.09335401], argmax=9\n",
            "         |->> Overwriting action in buffer [0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000]\n",
            "|->> Revisiting bbox: [145 147  32  72]. Action 5 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [146, 152,  34,  75] -> [145, 151,  32,  72] (Target was [148, 150,  32,  73])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for LEFT:bbox transition: [146, 152,  34,  75] -> [145, 152,  34,  75] w/ P(a|s)=0.0996745228767395 and iou=0.8197392923649907 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for SCALE DOWN:bbox transition: [145, 152,  34,  75] -> [146, 153,  32,  72] w/ P(a|s)=0.1030540019273758 and iou=0.8267716535433071 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X RIGHT:bbox transition: [146, 153,  32,  72] -> [148, 153,  32,  72] w/ P(a|s)=0.09032659232616425 and iou=0.9333333333333333 and reward=0.0 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.0) for LEFT:bbox transition: [148, 153,  32,  72] -> [147, 153,  32,  72] w/ P(a|s)=0.09530141949653625 and iou=0.8785425101214575 and reward=0.0 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (0.0) for 2X UP:bbox transition: [147, 153,  32,  72] -> [147, 149,  32,  72] w/ P(a|s)=0.09037017077207565 and iou=0.9024190241902419 and reward=0.0 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (0.0) for 2X UP:bbox transition: [147, 149,  32,  72] -> [147, 145,  32,  72] w/ P(a|s)=0.08872029185295105 and iou=0.8103784627389777 and reward=0.0 and discount=1.0\n",
            "   |->> t=7 Diff-Reward (0.0) for DOWN:bbox transition: [147, 145,  32,  72] -> [147, 147,  32,  72] w/ P(a|s)=0.09152235090732574 and iou=0.8552578968412635 and reward=0.0 and discount=1.0\n",
            "   |->> t=8 Diff-Reward (0.0) for 2X LEFT:bbox transition: [147, 147,  32,  72] -> [145, 147,  32,  72] w/ P(a|s)=0.09957997500896454 and iou=0.7582417582417582 and reward=0.0 and discount=1.0\n",
            "   |->> t=9 Diff-Reward (1.0) for 2X DOWN:bbox transition: [145, 147,  32,  72] -> [145, 151,  32,  72] w/ P(a|s)=0.08594193309545517 and iou=0.8181818181818182 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.        0.        0.        0.        0.        0.        0.\n",
            " 0.        2.4540834]\n",
            "\u001b[92m>> Total frame loss: 2.4540834426879883\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 6 with src: [145, 151,  32,  72] and target: [147, 150,  33,  75]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Doll/img/0007.jpg\n",
            "|->> Beginning tracking for bbox:[145 151  32  72]\n",
            "|->> Revisiting bbox: [145 151  32  72]. Action 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=17-th Action selection: 8/STOP (P(a|s) = 0.07599999755620956)\u001b[0m\n",
            "      |->> Bounding box moves to: [145 151  32  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0991 0.0971 0.0921 0.0879 0.0872 0.0877 0.0908 0.0842 0.0762 0.1031\n",
            " 0.0946], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.09911394 0.09712568 0.09211837 0.08794482 0.08719558 0.08766019\n",
            " 0.09080987 0.08419084 0.07618339 0.10309558 0.09456182], argmax=9\n",
            "         |->> Overwriting action in buffer [0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000]\n",
            "         |->> Hit a STOP on the 17-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [145, 151,  32,  72] -> [145, 151,  32,  72] (Target was [147, 150,  33,  75])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [145, 151,  32,  72] -> [145, 151,  32,  72] w/ P(a|s)=0.07618339359760284 and iou=0.8247422680412371 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [2.5746117]\n",
            "\u001b[92m>> Total frame loss: 2.5746116638183594\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 7 with src: [145, 151,  32,  72] and target: [147, 150,  33,  76]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Doll/img/0008.jpg\n",
            "|->> Beginning tracking for bbox:[145 151  32  72]\n",
            "|->> Revisiting bbox: [145 151  32  72]. Action 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=17-th Action selection: 8/STOP (P(a|s) = 0.07699999958276749)\u001b[0m\n",
            "      |->> Bounding box moves to: [145 151  32  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0974 0.0971 0.0933 0.0889 0.0865 0.0871 0.0919 0.0845 0.0768 0.1023\n",
            " 0.0941], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.09737454 0.09713984 0.09334925 0.08894053 0.08645941 0.08710609\n",
            " 0.09193163 0.0845033  0.07681378 0.10228037 0.09410129], argmax=9\n",
            "         |->> Overwriting action in buffer [00000000\u001b[35m1\u001b[0m00\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000]\n",
            "         |->> Hit a STOP on the 17-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [145, 151,  32,  72] -> [145, 151,  32,  72] (Target was [147, 150,  33,  76])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [145, 151,  32,  72] -> [145, 151,  32,  72] w/ P(a|s)=0.07681377977132797 and iou=0.8144796380090498 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [2.5663712]\n",
            "\u001b[92m>> Total frame loss: 2.566371202468872\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 8 with src: [145, 151,  32,  72] and target: [147, 150,  33,  76]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Doll/img/0009.jpg\n",
            "|->> Beginning tracking for bbox:[145 151  32  72]\n",
            "   \u001b[33m|->> #0/t=17-th Action selection: 5/2X UP (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [145 147  32  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0944 0.0978 0.0925 0.0888 0.0869 0.0882 0.0911 0.0849 0.0794 0.1013\n",
            " 0.0947], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.09444355 0.09775478 0.09247382 0.08883489 0.08686966 0.08818844\n",
            " 0.09109137 0.08489612 0.07944024 0.10133699 0.09467014], argmax=9\n",
            "         |->> Overwriting action in buffer [00000000\u001b[35m1\u001b[0m00\u001b[35m,\u001b[0m00000000\u001b[35m1\u001b[0m00\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0]\n",
            "   \u001b[33m|->> #1/t=18-th Action selection: 1/2X LEFT (P(a|s) = 0.0989999994635582)\u001b[0m\n",
            "      |->> Bounding box moves to: [143 147  32  72]\n",
            "         |->> Action Probabilities (Rounded): [0.0961 0.0988 0.0925 0.0888 0.0853 0.087  0.0908 0.0842 0.0768 0.1052\n",
            " 0.0946], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.09614047 0.09875311 0.09245259 0.08882597 0.08529133 0.08698794\n",
            " 0.09075979 0.08415834 0.07683501 0.10522953 0.09456591], argmax=9\n",
            "         |->> Overwriting action in buffer [00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000000\u001b[35m1\u001b[0m00\u001b[35m,\u001b[0m00000000\u001b[35m1\u001b[0m00\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000\u001b[35m,\u001b[0m000\u001b[35m1\u001b[0m0000000]\n",
            "   \u001b[33m|->> #2/t=19-th Action selection: 9/SCALE DOWN (P(a|s) = 0.10499999672174454)\u001b[0m\n",
            "      |->> Bounding box moves to: [144 148  30  69]\n",
            "         |->> Action Probabilities (Rounded): [0.0966 0.0975 0.0948 0.0887 0.086  0.0864 0.0909 0.085  0.0751 0.1055\n",
            " 0.0936], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.09664319 0.09752332 0.09476589 0.08866446 0.08600166 0.08637101\n",
            " 0.09088414 0.08499867 0.07505817 0.10546283 0.0936266 ], argmax=9\n",
            "         |->> Overwriting action in buffer [0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000000\u001b[35m1\u001b[0m00\u001b[35m,\u001b[0m00000000\u001b[35m1\u001b[0m00\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m\u001b[35m1\u001b[0m0000000000]\n",
            "   \u001b[33m|->> #3/t=20-th Action selection: 5/2X UP (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [144 144  30  69]\n",
            "         |->> Action Probabilities (Rounded): [0.0951 0.0997 0.0944 0.0892 0.0861 0.0866 0.0909 0.0858 0.0754 0.1018\n",
            " 0.0949], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.09512092 0.09970514 0.0943535  0.089198   0.08609697 0.08662969\n",
            " 0.09090383 0.08580394 0.07540739 0.10183094 0.09494967], argmax=9\n",
            "         |->> Overwriting action in buffer [000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000000\u001b[35m1\u001b[0m00\u001b[35m,\u001b[0m00000000\u001b[35m1\u001b[0m00\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000]\n",
            "   \u001b[33m|->> #4/t=21-th Action selection: 9/SCALE DOWN (P(a|s) = 0.10199999809265137)\u001b[0m\n",
            "      |->> Bounding box moves to: [145 145  28  66]\n",
            "         |->> Action Probabilities (Rounded): [0.094  0.0988 0.0941 0.0894 0.087  0.0865 0.0913 0.0849 0.0778 0.1022\n",
            " 0.0939], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.09397786 0.09881862 0.09414744 0.08944831 0.08702692 0.0865418\n",
            " 0.09125012 0.08491594 0.07780457 0.10215223 0.09391615], argmax=9\n",
            "         |->> Overwriting action in buffer [00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000000\u001b[35m1\u001b[0m00\u001b[35m,\u001b[0m00000000\u001b[35m1\u001b[0m00\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000]\n",
            "|->> Revisiting bbox: [145 145  28  66]. Action 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [145, 151,  32,  72] -> [145, 145,  28,  66] (Target was [147, 150,  33,  76])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X UP:bbox transition: [145, 151,  32,  72] -> [145, 147,  32,  72] w/ P(a|s)=0.08818843960762024 and iou=0.7549234135667396 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for 2X LEFT:bbox transition: [145, 147,  32,  72] -> [143, 147,  32,  72] w/ P(a|s)=0.09875310957431793 and iou=0.6708333333333333 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.0) for SCALE DOWN:bbox transition: [143, 147,  32,  72] -> [144, 148,  30,  69] w/ P(a|s)=0.10546282678842545 and iou=0.6533044420368364 and reward=0.0 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.0) for 2X UP:bbox transition: [144, 148,  30,  69] -> [144, 144,  30,  69] w/ P(a|s)=0.08662968873977661 and iou=0.5912408759124088 and reward=0.0 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [144, 144,  30,  69] -> [145, 145,  28,  66] w/ P(a|s)=0.10215222835540771 and iou=0.5725631768953069 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.         0.         0.         0.        -2.2812912]\n",
            "\u001b[31m>> Total frame loss: -2.2812912464141846\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 9 with src: [145, 145,  28,  66] and target: [146, 151,  34,  75]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Doll/img/0010.jpg\n",
            "|->> Beginning tracking for bbox:[145 145  28  66]\n",
            "   \u001b[33m|->> #0/t=22-th Action selection: 9/SCALE DOWN (P(a|s) = 0.09799999743700027)\u001b[0m\n",
            "      |->> Bounding box moves to: [146 146  26  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0949 0.1005 0.0938 0.09   0.0872 0.0868 0.092  0.0853 0.075  0.098\n",
            " 0.0965], argmax=1\n",
            "         |->> Action Probabilities (RAW): [0.09494349 0.10048711 0.09380318 0.08995906 0.08723851 0.08679646\n",
            " 0.09200074 0.08531504 0.07495426 0.09799854 0.09650365], argmax=1\n",
            "         |->> Overwriting action in buffer [000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000000\u001b[35m1\u001b[0m00\u001b[35m,\u001b[0m00000000\u001b[35m1\u001b[0m00\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000]\n",
            "|->> Revisiting bbox: [146 146  26  64]. Action 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [145, 145,  28,  66] -> [146, 146,  26,  64] (Target was [146, 151,  34,  75])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [145, 145,  28,  66] -> [146, 146,  26,  64] w/ P(a|s)=0.09799854457378387 and iou=0.5723880597014925 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.3228025]\n",
            "\u001b[31m>> Total frame loss: -2.3228025436401367\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 10 with src: [146, 146,  26,  64] and target: [147, 150,  34,  75]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Doll/img/0011.jpg\n",
            "|->> Beginning tracking for bbox:[146 146  26  64]\n",
            "|->> Revisiting bbox: [146 146  26  64]. Action 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=23-th Action selection: 8/STOP (P(a|s) = 0.07699999958276749)\u001b[0m\n",
            "      |->> Bounding box moves to: [146 146  26  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0947 0.0998 0.094  0.0905 0.0879 0.0877 0.0922 0.0859 0.0767 0.0943\n",
            " 0.0961], argmax=1\n",
            "         |->> Action Probabilities (RAW): [0.09473959 0.09980253 0.09400284 0.09050263 0.08793424 0.08770503\n",
            " 0.09223963 0.08593943 0.07669903 0.09429896 0.09613609], argmax=1\n",
            "         |->> Overwriting action in buffer [000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000000\u001b[35m1\u001b[0m00\u001b[35m,\u001b[0m00000000\u001b[35m1\u001b[0m00\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000]\n",
            "         |->> Hit a STOP on the 23-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [146, 146,  26,  64] -> [146, 146,  26,  64] (Target was [147, 150,  34,  75])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [146, 146,  26,  64] -> [146, 146,  26,  64] w/ P(a|s)=0.07669903337955475 and iou=0.552689756816507 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.567866]\n",
            "\u001b[31m>> Total frame loss: -2.567866086959839\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 11 with src: [146, 146,  26,  64] and target: [148, 151,  33,  75]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Doll/img/0012.jpg\n",
            "|->> Beginning tracking for bbox:[146 146  26  64]\n",
            "   \u001b[33m|->> #0/t=23-th Action selection: 6/DOWN (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [146 147  26  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0946 0.1001 0.0942 0.0897 0.0876 0.0881 0.0925 0.086  0.0772 0.0943\n",
            " 0.0956], argmax=1\n",
            "         |->> Action Probabilities (RAW): [0.09464812 0.10010052 0.09422296 0.089692   0.08763894 0.08809368\n",
            " 0.09254833 0.08596924 0.0771938  0.09427751 0.09561494], argmax=1\n",
            "         |->> Overwriting action in buffer [00000000\u001b[35m1\u001b[0m00\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000000\u001b[35m1\u001b[0m00\u001b[35m,\u001b[0m00000000\u001b[35m1\u001b[0m00\u001b[35m,\u001b[0m0000000\u001b[35m1\u001b[0m000]\n",
            "   \u001b[33m|->> #1/t=24-th Action selection: 7/2X DOWN (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [146 149  26  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0953 0.1008 0.0926 0.0906 0.0887 0.0891 0.09   0.087  0.0754 0.0954\n",
            " 0.0951], argmax=1\n",
            "         |->> Action Probabilities (RAW): [0.09525286 0.10084941 0.09261503 0.09056923 0.08872966 0.08909665\n",
            " 0.09004838 0.08697117 0.07539547 0.09535317 0.09511898], argmax=1\n",
            "         |->> Overwriting action in buffer [000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m00000000\u001b[35m1\u001b[0m00\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000000\u001b[35m1\u001b[0m00\u001b[35m,\u001b[0m00000000\u001b[35m1\u001b[0m00]\n",
            "   \u001b[33m|->> #2/t=25-th Action selection: 4/UP (P(a|s) = 0.0860000029206276)\u001b[0m\n",
            "      |->> Bounding box moves to: [146 148  26  64]\n",
            "         |->> Action Probabilities (Rounded): [0.0976 0.1028 0.0937 0.0889 0.0861 0.087  0.0904 0.085  0.0717 0.1018\n",
            " 0.0949], argmax=1\n",
            "         |->> Action Probabilities (RAW): [0.09761994 0.10284621 0.09374246 0.08893066 0.08606007 0.08696096\n",
            " 0.09044877 0.08496864 0.0717456  0.10178163 0.09489504], argmax=1\n",
            "         |->> Overwriting action in buffer [0000000\u001b[35m1\u001b[0m000\u001b[35m,\u001b[0m000000\u001b[35m1\u001b[0m0000\u001b[35m,\u001b[0m00000000\u001b[35m1\u001b[0m00\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m000000000\u001b[35m1\u001b[0m0\u001b[35m,\u001b[0m0\u001b[35m1\u001b[0m000000000\u001b[35m,\u001b[0m00000\u001b[35m1\u001b[0m00000\u001b[35m,\u001b[0m00000000\u001b[35m1\u001b[0m00]\n",
            "|->> Revisiting bbox: [146 149  26  64]. Action 6 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [146, 146,  26,  64] -> [146, 148,  26,  64] (Target was [148, 151,  33,  75])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for DOWN:bbox transition: [146, 146,  26,  64] -> [146, 147,  26,  64] w/ P(a|s)=0.09254833310842514 and iou=0.5335309373842164 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for 2X DOWN:bbox transition: [146, 147,  26,  64] -> [146, 149,  26,  64] w/ P(a|s)=0.08697117120027542 and iou=0.5612976235382875 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-1.0) for UP:bbox transition: [146, 149,  26,  64] -> [146, 148,  26,  64] w/ P(a|s)=0.0860600695014 and iou=0.5472897196261682 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.         0.        -2.4527097]\n",
            "\u001b[31m>> Total frame loss: -2.452709674835205\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 12 with src: [146, 148,  26,  64] and target: [148, 151,  33,  75]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Doll/img/0013.jpg\n"
          ]
        }
      ],
      "source": [
        "model, losses = epochs_train(adnet_model, Adam(learning_rate=LEARNING_RATE), \n",
        "                             datasets, epochs=N_EPOCHS, retry_count=N_RETRIES, \n",
        "                             randomize=RANDOMIZE_TRAINING)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LF9uTq5yY31"
      },
      "outputs": [],
      "source": [
        "# Plot losses\n",
        "fig = plt.figure()\n",
        "all_losses = np.concatenate([v for _, v in losses.items()])\n",
        "plt.plot(np.arange(len(all_losses)), all_losses) \n",
        "plt.xlabel('Number of Episodes')\n",
        "plt.ylabel('Avg Trajectory Loss')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYQ1oThc1c_2"
      },
      "source": [
        "### Save Weights for Reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZTaifbPkHeS"
      },
      "outputs": [],
      "source": [
        "!mkdir -p derek_models\n",
        "\n",
        "dt_string = datetime.now().strftime(\"%d-%m-%Y_%H%M%S\")\n",
        "model.save('derek_models/{0}'.format(dt_string))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "dt_string = datetime.now().strftime(\"%d-%m-%Y_%H%M%S\")\n",
        "model.save_weights(\"checkpoints/derek-{0}.h5\".format(dt_string))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1SsVnMeg8Up"
      },
      "outputs": [],
      "source": [
        "%debug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbUe72jpsol6"
      },
      "outputs": [],
      "source": [
        "# UNTESTED; uncomfirmed if works\n",
        "\n",
        "def move2Frame(model: ADNET, img: np.array, src_frame: int, src_bbox: np.array, \n",
        "               target_frame: int, target_bbox: np.array) -> np.array:\n",
        "  \n",
        "  bbox = src_bbox\n",
        "  actions = []\n",
        "  img = getFrame(dataset, target_frame) \n",
        "  target_bbox = gt[i]\n",
        "  for t in range(model.K):\n",
        "    patch = getPatch(img, bbox)\n",
        "    probs, conf_score = model(patch)\n",
        "    a_prob = tf.reshape(probs, (model.ACTION_DIM)) \n",
        "    a, bbox = selectMaxAction(np.array(img), bbox, a_prob)\n",
        "\n",
        "    actions.append(a)\n",
        "    model.updateActionHistory(a)\n",
        "    if isStop(a):\n",
        "        break  \n",
        "  \n",
        "  target_iou = calculate_IOU(bbox, target_bbox)   \n",
        "  return bbox, target_iou, actions\n",
        "\n",
        "\n",
        "def predict(model: ADNET, d: str, start_frame: int, end_frame: int):\n",
        "  gt = get_ground_truths(\"%s/groundtruth_rect.txt\" % d)\n",
        "  frames = sorted(glob.glob(os.path.join('%s/img' % d, '*.jpg'))) \n",
        "\n",
        "  ious = []\n",
        "  bbox = gt[start_frame]\n",
        "  model.clearActionHistory()\n",
        "  for i in range(start_frame+1, end_frame+1):\n",
        "    img = getFrame(dataset, i) \n",
        "    bbox, iou, actions = move2Frame(model, img, d)\n",
        "    ious.append(iou)\n",
        "  return model, ious\n",
        "\n",
        "\n",
        "def predict(model: ADNET, d: str):\n",
        "  gt = get_ground_truths(\"%s/groundtruth_rect.txt\" % d)\n",
        "  frames = sorted(glob.glob(os.path.join('%s/img' % d, '*.jpg'))) \n",
        "  return predict(model, d, 0, len(frames)-1)\n",
        "\n",
        "\n",
        "\n",
        "rand_idx = 11\n",
        "d = ALL_DATASETS_LIST[rand_idx] \n",
        "model, ious = predict(adnet_model, d)\n",
        "\n",
        "fig = plt.figure()\n",
        "for e in losses:\n",
        "  plt.plot(np.arange(len(ious)), ious) \n",
        "plt.xlabel('Frame')\n",
        "plt.ylabel('IOU')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMtzZ9r5nu8A"
      },
      "source": [
        "### Observations\n",
        "\n",
        "* The paper sums all sequence rewards. However, we found this to produce too much variance. We reduce_mean instead to address this. If we had"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmQvTRA7j9ET"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkTBunYkHcUQ"
      },
      "outputs": [],
      "source": [
        "print(erroneous_datasets)\n",
        "\n",
        "# !ls adnet_datasets/OTB/Diving/img/\n",
        "# ! wc -l adnet_datasets/OTB/Diving/groundtruth_rect.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0g-v8GupB9y"
      },
      "outputs": [],
      "source": [
        "def predict(model: tf.keras.Model,img: np.array,bbox: np.array) -> np.array:\n",
        "  ACTION_DIM=11\n",
        "  K=10\n",
        "  \n",
        "  action_hist = np.zeros((ACTION_DIM * K, 1))\n",
        "  seen_bboxes = set()\n",
        "  for t in range(K):\n",
        "    #model.setActionHistory(action_hist.reshape((1, 1, 1, ACTION_DIM * K)))\n",
        "    model.setActionHistory(action_hist.reshape((1,ACTION_DIM * K))) ### For ADNET_v2\n",
        "    patch = tf.image.resize(img[bbox[1]:(bbox[1] + bbox[3]), \n",
        "                                bbox[0]:(bbox[0] + bbox[2])], [112, 112])\n",
        "    patch = tf.reshape(patch, (1, 112, 112, 3))\n",
        "    a_prob = tf.reshape(model(patch)[0], (ACTION_DIM)) \n",
        "    a, bbox = selectAction(np.array(img), bbox, a_prob)\n",
        "    if isStop(a) or tuple(bbox) in seen_bboxes:\n",
        "      break\n",
        "\n",
        "    action_hist[t * ACTION_DIM + a] = 1 \n",
        "    seen_bboxes.add(tuple(bbox))\n",
        "  return bbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03dOCNAKz6sg"
      },
      "outputs": [],
      "source": [
        "def plotNpImageBBoxGT(img: np.array, bbox: np.array,gbbox: np.array) -> np.array:\n",
        "  '''\n",
        "  Plots the bounding box on an image and returns the bounding box\n",
        "  '''\n",
        "  fig, ax = plt.subplots()\n",
        "  x_pre,y_pre, w_pre, h_pre = bbox\n",
        "  x_gr,y_gr, w_gr, h_gr = gbbox\n",
        "  predicted_rect = patches.Rectangle((x_pre, y_pre), w_pre, h_pre, linewidth=1, edgecolor='r', facecolor='none')\n",
        "  gt_rect = patches.Rectangle((x_gr, y_gr), w_gr, h_gr, linewidth=1, edgecolor='b', facecolor='none')\n",
        "  ax.add_patch(predicted_rect)\n",
        "  ax.add_patch(gt_rect)\n",
        "  plt.imshow(img)\n",
        "  return bbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAvwFremUHsQ"
      },
      "outputs": [],
      "source": [
        "ALL_DATASETS_LIST = glob.glob(\"adnet_datasets/OTB/*\")\n",
        "j = random.randint(0, len(ALL_DATASETS_LIST)) \n",
        "dataset = ALL_DATASETS_LIST[j] \n",
        "frames = sorted(glob.glob(os.path.join('%s/img' % dataset, '*.jpg')))\n",
        "gt = get_ground_truths(\"%s/groundtruth_rect.txt\" % dataset)\n",
        "\n",
        "predicted_bbox = gt[0]\n",
        "for i, frame in enumerate(frames[1:]):\n",
        "  img = cv2.imread(frame)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  print(img.shape)\n",
        "  predicted_bbox=predict(model,img,predicted_bbox)\n",
        "  print(predicted_bbox)\n",
        "  gtbbox=gt[i]\n",
        "  plotNpImageBBoxGT(img,predicted_bbox,gtbbox)\n",
        "  #print(gtbbox)\n",
        "  #print(predicted_bbox)\n",
        "  break\n",
        "  #bbox = \n",
        "  #print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhMMozN6J64i"
      },
      "outputs": [],
      "source": [
        "def test_metrics( model: tf.keras.Model, model2:tf.keras.Model  ):\n",
        "    all_boxes = []\n",
        "    all_gt = []\n",
        "    time_perframe_for_each_video =[]\n",
        "    test_list = glob.glob(\"adnet_datasets/Test/*\")\n",
        "    d = ALL_DATASETS_LIST[rand_idx] \n",
        "    gt = get_ground_truths(\"%s/groundtruth_rect.txt\" % d)\n",
        "  \n",
        "    for  i in range(len(test_list)):  # start with 1\n",
        "      dataset = test_list[i]\n",
        "      print(dataset)\n",
        "      #frames = sorted(glob.glob(os.path.join('%s/img' % dataset, '*.jpg')))\n",
        "      gt = get_ground_truths(\"%s/groundtruth_rect.txt\" % dataset)     \n",
        "      all_gt.append(gt)\n",
        "      frames = sorted(glob.glob(os.path.join('%s/img' % dataset, '*.jpg')))\n",
        "      print(frames)\n",
        "      number_of_frames = len(frames)\n",
        "      #start_frame = random.randint(0, number_of_frames) maybe to test robustnes do not start always with first frame TRE\n",
        "      start_frame = 0\n",
        "      boxes_m1 =[]\n",
        "      boxes_m2 = []\n",
        "      time_perframe = []\n",
        "      predicted_box = gt[0]\n",
        "      predicted_box2 = gt[0]\n",
        "      start = time.time()\n",
        "      for f in range(len(frames) - start_frame):\n",
        "        img = cv2.imread(frames[f])\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        predicted_bbox=predict(model,img,predicted_box)\n",
        "        #predicted_bbox2 = predict(model, img,predicted_bbox) if we want to compare 2 models\n",
        "        boxes_m1.append(predicted_box)\n",
        "        #boxes_m2.append(predicted_bbox)\n",
        "      end = time.time()\n",
        "      time_perframe = (start-end)/len(frames)\n",
        "      all_boxes.append(boxes_m1)\n",
        "      time_perframe_for_each_video.append(time_perframe)\n",
        "    return all_boxes, all_gt , time_perframe_for_each_video\n",
        "\n",
        "\n",
        "\n",
        "all_boxes, all_gt , time_perframe_for_each_video = test_metrics(model , adnet_model)\n",
        "print (all_boxes)\n",
        "print(all_gt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9712yCAxLmtI"
      },
      "source": [
        "# TESTING & DEBUGGING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Me8c91RVoLvD"
      },
      "outputs": [],
      "source": [
        "# Update this with the appropriate dataset\n",
        "TEST_IMAGE_PATH = \"adnet_datasets/OTB/Couple/img/0082.jpg\"\n",
        "TEST_BBOX = get_ground_truths(\"adnet_datasets/OTB/Couple/groundtruth_rect.txt\")[82]\n",
        "TEST_IMAGE = cv2.imread(TEST_IMAGE_PATH)\n",
        "\n",
        "\n",
        "# Update the following two vars\n",
        "src_bbox = np.array([143, 131, 34, 87]) \n",
        "pred_bbox = np.array([138, 41, 32, 89])\n",
        "print(plotNpImageBBoxes(TEST_IMAGE, src_bbox, TEST_BBOX, pred_bbox))\n",
        "\n",
        "\n",
        "print(\"IOU: {0}\".format(calculate_IOU(pred_bbox, src_bbox)))\n",
        "\n",
        "print(\"Test bbox is: {0}\".format(TEST_BBOX))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzbeopDmi6q_"
      },
      "outputs": [],
      "source": [
        "# VERTICAL MOVEMENT TESTING \n",
        "TEST_IMAGE_PATH = \"adnet_datasets/OTB/Skater2/img/0005.jpg\"\n",
        "TEST_BBOX = get_ground_truths(\"adnet_datasets/OTB/Skater2/groundtruth_rect.txt\")[4]\n",
        "TEST_IMAGE = cv2.imread(TEST_IMAGE_PATH)\n",
        "\n",
        "# Test move down\n",
        "print(\"Down-shifted bounding box\")\n",
        "bbox = move2(img, TEST_BBOX, \"down\")\n",
        "print(plotNpImageBBox(img, bbox))\n",
        "\n",
        "print(\"Down-shifted bounding box\")\n",
        "bbox = move2(img, bbox, \"down\")\n",
        "print(plotNpImageBBox(img, bbox))\n",
        "\n",
        "print(\"Down-shifted bounding box\")\n",
        "bbox = move2(img, bbox, \"down\")\n",
        "print(plotNpImageBBox(img, bbox))\n",
        "\n",
        "print(\"Down-shifted bounding box\")\n",
        "bbox = move2(img, bbox, \"down\")\n",
        "print(plotNpImageBBox(img, bbox))\n",
        "\n",
        "\n",
        "print(\"Down-shifted bounding box\")\n",
        "bbox = move2(img, bbox, \"down\")\n",
        "print(plotNpImageBBox(img, bbox))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNBblMU8d4qh"
      },
      "outputs": [],
      "source": [
        "# HORIZONTAL MOVEMENT TESTING \n",
        "TEST_IMAGE_PATH = \"adnet_datasets/OTB/Skater2/img/0005.jpg\"\n",
        "TEST_BBOX = get_ground_truths(\"adnet_datasets/OTB/Skater2/groundtruth_rect.txt\")[4]\n",
        "TEST_IMAGE = cv2.imread(TEST_IMAGE_PATH)\n",
        "\n",
        "img, bbox = TEST_IMAGE, TEST_BBOX\n",
        "print(\"Original bounding box\")\n",
        "print(plotNpImageBBox(img, TEST_BBOX))\n",
        "\n",
        "# Test move left\n",
        "print(\"Left-shifted bounding box\")\n",
        "bbox = move2(img, TEST_BBOX, \"left\")\n",
        "print(plotNpImageBBox(img, bbox))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1MXfEC2IDNk"
      },
      "outputs": [],
      "source": [
        "# MOVEMENT TEST\n",
        "\n",
        "print(\"IOU between {1} and {2} is {0}\".format(calculate_IOU(np.array([143, 131,  34,  87]), np.array([138,  41,  32,  89])), [143, 131,  34,  87], [138,  41,  32,  89]))\n",
        "\n",
        "for i in range(11):\n",
        "  print(selectAction(np.zeros([300, 300, 3]), np.array([252, 65, 25, 30]), i))\n",
        "\n",
        "print(selectAction(np.zeros([300, 300, 3]), np.array([131,7,117,168]), 5))\n",
        "print(\"The following UP should do nothing because 0.03 * 168 * 2 is too large\")\n",
        "print(selectAction(np.zeros([300, 300, 3]), np.array([131,7,117,168]), 5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1j-Ud5nXofHE"
      },
      "outputs": [],
      "source": [
        "print(selectAction(np.zeros([450, 450, 3]), np.array([315,  0, 32,  35]), 5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBBRcPEAohhe"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "safe_reinforce.ipynb",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}