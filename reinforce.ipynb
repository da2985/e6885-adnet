{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/da2985/e6885-adnet/blob/main/reinforce.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c1BWwgpSXW9"
      },
      "source": [
        "# Imports & Starting Configs\n",
        "\n",
        "Please use the following two lines to load from Google Drive\n",
        "\n",
        "If your file is not there, upload it to https://drive.google.com/drive/folders/1tsPKyB2E1nW8Qw--kZ9GaeGW2u2-XoV6?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqT6TJ9DLT5v",
        "outputId": "1f808389-b674-4ee4-bf84-20b856932afa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# This must be run within a Google Colab environment \n",
        "from google.colab import drive  \n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "2sTHMZwqNPlW"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "sys.path.append('/content/gdrive/EE6885')\n",
        "\n",
        "os.chdir(\"/content/gdrive/My Drive/EE6885\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvlhZxrmdezd",
        "outputId": "70a9cde4-6be0-4ee7-a500-ec34c10a160c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Basketball   Car24\t Dog1\t      Human5\t     MountainBike   Surfer\n",
            " Bird2\t      Car4\t Doll\t      Human6\t     Panda\t    Suv\n",
            " BlurBody     CarDark\t DragonBaby   Human7\t     RedTeam\t    Sylvester\n",
            " BlurCar1     CarScale\t Dudek\t      Human8\t     Rubik\t    Tiger1\n",
            " BlurCar2     ClifBar\t FaceOcc1     Human9\t     Shaking\t    Tiger2\n",
            " BlurCar3     Coke\t FaceOcc2     Ironman\t     Singer1\t    Toy\n",
            " BlurCar4     Couple\t Fish\t      Jogging\t     Singer2\t    Trans\n",
            " BlurFace     Coupon\t FleetFace    Jump\t     Skater\t    Trellis\n",
            " BlurOwl      Crossing\t Football1    Jumping\t     Skater2\t    Twinnings\n",
            " Board\t      Crowds\t Freeman1     KiteSurf\t    'Skater2 (1)'   Vase\n",
            " Bolt\t      Dancer\t Girl\t      Lemming\t     Skating1\t    Walking\n",
            " Bolt2\t      Dancer2\t Girl2\t      Liquor\t     Skating2\t    Walking2\n",
            " Box\t      David2\t Gym\t      Man\t     Skating3\t    Woman\n",
            " Boy\t      David3\t Human2       Matrix\t     Skiing\n",
            " Car1\t      Deer\t Human3       Mhyang\t     Soccer\n",
            " Car2\t      Dog\t Human4       MotorRolling   Subway\n"
          ]
        }
      ],
      "source": [
        "!ls adnet_datasets/OTB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNOHmxvDD8wD",
        "outputId": "2e8a9d4f-334e-450a-a26f-0aa30e83b194"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hdf5storage in /usr/local/lib/python3.7/dist-packages (0.1.18)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (0.15.0)\n",
            "Requirement already satisfied: h5py>=2.1 in /usr/local/lib/python3.7/dist-packages (from hdf5storage) (3.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from hdf5storage) (1.19.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.1->hdf5storage) (1.5.2)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n"
          ]
        }
      ],
      "source": [
        "pip install hdf5storage tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "gNmhYpyeDLrQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "import tensorflow_probability as tfp\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow.experimental.numpy as tnp\n",
        "\n",
        "import cv2\n",
        "import glob\n",
        "import hdf5storage\n",
        "import math\n",
        "import random\n",
        "import re\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.patches as patches\n",
        "import scipy.io as sio\n",
        "\n",
        "import linecache\n",
        "\n",
        "from typing import Dict, List, Tuple\n",
        "from operator import add\n",
        "import copy\n",
        "\n",
        "from numpy.random import seed\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "UsXgP5KrEGNW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9756c572-8952-4de2-a0ef-e83dfb86a660"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        " %load_ext autoreload \n",
        " %autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdgRU7dpw6t4"
      },
      "source": [
        "# Configurations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3xZrSk9XdEA"
      },
      "outputs": [],
      "source": [
        "#@markdown Network configurations\n",
        "LEARNING_RATE = 1e-4 #@param {type:\"number\"}\n",
        "GOAL_IOU = 0.7 #@param {type:\"number\"}\n",
        "\n",
        "# The length of the action buffer\n",
        "L = 10 #@param {type:\"number\"}\n",
        "# Max Trajectory Length \n",
        "MAX_TRAJECTORY_LENGTH =  10#@param {type:\"number\"}\n",
        "POLICY_TYPE = \"stochastic\" #@param [\"deterministic\", \"stochastic\"] {type:\"string\"}\n",
        "DROPOUT_4 = 0.5 #@param {type:\"number\"}\n",
        "DROPOUT_5 = 0.5 #@param {type:\"number\"}\n",
        "N_EPOCHS =  3#@param {type:\"number\"}\n",
        "\n",
        "# Number of retries to collect sequence loss sum (to reduce variance)\n",
        "N_RETRIES =   1#@param {type:\"number\"}\n",
        "\n",
        "# Randomizes the order in which frames are trained on from a video clip\n",
        "RANDOMIZE_TRAINING = False #@param {type:\"boolean\"}\n",
        "\n",
        "# The paper uses sum. I thought avg would help address giant swings, but the training was taking way too long\n",
        "# with negligible updates\n",
        "GRAD_ACCUM_SCHEME = \"sum\" #@param [\"avg\", \"sum\"] {type:\"string\"}\n",
        "\n",
        "# Use to avoid overly long trajectories. \n",
        "# During trajectory collection, we were not receiving \n",
        "# enough positvie signals\n",
        "PREMATURE_BREAK = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Loss/Reward Constants\n",
        "# This is a probability offset for adding noise since log(P(a|s)=1)=0\n",
        "PROB_OFFSET = 1e-5 #@param {type:\"number\"} \n",
        "# This is the discount factor\n",
        "GAMMA = 1 #@param {type:\"number\"}\n",
        "\n",
        "# final_bbox is used in original Ad Net where  the final bounding box placement \n",
        "# is used in reward calculationfor all actions in a trajectory\n",
        "# individ_bbox individually assign rewards per each bounding box.\n",
        "# only_final_bbox only gives a reward to the final action\n",
        "REWARD_SCHEME = \"only_final_bbox\" #@param [\"only_final_bbox\", \"final_bbox\", \"individ_bbox\"] {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Bounding Box/Patch Constants (probably avoid touching)\n",
        "ALPHA = 0.03 #@param {type:\"number\"}\n",
        "MIN_WINDOW_SIZE = 10 #@param {type:\"number\"}\n",
        "PATCH_X = 112 #@param {type:\"number\"}\n",
        "PATCH_Y = 112 #@param {type:\"number\"}\n",
        "N_CHANNELS = 3 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown ---\n",
        "RANDOM_SEED = 6885\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "AQ4YPvJCt9Dg"
      },
      "outputs": [],
      "source": [
        "seed(RANDOM_SEED)\n",
        "tf.random.set_seed(RANDOM_SEED)\n",
        "\n",
        "DATASET_PATH = \"adnet_datasets/OTB/*\" #@param {type:\"string\"}\n",
        "ALL_DATASETS_LIST = glob.glob(DATASET_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCB-wEWrfk6N"
      },
      "source": [
        "### Successful Configurations (Minimize Me Please)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "mKjyrVB3fdcT"
      },
      "outputs": [],
      "source": [
        "### SUCCESSFUL CONFIGS\n",
        "\n",
        "# 12/18 4:41 PM\n",
        "# #@markdown Network configurations\n",
        "# LEARNING_RATE = 1e-4 #@param {type:\"number\"}\n",
        "# # The length of the action buffer\n",
        "# L = 10 #@param {type:\"number\"}\n",
        "# # Max Trajectory Length \n",
        "# MAX_TRAJECTORY_LENGTH = 20 #@param {type:\"number\"}\n",
        "# POLICY_TYPE = \"stochastic\" #@param [\"deterministic\", \"stochastic\"] {type:\"string\"}\n",
        "# DROPOUT_4 = 0.5 #@param {type:\"number\"}\n",
        "# DROPOUT_5 = 0.5 #@param {type:\"number\"}\n",
        "# N_EPOCHS =  1#@param {type:\"number\"}\n",
        "\n",
        "# # Number of retries to collect sequence loss sum (to reduce variance)\n",
        "# N_RETRIES =  4 #@param {type:\"number\"}\n",
        "\n",
        "# # Randomizes the order in which frames are trained on from a video clip\n",
        "# RANDOMIZE_TRAINING = True #@param {type:\"boolean\"}\n",
        "# GRAD_ACCUM_SCHEME = \"sum\" #@param [\"avg\", \"sum\"] {type:\"string\"}\n",
        "# # The paper uses sum\n",
        "\n",
        "\n",
        "# #@markdown ---\n",
        "# #@markdown Loss/Reward Constants\n",
        "# # This is a probability offset for adding noise since log(P(a|s)=1)=0\n",
        "# PROB_OFFSET = 1e-5 #@param {type:\"number\"} \n",
        "# # This is the discount factor\n",
        "# GAMMA = 0.99 #@param {type:\"number\"}\n",
        "# REWARD_SCHEME = \"final_bbox\" #@param [\"final_bbox\", \"individ_bbox\"] {type:\"string\"}\n",
        "\n",
        "# #@markdown ---\n",
        "# #@markdown Bounding Box/Patch Constants (probably avoid touching)\n",
        "# ALPHA = 0.03 #@param {type:\"number\"}\n",
        "# MIN_WINDOW_SIZE = 10 #@param {type:\"number\"}\n",
        "# PATCH_X = 112 #@param {type:\"number\"}\n",
        "# PATCH_Y = 112 #@param {type:\"number\"}\n",
        "# N_CHANNELS = 3 #@param {type:\"number\"}\n",
        "\n",
        "# #@markdown ---\n",
        "# RANDOM_SEED = 6885\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8s6YHABjUG5"
      },
      "source": [
        "## Model Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfRbj1tuEIyA",
        "outputId": "f69f1ea4-c3ba-4bab-f36b-fc6768f83d66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "class ADNET(tf.keras.Model):\n",
        "\n",
        "    ACTION_DIM = 11\n",
        "    K = 10\n",
        "    CONF_SCORE_DIM = 2\n",
        "\n",
        "    def __init__(self):\n",
        "        super(ADNET, self).__init__()\n",
        "\n",
        "        self.action_history = tf.keras.layers.Input(shape = (1,1, ADNET.ACTION_DIM * ADNET.K))\n",
        "\n",
        "        self.conv1 = tf.keras.layers.Conv2D(filters = 96, kernel_size = (7, 7), strides = (2, 2), padding = 'VALID', activation = 'relu', name = 'conv_1')\n",
        "        self.max1  = tf.keras.layers.MaxPooling2D(pool_size=(3,3), strides = (1, 1), padding = 'VALID')\n",
        "        self.conv2 = tf.keras.layers.Conv2D(filters = 256, kernel_size = (5, 5), strides = (2, 2), padding = 'VALID', activation = 'relu', name = 'conv_2')\n",
        "        self.max2  = tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides = (2, 2), padding = 'VALID')\n",
        "        self.conv3 = tf.keras.layers.Conv2D(filters = 512, kernel_size = (3, 3), strides = (2, 2), padding = 'VALID', activation = 'relu', name = 'conv_3')\n",
        "        self.max3  = tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides = (1, 1), padding = 'VALID')\n",
        "        \n",
        "        self.fc1 = tf.keras.layers.Conv2D(filters = 512, kernel_size = (3, 3), padding = 'VALID', activation = 'relu', name = 'fc1')\n",
        "        self.fc2 = tf.keras.layers.Conv2D(filters = 512, kernel_size = (1,1), padding = 'VALID', activation = 'relu', name = 'fc2')\n",
        "        self.fc3 = tf.keras.layers.Conv2D(filters = 11, kernel_size = (1,1), padding = 'VALID', name = 'fc3',activation=\"softmax\")\n",
        "        self.fc4 = tf.keras.layers.Conv2D(filters = 2, kernel_size = (1,1), padding = 'VALID', name = 'fc4',activation=\"softmax\")\n",
        "\n",
        "        # TODO: ADD A SEED\n",
        "        self.dropout1=tf.keras.layers.Dropout(DROPOUT_4)\n",
        "        self.dropout2=tf.keras.layers.Dropout(DROPOUT_5)\n",
        "        \n",
        "\n",
        "    def build(self):\n",
        "      super(ADNET, self).build((None, 112, 112, 3))\n",
        "      self.action_history = np.zeros(shape = (1,1,1,110))\n",
        "\n",
        "\n",
        "    def call(self, input_tensor, training=False):\n",
        "        x = self.conv1(input_tensor)\n",
        "        x = self.max1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.max2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.max3(x)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = tf.keras.layers.Concatenate(axis=-1)([x, self.action_history])\n",
        "        action = self.fc3(x)\n",
        "        confidence = self.fc4(x)\n",
        "        return [action, confidence]\n",
        "\n",
        "\n",
        "    def compile(self, optimizer):\n",
        "   \t\tsuper().compile(optimizer, loss={\n",
        "         'output_1':tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "         'output_2': tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "         })\n",
        "     \n",
        "    def getEmbedding(self,input_tensor):\n",
        "        x = self.conv1(input_tensor)\n",
        "        x = self.max1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.max2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.max3(x)\n",
        "        return tf.reshape(x,(-1,))\n",
        "\n",
        "    def getFC1(self,input_tensor):\n",
        "        x = self.conv1(input_tensor)\n",
        "        x = self.max1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.max2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.max3(x)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "    def setActionHistory(self, action_history):\n",
        "      self.action_history = action_history.reshape(\n",
        "          (1, 1, 1, ADNET.ACTION_DIM * ADNET.K))\n",
        "\n",
        "    def updateActionHistory(self, a: int=8) -> tnp.ndarray:\n",
        "      '''\n",
        "      Left-to-right FIFO queue of actions\n",
        "      '''\n",
        "      ah = np.array(self.action_history).flatten()\n",
        "      ah[ADNET.ACTION_DIM:] = ah[:-ADNET.ACTION_DIM]\n",
        "      ah[:ADNET.ACTION_DIM] = 0 \n",
        "      ah[a] = 1\n",
        "      self.setActionHistory(ah)\n",
        "      return ah\n",
        "\n",
        "    def clearActionHistory(self):\n",
        "      self.action_history = tf.zeros((1, 1, 1, ADNET.ACTION_DIM * ADNET.K))\n",
        "\n",
        "    def getPrettyActionHistory(self):\n",
        "      action_hist = tf.reshape(model.action_history, [-1])\n",
        "      sbuffer = \"[\"\n",
        "      for i, x in enumerate(action_hist):\n",
        "        if i > 0 and i % model.ACTION_DIM == 0:\n",
        "          sbuffer+= \"\\x1b[35m,\\x1b[0m\"\n",
        "        if x == 1:\n",
        "          sbuffer += \"\\x1b[35m{0}\\x1b[0m\".format(int(x))\n",
        "        else:\n",
        "          sbuffer += \"{0}\".format(int(x))\n",
        "      sbuffer += \"]\"\n",
        "      return sbuffer \n",
        "\n",
        "\n",
        "    def debugModelSummary(self):\n",
        "      '''\n",
        "      call model.debugModelSummary().summary() to get around the inconvenience \n",
        "      from model.summary() returning 'multiple' for each layer's output shape\n",
        "      '''\n",
        "      dummyInput = tf.keras.layers.Input(shape = (112,112,3))\n",
        "      return tf.keras.Model(inputs=[dummyInput], outputs = self.call(dummyInput))\n",
        "\n",
        "def setAllWeights(model, weights):\n",
        "  model.layers[0].set_weights([weights[\"conv1f\"], tf.reshape(weights[\"conv1b\"],(96,))])\n",
        "  model.layers[2].set_weights([weights[\"conv2f\"], tf.reshape(weights[\"conv2b\"],(256,))])\n",
        "  model.layers[4].set_weights([weights[\"conv3f\"], tf.reshape(weights[\"conv3b\"],(512,))])\n",
        "  model.layers[6].set_weights([weights[\"fc4f\"], tf.reshape(weights[\"fc4b\"],(512,))])\n",
        "  model.layers[7].set_weights([weights[\"fc5f\"], tf.reshape(weights[\"fc5b\"],(512,))])\n",
        "  model.layers[8].set_weights([weights[\"fc6_1f\"], tf.zeros(11)])\n",
        "  model.layers[9].set_weights([weights[\"fc6_2f\"], tf.zeros(2)])\n",
        "\n",
        "\n",
        "def setWeights(model, weights, weights2):\n",
        "  model.layers[0].set_weights([weights2[\"conv1f\"],tf.reshape(weights2[\"conv1b\"],(96,))])\n",
        "  model.layers[2].set_weights([weights2[\"conv2f\"],tf.reshape(weights2[\"conv2b\"],(256,))])\n",
        "  model.layers[4].set_weights([weights2[\"conv3f\"],tf.reshape(weights2[\"conv3b\"],(512,))])\n",
        "  \n",
        "  model.layers[6].set_weights([weights[\"fc4f\"],tf.reshape(weights[\"fc4b\"],(512,))])\n",
        "  model.layers[7].set_weights([weights[\"fc5f\"],tf.reshape(weights[\"fc5b\"],(512,))])\n",
        "  model.layers[8].set_weights([weights[\"fc6_1f\"],tf.zeros(11)])\n",
        "  model.layers[9].set_weights([weights[\"fc6_2f\"],tf.zeros(2)])\n",
        "  \n",
        "  return model\n",
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "WwHHmGrxq-b6"
      },
      "outputs": [],
      "source": [
        "class ADNET_v2(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(ADNET_v2, self).__init__()\n",
        "\n",
        "        #self.action_history = tf.keras.layers.Input(shape = (1,1,110))\n",
        "        self.action_history = tf.keras.layers.Input(shape = (110))\n",
        "\n",
        "        self.resnet=tf.keras.applications.ResNet50V2(include_top=False,weights=\"imagenet\",input_shape=(112,112,3),pooling=\"max\")\n",
        "        #self.resnet = tf.keras.applications.ResNet50V2(include_top=False,weights=\"imagenet\",input_shape=(112,112,3),pooling=None)\n",
        "        #self.conv1 = tf.keras.layers.Conv2D(filters = 128, kernel_size = (4,4), padding = 'VALID', name = 'fc4',activation=\"relu\")\n",
        "        \n",
        "        self.fc1 = tf.keras.layers.Dense(512,kernel_initializer='glorot_uniform',activation = 'relu', name = 'fc1')\n",
        "        self.fc2 = tf.keras.layers.Dense(512,kernel_initializer='glorot_uniform', activation = 'relu', name = 'fc2')\n",
        "        self.fc3 = tf.keras.layers.Dense(11,kernel_initializer='glorot_uniform', name = 'fc3',activation=\"softmax\")\n",
        "        self.fc4 = tf.keras.layers.Dense(2,kernel_initializer='glorot_uniform',name = 'fc4',activation=\"softmax\")\n",
        "\n",
        "        self.dropout1=tf.keras.layers.Dropout(0)\n",
        "        self.dropout2=tf.keras.layers.Dropout(0)\n",
        "        \n",
        "\n",
        "    def build(self, action_history):\n",
        "      super(ADNET_v2, self).build((None, 112, 112, 3))\n",
        "      self.action_history=action_history\n",
        "      self.resnet.trainable = False\n",
        "\n",
        "\n",
        "    def setActionHistory(self, action_history):\n",
        "      self.action_history=action_history\n",
        "\n",
        "\n",
        "    def call(self, input_tensor, training=False):\n",
        "        x = self.resnet(input_tensor)\n",
        "        #x = self.conv1(x)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x=  self.dropout1(x)\n",
        "        x = self.fc2(x)\n",
        "        x=  self.dropout2(x)\n",
        "        x = tf.keras.layers.Concatenate(axis=-1)([x, self.action_history])\n",
        "        action = self.fc3(x)\n",
        "        confidence = self.fc4(x)\n",
        "        return [action, confidence]\n",
        "\n",
        "     \n",
        "    def debugModelSummary(self):\n",
        "      '''\n",
        "      call model.debugModelSummary().summary() to get around the inconvenience \n",
        "      from model.summary() returning 'multiple' for each layer's output shape\n",
        "      '''\n",
        "      dummyInput = tf.keras.layers.Input(shape = (112,112,3))\n",
        "      return tf.keras.Model(inputs=[dummyInput], outputs = self.call(dummyInput))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcjMuA1EjRsE"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xY2WCmjC2gLN"
      },
      "source": [
        "### Plotting & Debugging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "NtQ22_87T8MQ",
        "outputId": "bf1e99f9-8c1e-4ffd-ce3a-4344d27ec90e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[171 128  99 316]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "def get_ground_truths(ground_truth_file: str) -> np.array:\n",
        "  '''\n",
        "  Use me to convert a ground_truth_file to a numpy array\n",
        "  '''\n",
        "  with open(ground_truth_file) as f:\n",
        "    ground_truths = f.readlines()\n",
        "    to_nparray = lambda s: np.array(re.findall('\\d+', s), dtype=int)\n",
        "    truths = list(map(to_nparray, ground_truths))\n",
        "    return np.asarray(truths)\n",
        "  return None\n",
        "\n",
        "def plotNpImageBBox(img: np.array, bbox: np.array) -> np.array:\n",
        "  '''\n",
        "  Plots the bounding box on an image and returns the bounding box\n",
        "  '''\n",
        "  fig, ax = plt.subplots()\n",
        "  x, y, w, h = bbox\n",
        "  rect = patches.Rectangle((x, y), w, h, linewidth=1, edgecolor='r', facecolor='none')\n",
        "  ax.add_patch(rect)\n",
        "  plt.imshow(img)\n",
        "  return bbox\n",
        "\n",
        "def plotNpImageBBoxes(img: np.array, src_bbox: np.array, target_bbox: np.array, \n",
        "                      pred_bbox: np.array) -> np.array:\n",
        "  '''\n",
        "  Plots the bounding boxes on an image and returns the bounding box\n",
        "  '''\n",
        "  fig, ax = plt.subplots()\n",
        "  x1, y1, w1, h1 = src_bbox\n",
        "  x2, y2, w2, h2 = target_bbox\n",
        "  x3, y3, w3, h3 = pred_bbox\n",
        "  rect1 = patches.Rectangle((x1, y1), w1, h1, linewidth=1, edgecolor='b', facecolor='none')\n",
        "  rect2 = patches.Rectangle((x2, y2), w2, h2, linewidth=1, edgecolor='g', facecolor='none')\n",
        "  rect3 = patches.Rectangle((x3, y3), w3, h3, linewidth=1, edgecolor='r', facecolor='none')\n",
        "  ax.add_patch(rect1)\n",
        "  ax.add_patch(rect2)\n",
        "  ax.add_patch(rect3)\n",
        "  plt.imshow(img)\n",
        "  return pred_bbox  \n",
        "\n",
        "def plotImageBBox(img: str, bbox: np.array) -> np.array:\n",
        "  '''\n",
        "  Plots the bounding box on an image (from given filepath) and returns the \n",
        "  bounding box\n",
        "  '''\n",
        "  img = cv2.imread(img)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  plotNpImageBBox(img, bbox)\n",
        "  return bbox\n",
        "\n",
        "def plotDatasetImageBBox(dataset: str, frame_no: int) -> Tuple[np.array, int]:\n",
        "  '''\n",
        "  Plot an image's bounding box. Returns the ground truth and frame number.\n",
        "  WORKS FOR OTB100\n",
        "  '''\n",
        "  imgs = sorted(glob.glob(\"{0}/img/*\".format(dataset)))\n",
        "  gt = get_ground_truths(\"{0}/groundtruth_rect.txt\".format(dataset))\n",
        "  plotImageBBox(imgs[frame_no], gt[frame_no])\n",
        "  return gt[frame_no], frame_no\n",
        "\n",
        "\n",
        "# print(plotDatasetImageBBox(\"adnet_datasets/OTB/Basketball\", 50)[0])\n",
        "print(plotDatasetImageBBox(\"adnet_datasets/OTB/BlurBody\", 10)[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX5bfwFm2c80"
      },
      "source": [
        "### Movement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "VzDdHq04ERNg"
      },
      "outputs": [],
      "source": [
        "STOP_ACTION_INDEX = 8\n",
        "\n",
        "def getFrame(f_path: str) -> np.array:\n",
        "  print(\"Frame path: {0}\".format(f_path))\n",
        "  img = cv2.imread(f_path)\n",
        "  return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\n",
        "def calculate_IOU(bbox1: np.array, bbox2: np.array):\n",
        "    x1, y1, w1, h1 = bbox1\n",
        "    x2, y2, w2, h2 = bbox2\n",
        "           \n",
        "    i_x1 = max(x1, x2)\n",
        "    i_y1 = max(y1, y2)\n",
        "    i_x2 = min(x1 + w1, x2 + w2)\n",
        "    i_y2 = min(y1 + h1, y2 + h2)\n",
        "    if i_x1 >= i_x2 or i_y1 >= i_y2:\n",
        "      return 0.0\n",
        "\n",
        "    intersection_area = (i_x2 - i_x1) * (i_y2 - i_y1)\n",
        "    box1_area = w1 * h1\n",
        "    box2_area = w2 * h2\n",
        "    \n",
        "    iou = intersection_area / float(box1_area + box2_area - intersection_area)\n",
        "    return iou\n",
        "\n",
        "\n",
        "def move(image: np.array, bbox: np.array, action: str, \n",
        "         stride_magnitude: int=1) -> np.array:\n",
        "  '''\n",
        "  Returns the new bounding box after taking an action: \n",
        "  {\"left\", \"right\", \"up\", \"down\"}. Use stride to indicate the step size.\n",
        "  '''\n",
        "  if action not in set([\"left\", \"right\", \"up\", \"down\"]):\n",
        "    raise RuntimeError(\"Invalid action taken :(\") \n",
        "  \n",
        "  x, y, w, h = bbox\n",
        "  if action in set([\"left\", \"right\"]):\n",
        "    step = max(1, int(ALPHA * w)) * stride_magnitude * (-1 if action==\"left\" else 1)\n",
        "    x = min(max(0, int(x + step)), int(image.shape[1] - w - 1)) \n",
        "  else:\n",
        "    step = max(1, int(ALPHA * h)) * stride_magnitude * (-1 if action==\"up\" else 1)\n",
        "    y = min(max(0, int(y + step)), int(image.shape[0] - h - 1)) \n",
        "\n",
        "  return np.array([x, y, w, h])\n",
        "\n",
        "\n",
        "def scale(image: np.array, bbox: np.array, scaleUp: bool):\n",
        "  x, y, w, h = bbox\n",
        "  deltaW, deltaH = max(2, ALPHA * w), max(2, ALPHA * h)\n",
        "  if not scaleUp: \n",
        "    deltaW *= -1\n",
        "    deltaH *= -1\n",
        "  nw = min(image.shape[1], max(MIN_WINDOW_SIZE, int(w + deltaW))) \n",
        "  nh = min(image.shape[0], max(MIN_WINDOW_SIZE, int(h + deltaH)))\n",
        "  \n",
        "\n",
        "  x = max(0, min(int(x - deltaW / 2), int(image.shape[1] - w - 1)))\n",
        "  y = max(0, min(int(y - deltaH / 2), int(image.shape[0] - h - 1)))\n",
        "  return np.array([x, y, nw, nh])\n",
        "\n",
        "\n",
        "def selectAction(img: np.array, bbox: np.array, index: int): \n",
        "  if index == 0 :\n",
        "    bbox = move(img, bbox, \"left\")\n",
        "  elif index == 1 :\n",
        "    bbox = move(img, bbox, \"left\", stride_magnitude=2)\n",
        "  elif index == 2 :\n",
        "    bbox = move(img, bbox, \"right\")\n",
        "  elif index == 3 :\n",
        "    bbox = move(img, bbox, \"right\", stride_magnitude=2)  \n",
        "  elif index == 4 :\n",
        "    bbox = move(img, bbox, \"up\")  \n",
        "  elif index == 5 :\n",
        "    bbox = move(img, bbox, \"up\", stride_magnitude=2)\n",
        "  elif index == 6 :\n",
        "    bbox = move(img, bbox, \"down\")\n",
        "  elif index == 7 :\n",
        "    bbox = move(img, bbox, \"down\", stride_magnitude=2)\n",
        "  elif index == 8:\n",
        "    bbox = bbox\n",
        "  elif index == 9 :\n",
        "    bbox = scale(img, bbox, False)     \n",
        "  elif index == 10 :\n",
        "    bbox = scale(img, bbox, True)    \n",
        "  else:\n",
        "    raise ValueError(\"Invalid action provided: {0}\".format(index))\n",
        "\n",
        "  x, y, w, h = bbox\n",
        "  # some of the data is just invalid :/\n",
        "  # assert 0 <= x <= img.shape[1] - w, \"x:{0}, w:{1} is out of bounds: [0, {2}]\".format(x, w, img.shape[1])\n",
        "  # assert 0 <= y <= img.shape[0] - h, \"y:{0}, h:{1} is out of bounds: [0, {2}]\".format(y, h, img.shape[0])\n",
        "  # assert MIN_WINDOW_SIZE <= w <= img.shape[1], \"w:{0}, is invalid\".format(w)\n",
        "  # assert MIN_WINDOW_SIZE <= h <= img.shape[0], \"h:{0} is invalid\".format(h)\n",
        "  return index, bbox\n",
        "\n",
        "\n",
        "def human_readable_action(index: int) -> str:\n",
        "  '''\n",
        "  Map action numbers to human readable strings\n",
        "  '''\n",
        "  def _get_action(index:int) -> str:\n",
        "    if index == 0:\n",
        "      return \"left\"\n",
        "    elif index == 1:\n",
        "      return \"2x left\"\n",
        "    elif index == 2:\n",
        "      return \"right\"\n",
        "    elif index == 3:\n",
        "      return \"2x right\"\n",
        "    elif index == 4:\n",
        "      return \"up\"\n",
        "    elif index == 5:\n",
        "      return \"2x up\"\n",
        "    elif index == 6:\n",
        "      return \"down\"\n",
        "    elif index == 7:\n",
        "      return \"2x down\"\n",
        "    elif index == 8:\n",
        "      return \"stop\"\n",
        "    elif index == 9:\n",
        "      return \"scale down\"\n",
        "    elif index == 10 :\n",
        "      return \"scale up\"\n",
        "  return _get_action(index).upper()\n",
        "\n",
        "\n",
        "def getAction(img: np.array, bbox: np.array, action_probs: np.array):  \n",
        "  a = -1\n",
        "  if POLICY_TYPE == \"deterministic\":\n",
        "    a = tf.math.argmax(action_probs)\n",
        "  else:\n",
        "    action_probs = np.array(action_probs) + PROB_OFFSET\n",
        "    action_probs /= action_probs.sum()\n",
        "  \n",
        "    a = np.random.choice(np.arange(len(action_probs)), p=action_probs)\n",
        "  return selectAction(img, bbox, a)\n",
        "\n",
        "\n",
        "def isStop(action: int):\n",
        "  return action == STOP_ACTION_INDEX\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLxdpmQ5jOjL"
      },
      "source": [
        "# REINFORCE Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CP9qJBgVq5B"
      },
      "source": [
        "### Trajectory Loss Function\n",
        "\n",
        "TODO: investigate adding https://www.analyticsvidhya.com/blog/2020/11/baseline-for-policy-gradients/\n",
        "Or rather https://arxiv.org/pdf/1301.2315.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "Id7dQxPDVtJ_"
      },
      "outputs": [],
      "source": [
        "def getNonStopScore(bbox1: np.array, bbox2: np.array, gt: np.array) -> float:\n",
        "  # Issues with this blowing up the gradient in the wrong direction\n",
        "\n",
        "  def _dist(x1, y1, x2, y2):\n",
        "    return math.sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2)\n",
        "  \n",
        "  prevIou = calculate_IOU(bbox1, gt) \n",
        "  nextIou = calculate_IOU(bbox2, gt)\n",
        "  x1, y1 = bbox1[:2]\n",
        "  x2, y2 = bbox2[:2]\n",
        "  xg, yg = gt[:2]\n",
        "\n",
        "  # if prevIou == nextIou: EXPERIMENTED WITH USING EUCLIDEAN DISTANCE\n",
        "  #   return -1 * (_dist(x2, y2, xg, yg) - _dist(x1, y1, xg, yg))\n",
        "  result = nextIou - prevIou \n",
        "  return result \n",
        "\n",
        "def seqLosses(action_probs: List[np.array], actions_taken: List[int], \n",
        "              bboxes: List[np.array], \n",
        "              target_bbox: np.array) -> np.array:\n",
        "\n",
        "    assertMsg = \"Invalid trajectory: actions taken ({0}) + 1 != Bboxes length ({1})\".format(\n",
        "              len(actions_taken), len(bboxes)) \n",
        "    assert len(actions_taken) + 1 == len(bboxes), assertMsg\n",
        "          \n",
        "    src_bbox = np.array(bboxes[0])\n",
        "    end_bbox = np.array(bboxes[-1])\n",
        "    print(\"\\x1b[34m>> Calculating frame loss : {0} -> {1} (Target was {2})\\x1b[0m\".format(\n",
        "            np.array2string(src_bbox, separator=', '),\n",
        "            np.array2string(end_bbox, separator=', '),\n",
        "            np.array2string(target_bbox, separator=', ')))\n",
        "    rewards = np.zeros(len(actions_taken))\n",
        "    discounts = np.zeros(len(actions_taken))\n",
        "    for i, a in enumerate(actions_taken):\n",
        "      prev_bbox = np.array(bboxes[i])\n",
        "      next_bbox = np.array(bboxes[i+1])\n",
        "      ###################### CHANGE REWARD CALCULATION HERE ####################\n",
        "      if REWARD_SCHEME == \"final_bbox\":\n",
        "        rewards[i] = 1 if calculate_IOU(end_bbox, target_bbox) > GOAL_IOU\\\n",
        "                      else -1      \n",
        "      elif REWARD_SCHEME == \"only_final_bbox\" and i == len(actions_taken) - 1:\n",
        "        rewards[i] = 1 if calculate_IOU(end_bbox, target_bbox) > GOAL_IOU\\\n",
        "                      else -1      \n",
        "      else:\n",
        "        if isStop(a):\n",
        "          rewards[i] = 1 if calculate_IOU(next_bbox, target_bbox) > GOAL_IOU else -1\n",
        "        else:\n",
        "          rewards[i] = getNonStopScore(prev_bbox, next_bbox, target_bbox) \n",
        "      ###################### CHANGE REWARD CALCULATION UP ABOVE ################\n",
        "      prob_a = action_probs[i][a]\n",
        "      discounts[i] = GAMMA ** i\n",
        "      print(\"   |->> t={0} {1}-Reward ({2}) for {3}:bbox transition: {4} -> {5} w/ P(a|s)={6} and iou={7} and reward={8} and discount={9}\"\n",
        "            .format(i+1, \"Stop\" if isStop(a) else \"Diff\", \n",
        "                    np.around(rewards[i], decimals=3), \n",
        "                    human_readable_action(a).upper(),\n",
        "                    np.array2string(prev_bbox, separator=', '),\n",
        "                    np.array2string(next_bbox, separator=', '), prob_a, \n",
        "                    calculate_IOU(next_bbox, target_bbox), \n",
        "                    rewards[i], discounts[i]), \n",
        "            )\n",
        "    \n",
        "    gather_idx = [[i, a] for i, a in enumerate(actions_taken)]\n",
        "    p_a = tf.gather_nd(tf.stack(action_probs), gather_idx)\n",
        "    p_a = tf.clip_by_value(p_a, PROB_OFFSET, 1 - PROB_OFFSET) # done to prevent 0 reward   \n",
        "    \n",
        "    entropy = -1 * tf.math.reduce_sum((tf.math.log(action_probs) * action_probs), \n",
        "                                 axis=1) \n",
        "    \n",
        "    discount = tf.convert_to_tensor(discounts, dtype=tf.float32)\n",
        "    losses = -1 * (discount * rewards * tf.math.log(p_a))\n",
        "    \n",
        "    \n",
        "    print(\"   |->> Assigned losses: {0}\".format(losses))\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMujgGmUVu4k"
      },
      "source": [
        "### Tracking Procedure\n",
        "\n",
        "* This function collects trajectories either via argmax deterministic policy or sampling from a stochastic policy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "EqN0GHI5VlAM"
      },
      "outputs": [],
      "source": [
        "def getPatch(img: np.array, bbox: np.array) -> tf.Tensor:\n",
        "  def _patch(img: np.array, bbox: np.array) -> np.array:\n",
        "    x, y, w, h, = bbox\n",
        "    return img[y : (y + h), x : (x + w)]\n",
        "      \n",
        "  patch = tf.image.resize(_patch(img, bbox), [PATCH_X, PATCH_Y])\n",
        "  return tf.reshape(patch, (1, PATCH_X, PATCH_Y, N_CHANNELS))\n",
        "\n",
        "\n",
        "def tracking(model: ADNET, img: np.array, bbox: np.array,\n",
        "             t: int, target_bbox: np.array, \n",
        "             tracking_length: int= MAX_TRAJECTORY_LENGTH):\n",
        "    \"\"\" \n",
        "    Runs tracking until # actions > MAX_ACTIONS_SEQ_LIMIT, STOP is taken, or\n",
        "    oscillation occurs.\n",
        "    \"\"\"\n",
        "    print(\"|->> Beginning tracking for bbox:{0}\".format(bbox))    \n",
        "    patch = getPatch(img, bbox)\n",
        "    actions_taken = []\n",
        "    action_probs = []\n",
        "    bboxes = [tuple(bbox)]\n",
        "    prev_score = None\n",
        "    while len(actions_taken) < tracking_length:\n",
        "      prev_bbox = bbox.copy()\n",
        "      \n",
        "      probs, conf_score = model(patch)\n",
        "      probs = tf.reshape(probs, (model.ACTION_DIM)) \n",
        "      \n",
        "      a, bbox = getAction(np.array(img), bbox, probs)\n",
        "      prev_iou = calculate_IOU(prev_bbox, target_bbox)      \n",
        "      iou = calculate_IOU(bbox, target_bbox)   \n",
        "\n",
        "      if tuple(bbox) in bboxes:\n",
        "        print(\"|->> Revisiting bbox: {0}. Action {1} did nothing. Breaking action sequence\"\n",
        "                  .format(bbox, a))\n",
        "        print(\"   |->> Trajectory ending is FORCED\".format(iou))\n",
        "        a, bbox = 8, prev_bbox\n",
        "        if len(actions_taken) > 0:\n",
        "          # We observed too many trajectory STOPS were leading to gradient updates\n",
        "          # that reduce P(STOP|s) to near 0, which is undesirable. In this case, \n",
        "          # we allow STOPs if selected naturally by the policy or it's the only \n",
        "          # action on a trajectory (a trajectory MUST \n",
        "          # have at least one action). All other STOPs we just forego\n",
        "          # to prevent these harmful gradient updates\n",
        "          break\n",
        "      elif PREMATURE_BREAK and not isStop(a) and iou < GOAL_IOU  and prev_iou > GOAL_IOU:\n",
        "        # TRAJECTORY IS WORSENING\n",
        "        print(\"             |->> IOU declining: {0}:{1} -> {2}:{3}.\"\n",
        "                  .format(prev_bbox, prev_iou, bbox, iou))\n",
        "        print(\"             |->> Overriding with STOP\"\n",
        "                .format(iou))\n",
        "        a, bbox = 8, prev_bbox\n",
        "      \n",
        "      a_prob = probs[a] \n",
        "      print(\"   \\x1b[33m|->> #{0}/t={1}-th Action selection: {2}/{3} (P(a|s) = {4})\\x1b[0m\"\n",
        "                .format(len(actions_taken), t, a, human_readable_action(a).upper(), \n",
        "                        np.around(a_prob, decimals=3)))\n",
        "      print(\"      |->> Bounding box moves to: {0}\"\n",
        "                .format(bbox))\n",
        "      print(\"         |->> Action Probabilities (Rounded): {0}, argmax={1}\"\n",
        "              .format(np.around(probs.numpy(), decimals=4), np.argmax(probs)))\n",
        "      print(\"         |->> Action Probabilities (RAW): {0}, argmax={1}\"\n",
        "              .format(probs.numpy(), np.argmax(probs)))\n",
        "\n",
        "      if VERBOSE:\n",
        "        print(\"         |->> Overwriting action in buffer {0}\"\n",
        "            .format(model.getPrettyActionHistory() if VERBOSE else \"\"))\n",
        "        \n",
        "      action_probs.append(probs)\n",
        "      actions_taken.append(a)\n",
        "      model.updateActionHistory(a)\n",
        "      bboxes.append(tuple(bbox))  \n",
        "      patch = getPatch(img, bbox)      \n",
        "\n",
        "      # Stopping condition\n",
        "      if isStop(a):\n",
        "        print(\"         |->> Hit a STOP on the {0}-th action!\".format(t))\n",
        "        break  \n",
        "      \n",
        "      t += 1\n",
        "\n",
        "    print(\"    \\x1b[31m|->> Completed tracking\\x1b[0m\")\n",
        "    \n",
        "    return action_probs, actions_taken, bboxes, t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akOkB6DOxC_v"
      },
      "source": [
        "### Single Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "4w8_6oDV7900"
      },
      "outputs": [],
      "source": [
        "VERBOSE = True\n",
        "\n",
        "def train(model: ADNET, opt: tf.keras.optimizers.Optimizer, \n",
        "          dataset: str, start_frame: int, end_frame: int, \n",
        "          retry_count: int=N_RETRIES) -> float:\n",
        "  '''\n",
        "  Run training for a model on a frame sequence {start_frame, end_frame} \n",
        "  n_retries times.\n",
        "  :param: dataset: is the dataset path to train from\n",
        "  :param: retry_count: number of times to train on the frame sequence. \n",
        "  :return: returns the model and average loss\n",
        "  '''\n",
        "\n",
        "  gt = get_ground_truths(\"%s/groundtruth_rect.txt\" % dataset)\n",
        "  frames = sorted(glob.glob(os.path.join('%s/img' % dataset, '*.jpg'))) \n",
        "  loss = 0.0\n",
        "\n",
        "  train_vars = model.trainable_variables\n",
        "  accum_gradient = [tf.zeros_like(this_var) for this_var in train_vars]\n",
        "  for i in range(retry_count):\n",
        "    print(\"\\n\\x1b[36m####################### EPISODE # {0} ############################\\x1b[0m\".format(i+1))\n",
        "    bbox = gt[start_frame]\n",
        "    print(\"Starting bounding box={3} for {0}'s frames (index: {1})\\nsrc:{2}\\ntarget:{3}.\".format(\n",
        "        dataset, i, frames[start_frame], frames[end_frame], bbox))\n",
        "    \n",
        "    t = 1    \n",
        "    model.clearActionHistory()\n",
        "    for i in range(start_frame+1, end_frame+1):\n",
        "      with tf.GradientTape() as tape:\n",
        "        target_bbox = gt[i]\n",
        "        prev_bbox = np.array(bbox, copy=True)\n",
        "\n",
        "        print(\"\\x1b[34m>> Attempting to reach frame {0} with src: {1} and target: {2}\\x1b[0m\"\n",
        "            .format(i, np.array2string(bbox, separator=', '), \n",
        "                    np.array2string(target_bbox, separator=', ')))\n",
        "        img = getFrame(frames[i])\n",
        "        action_probs, taken_actions, bboxes, t = tracking(model, img, \n",
        "                                                          bbox, t, target_bbox)\n",
        "        bbox = np.array(bboxes[-1])\n",
        "\n",
        "\n",
        "        frame_losses = seqLosses(action_probs, taken_actions, bboxes, target_bbox)\n",
        "        total_frame_loss = tf.reduce_sum(frame_losses)\n",
        "        \n",
        "        loss += np.sum(total_frame_loss.numpy())\n",
        "        print(\"{0}>> Total frame loss: {1}\\x1b[0m\".format(\n",
        "              \"\\x1b[92m\" if total_frame_loss > 0 else \"\\x1b[31m\", \n",
        "              total_frame_loss))\n",
        "\n",
        "      gradients = tape.gradient(total_frame_loss, train_vars)\n",
        "      accum_gradient = [(acum_grad + grad) \n",
        "                        for acum_grad, grad in zip(accum_gradient, gradients)]\n",
        "\n",
        "    print(\"Final bounding box: {0} reached in {1} timesteps (originating from {2}). Target was {3}\"\n",
        "          .format(bbox, t, np.array(gt[start_frame]), np.array(gt[end_frame])))\n",
        "    print(\"\\n\\x1b[36m############# END EPISODE # {0} in t={1} timesteps ################\\x1b[0m\"\n",
        "          .format(i+1, t))\n",
        "    \n",
        "\n",
        "  print(\"Avg Loss Across Trajectories: {0}\\x1b[0m\".format(\n",
        "      \"\\x1b[92m\" if loss > 0 else \"\\x1b[31m\"))  \n",
        "  \n",
        "  \n",
        "  \n",
        "  accum_gradient = [g / retry_count if GRAD_ACCUM_SCHEME == \"avg\" else g \n",
        "                    for g in accum_gradient]\n",
        "  for i in range(len(accum_gradient)):\n",
        "      print(\"Layer Name: {}, GRAD NORM = {}\".format(\n",
        "      adnet_model.trainable_variables[i].name, tf.norm(accum_gradient[i])))\n",
        "  opt.apply_gradients(zip(accum_gradient, model.trainable_variables))\n",
        "  return model, loss / retry_count\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFKnC5VrgVhn"
      },
      "source": [
        "### Epoch Training Loops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "otMLmAPjVSiS"
      },
      "outputs": [],
      "source": [
        "def epochs_train(model: ADNET, opt: tf.keras.optimizers.Optimizer, \n",
        "                 datasets: List[str], \n",
        "                 epochs: int=1, retry_count: int=1, action_strategy: str=\"max\",\n",
        "                 seq_length: int=10, randomize: bool=RANDOMIZE_TRAINING):\n",
        "\n",
        "  print(\"TRAINING ON: {0}\".format(datasets))\n",
        "  # Collect list of datasets & trainable frames\n",
        "  dataset_frames = []\n",
        "  for d in datasets:\n",
        "    frames = sorted(glob.glob(os.path.join('%s/img' % d, '*.jpg')))\n",
        "    frames = list(range(len(frames) - L))\n",
        "    for f in frames:\n",
        "      dataset_frames.append((d, f))\n",
        "  if randomize: random.shuffle(dataset_frames)\n",
        "\n",
        "  # Train for n epochs\n",
        "  losses = {}\n",
        "  bad_data_log = []\n",
        "  for e in range(epochs):\n",
        "    epoch_loss = []\n",
        "    \n",
        "    for i, d_frame in enumerate(dataset_frames):\n",
        "      d, start_frame = d_frame\n",
        "      end_frame = start_frame + seq_length\n",
        "\n",
        "      print(\"\\n\\n#############################################\")\n",
        "      print(\"Dataset={0}\".format(d))\n",
        "      print(\"#################################################\")\n",
        "      adnet_model, l = train(model, opt, d, start_frame, end_frame, \n",
        "                             retry_count=retry_count)\n",
        "      epoch_loss.append(l)\n",
        "      print(\"#################################################\")\n",
        "      print(\"#################################################\")\n",
        "      \n",
        "    losses[e] = epoch_loss\n",
        "\n",
        "  print(\"Finished Training On: {0}\".format(datasets))\n",
        "  return model, losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5g5kT2HgaoO"
      },
      "source": [
        "# Training Procedure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "8wAaN7or552g"
      },
      "outputs": [],
      "source": [
        "%reload_ext autoreload"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adnet_model = ADNET()\n",
        "adnet_model.build()\n",
        "WEIGHTS_PATH = \"yifanweights.mat\"\n",
        "weights = hdf5storage.loadmat(WEIGHTS_PATH)\n",
        "adnet_model = setWeights(adnet_model,weights,weights)\n",
        "adnet_model.layers[-3].trainable=False"
      ],
      "metadata": {
        "id": "Isj57xK2FnN7"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To reload saved weights"
      ],
      "metadata": {
        "id": "pZt5PyM2Foj4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SAVED_MODEL_PATH = \"derek_models/19-12-2021_060516\"\n",
        "loaded_model = tf.keras.models.load_model(SAVED_MODEL_PATH, \n",
        "                                         custom_objects={\"ADNET\": ADNET}, \n",
        "                                          compile=False)\n",
        "loaded_model.compile(optimizer=Adam(learning_rate=LEARNING_RATE))\n",
        "adnet_model.set_weights(loaded_model.get_weights())"
      ],
      "metadata": {
        "id": "P7aHgxIpCLpa"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEsOSSVhg-qp",
        "outputId": "35ddd718-c6f6-481f-ccb8-bae6f6e2ddbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on datasets: ['adnet_datasets/OTB/Rubik', 'adnet_datasets/OTB/Girl', 'adnet_datasets/OTB/Shaking']\n"
          ]
        }
      ],
      "source": [
        "N_VIDEOS = 3\n",
        "datasets = np.random.choice(len(ALL_DATASETS_LIST), size=N_VIDEOS, replace=False)\n",
        "datasets = list(map(lambda rand_idx: ALL_DATASETS_LIST[rand_idx], datasets))\n",
        "print(\"Training on datasets: {0}\".format(datasets))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41yhNXMygPIy",
        "outputId": "6fbbcd29-8ccd-4250-fe56-29fa332b0175"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            " 0.09751283 0.08029248 0.21307258 0.06070264 0.08397444], argmax=8\n",
            "|->> Revisiting bbox: [275 147 104 102]. ACtion 4 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [276, 148, 105, 103] -> [275, 150, 104, 102] (Target was [279, 144,  90,  97])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.014) for SCALE UP:bbox transition: [276, 148, 105, 103] -> [274, 146, 108, 106] w/ P(a|s)=0.09042461961507797 and iou=0.7352941176470589 and reward=-0.013699170943545114 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.042) for SCALE DOWN:bbox transition: [274, 146, 108, 106] -> [275, 147, 104, 102] w/ P(a|s)=0.06970811635255814 and iou=0.7777164920022063 and reward=0.042422374355147396 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (1.0) for DOWN:bbox transition: [275, 147, 104, 102] -> [275, 150, 104, 102] w/ P(a|s)=0.09751283377408981 and iou=0.7346609257265877 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.03292238  0.11298938  2.3277712 ]\n",
            "\u001b[92m>> Total frame loss: 2.4078381061553955\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1762 with src: [275, 150, 104, 102] and target: [279, 141,  89,  99]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1763.jpg\n",
            "|->> Beginning tracking for bbox:[275 150 104 102]\n",
            "|->> Revisiting bbox: [275 150 104 102]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=7-th Action selection: 8/STOP (P(a|s) = 0.25699999928474426)\u001b[0m\n",
            "      |->> Bounding box moves to: [275 150 104 102]\n",
            "         |->> Action Probabilities (Rounded): [0.0741 0.0666 0.0791 0.0715 0.0867 0.0657 0.089  0.0707 0.2568 0.0561\n",
            " 0.0838], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07407553 0.06660926 0.07910236 0.07147264 0.08667743 0.06572443\n",
            " 0.08896935 0.07065958 0.25678062 0.05613525 0.08379359], argmax=8\n",
            "         |->> Hit a STOP on the 7-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [275, 150, 104, 102] -> [275, 150, 104, 102] (Target was [279, 141,  89,  99])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [275, 150, 104, 102] -> [275, 150, 104, 102] w/ P(a|s)=0.25678062438964844 and iou=0.7020773073889035 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [1.3595332]\n",
            "\u001b[92m>> Total frame loss: 1.3595331907272339\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1763 with src: [275, 150, 104, 102] and target: [281, 139,  92,  99]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1764.jpg\n",
            "|->> Beginning tracking for bbox:[275 150 104 102]\n",
            "   \u001b[33m|->> #0/t=7-th Action selection: 9/SCALE DOWN (P(a|s) = 0.054999999701976776)\u001b[0m\n",
            "      |->> Bounding box moves to: [276 151 100  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0746 0.0591 0.0865 0.0673 0.0833 0.0657 0.0885 0.0716 0.2707 0.055\n",
            " 0.0777], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07463186 0.05913417 0.0864765  0.06734522 0.0833414  0.06569019\n",
            " 0.08847322 0.07159027 0.27068362 0.05496914 0.07766433], argmax=8\n",
            "   \u001b[33m|->> #1/t=8-th Action selection: 3/2X RIGHT (P(a|s) = 0.06700000166893005)\u001b[0m\n",
            "      |->> Bounding box moves to: [282 151 100  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0654 0.0561 0.0736 0.0666 0.08   0.0561 0.083  0.0669 0.3296 0.0475\n",
            " 0.0752], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06540969 0.05614029 0.07355703 0.06656183 0.08001885 0.05607984\n",
            " 0.08299101 0.06692815 0.32963377 0.0475127  0.07516685], argmax=8\n",
            "   \u001b[33m|->> #2/t=9-th Action selection: 3/2X RIGHT (P(a|s) = 0.0560000017285347)\u001b[0m\n",
            "      |->> Bounding box moves to: [288 151 100  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0666 0.0558 0.0666 0.0556 0.0695 0.0552 0.076  0.0641 0.3727 0.0439\n",
            " 0.074 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06655563 0.05584703 0.06655658 0.05562109 0.06948908 0.05523863\n",
            " 0.07600484 0.06410532 0.3726532  0.0439483  0.07398029], argmax=8\n",
            "|->> Revisiting bbox: [288 151 100  98]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [275, 150, 104, 102] -> [288, 151, 100,  98] (Target was [281, 139,  92,  99])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.037) for SCALE DOWN:bbox transition: [275, 150, 104, 102] -> [276, 151, 100,  98] w/ P(a|s)=0.05496913939714432 and iou=0.7340425531914894 and reward=0.03731277694364088 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.014) for 2X RIGHT:bbox transition: [276, 151, 100,  98] -> [282, 151, 100,  98] w/ P(a|s)=0.06656183302402496 and iou=0.7203166226912929 and reward=-0.013725930500196437 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [282, 151, 100,  98] -> [288, 151, 100,  98] w/ P(a|s)=0.05562108755111694 and iou=0.6423173803526449 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.10824374 -0.03719211 -2.8891928 ]\n",
            "\u001b[31m>> Total frame loss: -2.818141222000122\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1764 with src: [288, 151, 100,  98] and target: [284, 147,  90,  87]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1765.jpg\n",
            "|->> Beginning tracking for bbox:[288 151 100  98]\n",
            "|->> Revisiting bbox: [288 151 100  98]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=10-th Action selection: 8/STOP (P(a|s) = 0.42500001192092896)\u001b[0m\n",
            "      |->> Bounding box moves to: [288 151 100  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0628 0.0552 0.0577 0.0468 0.0679 0.0508 0.0711 0.059  0.4247 0.0401\n",
            " 0.0639], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0628063  0.05519834 0.05770604 0.0468398  0.06787954 0.05083777\n",
            " 0.07105284 0.05903526 0.42468923 0.04008849 0.06386638], argmax=8\n",
            "         |->> Hit a STOP on the 10-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [288, 151, 100,  98] -> [288, 151, 100,  98] (Target was [284, 147,  90,  87])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [288, 151, 100,  98] -> [288, 151, 100,  98] w/ P(a|s)=0.42468923330307007 and iou=0.680327868852459 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.8563976]\n",
            "\u001b[31m>> Total frame loss: -0.8563976287841797\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1765 with src: [288, 151, 100,  98] and target: [286, 147,  87,  82]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1766.jpg\n",
            "|->> Beginning tracking for bbox:[288 151 100  98]\n",
            "|->> Revisiting bbox: [288 151 100  98]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=10-th Action selection: 8/STOP (P(a|s) = 0.41200000047683716)\u001b[0m\n",
            "      |->> Bounding box moves to: [288 151 100  98]\n",
            "         |->> Action Probabilities (Rounded): [0.06   0.0514 0.0629 0.0483 0.0702 0.0489 0.0779 0.0589 0.4121 0.0407\n",
            " 0.0687], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0599687  0.0514158  0.06294256 0.04831253 0.07022417 0.04891985\n",
            " 0.0779008  0.05887185 0.41208434 0.04066248 0.06869689], argmax=8\n",
            "         |->> Hit a STOP on the 10-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [288, 151, 100,  98] -> [288, 151, 100,  98] (Target was [286, 147,  87,  82])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [288, 151, 100,  98] -> [288, 151, 100,  98] w/ P(a|s)=0.41208434104919434 and iou=0.6434394409937888 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.88652724]\n",
            "\u001b[31m>> Total frame loss: -0.8865272402763367\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1766 with src: [288, 151, 100,  98] and target: [284, 147,  93,  82]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1767.jpg\n",
            "|->> Beginning tracking for bbox:[288 151 100  98]\n",
            "   \u001b[33m|->> #0/t=10-th Action selection: 0/LEFT (P(a|s) = 0.05999999865889549)\u001b[0m\n",
            "      |->> Bounding box moves to: [285 151 100  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0601 0.0564 0.0624 0.0501 0.0655 0.0502 0.0813 0.0622 0.4008 0.0422\n",
            " 0.0688], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0601042  0.05640927 0.06237967 0.05011392 0.06551853 0.05018285\n",
            " 0.08133318 0.06216095 0.40078846 0.04217352 0.06883555], argmax=8\n",
            "   \u001b[33m|->> #1/t=11-th Action selection: 9/SCALE DOWN (P(a|s) = 0.039000000804662704)\u001b[0m\n",
            "      |->> Bounding box moves to: [286 152  97  95]\n",
            "         |->> Action Probabilities (Rounded): [0.0504 0.0494 0.0641 0.0518 0.0655 0.0494 0.0703 0.0618 0.4395 0.0387\n",
            " 0.0592], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05043787 0.04942151 0.06408978 0.05184342 0.06549521 0.04941317\n",
            " 0.07026913 0.06175199 0.43947154 0.03865546 0.0591509 ], argmax=8\n",
            "   \u001b[33m|->> #2/t=12-th Action selection: 0/LEFT (P(a|s) = 0.05299999937415123)\u001b[0m\n",
            "      |->> Bounding box moves to: [284 152  97  95]\n",
            "         |->> Action Probabilities (Rounded): [0.053  0.0452 0.0619 0.0519 0.0609 0.0436 0.0709 0.0579 0.4624 0.0332\n",
            " 0.059 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05300026 0.04521481 0.06192534 0.05194551 0.06093854 0.04360176\n",
            " 0.07087987 0.0578946  0.46238658 0.03318772 0.05902493], argmax=8\n",
            "|->> Revisiting bbox: [284 152  97  95]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [288, 151, 100,  98] -> [284, 152,  97,  95] (Target was [284, 147,  93,  82])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.038) for LEFT:bbox transition: [288, 151, 100,  98] -> [285, 151, 100,  98] w/ P(a|s)=0.06010419875383377 and iou=0.7000975609756097 and reward=0.03794571053684592 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.012) for SCALE DOWN:bbox transition: [285, 151, 100,  98] -> [286, 152,  97,  95] w/ P(a|s)=0.038655463606119156 and iou=0.7125279642058165 and reward=0.012430403230206832 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (1.0) for LEFT:bbox transition: [286, 152,  97,  95] -> [284, 152,  97,  95] w/ P(a|s)=0.05300026386976242 and iou=0.7397727272727272 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.10669103 0.04043694 2.9374585 ]\n",
            "\u001b[92m>> Total frame loss: 3.0845863819122314\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1767 with src: [284, 152,  97,  95] and target: [284, 142,  90,  85]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1768.jpg\n",
            "|->> Beginning tracking for bbox:[284 152  97  95]\n",
            "   \u001b[33m|->> #0/t=13-th Action selection: 0/LEFT (P(a|s) = 0.04899999871850014)\u001b[0m\n",
            "      |->> Bounding box moves to: [282 152  97  95]\n",
            "         |->> Action Probabilities (Rounded): [0.0491 0.0437 0.0729 0.0539 0.0604 0.048  0.0735 0.0583 0.4437 0.035\n",
            " 0.0615], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.04911622 0.04370518 0.07290503 0.0538938  0.06039543 0.04803492\n",
            " 0.07350422 0.05830285 0.44365996 0.03498754 0.06149483], argmax=8\n",
            "|->> Revisiting bbox: [284 152  97  95]. ACtion 2 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [284, 152,  97,  95] -> [282, 152,  97,  95] (Target was [284, 142,  90,  85])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for LEFT:bbox transition: [284, 152,  97,  95] -> [282, 152,  97,  95] w/ P(a|s)=0.04911622032523155 and iou=0.6673257538309442 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-3.013566]\n",
            "\u001b[31m>> Total frame loss: -3.013566017150879\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1768 with src: [282, 152,  97,  95] and target: [281, 150,  95,  85]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1769.jpg\n",
            "|->> Beginning tracking for bbox:[282 152  97  95]\n",
            "   \u001b[33m|->> #0/t=14-th Action selection: 5/2X UP (P(a|s) = 0.04899999871850014)\u001b[0m\n",
            "      |->> Bounding box moves to: [282 148  97  95]\n",
            "         |->> Action Probabilities (Rounded): [0.0564 0.0409 0.0694 0.0547 0.0613 0.0486 0.0739 0.0581 0.443  0.0346\n",
            " 0.059 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05643542 0.04094303 0.06939989 0.05471024 0.06132917 0.04861138\n",
            " 0.07386777 0.05808925 0.44299808 0.03456605 0.05904979], argmax=8\n",
            "   \u001b[33m|->> #1/t=15-th Action selection: 0/LEFT (P(a|s) = 0.05299999937415123)\u001b[0m\n",
            "      |->> Bounding box moves to: [280 148  97  95]\n",
            "         |->> Action Probabilities (Rounded): [0.0534 0.0419 0.0674 0.056  0.0623 0.0411 0.0792 0.0625 0.4469 0.0342\n",
            " 0.0552], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05338629 0.04188944 0.06735168 0.05597461 0.06227355 0.04111527\n",
            " 0.07915151 0.06254943 0.44692796 0.03420136 0.05517887], argmax=8\n",
            "|->> Revisiting bbox: [280 148  97  95]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [282, 152,  97,  95] -> [280, 148,  97,  95] (Target was [281, 150,  95,  85])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.037) for 2X UP:bbox transition: [282, 152,  97,  95] -> [282, 148,  97,  95] w/ P(a|s)=0.04861138388514519 and iou=0.8591397849462366 and reward=0.03683792997153168 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for LEFT:bbox transition: [282, 148,  97,  95] -> [280, 148,  97,  95] w/ P(a|s)=0.05338629335165024 and iou=0.8762886597938144 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.11139414 2.9302013 ]\n",
            "\u001b[92m>> Total frame loss: 3.041595458984375\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1769 with src: [280, 148,  97,  95] and target: [281, 145,  95,  91]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1770.jpg\n",
            "|->> Beginning tracking for bbox:[280 148  97  95]\n",
            "   \u001b[33m|->> #0/t=16-th Action selection: 2/RIGHT (P(a|s) = 0.07800000160932541)\u001b[0m\n",
            "      |->> Bounding box moves to: [282 148  97  95]\n",
            "         |->> Action Probabilities (Rounded): [0.0492 0.0411 0.0784 0.0656 0.0622 0.0461 0.0796 0.066  0.4213 0.0356\n",
            " 0.0548], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.04920173 0.04110133 0.07841613 0.06563654 0.06224257 0.04610047\n",
            " 0.07958961 0.0659992  0.4213207  0.03561164 0.05478017], argmax=8\n",
            "|->> Revisiting bbox: [280 148  97  95]. ACtion 0 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [280, 148,  97,  95] -> [282, 148,  97,  95] (Target was [281, 145,  95,  91])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for RIGHT:bbox transition: [280, 148,  97,  95] -> [282, 148,  97,  95] w/ P(a|s)=0.0784161314368248 and iou=0.8627450980392157 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [2.5457256]\n",
            "\u001b[92m>> Total frame loss: 2.5457255840301514\u001b[0m\n",
            "Final bounding box: [282 148  97  95] reached in 17 timesteps (originating from [269 144 109 107]). Target was [281 145  95  91]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 1770 in t=17 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[92m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 8.615240097045898\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 1.9837615489959717\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/Rubik\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Starting bounding box=adnet_datasets/OTB/Rubik/img/1771.jpg for adnet_datasets/OTB/Rubik's frames (index: 0)\n",
            "src:adnet_datasets/OTB/Rubik/img/1761.jpg\n",
            "target:adnet_datasets/OTB/Rubik/img/1771.jpg.\n",
            "\u001b[34m>> Attempting to reach frame 1761 with src: [277, 143,  94, 103] and target: [279, 144,  90,  97]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1762.jpg\n",
            "|->> Beginning tracking for bbox:[277 143  94 103]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 5/2X UP (P(a|s) = 0.0820000022649765)\u001b[0m\n",
            "      |->> Bounding box moves to: [277 137  94 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0885 0.0811 0.0936 0.0878 0.0915 0.0821 0.0957 0.0877 0.1201 0.0821\n",
            " 0.0897], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08852482 0.08108189 0.09364557 0.08775668 0.09146903 0.08214588\n",
            " 0.09572896 0.08767802 0.12014605 0.08214984 0.08967324], argmax=8\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 3/2X RIGHT (P(a|s) = 0.08299999684095383)\u001b[0m\n",
            "      |->> Bounding box moves to: [281 137  94 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0861 0.0777 0.0927 0.0835 0.088  0.0722 0.0977 0.0947 0.1426 0.0772\n",
            " 0.0876], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08614903 0.07772435 0.09267557 0.0834576  0.08800392 0.0722156\n",
            " 0.09769239 0.09467059 0.14257437 0.07724056 0.08759603], argmax=8\n",
            "   \u001b[33m|->> #2/t=3-th Action selection: 3/2X RIGHT (P(a|s) = 0.07699999958276749)\u001b[0m\n",
            "      |->> Bounding box moves to: [285 137  94 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0872 0.0822 0.088  0.0766 0.0858 0.0708 0.1023 0.0893 0.1554 0.0756\n",
            " 0.0867], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08719158 0.08218097 0.08799236 0.07663085 0.08583967 0.07084772\n",
            " 0.1023337  0.0893458  0.15539232 0.07558038 0.08666466], argmax=8\n",
            "   \u001b[33m|->> #3/t=4-th Action selection: 2/RIGHT (P(a|s) = 0.0820000022649765)\u001b[0m\n",
            "      |->> Bounding box moves to: [287 137  94 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0885 0.0869 0.082  0.0681 0.0848 0.0665 0.0952 0.0877 0.1803 0.0744\n",
            " 0.0857], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08853277 0.08685504 0.08204142 0.06814902 0.08475581 0.06645354\n",
            " 0.09516183 0.0876769  0.18027444 0.07439961 0.08569963], argmax=8\n",
            "   \u001b[33m|->> #4/t=5-th Action selection: 4/UP (P(a|s) = 0.0860000029206276)\u001b[0m\n",
            "      |->> Bounding box moves to: [287 134  94 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0951 0.0773 0.0745 0.0647 0.0856 0.0648 0.0969 0.09   0.195  0.0693\n",
            " 0.0868], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0951007  0.07727069 0.0745258  0.06473691 0.08556442 0.06482972\n",
            " 0.09686747 0.0899939  0.19501464 0.06925213 0.08684361], argmax=8\n",
            "   \u001b[33m|->> #5/t=6-th Action selection: 5/2X UP (P(a|s) = 0.061000000685453415)\u001b[0m\n",
            "      |->> Bounding box moves to: [287 128  94 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0805 0.0775 0.0797 0.0619 0.0812 0.0611 0.097  0.0879 0.2279 0.0647\n",
            " 0.0806], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08048255 0.07752144 0.07966971 0.0619241  0.08115544 0.0611276\n",
            " 0.09701398 0.08789971 0.22788413 0.06468438 0.08063687], argmax=8\n",
            "|->> Revisiting bbox: [287 134  94 103]. ACtion 7 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [277, 143,  94, 103] -> [287, 128,  94, 103] (Target was [279, 144,  90,  97])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.018) for 2X UP:bbox transition: [277, 143,  94, 103] -> [277, 137,  94, 103] w/ P(a|s)=0.08214588463306427 and iou=0.8841588211215718 and reward=-0.017514386893301093 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.036) for 2X RIGHT:bbox transition: [277, 137,  94, 103] -> [281, 137,  94, 103] w/ P(a|s)=0.08345760405063629 and iou=0.8478522681653954 and reward=-0.03630655295617646 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.069) for 2X RIGHT:bbox transition: [281, 137,  94, 103] -> [285, 137,  94, 103] w/ P(a|s)=0.0766308456659317 and iou=0.7792810204870506 and reward=-0.06857124767834477 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-0.032) for RIGHT:bbox transition: [285, 137,  94, 103] -> [287, 137,  94, 103] w/ P(a|s)=0.0820414200425148 and iou=0.7468690702087286 and reward=-0.032411950278322 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (-0.04) for UP:bbox transition: [287, 137,  94, 103] -> [287, 134,  94, 103] w/ P(a|s)=0.08556441962718964 and iou=0.7070276284071945 and reward=-0.03984144180153415 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (-1.0) for 2X UP:bbox transition: [287, 134,  94, 103] -> [287, 128,  94, 103] w/ P(a|s)=0.06112759932875633 and iou=0.6325589643553822 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.04377298 -0.0901643  -0.17614278 -0.08104709 -0.09794962 -2.7947917 ]\n",
            "\u001b[31m>> Total frame loss: -3.2838683128356934\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1762 with src: [287, 128,  94, 103] and target: [279, 141,  89,  99]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1763.jpg\n",
            "|->> Beginning tracking for bbox:[287 128  94 103]\n",
            "   \u001b[33m|->> #0/t=7-th Action selection: 2/RIGHT (P(a|s) = 0.0729999989271164)\u001b[0m\n",
            "      |->> Bounding box moves to: [289 128  94 103]\n",
            "         |->> Action Probabilities (Rounded): [0.079  0.0713 0.073  0.0577 0.0759 0.0524 0.0955 0.0873 0.2675 0.061\n",
            " 0.0794], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07897176 0.07131577 0.07298123 0.0576978  0.07591532 0.05240399\n",
            " 0.0954816  0.08728474 0.2675293  0.06104847 0.07936998], argmax=8\n",
            "   \u001b[33m|->> #1/t=8-th Action selection: 10/SCALE UP (P(a|s) = 0.07400000095367432)\u001b[0m\n",
            "      |->> Bounding box moves to: [287 126  96 106]\n",
            "         |->> Action Probabilities (Rounded): [0.0827 0.0712 0.0684 0.057  0.0677 0.049  0.1049 0.0846 0.287  0.0532\n",
            " 0.0743], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08267503 0.0712093  0.0683912  0.05702063 0.06774019 0.04898807\n",
            " 0.10492975 0.08457049 0.2869736  0.05318502 0.07431674], argmax=8\n",
            "   \u001b[33m|->> #2/t=9-th Action selection: 2/RIGHT (P(a|s) = 0.07100000232458115)\u001b[0m\n",
            "      |->> Bounding box moves to: [289 126  96 106]\n",
            "         |->> Action Probabilities (Rounded): [0.0708 0.0622 0.0711 0.0523 0.0687 0.0475 0.09   0.0786 0.3398 0.0544\n",
            " 0.0646], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07081439 0.06218376 0.07107516 0.05233361 0.06866007 0.04748262\n",
            " 0.0900025  0.07855881 0.3398451  0.05444917 0.06459476], argmax=8\n",
            "|->> Revisiting bbox: [289 126  96 106]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [287, 128,  94, 103] -> [289, 126,  96, 106] (Target was [279, 141,  89,  99])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.026) for RIGHT:bbox transition: [287, 128,  94, 103] -> [289, 128,  94, 103] w/ P(a|s)=0.07298123091459274 and iou=0.6246156549240095 and reward=-0.026102902605223743 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.01) for SCALE UP:bbox transition: [289, 128,  94, 103] -> [287, 126,  96, 106] w/ P(a|s)=0.07431674003601074 and iou=0.6345557851239669 and reward=0.009940130199957431 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-1.0) for RIGHT:bbox transition: [287, 126,  96, 106] -> [289, 126,  96, 106] w/ P(a|s)=0.07107515633106232 and iou=0.6093405661976606 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.06832573  0.02583857 -2.6440175 ]\n",
            "\u001b[31m>> Total frame loss: -2.686504602432251\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1763 with src: [289, 126,  96, 106] and target: [281, 139,  92,  99]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1764.jpg\n",
            "|->> Beginning tracking for bbox:[289 126  96 106]\n",
            "|->> Revisiting bbox: [289 126  96 106]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=10-th Action selection: 8/STOP (P(a|s) = 0.36000001430511475)\u001b[0m\n",
            "      |->> Bounding box moves to: [289 126  96 106]\n",
            "         |->> Action Probabilities (Rounded): [0.0787 0.0542 0.0553 0.0499 0.0642 0.0468 0.0935 0.0791 0.3599 0.0509\n",
            " 0.0675], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07869393 0.05419706 0.05528249 0.04993767 0.06418517 0.04682135\n",
            " 0.09347084 0.07913046 0.35986754 0.05093065 0.06748282], argmax=8\n",
            "         |->> Hit a STOP on the 10-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [289, 126,  96, 106] -> [289, 126,  96, 106] (Target was [281, 139,  92,  99])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [289, 126,  96, 106] -> [289, 126,  96, 106] w/ P(a|s)=0.35986754298210144 and iou=0.6809623430962343 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-1.0220193]\n",
            "\u001b[31m>> Total frame loss: -1.0220192670822144\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1764 with src: [289, 126,  96, 106] and target: [284, 147,  90,  87]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1765.jpg\n",
            "|->> Beginning tracking for bbox:[289 126  96 106]\n",
            "|->> Revisiting bbox: [289 126  96 106]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=10-th Action selection: 8/STOP (P(a|s) = 0.3889999985694885)\u001b[0m\n",
            "      |->> Bounding box moves to: [289 126  96 106]\n",
            "         |->> Action Probabilities (Rounded): [0.0698 0.0578 0.0653 0.0473 0.062  0.0433 0.0919 0.071  0.3886 0.0446\n",
            " 0.0585], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06978759 0.05782811 0.06526445 0.04731091 0.06195742 0.04331327\n",
            " 0.09190857 0.07095643 0.38863748 0.04456911 0.05846667], argmax=8\n",
            "         |->> Hit a STOP on the 10-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [289, 126,  96, 106] -> [289, 126,  96, 106] (Target was [284, 147,  90,  87])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [289, 126,  96, 106] -> [289, 126,  96, 106] w/ P(a|s)=0.3886374831199646 and iou=0.6701604674891012 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.9451083]\n",
            "\u001b[31m>> Total frame loss: -0.9451082944869995\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1765 with src: [289, 126,  96, 106] and target: [286, 147,  87,  82]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1766.jpg\n",
            "|->> Beginning tracking for bbox:[289 126  96 106]\n",
            "|->> Revisiting bbox: [289 126  96 106]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=10-th Action selection: 8/STOP (P(a|s) = 0.37400001287460327)\u001b[0m\n",
            "      |->> Bounding box moves to: [289 126  96 106]\n",
            "         |->> Action Probabilities (Rounded): [0.0694 0.0553 0.0631 0.0505 0.0676 0.0479 0.091  0.0689 0.3743 0.0468\n",
            " 0.0652], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06937894 0.05526867 0.06307677 0.05054975 0.06758187 0.04790963\n",
            " 0.0910127  0.06886856 0.3743211  0.04684432 0.06518767], argmax=8\n",
            "         |->> Hit a STOP on the 10-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [289, 126,  96, 106] -> [289, 126,  96, 106] (Target was [286, 147,  87,  82])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [289, 126,  96, 106] -> [289, 126,  96, 106] w/ P(a|s)=0.3743211030960083 and iou=0.66090961427749 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.9826413]\n",
            "\u001b[31m>> Total frame loss: -0.9826412796974182\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1766 with src: [289, 126,  96, 106] and target: [284, 147,  93,  82]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1767.jpg\n",
            "|->> Beginning tracking for bbox:[289 126  96 106]\n",
            "|->> Revisiting bbox: [289 126  96 106]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=10-th Action selection: 8/STOP (P(a|s) = 0.40400001406669617)\u001b[0m\n",
            "      |->> Bounding box moves to: [289 126  96 106]\n",
            "         |->> Action Probabilities (Rounded): [0.0629 0.0544 0.0625 0.0558 0.0594 0.0443 0.0862 0.0665 0.4036 0.0431\n",
            " 0.0613], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06285299 0.05437763 0.0625355  0.05583225 0.05935661 0.04429612\n",
            " 0.08619976 0.06648557 0.40364444 0.04310963 0.06130948], argmax=8\n",
            "         |->> Hit a STOP on the 10-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [289, 126,  96, 106] -> [289, 126,  96, 106] (Target was [284, 147,  93,  82])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [289, 126,  96, 106] -> [289, 126,  96, 106] w/ P(a|s)=0.4036444425582886 and iou=0.6816550160589457 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.9072209]\n",
            "\u001b[31m>> Total frame loss: -0.9072209000587463\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1767 with src: [289, 126,  96, 106] and target: [284, 142,  90,  85]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1768.jpg\n",
            "|->> Beginning tracking for bbox:[289 126  96 106]\n",
            "   \u001b[33m|->> #0/t=10-th Action selection: 5/2X UP (P(a|s) = 0.04399999976158142)\u001b[0m\n",
            "      |->> Bounding box moves to: [289 120  96 106]\n",
            "         |->> Action Probabilities (Rounded): [0.0595 0.0461 0.0635 0.0529 0.0597 0.0441 0.082  0.0647 0.4281 0.0406\n",
            " 0.0587], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05952606 0.04614347 0.0635068  0.05290275 0.05966939 0.04414544\n",
            " 0.08200806 0.06465269 0.42813888 0.04061523 0.05869118], argmax=8\n",
            "|->> Revisiting bbox: [289 120  96 106]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [289, 126,  96, 106] -> [289, 120,  96, 106] (Target was [284, 142,  90,  85])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for 2X UP:bbox transition: [289, 126,  96, 106] -> [289, 120,  96, 106] w/ P(a|s)=0.04414544254541397 and iou=0.6681639528354857 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-3.1202655]\n",
            "\u001b[31m>> Total frame loss: -3.120265483856201\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1768 with src: [289, 120,  96, 106] and target: [281, 150,  95,  85]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1769.jpg\n",
            "|->> Beginning tracking for bbox:[289 120  96 106]\n",
            "|->> Revisiting bbox: [289 120  96 106]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=11-th Action selection: 8/STOP (P(a|s) = 0.48500001430511475)\u001b[0m\n",
            "      |->> Bounding box moves to: [289 120  96 106]\n",
            "         |->> Action Probabilities (Rounded): [0.05   0.0409 0.0576 0.049  0.0508 0.0387 0.0712 0.0685 0.485  0.0372\n",
            " 0.0512], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.04996723 0.04086037 0.05759156 0.04898112 0.05075579 0.03870285\n",
            " 0.07123304 0.0684751  0.48503083 0.03724319 0.05115889], argmax=8\n",
            "         |->> Hit a STOP on the 11-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [289, 120,  96, 106] -> [289, 120,  96, 106] (Target was [281, 150,  95,  85])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [289, 120,  96, 106] -> [289, 120,  96, 106] w/ P(a|s)=0.4850308299064636 and iou=0.5680900420998367 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.7235428]\n",
            "\u001b[31m>> Total frame loss: -0.7235428094863892\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1769 with src: [289, 120,  96, 106] and target: [281, 145,  95,  91]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1770.jpg\n",
            "|->> Beginning tracking for bbox:[289 120  96 106]\n",
            "   \u001b[33m|->> #0/t=11-th Action selection: 6/DOWN (P(a|s) = 0.07999999821186066)\u001b[0m\n",
            "      |->> Bounding box moves to: [289 123  96 106]\n",
            "         |->> Action Probabilities (Rounded): [0.0534 0.0437 0.0657 0.0539 0.0541 0.0391 0.0805 0.0654 0.4559 0.0361\n",
            " 0.0521], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05341857 0.04370974 0.06567823 0.05388906 0.05413476 0.03911672\n",
            " 0.08046721 0.06543814 0.45591822 0.03614124 0.05208809], argmax=8\n",
            "   \u001b[33m|->> #1/t=12-th Action selection: 9/SCALE DOWN (P(a|s) = 0.03700000047683716)\u001b[0m\n",
            "      |->> Bounding box moves to: [290 124  93 102]\n",
            "         |->> Action Probabilities (Rounded): [0.0504 0.0414 0.0586 0.0509 0.057  0.0415 0.0684 0.059  0.4848 0.037\n",
            " 0.0509], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05044011 0.04135583 0.0585703  0.05093184 0.05697735 0.04146089\n",
            " 0.06841983 0.05903965 0.4848199  0.03703801 0.05094625], argmax=8\n",
            "   \u001b[33m|->> #2/t=13-th Action selection: 2/RIGHT (P(a|s) = 0.06300000101327896)\u001b[0m\n",
            "      |->> Bounding box moves to: [292 124  93 102]\n",
            "         |->> Action Probabilities (Rounded): [0.0513 0.0413 0.0634 0.0553 0.0542 0.0401 0.0676 0.0583 0.4827 0.0349\n",
            " 0.0509], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05131887 0.0412824  0.06341794 0.05534746 0.05421151 0.04012316\n",
            " 0.06759312 0.05831602 0.48267063 0.03485378 0.05086509], argmax=8\n",
            "|->> Revisiting bbox: [292 124  93 102]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [289, 120,  96, 106] -> [292, 124,  93, 102] (Target was [281, 145,  95,  91])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.036) for DOWN:bbox transition: [289, 120,  96, 106] -> [289, 123,  96, 106] w/ P(a|s)=0.08046720921993256 and iou=0.6347607052896725 and reward=0.036238537801987825 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.011) for SCALE DOWN:bbox transition: [289, 123,  96, 106] -> [290, 124,  93, 102] w/ P(a|s)=0.037038013339042664 and iou=0.6239140170174653 and reward=-0.01084668827220725 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-1.0) for RIGHT:bbox transition: [290, 124,  93, 102] -> [292, 124,  93, 102] w/ P(a|s)=0.0634179413318634 and iou=0.6006886201112386 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.09131769 -0.03574863 -2.7580085 ]\n",
            "\u001b[31m>> Total frame loss: -2.702439308166504\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1770 with src: [292, 124,  93, 102] and target: [276, 140, 107,  97]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1771.jpg\n",
            "|->> Beginning tracking for bbox:[292 124  93 102]\n",
            "|->> Revisiting bbox: [292 124  93 102]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=14-th Action selection: 8/STOP (P(a|s) = 0.4659999907016754)\u001b[0m\n",
            "      |->> Bounding box moves to: [292 124  93 102]\n",
            "         |->> Action Probabilities (Rounded): [0.0593 0.044  0.058  0.0544 0.0573 0.0421 0.0701 0.0591 0.4664 0.0351\n",
            " 0.0543], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05930912 0.04402129 0.05796107 0.05435264 0.05730251 0.04210934\n",
            " 0.07011583 0.05905382 0.4664238  0.03508785 0.05426265], argmax=8\n",
            "         |->> Hit a STOP on the 14-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [292, 124,  93, 102] -> [292, 124,  93, 102] (Target was [276, 140, 107,  97])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [292, 124,  93, 102] -> [292, 124,  93, 102] w/ P(a|s)=0.46642380952835083 and iou=0.650053991195282 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.7626606]\n",
            "\u001b[31m>> Total frame loss: -0.7626606225967407\u001b[0m\n",
            "Final bounding box: [292 124  93 102] reached in 14 timesteps (originating from [277 143  94 103]). Target was [276 140 107  97]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 1771 in t=14 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[31m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 7.796518802642822\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 3.4179437160491943\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/Rubik\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Starting bounding box=adnet_datasets/OTB/Rubik/img/1772.jpg for adnet_datasets/OTB/Rubik's frames (index: 0)\n",
            "src:adnet_datasets/OTB/Rubik/img/1762.jpg\n",
            "target:adnet_datasets/OTB/Rubik/img/1772.jpg.\n",
            "\u001b[34m>> Attempting to reach frame 1762 with src: [279, 144,  90,  97] and target: [279, 141,  89,  99]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1763.jpg\n",
            "|->> Beginning tracking for bbox:[279 144  90  97]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 4/UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [279 142  90  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0885 0.0811 0.0936 0.0878 0.0915 0.0821 0.0957 0.0877 0.1201 0.0822\n",
            " 0.0897], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08852348 0.08107951 0.09364591 0.08775808 0.09146927 0.0821453\n",
            " 0.09572779 0.08767938 0.12014803 0.08215038 0.08967294], argmax=8\n",
            "|->> Revisiting bbox: [279 142  90  97]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [279, 144,  90,  97] -> [279, 142,  90,  97] (Target was [279, 141,  89,  99])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for UP:bbox transition: [279, 144,  90,  97] -> [279, 142,  90,  97] w/ P(a|s)=0.09146926552057266 and iou=0.969128872923215 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [2.3917522]\n",
            "\u001b[92m>> Total frame loss: 2.391752243041992\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1763 with src: [279, 142,  90,  97] and target: [281, 139,  92,  99]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1764.jpg\n",
            "|->> Beginning tracking for bbox:[279 142  90  97]\n",
            "   \u001b[33m|->> #0/t=2-th Action selection: 5/2X UP (P(a|s) = 0.07800000160932541)\u001b[0m\n",
            "      |->> Bounding box moves to: [279 138  90  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0874 0.0777 0.0934 0.0865 0.0878 0.0776 0.0982 0.0896 0.1382 0.0775\n",
            " 0.0862], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08741043 0.07768609 0.09335357 0.0864796  0.08782235 0.07762974\n",
            " 0.09819435 0.08955579 0.13820553 0.07747841 0.08618421], argmax=8\n",
            "   \u001b[33m|->> #1/t=3-th Action selection: 6/DOWN (P(a|s) = 0.09799999743700027)\u001b[0m\n",
            "      |->> Bounding box moves to: [279 140  90  97]\n",
            "         |->> Action Probabilities (Rounded): [0.085  0.0744 0.0916 0.0812 0.0851 0.0678 0.0976 0.0958 0.1626 0.0739\n",
            " 0.085 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08495773 0.07442866 0.09157111 0.08124854 0.08509196 0.06779923\n",
            " 0.09756938 0.09584856 0.16263624 0.07385957 0.08498912], argmax=8\n",
            "   \u001b[33m|->> #2/t=4-th Action selection: 7/2X DOWN (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [279 144  90  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0806 0.0708 0.0931 0.0818 0.0871 0.0669 0.1017 0.0875 0.1748 0.0702\n",
            " 0.0856], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08059298 0.07077347 0.09306722 0.08175415 0.08709598 0.06687438\n",
            " 0.10172835 0.08753307 0.17483555 0.07018819 0.08555659], argmax=8\n",
            "   \u001b[33m|->> #3/t=5-th Action selection: 0/LEFT (P(a|s) = 0.07900000363588333)\u001b[0m\n",
            "      |->> Bounding box moves to: [277 144  90  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0787 0.0657 0.0944 0.0792 0.0884 0.0677 0.0909 0.0794 0.2046 0.0711\n",
            " 0.0799], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07868035 0.06574258 0.09444314 0.0791913  0.08835202 0.0677081\n",
            " 0.09086534 0.07942288 0.20457788 0.07114291 0.07987352], argmax=8\n",
            "|->> Revisiting bbox: [277 144  90  97]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [279, 142,  90,  97] -> [277, 144,  90,  97] (Target was [281, 139,  92,  99])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X UP:bbox transition: [279, 142,  90,  97] -> [279, 138,  90,  97] w/ P(a|s)=0.07762973755598068 and iou=0.8996805111821087 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.018) for DOWN:bbox transition: [279, 138,  90,  97] -> [279, 140,  90,  97] w/ P(a|s)=0.09756938368082047 and iou=0.9176521178241238 and reward=0.017971606642015137 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.053) for 2X DOWN:bbox transition: [279, 140,  90,  97] -> [279, 144,  90,  97] w/ P(a|s)=0.08753307163715363 and iou=0.864729249425047 and reward=-0.05292286839907678 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (1.0) for LEFT:bbox transition: [279, 144,  90,  97] -> [277, 144,  90,  97] w/ P(a|s)=0.07868035137653351 and iou=0.8287881894607341 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.          0.04182337 -0.12890626  2.5423617 ]\n",
            "\u001b[92m>> Total frame loss: 2.4552788734436035\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1764 with src: [277, 144,  90,  97] and target: [284, 147,  90,  87]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1765.jpg\n",
            "|->> Beginning tracking for bbox:[277 144  90  97]\n",
            "   \u001b[33m|->> #0/t=6-th Action selection: 2/RIGHT (P(a|s) = 0.0989999994635582)\u001b[0m\n",
            "      |->> Bounding box moves to: [279 144  90  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0702 0.06   0.0994 0.081  0.0842 0.0677 0.0909 0.077  0.2249 0.064\n",
            " 0.0808], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07021355 0.06002079 0.09943125 0.08099496 0.08418527 0.06765082\n",
            " 0.0908634  0.07701603 0.22486894 0.0639552  0.08079989], argmax=8\n",
            "   \u001b[33m|->> #1/t=7-th Action selection: 4/UP (P(a|s) = 0.08399999886751175)\u001b[0m\n",
            "      |->> Bounding box moves to: [279 142  90  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0846 0.061  0.0793 0.0741 0.0835 0.0667 0.0933 0.075  0.2454 0.0608\n",
            " 0.0763], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08464236 0.06101659 0.07934903 0.07411132 0.08352359 0.06665079\n",
            " 0.09325469 0.07497332 0.24537216 0.06078051 0.07632566], argmax=8\n",
            "   \u001b[33m|->> #2/t=8-th Action selection: 4/UP (P(a|s) = 0.07599999755620956)\u001b[0m\n",
            "      |->> Bounding box moves to: [279 140  90  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0722 0.0572 0.0837 0.0694 0.0763 0.0591 0.0907 0.0709 0.2922 0.0562\n",
            " 0.0721], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07222711 0.05720774 0.08373118 0.06941616 0.07628113 0.05906091\n",
            " 0.09071168 0.07090142 0.2921859  0.05621304 0.07206374], argmax=8\n",
            "   \u001b[33m|->> #3/t=9-th Action selection: 4/UP (P(a|s) = 0.0689999982714653)\u001b[0m\n",
            "      |->> Bounding box moves to: [279 138  90  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0735 0.0502 0.0703 0.067  0.0693 0.0537 0.0858 0.0699 0.3439 0.0506\n",
            " 0.0657], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07352184 0.05024227 0.07033945 0.06704985 0.06933409 0.05370542\n",
            " 0.08578353 0.06985402 0.343911   0.05056437 0.06569418], argmax=8\n",
            "   \u001b[33m|->> #4/t=10-th Action selection: 3/2X RIGHT (P(a|s) = 0.061000000685453415)\u001b[0m\n",
            "      |->> Bounding box moves to: [283 138  90  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0622 0.0506 0.0726 0.061  0.0653 0.0456 0.0847 0.0653 0.3842 0.0465\n",
            " 0.0621], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06220127 0.05056531 0.0725559  0.06104463 0.0653104  0.04556164\n",
            " 0.08468042 0.06530309 0.38421452 0.04650545 0.06205733], argmax=8\n",
            "|->> Revisiting bbox: [283 138  90  97]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [277, 144,  90,  97] -> [283, 138,  90,  97] (Target was [284, 147,  90,  87])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.034) for RIGHT:bbox transition: [277, 144,  90,  97] -> [279, 144,  90,  97] w/ P(a|s)=0.09943124651908875 and iou=0.806873977086743 and reward=0.03366485405429842 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for UP:bbox transition: [279, 144,  90,  97] -> [279, 142,  90,  97] w/ P(a|s)=0.08352358639240265 and iou=0.806873977086743 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.0) for UP:bbox transition: [279, 142,  90,  97] -> [279, 140,  90,  97] w/ P(a|s)=0.07628113031387329 and iou=0.806873977086743 and reward=0.0 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.0) for UP:bbox transition: [279, 140,  90,  97] -> [279, 138,  90,  97] w/ P(a|s)=0.06933408975601196 and iou=0.806873977086743 and reward=0.0 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (1.0) for 2X RIGHT:bbox transition: [279, 138,  90,  97] -> [283, 138,  90,  97] w/ P(a|s)=0.06104463338851929 and iou=0.8781898604967676 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.0777082 0.        0.        0.        2.79615  ]\n",
            "\u001b[92m>> Total frame loss: 2.8738582134246826\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1765 with src: [283, 138,  90,  97] and target: [286, 147,  87,  82]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1766.jpg\n",
            "|->> Beginning tracking for bbox:[283 138  90  97]\n",
            "   \u001b[33m|->> #0/t=11-th Action selection: 9/SCALE DOWN (P(a|s) = 0.04500000178813934)\u001b[0m\n",
            "      |->> Bounding box moves to: [284 139  87  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0594 0.0509 0.0669 0.0517 0.0631 0.0439 0.08   0.0623 0.4157 0.045\n",
            " 0.061 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05940818 0.05088311 0.06693902 0.05166589 0.06306217 0.04386261\n",
            " 0.08004372 0.0623183  0.4157418  0.04502768 0.06104749], argmax=8\n",
            "   \u001b[33m|->> #1/t=12-th Action selection: 4/UP (P(a|s) = 0.06400000303983688)\u001b[0m\n",
            "      |->> Bounding box moves to: [284 137  87  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0593 0.0463 0.0643 0.056  0.0636 0.0447 0.0772 0.0663 0.4161 0.0418\n",
            " 0.0644], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05928314 0.04633157 0.06433646 0.05604839 0.06357843 0.04467668\n",
            " 0.07715029 0.06625513 0.41613477 0.04182506 0.06438003], argmax=8\n",
            "|->> Revisiting bbox: [284 137  87  94]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [283, 138,  90,  97] -> [284, 137,  87,  94] (Target was [286, 147,  87,  82])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.018) for SCALE DOWN:bbox transition: [283, 138,  90,  97] -> [284, 139,  87,  94] w/ P(a|s)=0.045027684420347214 and iou=0.8355310477103812 and reward=0.018348917126188802 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for UP:bbox transition: [284, 139,  87,  94] -> [284, 137,  87,  94] w/ P(a|s)=0.06357843428850174 and iou=0.8355310477103812 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.05689041 2.755481  ]\n",
            "\u001b[92m>> Total frame loss: 2.8123714923858643\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1766 with src: [284, 137,  87,  94] and target: [284, 147,  93,  82]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1767.jpg\n",
            "|->> Beginning tracking for bbox:[284 137  87  94]\n",
            "   \u001b[33m|->> #0/t=13-th Action selection: 3/2X RIGHT (P(a|s) = 0.05299999937415123)\u001b[0m\n",
            "      |->> Bounding box moves to: [288 137  87  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0582 0.0477 0.069  0.0527 0.0694 0.0456 0.083  0.0672 0.4032 0.0423\n",
            " 0.0617], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05820973 0.04767858 0.06902596 0.05271145 0.06943049 0.04558909\n",
            " 0.08296336 0.06724828 0.40316907 0.04226466 0.06170927], argmax=8\n",
            "|->> Revisiting bbox: [284 137  87  94]. ACtion 1 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [284, 137,  87,  94] -> [288, 137,  87,  94] (Target was [284, 147,  93,  82])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for 2X RIGHT:bbox transition: [284, 137,  87,  94] -> [288, 137,  87,  94] w/ P(a|s)=0.052711453288793564 and iou=0.8228373702422145 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [2.9429226]\n",
            "\u001b[92m>> Total frame loss: 2.942922592163086\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1767 with src: [288, 137,  87,  94] and target: [284, 142,  90,  85]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1768.jpg\n",
            "|->> Beginning tracking for bbox:[288 137  87  94]\n",
            "   \u001b[33m|->> #0/t=14-th Action selection: 10/SCALE UP (P(a|s) = 0.06199999898672104)\u001b[0m\n",
            "      |->> Bounding box moves to: [286 135  89  96]\n",
            "         |->> Action Probabilities (Rounded): [0.0636 0.0557 0.059  0.0465 0.0619 0.0455 0.0825 0.0664 0.4154 0.0416\n",
            " 0.062 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06357083 0.05574087 0.05899853 0.04646884 0.06193814 0.04545671\n",
            " 0.08247129 0.06639963 0.4153607  0.04163906 0.06195547], argmax=8\n",
            "   \u001b[33m|->> #1/t=15-th Action selection: 4/UP (P(a|s) = 0.06300000101327896)\u001b[0m\n",
            "      |->> Bounding box moves to: [286 133  89  96]\n",
            "         |->> Action Probabilities (Rounded): [0.062  0.0546 0.0636 0.0511 0.0626 0.042  0.0835 0.0697 0.4103 0.0431\n",
            " 0.0576], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06201422 0.05455294 0.06356806 0.05112669 0.06257487 0.04201383\n",
            " 0.08346505 0.06968264 0.4103129  0.04311195 0.05757685], argmax=8\n",
            "   \u001b[33m|->> #2/t=16-th Action selection: 3/2X RIGHT (P(a|s) = 0.054999999701976776)\u001b[0m\n",
            "      |->> Bounding box moves to: [290 133  89  96]\n",
            "         |->> Action Probabilities (Rounded): [0.0649 0.0502 0.0659 0.055  0.0632 0.0401 0.0868 0.0728 0.4005 0.044\n",
            " 0.0567], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06490345 0.0501934  0.06594474 0.05495512 0.06316373 0.04011038\n",
            " 0.08675247 0.07278392 0.40049717 0.04395012 0.05674543], argmax=8\n",
            "|->> Revisiting bbox: [286 133  89  96]. ACtion 1 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [288, 137,  87,  94] -> [290, 133,  89,  96] (Target was [284, 142,  90,  85])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for SCALE UP:bbox transition: [288, 137,  87,  94] -> [286, 135,  89,  96] w/ P(a|s)=0.06195547431707382 and iou=0.8583887996327748 and reward=0.00020612764404503991 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for UP:bbox transition: [286, 135,  89,  96] -> [286, 133,  89,  96] w/ P(a|s)=0.06257487088441849 and iou=0.8583887996327748 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (1.0) for 2X RIGHT:bbox transition: [286, 133,  89,  96] -> [290, 133,  89,  96] w/ P(a|s)=0.054955121129751205 and iou=0.7886017229953611 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [5.7331094e-04 0.0000000e+00 2.9012384e+00]\n",
            "\u001b[92m>> Total frame loss: 2.9018118381500244\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1768 with src: [290, 133,  89,  96] and target: [281, 150,  95,  85]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1769.jpg\n",
            "|->> Beginning tracking for bbox:[290 133  89  96]\n",
            "   \u001b[33m|->> #0/t=17-th Action selection: 0/LEFT (P(a|s) = 0.06599999964237213)\u001b[0m\n",
            "      |->> Bounding box moves to: [288 133  89  96]\n",
            "         |->> Action Probabilities (Rounded): [0.0665 0.0552 0.0558 0.0483 0.0599 0.0447 0.0781 0.0666 0.418  0.0457\n",
            " 0.0612], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06646303 0.0552204  0.05584304 0.04826247 0.05992949 0.04473215\n",
            " 0.07814947 0.0665666  0.41795343 0.04566975 0.06121011], argmax=8\n",
            "   \u001b[33m|->> #1/t=18-th Action selection: 10/SCALE UP (P(a|s) = 0.05900000035762787)\u001b[0m\n",
            "      |->> Bounding box moves to: [286 131  91  98]\n",
            "         |->> Action Probabilities (Rounded): [0.053  0.0513 0.0692 0.0493 0.0621 0.0426 0.0824 0.0685 0.4215 0.0406\n",
            " 0.0593], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0530103  0.0513356  0.06921048 0.0492769  0.06209451 0.04262458\n",
            " 0.08241911 0.06854571 0.42154723 0.04064942 0.05928612], argmax=8\n",
            "   \u001b[33m|->> #2/t=19-th Action selection: 1/2X LEFT (P(a|s) = 0.050999999046325684)\u001b[0m\n",
            "      |->> Bounding box moves to: [282 131  91  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0615 0.051  0.0692 0.0538 0.0643 0.0439 0.0834 0.0649 0.4093 0.0447\n",
            " 0.0539], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06147971 0.05102228 0.06919212 0.05383668 0.06434786 0.04390334\n",
            " 0.08338342 0.06494559 0.40925333 0.0446997  0.05393593], argmax=8\n",
            "|->> Revisiting bbox: [282 131  91  98]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [290, 133,  89,  96] -> [282, 131,  91,  98] (Target was [281, 150,  95,  85])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.028) for LEFT:bbox transition: [290, 133,  89,  96] -> [288, 133,  89,  96] w/ P(a|s)=0.06646303087472916 and iou=0.719147615599462 and reward=0.02764634333483096 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for SCALE UP:bbox transition: [288, 133,  89,  96] -> [286, 131,  91,  98] w/ P(a|s)=0.05928611755371094 and iou=0.7194171810179095 and reward=0.0002695654184474705 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (1.0) for 2X LEFT:bbox transition: [286, 131,  91,  98] -> [282, 131,  91,  98] w/ P(a|s)=0.051022276282310486 and iou=0.7332721338229294 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [7.495227e-02 7.616247e-04 2.975493e+00]\n",
            "\u001b[92m>> Total frame loss: 3.0512068271636963\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1769 with src: [282, 131,  91,  98] and target: [281, 145,  95,  91]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1770.jpg\n",
            "|->> Beginning tracking for bbox:[282 131  91  98]\n",
            "   \u001b[33m|->> #0/t=20-th Action selection: 5/2X UP (P(a|s) = 0.04899999871850014)\u001b[0m\n",
            "      |->> Bounding box moves to: [282 127  91  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0594 0.0446 0.067  0.0586 0.0656 0.0487 0.0828 0.0678 0.4016 0.0432\n",
            " 0.0606], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0593541  0.04463982 0.06702363 0.05861513 0.06560824 0.04866602\n",
            " 0.08277094 0.06783474 0.40161628 0.04324919 0.06062189], argmax=8\n",
            "|->> Revisiting bbox: [282 127  91  98]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [282, 131,  91,  98] -> [282, 127,  91,  98] (Target was [281, 145,  95,  91])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for 2X UP:bbox transition: [282, 131,  91,  98] -> [282, 127,  91,  98] w/ P(a|s)=0.04866601526737213 and iou=0.7079646017699115 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [3.0227742]\n",
            "\u001b[92m>> Total frame loss: 3.0227742195129395\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1770 with src: [282, 127,  91,  98] and target: [276, 140, 107,  97]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1771.jpg\n",
            "|->> Beginning tracking for bbox:[282 127  91  98]\n",
            "|->> Revisiting bbox: [282 127  91  98]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=21-th Action selection: 8/STOP (P(a|s) = 0.43700000643730164)\u001b[0m\n",
            "      |->> Bounding box moves to: [282 127  91  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0566 0.0407 0.0649 0.0572 0.0616 0.0393 0.0821 0.0677 0.4369 0.0403\n",
            " 0.0529], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05658772 0.04068577 0.06487056 0.05715703 0.0615955  0.03932012\n",
            " 0.08210976 0.06768015 0.43685102 0.04028264 0.05285979], argmax=8\n",
            "         |->> Hit a STOP on the 21-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [282, 127,  91,  98] -> [282, 127,  91,  98] (Target was [276, 140, 107,  97])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [282, 127,  91,  98] -> [282, 127,  91,  98] w/ P(a|s)=0.43685102462768555 and iou=0.6690019027849853 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.828163]\n",
            "\u001b[31m>> Total frame loss: -0.8281630277633667\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1771 with src: [282, 127,  91,  98] and target: [275, 133, 103, 103]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1772.jpg\n",
            "|->> Beginning tracking for bbox:[282 127  91  98]\n",
            "   \u001b[33m|->> #0/t=21-th Action selection: 6/DOWN (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [282 129  91  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0564 0.0447 0.0753 0.0644 0.0631 0.0431 0.0895 0.0734 0.3918 0.0433\n",
            " 0.0551], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05639359 0.04466878 0.07529367 0.06438992 0.06308524 0.04309411\n",
            " 0.0894833  0.07342619 0.39179683 0.04329721 0.05507109], argmax=8\n",
            "   \u001b[33m|->> #1/t=22-th Action selection: 10/SCALE UP (P(a|s) = 0.05900000035762787)\u001b[0m\n",
            "      |->> Bounding box moves to: [280 127  93 100]\n",
            "         |->> Action Probabilities (Rounded): [0.0561 0.0437 0.0625 0.0586 0.0657 0.045  0.0801 0.0648 0.4217 0.0428\n",
            " 0.0591], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05607644 0.04372225 0.0624505  0.05855445 0.06565677 0.04501829\n",
            " 0.08013194 0.0648417  0.42166382 0.04282553 0.0590583 ], argmax=8\n",
            "   \u001b[33m|->> #2/t=23-th Action selection: 6/DOWN (P(a|s) = 0.07800000160932541)\u001b[0m\n",
            "      |->> Bounding box moves to: [280 130  93 100]\n",
            "         |->> Action Probabilities (Rounded): [0.0536 0.0393 0.0684 0.0625 0.0621 0.0415 0.078  0.0667 0.4321 0.0451\n",
            " 0.0505], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05363864 0.03932809 0.06844886 0.06254314 0.06206156 0.04148707\n",
            " 0.07799229 0.06673992 0.4321429  0.04512268 0.05049476], argmax=8\n",
            "|->> Revisiting bbox: [280 130  93 100]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [282, 127,  91,  98] -> [280, 130,  93, 100] (Target was [275, 133, 103, 103])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.029) for DOWN:bbox transition: [282, 127,  91,  98] -> [282, 129,  91,  98] w/ P(a|s)=0.08948329836130142 and iou=0.779549804064522 and reward=0.02903434014699624 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.003) for SCALE UP:bbox transition: [282, 129,  91,  98] -> [280, 127,  93, 100] w/ P(a|s)=0.0590583011507988 and iou=0.7828423032148294 and reward=0.003292499150307382 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (1.0) for DOWN:bbox transition: [280, 127,  93, 100] -> [280, 130,  93, 100] w/ P(a|s)=0.07799229025840759 and iou=0.8285268185157972 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.07008028 0.00931524 2.5511453 ]\n",
            "\u001b[92m>> Total frame loss: 2.6305408477783203\u001b[0m\n",
            "Final bounding box: [280 130  93 100] reached in 24 timesteps (originating from [279 144  90  97]). Target was [275 133 103 103]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 1772 in t=24 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[92m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 10.07179069519043\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 4.959012985229492\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/Rubik\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Starting bounding box=adnet_datasets/OTB/Rubik/img/1773.jpg for adnet_datasets/OTB/Rubik's frames (index: 0)\n",
            "src:adnet_datasets/OTB/Rubik/img/1763.jpg\n",
            "target:adnet_datasets/OTB/Rubik/img/1773.jpg.\n",
            "\u001b[34m>> Attempting to reach frame 1763 with src: [279, 141,  89,  99] and target: [281, 139,  92,  99]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1764.jpg\n",
            "|->> Beginning tracking for bbox:[279 141  89  99]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 3/2X RIGHT (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [283 141  89  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0885 0.0811 0.0936 0.0878 0.0915 0.0821 0.0957 0.0877 0.1201 0.0822\n",
            " 0.0897], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08852272 0.08107791 0.09364545 0.08776207 0.09147096 0.0821453\n",
            " 0.09572699 0.08767985 0.12014655 0.08215028 0.08967194], argmax=8\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 5/2X UP (P(a|s) = 0.07900000363588333)\u001b[0m\n",
            "      |->> Bounding box moves to: [283 137  89  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0914 0.0872 0.0879 0.0781 0.0894 0.0792 0.0959 0.0845 0.136  0.0806\n",
            " 0.0898], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09141313 0.08719765 0.08791207 0.07812909 0.08939232 0.07919953\n",
            " 0.09594017 0.08445079 0.13595203 0.08058419 0.08982906], argmax=8\n",
            "   \u001b[33m|->> #2/t=3-th Action selection: 3/2X RIGHT (P(a|s) = 0.07500000298023224)\u001b[0m\n",
            "      |->> Bounding box moves to: [287 137  89  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0867 0.0801 0.0875 0.0748 0.087  0.0694 0.0954 0.0931 0.163  0.0751\n",
            " 0.0876], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08674601 0.08013114 0.08749618 0.07483903 0.08702748 0.06942897\n",
            " 0.09544342 0.09309649 0.16302477 0.0751319  0.08763466], argmax=8\n",
            "   \u001b[33m|->> #3/t=4-th Action selection: 6/DOWN (P(a|s) = 0.10199999809265137)\u001b[0m\n",
            "      |->> Bounding box moves to: [287 139  89  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0872 0.0829 0.0848 0.0682 0.0865 0.0676 0.1022 0.0879 0.1738 0.0727\n",
            " 0.0862], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08719306 0.08293398 0.08475899 0.06817646 0.08651495 0.06759167\n",
            " 0.10222199 0.08787043 0.17383423 0.07267436 0.0862299 ], argmax=8\n",
            "|->> Revisiting bbox: [287 139  89  99]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [279, 141,  89,  99] -> [287, 139,  89,  99] (Target was [281, 139,  92,  99])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.039) for 2X RIGHT:bbox transition: [279, 141,  89,  99] -> [283, 141,  89,  99] w/ P(a|s)=0.08776206523180008 and iou=0.9296790867973294 and reward=0.03948921337960787 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for 2X UP:bbox transition: [283, 141,  89,  99] -> [283, 137,  89,  99] w/ P(a|s)=0.07919953018426895 and iou=0.9296790867973294 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.059) for 2X RIGHT:bbox transition: [283, 137,  89,  99] -> [287, 137,  89,  99] w/ P(a|s)=0.0748390331864357 and iou=0.8710452124882531 and reward=-0.058633874309076295 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (1.0) for DOWN:bbox transition: [287, 137,  89,  99] -> [287, 139,  89,  99] w/ P(a|s)=0.10222198814153671 and iou=0.9052631578947369 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.09608223  0.         -0.15200338  2.2806084 ]\n",
            "\u001b[92m>> Total frame loss: 2.224687337875366\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1764 with src: [287, 139,  89,  99] and target: [284, 147,  90,  87]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1765.jpg\n",
            "|->> Beginning tracking for bbox:[287 139  89  99]\n",
            "   \u001b[33m|->> #0/t=5-th Action selection: 6/DOWN (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [287 141  89  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0814 0.0803 0.0813 0.0672 0.0883 0.0654 0.0913 0.0834 0.2049 0.0699\n",
            " 0.0865], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08144614 0.08032541 0.08129251 0.06715956 0.08833214 0.06540918\n",
            " 0.09129822 0.08336207 0.20491423 0.06991107 0.08654947], argmax=8\n",
            "   \u001b[33m|->> #1/t=6-th Action selection: 3/2X RIGHT (P(a|s) = 0.06400000303983688)\u001b[0m\n",
            "      |->> Bounding box moves to: [291 141  89  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0816 0.0685 0.0842 0.0644 0.0895 0.066  0.0916 0.0789 0.2243 0.0652\n",
            " 0.086 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08158923 0.06846442 0.08415949 0.06438653 0.08945061 0.06597096\n",
            " 0.09155801 0.0789024  0.22430119 0.06521475 0.08600234], argmax=8\n",
            "   \u001b[33m|->> #2/t=7-th Action selection: 4/UP (P(a|s) = 0.07999999821186066)\u001b[0m\n",
            "      |->> Bounding box moves to: [291 139  89  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0823 0.078  0.0763 0.0579 0.0796 0.0634 0.0878 0.0731 0.2541 0.0645\n",
            " 0.083 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0823456  0.07795049 0.07630403 0.05792329 0.07957871 0.06342553\n",
            " 0.08783814 0.07310716 0.25411388 0.06445688 0.08295627], argmax=8\n",
            "|->> Revisiting bbox: [291 139  89  99]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [287, 139,  89,  99] -> [291, 139,  89,  99] (Target was [284, 147,  90,  87])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for DOWN:bbox transition: [287, 139,  89,  99] -> [287, 141,  89,  99] w/ P(a|s)=0.09129822254180908 and iou=0.8343253968253969 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.068) for 2X RIGHT:bbox transition: [287, 141,  89,  99] -> [291, 141,  89,  99] w/ P(a|s)=0.0643865317106247 and iou=0.7665605095541401 and reward=-0.06776488727125674 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (1.0) for UP:bbox transition: [291, 141,  89,  99] -> [291, 139,  89,  99] w/ P(a|s)=0.0795787051320076 and iou=0.7665605095541401 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.         -0.18586896  2.5310087 ]\n",
            "\u001b[92m>> Total frame loss: 2.345139741897583\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1765 with src: [291, 139,  89,  99] and target: [286, 147,  87,  82]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1766.jpg\n",
            "|->> Beginning tracking for bbox:[291 139  89  99]\n",
            "   \u001b[33m|->> #0/t=8-th Action selection: 0/LEFT (P(a|s) = 0.07999999821186066)\u001b[0m\n",
            "      |->> Bounding box moves to: [289 139  89  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0805 0.0663 0.074  0.0545 0.0754 0.0584 0.0842 0.0716 0.2952 0.0592\n",
            " 0.0808], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08048201 0.06626101 0.07398191 0.05454369 0.07536535 0.05837321\n",
            " 0.08423555 0.07159748 0.2952129  0.05919268 0.0807542 ], argmax=8\n",
            "|->> Revisiting bbox: [289 139  89  99]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [291, 139,  89,  99] -> [289, 139,  89,  99] (Target was [286, 147,  87,  82])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for LEFT:bbox transition: [291, 139,  89,  99] -> [289, 139,  89,  99] w/ P(a|s)=0.08048200607299805 and iou=0.7605167273931766 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [2.5197217]\n",
            "\u001b[92m>> Total frame loss: 2.519721746444702\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1766 with src: [289, 139,  89,  99] and target: [284, 147,  93,  82]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1767.jpg\n",
            "|->> Beginning tracking for bbox:[289 139  89  99]\n",
            "   \u001b[33m|->> #0/t=9-th Action selection: 2/RIGHT (P(a|s) = 0.08100000023841858)\u001b[0m\n",
            "      |->> Bounding box moves to: [291 139  89  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0665 0.0622 0.081  0.0556 0.072  0.0564 0.0849 0.0714 0.3271 0.0524\n",
            " 0.0706], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06649873 0.06218695 0.08101354 0.05560182 0.07196859 0.05636306\n",
            " 0.08492432 0.07137708 0.32708874 0.05237338 0.07060378], argmax=8\n",
            "   \u001b[33m|->> #1/t=10-th Action selection: 3/2X RIGHT (P(a|s) = 0.04899999871850014)\u001b[0m\n",
            "      |->> Bounding box moves to: [295 139  89  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0753 0.0606 0.0573 0.0487 0.0655 0.0523 0.0861 0.0638 0.3683 0.0481\n",
            " 0.074 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07528121 0.0606349  0.05734018 0.04866715 0.06552988 0.05226945\n",
            " 0.08609642 0.06376956 0.368277   0.04812486 0.07400943], argmax=8\n",
            "|->> Revisiting bbox: [295 139  89  99]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [289, 139,  89,  99] -> [295, 139,  89,  99] (Target was [284, 147,  93,  82])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.031) for RIGHT:bbox transition: [289, 139,  89,  99] -> [291, 139,  89,  99] w/ P(a|s)=0.08101353794336319 and iou=0.7514118273841236 and reward=-0.03114971691692836 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [291, 139,  89,  99] -> [295, 139,  89,  99] w/ P(a|s)=0.04866715148091316 and iou=0.6922680943065994 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.07828357 -3.022751  ]\n",
            "\u001b[31m>> Total frame loss: -3.101034641265869\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1767 with src: [295, 139,  89,  99] and target: [284, 142,  90,  85]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1768.jpg\n",
            "|->> Beginning tracking for bbox:[295 139  89  99]\n",
            "|->> Revisiting bbox: [295 139  89  99]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=11-th Action selection: 8/STOP (P(a|s) = 0.4339999854564667)\u001b[0m\n",
            "      |->> Bounding box moves to: [295 139  89  99]\n",
            "         |->> Action Probabilities (Rounded): [0.06   0.0562 0.0601 0.0416 0.0621 0.0471 0.0766 0.0586 0.434  0.0423\n",
            " 0.0614], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05995053 0.05622459 0.06011915 0.0415874  0.06213001 0.04714598\n",
            " 0.07658394 0.05857208 0.4340407  0.04228266 0.06136293], argmax=8\n",
            "         |->> Hit a STOP on the 11-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [295, 139,  89,  99] -> [295, 139,  89,  99] (Target was [284, 142,  90,  85])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [295, 139,  89,  99] -> [295, 139,  89,  99] w/ P(a|s)=0.43404069542884827 and iou=0.6890006156371845 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.834617]\n",
            "\u001b[31m>> Total frame loss: -0.834617018699646\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1768 with src: [295, 139,  89,  99] and target: [281, 150,  95,  85]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1769.jpg\n",
            "|->> Beginning tracking for bbox:[295 139  89  99]\n",
            "|->> Revisiting bbox: [295 139  89  99]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=11-th Action selection: 8/STOP (P(a|s) = 0.3919999897480011)\u001b[0m\n",
            "      |->> Bounding box moves to: [295 139  89  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0702 0.054  0.0625 0.0498 0.0687 0.0489 0.079  0.0652 0.3915 0.0488\n",
            " 0.0614], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07019861 0.0539928  0.06247761 0.04981267 0.06866639 0.04886798\n",
            " 0.0790276  0.06523297 0.3915367  0.04883296 0.06135375], argmax=8\n",
            "         |->> Hit a STOP on the 11-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [295, 139,  89,  99] -> [295, 139,  89,  99] (Target was [281, 150,  95,  85])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [295, 139,  89,  99] -> [295, 139,  89,  99] w/ P(a|s)=0.3915367126464844 and iou=0.6884311568843116 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.937676]\n",
            "\u001b[31m>> Total frame loss: -0.9376760125160217\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1769 with src: [295, 139,  89,  99] and target: [281, 145,  95,  91]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1770.jpg\n",
            "|->> Beginning tracking for bbox:[295 139  89  99]\n",
            "   \u001b[33m|->> #0/t=11-th Action selection: 2/RIGHT (P(a|s) = 0.06400000303983688)\u001b[0m\n",
            "      |->> Bounding box moves to: [297 139  89  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0655 0.056  0.0636 0.0478 0.0702 0.0526 0.0831 0.0645 0.382  0.0458\n",
            " 0.0689], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06546778 0.05599932 0.06362012 0.04776236 0.07016546 0.05257222\n",
            " 0.08310279 0.06454495 0.38200867 0.04581761 0.06893872], argmax=8\n",
            "|->> Revisiting bbox: [297 139  89  99]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [295, 139,  89,  99] -> [297, 139,  89,  99] (Target was [281, 145,  95,  91])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for RIGHT:bbox transition: [295, 139,  89,  99] -> [297, 139,  89,  99] w/ P(a|s)=0.06362012028694153 and iou=0.7002045388136748 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [2.7548256]\n",
            "\u001b[92m>> Total frame loss: 2.7548255920410156\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1770 with src: [297, 139,  89,  99] and target: [276, 140, 107,  97]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1771.jpg\n",
            "|->> Beginning tracking for bbox:[297 139  89  99]\n",
            "   \u001b[33m|->> #0/t=12-th Action selection: 0/LEFT (P(a|s) = 0.06599999964237213)\u001b[0m\n",
            "      |->> Bounding box moves to: [295 139  89  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0662 0.0521 0.052  0.0495 0.068  0.0483 0.0804 0.0621 0.4121 0.0408\n",
            " 0.0686], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06619021 0.05206616 0.05201161 0.04947896 0.067967   0.04830532\n",
            " 0.08038601 0.06207919 0.41213587 0.04078152 0.06859815], argmax=8\n",
            "   \u001b[33m|->> #1/t=13-th Action selection: 6/DOWN (P(a|s) = 0.07599999755620956)\u001b[0m\n",
            "      |->> Bounding box moves to: [295 141  89  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0504 0.046  0.0646 0.0514 0.0624 0.0438 0.0764 0.0647 0.4442 0.0389\n",
            " 0.0573], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0504386  0.04603824 0.06455232 0.05138859 0.06235256 0.04375172\n",
            " 0.07640771 0.06471524 0.44418025 0.03885746 0.05731731], argmax=8\n",
            "|->> Revisiting bbox: [295 141  89  99]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [297, 139,  89,  99] -> [295, 141,  89,  99] (Target was [276, 140, 107,  97])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.032) for LEFT:bbox transition: [297, 139,  89,  99] -> [295, 139,  89,  99] w/ P(a|s)=0.066190205514431 and iou=0.8012014266941994 and reward=0.032211751177975145 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for DOWN:bbox transition: [295, 139,  89,  99] -> [295, 141,  89,  99] w/ P(a|s)=0.07640770822763443 and iou=0.7864457270526903 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.08746208 2.5716717 ]\n",
            "\u001b[92m>> Total frame loss: 2.6591339111328125\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1771 with src: [295, 141,  89,  99] and target: [275, 133, 103, 103]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1772.jpg\n",
            "|->> Beginning tracking for bbox:[295 141  89  99]\n",
            "|->> Revisiting bbox: [295 141  89  99]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=14-th Action selection: 8/STOP (P(a|s) = 0.4410000145435333)\u001b[0m\n",
            "      |->> Bounding box moves to: [295 141  89  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0599 0.0465 0.0647 0.0506 0.0649 0.0448 0.0721 0.0568 0.4412 0.0413\n",
            " 0.0572], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05992405 0.04649279 0.06473036 0.05056017 0.06492815 0.04480518\n",
            " 0.07212574 0.05675377 0.4411561  0.04129397 0.0572298 ], argmax=8\n",
            "         |->> Hit a STOP on the 14-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [295, 141,  89,  99] -> [295, 141,  89,  99] (Target was [275, 133, 103, 103])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [295, 141,  89,  99] -> [295, 141,  89,  99] w/ P(a|s)=0.4411560893058777 and iou=0.6835717381881231 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.8183565]\n",
            "\u001b[31m>> Total frame loss: -0.8183565139770508\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1772 with src: [295, 141,  89,  99] and target: [279, 139,  96, 102]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1773.jpg\n",
            "|->> Beginning tracking for bbox:[295 141  89  99]\n",
            "|->> Revisiting bbox: [295 141  89  99]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=14-th Action selection: 8/STOP (P(a|s) = 0.4129999876022339)\u001b[0m\n",
            "      |->> Bounding box moves to: [295 141  89  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0625 0.0467 0.0702 0.0531 0.0596 0.0528 0.0796 0.0597 0.4129 0.0413\n",
            " 0.0616], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06253995 0.04666807 0.07023646 0.05309041 0.05961213 0.05276181\n",
            " 0.07957982 0.05973726 0.4128744  0.04130527 0.06159437], argmax=8\n",
            "         |->> Hit a STOP on the 14-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [295, 141,  89,  99] -> [295, 141,  89,  99] (Target was [279, 139,  96, 102])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [295, 141,  89,  99] -> [295, 141,  89,  99] w/ P(a|s)=0.41287440061569214 and iou=0.7413647851727043 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.88461185]\n",
            "\u001b[92m>> Total frame loss: 0.8846118450164795\u001b[0m\n",
            "Final bounding box: [295 141  89  99] reached in 14 timesteps (originating from [279 141  89  99]). Target was [279 139  96 102]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 1773 in t=14 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[92m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 8.040562629699707\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 3.5090112686157227\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/Rubik\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Starting bounding box=adnet_datasets/OTB/Rubik/img/1774.jpg for adnet_datasets/OTB/Rubik's frames (index: 0)\n",
            "src:adnet_datasets/OTB/Rubik/img/1764.jpg\n",
            "target:adnet_datasets/OTB/Rubik/img/1774.jpg.\n",
            "\u001b[34m>> Attempting to reach frame 1764 with src: [281, 139,  92,  99] and target: [284, 147,  90,  87]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1765.jpg\n",
            "|->> Beginning tracking for bbox:[281 139  92  99]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 6/DOWN (P(a|s) = 0.09600000083446503)\u001b[0m\n",
            "      |->> Bounding box moves to: [281 141  92  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0885 0.0811 0.0936 0.0878 0.0915 0.0821 0.0957 0.0877 0.1201 0.0821\n",
            " 0.0897], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08852298 0.08107625 0.09364592 0.08776422 0.09147336 0.08214511\n",
            " 0.09572814 0.08768005 0.12014323 0.08214998 0.08967079], argmax=8\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 2/RIGHT (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [283 141  92  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0861 0.0771 0.0936 0.0858 0.0952 0.0813 0.0927 0.0826 0.1366 0.079\n",
            " 0.09  ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08614283 0.0770859  0.09361968 0.08576774 0.09521756 0.0812723\n",
            " 0.09267779 0.08261523 0.13658094 0.07904001 0.08998004], argmax=8\n",
            "   \u001b[33m|->> #2/t=3-th Action selection: 6/DOWN (P(a|s) = 0.0949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [283 143  92  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0967 0.0748 0.0828 0.0814 0.0914 0.0791 0.0954 0.0833 0.1509 0.0749\n",
            " 0.0893], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09668432 0.07477355 0.0828261  0.08138795 0.0913621  0.07910949\n",
            " 0.09543192 0.0832551  0.15091111 0.07492754 0.08933086], argmax=8\n",
            "   \u001b[33m|->> #3/t=4-th Action selection: 0/LEFT (P(a|s) = 0.08399999886751175)\u001b[0m\n",
            "      |->> Bounding box moves to: [281 143  92  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0839 0.0739 0.0926 0.0773 0.0951 0.0756 0.0891 0.0762 0.1755 0.0721\n",
            " 0.0887], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08385383 0.07394253 0.09260625 0.07726644 0.09514204 0.07555436\n",
            " 0.08910777 0.07615295 0.17551601 0.07212023 0.08873761], argmax=8\n",
            "   \u001b[33m|->> #4/t=5-th Action selection: 1/2X LEFT (P(a|s) = 0.06499999761581421)\u001b[0m\n",
            "      |->> Bounding box moves to: [277 143  92  99]\n",
            "         |->> Action Probabilities (Rounded): [0.077  0.0654 0.0969 0.0795 0.0903 0.0767 0.0907 0.076  0.195  0.0687\n",
            " 0.0837], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0769517  0.06542924 0.09693563 0.07954777 0.09026578 0.076735\n",
            " 0.09065884 0.07604045 0.1950398  0.06872877 0.08366701], argmax=8\n",
            "|->> Revisiting bbox: [277 143  92  99]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [281, 139,  92,  99] -> [277, 143,  92,  99] (Target was [284, 147,  90,  87])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for DOWN:bbox transition: [281, 139,  92,  99] -> [281, 141,  92,  99] w/ P(a|s)=0.09572813659906387 and iou=0.8420880913539968 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.018) for RIGHT:bbox transition: [281, 141,  92,  99] -> [283, 141,  92,  99] w/ P(a|s)=0.0936196818947792 and iou=0.8596837944664032 and reward=0.017595703112406436 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.0) for DOWN:bbox transition: [283, 141,  92,  99] -> [283, 143,  92,  99] w/ P(a|s)=0.09543192386627197 and iou=0.8596837944664032 and reward=0.0 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-0.018) for LEFT:bbox transition: [283, 143,  92,  99] -> [281, 143,  92,  99] w/ P(a|s)=0.0838538259267807 and iou=0.8420880913539968 and reward=-0.017595703112406436 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (1.0) for 2X LEFT:bbox transition: [281, 143,  92,  99] -> [277, 143,  92,  99] w/ P(a|s)=0.06542924046516418 and iou=0.7749135491983653 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.          0.04167568  0.         -0.04361412  2.7267861 ]\n",
            "\u001b[92m>> Total frame loss: 2.7248477935791016\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1765 with src: [277, 143,  92,  99] and target: [286, 147,  87,  82]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1766.jpg\n",
            "|->> Beginning tracking for bbox:[277 143  92  99]\n",
            "|->> Revisiting bbox: [277 143  92  99]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=6-th Action selection: 8/STOP (P(a|s) = 0.22300000488758087)\u001b[0m\n",
            "      |->> Bounding box moves to: [277 143  92  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0782 0.0613 0.0947 0.0841 0.0849 0.0681 0.0937 0.069  0.2228 0.062\n",
            " 0.0812], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07821976 0.06130817 0.09468264 0.08411404 0.08493145 0.068101\n",
            " 0.09372058 0.06903315 0.22277185 0.0619607  0.08115663], argmax=8\n",
            "         |->> Hit a STOP on the 6-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [277, 143,  92,  99] -> [277, 143,  92,  99] (Target was [286, 147,  87,  82])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [277, 143,  92,  99] -> [277, 143,  92,  99] w/ P(a|s)=0.22277185320854187 and iou=0.7212802034760492 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [1.5016071]\n",
            "\u001b[92m>> Total frame loss: 1.501607060432434\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1766 with src: [277, 143,  92,  99] and target: [284, 147,  93,  82]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1767.jpg\n",
            "|->> Beginning tracking for bbox:[277 143  92  99]\n",
            "|->> Revisiting bbox: [277 143  92  99]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=6-th Action selection: 8/STOP (P(a|s) = 0.24199999868869781)\u001b[0m\n",
            "      |->> Bounding box moves to: [277 143  92  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0747 0.0547 0.0942 0.0809 0.0839 0.0693 0.0916 0.0692 0.2418 0.0596\n",
            " 0.08  ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07468187 0.0546863  0.09421402 0.08090425 0.08387432 0.06931388\n",
            " 0.09161352 0.06924915 0.24182123 0.05964243 0.07999904], argmax=8\n",
            "         |->> Hit a STOP on the 6-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [277, 143,  92,  99] -> [277, 143,  92,  99] (Target was [284, 147,  93,  82])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [277, 143,  92,  99] -> [277, 143,  92,  99] w/ P(a|s)=0.24182122945785522 and iou=0.713846784104875 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [1.4195565]\n",
            "\u001b[92m>> Total frame loss: 1.4195564985275269\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1767 with src: [277, 143,  92,  99] and target: [284, 142,  90,  85]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1768.jpg\n",
            "|->> Beginning tracking for bbox:[277 143  92  99]\n",
            "   \u001b[33m|->> #0/t=6-th Action selection: 5/2X UP (P(a|s) = 0.06599999964237213)\u001b[0m\n",
            "      |->> Bounding box moves to: [277 139  92  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0724 0.0521 0.085  0.0806 0.0782 0.0663 0.0886 0.0704 0.2724 0.0589\n",
            " 0.075 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07240167 0.05205965 0.08500802 0.08057577 0.07824593 0.06631961\n",
            " 0.08860478 0.07038237 0.27244288 0.05892921 0.07503016], argmax=8\n",
            "   \u001b[33m|->> #1/t=7-th Action selection: 0/LEFT (P(a|s) = 0.05999999865889549)\u001b[0m\n",
            "      |->> Bounding box moves to: [275 139  92  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0603 0.0469 0.0735 0.0637 0.071  0.0525 0.0828 0.07   0.3694 0.046\n",
            " 0.0641], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06025665 0.04686747 0.07346169 0.063656   0.07101757 0.05250887\n",
            " 0.08284464 0.0699806  0.36935794 0.04597837 0.06407012], argmax=8\n",
            "   \u001b[33m|->> #2/t=8-th Action selection: 4/UP (P(a|s) = 0.06499999761581421)\u001b[0m\n",
            "      |->> Bounding box moves to: [275 137  92  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0476 0.0411 0.0802 0.0663 0.0649 0.0467 0.0778 0.0673 0.4062 0.0421\n",
            " 0.0597], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.04762978 0.04112551 0.08015067 0.06627844 0.0649493  0.04673245\n",
            " 0.07784321 0.06731898 0.40622294 0.04205025 0.05969851], argmax=8\n",
            "   \u001b[33m|->> #3/t=9-th Action selection: 3/2X RIGHT (P(a|s) = 0.06300000101327896)\u001b[0m\n",
            "      |->> Bounding box moves to: [279 137  92  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0496 0.0388 0.0693 0.0627 0.0604 0.0398 0.0767 0.0614 0.4496 0.0392\n",
            " 0.0525], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.04957712 0.03880799 0.06931534 0.0627448  0.06039179 0.03978719\n",
            " 0.07672992 0.06140899 0.4496104  0.03916829 0.05245809], argmax=8\n",
            "|->> Revisiting bbox: [279 137  92  99]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [277, 143,  92,  99] -> [279, 137,  92,  99] (Target was [284, 142,  90,  85])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.016) for 2X UP:bbox transition: [277, 143,  92,  99] -> [277, 139,  92,  99] w/ P(a|s)=0.06631961464881897 and iou=0.757893632644498 and reward=0.015535554041878008 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.031) for LEFT:bbox transition: [277, 139,  92,  99] -> [275, 139,  92,  99] w/ P(a|s)=0.06025664880871773 and iou=0.7270947129753684 and reward=-0.03079891966912962 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.0) for UP:bbox transition: [275, 139,  92,  99] -> [275, 137,  92,  99] w/ P(a|s)=0.06494929641485214 and iou=0.7270947129753684 and reward=0.0 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (1.0) for 2X RIGHT:bbox transition: [275, 137,  92,  99] -> [279, 137,  92,  99] w/ P(a|s)=0.06274479627609253 and iou=0.7898109580262737 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.04215214 -0.08651855  0.          2.7686796 ]\n",
            "\u001b[92m>> Total frame loss: 2.724313259124756\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1768 with src: [279, 137,  92,  99] and target: [281, 150,  95,  85]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1769.jpg\n",
            "|->> Beginning tracking for bbox:[279 137  92  99]\n",
            "|->> Revisiting bbox: [279 137  92  99]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=10-th Action selection: 8/STOP (P(a|s) = 0.4440000057220459)\u001b[0m\n",
            "      |->> Bounding box moves to: [279 137  92  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0545 0.0398 0.0685 0.0557 0.0593 0.0445 0.0712 0.0641 0.4439 0.0414\n",
            " 0.057 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05447625 0.03982046 0.06850043 0.05565519 0.05929758 0.04453162\n",
            " 0.07122637 0.0641396  0.44392288 0.0413838  0.0570459 ], argmax=8\n",
            "         |->> Hit a STOP on the 10-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [279, 137,  92,  99] -> [279, 137,  92,  99] (Target was [281, 150,  95,  85])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [279, 137,  92,  99] -> [279, 137,  92,  99] w/ P(a|s)=0.44392287731170654 and iou=0.8024756110353509 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.81210446]\n",
            "\u001b[92m>> Total frame loss: 0.8121044635772705\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1769 with src: [279, 137,  92,  99] and target: [281, 145,  95,  91]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1770.jpg\n",
            "|->> Beginning tracking for bbox:[279 137  92  99]\n",
            "|->> Revisiting bbox: [279 137  92  99]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=10-th Action selection: 8/STOP (P(a|s) = 0.4099999964237213)\u001b[0m\n",
            "      |->> Bounding box moves to: [279 137  92  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0586 0.0436 0.0706 0.0615 0.0631 0.0452 0.0805 0.0672 0.4097 0.0412\n",
            " 0.0587], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05859905 0.04359475 0.0706258  0.06148851 0.06313647 0.04524941\n",
            " 0.08052302 0.067199   0.40969256 0.04117304 0.05871837], argmax=8\n",
            "         |->> Hit a STOP on the 10-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [279, 137,  92,  99] -> [279, 137,  92,  99] (Target was [281, 145,  95,  91])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [279, 137,  92,  99] -> [279, 137,  92,  99] w/ P(a|s)=0.40969255566596985 and iou=0.8564258078008993 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.8923483]\n",
            "\u001b[92m>> Total frame loss: 0.8923482894897461\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1770 with src: [279, 137,  92,  99] and target: [276, 140, 107,  97]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1771.jpg\n",
            "|->> Beginning tracking for bbox:[279 137  92  99]\n",
            "|->> Revisiting bbox: [279 137  92  99]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=10-th Action selection: 8/STOP (P(a|s) = 0.42100000381469727)\u001b[0m\n",
            "      |->> Bounding box moves to: [279 137  92  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0551 0.0422 0.075  0.0587 0.0644 0.0451 0.0768 0.0652 0.4208 0.041\n",
            " 0.0557], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05509578 0.04223774 0.07504455 0.05865842 0.06436798 0.04510873\n",
            " 0.07675777 0.0652082  0.42083734 0.04096641 0.05571714], argmax=8\n",
            "         |->> Hit a STOP on the 10-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [279, 137,  92,  99] -> [279, 137,  92,  99] (Target was [276, 140, 107,  97])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [279, 137,  92,  99] -> [279, 137,  92,  99] w/ P(a|s)=0.4208373427391052 and iou=0.8289066166119193 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.8655089]\n",
            "\u001b[92m>> Total frame loss: 0.8655089139938354\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1771 with src: [279, 137,  92,  99] and target: [275, 133, 103, 103]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1772.jpg\n",
            "|->> Beginning tracking for bbox:[279 137  92  99]\n",
            "   \u001b[33m|->> #0/t=10-th Action selection: 7/2X DOWN (P(a|s) = 0.06599999964237213)\u001b[0m\n",
            "      |->> Bounding box moves to: [279 141  92  99]\n",
            "         |->> Action Probabilities (Rounded): [0.053  0.0472 0.0657 0.0584 0.0571 0.0459 0.08   0.0657 0.4259 0.0408\n",
            " 0.0604], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05303964 0.04718551 0.06568315 0.05840895 0.05710812 0.04587359\n",
            " 0.07996614 0.06568009 0.4258962  0.04078383 0.0603749 ], argmax=8\n",
            "|->> Revisiting bbox: [279 141  92  99]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [279, 137,  92,  99] -> [279, 141,  92,  99] (Target was [275, 133, 103, 103])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for 2X DOWN:bbox transition: [279, 137,  92,  99] -> [279, 141,  92,  99] w/ P(a|s)=0.06568009406328201 and iou=0.7962102578117883 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [2.7229593]\n",
            "\u001b[92m>> Total frame loss: 2.722959280014038\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1772 with src: [279, 141,  92,  99] and target: [279, 139,  96, 102]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1773.jpg\n",
            "|->> Beginning tracking for bbox:[279 141  92  99]\n",
            "   \u001b[33m|->> #0/t=11-th Action selection: 7/2X DOWN (P(a|s) = 0.05999999865889549)\u001b[0m\n",
            "      |->> Bounding box moves to: [279 145  92  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0518 0.0446 0.0605 0.0504 0.0597 0.0459 0.0733 0.0601 0.4576 0.0392\n",
            " 0.0568], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05184755 0.04461951 0.06045661 0.05041599 0.059691   0.04594326\n",
            " 0.07326932 0.06014317 0.4576085  0.03915899 0.05684612], argmax=8\n",
            "   \u001b[33m|->> #1/t=12-th Action selection: 3/2X RIGHT (P(a|s) = 0.052000001072883606)\u001b[0m\n",
            "      |->> Bounding box moves to: [283 145  92  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0544 0.0436 0.0642 0.0524 0.0607 0.0465 0.0655 0.0538 0.4617 0.0418\n",
            " 0.0553], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05438675 0.0436247  0.06423742 0.05244516 0.06071644 0.04651181\n",
            " 0.06549571 0.05379566 0.46168053 0.04176791 0.05533789], argmax=8\n",
            "|->> Revisiting bbox: [283 145  92  99]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [279, 141,  92,  99] -> [283, 145,  92,  99] (Target was [279, 139,  96, 102])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.053) for 2X DOWN:bbox transition: [279, 141,  92,  99] -> [279, 145,  92,  99] w/ P(a|s)=0.06014316529035568 and iou=0.8772348033373063 and reward=-0.052912255486223136 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for 2X RIGHT:bbox transition: [279, 145,  92,  99] -> [283, 145,  92,  99] w/ P(a|s)=0.05244516208767891 and iou=0.8772348033373063 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.1487378  2.947987 ]\n",
            "\u001b[92m>> Total frame loss: 2.7992491722106934\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1773 with src: [283, 145,  92,  99] and target: [279, 140,  97,  99]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1774.jpg\n",
            "|->> Beginning tracking for bbox:[283 145  92  99]\n",
            "   \u001b[33m|->> #0/t=13-th Action selection: 4/UP (P(a|s) = 0.05999999865889549)\u001b[0m\n",
            "      |->> Bounding box moves to: [283 143  92  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0617 0.0463 0.058  0.0488 0.0603 0.0496 0.0678 0.0507 0.4585 0.0413\n",
            " 0.057 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06167161 0.04627005 0.05796832 0.04883542 0.06032919 0.04961064\n",
            " 0.06775273 0.05070404 0.45848027 0.04133271 0.05704497], argmax=8\n",
            "|->> Revisiting bbox: [283 143  92  99]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [283, 145,  92,  99] -> [283, 143,  92,  99] (Target was [279, 140,  97,  99])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for UP:bbox transition: [283, 145,  92,  99] -> [283, 143,  92,  99] w/ P(a|s)=0.06032918766140938 and iou=0.8940176131187367 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [2.8079393]\n",
            "\u001b[92m>> Total frame loss: 2.807939291000366\u001b[0m\n",
            "Final bounding box: [283 143  92  99] reached in 14 timesteps (originating from [281 139  92  99]). Target was [279 140  97  99]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 1774 in t=14 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[92m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 8.252744674682617\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 2.5516533851623535\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/Rubik\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Starting bounding box=adnet_datasets/OTB/Rubik/img/1775.jpg for adnet_datasets/OTB/Rubik's frames (index: 0)\n",
            "src:adnet_datasets/OTB/Rubik/img/1765.jpg\n",
            "target:adnet_datasets/OTB/Rubik/img/1775.jpg.\n",
            "\u001b[34m>> Attempting to reach frame 1765 with src: [284, 147,  90,  87] and target: [286, 147,  87,  82]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1766.jpg\n",
            "|->> Beginning tracking for bbox:[284 147  90  87]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 5/2X UP (P(a|s) = 0.0820000022649765)\u001b[0m\n",
            "      |->> Bounding box moves to: [284 143  90  87]\n",
            "         |->> Action Probabilities (Rounded): [0.0885 0.0811 0.0936 0.0878 0.0915 0.0821 0.0957 0.0877 0.1201 0.0821\n",
            " 0.0897], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08852252 0.08107537 0.09364552 0.08776774 0.09147592 0.08214443\n",
            " 0.09572838 0.0876806  0.12014139 0.08214914 0.08966903], argmax=8\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 10/SCALE UP (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [282 141  92  89]\n",
            "         |->> Action Probabilities (Rounded): [0.0862 0.0777 0.0927 0.0835 0.088  0.0722 0.0977 0.0947 0.1426 0.0772\n",
            " 0.0876], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08615909 0.07771904 0.0926763  0.08346939 0.08799855 0.07222044\n",
            " 0.09769638 0.09467561 0.1425628  0.07723028 0.08759205], argmax=8\n",
            "   \u001b[33m|->> #2/t=3-th Action selection: 4/UP (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [282 139  92  89]\n",
            "         |->> Action Probabilities (Rounded): [0.0818 0.0725 0.0943 0.0863 0.0875 0.0711 0.1029 0.092  0.1562 0.0767\n",
            " 0.0787], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08181811 0.07249118 0.09427023 0.08633056 0.08745323 0.07106948\n",
            " 0.10290289 0.09200185 0.15619993 0.07673491 0.07872764], argmax=8\n",
            "|->> Revisiting bbox: [282 141  92  89]. ACtion 6 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [284, 147,  90,  87] -> [282, 139,  92,  89] (Target was [286, 147,  87,  82])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X UP:bbox transition: [284, 147,  90,  87] -> [284, 143,  90,  87] w/ P(a|s)=0.08214443176984787 and iou=0.9111111111111111 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.04) for SCALE UP:bbox transition: [284, 143,  90,  87] -> [282, 141,  92,  89] w/ P(a|s)=0.08759205043315887 and iou=0.8712750366389839 and reward=-0.039836074472127225 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (1.0) for UP:bbox transition: [282, 141,  92,  89] -> [282, 139,  92,  89] w/ P(a|s)=0.08745323121547699 and iou=0.8516012084592145 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.         -0.09700343  2.4366512 ]\n",
            "\u001b[92m>> Total frame loss: 2.3396477699279785\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1766 with src: [282, 139,  92,  89] and target: [284, 147,  93,  82]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1767.jpg\n",
            "|->> Beginning tracking for bbox:[282 139  92  89]\n",
            "|->> Revisiting bbox: [282 139  92  89]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=4-th Action selection: 8/STOP (P(a|s) = 0.17599999904632568)\u001b[0m\n",
            "      |->> Bounding box moves to: [282 139  92  89]\n",
            "         |->> Action Probabilities (Rounded): [0.0816 0.0706 0.0932 0.083  0.0844 0.0642 0.1033 0.0951 0.1755 0.072\n",
            " 0.077 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08162116 0.07062574 0.09324346 0.08295707 0.08438646 0.06424512\n",
            " 0.10327515 0.09510763 0.17554615 0.07199724 0.0769948 ], argmax=8\n",
            "         |->> Hit a STOP on the 4-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [282, 139,  92,  89] -> [282, 139,  92,  89] (Target was [284, 147,  93,  82])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [282, 139,  92,  89] -> [282, 139,  92,  89] w/ P(a|s)=0.17554615437984467 and iou=0.8552322853120601 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [1.7398533]\n",
            "\u001b[92m>> Total frame loss: 1.7398532629013062\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1767 with src: [282, 139,  92,  89] and target: [284, 142,  90,  85]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1768.jpg\n",
            "|->> Beginning tracking for bbox:[282 139  92  89]\n",
            "|->> Revisiting bbox: [282 139  92  89]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=4-th Action selection: 8/STOP (P(a|s) = 0.18400000035762787)\u001b[0m\n",
            "      |->> Bounding box moves to: [282 139  92  89]\n",
            "         |->> Action Probabilities (Rounded): [0.0844 0.0673 0.0932 0.0816 0.0812 0.0649 0.1015 0.09   0.1838 0.0708\n",
            " 0.0812], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08437002 0.06734934 0.09321418 0.08161776 0.08123541 0.06487374\n",
            " 0.10146278 0.09004997 0.18380937 0.07083156 0.08118592], argmax=8\n",
            "         |->> Hit a STOP on the 4-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [282, 139,  92,  89] -> [282, 139,  92,  89] (Target was [284, 142,  90,  85])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [282, 139,  92,  89] -> [282, 139,  92,  89] w/ P(a|s)=0.18380936980247498 and iou=0.9342940889106008 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [1.6938561]\n",
            "\u001b[92m>> Total frame loss: 1.693856120109558\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1768 with src: [282, 139,  92,  89] and target: [281, 150,  95,  85]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1769.jpg\n",
            "|->> Beginning tracking for bbox:[282 139  92  89]\n",
            "   \u001b[33m|->> #0/t=4-th Action selection: 7/2X DOWN (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [282 143  92  89]\n",
            "         |->> Action Probabilities (Rounded): [0.0773 0.066  0.09   0.0785 0.0786 0.0634 0.1031 0.089  0.2079 0.066\n",
            " 0.0801], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07734242 0.06599668 0.08999026 0.07849582 0.07861459 0.06344678\n",
            " 0.10312221 0.0890276  0.20788945 0.06601164 0.08006256], argmax=8\n",
            "   \u001b[33m|->> #1/t=5-th Action selection: 10/SCALE UP (P(a|s) = 0.0729999989271164)\u001b[0m\n",
            "      |->> Bounding box moves to: [280 141  94  91]\n",
            "         |->> Action Probabilities (Rounded): [0.0697 0.0574 0.0841 0.075  0.0796 0.0593 0.089  0.0757 0.2751 0.0621\n",
            " 0.0729], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06969101 0.05737613 0.08408831 0.07501689 0.07963947 0.05929565\n",
            " 0.08900745 0.0757394  0.27511707 0.06212624 0.07290234], argmax=8\n",
            "   \u001b[33m|->> #2/t=6-th Action selection: 4/UP (P(a|s) = 0.07199999690055847)\u001b[0m\n",
            "      |->> Bounding box moves to: [280 139  94  91]\n",
            "         |->> Action Probabilities (Rounded): [0.0646 0.0533 0.0802 0.0738 0.072  0.0565 0.0851 0.0739 0.3217 0.0559\n",
            " 0.0631], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06456023 0.05331244 0.0802454  0.07377534 0.0719767  0.05653713\n",
            " 0.08508611 0.07387738 0.3216706  0.05588432 0.06307433], argmax=8\n",
            "   \u001b[33m|->> #3/t=7-th Action selection: 0/LEFT (P(a|s) = 0.06199999898672104)\u001b[0m\n",
            "      |->> Bounding box moves to: [278 139  94  91]\n",
            "         |->> Action Probabilities (Rounded): [0.0624 0.0502 0.0785 0.065  0.0691 0.0533 0.0881 0.0708 0.352  0.051\n",
            " 0.0596], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06244745 0.05017283 0.0784529  0.06501844 0.0690735  0.05326614\n",
            " 0.08814352 0.07081346 0.35199845 0.05099232 0.059621  ], argmax=8\n",
            "|->> Revisiting bbox: [278 139  94  91]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [282, 139,  92,  89] -> [278, 139,  94,  91] (Target was [281, 150,  95,  85])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.076) for 2X DOWN:bbox transition: [282, 139,  92,  89] -> [282, 143,  92,  89] w/ P(a|s)=0.08902759850025177 and iou=0.8652368390870513 and reward=0.07553726827160068 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.018) for SCALE UP:bbox transition: [282, 143,  92,  89] -> [280, 141,  94,  91] w/ P(a|s)=0.07290233671665192 and iou=0.8470509830056647 and reward=-0.018185856081386564 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.037) for UP:bbox transition: [280, 141,  94,  91] -> [280, 139,  94,  91] w/ P(a|s)=0.07197669893503189 and iou=0.8096637283708782 and reward=-0.03738725463478654 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (1.0) for LEFT:bbox transition: [280, 139,  94,  91] -> [278, 139,  94,  91] w/ P(a|s)=0.0624474473297596 and iou=0.778692908332442 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.18271023 -0.04762211 -0.0983813   2.7734299 ]\n",
            "\u001b[92m>> Total frame loss: 2.8101367950439453\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1769 with src: [278, 139,  94,  91] and target: [281, 145,  95,  91]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1770.jpg\n",
            "|->> Beginning tracking for bbox:[278 139  94  91]\n",
            "|->> Revisiting bbox: [278 139  94  91]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=8-th Action selection: 8/STOP (P(a|s) = 0.414000004529953)\u001b[0m\n",
            "      |->> Bounding box moves to: [278 139  94  91]\n",
            "         |->> Action Probabilities (Rounded): [0.0525 0.0429 0.0771 0.0632 0.0614 0.0476 0.0799 0.0625 0.4137 0.0435\n",
            " 0.0558], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05245605 0.04289986 0.07714623 0.06322227 0.06135579 0.04755539\n",
            " 0.07988799 0.06245551 0.4137332  0.0434642  0.05582343], argmax=8\n",
            "         |->> Hit a STOP on the 8-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [278, 139,  94,  91] -> [278, 139,  94,  91] (Target was [281, 145,  95,  91])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [278, 139,  94,  91] -> [278, 139,  94,  91] w/ P(a|s)=0.41373321413993835 and iou=0.8173076923076923 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.8825339]\n",
            "\u001b[92m>> Total frame loss: 0.8825339078903198\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1770 with src: [278, 139,  94,  91] and target: [276, 140, 107,  97]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1771.jpg\n",
            "|->> Beginning tracking for bbox:[278 139  94  91]\n",
            "   \u001b[33m|->> #0/t=8-th Action selection: 4/UP (P(a|s) = 0.06300000101327896)\u001b[0m\n",
            "      |->> Bounding box moves to: [278 137  94  91]\n",
            "         |->> Action Probabilities (Rounded): [0.061  0.0438 0.0722 0.063  0.0634 0.0446 0.0847 0.0627 0.408  0.0415\n",
            " 0.055 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06104901 0.04381434 0.07221517 0.06298168 0.06340399 0.04464184\n",
            " 0.08470987 0.06266724 0.40796012 0.04154598 0.05501078], argmax=8\n",
            "|->> Revisiting bbox: [278 137  94  91]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [278, 139,  94,  91] -> [278, 137,  94,  91] (Target was [276, 140, 107,  97])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for UP:bbox transition: [278, 139,  94,  91] -> [278, 137,  94,  91] w/ P(a|s)=0.06340398639440536 and iou=0.7759122033580339 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [2.7582285]\n",
            "\u001b[92m>> Total frame loss: 2.7582285404205322\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1771 with src: [278, 137,  94,  91] and target: [275, 133, 103, 103]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1772.jpg\n",
            "|->> Beginning tracking for bbox:[278 137  94  91]\n",
            "   \u001b[33m|->> #0/t=9-th Action selection: 1/2X LEFT (P(a|s) = 0.04100000113248825)\u001b[0m\n",
            "      |->> Bounding box moves to: [274 137  94  91]\n",
            "         |->> Action Probabilities (Rounded): [0.0516 0.0407 0.0682 0.0633 0.0614 0.0458 0.0753 0.0592 0.4444 0.0409\n",
            " 0.0492], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05158981 0.04071257 0.06821019 0.06327321 0.0614359  0.04576946\n",
            " 0.07528284 0.0591686  0.4444196  0.0408973  0.04924059], argmax=8\n",
            "|->> Revisiting bbox: [274 137  94  91]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [278, 137,  94,  91] -> [274, 137,  94,  91] (Target was [275, 133, 103, 103])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for 2X LEFT:bbox transition: [278, 137,  94,  91] -> [274, 137,  94,  91] w/ P(a|s)=0.040712565183639526 and iou=0.7909345794392524 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [3.2012186]\n",
            "\u001b[92m>> Total frame loss: 3.201218605041504\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1772 with src: [274, 137,  94,  91] and target: [279, 139,  96, 102]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1773.jpg\n",
            "|->> Beginning tracking for bbox:[274 137  94  91]\n",
            "   \u001b[33m|->> #0/t=10-th Action selection: 4/UP (P(a|s) = 0.057999998331069946)\u001b[0m\n",
            "      |->> Bounding box moves to: [274 135  94  91]\n",
            "         |->> Action Probabilities (Rounded): [0.0518 0.036  0.0711 0.0649 0.0583 0.0452 0.0698 0.0609 0.4513 0.0393\n",
            " 0.0514], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0517846  0.03600833 0.07105364 0.06492188 0.05833881 0.0451918\n",
            " 0.06980629 0.06089093 0.45128003 0.03928647 0.05143727], argmax=8\n",
            "   \u001b[33m|->> #1/t=11-th Action selection: 7/2X DOWN (P(a|s) = 0.06199999898672104)\u001b[0m\n",
            "      |->> Bounding box moves to: [274 139  94  91]\n",
            "         |->> Action Probabilities (Rounded): [0.0521 0.0385 0.0707 0.0643 0.0592 0.0436 0.0753 0.0618 0.4408 0.0396\n",
            " 0.0542], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05211768 0.03847718 0.07065788 0.0642852  0.05919103 0.04357108\n",
            " 0.07530296 0.06183973 0.44081444 0.03955163 0.05419118], argmax=8\n",
            "|->> Revisiting bbox: [274 139  94  91]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [274, 137,  94,  91] -> [274, 139,  94,  91] (Target was [279, 139,  96, 102])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.03) for UP:bbox transition: [274, 137,  94,  91] -> [274, 135,  94,  91] w/ P(a|s)=0.05833880603313446 and iou=0.7302650193341507 and reward=-0.02954313414306753 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for 2X DOWN:bbox transition: [274, 135,  94,  91] -> [274, 139,  94,  91] w/ P(a|s)=0.06183973327279091 and iou=0.7903776715136137 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.08394646  2.783209  ]\n",
            "\u001b[92m>> Total frame loss: 2.6992626190185547\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1773 with src: [274, 139,  94,  91] and target: [279, 140,  97,  99]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1774.jpg\n",
            "|->> Beginning tracking for bbox:[274 139  94  91]\n",
            "   \u001b[33m|->> #0/t=12-th Action selection: 10/SCALE UP (P(a|s) = 0.0560000017285347)\u001b[0m\n",
            "      |->> Bounding box moves to: [272 137  96  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0528 0.0381 0.074  0.0653 0.0654 0.0464 0.07   0.0553 0.4333 0.0433\n",
            " 0.0561], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05276045 0.03810257 0.07397154 0.06532113 0.06540588 0.04641695\n",
            " 0.07004163 0.05529375 0.43328682 0.04333665 0.05606259], argmax=8\n",
            "   \u001b[33m|->> #1/t=13-th Action selection: 5/2X UP (P(a|s) = 0.04699999839067459)\u001b[0m\n",
            "      |->> Bounding box moves to: [272 133  96  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0533 0.0401 0.0685 0.0654 0.0615 0.0465 0.0791 0.0578 0.4341 0.0434\n",
            " 0.0501], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05331243 0.04013139 0.06854204 0.06544047 0.06151208 0.04653147\n",
            " 0.07911532 0.05779297 0.43411952 0.04338358 0.05011876], argmax=8\n",
            "   \u001b[33m|->> #2/t=14-th Action selection: 3/2X RIGHT (P(a|s) = 0.06300000101327896)\u001b[0m\n",
            "      |->> Bounding box moves to: [276 133  96  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0522 0.0401 0.0715 0.0629 0.0662 0.0405 0.0794 0.067  0.4246 0.0451\n",
            " 0.0505], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.052184   0.04014917 0.07154357 0.06286608 0.06619    0.0404845\n",
            " 0.07935181 0.06699577 0.42464125 0.04511147 0.0504824 ], argmax=8\n",
            "|->> Revisiting bbox: [276 133  96  93]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [274, 139,  94,  91] -> [276, 133,  96,  93] (Target was [279, 140,  97,  99])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.028) for SCALE UP:bbox transition: [274, 139,  94,  91] -> [272, 137,  96,  93] w/ P(a|s)=0.05606259033083916 and iou=0.7613344739093242 and reward=-0.028061406646505138 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.058) for 2X UP:bbox transition: [272, 137,  96,  93] -> [272, 133,  96,  93] w/ P(a|s)=0.046531468629837036 and iou=0.7036866783120346 and reward=-0.05764779559728961 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (1.0) for 2X RIGHT:bbox transition: [272, 133,  96,  93] -> [276, 133,  96,  93] w/ P(a|s)=0.06286607682704926 and iou=0.759327826829963 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.08085296 -0.1768419   2.7667487 ]\n",
            "\u001b[92m>> Total frame loss: 2.5090537071228027\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1774 with src: [276, 133,  96,  93] and target: [280, 139,  99,  93]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1775.jpg\n",
            "|->> Beginning tracking for bbox:[276 133  96  93]\n",
            "   \u001b[33m|->> #0/t=15-th Action selection: 7/2X DOWN (P(a|s) = 0.061000000685453415)\u001b[0m\n",
            "      |->> Bounding box moves to: [276 137  96  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0582 0.0428 0.0646 0.0573 0.0594 0.0442 0.0819 0.061  0.4331 0.0436\n",
            " 0.0539], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05815265 0.04282409 0.06464352 0.05726218 0.05942943 0.04424705\n",
            " 0.08190943 0.06096562 0.43311742 0.04357586 0.05387268], argmax=8\n",
            "|->> Revisiting bbox: [276 137  96  93]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [276, 133,  96,  93] -> [276, 137,  96,  93] (Target was [280, 139,  99,  93])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for 2X DOWN:bbox transition: [276, 133,  96,  93] -> [276, 137,  96,  93] w/ P(a|s)=0.06096562370657921 and iou=0.8575233022636485 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [2.797445]\n",
            "\u001b[92m>> Total frame loss: 2.797445058822632\u001b[0m\n",
            "Final bounding box: [276 137  96  93] reached in 16 timesteps (originating from [284 147  90  87]). Target was [280 139  99  93]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 1775 in t=16 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[92m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 8.46701717376709\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 2.541154146194458\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/Rubik\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Starting bounding box=adnet_datasets/OTB/Rubik/img/1776.jpg for adnet_datasets/OTB/Rubik's frames (index: 0)\n",
            "src:adnet_datasets/OTB/Rubik/img/1766.jpg\n",
            "target:adnet_datasets/OTB/Rubik/img/1776.jpg.\n",
            "\u001b[34m>> Attempting to reach frame 1766 with src: [286, 147,  87,  82] and target: [284, 147,  93,  82]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1767.jpg\n",
            "|->> Beginning tracking for bbox:[286 147  87  82]\n",
            "|->> Revisiting bbox: [286 147  87  82]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 8/STOP (P(a|s) = 0.11999999731779099)\u001b[0m\n",
            "      |->> Bounding box moves to: [286 147  87  82]\n",
            "         |->> Action Probabilities (Rounded): [0.0885 0.0811 0.0936 0.0878 0.0915 0.0821 0.0957 0.0877 0.1201 0.0821\n",
            " 0.0897], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0885225  0.08107512 0.09364427 0.08777127 0.09147961 0.0821432\n",
            " 0.09572769 0.08768252 0.12013941 0.08214772 0.08966661], argmax=8\n",
            "         |->> Hit a STOP on the 1-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [286, 147,  87,  82] -> [286, 147,  87,  82] (Target was [284, 147,  93,  82])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [286, 147,  87,  82] -> [286, 147,  87,  82] w/ P(a|s)=0.12013940513134003 and iou=0.9354838709677419 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [2.1191025]\n",
            "\u001b[92m>> Total frame loss: 2.1191024780273438\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1767 with src: [286, 147,  87,  82] and target: [284, 142,  90,  85]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1768.jpg\n",
            "|->> Beginning tracking for bbox:[286 147  87  82]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 2/RIGHT (P(a|s) = 0.09600000083446503)\u001b[0m\n",
            "      |->> Bounding box moves to: [288 147  87  82]\n",
            "         |->> Action Probabilities (Rounded): [0.0887 0.0797 0.096  0.0865 0.0899 0.0804 0.0987 0.0863 0.1241 0.0794\n",
            " 0.0903], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08874612 0.07972503 0.09597151 0.08647627 0.08994279 0.08039027\n",
            " 0.09868268 0.08629816 0.12410116 0.07937579 0.09029026], argmax=8\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 7/2X DOWN (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [288 151  87  82]\n",
            "         |->> Action Probabilities (Rounded): [0.0938 0.0761 0.0792 0.0814 0.0884 0.078  0.0984 0.0875 0.1544 0.0741\n",
            " 0.0887], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09377547 0.07607118 0.07922404 0.08144227 0.08843476 0.07802313\n",
            " 0.09836517 0.08747713 0.15440416 0.07406962 0.0887131 ], argmax=8\n",
            "   \u001b[33m|->> #2/t=3-th Action selection: 4/UP (P(a|s) = 0.09099999815225601)\u001b[0m\n",
            "      |->> Bounding box moves to: [288 149  87  82]\n",
            "         |->> Action Probabilities (Rounded): [0.0814 0.0736 0.0904 0.0775 0.0906 0.0748 0.0894 0.0791 0.1874 0.0722\n",
            " 0.0836], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0813999  0.07360577 0.0903639  0.07746942 0.09060124 0.07483197\n",
            " 0.08940037 0.07907343 0.18738315 0.07224626 0.08362452], argmax=8\n",
            "|->> Revisiting bbox: [288 149  87  82]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [286, 147,  87,  82] -> [288, 149,  87,  82] (Target was [284, 142,  90,  85])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.019) for RIGHT:bbox transition: [286, 147,  87,  82] -> [288, 147,  87,  82] w/ P(a|s)=0.09597150981426239 and iou=0.8704453441295547 and reward=-0.01912520801768458 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.078) for 2X DOWN:bbox transition: [288, 147,  87,  82] -> [288, 151,  87,  82] w/ P(a|s)=0.08747713267803192 and iou=0.7924345295829291 and reward=-0.0780108145466255 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (1.0) for UP:bbox transition: [288, 151,  87,  82] -> [288, 149,  87,  82] w/ P(a|s)=0.09060124307870865 and iou=0.8306092124814265 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.04482383 -0.1900638   2.4012873 ]\n",
            "\u001b[92m>> Total frame loss: 2.1663997173309326\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1768 with src: [288, 149,  87,  82] and target: [281, 150,  95,  85]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1769.jpg\n",
            "|->> Beginning tracking for bbox:[288 149  87  82]\n",
            "   \u001b[33m|->> #0/t=4-th Action selection: 3/2X RIGHT (P(a|s) = 0.07900000363588333)\u001b[0m\n",
            "      |->> Bounding box moves to: [292 149  87  82]\n",
            "         |->> Action Probabilities (Rounded): [0.0826 0.0692 0.0849 0.0791 0.0844 0.0719 0.0918 0.0769 0.2116 0.0681\n",
            " 0.0795], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0825818  0.06922299 0.08492112 0.07908271 0.08443654 0.07186068\n",
            " 0.09184322 0.07686663 0.21156517 0.06814267 0.07947645], argmax=8\n",
            "   \u001b[33m|->> #1/t=5-th Action selection: 9/SCALE DOWN (P(a|s) = 0.06599999964237213)\u001b[0m\n",
            "      |->> Bounding box moves to: [293 150  84  79]\n",
            "         |->> Action Probabilities (Rounded): [0.0839 0.0754 0.0813 0.0674 0.0818 0.0701 0.0913 0.0698 0.2327 0.0655\n",
            " 0.081 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0838677  0.07536741 0.08125241 0.06736311 0.08177321 0.07007738\n",
            " 0.09128091 0.06977461 0.23271343 0.06554462 0.08098522], argmax=8\n",
            "   \u001b[33m|->> #2/t=6-th Action selection: 7/2X DOWN (P(a|s) = 0.07000000029802322)\u001b[0m\n",
            "      |->> Bounding box moves to: [293 154  84  79]\n",
            "         |->> Action Probabilities (Rounded): [0.0779 0.0667 0.0778 0.066  0.0802 0.062  0.0904 0.0705 0.2741 0.0549\n",
            " 0.0797], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07788897 0.06665462 0.07776508 0.06598687 0.08022299 0.06197419\n",
            " 0.09040277 0.07045119 0.27407932 0.05490747 0.07966652], argmax=8\n",
            "|->> Revisiting bbox: [293 154  84  79]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [288, 149,  87,  82] -> [293, 154,  84,  79] (Target was [281, 150,  95,  85])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.054) for 2X RIGHT:bbox transition: [288, 149,  87,  82] -> [292, 149,  87,  82] w/ P(a|s)=0.07908270508050919 and iou=0.8095181439619274 and reward=-0.053873181693549155 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.005) for SCALE DOWN:bbox transition: [292, 149,  87,  82] -> [293, 150,  84,  79] w/ P(a|s)=0.06554462015628815 and iou=0.8041452048074564 and reward=-0.0053729391544710126 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (1.0) for 2X DOWN:bbox transition: [293, 150,  84,  79] -> [293, 154,  84,  79] w/ P(a|s)=0.07045119255781174 and iou=0.8041452048074564 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.13669032 -0.01464139  2.6528351 ]\n",
            "\u001b[92m>> Total frame loss: 2.5015034675598145\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1769 with src: [293, 154,  84,  79] and target: [281, 145,  95,  91]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1770.jpg\n",
            "|->> Beginning tracking for bbox:[293 154  84  79]\n",
            "   \u001b[33m|->> #0/t=7-th Action selection: 6/DOWN (P(a|s) = 0.08299999684095383)\u001b[0m\n",
            "      |->> Bounding box moves to: [293 156  84  79]\n",
            "         |->> Action Probabilities (Rounded): [0.0724 0.0596 0.0806 0.0649 0.0841 0.0631 0.0832 0.0646 0.2989 0.0554\n",
            " 0.0733], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0723548  0.0596057  0.08056366 0.06486561 0.08407868 0.06311281\n",
            " 0.08322694 0.06464545 0.29887962 0.05536763 0.07329915], argmax=8\n",
            "   \u001b[33m|->> #1/t=8-th Action selection: 5/2X UP (P(a|s) = 0.06499999761581421)\u001b[0m\n",
            "      |->> Bounding box moves to: [293 152  84  79]\n",
            "         |->> Action Probabilities (Rounded): [0.0673 0.0578 0.0724 0.0591 0.0816 0.0648 0.0784 0.0569 0.3403 0.05\n",
            " 0.0713], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06734408 0.05775884 0.07241122 0.05911386 0.08162884 0.06481871\n",
            " 0.07843995 0.0568576  0.34028566 0.05004528 0.07129592], argmax=8\n",
            "|->> Revisiting bbox: [293 152  84  79]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [293, 154,  84,  79] -> [293, 152,  84,  79] (Target was [281, 145,  95,  91])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for DOWN:bbox transition: [293, 154,  84,  79] -> [293, 156,  84,  79] w/ P(a|s)=0.08322694152593613 and iou=0.7516047684548373 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for 2X UP:bbox transition: [293, 156,  84,  79] -> [293, 152,  84,  79] w/ P(a|s)=0.06481871008872986 and iou=0.7516047684548373 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.       2.736161]\n",
            "\u001b[92m>> Total frame loss: 2.73616099357605\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1770 with src: [293, 152,  84,  79] and target: [276, 140, 107,  97]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1771.jpg\n",
            "|->> Beginning tracking for bbox:[293 152  84  79]\n",
            "   \u001b[33m|->> #0/t=9-th Action selection: 6/DOWN (P(a|s) = 0.07900000363588333)\u001b[0m\n",
            "      |->> Bounding box moves to: [293 154  84  79]\n",
            "         |->> Action Probabilities (Rounded): [0.0632 0.0532 0.0702 0.0526 0.0742 0.0552 0.0794 0.0626 0.3735 0.046\n",
            " 0.07  ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0631832  0.05321513 0.07015388 0.05257443 0.07420968 0.05522645\n",
            " 0.07938824 0.06257951 0.37347662 0.04595966 0.07003321], argmax=8\n",
            "|->> Revisiting bbox: [293 154  84  79]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [293, 152,  84,  79] -> [293, 154,  84,  79] (Target was [276, 140, 107,  97])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for DOWN:bbox transition: [293, 152,  84,  79] -> [293, 154,  84,  79] w/ P(a|s)=0.07938823848962784 and iou=0.6393679545235572 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.533405]\n",
            "\u001b[31m>> Total frame loss: -2.533405065536499\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1771 with src: [293, 154,  84,  79] and target: [275, 133, 103, 103]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1772.jpg\n",
            "|->> Beginning tracking for bbox:[293 154  84  79]\n",
            "   \u001b[33m|->> #0/t=10-th Action selection: 6/DOWN (P(a|s) = 0.0729999989271164)\u001b[0m\n",
            "      |->> Bounding box moves to: [293 156  84  79]\n",
            "         |->> Action Probabilities (Rounded): [0.0594 0.05   0.0672 0.0551 0.069  0.0499 0.0725 0.0535 0.4141 0.0433\n",
            " 0.0661], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0593826  0.049994   0.06718575 0.05505726 0.06902566 0.0498746\n",
            " 0.07253956 0.05348159 0.41407603 0.04328074 0.06610226], argmax=8\n",
            "|->> Revisiting bbox: [293 154  84  79]. ACtion 4 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [293, 154,  84,  79] -> [293, 156,  84,  79] (Target was [275, 133, 103, 103])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for DOWN:bbox transition: [293, 154,  84,  79] -> [293, 156,  84,  79] w/ P(a|s)=0.0725395604968071 and iou=0.6255066453011594 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.6236231]\n",
            "\u001b[31m>> Total frame loss: -2.6236231327056885\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1772 with src: [293, 156,  84,  79] and target: [279, 139,  96, 102]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1773.jpg\n",
            "|->> Beginning tracking for bbox:[293 156  84  79]\n",
            "|->> Revisiting bbox: [293 156  84  79]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=11-th Action selection: 8/STOP (P(a|s) = 0.421999990940094)\u001b[0m\n",
            "      |->> Bounding box moves to: [293 156  84  79]\n",
            "         |->> Action Probabilities (Rounded): [0.0645 0.0443 0.0641 0.0531 0.0707 0.0523 0.0644 0.0532 0.4221 0.046\n",
            " 0.0653], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06452762 0.04425888 0.06405587 0.05305936 0.07073308 0.05232298\n",
            " 0.06438504 0.05324627 0.42210537 0.04599668 0.06530893], argmax=8\n",
            "         |->> Hit a STOP on the 11-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [293, 156,  84,  79] -> [293, 156,  84,  79] (Target was [279, 139,  96, 102])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [293, 156,  84,  79] -> [293, 156,  84,  79] w/ P(a|s)=0.4221053719520569 and iou=0.6510552763819095 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.8625003]\n",
            "\u001b[31m>> Total frame loss: -0.8625003099441528\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1773 with src: [293, 156,  84,  79] and target: [279, 140,  97,  99]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1774.jpg\n",
            "|->> Beginning tracking for bbox:[293 156  84  79]\n",
            "|->> Revisiting bbox: [293 156  84  79]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=11-th Action selection: 8/STOP (P(a|s) = 0.39800000190734863)\u001b[0m\n",
            "      |->> Bounding box moves to: [293 156  84  79]\n",
            "         |->> Action Probabilities (Rounded): [0.0619 0.0476 0.0701 0.0564 0.072  0.0524 0.0735 0.0532 0.3979 0.0453\n",
            " 0.0697], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06189221 0.04757226 0.07010141 0.05643785 0.07200687 0.05240988\n",
            " 0.07346293 0.05320964 0.3979085  0.04532806 0.06967033], argmax=8\n",
            "         |->> Hit a STOP on the 11-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [293, 156,  84,  79] -> [293, 156,  84,  79] (Target was [279, 140,  97,  99])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [293, 156,  84,  79] -> [293, 156,  84,  79] w/ P(a|s)=0.3979085087776184 and iou=0.6772361082420988 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.92153317]\n",
            "\u001b[31m>> Total frame loss: -0.9215331673622131\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1774 with src: [293, 156,  84,  79] and target: [280, 139,  99,  93]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1775.jpg\n",
            "|->> Beginning tracking for bbox:[293 156  84  79]\n",
            "   \u001b[33m|->> #0/t=11-th Action selection: 4/UP (P(a|s) = 0.06599999964237213)\u001b[0m\n",
            "      |->> Bounding box moves to: [293 154  84  79]\n",
            "         |->> Action Probabilities (Rounded): [0.0601 0.0476 0.0699 0.0553 0.0661 0.0538 0.073  0.0565 0.4048 0.0455\n",
            " 0.0673], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06013882 0.04759968 0.06985829 0.05534353 0.06606008 0.05380516\n",
            " 0.07303797 0.05652958 0.4048422  0.04547558 0.0673091 ], argmax=8\n",
            "|->> Revisiting bbox: [293 154  84  79]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [293, 156,  84,  79] -> [293, 154,  84,  79] (Target was [280, 139,  99,  93])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for UP:bbox transition: [293, 156,  84,  79] -> [293, 154,  84,  79] w/ P(a|s)=0.06606008112430573 and iou=0.7051985792702615 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [2.7171907]\n",
            "\u001b[92m>> Total frame loss: 2.717190742492676\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1775 with src: [293, 154,  84,  79] and target: [280, 137,  97,  99]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1776.jpg\n",
            "|->> Beginning tracking for bbox:[293 154  84  79]\n",
            "|->> Revisiting bbox: [293 154  84  79]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=12-th Action selection: 8/STOP (P(a|s) = 0.4320000112056732)\u001b[0m\n",
            "      |->> Bounding box moves to: [293 154  84  79]\n",
            "         |->> Action Probabilities (Rounded): [0.0576 0.0453 0.0637 0.0557 0.0634 0.0502 0.0679 0.0568 0.4321 0.0431\n",
            " 0.0641], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0575543  0.04532232 0.06373159 0.05568136 0.06344812 0.05019642\n",
            " 0.06787734 0.056816   0.43211213 0.04314185 0.06411851], argmax=8\n",
            "         |->> Hit a STOP on the 12-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [293, 154,  84,  79] -> [293, 154,  84,  79] (Target was [280, 137,  97,  99])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [293, 154,  84,  79] -> [293, 154,  84,  79] w/ P(a|s)=0.4321121275424957 and iou=0.6910340518587941 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.8390702]\n",
            "\u001b[31m>> Total frame loss: -0.839070200920105\u001b[0m\n",
            "Final bounding box: [293 154  84  79] reached in 12 timesteps (originating from [286 147  87  82]). Target was [280 137  97  99]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 1776 in t=12 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[92m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 7.854394435882568\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 3.357975721359253\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/Rubik\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Starting bounding box=adnet_datasets/OTB/Rubik/img/1777.jpg for adnet_datasets/OTB/Rubik's frames (index: 0)\n",
            "src:adnet_datasets/OTB/Rubik/img/1767.jpg\n",
            "target:adnet_datasets/OTB/Rubik/img/1777.jpg.\n",
            "\u001b[34m>> Attempting to reach frame 1767 with src: [284, 147,  93,  82] and target: [284, 142,  90,  85]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1768.jpg\n",
            "|->> Beginning tracking for bbox:[284 147  93  82]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 1/2X LEFT (P(a|s) = 0.08100000023841858)\u001b[0m\n",
            "      |->> Bounding box moves to: [280 147  93  82]\n",
            "         |->> Action Probabilities (Rounded): [0.0885 0.0811 0.0936 0.0878 0.0915 0.0821 0.0957 0.0877 0.1201 0.0821\n",
            " 0.0897], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08852242 0.0810748  0.09364305 0.0877743  0.09148505 0.08214309\n",
            " 0.0957249  0.08768514 0.12013655 0.08214635 0.08966435], argmax=8\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 5/2X UP (P(a|s) = 0.07800000160932541)\u001b[0m\n",
            "      |->> Bounding box moves to: [280 143  93  82]\n",
            "         |->> Action Probabilities (Rounded): [0.0832 0.0704 0.0981 0.0951 0.0902 0.0778 0.0964 0.0856 0.1396 0.0769\n",
            " 0.0866], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08324583 0.07036704 0.09811436 0.09505741 0.09024554 0.0777928\n",
            " 0.09643245 0.08563199 0.13962828 0.07687712 0.08660719], argmax=8\n",
            "   \u001b[33m|->> #2/t=3-th Action selection: 1/2X LEFT (P(a|s) = 0.06700000166893005)\u001b[0m\n",
            "      |->> Bounding box moves to: [276 143  93  82]\n",
            "         |->> Action Probabilities (Rounded): [0.0797 0.0672 0.096  0.0894 0.0863 0.0679 0.0968 0.0921 0.1659 0.0736\n",
            " 0.085 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07968041 0.06723907 0.09595083 0.08942827 0.08633787 0.06788599\n",
            " 0.09677928 0.09213749 0.16589825 0.07364465 0.08501792], argmax=8\n",
            "|->> Revisiting bbox: [276 143  93  82]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [284, 147,  93,  82] -> [276, 143,  93,  82] (Target was [284, 142,  90,  85])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.019) for 2X LEFT:bbox transition: [284, 147,  93,  82] -> [280, 147,  93,  82] w/ P(a|s)=0.0810747966170311 and iou=0.8729769494850417 and reward=-0.0185535111390297 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.042) for 2X UP:bbox transition: [280, 147,  93,  82] -> [280, 143,  93,  82] w/ P(a|s)=0.07779280096292496 and iou=0.9147656054148909 and reward=0.04178865592984926 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (1.0) for 2X LEFT:bbox transition: [280, 143,  93,  82] -> [276, 143,  93,  82] w/ P(a|s)=0.06723906844854355 and iou=0.8391524199373946 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.04661353  0.10671596  2.6995008 ]\n",
            "\u001b[92m>> Total frame loss: 2.759603261947632\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1768 with src: [276, 143,  93,  82] and target: [281, 150,  95,  85]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1769.jpg\n",
            "|->> Beginning tracking for bbox:[276 143  93  82]\n",
            "   \u001b[33m|->> #0/t=4-th Action selection: 10/SCALE UP (P(a|s) = 0.07900000363588333)\u001b[0m\n",
            "      |->> Bounding box moves to: [274 141  95  84]\n",
            "         |->> Action Probabilities (Rounded): [0.0727 0.0574 0.1011 0.099  0.0849 0.0655 0.1013 0.0885 0.1823 0.0679\n",
            " 0.0794], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07271843 0.05740909 0.10111141 0.09904362 0.08491131 0.06550512\n",
            " 0.10130055 0.08847185 0.1822543  0.06791934 0.07935496], argmax=8\n",
            "   \u001b[33m|->> #1/t=5-th Action selection: 0/LEFT (P(a|s) = 0.07100000232458115)\u001b[0m\n",
            "      |->> Bounding box moves to: [272 141  95  84]\n",
            "         |->> Action Probabilities (Rounded): [0.071  0.057  0.0979 0.0935 0.0832 0.0624 0.0974 0.0862 0.2117 0.0685\n",
            " 0.0711], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07095331 0.05696155 0.09793944 0.09345222 0.08323558 0.06242272\n",
            " 0.09742343 0.08624735 0.21173768 0.06848698 0.07113975], argmax=8\n",
            "   \u001b[33m|->> #2/t=6-th Action selection: 7/2X DOWN (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [272 145  95  84]\n",
            "         |->> Action Probabilities (Rounded): [0.0621 0.0512 0.1069 0.0919 0.082  0.0593 0.0984 0.0872 0.2262 0.0631\n",
            " 0.0716], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06210326 0.05118857 0.10693432 0.09194253 0.08196057 0.05931859\n",
            " 0.09837306 0.08724351 0.22621436 0.06308813 0.07163306], argmax=8\n",
            "   \u001b[33m|->> #3/t=7-th Action selection: 6/DOWN (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [272 147  95  84]\n",
            "         |->> Action Probabilities (Rounded): [0.0701 0.0498 0.0931 0.0864 0.0806 0.0618 0.0929 0.0715 0.2632 0.0617\n",
            " 0.069 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07005201 0.04976996 0.0930666  0.08638825 0.08060616 0.06182354\n",
            " 0.0929188  0.07149145 0.26318455 0.06173629 0.06896242], argmax=8\n",
            "   \u001b[33m|->> #4/t=8-th Action selection: 6/DOWN (P(a|s) = 0.08299999684095383)\u001b[0m\n",
            "      |->> Bounding box moves to: [272 149  95  84]\n",
            "         |->> Action Probabilities (Rounded): [0.063  0.047  0.0936 0.0827 0.0847 0.0621 0.0828 0.0658 0.2908 0.0575\n",
            " 0.07  ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06302088 0.04698417 0.09360243 0.08269227 0.0846571  0.0621189\n",
            " 0.08283317 0.06581718 0.2907735  0.05750509 0.06999534], argmax=8\n",
            "|->> Revisiting bbox: [272 147  95  84]. ACtion 4 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [276, 143,  93,  82] -> [272, 149,  95,  84] (Target was [281, 150,  95,  85])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.027) for SCALE UP:bbox transition: [276, 143,  93,  82] -> [274, 141,  95,  84] w/ P(a|s)=0.07935495674610138 and iou=0.6980433632998414 and reward=-0.02715167021295939 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.027) for LEFT:bbox transition: [274, 141,  95,  84] -> [272, 141,  95,  84] w/ P(a|s)=0.07095330953598022 and iou=0.6715252472670484 and reward=-0.02651811603279297 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.062) for 2X DOWN:bbox transition: [272, 141,  95,  84] -> [272, 145,  95,  84] w/ P(a|s)=0.08724351227283478 and iou=0.733614080552856 and reward=0.06208883328580761 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.033) for DOWN:bbox transition: [272, 145,  95,  84] -> [272, 147,  95,  84] w/ P(a|s)=0.09291879832744598 and iou=0.7664209483991639 and reward=0.03280686784630782 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (1.0) for DOWN:bbox transition: [272, 147,  95,  84] -> [272, 149,  95,  84] w/ P(a|s)=0.0828331708908081 and iou=0.8004934394975889 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.06879757 -0.07015986  0.1514379   0.07795008  2.4909267 ]\n",
            "\u001b[92m>> Total frame loss: 2.58135724067688\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1769 with src: [272, 149,  95,  84] and target: [281, 145,  95,  91]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1770.jpg\n",
            "|->> Beginning tracking for bbox:[272 149  95  84]\n",
            "   \u001b[33m|->> #0/t=9-th Action selection: 0/LEFT (P(a|s) = 0.06400000303983688)\u001b[0m\n",
            "      |->> Bounding box moves to: [270 149  95  84]\n",
            "         |->> Action Probabilities (Rounded): [0.0643 0.0432 0.0822 0.0821 0.0803 0.0604 0.0817 0.0605 0.3252 0.0519\n",
            " 0.0682], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06426843 0.04322139 0.08217398 0.08211398 0.08031191 0.06038108\n",
            " 0.08171694 0.06052359 0.3252281  0.05188159 0.06817906], argmax=8\n",
            "|->> Revisiting bbox: [270 149  95  84]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [272, 149,  95,  84] -> [270, 149,  95,  84] (Target was [281, 145,  95,  91])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for LEFT:bbox transition: [272, 149,  95,  84] -> [270, 149,  95,  84] w/ P(a|s)=0.06426843255758286 and iou=0.737381126554499 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [2.7446866]\n",
            "\u001b[92m>> Total frame loss: 2.7446866035461426\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1770 with src: [270, 149,  95,  84] and target: [276, 140, 107,  97]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1771.jpg\n",
            "|->> Beginning tracking for bbox:[270 149  95  84]\n",
            "|->> Revisiting bbox: [270 149  95  84]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=10-th Action selection: 8/STOP (P(a|s) = 0.3790000081062317)\u001b[0m\n",
            "      |->> Bounding box moves to: [270 149  95  84]\n",
            "         |->> Action Probabilities (Rounded): [0.0496 0.0383 0.0905 0.0698 0.0759 0.0578 0.0742 0.0576 0.3788 0.0453\n",
            " 0.0622], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0495833  0.0383447  0.09048653 0.06978934 0.07592737 0.0577775\n",
            " 0.07423081 0.05763073 0.37876546 0.0452502  0.06221408], argmax=8\n",
            "         |->> Hit a STOP on the 10-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [270, 149,  95,  84] -> [270, 149,  95,  84] (Target was [276, 140, 107,  97])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [270, 149,  95,  84] -> [270, 149,  95,  84] w/ P(a|s)=0.3787654638290405 and iou=0.6869429385279794 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.97083807]\n",
            "\u001b[31m>> Total frame loss: -0.9708380699157715\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1771 with src: [270, 149,  95,  84] and target: [275, 133, 103, 103]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1772.jpg\n",
            "|->> Beginning tracking for bbox:[270 149  95  84]\n",
            "   \u001b[33m|->> #0/t=10-th Action selection: 7/2X DOWN (P(a|s) = 0.0560000017285347)\u001b[0m\n",
            "      |->> Bounding box moves to: [270 153  95  84]\n",
            "         |->> Action Probabilities (Rounded): [0.0563 0.0395 0.0824 0.0705 0.0679 0.0527 0.0771 0.0561 0.3923 0.0448\n",
            " 0.0604], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05630212 0.0395009  0.08240797 0.07052548 0.06785816 0.0526805\n",
            " 0.07711966 0.05609334 0.39232653 0.0448215  0.06036386], argmax=8\n",
            "   \u001b[33m|->> #1/t=11-th Action selection: 0/LEFT (P(a|s) = 0.052000001072883606)\u001b[0m\n",
            "      |->> Bounding box moves to: [268 153  95  84]\n",
            "         |->> Action Probabilities (Rounded): [0.052  0.0382 0.0718 0.0646 0.0731 0.0582 0.071  0.0534 0.4179 0.0432\n",
            " 0.0566], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0520268  0.03824412 0.07176395 0.06455526 0.07309933 0.05817853\n",
            " 0.0710486  0.05335892 0.41787672 0.04324747 0.05660032], argmax=8\n",
            "|->> Revisiting bbox: [270 153  95  84]. ACtion 2 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [270, 149,  95,  84] -> [268, 153,  95,  84] (Target was [275, 133, 103, 103])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.014) for 2X DOWN:bbox transition: [270, 149,  95,  84] -> [270, 153,  95,  84] w/ P(a|s)=0.05609333515167236 and iou=0.6718230056659772 and reward=-0.013642585049409517 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for LEFT:bbox transition: [270, 153,  95,  84] -> [268, 153,  95,  84] w/ P(a|s)=0.05202680453658104 and iou=0.6472308373947718 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.03930072 -2.9559963 ]\n",
            "\u001b[31m>> Total frame loss: -2.9952969551086426\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1772 with src: [268, 153,  95,  84] and target: [279, 139,  96, 102]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1773.jpg\n",
            "|->> Beginning tracking for bbox:[268 153  95  84]\n",
            "   \u001b[33m|->> #0/t=12-th Action selection: 10/SCALE UP (P(a|s) = 0.0560000017285347)\u001b[0m\n",
            "      |->> Bounding box moves to: [266 151  97  86]\n",
            "         |->> Action Probabilities (Rounded): [0.0481 0.0381 0.0738 0.0639 0.0677 0.0562 0.0668 0.0522 0.434  0.0429\n",
            " 0.0563], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.04813926 0.03806581 0.07377799 0.06387147 0.06769402 0.05615173\n",
            " 0.06684972 0.0521603  0.4340291  0.04292319 0.05633748], argmax=8\n",
            "   \u001b[33m|->> #1/t=13-th Action selection: 6/DOWN (P(a|s) = 0.06800000369548798)\u001b[0m\n",
            "      |->> Bounding box moves to: [266 153  97  86]\n",
            "         |->> Action Probabilities (Rounded): [0.054  0.0386 0.0699 0.0638 0.0689 0.0534 0.0683 0.0489 0.4372 0.044\n",
            " 0.053 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05395241 0.03861319 0.06991258 0.0638141  0.06890077 0.05341323\n",
            " 0.06830812 0.04885567 0.43719703 0.04402463 0.05300827], argmax=8\n",
            "   \u001b[33m|->> #2/t=14-th Action selection: 9/SCALE DOWN (P(a|s) = 0.04500000178813934)\u001b[0m\n",
            "      |->> Bounding box moves to: [267 154  94  83]\n",
            "         |->> Action Probabilities (Rounded): [0.0514 0.0378 0.0786 0.0616 0.0726 0.0536 0.0638 0.0476 0.4317 0.0452\n",
            " 0.0564], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05135512 0.03775172 0.07856461 0.06156205 0.07255317 0.05361284\n",
            " 0.06375459 0.04756119 0.43172756 0.04518501 0.05637214], argmax=8\n",
            "|->> Revisiting bbox: [267 154  94  83]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [268, 153,  95,  84] -> [267, 154,  94,  83] (Target was [279, 139,  96, 102])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.004) for SCALE UP:bbox transition: [268, 153,  95,  84] -> [266, 151,  97,  86] w/ P(a|s)=0.05633747950196266 and iou=0.6621448212648946 and reward=0.0036901740084556156 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for DOWN:bbox transition: [266, 151,  97,  86] -> [266, 153,  97,  86] w/ P(a|s)=0.06830812245607376 and iou=0.6621448212648946 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [266, 153,  97,  86] -> [267, 154,  94,  83] w/ P(a|s)=0.045185014605522156 and iou=0.6308861698183167 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.0106144  0.        -3.0969899]\n",
            "\u001b[31m>> Total frame loss: -3.0863754749298096\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1773 with src: [267, 154,  94,  83] and target: [279, 140,  97,  99]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1774.jpg\n",
            "|->> Beginning tracking for bbox:[267 154  94  83]\n",
            "|->> Revisiting bbox: [267 154  94  83]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=15-th Action selection: 8/STOP (P(a|s) = 0.4350000023841858)\u001b[0m\n",
            "      |->> Bounding box moves to: [267 154  94  83]\n",
            "         |->> Action Probabilities (Rounded): [0.0571 0.0389 0.0669 0.0638 0.0689 0.0528 0.0683 0.051  0.4346 0.0402\n",
            " 0.0575], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05706934 0.03892031 0.06689521 0.06383609 0.06889889 0.05279247\n",
            " 0.06829471 0.05103448 0.4345604  0.04023866 0.05745938], argmax=8\n",
            "         |->> Hit a STOP on the 15-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [267, 154,  94,  83] -> [267, 154,  94,  83] (Target was [279, 140,  97,  99])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [267, 154,  94,  83] -> [267, 154,  94,  83] w/ P(a|s)=0.4345603883266449 and iou=0.6421360505708086 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.8334204]\n",
            "\u001b[31m>> Total frame loss: -0.8334203958511353\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1774 with src: [267, 154,  94,  83] and target: [280, 139,  99,  93]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1775.jpg\n",
            "|->> Beginning tracking for bbox:[267 154  94  83]\n",
            "   \u001b[33m|->> #0/t=15-th Action selection: 2/RIGHT (P(a|s) = 0.07800000160932541)\u001b[0m\n",
            "      |->> Bounding box moves to: [269 154  94  83]\n",
            "         |->> Action Probabilities (Rounded): [0.0559 0.0435 0.0778 0.0645 0.0815 0.0554 0.0732 0.0564 0.3845 0.0425\n",
            " 0.0648], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05586978 0.04353812 0.07775558 0.06448131 0.08146048 0.05538115\n",
            " 0.07319924 0.05644659 0.38452744 0.04251331 0.06482694], argmax=8\n",
            "|->> Revisiting bbox: [269 154  94  83]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [267, 154,  94,  83] -> [269, 154,  94,  83] (Target was [280, 139,  99,  93])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for RIGHT:bbox transition: [267, 154,  94,  83] -> [269, 154,  94,  83] w/ P(a|s)=0.07775557786226273 and iou=0.6145230185097295 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.554185]\n",
            "\u001b[31m>> Total frame loss: -2.554184913635254\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1775 with src: [269, 154,  94,  83] and target: [280, 137,  97,  99]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1776.jpg\n",
            "|->> Beginning tracking for bbox:[269 154  94  83]\n",
            "|->> Revisiting bbox: [269 154  94  83]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=16-th Action selection: 8/STOP (P(a|s) = 0.41499999165534973)\u001b[0m\n",
            "      |->> Bounding box moves to: [269 154  94  83]\n",
            "         |->> Action Probabilities (Rounded): [0.0614 0.0421 0.0636 0.0601 0.0706 0.0529 0.0746 0.0572 0.415  0.041\n",
            " 0.0615], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06139681 0.04209236 0.06356995 0.06010151 0.07061239 0.0529031\n",
            " 0.07458921 0.05719813 0.41504937 0.04099852 0.06148867], argmax=8\n",
            "         |->> Hit a STOP on the 16-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [269, 154,  94,  83] -> [269, 154,  94,  83] (Target was [280, 137,  97,  99])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [269, 154,  94,  83] -> [269, 154,  94,  83] w/ P(a|s)=0.41504937410354614 and iou=0.6421360505708086 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.8793578]\n",
            "\u001b[31m>> Total frame loss: -0.8793578147888184\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1776 with src: [269, 154,  94,  83] and target: [278, 137,  96, 104]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1777.jpg\n",
            "|->> Beginning tracking for bbox:[269 154  94  83]\n",
            "   \u001b[33m|->> #0/t=16-th Action selection: 7/2X DOWN (P(a|s) = 0.061000000685453415)\u001b[0m\n",
            "      |->> Bounding box moves to: [269 158  94  83]\n",
            "         |->> Action Probabilities (Rounded): [0.0559 0.0466 0.0726 0.0611 0.0677 0.0529 0.074  0.061  0.4012 0.0426\n",
            " 0.0644], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0558858  0.04658414 0.07260977 0.06107138 0.0676646  0.05286996\n",
            " 0.07403991 0.06104685 0.4011998  0.04259071 0.06443701], argmax=8\n",
            "|->> Revisiting bbox: [269 158  94  83]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [269, 154,  94,  83] -> [269, 158,  94,  83] (Target was [278, 137,  96, 104])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for 2X DOWN:bbox transition: [269, 154,  94,  83] -> [269, 158,  94,  83] w/ P(a|s)=0.06104684993624687 and iou=0.657441058615227 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.7961137]\n",
            "\u001b[31m>> Total frame loss: -2.7961137294769287\u001b[0m\n",
            "Final bounding box: [269 158  94  83] reached in 17 timesteps (originating from [284 147  93  82]). Target was [278 137  96 104]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 1777 in t=17 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[31m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 8.260783195495605\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 2.424255132675171\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/Rubik\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Starting bounding box=adnet_datasets/OTB/Rubik/img/1778.jpg for adnet_datasets/OTB/Rubik's frames (index: 0)\n",
            "src:adnet_datasets/OTB/Rubik/img/1768.jpg\n",
            "target:adnet_datasets/OTB/Rubik/img/1778.jpg.\n",
            "\u001b[34m>> Attempting to reach frame 1768 with src: [284, 142,  90,  85] and target: [281, 150,  95,  85]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1769.jpg\n",
            "|->> Beginning tracking for bbox:[284 142  90  85]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 6/DOWN (P(a|s) = 0.09600000083446503)\u001b[0m\n",
            "      |->> Bounding box moves to: [284 144  90  85]\n",
            "         |->> Action Probabilities (Rounded): [0.0885 0.0811 0.0936 0.0878 0.0915 0.0821 0.0957 0.0877 0.1201 0.0821\n",
            " 0.0897], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08852248 0.08107571 0.09364106 0.08777723 0.09149024 0.08214322\n",
            " 0.0957237  0.08768665 0.1201332  0.08214399 0.08966253], argmax=8\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 0/LEFT (P(a|s) = 0.0860000029206276)\u001b[0m\n",
            "      |->> Bounding box moves to: [282 144  90  85]\n",
            "         |->> Action Probabilities (Rounded): [0.0861 0.0771 0.0936 0.0858 0.0952 0.0813 0.0927 0.0826 0.1366 0.079\n",
            " 0.09  ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0861451  0.07708526 0.09361282 0.08578408 0.0952332  0.08128459\n",
            " 0.09266885 0.08262388 0.13656217 0.07902946 0.08997057], argmax=8\n",
            "|->> Revisiting bbox: [284 144  90  85]. ACtion 2 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [284, 142,  90,  85] -> [282, 144,  90,  85] (Target was [281, 150,  95,  85])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.037) for DOWN:bbox transition: [284, 142,  90,  85] -> [284, 144,  90,  85] w/ P(a|s)=0.0957236960530281 and iou=0.8253047011027278 and reward=0.03735700354729854 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for LEFT:bbox transition: [284, 144,  90,  85] -> [282, 144,  90,  85] w/ P(a|s)=0.08614509552717209 and iou=0.8253047011027278 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.08765034 2.4517221 ]\n",
            "\u001b[92m>> Total frame loss: 2.539372444152832\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1769 with src: [282, 144,  90,  85] and target: [281, 145,  95,  91]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1770.jpg\n",
            "|->> Beginning tracking for bbox:[282 144  90  85]\n",
            "   \u001b[33m|->> #0/t=3-th Action selection: 1/2X LEFT (P(a|s) = 0.07000000029802322)\u001b[0m\n",
            "      |->> Bounding box moves to: [278 144  90  85]\n",
            "         |->> Action Probabilities (Rounded): [0.0769 0.0701 0.1034 0.0871 0.0912 0.0799 0.0946 0.0829 0.1543 0.0729\n",
            " 0.0868], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07685822 0.07014979 0.10339877 0.08708459 0.09123931 0.07985883\n",
            " 0.09459808 0.08285008 0.15429503 0.07287149 0.08679576], argmax=8\n",
            "   \u001b[33m|->> #1/t=4-th Action selection: 7/2X DOWN (P(a|s) = 0.07599999755620956)\u001b[0m\n",
            "      |->> Bounding box moves to: [278 148  90  85]\n",
            "         |->> Action Probabilities (Rounded): [0.0806 0.0624 0.102  0.0929 0.0895 0.0722 0.0943 0.0765 0.1772 0.0685\n",
            " 0.0841], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08061403 0.06239766 0.10197659 0.09285144 0.08948179 0.07218786\n",
            " 0.09425633 0.07649574 0.17715679 0.06847974 0.08410204], argmax=8\n",
            "   \u001b[33m|->> #2/t=5-th Action selection: 1/2X LEFT (P(a|s) = 0.057999998331069946)\u001b[0m\n",
            "      |->> Bounding box moves to: [274 148  90  85]\n",
            "         |->> Action Probabilities (Rounded): [0.0747 0.0578 0.1018 0.0901 0.0896 0.0763 0.087  0.0715 0.2013 0.0698\n",
            " 0.08  ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07474095 0.05783779 0.10183561 0.09014605 0.08956379 0.0762798\n",
            " 0.08695206 0.07152588 0.20131157 0.06983019 0.07997639], argmax=8\n",
            "   \u001b[33m|->> #3/t=6-th Action selection: 7/2X DOWN (P(a|s) = 0.0689999982714653)\u001b[0m\n",
            "      |->> Bounding box moves to: [274 152  90  85]\n",
            "         |->> Action Probabilities (Rounded): [0.0729 0.0515 0.0966 0.0982 0.0871 0.0735 0.0868 0.0686 0.2258 0.0635\n",
            " 0.0756], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07294476 0.0514735  0.09655865 0.09823588 0.08713973 0.07347748\n",
            " 0.08678122 0.06858452 0.22578886 0.0634636  0.07555171], argmax=8\n",
            "|->> Revisiting bbox: [274 152  90  85]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [282, 144,  90,  85] -> [274, 152,  90,  85] (Target was [281, 145,  95,  91])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.052) for 2X LEFT:bbox transition: [282, 144,  90,  85] -> [278, 144,  90,  85] w/ P(a|s)=0.07014978677034378 and iou=0.8131745855124068 and reward=-0.0523091008069978 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.018) for 2X DOWN:bbox transition: [278, 144,  90,  85] -> [278, 148,  90,  85] w/ P(a|s)=0.07649573683738708 and iou=0.8308988764044943 and reward=0.01772429089208749 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.067) for 2X LEFT:bbox transition: [278, 148,  90,  85] -> [274, 148,  90,  85] w/ P(a|s)=0.05783779174089432 and iou=0.7635281385281385 and reward=-0.06737073787635584 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (1.0) for 2X DOWN:bbox transition: [274, 148,  90,  85] -> [274, 152,  90,  85] w/ P(a|s)=0.06858452409505844 and iou=0.7478279523758447 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.1389917   0.04556065 -0.1920142   2.6796885 ]\n",
            "\u001b[92m>> Total frame loss: 2.3942432403564453\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1770 with src: [274, 152,  90,  85] and target: [276, 140, 107,  97]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1771.jpg\n",
            "|->> Beginning tracking for bbox:[274 152  90  85]\n",
            "   \u001b[33m|->> #0/t=7-th Action selection: 1/2X LEFT (P(a|s) = 0.04899999871850014)\u001b[0m\n",
            "      |->> Bounding box moves to: [270 152  90  85]\n",
            "         |->> Action Probabilities (Rounded): [0.0654 0.0487 0.0923 0.0859 0.0889 0.0732 0.0826 0.0601 0.2697 0.0597\n",
            " 0.0736], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06539019 0.04870168 0.09226536 0.0858632  0.08889624 0.0732282\n",
            " 0.08259555 0.06005872 0.269737   0.05971178 0.07355202], argmax=8\n",
            "   \u001b[33m|->> #1/t=8-th Action selection: 6/DOWN (P(a|s) = 0.07699999958276749)\u001b[0m\n",
            "      |->> Bounding box moves to: [270 154  90  85]\n",
            "         |->> Action Probabilities (Rounded): [0.0593 0.0418 0.0949 0.092  0.0821 0.0634 0.0768 0.0561 0.3086 0.0567\n",
            " 0.0682], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0593279  0.04183665 0.09491845 0.09202596 0.08208639 0.06337282\n",
            " 0.07682996 0.05609952 0.30859736 0.05668844 0.06821658], argmax=8\n",
            "   \u001b[33m|->> #2/t=9-th Action selection: 1/2X LEFT (P(a|s) = 0.039000000804662704)\u001b[0m\n",
            "      |->> Bounding box moves to: [266 154  90  85]\n",
            "         |->> Action Probabilities (Rounded): [0.0568 0.0393 0.0832 0.085  0.0841 0.0644 0.079  0.0546 0.3339 0.0529\n",
            " 0.067 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05678092 0.03927805 0.08316626 0.08501644 0.08405122 0.06440564\n",
            " 0.0789913  0.05455094 0.33386862 0.05286055 0.06703006], argmax=8\n",
            "|->> Revisiting bbox: [270 154  90  85]. ACtion 3 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [274, 152,  90,  85] -> [266, 154,  90,  85] (Target was [276, 140, 107,  97])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.053) for 2X LEFT:bbox transition: [274, 152,  90,  85] -> [270, 152,  90,  85] w/ P(a|s)=0.048701681196689606 and iou=0.655707594820461 and reward=-0.05336435512740134 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.025) for DOWN:bbox transition: [270, 152,  90,  85] -> [270, 154,  90,  85] w/ P(a|s)=0.07682996243238449 and iou=0.630550782309849 and reward=-0.02515681251061208 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [270, 154,  90,  85] -> [266, 154,  90,  85] w/ P(a|s)=0.039278045296669006 and iou=0.5830187022565634 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.1612693  -0.06455643 -3.2370896 ]\n",
            "\u001b[31m>> Total frame loss: -3.4629154205322266\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1771 with src: [266, 154,  90,  85] and target: [275, 133, 103, 103]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1772.jpg\n",
            "|->> Beginning tracking for bbox:[266 154  90  85]\n",
            "   \u001b[33m|->> #0/t=10-th Action selection: 2/RIGHT (P(a|s) = 0.08299999684095383)\u001b[0m\n",
            "      |->> Bounding box moves to: [268 154  90  85]\n",
            "         |->> Action Probabilities (Rounded): [0.0496 0.0322 0.083  0.0808 0.0802 0.0587 0.0674 0.0518 0.3864 0.0477\n",
            " 0.0623], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.04956261 0.03216593 0.08298805 0.08080569 0.08023077 0.05865399\n",
            " 0.06737828 0.05177693 0.38643855 0.04773714 0.06226206], argmax=8\n",
            "|->> Revisiting bbox: [268 154  90  85]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [266, 154,  90,  85] -> [268, 154,  90,  85] (Target was [275, 133, 103, 103])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for RIGHT:bbox transition: [266, 154,  90,  85] -> [268, 154,  90,  85] w/ P(a|s)=0.08298805356025696 and iou=0.5942547804068803 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.4890585]\n",
            "\u001b[31m>> Total frame loss: -2.489058494567871\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1772 with src: [268, 154,  90,  85] and target: [279, 139,  96, 102]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1773.jpg\n",
            "|->> Beginning tracking for bbox:[268 154  90  85]\n",
            "|->> Revisiting bbox: [268 154  90  85]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=11-th Action selection: 8/STOP (P(a|s) = 0.4230000078678131)\u001b[0m\n",
            "      |->> Bounding box moves to: [268 154  90  85]\n",
            "         |->> Action Probabilities (Rounded): [0.0545 0.0316 0.071  0.0719 0.0703 0.0514 0.0723 0.051  0.423  0.0421\n",
            " 0.061 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05447497 0.03155987 0.0710298  0.07188373 0.07031222 0.05143537\n",
            " 0.07226463 0.05095235 0.42301533 0.04209344 0.06097832], argmax=8\n",
            "         |->> Hit a STOP on the 11-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [268, 154,  90,  85] -> [268, 154,  90,  85] (Target was [279, 139,  96, 102])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [268, 154,  90,  85] -> [268, 154,  90,  85] w/ P(a|s)=0.4230153262615204 and iou=0.6259904912836767 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.86034685]\n",
            "\u001b[31m>> Total frame loss: -0.8603468537330627\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1773 with src: [268, 154,  90,  85] and target: [279, 140,  97,  99]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1774.jpg\n",
            "|->> Beginning tracking for bbox:[268 154  90  85]\n",
            "|->> Revisiting bbox: [268 154  90  85]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=11-th Action selection: 8/STOP (P(a|s) = 0.4059999883174896)\u001b[0m\n",
            "      |->> Bounding box moves to: [268 154  90  85]\n",
            "         |->> Action Probabilities (Rounded): [0.0496 0.0363 0.0812 0.0718 0.0741 0.0551 0.0673 0.0533 0.4062 0.0445\n",
            " 0.0604], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.04964976 0.03632235 0.08124256 0.07177309 0.07410456 0.05514657\n",
            " 0.0673121  0.0533431  0.40618843 0.04450954 0.06040792], argmax=8\n",
            "         |->> Hit a STOP on the 11-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [268, 154,  90,  85] -> [268, 154,  90,  85] (Target was [279, 140,  97,  99])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [268, 154,  90,  85] -> [268, 154,  90,  85] w/ P(a|s)=0.406188428401947 and iou=0.6372176883659139 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.90093815]\n",
            "\u001b[31m>> Total frame loss: -0.9009381532669067\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1774 with src: [268, 154,  90,  85] and target: [280, 139,  99,  93]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1775.jpg\n",
            "|->> Beginning tracking for bbox:[268 154  90  85]\n",
            "   \u001b[33m|->> #0/t=11-th Action selection: 2/RIGHT (P(a|s) = 0.07199999690055847)\u001b[0m\n",
            "      |->> Bounding box moves to: [270 154  90  85]\n",
            "         |->> Action Probabilities (Rounded): [0.0531 0.0389 0.0718 0.0688 0.0671 0.0553 0.0768 0.0545 0.4042 0.0473\n",
            " 0.0623], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05307436 0.03886478 0.07176465 0.06879299 0.0670779  0.05529854\n",
            " 0.07678515 0.05454373 0.4041941  0.0473467  0.06225711], argmax=8\n",
            "|->> Revisiting bbox: [270 154  90  85]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [268, 154,  90,  85] -> [270, 154,  90,  85] (Target was [280, 139,  99,  93])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for RIGHT:bbox transition: [268, 154,  90,  85] -> [270, 154,  90,  85] w/ P(a|s)=0.07176464796066284 and iou=0.5877366487708392 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.6343632]\n",
            "\u001b[31m>> Total frame loss: -2.6343631744384766\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1775 with src: [270, 154,  90,  85] and target: [280, 137,  97,  99]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1776.jpg\n",
            "|->> Beginning tracking for bbox:[270 154  90  85]\n",
            "   \u001b[33m|->> #0/t=12-th Action selection: 10/SCALE UP (P(a|s) = 0.05999999865889549)\u001b[0m\n",
            "      |->> Bounding box moves to: [268 152  92  87]\n",
            "         |->> Action Probabilities (Rounded): [0.0537 0.0396 0.0566 0.0589 0.0636 0.0492 0.0686 0.0523 0.4576 0.0396\n",
            " 0.0602], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05372605 0.03961351 0.0565755  0.05891449 0.06355034 0.04922625\n",
            " 0.0686029  0.05232775 0.45764226 0.03960219 0.06021879], argmax=8\n",
            "   \u001b[33m|->> #1/t=13-th Action selection: 2/RIGHT (P(a|s) = 0.06499999761581421)\u001b[0m\n",
            "      |->> Bounding box moves to: [270 152  92  87]\n",
            "         |->> Action Probabilities (Rounded): [0.0489 0.0375 0.0653 0.061  0.0614 0.0435 0.0689 0.0557 0.4647 0.0422\n",
            " 0.051 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.04894027 0.0374872  0.06527141 0.06095852 0.06143127 0.04348251\n",
            " 0.0688945  0.05570762 0.4646553  0.04216366 0.05100768], argmax=8\n",
            "   \u001b[33m|->> #2/t=14-th Action selection: 5/2X UP (P(a|s) = 0.04699999839067459)\u001b[0m\n",
            "      |->> Bounding box moves to: [270 148  92  87]\n",
            "         |->> Action Probabilities (Rounded): [0.0588 0.0403 0.0598 0.0565 0.0658 0.047  0.0725 0.0581 0.4436 0.043\n",
            " 0.0547], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0587595  0.0402593  0.05978282 0.05645965 0.06583481 0.04703943\n",
            " 0.07250653 0.05806149 0.44361252 0.04298924 0.05469467], argmax=8\n",
            "|->> Revisiting bbox: [270 148  92  87]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [270, 154,  90,  85] -> [270, 148,  92,  87] (Target was [280, 137,  97,  99])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.004) for SCALE UP:bbox transition: [270, 154,  90,  85] -> [268, 152,  92,  87] w/ P(a|s)=0.06021878868341446 and iou=0.6172499311104988 and reward=0.003764473334383567 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.025) for RIGHT:bbox transition: [268, 152,  92,  87] -> [270, 152,  92,  87] w/ P(a|s)=0.06527140736579895 and iou=0.642597257206829 and reward=0.02534732609633028 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-1.0) for 2X UP:bbox transition: [270, 152,  92,  87] -> [270, 148,  92,  87] w/ P(a|s)=0.04703943431377411 and iou=0.6811801775995416 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.01057731  0.06917796 -3.056769  ]\n",
            "\u001b[31m>> Total frame loss: -2.97701358795166\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1776 with src: [270, 148,  92,  87] and target: [278, 137,  96, 104]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1777.jpg\n",
            "|->> Beginning tracking for bbox:[270 148  92  87]\n",
            "|->> Revisiting bbox: [270 148  92  87]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=15-th Action selection: 8/STOP (P(a|s) = 0.4620000123977661)\u001b[0m\n",
            "      |->> Bounding box moves to: [270 148  92  87]\n",
            "         |->> Action Probabilities (Rounded): [0.0537 0.0423 0.0661 0.0522 0.0562 0.0408 0.0748 0.0612 0.4618 0.039\n",
            " 0.0519], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05374419 0.04229908 0.06610323 0.05215611 0.05617514 0.04075417\n",
            " 0.07478782 0.06119234 0.46182054 0.03902565 0.05194168], argmax=8\n",
            "         |->> Hit a STOP on the 15-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [270, 148,  92,  87] -> [270, 148,  92,  87] (Target was [278, 137,  96, 104])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [270, 148,  92,  87] -> [270, 148,  92,  87] w/ P(a|s)=0.4618205428123474 and iou=0.6842696629213483 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.7725789]\n",
            "\u001b[31m>> Total frame loss: -0.7725788950920105\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1777 with src: [270, 148,  92,  87] and target: [274, 134, 102, 101]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1778.jpg\n",
            "|->> Beginning tracking for bbox:[270 148  92  87]\n",
            "|->> Revisiting bbox: [270 148  92  87]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=15-th Action selection: 8/STOP (P(a|s) = 0.40299999713897705)\u001b[0m\n",
            "      |->> Bounding box moves to: [270 148  92  87]\n",
            "         |->> Action Probabilities (Rounded): [0.0581 0.046  0.0685 0.0564 0.0681 0.0468 0.0878 0.0661 0.403  0.0416\n",
            " 0.0577], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05810254 0.04596798 0.06850013 0.05640589 0.06813919 0.0467654\n",
            " 0.0877763  0.06610746 0.40298253 0.04155737 0.0576952 ], argmax=8\n",
            "         |->> Hit a STOP on the 15-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [270, 148,  92,  87] -> [270, 148,  92,  87] (Target was [274, 134, 102, 101])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [270, 148,  92,  87] -> [270, 148,  92,  87] w/ P(a|s)=0.40298253297805786 and iou=0.7188732394366197 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.90886205]\n",
            "\u001b[92m>> Total frame loss: 0.9088620543479919\u001b[0m\n",
            "Final bounding box: [270 148  92  87] reached in 15 timesteps (originating from [284 142  90  85]). Target was [274 134 102 101]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 1778 in t=15 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[31m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 7.232938289642334\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 2.7945284843444824\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/Rubik\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Starting bounding box=adnet_datasets/OTB/Rubik/img/1779.jpg for adnet_datasets/OTB/Rubik's frames (index: 0)\n",
            "src:adnet_datasets/OTB/Rubik/img/1769.jpg\n",
            "target:adnet_datasets/OTB/Rubik/img/1779.jpg.\n",
            "\u001b[34m>> Attempting to reach frame 1769 with src: [281, 150,  95,  85] and target: [281, 145,  95,  91]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1770.jpg\n",
            "|->> Beginning tracking for bbox:[281 150  95  85]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 7/2X DOWN (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [281 154  95  85]\n",
            "         |->> Action Probabilities (Rounded): [0.0885 0.0811 0.0936 0.0878 0.0915 0.0821 0.0957 0.0877 0.1201 0.0821\n",
            " 0.0897], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08852385 0.08107536 0.09363732 0.08778018 0.09149521 0.08214246\n",
            " 0.09572291 0.08768929 0.12013029 0.08214205 0.08966114], argmax=8\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 4/UP (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [281 152  95  85]\n",
            "         |->> Action Probabilities (Rounded): [0.0863 0.0774 0.0951 0.0854 0.0942 0.0833 0.0915 0.0799 0.1374 0.0817\n",
            " 0.0877], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08626301 0.0774225  0.09512248 0.08543584 0.09417654 0.0832825\n",
            " 0.09147862 0.07994514 0.13744628 0.08172138 0.08770571], argmax=8\n",
            "   \u001b[33m|->> #2/t=3-th Action selection: 1/2X LEFT (P(a|s) = 0.07500000298023224)\u001b[0m\n",
            "      |->> Bounding box moves to: [277 152  95  85]\n",
            "         |->> Action Probabilities (Rounded): [0.0863 0.0748 0.0936 0.086  0.0891 0.0799 0.0935 0.0801 0.1561 0.0758\n",
            " 0.0846], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08631161 0.07481567 0.09361109 0.08602118 0.08910669 0.07994121\n",
            " 0.09353927 0.08012901 0.15609454 0.07581864 0.0846111 ], argmax=8\n",
            "   \u001b[33m|->> #3/t=4-th Action selection: 0/LEFT (P(a|s) = 0.07999999821186066)\u001b[0m\n",
            "      |->> Bounding box moves to: [275 152  95  85]\n",
            "         |->> Action Probabilities (Rounded): [0.0801 0.0647 0.0945 0.0912 0.09   0.077  0.0935 0.0775 0.1773 0.0712\n",
            " 0.0832], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08005396 0.06466728 0.09454798 0.09115812 0.08995265 0.07695182\n",
            " 0.09350292 0.07750573 0.17725271 0.0711578  0.08324901], argmax=8\n",
            "   \u001b[33m|->> #4/t=5-th Action selection: 5/2X UP (P(a|s) = 0.07000000029802322)\u001b[0m\n",
            "      |->> Bounding box moves to: [275 148  95  85]\n",
            "         |->> Action Probabilities (Rounded): [0.0676 0.059  0.1045 0.089  0.0852 0.0703 0.0937 0.0761 0.2074 0.0662\n",
            " 0.081 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06763532 0.05901616 0.1044794  0.08903421 0.0852381  0.07027955\n",
            " 0.09369215 0.07613935 0.20736924 0.06616218 0.0809543 ], argmax=8\n",
            "   \u001b[33m|->> #5/t=6-th Action selection: 0/LEFT (P(a|s) = 0.07199999690055847)\u001b[0m\n",
            "      |->> Bounding box moves to: [273 148  95  85]\n",
            "         |->> Action Probabilities (Rounded): [0.0719 0.0546 0.0959 0.0846 0.082  0.0604 0.0938 0.0805 0.2398 0.0615\n",
            " 0.075 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0718761  0.05464163 0.09591553 0.08461922 0.08196156 0.06040347\n",
            " 0.09378776 0.08045352 0.23978199 0.0615368  0.07502242], argmax=8\n",
            "|->> Revisiting bbox: [273 148  95  85]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [281, 150,  95,  85] -> [273, 148,  95,  85] (Target was [281, 145,  95,  91])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.062) for 2X DOWN:bbox transition: [281, 150,  95,  85] -> [281, 154,  95,  85] w/ P(a|s)=0.08768928796052933 and iou=0.8723404255319149 and reward=-0.06172550853401915 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.041) for UP:bbox transition: [281, 154,  95,  85] -> [281, 152,  95,  85] w/ P(a|s)=0.09417653828859329 and iou=0.9130434782608695 and reward=0.04070305272895458 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.071) for 2X LEFT:bbox transition: [281, 152,  95,  85] -> [277, 152,  95,  85] w/ P(a|s)=0.07481566816568375 and iou=0.8422212428382547 and reward=-0.07082223542261479 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-0.033) for LEFT:bbox transition: [277, 152,  95,  85] -> [275, 152,  95,  85] w/ P(a|s)=0.08005395531654358 and iou=0.8087408048463869 and reward=-0.03348043799186784 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (0.018) for 2X UP:bbox transition: [275, 152,  95,  85] -> [275, 148,  95,  85] w/ P(a|s)=0.0702795460820198 and iou=0.8263244128891316 and reward=0.017583608042744725 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (1.0) for LEFT:bbox transition: [275, 148,  95,  85] -> [273, 148,  95,  85] w/ P(a|s)=0.07187610119581223 and iou=0.793029490616622 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.15023716  0.09616439 -0.18362279 -0.08453993  0.04668931  2.6328115 ]\n",
            "\u001b[92m>> Total frame loss: 2.3572652339935303\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1770 with src: [273, 148,  95,  85] and target: [276, 140, 107,  97]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1771.jpg\n",
            "|->> Beginning tracking for bbox:[273 148  95  85]\n",
            "   \u001b[33m|->> #0/t=7-th Action selection: 4/UP (P(a|s) = 0.08100000023841858)\u001b[0m\n",
            "      |->> Bounding box moves to: [273 146  95  85]\n",
            "         |->> Action Probabilities (Rounded): [0.0589 0.05   0.0997 0.0832 0.0807 0.0637 0.0987 0.0787 0.2612 0.0545\n",
            " 0.0707], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05885353 0.04997841 0.09969947 0.08324595 0.08071301 0.06371186\n",
            " 0.09872423 0.07872022 0.26119432 0.05449047 0.0706685 ], argmax=8\n",
            "   \u001b[33m|->> #1/t=8-th Action selection: 4/UP (P(a|s) = 0.07500000298023224)\u001b[0m\n",
            "      |->> Bounding box moves to: [273 144  95  85]\n",
            "         |->> Action Probabilities (Rounded): [0.0687 0.0502 0.0889 0.0773 0.0746 0.052  0.0914 0.0776 0.3004 0.0535\n",
            " 0.0654], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06867596 0.0502045  0.08888825 0.07726254 0.07464618 0.05202673\n",
            " 0.09140128 0.077574   0.30043527 0.05347592 0.06540938], argmax=8\n",
            "|->> Revisiting bbox: [273 146  95  85]. ACtion 6 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [273, 148,  95,  85] -> [273, 144,  95,  85] (Target was [276, 140, 107,  97])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for UP:bbox transition: [273, 148,  95,  85] -> [273, 146,  95,  85] w/ P(a|s)=0.08071301132440567 and iou=0.7353770923453075 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for UP:bbox transition: [273, 146,  95,  85] -> [273, 144,  95,  85] w/ P(a|s)=0.07464618235826492 and iou=0.7353770923453075 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.       2.594996]\n",
            "\u001b[92m>> Total frame loss: 2.5949959754943848\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1771 with src: [273, 144,  95,  85] and target: [275, 133, 103, 103]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1772.jpg\n",
            "|->> Beginning tracking for bbox:[273 144  95  85]\n",
            "   \u001b[33m|->> #0/t=9-th Action selection: 6/DOWN (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [273 146  95  85]\n",
            "         |->> Action Probabilities (Rounded): [0.0641 0.0448 0.0828 0.0781 0.0678 0.0502 0.0895 0.0764 0.3302 0.0496\n",
            " 0.0666], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06406683 0.04477339 0.08284142 0.07809972 0.06779773 0.05020562\n",
            " 0.08950084 0.07635921 0.3302098  0.04957175 0.06657371], argmax=8\n",
            "   \u001b[33m|->> #1/t=10-th Action selection: 7/2X DOWN (P(a|s) = 0.06800000369548798)\u001b[0m\n",
            "      |->> Bounding box moves to: [273 150  95  85]\n",
            "         |->> Action Probabilities (Rounded): [0.0619 0.0434 0.0753 0.0732 0.0721 0.0493 0.0791 0.0683 0.3647 0.048\n",
            " 0.0648], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06185574 0.04342895 0.07525838 0.07320168 0.07209485 0.04930502\n",
            " 0.07908091 0.06826652 0.36472315 0.04799024 0.0647946 ], argmax=8\n",
            "|->> Revisiting bbox: [273 150  95  85]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [273, 144,  95,  85] -> [273, 150,  95,  85] (Target was [275, 133, 103, 103])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for DOWN:bbox transition: [273, 144,  95,  85] -> [273, 146,  95,  85] w/ P(a|s)=0.08950084447860718 and iou=0.7333704425271361 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for 2X DOWN:bbox transition: [273, 146,  95,  85] -> [273, 150,  95,  85] w/ P(a|s)=0.06826651841402054 and iou=0.7333704425271361 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.       2.684336]\n",
            "\u001b[92m>> Total frame loss: 2.684335947036743\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1772 with src: [273, 150,  95,  85] and target: [279, 139,  96, 102]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1773.jpg\n",
            "|->> Beginning tracking for bbox:[273 150  95  85]\n",
            "|->> Revisiting bbox: [273 150  95  85]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=11-th Action selection: 8/STOP (P(a|s) = 0.42500001192092896)\u001b[0m\n",
            "      |->> Bounding box moves to: [273 150  95  85]\n",
            "         |->> Action Probabilities (Rounded): [0.0527 0.0381 0.0777 0.0654 0.0656 0.0429 0.0745 0.0573 0.425  0.0437\n",
            " 0.057 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05270036 0.0381113  0.07772398 0.06539593 0.06560437 0.04294021\n",
            " 0.07446657 0.05731161 0.42500857 0.04370616 0.0570309 ], argmax=8\n",
            "         |->> Hit a STOP on the 11-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [273, 150,  95,  85] -> [273, 150,  95,  85] (Target was [279, 139,  96, 102])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [273, 150,  95,  85] -> [273, 150,  95,  85] w/ P(a|s)=0.4250085651874542 and iou=0.7343234323432343 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.85564595]\n",
            "\u001b[92m>> Total frame loss: 0.8556459546089172\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1773 with src: [273, 150,  95,  85] and target: [279, 140,  97,  99]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1774.jpg\n",
            "|->> Beginning tracking for bbox:[273 150  95  85]\n",
            "|->> Revisiting bbox: [273 150  95  85]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=11-th Action selection: 8/STOP (P(a|s) = 0.38999998569488525)\u001b[0m\n",
            "      |->> Bounding box moves to: [273 150  95  85]\n",
            "         |->> Action Probabilities (Rounded): [0.0554 0.0419 0.0814 0.0683 0.0673 0.0489 0.078  0.0617 0.3899 0.0454\n",
            " 0.0617], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05540816 0.04187868 0.0813818  0.06831482 0.0673273  0.04892521\n",
            " 0.07803536 0.06174557 0.38985187 0.04541482 0.06171635], argmax=8\n",
            "         |->> Hit a STOP on the 11-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [273, 150,  95,  85] -> [273, 150,  95,  85] (Target was [279, 140,  97,  99])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [273, 150,  95,  85] -> [273, 150,  95,  85] w/ P(a|s)=0.3898518681526184 and iou=0.7480470681301296 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.94198847]\n",
            "\u001b[92m>> Total frame loss: 0.941988468170166\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1774 with src: [273, 150,  95,  85] and target: [280, 139,  99,  93]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1775.jpg\n",
            "|->> Beginning tracking for bbox:[273 150  95  85]\n",
            "   \u001b[33m|->> #0/t=11-th Action selection: 3/2X RIGHT (P(a|s) = 0.06300000101327896)\u001b[0m\n",
            "      |->> Bounding box moves to: [277 150  95  85]\n",
            "         |->> Action Probabilities (Rounded): [0.0571 0.0433 0.0713 0.0633 0.0667 0.0553 0.0845 0.0644 0.387  0.0459\n",
            " 0.0611], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05707919 0.04328463 0.07133675 0.06332786 0.06674688 0.05531907\n",
            " 0.08445168 0.06442472 0.38696074 0.04592196 0.06114656], argmax=8\n",
            "   \u001b[33m|->> #1/t=12-th Action selection: 4/UP (P(a|s) = 0.061000000685453415)\u001b[0m\n",
            "      |->> Bounding box moves to: [277 148  95  85]\n",
            "         |->> Action Probabilities (Rounded): [0.0562 0.0474 0.061  0.0517 0.0611 0.0478 0.0735 0.0609 0.4378 0.0431\n",
            " 0.0596], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0561817  0.04742729 0.06096906 0.05168046 0.06107947 0.04776844\n",
            " 0.07354407 0.06086413 0.43781134 0.0430637  0.05961038], argmax=8\n",
            "   \u001b[33m|->> #2/t=13-th Action selection: 4/UP (P(a|s) = 0.05900000035762787)\u001b[0m\n",
            "      |->> Bounding box moves to: [277 146  95  85]\n",
            "         |->> Action Probabilities (Rounded): [0.0591 0.0425 0.0574 0.0521 0.0588 0.0421 0.072  0.0613 0.4612 0.0383\n",
            " 0.0552], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05905598 0.04253826 0.05738282 0.05214958 0.05877864 0.04212058\n",
            " 0.07204859 0.06129676 0.46117362 0.03829212 0.05516305], argmax=8\n",
            "   \u001b[33m|->> #3/t=14-th Action selection: 4/UP (P(a|s) = 0.05999999865889549)\u001b[0m\n",
            "      |->> Bounding box moves to: [277 144  95  85]\n",
            "         |->> Action Probabilities (Rounded): [0.0552 0.0415 0.0642 0.0532 0.0602 0.0419 0.0675 0.0582 0.4648 0.0403\n",
            " 0.0529], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05524576 0.04152763 0.06415986 0.05316454 0.06020264 0.0419177\n",
            " 0.06753622 0.05815586 0.46482164 0.04034027 0.05292789], argmax=8\n",
            "|->> Revisiting bbox: [277 144  95  85]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [273, 150,  95,  85] -> [277, 144,  95,  85] (Target was [280, 139,  99,  93])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.058) for 2X RIGHT:bbox transition: [273, 150,  95,  85] -> [277, 150,  95,  85] w/ P(a|s)=0.063327856361866 and iou=0.7746970630519614 and reward=0.057828396252835645 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.034) for UP:bbox transition: [277, 150,  95,  85] -> [277, 148,  95,  85] w/ P(a|s)=0.061079468578100204 and iou=0.8088758635126648 and reward=0.03417880046070343 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.018) for UP:bbox transition: [277, 148,  95,  85] -> [277, 146,  95,  85] w/ P(a|s)=0.058778636157512665 and iou=0.8264637497357853 and reward=0.017587886223120464 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (1.0) for UP:bbox transition: [277, 146,  95,  85] -> [277, 144,  95,  85] w/ P(a|s)=0.060202643275260925 and iou=0.8264637497357853 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.1595734  0.09554955 0.04984366 2.810039  ]\n",
            "\u001b[92m>> Total frame loss: 3.1150054931640625\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1775 with src: [277, 144,  95,  85] and target: [280, 137,  97,  99]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1776.jpg\n",
            "|->> Beginning tracking for bbox:[277 144  95  85]\n",
            "|->> Revisiting bbox: [277 144  95  85]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=15-th Action selection: 8/STOP (P(a|s) = 0.45399999618530273)\u001b[0m\n",
            "      |->> Bounding box moves to: [277 144  95  85]\n",
            "         |->> Action Probabilities (Rounded): [0.054  0.047  0.0647 0.0519 0.0565 0.0409 0.0734 0.0601 0.4544 0.0415\n",
            " 0.0556], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05400633 0.04698771 0.06470884 0.05185294 0.05645609 0.04091979\n",
            " 0.07339602 0.06010517 0.45441788 0.04153837 0.05561087], argmax=8\n",
            "         |->> Hit a STOP on the 15-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [277, 144,  95,  85] -> [277, 144,  95,  85] (Target was [280, 137,  97,  99])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [277, 144,  95,  85] -> [277, 144,  95,  85] w/ P(a|s)=0.454417884349823 and iou=0.7932643538243052 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.7887381]\n",
            "\u001b[92m>> Total frame loss: 0.7887380719184875\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1776 with src: [277, 144,  95,  85] and target: [278, 137,  96, 104]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1777.jpg\n",
            "|->> Beginning tracking for bbox:[277 144  95  85]\n",
            "   \u001b[33m|->> #0/t=15-th Action selection: 2/RIGHT (P(a|s) = 0.0689999982714653)\u001b[0m\n",
            "      |->> Bounding box moves to: [279 144  95  85]\n",
            "         |->> Action Probabilities (Rounded): [0.0576 0.0489 0.069  0.0554 0.0604 0.0465 0.0764 0.0624 0.4198 0.0426\n",
            " 0.061 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05756488 0.04890585 0.06895708 0.05541376 0.06043128 0.04652237\n",
            " 0.07640367 0.06240594 0.41976866 0.04263666 0.06098979], argmax=8\n",
            "   \u001b[33m|->> #1/t=16-th Action selection: 10/SCALE UP (P(a|s) = 0.05900000035762787)\u001b[0m\n",
            "      |->> Bounding box moves to: [277 142  97  87]\n",
            "         |->> Action Probabilities (Rounded): [0.0614 0.0485 0.0577 0.0528 0.0621 0.046  0.0764 0.0621 0.4316 0.0424\n",
            " 0.059 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06136822 0.04852521 0.05773952 0.05278831 0.06213354 0.04597905\n",
            " 0.07637277 0.06209426 0.4315993  0.0424138  0.05898599], argmax=8\n",
            "   \u001b[33m|->> #2/t=17-th Action selection: 3/2X RIGHT (P(a|s) = 0.04899999871850014)\u001b[0m\n",
            "      |->> Bounding box moves to: [281 142  97  87]\n",
            "         |->> Action Probabilities (Rounded): [0.0544 0.0461 0.0629 0.0493 0.0574 0.0437 0.0723 0.0624 0.4575 0.0417\n",
            " 0.0523], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0544483  0.04606766 0.06285115 0.04928989 0.05741824 0.04369952\n",
            " 0.07234255 0.06235732 0.45747045 0.04173847 0.05231641], argmax=8\n",
            "|->> Revisiting bbox: [281 142  97  87]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [277, 144,  95,  85] -> [281, 142,  97,  87] (Target was [278, 137,  96, 104])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.015) for RIGHT:bbox transition: [277, 144,  95,  85] -> [279, 144,  95,  85] w/ P(a|s)=0.06895708292722702 and iou=0.8087940705128205 and reward=0.015269390802819527 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.021) for SCALE UP:bbox transition: [279, 144,  95,  85] -> [277, 142,  97,  87] w/ P(a|s)=0.058985985815525055 and iou=0.8293118856121537 and reward=0.02051781509933326 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (1.0) for 2X RIGHT:bbox transition: [277, 142,  97,  87] -> [281, 142,  97,  87] w/ P(a|s)=0.04928989335894585 and iou=0.7831010452961672 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.04083449 0.05807476 3.0100362 ]\n",
            "\u001b[92m>> Total frame loss: 3.108945369720459\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1777 with src: [281, 142,  97,  87] and target: [274, 134, 102, 101]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1778.jpg\n",
            "|->> Beginning tracking for bbox:[281 142  97  87]\n",
            "   \u001b[33m|->> #0/t=18-th Action selection: 4/UP (P(a|s) = 0.06300000101327896)\u001b[0m\n",
            "      |->> Bounding box moves to: [281 140  97  87]\n",
            "         |->> Action Probabilities (Rounded): [0.0658 0.0541 0.0576 0.0483 0.0625 0.0444 0.0855 0.0661 0.4139 0.0438\n",
            " 0.058 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06577542 0.05413514 0.0576411  0.0483043  0.06253158 0.04437423\n",
            " 0.08546503 0.0660635  0.41385347 0.04383277 0.05802349], argmax=8\n",
            "   \u001b[33m|->> #1/t=19-th Action selection: 3/2X RIGHT (P(a|s) = 0.04899999871850014)\u001b[0m\n",
            "      |->> Bounding box moves to: [285 140  97  87]\n",
            "         |->> Action Probabilities (Rounded): [0.0666 0.052  0.0604 0.0495 0.0589 0.0425 0.0829 0.0651 0.4239 0.0428\n",
            " 0.0555], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06655794 0.05197033 0.06042618 0.04946336 0.05893814 0.04246321\n",
            " 0.08290858 0.06506155 0.42390278 0.04279609 0.05551181], argmax=8\n",
            "   \u001b[33m|->> #2/t=20-th Action selection: 6/DOWN (P(a|s) = 0.08399999886751175)\u001b[0m\n",
            "      |->> Bounding box moves to: [285 142  97  87]\n",
            "         |->> Action Probabilities (Rounded): [0.0675 0.0558 0.0593 0.0475 0.0639 0.0412 0.0837 0.0654 0.4134 0.0434\n",
            " 0.0589], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06750338 0.05580101 0.05932878 0.04745487 0.0638976  0.04115944\n",
            " 0.08368857 0.06539522 0.41343924 0.04341774 0.05891417], argmax=8\n",
            "|->> Revisiting bbox: [285 140  97  87]. ACtion 4 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [281, 142,  97,  87] -> [285, 142,  97,  87] (Target was [274, 134, 102, 101])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for UP:bbox transition: [281, 142,  97,  87] -> [281, 140,  97,  87] w/ P(a|s)=0.06253157556056976 and iou=0.7889461626575028 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.058) for 2X RIGHT:bbox transition: [281, 140,  97,  87] -> [285, 140,  97,  87] w/ P(a|s)=0.04946335777640343 and iou=0.731430155210643 and reward=-0.05751600744685981 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (1.0) for DOWN:bbox transition: [285, 140,  97,  87] -> [285, 142,  97,  87] w/ P(a|s)=0.08368857204914093 and iou=0.731430155210643 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.        -0.1729232  2.4806528]\n",
            "\u001b[92m>> Total frame loss: 2.307729721069336\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1778 with src: [285, 142,  97,  87] and target: [274, 133, 107, 103]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1779.jpg\n",
            "|->> Beginning tracking for bbox:[285 142  97  87]\n",
            "   \u001b[33m|->> #0/t=21-th Action selection: 4/UP (P(a|s) = 0.06400000303983688)\u001b[0m\n",
            "      |->> Bounding box moves to: [285 140  97  87]\n",
            "         |->> Action Probabilities (Rounded): [0.0613 0.0534 0.0592 0.0522 0.0639 0.0425 0.0753 0.0617 0.4268 0.0443\n",
            " 0.0593], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06130385 0.05343293 0.05917943 0.0522043  0.06392378 0.04249663\n",
            " 0.07531105 0.06172935 0.42684096 0.04428154 0.05929621], argmax=8\n",
            "   \u001b[33m|->> #1/t=22-th Action selection: 9/SCALE DOWN (P(a|s) = 0.041999999433755875)\u001b[0m\n",
            "      |->> Bounding box moves to: [286 141  94  84]\n",
            "         |->> Action Probabilities (Rounded): [0.06   0.0486 0.0678 0.0484 0.0615 0.0452 0.0787 0.0636 0.4296 0.0419\n",
            " 0.0547], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05999969 0.04855801 0.06784926 0.04839804 0.06145484 0.04517949\n",
            " 0.07868996 0.06363837 0.42958912 0.04193138 0.05471189], argmax=8\n",
            "|->> Revisiting bbox: [286 141  94  84]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [285, 142,  97,  87] -> [286, 141,  94,  84] (Target was [274, 133, 107, 103])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for UP:bbox transition: [285, 142,  97,  87] -> [285, 140,  97,  87] w/ P(a|s)=0.06392377614974976 and iou=0.7518905293482175 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for SCALE DOWN:bbox transition: [285, 140,  97,  87] -> [286, 141,  94,  84] w/ P(a|s)=0.041931383311748505 and iou=0.7164504128481989 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.        3.1717207]\n",
            "\u001b[92m>> Total frame loss: 3.1717207431793213\u001b[0m\n",
            "Final bounding box: [286 141  94  84] reached in 23 timesteps (originating from [281 150  95  85]). Target was [274 133 107 103]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 1779 in t=23 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[92m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 8.391921043395996\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 2.240407943725586\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/Rubik\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Starting bounding box=adnet_datasets/OTB/Rubik/img/1780.jpg for adnet_datasets/OTB/Rubik's frames (index: 0)\n",
            "src:adnet_datasets/OTB/Rubik/img/1770.jpg\n",
            "target:adnet_datasets/OTB/Rubik/img/1780.jpg.\n",
            "\u001b[34m>> Attempting to reach frame 1770 with src: [281, 145,  95,  91] and target: [276, 140, 107,  97]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1771.jpg\n",
            "|->> Beginning tracking for bbox:[281 145  95  91]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 5/2X UP (P(a|s) = 0.0820000022649765)\u001b[0m\n",
            "      |->> Bounding box moves to: [281 141  95  91]\n",
            "         |->> Action Probabilities (Rounded): [0.0885 0.0811 0.0936 0.0878 0.0915 0.0821 0.0957 0.0877 0.1201 0.0821\n",
            " 0.0897], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08852547 0.08107441 0.09363311 0.08778323 0.09150121 0.08214129\n",
            " 0.09572238 0.08769191 0.12012682 0.08214095 0.08965917], argmax=8\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 3/2X RIGHT (P(a|s) = 0.08399999886751175)\u001b[0m\n",
            "      |->> Bounding box moves to: [285 141  95  91]\n",
            "         |->> Action Probabilities (Rounded): [0.0862 0.0777 0.0927 0.0835 0.088  0.0722 0.0977 0.0947 0.1425 0.0772\n",
            " 0.0876], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0861747  0.07772888 0.092664   0.08350094 0.08801318 0.07222231\n",
            " 0.09767979 0.09468853 0.14253156 0.07721455 0.08758159], argmax=8\n",
            "   \u001b[33m|->> #2/t=3-th Action selection: 9/SCALE DOWN (P(a|s) = 0.07599999755620956)\u001b[0m\n",
            "      |->> Bounding box moves to: [286 142  92  88]\n",
            "         |->> Action Probabilities (Rounded): [0.0872 0.0822 0.088  0.0766 0.0859 0.0708 0.1024 0.0894 0.1553 0.0756\n",
            " 0.0866], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08717681 0.08216622 0.08799034 0.07663067 0.08591256 0.07082468\n",
            " 0.10236196 0.08939257 0.15533157 0.07556599 0.08664663], argmax=8\n",
            "   \u001b[33m|->> #3/t=4-th Action selection: 1/2X LEFT (P(a|s) = 0.07800000160932541)\u001b[0m\n",
            "      |->> Bounding box moves to: [282 142  92  88]\n",
            "         |->> Action Probabilities (Rounded): [0.0841 0.0782 0.0859 0.0773 0.0864 0.0656 0.0955 0.0908 0.1829 0.0671\n",
            " 0.0862], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08408798 0.07818023 0.0859079  0.07733513 0.08641391 0.065552\n",
            " 0.09554129 0.0908042  0.18290135 0.06711031 0.08616568], argmax=8\n",
            "   \u001b[33m|->> #4/t=5-th Action selection: 1/2X LEFT (P(a|s) = 0.06400000303983688)\u001b[0m\n",
            "      |->> Bounding box moves to: [278 142  92  88]\n",
            "         |->> Action Probabilities (Rounded): [0.0784 0.0643 0.0927 0.0816 0.0866 0.0631 0.0997 0.0881 0.1988 0.0628\n",
            " 0.084 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07839606 0.06430275 0.09265102 0.08161785 0.0865762  0.06311271\n",
            " 0.09974274 0.08807602 0.19876464 0.06275205 0.08400797], argmax=8\n",
            "|->> Revisiting bbox: [278 142  92  88]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [281, 145,  95,  91] -> [278, 142,  92,  88] (Target was [276, 140, 107,  97])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X UP:bbox transition: [281, 145,  95,  91] -> [281, 141,  95,  91] w/ P(a|s)=0.08214128762483597 and iou=0.83293188168417 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for 2X RIGHT:bbox transition: [281, 141,  95,  91] -> [285, 141,  95,  91] w/ P(a|s)=0.0835009440779686 and iou=0.83293188168417 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.053) for SCALE DOWN:bbox transition: [285, 141,  95,  91] -> [286, 142,  92,  88] w/ P(a|s)=0.07556599378585815 and iou=0.7800366123904037 and reward=-0.05289526929376631 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.0) for 2X LEFT:bbox transition: [286, 142,  92,  88] -> [282, 142,  92,  88] w/ P(a|s)=0.078180231153965 and iou=0.7800366123904037 and reward=0.0 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (1.0) for 2X LEFT:bbox transition: [282, 142,  92,  88] -> [278, 142,  92,  88] w/ P(a|s)=0.06430274993181229 and iou=0.7800366123904037 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.         0.        -0.1366152  0.         2.7441528]\n",
            "\u001b[92m>> Total frame loss: 2.6075375080108643\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1771 with src: [278, 142,  92,  88] and target: [275, 133, 103, 103]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1772.jpg\n",
            "|->> Beginning tracking for bbox:[278 142  92  88]\n",
            "|->> Revisiting bbox: [278 142  92  88]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=6-th Action selection: 8/STOP (P(a|s) = 0.23899999260902405)\u001b[0m\n",
            "      |->> Bounding box moves to: [278 142  92  88]\n",
            "         |->> Action Probabilities (Rounded): [0.0695 0.0564 0.0896 0.086  0.0808 0.0603 0.0956 0.0828 0.2395 0.0601\n",
            " 0.0794], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06947546 0.05640919 0.08961796 0.08596403 0.08078309 0.06031227\n",
            " 0.09560838 0.08283194 0.23948255 0.06010401 0.07941108], argmax=8\n",
            "         |->> Hit a STOP on the 6-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [278, 142,  92,  88] -> [278, 142,  92,  88] (Target was [275, 133, 103, 103])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [278, 142,  92,  88] -> [278, 142,  92,  88] w/ P(a|s)=0.2394825518131256 and iou=0.7631256480346875 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [1.4292747]\n",
            "\u001b[92m>> Total frame loss: 1.4292746782302856\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1772 with src: [278, 142,  92,  88] and target: [279, 139,  96, 102]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1773.jpg\n",
            "|->> Beginning tracking for bbox:[278 142  92  88]\n",
            "   \u001b[33m|->> #0/t=6-th Action selection: 7/2X DOWN (P(a|s) = 0.07900000363588333)\u001b[0m\n",
            "      |->> Bounding box moves to: [278 146  92  88]\n",
            "         |->> Action Probabilities (Rounded): [0.0696 0.0543 0.0932 0.0826 0.0816 0.0575 0.0969 0.0794 0.2442 0.0595\n",
            " 0.0811], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06959381 0.05432663 0.09323446 0.08258307 0.08159719 0.05748115\n",
            " 0.09685999 0.07943048 0.24422693 0.05952619 0.08114012], argmax=8\n",
            "   \u001b[33m|->> #1/t=7-th Action selection: 3/2X RIGHT (P(a|s) = 0.07800000160932541)\u001b[0m\n",
            "      |->> Bounding box moves to: [282 146  92  88]\n",
            "         |->> Action Probabilities (Rounded): [0.0633 0.0518 0.0856 0.0779 0.0742 0.0585 0.0869 0.0722 0.3048 0.0539\n",
            " 0.0708], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06329756 0.05179754 0.08563942 0.07792278 0.07424655 0.0585094\n",
            " 0.08693767 0.0721509  0.30481616 0.05391571 0.07076634], argmax=8\n",
            "   \u001b[33m|->> #2/t=8-th Action selection: 7/2X DOWN (P(a|s) = 0.06300000101327896)\u001b[0m\n",
            "      |->> Bounding box moves to: [282 150  92  88]\n",
            "         |->> Action Probabilities (Rounded): [0.0662 0.0544 0.073  0.0606 0.0698 0.0573 0.0789 0.0631 0.3553 0.0512\n",
            " 0.0702], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06619643 0.05441603 0.07296    0.06055208 0.06984973 0.05733016\n",
            " 0.07885146 0.06314951 0.3553175  0.05119912 0.07017797], argmax=8\n",
            "   \u001b[33m|->> #3/t=9-th Action selection: 7/2X DOWN (P(a|s) = 0.054999999701976776)\u001b[0m\n",
            "      |->> Bounding box moves to: [282 154  92  88]\n",
            "         |->> Action Probabilities (Rounded): [0.0577 0.0467 0.0665 0.0598 0.0717 0.0533 0.0741 0.0551 0.4023 0.0476\n",
            " 0.065 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05765183 0.04674273 0.06652617 0.05982484 0.07173725 0.05334648\n",
            " 0.0740886  0.0551296  0.4023452  0.04759441 0.06501288], argmax=8\n",
            "|->> Revisiting bbox: [282 154  92  88]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [278, 142,  92,  88] -> [282, 154,  92,  88] (Target was [279, 139,  96, 102])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X DOWN:bbox transition: [278, 142,  92,  88] -> [278, 146,  92,  88] w/ P(a|s)=0.0794304758310318 and iou=0.8105263157894737 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.016) for 2X RIGHT:bbox transition: [278, 146,  92,  88] -> [282, 146,  92,  88] w/ P(a|s)=0.07792278379201889 and iou=0.826797385620915 and reward=0.01627106983144133 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X DOWN:bbox transition: [282, 146,  92,  88] -> [282, 150,  92,  88] w/ P(a|s)=0.06314951181411743 and iou=0.826797385620915 and reward=0.0 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (1.0) for 2X DOWN:bbox transition: [282, 150,  92,  88] -> [282, 154,  92,  88] w/ P(a|s)=0.055129602551460266 and iou=0.8097936058276002 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.         0.04152437 0.         2.8980684 ]\n",
            "\u001b[92m>> Total frame loss: 2.9395928382873535\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1773 with src: [282, 154,  92,  88] and target: [279, 140,  97,  99]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1774.jpg\n",
            "|->> Beginning tracking for bbox:[282 154  92  88]\n",
            "|->> Revisiting bbox: [282 154  92  88]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=10-th Action selection: 8/STOP (P(a|s) = 0.4390000104904175)\u001b[0m\n",
            "      |->> Bounding box moves to: [282 154  92  88]\n",
            "         |->> Action Probabilities (Rounded): [0.0555 0.0402 0.0688 0.0551 0.0716 0.0543 0.0653 0.0464 0.4394 0.0441\n",
            " 0.0594], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0554981  0.04020264 0.0688151  0.05510561 0.07158365 0.05429934\n",
            " 0.06528501 0.04643235 0.43935013 0.04407235 0.0593557 ], argmax=8\n",
            "         |->> Hit a STOP on the 10-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [282, 154,  92,  88] -> [282, 154,  92,  88] (Target was [279, 140,  97,  99])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [282, 154,  92,  88] -> [282, 154,  92,  88] w/ P(a|s)=0.4393501281738281 and iou=0.7915780949488814 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.8224586]\n",
            "\u001b[92m>> Total frame loss: 0.8224586248397827\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1774 with src: [282, 154,  92,  88] and target: [280, 139,  99,  93]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1775.jpg\n",
            "|->> Beginning tracking for bbox:[282 154  92  88]\n",
            "   \u001b[33m|->> #0/t=10-th Action selection: 10/SCALE UP (P(a|s) = 0.06700000166893005)\u001b[0m\n",
            "      |->> Bounding box moves to: [280 152  94  90]\n",
            "         |->> Action Probabilities (Rounded): [0.0572 0.0476 0.0696 0.0621 0.0737 0.0629 0.0712 0.0491 0.3955 0.0436\n",
            " 0.0673], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0572382  0.04762401 0.06962062 0.06214485 0.07368517 0.06290548\n",
            " 0.07116352 0.04913578 0.39551958 0.0436154  0.06734736], argmax=8\n",
            "|->> Revisiting bbox: [280 152  94  90]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [282, 154,  92,  88] -> [280, 152,  94,  90] (Target was [280, 139,  99,  93])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for SCALE UP:bbox transition: [282, 154,  92,  88] -> [280, 152,  94,  90] w/ P(a|s)=0.06734735518693924 and iou=0.7411057455405539 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [2.6978917]\n",
            "\u001b[92m>> Total frame loss: 2.6978917121887207\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1775 with src: [280, 152,  94,  90] and target: [280, 137,  97,  99]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1776.jpg\n",
            "|->> Beginning tracking for bbox:[280 152  94  90]\n",
            "   \u001b[33m|->> #0/t=11-th Action selection: 6/DOWN (P(a|s) = 0.0689999982714653)\u001b[0m\n",
            "      |->> Bounding box moves to: [280 154  94  90]\n",
            "         |->> Action Probabilities (Rounded): [0.0492 0.0399 0.0642 0.0589 0.0743 0.0585 0.0689 0.0466 0.4434 0.0416\n",
            " 0.0545], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.04921966 0.03988794 0.06416678 0.05889608 0.07432222 0.05851092\n",
            " 0.06891051 0.04658524 0.44338217 0.04160267 0.0545159 ], argmax=8\n",
            "   \u001b[33m|->> #1/t=12-th Action selection: 10/SCALE UP (P(a|s) = 0.05299999937415123)\u001b[0m\n",
            "      |->> Bounding box moves to: [278 152  96  92]\n",
            "         |->> Action Probabilities (Rounded): [0.0504 0.0396 0.0694 0.0554 0.0678 0.053  0.0651 0.0489 0.4541 0.0438\n",
            " 0.0526], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05043399 0.03957689 0.06940113 0.05541548 0.0677712  0.05295574\n",
            " 0.06506222 0.04889314 0.45408475 0.0437687  0.05263674], argmax=8\n",
            "|->> Revisiting bbox: [278 152  96  92]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [280, 152,  94,  90] -> [278, 152,  96,  92] (Target was [280, 137,  97,  99])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.032) for DOWN:bbox transition: [280, 152,  94,  90] -> [280, 154,  94,  90] w/ P(a|s)=0.06891050934791565 and iou=0.7443746982134235 and reward=-0.0322555762038087 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for SCALE UP:bbox transition: [280, 154,  94,  90] -> [278, 152,  96,  92] w/ P(a|s)=0.05263673514127731 and iou=0.7492171932820951 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.08628194  2.944341  ]\n",
            "\u001b[92m>> Total frame loss: 2.8580589294433594\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1776 with src: [278, 152,  96,  92] and target: [278, 137,  96, 104]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1777.jpg\n",
            "|->> Beginning tracking for bbox:[278 152  96  92]\n",
            "|->> Revisiting bbox: [278 152  96  92]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=13-th Action selection: 8/STOP (P(a|s) = 0.4490000009536743)\u001b[0m\n",
            "      |->> Bounding box moves to: [278 152  96  92]\n",
            "         |->> Action Probabilities (Rounded): [0.0548 0.0408 0.0621 0.0568 0.0655 0.0558 0.0653 0.0476 0.4488 0.0464\n",
            " 0.0561], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05476717 0.0407621  0.06209443 0.05683754 0.06551097 0.05582189\n",
            " 0.06529734 0.04762367 0.44877407 0.04643638 0.05607441], argmax=8\n",
            "         |->> Hit a STOP on the 13-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [278, 152,  96,  92] -> [278, 152,  96,  92] (Target was [278, 137,  96, 104])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [278, 152,  96,  92] -> [278, 152,  96,  92] w/ P(a|s)=0.4487740695476532 and iou=0.8317757009345794 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.8012357]\n",
            "\u001b[92m>> Total frame loss: 0.8012356758117676\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1777 with src: [278, 152,  96,  92] and target: [274, 134, 102, 101]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1778.jpg\n",
            "|->> Beginning tracking for bbox:[278 152  96  92]\n",
            "   \u001b[33m|->> #0/t=13-th Action selection: 5/2X UP (P(a|s) = 0.05700000002980232)\u001b[0m\n",
            "      |->> Bounding box moves to: [278 148  96  92]\n",
            "         |->> Action Probabilities (Rounded): [0.0608 0.0471 0.0752 0.0541 0.0754 0.0569 0.0719 0.0504 0.3965 0.0487\n",
            " 0.0631], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06078092 0.04705477 0.07518623 0.05407634 0.07541309 0.05691655\n",
            " 0.07193423 0.05035442 0.39648405 0.04868181 0.06311762], argmax=8\n",
            "   \u001b[33m|->> #1/t=14-th Action selection: 4/UP (P(a|s) = 0.061000000685453415)\u001b[0m\n",
            "      |->> Bounding box moves to: [278 146  96  92]\n",
            "         |->> Action Probabilities (Rounded): [0.0542 0.0437 0.0634 0.0535 0.0614 0.0464 0.0673 0.0534 0.4556 0.0444\n",
            " 0.0566], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05421529 0.04373774 0.06336704 0.05347922 0.06141271 0.04636219\n",
            " 0.06734227 0.05343639 0.45561162 0.04439889 0.05663667], argmax=8\n",
            "|->> Revisiting bbox: [278 146  96  92]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [278, 152,  96,  92] -> [278, 146,  96,  92] (Target was [274, 134, 102, 101])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.061) for 2X UP:bbox transition: [278, 152,  96,  92] -> [278, 148,  96,  92] w/ P(a|s)=0.056916553527116776 and iou=0.7746243739565943 and reward=0.06102953247352072 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for UP:bbox transition: [278, 148,  96,  92] -> [278, 146,  96,  92] w/ P(a|s)=0.061412710696458817 and iou=0.806798866855524 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.17492095 2.7901385 ]\n",
            "\u001b[92m>> Total frame loss: 2.965059518814087\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1778 with src: [278, 146,  96,  92] and target: [274, 133, 107, 103]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1779.jpg\n",
            "|->> Beginning tracking for bbox:[278 146  96  92]\n",
            "   \u001b[33m|->> #0/t=15-th Action selection: 5/2X UP (P(a|s) = 0.04699999839067459)\u001b[0m\n",
            "      |->> Bounding box moves to: [278 142  96  92]\n",
            "         |->> Action Probabilities (Rounded): [0.0523 0.0445 0.0662 0.0567 0.063  0.0472 0.0724 0.0604 0.4384 0.0425\n",
            " 0.0562], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05230984 0.04454565 0.0662353  0.05671384 0.06303696 0.04718655\n",
            " 0.07243501 0.06044658 0.43843296 0.04249079 0.05616654], argmax=8\n",
            "   \u001b[33m|->> #1/t=16-th Action selection: 2/RIGHT (P(a|s) = 0.06199999898672104)\u001b[0m\n",
            "      |->> Bounding box moves to: [280 142  96  92]\n",
            "         |->> Action Probabilities (Rounded): [0.0502 0.0417 0.0623 0.0526 0.0554 0.0366 0.0661 0.0608 0.4849 0.0398\n",
            " 0.0495], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05020006 0.04171106 0.06226772 0.05258559 0.05540582 0.03661783\n",
            " 0.06609719 0.06081476 0.48493576 0.03983847 0.0495257 ], argmax=8\n",
            "   \u001b[33m|->> #2/t=17-th Action selection: 6/DOWN (P(a|s) = 0.07900000363588333)\u001b[0m\n",
            "      |->> Bounding box moves to: [280 144  96  92]\n",
            "         |->> Action Probabilities (Rounded): [0.0588 0.0417 0.0636 0.0556 0.0564 0.0393 0.0791 0.0666 0.4428 0.0407\n",
            " 0.0555], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05877043 0.04174839 0.06363552 0.05564557 0.05638397 0.0392736\n",
            " 0.07906596 0.06656024 0.44277707 0.04067483 0.05546436], argmax=8\n",
            "   \u001b[33m|->> #3/t=18-th Action selection: 10/SCALE UP (P(a|s) = 0.052000001072883606)\u001b[0m\n",
            "      |->> Bounding box moves to: [278 142  98  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0542 0.0446 0.0656 0.0538 0.0645 0.0406 0.0761 0.0679 0.4373 0.0434\n",
            " 0.0519], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05415063 0.04463299 0.06556747 0.05384931 0.06451923 0.04063279\n",
            " 0.07605869 0.06793075 0.43732792 0.04338338 0.05194687], argmax=8\n",
            "   \u001b[33m|->> #4/t=19-th Action selection: 10/SCALE UP (P(a|s) = 0.05400000140070915)\u001b[0m\n",
            "      |->> Bounding box moves to: [276 140 100  96]\n",
            "         |->> Action Probabilities (Rounded): [0.0597 0.0415 0.0639 0.0596 0.0652 0.043  0.0782 0.0676 0.4206 0.0472\n",
            " 0.0536], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05974099 0.04153521 0.06386988 0.0595895  0.06517213 0.04295115\n",
            " 0.07818539 0.06759448 0.42059422 0.04717374 0.05359328], argmax=8\n",
            "   \u001b[33m|->> #5/t=20-th Action selection: 9/SCALE DOWN (P(a|s) = 0.04500000178813934)\u001b[0m\n",
            "      |->> Bounding box moves to: [277 141  97  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0558 0.047  0.0715 0.0568 0.0623 0.0419 0.0867 0.0682 0.4126 0.0453\n",
            " 0.0519], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05580545 0.04702789 0.07145804 0.05680634 0.06225784 0.04192808\n",
            " 0.08667731 0.06820524 0.41262084 0.04527942 0.05193358], argmax=8\n",
            "|->> Revisiting bbox: [277 141  97  93]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [278, 146,  96,  92] -> [277, 141,  97,  93] (Target was [274, 133, 107, 103])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.031) for 2X UP:bbox transition: [278, 146,  96,  92] -> [278, 142,  96,  92] w/ P(a|s)=0.04718654602766037 and iou=0.8013791851919063 and reward=0.030844983818500427 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for RIGHT:bbox transition: [278, 142,  96,  92] -> [280, 142,  96,  92] w/ P(a|s)=0.0622677244246006 and iou=0.8013791851919063 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.0) for DOWN:bbox transition: [280, 142,  96,  92] -> [280, 144,  96,  92] w/ P(a|s)=0.0790659561753273 and iou=0.8013791851919063 and reward=0.0 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.034) for SCALE UP:bbox transition: [280, 144,  96,  92] -> [278, 142,  98,  94] w/ P(a|s)=0.05194687098264694 and iou=0.8358588149895654 and reward=0.03447962979765906 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (0.035) for SCALE UP:bbox transition: [278, 142,  98,  94] -> [276, 140, 100,  96] w/ P(a|s)=0.05359327793121338 and iou=0.871064331730333 and reward=0.03520551674076766 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (1.0) for SCALE DOWN:bbox transition: [276, 140, 100,  96] -> [277, 141,  97,  93] w/ P(a|s)=0.04527942091226578 and iou=0.8185282642228473 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.09418968 0.         0.         0.10197467 0.10302301 3.0949025 ]\n",
            "\u001b[92m>> Total frame loss: 3.394089937210083\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1779 with src: [277, 141,  97,  93] and target: [276, 136, 105, 103]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1780.jpg\n",
            "|->> Beginning tracking for bbox:[277 141  97  93]\n",
            "   \u001b[33m|->> #0/t=21-th Action selection: 3/2X RIGHT (P(a|s) = 0.05999999865889549)\u001b[0m\n",
            "      |->> Bounding box moves to: [281 141  97  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0645 0.0466 0.0694 0.0596 0.065  0.0416 0.0862 0.0651 0.3995 0.0443\n",
            " 0.0582], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06446144 0.04664027 0.06941694 0.05955923 0.0649945  0.04157292\n",
            " 0.08618164 0.06514791 0.39948404 0.04433562 0.05820549], argmax=8\n",
            "   \u001b[33m|->> #1/t=22-th Action selection: 9/SCALE DOWN (P(a|s) = 0.04399999976158142)\u001b[0m\n",
            "      |->> Bounding box moves to: [282 142  94  90]\n",
            "         |->> Action Probabilities (Rounded): [0.0646 0.0519 0.0626 0.0535 0.062  0.0455 0.0843 0.0651 0.407  0.0437\n",
            " 0.0597], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06461615 0.05194611 0.06264107 0.05347794 0.06199437 0.04553017\n",
            " 0.08434301 0.06511881 0.40695488 0.04369102 0.05968649], argmax=8\n",
            "   \u001b[33m|->> #2/t=23-th Action selection: 7/2X DOWN (P(a|s) = 0.06400000303983688)\u001b[0m\n",
            "      |->> Bounding box moves to: [282 146  94  90]\n",
            "         |->> Action Probabilities (Rounded): [0.0596 0.0476 0.0623 0.0523 0.0643 0.0415 0.0796 0.0639 0.4326 0.0377\n",
            " 0.0586], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05960516 0.0475931  0.06228128 0.0523187  0.06425368 0.04151628\n",
            " 0.07964081 0.0639339  0.43257627 0.03772466 0.05855621], argmax=8\n",
            "|->> Revisiting bbox: [282 146  94  90]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [277, 141,  97,  93] -> [282, 146,  94,  90] (Target was [276, 136, 105, 103])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X RIGHT:bbox transition: [277, 141,  97,  93] -> [281, 141,  97,  93] w/ P(a|s)=0.059559233486652374 and iou=0.834119278779473 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.052) for SCALE DOWN:bbox transition: [281, 141,  97,  93] -> [282, 142,  94,  90] w/ P(a|s)=0.04369101673364639 and iou=0.782246879334258 and reward=-0.051872399445215045 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (1.0) for 2X DOWN:bbox transition: [282, 142,  94,  90] -> [282, 146,  94,  90] w/ P(a|s)=0.06393390148878098 and iou=0.782246879334258 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.        -0.1623924  2.7499056]\n",
            "\u001b[92m>> Total frame loss: 2.5875132083892822\u001b[0m\n",
            "Final bounding box: [282 146  94  90] reached in 24 timesteps (originating from [281 145  95  91]). Target was [276 136 105 103]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 1780 in t=24 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[92m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 8.651368141174316\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 2.7296221256256104\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/Rubik\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Starting bounding box=adnet_datasets/OTB/Rubik/img/1781.jpg for adnet_datasets/OTB/Rubik's frames (index: 0)\n",
            "src:adnet_datasets/OTB/Rubik/img/1771.jpg\n",
            "target:adnet_datasets/OTB/Rubik/img/1781.jpg.\n",
            "\u001b[34m>> Attempting to reach frame 1771 with src: [276, 140, 107,  97] and target: [275, 133, 103, 103]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1772.jpg\n",
            "|->> Beginning tracking for bbox:[276 140 107  97]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 9/SCALE DOWN (P(a|s) = 0.0820000022649765)\u001b[0m\n",
            "      |->> Bounding box moves to: [277 141 103  94]\n",
            "         |->> Action Probabilities (Rounded): [0.0885 0.0811 0.0936 0.0878 0.0915 0.0821 0.0957 0.0877 0.1201 0.0821\n",
            " 0.0897], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08852624 0.08107413 0.09362846 0.08778527 0.09150694 0.08213972\n",
            " 0.09572103 0.08769572 0.12012292 0.08214048 0.08965909], argmax=8\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 10/SCALE UP (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [275 139 106  96]\n",
            "         |->> Action Probabilities (Rounded): [0.0868 0.0785 0.0921 0.0887 0.0911 0.0781 0.0963 0.0875 0.138  0.0727\n",
            " 0.0903], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08680658 0.07850832 0.09208522 0.08865051 0.09107186 0.07813639\n",
            " 0.09631601 0.08745632 0.13796969 0.07267685 0.09032222], argmax=8\n",
            "   \u001b[33m|->> #2/t=3-th Action selection: 6/DOWN (P(a|s) = 0.09799999743700027)\u001b[0m\n",
            "      |->> Bounding box moves to: [275 141 106  96]\n",
            "         |->> Action Probabilities (Rounded): [0.0834 0.075  0.0936 0.0875 0.0917 0.076  0.0984 0.0863 0.1531 0.0733\n",
            " 0.0817], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08337952 0.07502261 0.09364276 0.08748292 0.09169318 0.07598351\n",
            " 0.09843806 0.08629411 0.1530876  0.07325824 0.08171757], argmax=8\n",
            "   \u001b[33m|->> #3/t=4-th Action selection: 6/DOWN (P(a|s) = 0.09700000286102295)\u001b[0m\n",
            "      |->> Bounding box moves to: [275 143 106  96]\n",
            "         |->> Action Probabilities (Rounded): [0.0816 0.0686 0.0929 0.083  0.0951 0.0738 0.0974 0.0825 0.1715 0.07\n",
            " 0.0836], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08159558 0.06864928 0.09285669 0.08297234 0.09513476 0.07382742\n",
            " 0.09737508 0.08249853 0.17149879 0.06998965 0.08360183], argmax=8\n",
            "|->> Revisiting bbox: [275 143 106  96]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [276, 140, 107,  97] -> [275, 143, 106,  96] (Target was [275, 133, 103, 103])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.005) for SCALE DOWN:bbox transition: [276, 140, 107,  97] -> [277, 141, 103,  94] w/ P(a|s)=0.0821404755115509 and iou=0.8793183291655089 and reward=0.004720258425959023 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.028) for SCALE UP:bbox transition: [277, 141, 103,  94] -> [275, 139, 106,  96] w/ P(a|s)=0.09032221883535385 and iou=0.9074057079930256 and reward=0.028087378827516662 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.018) for DOWN:bbox transition: [275, 139, 106,  96] -> [275, 141, 106,  96] w/ P(a|s)=0.09843806177377701 and iou=0.8895454545454545 and reward=-0.01786025344757103 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (1.0) for DOWN:bbox transition: [275, 141, 106,  96] -> [275, 143, 106,  96] w/ P(a|s)=0.09737507998943329 and iou=0.8548099232553988 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.01179746  0.0675325  -0.04140592  2.329185  ]\n",
            "\u001b[92m>> Total frame loss: 2.3671090602874756\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1772 with src: [275, 143, 106,  96] and target: [279, 139,  96, 102]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1773.jpg\n",
            "|->> Beginning tracking for bbox:[275 143 106  96]\n",
            "   \u001b[33m|->> #0/t=5-th Action selection: 5/2X UP (P(a|s) = 0.07400000095367432)\u001b[0m\n",
            "      |->> Bounding box moves to: [275 139 106  96]\n",
            "         |->> Action Probabilities (Rounded): [0.0812 0.0649 0.0901 0.0807 0.0944 0.0736 0.0912 0.0746 0.1956 0.0682\n",
            " 0.0856], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08117073 0.06491352 0.09010288 0.08070736 0.09437174 0.07355271\n",
            " 0.0911537  0.07456553 0.1956292  0.06822532 0.08560737], argmax=8\n",
            "   \u001b[33m|->> #1/t=6-th Action selection: 0/LEFT (P(a|s) = 0.07699999958276749)\u001b[0m\n",
            "      |->> Bounding box moves to: [272 139 106  96]\n",
            "         |->> Action Probabilities (Rounded): [0.0772 0.0623 0.0916 0.0773 0.0851 0.0632 0.0901 0.0813 0.2273 0.0621\n",
            " 0.0826], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07721601 0.06229253 0.09157225 0.07731883 0.08507285 0.06316438\n",
            " 0.09008182 0.08131106 0.22734247 0.06207685 0.082551  ], argmax=8\n",
            "   \u001b[33m|->> #2/t=7-th Action selection: 5/2X UP (P(a|s) = 0.06400000303983688)\u001b[0m\n",
            "      |->> Bounding box moves to: [272 135 106  96]\n",
            "         |->> Action Probabilities (Rounded): [0.0663 0.0569 0.1004 0.0791 0.0833 0.0637 0.09   0.0767 0.2508 0.0575\n",
            " 0.0752], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06632738 0.056912   0.10038311 0.07913531 0.08326048 0.06367608\n",
            " 0.09000482 0.07674894 0.25084302 0.05748744 0.07522145], argmax=8\n",
            "|->> Revisiting bbox: [272 135 106  96]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [275, 143, 106,  96] -> [272, 135, 106,  96] (Target was [279, 139,  96, 102])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X UP:bbox transition: [275, 143, 106,  96] -> [275, 139, 106,  96] w/ P(a|s)=0.073552705347538 and iou=0.8571428571428571 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for LEFT:bbox transition: [275, 139, 106,  96] -> [272, 139, 106,  96] w/ P(a|s)=0.0772160142660141 and iou=0.8571428571428571 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (1.0) for 2X UP:bbox transition: [272, 139, 106,  96] -> [272, 135, 106,  96] w/ P(a|s)=0.06367608159780502 and iou=0.7931034482758621 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.        0.        2.7539463]\n",
            "\u001b[92m>> Total frame loss: 2.753946304321289\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1773 with src: [272, 135, 106,  96] and target: [279, 140,  97,  99]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1774.jpg\n",
            "|->> Beginning tracking for bbox:[272 135 106  96]\n",
            "   \u001b[33m|->> #0/t=8-th Action selection: 4/UP (P(a|s) = 0.07699999958276749)\u001b[0m\n",
            "      |->> Bounding box moves to: [272 133 106  96]\n",
            "         |->> Action Probabilities (Rounded): [0.0687 0.0544 0.0859 0.0713 0.0771 0.0533 0.0879 0.0792 0.2969 0.0544\n",
            " 0.071 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06874616 0.054371   0.08585354 0.07131873 0.07707575 0.05326328\n",
            " 0.08786156 0.07918653 0.2969162  0.05435761 0.07104965], argmax=8\n",
            "|->> Revisiting bbox: [272 133 106  96]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [272, 135, 106,  96] -> [272, 133, 106,  96] (Target was [279, 140,  97,  99])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for UP:bbox transition: [272, 135, 106,  96] -> [272, 133, 106,  96] w/ P(a|s)=0.07707574963569641 and iou=0.77453795083438 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [2.5629666]\n",
            "\u001b[92m>> Total frame loss: 2.5629665851593018\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1774 with src: [272, 133, 106,  96] and target: [280, 139,  99,  93]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1775.jpg\n",
            "|->> Beginning tracking for bbox:[272 133 106  96]\n",
            "   \u001b[33m|->> #0/t=9-th Action selection: 4/UP (P(a|s) = 0.06800000369548798)\u001b[0m\n",
            "      |->> Bounding box moves to: [272 131 106  96]\n",
            "         |->> Action Probabilities (Rounded): [0.0634 0.048  0.0802 0.0689 0.0678 0.0524 0.0926 0.0768 0.3361 0.0481\n",
            " 0.0658], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06336085 0.04797661 0.08024294 0.06893457 0.06775191 0.0524183\n",
            " 0.09256981 0.07677342 0.336121   0.04806767 0.06578285], argmax=8\n",
            "   \u001b[33m|->> #1/t=10-th Action selection: 4/UP (P(a|s) = 0.06300000101327896)\u001b[0m\n",
            "      |->> Bounding box moves to: [272 129 106  96]\n",
            "         |->> Action Probabilities (Rounded): [0.0621 0.0445 0.0699 0.0654 0.0635 0.0444 0.0789 0.0744 0.3944 0.0441\n",
            " 0.0583], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06211393 0.04446534 0.06994294 0.06544357 0.0634981  0.04442675\n",
            " 0.07887504 0.0743634  0.39443687 0.04414071 0.05829332], argmax=8\n",
            "|->> Revisiting bbox: [272 129 106  96]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [272, 133, 106,  96] -> [272, 129, 106,  96] (Target was [280, 139,  99,  93])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.033) for UP:bbox transition: [272, 133, 106,  96] -> [272, 131, 106,  96] w/ P(a|s)=0.0677519142627716 and iou=0.8015614834092388 and reward=-0.03342857623290829 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for UP:bbox transition: [272, 131, 106,  96] -> [272, 129, 106,  96] w/ P(a|s)=0.0634981021285057 and iou=0.7693290734824281 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.08998647  2.7567453 ]\n",
            "\u001b[92m>> Total frame loss: 2.6667587757110596\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1775 with src: [272, 129, 106,  96] and target: [280, 137,  97,  99]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1776.jpg\n",
            "|->> Beginning tracking for bbox:[272 129 106  96]\n",
            "|->> Revisiting bbox: [272 129 106  96]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=11-th Action selection: 8/STOP (P(a|s) = 0.41999998688697815)\u001b[0m\n",
            "      |->> Bounding box moves to: [272 129 106  96]\n",
            "         |->> Action Probabilities (Rounded): [0.0563 0.0417 0.0703 0.0593 0.0608 0.038  0.0836 0.0707 0.4199 0.0427\n",
            " 0.0567], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05626376 0.04171232 0.07028884 0.05928111 0.06084276 0.03798076\n",
            " 0.08357245 0.0707148  0.41990057 0.04271462 0.05672803], argmax=8\n",
            "         |->> Hit a STOP on the 11-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [272, 129, 106,  96] -> [272, 129, 106,  96] (Target was [280, 137,  97,  99])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [272, 129, 106,  96] -> [272, 129, 106,  96] w/ P(a|s)=0.4199005663394928 and iou=0.7592279640665303 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.86773735]\n",
            "\u001b[92m>> Total frame loss: 0.867737352848053\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1776 with src: [272, 129, 106,  96] and target: [278, 137,  96, 104]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1777.jpg\n",
            "|->> Beginning tracking for bbox:[272 129 106  96]\n",
            "   \u001b[33m|->> #0/t=11-th Action selection: 0/LEFT (P(a|s) = 0.05900000035762787)\u001b[0m\n",
            "      |->> Bounding box moves to: [269 129 106  96]\n",
            "         |->> Action Probabilities (Rounded): [0.0587 0.0467 0.0762 0.0633 0.062  0.0418 0.0856 0.0736 0.3843 0.0472\n",
            " 0.0607], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05871158 0.04665098 0.07615694 0.06328928 0.06195186 0.04184951\n",
            " 0.08557162 0.07359519 0.38429922 0.04722663 0.06069725], argmax=8\n",
            "   \u001b[33m|->> #1/t=12-th Action selection: 6/DOWN (P(a|s) = 0.08500000089406967)\u001b[0m\n",
            "      |->> Bounding box moves to: [269 131 106  96]\n",
            "         |->> Action Probabilities (Rounded): [0.0477 0.0406 0.0747 0.0606 0.0623 0.0425 0.0854 0.0709 0.4112 0.0423\n",
            " 0.0617], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.04771283 0.04063881 0.0747494  0.06061453 0.06234313 0.04245082\n",
            " 0.08536963 0.07088929 0.4112327  0.04228601 0.06171283], argmax=8\n",
            "|->> Revisiting bbox: [269 131 106  96]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [272, 129, 106,  96] -> [269, 131, 106,  96] (Target was [278, 137,  96, 104])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for LEFT:bbox transition: [272, 129, 106,  96] -> [269, 129, 106,  96] w/ P(a|s)=0.05871158093214035 and iou=0.7213114754098361 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for DOWN:bbox transition: [269, 129, 106,  96] -> [269, 131, 106,  96] w/ P(a|s)=0.08536963164806366 and iou=0.75 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.       2.460765]\n",
            "\u001b[92m>> Total frame loss: 2.4607648849487305\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1777 with src: [269, 131, 106,  96] and target: [274, 134, 102, 101]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1778.jpg\n",
            "|->> Beginning tracking for bbox:[269 131 106  96]\n",
            "|->> Revisiting bbox: [269 131 106  96]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=13-th Action selection: 8/STOP (P(a|s) = 0.42899999022483826)\u001b[0m\n",
            "      |->> Bounding box moves to: [269 131 106  96]\n",
            "         |->> Action Probabilities (Rounded): [0.0508 0.04   0.0704 0.0588 0.0632 0.0404 0.0801 0.0686 0.4292 0.0405\n",
            " 0.058 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05084591 0.04003274 0.07042836 0.05875067 0.06324074 0.04038611\n",
            " 0.08005086 0.0686045  0.42916936 0.04049131 0.05799936], argmax=8\n",
            "         |->> Hit a STOP on the 13-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [269, 131, 106,  96] -> [269, 131, 106,  96] (Target was [274, 134, 102, 101])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [269, 131, 106,  96] -> [269, 131, 106,  96] w/ P(a|s)=0.42916935682296753 and iou=0.847361299052774 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.84590364]\n",
            "\u001b[92m>> Total frame loss: 0.8459036350250244\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1778 with src: [269, 131, 106,  96] and target: [274, 133, 107, 103]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1779.jpg\n",
            "|->> Beginning tracking for bbox:[269 131 106  96]\n",
            "   \u001b[33m|->> #0/t=13-th Action selection: 4/UP (P(a|s) = 0.06199999898672104)\u001b[0m\n",
            "      |->> Bounding box moves to: [269 129 106  96]\n",
            "         |->> Action Probabilities (Rounded): [0.0599 0.0424 0.0737 0.0605 0.0616 0.0443 0.0879 0.0715 0.3976 0.041\n",
            " 0.0595], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0599031  0.04238962 0.07372129 0.06045854 0.06162496 0.04430009\n",
            " 0.08792651 0.07151265 0.3976485  0.04103378 0.05948095], argmax=8\n",
            "   \u001b[33m|->> #1/t=14-th Action selection: 9/SCALE DOWN (P(a|s) = 0.039000000804662704)\u001b[0m\n",
            "      |->> Bounding box moves to: [270 130 102  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0589 0.0405 0.0671 0.0598 0.0575 0.0429 0.0776 0.0666 0.4348 0.0392\n",
            " 0.0552], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05887498 0.04046592 0.06706875 0.05977384 0.05753808 0.04294225\n",
            " 0.07758717 0.06657365 0.43475077 0.03924926 0.05517529], argmax=8\n",
            "|->> Revisiting bbox: [270 130 102  93]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [269, 131, 106,  96] -> [270, 130, 102,  93] (Target was [274, 133, 107, 103])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.031) for UP:bbox transition: [269, 131, 106,  96] -> [269, 129, 106,  96] w/ P(a|s)=0.06162496283650398 and iou=0.7805123897522049 and reward=-0.03073259016747376 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for SCALE DOWN:bbox transition: [269, 129, 106,  96] -> [270, 130, 102,  93] w/ P(a|s)=0.03924925625324249 and iou=0.7546846923932574 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.08564215  3.2378228 ]\n",
            "\u001b[92m>> Total frame loss: 3.1521806716918945\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1779 with src: [270, 130, 102,  93] and target: [276, 136, 105, 103]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1780.jpg\n",
            "|->> Beginning tracking for bbox:[270 130 102  93]\n",
            "   \u001b[33m|->> #0/t=15-th Action selection: 6/DOWN (P(a|s) = 0.07500000298023224)\u001b[0m\n",
            "      |->> Bounding box moves to: [270 132 102  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0582 0.0414 0.0642 0.0626 0.0599 0.0384 0.0751 0.0664 0.4432 0.0361\n",
            " 0.0546], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05815583 0.04137011 0.06420456 0.06256048 0.05985259 0.03836891\n",
            " 0.0751476  0.06642289 0.44315323 0.03611607 0.05464768], argmax=8\n",
            "   \u001b[33m|->> #1/t=16-th Action selection: 6/DOWN (P(a|s) = 0.07500000298023224)\u001b[0m\n",
            "      |->> Bounding box moves to: [270 134 102  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0547 0.0446 0.0659 0.0644 0.0651 0.0435 0.0752 0.0598 0.4302 0.038\n",
            " 0.0585], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05471155 0.04464689 0.06585383 0.0644243  0.06514902 0.04352778\n",
            " 0.07516575 0.05976313 0.43024257 0.03803461 0.05848053], argmax=8\n",
            "   \u001b[33m|->> #2/t=17-th Action selection: 7/2X DOWN (P(a|s) = 0.05400000140070915)\u001b[0m\n",
            "      |->> Bounding box moves to: [270 138 102  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0515 0.0384 0.0691 0.0581 0.0635 0.0464 0.0688 0.0542 0.4559 0.0383\n",
            " 0.0557], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05152466 0.03842511 0.06910843 0.05807513 0.06348078 0.04642022\n",
            " 0.06883589 0.05422784 0.45588443 0.03828566 0.05573185], argmax=8\n",
            "|->> Revisiting bbox: [270 138 102  93]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [270, 130, 102,  93] -> [270, 138, 102,  93] (Target was [276, 136, 105, 103])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.028) for DOWN:bbox transition: [270, 130, 102,  93] -> [270, 132, 102,  93] w/ P(a|s)=0.0751475989818573 and iou=0.7267159989793315 and reward=0.0277453738224146 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.029) for DOWN:bbox transition: [270, 132, 102,  93] -> [270, 134, 102,  93] w/ P(a|s)=0.0751657485961914 and iou=0.7553826199740596 and reward=0.028666620994728165 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (1.0) for 2X DOWN:bbox transition: [270, 134, 102,  93] -> [270, 138, 102,  93] w/ P(a|s)=0.05422784388065338 and iou=0.7850171458718016 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.07181338 0.07419092 2.9145608 ]\n",
            "\u001b[92m>> Total frame loss: 3.0605649948120117\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1780 with src: [270, 138, 102,  93] and target: [275, 133,  99,  98]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1781.jpg\n",
            "|->> Beginning tracking for bbox:[270 138 102  93]\n",
            "|->> Revisiting bbox: [270 138 102  93]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=18-th Action selection: 8/STOP (P(a|s) = 0.4320000112056732)\u001b[0m\n",
            "      |->> Bounding box moves to: [270 138 102  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0546 0.041  0.0711 0.0588 0.0683 0.0501 0.0668 0.0526 0.4316 0.0436\n",
            " 0.0614], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05464712 0.04103742 0.07113975 0.05882588 0.06828699 0.05011827\n",
            " 0.06679438 0.05264522 0.43155783 0.04358273 0.06136446], argmax=8\n",
            "         |->> Hit a STOP on the 18-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [270, 138, 102,  93] -> [270, 138, 102,  93] (Target was [275, 133,  99,  98])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [270, 138, 102,  93] -> [270, 138, 102,  93] w/ P(a|s)=0.431557834148407 and iou=0.8872823841841251 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.8403537]\n",
            "\u001b[92m>> Total frame loss: 0.8403537273406982\u001b[0m\n",
            "Final bounding box: [270 138 102  93] reached in 18 timesteps (originating from [276 140 107  97]). Target was [275 133  99  98]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 1781 in t=18 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[92m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 7.9971022605896\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 2.4747471809387207\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/Rubik\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Starting bounding box=adnet_datasets/OTB/Rubik/img/1782.jpg for adnet_datasets/OTB/Rubik's frames (index: 0)\n",
            "src:adnet_datasets/OTB/Rubik/img/1772.jpg\n",
            "target:adnet_datasets/OTB/Rubik/img/1782.jpg.\n",
            "\u001b[34m>> Attempting to reach frame 1772 with src: [275, 133, 103, 103] and target: [279, 139,  96, 102]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1773.jpg\n",
            "|->> Beginning tracking for bbox:[275 133 103 103]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 4/UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [275 130 103 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0885 0.0811 0.0936 0.0878 0.0915 0.0821 0.0957 0.0877 0.1201 0.0821\n",
            " 0.0897], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08852625 0.08107335 0.09362338 0.08778635 0.09151344 0.08213885\n",
            " 0.0957211  0.08769947 0.1201188  0.08214069 0.08965829], argmax=8\n",
            "|->> Revisiting bbox: [275 130 103 103]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [275, 133, 103, 103] -> [275, 130, 103, 103] (Target was [279, 139,  96, 102])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for UP:bbox transition: [275, 133, 103, 103] -> [275, 130, 103, 103] w/ P(a|s)=0.09151344001293182 and iou=0.7931792212358266 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [2.3912694]\n",
            "\u001b[92m>> Total frame loss: 2.3912694454193115\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1773 with src: [275, 130, 103, 103] and target: [279, 140,  97,  99]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1774.jpg\n",
            "|->> Beginning tracking for bbox:[275 130 103 103]\n",
            "   \u001b[33m|->> #0/t=2-th Action selection: 5/2X UP (P(a|s) = 0.07800000160932541)\u001b[0m\n",
            "      |->> Bounding box moves to: [275 124 103 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0874 0.0777 0.0933 0.0866 0.0879 0.0776 0.0982 0.0896 0.1381 0.0775\n",
            " 0.0862], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08742459 0.07767621 0.0933224  0.08658862 0.08787018 0.07758738\n",
            " 0.09816071 0.08959078 0.13813964 0.0774783  0.08616124], argmax=8\n",
            "   \u001b[33m|->> #1/t=3-th Action selection: 6/DOWN (P(a|s) = 0.09799999743700027)\u001b[0m\n",
            "      |->> Bounding box moves to: [275 127 103 103]\n",
            "         |->> Action Probabilities (Rounded): [0.085  0.0744 0.0916 0.0813 0.0851 0.0678 0.0976 0.0959 0.1626 0.0738\n",
            " 0.085 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08498116 0.07443064 0.0915612  0.08130035 0.08509823 0.06779508\n",
            " 0.0975605  0.09586969 0.16261536 0.07382806 0.08495966], argmax=8\n",
            "   \u001b[33m|->> #2/t=4-th Action selection: 3/2X RIGHT (P(a|s) = 0.0820000022649765)\u001b[0m\n",
            "      |->> Bounding box moves to: [281 127 103 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0806 0.0707 0.0931 0.0818 0.0872 0.0669 0.1017 0.0876 0.1748 0.0702\n",
            " 0.0855], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08058822 0.07074224 0.09305037 0.08175658 0.08716773 0.06687279\n",
            " 0.10171168 0.08764727 0.17479017 0.07015308 0.08551983], argmax=8\n",
            "   \u001b[33m|->> #3/t=5-th Action selection: 4/UP (P(a|s) = 0.08399999886751175)\u001b[0m\n",
            "      |->> Bounding box moves to: [281 124 103 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0835 0.0741 0.0873 0.0726 0.0841 0.0644 0.0954 0.084  0.2024 0.0702\n",
            " 0.0819], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0835497  0.07413477 0.08725522 0.07262664 0.08412778 0.06442121\n",
            " 0.09536318 0.08403362 0.202414   0.07022001 0.08185384], argmax=8\n",
            "   \u001b[33m|->> #4/t=6-th Action selection: 0/LEFT (P(a|s) = 0.08100000023841858)\u001b[0m\n",
            "      |->> Bounding box moves to: [278 124 103 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0809 0.0666 0.0843 0.0709 0.0798 0.0612 0.0944 0.0865 0.229  0.0649\n",
            " 0.0815], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08090041 0.06660155 0.08425441 0.07087774 0.07979278 0.06117819\n",
            " 0.09438654 0.08650471 0.22903547 0.06492979 0.08153843], argmax=8\n",
            "   \u001b[33m|->> #5/t=7-th Action selection: 4/UP (P(a|s) = 0.07900000363588333)\u001b[0m\n",
            "      |->> Bounding box moves to: [278 121 103 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0688 0.0618 0.0935 0.0689 0.0794 0.0599 0.0932 0.0861 0.254  0.06\n",
            " 0.0743], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06880949 0.06180149 0.0934619  0.06889573 0.07941342 0.05986594\n",
            " 0.09324995 0.08608966 0.25404897 0.06004823 0.07431521], argmax=8\n",
            "   \u001b[33m|->> #6/t=8-th Action selection: 1/2X LEFT (P(a|s) = 0.06300000101327896)\u001b[0m\n",
            "      |->> Bounding box moves to: [272 121 103 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0755 0.0635 0.0802 0.0678 0.0722 0.0524 0.099  0.0771 0.2808 0.0558\n",
            " 0.0758], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07548779 0.06348824 0.08020049 0.0678196  0.07218237 0.05236768\n",
            " 0.09896071 0.07714272 0.28080124 0.05577801 0.07577115], argmax=8\n",
            "|->> Revisiting bbox: [272 121 103 103]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [275, 130, 103, 103] -> [272, 121, 103, 103] (Target was [279, 140,  97,  99])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.089) for 2X UP:bbox transition: [275, 130, 103, 103] -> [275, 124, 103, 103] w/ P(a|s)=0.07758738100528717 and iou=0.7168096491973159 and reward=-0.0892845336281688 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.044) for DOWN:bbox transition: [275, 124, 103, 103] -> [275, 127, 103, 103] w/ P(a|s)=0.09756049513816833 and iou=0.760320501654764 and reward=0.04351085245744801 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.027) for 2X RIGHT:bbox transition: [275, 127, 103, 103] -> [281, 127, 103, 103] w/ P(a|s)=0.0817565843462944 and iou=0.7331504030183502 and reward=-0.02717009863641373 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-0.041) for UP:bbox transition: [281, 127, 103, 103] -> [281, 124, 103, 103] w/ P(a|s)=0.08412778377532959 and iou=0.6918054741776178 and reward=-0.041344928840732376 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (0.025) for LEFT:bbox transition: [281, 124, 103, 103] -> [278, 124, 103, 103] w/ P(a|s)=0.0809004083275795 and iou=0.7168096491973159 and reward=0.025004175019698094 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (-0.041) for UP:bbox transition: [278, 124, 103, 103] -> [278, 121, 103, 103] w/ P(a|s)=0.07941342145204544 and iou=0.6753978779840849 and reward=-0.04141177121323103 and discount=1.0\n",
            "   |->> t=7 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [278, 121, 103, 103] -> [272, 121, 103, 103] w/ P(a|s)=0.06348823755979538 and iou=0.6638129733289431 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.22824256  0.10126206 -0.06803417 -0.102346    0.06287391 -0.10489966\n",
            " -2.7569005 ]\n",
            "\u001b[31m>> Total frame loss: -3.0962870121002197\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1774 with src: [272, 121, 103, 103] and target: [280, 139,  99,  93]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1775.jpg\n",
            "|->> Beginning tracking for bbox:[272 121 103 103]\n",
            "   \u001b[33m|->> #0/t=9-th Action selection: 7/2X DOWN (P(a|s) = 0.0729999989271164)\u001b[0m\n",
            "      |->> Bounding box moves to: [272 127 103 103]\n",
            "         |->> Action Probabilities (Rounded): [0.063  0.047  0.0806 0.0697 0.0672 0.0498 0.0883 0.0727 0.3489 0.0478\n",
            " 0.0649], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06303282 0.04698381 0.08062112 0.06972948 0.06716008 0.04983691\n",
            " 0.08834017 0.07270996 0.34892395 0.04776524 0.06489635], argmax=8\n",
            "   \u001b[33m|->> #1/t=10-th Action selection: 4/UP (P(a|s) = 0.06700000166893005)\u001b[0m\n",
            "      |->> Bounding box moves to: [272 124 103 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0609 0.0447 0.0757 0.0664 0.0665 0.0469 0.0799 0.0637 0.3839 0.0499\n",
            " 0.0615], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06092394 0.04471559 0.07565617 0.06642263 0.06650557 0.04685761\n",
            " 0.07989983 0.06367348 0.3839304  0.04987408 0.06154069], argmax=8\n",
            "|->> Revisiting bbox: [272 121 103 103]. ACtion 4 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [272, 121, 103, 103] -> [272, 124, 103, 103] (Target was [280, 139,  99,  93])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.086) for 2X DOWN:bbox transition: [272, 121, 103, 103] -> [272, 127, 103, 103] w/ P(a|s)=0.07270996272563934 and iou=0.7738787933040909 and reward=0.08611795521534205 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for UP:bbox transition: [272, 127, 103, 103] -> [272, 124, 103, 103] w/ P(a|s)=0.066505566239357 and iou=0.7297486033519553 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.225739  2.7104697]\n",
            "\u001b[92m>> Total frame loss: 2.936208724975586\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1775 with src: [272, 124, 103, 103] and target: [280, 137,  97,  99]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1776.jpg\n",
            "|->> Beginning tracking for bbox:[272 124 103 103]\n",
            "   \u001b[33m|->> #0/t=11-th Action selection: 5/2X UP (P(a|s) = 0.04600000008940697)\u001b[0m\n",
            "      |->> Bounding box moves to: [272 118 103 103]\n",
            "         |->> Action Probabilities (Rounded): [0.053  0.0408 0.0705 0.0599 0.0616 0.0461 0.0762 0.0636 0.4301 0.0432\n",
            " 0.0549], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05304954 0.04083163 0.07052553 0.05994068 0.06156297 0.046053\n",
            " 0.07616519 0.0636113  0.43012255 0.04319958 0.05493801], argmax=8\n",
            "|->> Revisiting bbox: [272 118 103 103]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [272, 124, 103, 103] -> [272, 118, 103, 103] (Target was [280, 137,  97,  99])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for 2X UP:bbox transition: [272, 124, 103, 103] -> [272, 118, 103, 103] w/ P(a|s)=0.046052999794483185 and iou=0.6523871811641596 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-3.0779624]\n",
            "\u001b[31m>> Total frame loss: -3.0779623985290527\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1776 with src: [272, 118, 103, 103] and target: [278, 137,  96, 104]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1777.jpg\n",
            "|->> Beginning tracking for bbox:[272 118 103 103]\n",
            "|->> Revisiting bbox: [272 118 103 103]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=12-th Action selection: 8/STOP (P(a|s) = 0.4189999997615814)\u001b[0m\n",
            "      |->> Bounding box moves to: [272 118 103 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0581 0.0421 0.0662 0.0585 0.0648 0.0438 0.0803 0.0667 0.4192 0.041\n",
            " 0.0593], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05810199 0.04209748 0.06616461 0.05853613 0.06483217 0.04383458\n",
            " 0.08030266 0.06670472 0.41917202 0.04096277 0.05929088], argmax=8\n",
            "         |->> Hit a STOP on the 12-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [272, 118, 103, 103] -> [272, 118, 103, 103] (Target was [278, 137,  96, 104])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [272, 118, 103, 103] -> [272, 118, 103, 103] w/ P(a|s)=0.4191720187664032 and iou=0.6436267858568122 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.86947393]\n",
            "\u001b[31m>> Total frame loss: -0.869473934173584\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1777 with src: [272, 118, 103, 103] and target: [274, 134, 102, 101]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1778.jpg\n",
            "|->> Beginning tracking for bbox:[272 118 103 103]\n",
            "   \u001b[33m|->> #0/t=12-th Action selection: 3/2X RIGHT (P(a|s) = 0.06199999898672104)\u001b[0m\n",
            "      |->> Bounding box moves to: [278 118 103 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0566 0.0444 0.073  0.062  0.0662 0.0443 0.0911 0.0672 0.3904 0.0448\n",
            " 0.0601], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05656774 0.04443921 0.07303808 0.06196995 0.06620352 0.04428186\n",
            " 0.0910688  0.06715648 0.39037398 0.04477554 0.06012481], argmax=8\n",
            "   \u001b[33m|->> #1/t=13-th Action selection: 7/2X DOWN (P(a|s) = 0.06499999761581421)\u001b[0m\n",
            "      |->> Bounding box moves to: [278 124 103 103]\n",
            "         |->> Action Probabilities (Rounded): [0.058  0.0464 0.0619 0.0573 0.0628 0.0414 0.0801 0.0647 0.4227 0.045\n",
            " 0.0598], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05800217 0.04642665 0.06191909 0.05726198 0.06275913 0.04141091\n",
            " 0.08005398 0.06470697 0.42266437 0.04501833 0.05977632], argmax=8\n",
            "   \u001b[33m|->> #2/t=14-th Action selection: 6/DOWN (P(a|s) = 0.07000000029802322)\u001b[0m\n",
            "      |->> Bounding box moves to: [278 127 103 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0545 0.0406 0.0627 0.0563 0.0668 0.0477 0.0698 0.0621 0.4392 0.0433\n",
            " 0.0572], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0544586  0.04058301 0.06271031 0.05630204 0.06676766 0.04768204\n",
            " 0.06975148 0.06205733 0.4392265  0.0433002  0.05716081], argmax=8\n",
            "|->> Revisiting bbox: [278 127 103 103]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [272, 118, 103, 103] -> [278, 127, 103, 103] (Target was [274, 134, 102, 101])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.036) for 2X RIGHT:bbox transition: [272, 118, 103, 103] -> [278, 118, 103, 103] w/ P(a|s)=0.061969950795173645 and iou=0.6884134033104562 and reward=-0.036347401704390436 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.084) for 2X DOWN:bbox transition: [278, 118, 103, 103] -> [278, 124, 103, 103] w/ P(a|s)=0.0647069662809372 and iou=0.7725692972789693 and reward=0.08415589396851308 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (1.0) for DOWN:bbox transition: [278, 124, 103, 103] -> [278, 127, 103, 103] w/ P(a|s)=0.06975147873163223 and iou=0.8178735981917761 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.10108596  0.23040928  2.6628168 ]\n",
            "\u001b[92m>> Total frame loss: 2.792140007019043\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1778 with src: [278, 127, 103, 103] and target: [274, 133, 107, 103]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1779.jpg\n",
            "|->> Beginning tracking for bbox:[278 127 103 103]\n",
            "   \u001b[33m|->> #0/t=15-th Action selection: 6/DOWN (P(a|s) = 0.06800000369548798)\u001b[0m\n",
            "      |->> Bounding box moves to: [278 130 103 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0526 0.0417 0.0709 0.0569 0.0666 0.0451 0.0679 0.0574 0.441  0.0428\n",
            " 0.0571], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0526481  0.04170314 0.07085835 0.0569336  0.06655703 0.04507849\n",
            " 0.06792153 0.05743337 0.44096473 0.04275728 0.05714443], argmax=8\n",
            "   \u001b[33m|->> #1/t=16-th Action selection: 6/DOWN (P(a|s) = 0.0689999982714653)\u001b[0m\n",
            "      |->> Bounding box moves to: [278 133 103 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0557 0.0443 0.0672 0.056  0.0694 0.0511 0.0688 0.0506 0.4278 0.0445\n",
            " 0.0646], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05570316 0.04426873 0.06716345 0.05603642 0.06935628 0.05111153\n",
            " 0.06883931 0.05064635 0.4277589  0.0445482  0.06456766], argmax=8\n",
            "|->> Revisiting bbox: [278 133 103 103]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [278, 127, 103, 103] -> [278, 133, 103, 103] (Target was [274, 133, 107, 103])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.051) for DOWN:bbox transition: [278, 127, 103, 103] -> [278, 130, 103, 103] w/ P(a|s)=0.06792153418064117 and iou=0.9090909090909091 and reward=0.05068382944489136 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for DOWN:bbox transition: [278, 130, 103, 103] -> [278, 133, 103, 103] w/ P(a|s)=0.06883931159973145 and iou=0.9626168224299065 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.13630919 2.6759803 ]\n",
            "\u001b[92m>> Total frame loss: 2.8122894763946533\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1779 with src: [278, 133, 103, 103] and target: [276, 136, 105, 103]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1780.jpg\n",
            "|->> Beginning tracking for bbox:[278 133 103 103]\n",
            "   \u001b[33m|->> #0/t=17-th Action selection: 6/DOWN (P(a|s) = 0.06599999964237213)\u001b[0m\n",
            "      |->> Bounding box moves to: [278 136 103 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0559 0.0431 0.0657 0.0535 0.0663 0.0494 0.066  0.0486 0.4475 0.0435\n",
            " 0.0606], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05586239 0.04310299 0.06569836 0.05351868 0.06626781 0.04937112\n",
            " 0.06604761 0.04858992 0.44749418 0.04349479 0.06055218], argmax=8\n",
            "   \u001b[33m|->> #1/t=18-th Action selection: 6/DOWN (P(a|s) = 0.06300000101327896)\u001b[0m\n",
            "      |->> Bounding box moves to: [278 139 103 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0595 0.0459 0.0678 0.0529 0.0696 0.0511 0.0629 0.0466 0.4373 0.0443\n",
            " 0.062 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0595092  0.04590276 0.06778982 0.05289591 0.06962451 0.05110991\n",
            " 0.06293289 0.04663028 0.43729353 0.04428979 0.06202138], argmax=8\n",
            "   \u001b[33m|->> #2/t=19-th Action selection: 2/RIGHT (P(a|s) = 0.06599999964237213)\u001b[0m\n",
            "      |->> Bounding box moves to: [281 139 103 103]\n",
            "         |->> Action Probabilities (Rounded): [0.059  0.0458 0.066  0.0512 0.0699 0.0585 0.0641 0.0485 0.426  0.0454\n",
            " 0.0656], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05896865 0.04582164 0.06599173 0.0512368  0.06986904 0.05850223\n",
            " 0.06413187 0.04851101 0.4259602  0.04540352 0.06560336], argmax=8\n",
            "|->> Revisiting bbox: [281 139 103 103]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [278, 133, 103, 103] -> [281, 139, 103, 103] (Target was [276, 136, 105, 103])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.055) for DOWN:bbox transition: [278, 133, 103, 103] -> [278, 136, 103, 103] w/ P(a|s)=0.06604760885238647 and iou=0.9809523809523809 and reward=0.05502645502645498 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.055) for DOWN:bbox transition: [278, 136, 103, 103] -> [278, 139, 103, 103] w/ P(a|s)=0.06293289363384247 and iou=0.9259259259259259 and reward=-0.05502645502645498 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (1.0) for RIGHT:bbox transition: [278, 139, 103, 103] -> [281, 139, 103, 103] w/ P(a|s)=0.06599172949790955 and iou=0.8753501400560224 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.14952777 -0.15218592  2.718226  ]\n",
            "\u001b[92m>> Total frame loss: 2.7155678272247314\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1780 with src: [281, 139, 103, 103] and target: [275, 133,  99,  98]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1781.jpg\n",
            "|->> Beginning tracking for bbox:[281 139 103 103]\n",
            "|->> Revisiting bbox: [281 139 103 103]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=20-th Action selection: 8/STOP (P(a|s) = 0.4129999876022339)\u001b[0m\n",
            "      |->> Bounding box moves to: [281 139 103 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0709 0.0476 0.061  0.0506 0.0715 0.0565 0.0675 0.0496 0.4125 0.0445\n",
            " 0.0677], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07091983 0.04761179 0.06099537 0.05057597 0.07148892 0.05648866\n",
            " 0.06751979 0.04961376 0.41254702 0.04454758 0.06769132], argmax=8\n",
            "         |->> Hit a STOP on the 20-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [281, 139, 103, 103] -> [281, 139, 103, 103] (Target was [275, 133,  99,  98])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [281, 139, 103, 103] -> [281, 139, 103, 103] w/ P(a|s)=0.4125470221042633 and iou=0.7278604849000425 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.88540506]\n",
            "\u001b[92m>> Total frame loss: 0.8854050636291504\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1781 with src: [281, 139, 103, 103] and target: [276, 132, 102, 103]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1782.jpg\n",
            "|->> Beginning tracking for bbox:[281 139 103 103]\n",
            "   \u001b[33m|->> #0/t=20-th Action selection: 2/RIGHT (P(a|s) = 0.07000000029802322)\u001b[0m\n",
            "      |->> Bounding box moves to: [284 139 103 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0647 0.0516 0.0696 0.0528 0.073  0.0602 0.0684 0.0491 0.392  0.0485\n",
            " 0.0702], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06468261 0.05156975 0.06955955 0.05278181 0.07296794 0.06022388\n",
            " 0.06835245 0.04913738 0.39198792 0.04849366 0.07024305], argmax=8\n",
            "   \u001b[33m|->> #1/t=21-th Action selection: 2/RIGHT (P(a|s) = 0.05400000140070915)\u001b[0m\n",
            "      |->> Bounding box moves to: [287 139 103 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0672 0.05   0.0542 0.0504 0.0722 0.0579 0.0679 0.0507 0.4148 0.0483\n",
            " 0.0664], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06719182 0.05004986 0.05417563 0.05041183 0.07219031 0.05790517\n",
            " 0.06785206 0.05071992 0.41479856 0.04828048 0.06642435], argmax=8\n",
            "   \u001b[33m|->> #2/t=22-th Action selection: 2/RIGHT (P(a|s) = 0.054999999701976776)\u001b[0m\n",
            "      |->> Bounding box moves to: [290 139 103 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0635 0.0502 0.0551 0.0486 0.0672 0.051  0.0672 0.0514 0.4399 0.0432\n",
            " 0.0626], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06348091 0.05023718 0.05514131 0.04859496 0.06719042 0.05098051\n",
            " 0.06723913 0.05137597 0.43994808 0.0431845  0.06262703], argmax=8\n",
            "   \u001b[33m|->> #3/t=23-th Action selection: 3/2X RIGHT (P(a|s) = 0.04800000041723251)\u001b[0m\n",
            "      |->> Bounding box moves to: [296 139 103 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0654 0.0479 0.0535 0.048  0.0723 0.0495 0.0714 0.0548 0.4305 0.0433\n",
            " 0.0634], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0653925  0.04787948 0.05350097 0.04802404 0.07229252 0.04952578\n",
            " 0.07135322 0.05478874 0.43054616 0.04333071 0.06336579], argmax=8\n",
            "|->> Revisiting bbox: [296 139 103 103]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [281, 139, 103, 103] -> [296, 139, 103, 103] (Target was [276, 132, 102, 103])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.043) for RIGHT:bbox transition: [281, 139, 103, 103] -> [284, 139, 103, 103] w/ P(a|s)=0.06955955177545547 and iou=0.7463402530808039 and reward=-0.042611708284950645 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.041) for RIGHT:bbox transition: [284, 139, 103, 103] -> [287, 139, 103, 103] w/ P(a|s)=0.05417563021183014 and iou=0.7057112852411341 and reward=-0.04062896783966974 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.039) for RIGHT:bbox transition: [287, 139, 103, 103] -> [290, 139, 103, 103] w/ P(a|s)=0.05514131486415863 and iou=0.666929817636378 and reward=-0.03878146760475609 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [290, 139, 103, 103] -> [296, 139, 103, 103] w/ P(a|s)=0.04802403599023819 and iou=0.5944272445820433 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.11358457 -0.11845474 -0.11238311 -3.0360537 ]\n",
            "\u001b[31m>> Total frame loss: -3.3804759979248047\u001b[0m\n",
            "Final bounding box: [296 139 103 103] reached in 24 timesteps (originating from [275 133 103 103]). Target was [276 132 102 103]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 1782 in t=24 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[92m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 8.977927207946777\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 3.4909591674804688\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/Rubik\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Starting bounding box=adnet_datasets/OTB/Rubik/img/1783.jpg for adnet_datasets/OTB/Rubik's frames (index: 0)\n",
            "src:adnet_datasets/OTB/Rubik/img/1773.jpg\n",
            "target:adnet_datasets/OTB/Rubik/img/1783.jpg.\n",
            "\u001b[34m>> Attempting to reach frame 1773 with src: [279, 139,  96, 102] and target: [279, 140,  97,  99]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1774.jpg\n",
            "|->> Beginning tracking for bbox:[279 139  96 102]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 3/2X RIGHT (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [283 139  96 102]\n",
            "         |->> Action Probabilities (Rounded): [0.0885 0.0811 0.0936 0.0878 0.0915 0.0821 0.0957 0.0877 0.1201 0.0821\n",
            " 0.0897], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08852615 0.08107144 0.09361964 0.08778597 0.09152123 0.08213677\n",
            " 0.09572323 0.08770291 0.12011456 0.08214075 0.0896574 ], argmax=8\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 5/2X UP (P(a|s) = 0.07900000363588333)\u001b[0m\n",
            "      |->> Bounding box moves to: [283 133  96 102]\n",
            "         |->> Action Probabilities (Rounded): [0.0914 0.0872 0.0879 0.0781 0.0895 0.0792 0.096  0.0845 0.1359 0.0806\n",
            " 0.0898], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09141231 0.08718485 0.08787894 0.07813384 0.08949704 0.07918292\n",
            " 0.09596979 0.08448767 0.13587648 0.0805706  0.08980547], argmax=8\n",
            "|->> Revisiting bbox: [283 133  96 102]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [279, 139,  96, 102] -> [283, 133,  96, 102] (Target was [279, 140,  97,  99])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.057) for 2X RIGHT:bbox transition: [279, 139,  96, 102] -> [283, 139,  96, 102] w/ P(a|s)=0.08778596669435501 and iou=0.9037102473498233 and reward=-0.057163274033252165 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for 2X UP:bbox transition: [283, 139,  96, 102] -> [283, 133,  96, 102] w/ P(a|s)=0.07918291538953781 and iou=0.8366477272727273 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.13906989  2.5359948 ]\n",
            "\u001b[92m>> Total frame loss: 2.3969249725341797\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1774 with src: [283, 133,  96, 102] and target: [280, 139,  99,  93]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1775.jpg\n",
            "|->> Beginning tracking for bbox:[283 133  96 102]\n",
            "   \u001b[33m|->> #0/t=3-th Action selection: 5/2X UP (P(a|s) = 0.0689999982714653)\u001b[0m\n",
            "      |->> Bounding box moves to: [283 127  96 102]\n",
            "         |->> Action Probabilities (Rounded): [0.0868 0.0801 0.0875 0.0749 0.0871 0.0694 0.0954 0.0932 0.1629 0.0751\n",
            " 0.0876], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08679655 0.08013867 0.0874641  0.07487173 0.08712304 0.06941952\n",
            " 0.09543183 0.09316019 0.16287081 0.07511381 0.08760973], argmax=8\n",
            "   \u001b[33m|->> #1/t=4-th Action selection: 2/RIGHT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [285 127  96 102]\n",
            "         |->> Action Probabilities (Rounded): [0.0819 0.0737 0.089  0.0726 0.0849 0.0614 0.1037 0.0982 0.1815 0.0694\n",
            " 0.0837], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08187836 0.07367716 0.08899943 0.07262789 0.08488588 0.06137863\n",
            " 0.10373397 0.09817912 0.1815345  0.06937242 0.08373263], argmax=8\n",
            "   \u001b[33m|->> #2/t=5-th Action selection: 9/SCALE DOWN (P(a|s) = 0.06599999964237213)\u001b[0m\n",
            "      |->> Bounding box moves to: [286 128  93  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0869 0.0758 0.0761 0.0712 0.0814 0.0592 0.1047 0.0955 0.2003 0.0663\n",
            " 0.0827], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08688479 0.07577108 0.07608065 0.07122512 0.08143156 0.05919908\n",
            " 0.10470378 0.09547608 0.20028499 0.06625222 0.08269059], argmax=8\n",
            "   \u001b[33m|->> #3/t=6-th Action selection: 5/2X UP (P(a|s) = 0.054999999701976776)\u001b[0m\n",
            "      |->> Bounding box moves to: [286 124  93  98]\n",
            "         |->> Action Probabilities (Rounded): [0.078  0.0709 0.0825 0.0687 0.0798 0.0548 0.0978 0.0933 0.2356 0.0581\n",
            " 0.0805], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07801261 0.07086099 0.08249818 0.06874558 0.07975695 0.05484115\n",
            " 0.09776828 0.09326196 0.23559934 0.05810798 0.08054697], argmax=8\n",
            "|->> Revisiting bbox: [286 124  93  98]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [283, 133,  96, 102] -> [286, 124,  93,  98] (Target was [280, 139,  99,  93])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.052) for 2X UP:bbox transition: [283, 133,  96, 102] -> [283, 127,  96, 102] w/ P(a|s)=0.06941951811313629 and iou=0.8340573414422241 and reward=-0.05244846731559538 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.031) for RIGHT:bbox transition: [283, 127,  96, 102] -> [285, 127,  96, 102] w/ P(a|s)=0.0889994278550148 and iou=0.802732707087959 and reward=-0.031324634354265135 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.012) for SCALE DOWN:bbox transition: [285, 127,  96, 102] -> [286, 128,  93,  98] w/ P(a|s)=0.0662522241473198 and iou=0.7909090909090909 and reward=-0.011823616178868068 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (1.0) for 2X UP:bbox transition: [286, 128,  93,  98] -> [286, 124,  93,  98] w/ P(a|s)=0.05484114587306976 and iou=0.7280701754385965 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.13991086 -0.07577822 -0.03209268  2.9033146 ]\n",
            "\u001b[92m>> Total frame loss: 2.6555328369140625\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1775 with src: [286, 124,  93,  98] and target: [280, 137,  97,  99]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1776.jpg\n",
            "|->> Beginning tracking for bbox:[286 124  93  98]\n",
            "   \u001b[33m|->> #0/t=7-th Action selection: 3/2X RIGHT (P(a|s) = 0.06499999761581421)\u001b[0m\n",
            "      |->> Bounding box moves to: [290 124  93  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0766 0.0653 0.0778 0.0654 0.074  0.0502 0.098  0.0969 0.2629 0.0572\n",
            " 0.0756], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07656538 0.06529842 0.07784833 0.06541304 0.07402491 0.0502352\n",
            " 0.0980258  0.09687296 0.2628992  0.05719873 0.07561807], argmax=8\n",
            "|->> Revisiting bbox: [286 124  93  98]. ACtion 1 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [286, 124,  93,  98] -> [290, 124,  93,  98] (Target was [280, 137,  97,  99])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [286, 124,  93,  98] -> [290, 124,  93,  98] w/ P(a|s)=0.06541303545236588 and iou=0.6531531531531531 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.7270336]\n",
            "\u001b[31m>> Total frame loss: -2.7270336151123047\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1776 with src: [290, 124,  93,  98] and target: [278, 137,  96, 104]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1777.jpg\n",
            "|->> Beginning tracking for bbox:[290 124  93  98]\n",
            "|->> Revisiting bbox: [290 124  93  98]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=8-th Action selection: 8/STOP (P(a|s) = 0.2939999997615814)\u001b[0m\n",
            "      |->> Bounding box moves to: [290 124  93  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0773 0.0668 0.0705 0.0571 0.069  0.0483 0.101  0.0841 0.294  0.055\n",
            " 0.0768], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07732818 0.06679823 0.07050435 0.05713496 0.06900086 0.04833801\n",
            " 0.10097146 0.08409172 0.29402614 0.05500442 0.07680164], argmax=8\n",
            "         |->> Hit a STOP on the 8-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [290, 124,  93,  98] -> [290, 124,  93,  98] (Target was [278, 137,  96, 104])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [290, 124,  93,  98] -> [290, 124,  93,  98] w/ P(a|s)=0.29402613639831543 and iou=0.5970898143502258 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-1.2240866]\n",
            "\u001b[31m>> Total frame loss: -1.2240866422653198\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1777 with src: [290, 124,  93,  98] and target: [274, 134, 102, 101]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1778.jpg\n",
            "|->> Beginning tracking for bbox:[290 124  93  98]\n",
            "|->> Revisiting bbox: [290 124  93  98]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=8-th Action selection: 8/STOP (P(a|s) = 0.31299999356269836)\u001b[0m\n",
            "      |->> Bounding box moves to: [290 124  93  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0745 0.0636 0.0736 0.056  0.0712 0.045  0.0961 0.0806 0.3127 0.0513\n",
            " 0.0755], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07454827 0.06360621 0.07356803 0.05601345 0.07115519 0.04495279\n",
            " 0.096053   0.08061238 0.31268024 0.05130639 0.07550406], argmax=8\n",
            "         |->> Hit a STOP on the 8-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [290, 124,  93,  98] -> [290, 124,  93,  98] (Target was [274, 134, 102, 101])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [290, 124,  93,  98] -> [290, 124,  93,  98] w/ P(a|s)=0.3126802444458008 and iou=0.6387575962187712 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-1.1625742]\n",
            "\u001b[31m>> Total frame loss: -1.1625741720199585\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1778 with src: [290, 124,  93,  98] and target: [274, 133, 107, 103]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1779.jpg\n",
            "|->> Beginning tracking for bbox:[290 124  93  98]\n",
            "   \u001b[33m|->> #0/t=8-th Action selection: 7/2X DOWN (P(a|s) = 0.07999999821186066)\u001b[0m\n",
            "      |->> Bounding box moves to: [290 128  93  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0674 0.0567 0.07   0.0553 0.0628 0.0451 0.0928 0.0799 0.3491 0.0481\n",
            " 0.0726], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06739645 0.0566607  0.07001752 0.05534434 0.06282092 0.04512803\n",
            " 0.09282345 0.07994065 0.3491422  0.04808266 0.07264307], argmax=8\n",
            "|->> Revisiting bbox: [290 128  93  98]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [290, 124,  93,  98] -> [290, 128,  93,  98] (Target was [274, 133, 107, 103])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for 2X DOWN:bbox transition: [290, 124,  93,  98] -> [290, 128,  93,  98] w/ P(a|s)=0.07994065433740616 and iou=0.7250685400959561 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [2.5264707]\n",
            "\u001b[92m>> Total frame loss: 2.52647066116333\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1779 with src: [290, 128,  93,  98] and target: [276, 136, 105, 103]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1780.jpg\n",
            "|->> Beginning tracking for bbox:[290 128  93  98]\n",
            "   \u001b[33m|->> #0/t=9-th Action selection: 6/DOWN (P(a|s) = 0.07500000298023224)\u001b[0m\n",
            "      |->> Bounding box moves to: [290 130  93  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0556 0.0514 0.0592 0.0461 0.0599 0.046  0.075  0.0647 0.4394 0.0414\n",
            " 0.0613], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05559662 0.05135432 0.05922019 0.04614491 0.05988571 0.04604649\n",
            " 0.07498311 0.06473881 0.4393874  0.0413809  0.0612615 ], argmax=8\n",
            "   \u001b[33m|->> #1/t=10-th Action selection: 5/2X UP (P(a|s) = 0.0430000014603138)\u001b[0m\n",
            "      |->> Bounding box moves to: [290 126  93  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0547 0.0448 0.0612 0.0499 0.0634 0.0429 0.0709 0.0597 0.4535 0.0392\n",
            " 0.0599], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05467103 0.04480686 0.06122269 0.04988456 0.06336562 0.04287183\n",
            " 0.07085612 0.0596707  0.45354658 0.03923768 0.0598663 ], argmax=8\n",
            "   \u001b[33m|->> #2/t=11-th Action selection: 5/2X UP (P(a|s) = 0.041999999433755875)\u001b[0m\n",
            "      |->> Bounding box moves to: [290 122  93  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0555 0.0456 0.0641 0.0497 0.0577 0.0415 0.0711 0.0592 0.4609 0.038\n",
            " 0.0567], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05546682 0.04556125 0.06410687 0.04969467 0.05766832 0.04151461\n",
            " 0.07106357 0.05923251 0.46093598 0.03802795 0.05672739], argmax=8\n",
            "|->> Revisiting bbox: [290 122  93  98]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [290, 128,  93,  98] -> [290, 122,  93,  98] (Target was [276, 136, 105, 103])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.027) for DOWN:bbox transition: [290, 128,  93,  98] -> [290, 130,  93,  98] w/ P(a|s)=0.07498311251401901 and iou=0.7244094488188977 and reward=0.026735030214246502 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.053) for 2X UP:bbox transition: [290, 130,  93,  98] -> [290, 126,  93,  98] w/ P(a|s)=0.04287182539701462 and iou=0.6717557251908397 and reward=-0.05265372362805798 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-1.0) for 2X UP:bbox transition: [290, 126,  93,  98] -> [290, 122,  93,  98] w/ P(a|s)=0.04151460528373718 and iou=0.6222222222222222 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.06925689 -0.16583502 -3.18171   ]\n",
            "\u001b[31m>> Total frame loss: -3.2782881259918213\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1780 with src: [290, 122,  93,  98] and target: [275, 133,  99,  98]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1781.jpg\n",
            "|->> Beginning tracking for bbox:[290 122  93  98]\n",
            "|->> Revisiting bbox: [290 122  93  98]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=12-th Action selection: 8/STOP (P(a|s) = 0.47200000286102295)\u001b[0m\n",
            "      |->> Bounding box moves to: [290 122  93  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0553 0.0418 0.0621 0.0461 0.0556 0.04   0.0702 0.0592 0.4719 0.0384\n",
            " 0.0593], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05534179 0.04181496 0.06208548 0.0461329  0.05555554 0.04004448\n",
            " 0.07017332 0.05920561 0.471893   0.03844414 0.05930887], argmax=8\n",
            "         |->> Hit a STOP on the 12-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [290, 122,  93,  98] -> [290, 122,  93,  98] (Target was [275, 133,  99,  98])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [290, 122,  93,  98] -> [290, 122,  93,  98] w/ P(a|s)=0.4718930125236511 and iou=0.635036496350365 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.75100297]\n",
            "\u001b[31m>> Total frame loss: -0.7510029673576355\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1781 with src: [290, 122,  93,  98] and target: [276, 132, 102, 103]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1782.jpg\n",
            "|->> Beginning tracking for bbox:[290 122  93  98]\n",
            "   \u001b[33m|->> #0/t=12-th Action selection: 2/RIGHT (P(a|s) = 0.06700000166893005)\u001b[0m\n",
            "      |->> Bounding box moves to: [292 122  93  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0565 0.0465 0.0666 0.0553 0.0607 0.0421 0.083  0.0643 0.4271 0.0398\n",
            " 0.0581], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05646086 0.04647824 0.06660897 0.05529755 0.06071033 0.04206504\n",
            " 0.0830005  0.06430326 0.4271462  0.03983959 0.0580895 ], argmax=8\n",
            "   \u001b[33m|->> #1/t=13-th Action selection: 7/2X DOWN (P(a|s) = 0.06599999964237213)\u001b[0m\n",
            "      |->> Bounding box moves to: [292 126  93  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0617 0.0463 0.0551 0.0517 0.0617 0.0431 0.0751 0.0663 0.4426 0.0408\n",
            " 0.0556], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06166988 0.04634997 0.05511191 0.05167013 0.06173886 0.04308818\n",
            " 0.0750842  0.06630812 0.4425842  0.04076636 0.05562827], argmax=8\n",
            "|->> Revisiting bbox: [292 122  93  98]. ACtion 5 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [290, 122,  93,  98] -> [292, 126,  93,  98] (Target was [276, 132, 102, 103])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.024) for RIGHT:bbox transition: [290, 122,  93,  98] -> [292, 122,  93,  98] w/ P(a|s)=0.0666089728474617 and iou=0.6279455692001328 and reward=-0.024125835313171362 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for 2X DOWN:bbox transition: [292, 122,  93,  98] -> [292, 126,  93,  98] w/ P(a|s)=0.06630811840295792 and iou=0.6757772463272975 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.06535486 -2.713443  ]\n",
            "\u001b[31m>> Total frame loss: -2.7787978649139404\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1782 with src: [292, 126,  93,  98] and target: [277, 130,  98,  96]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1783.jpg\n",
            "|->> Beginning tracking for bbox:[292 126  93  98]\n",
            "|->> Revisiting bbox: [292 126  93  98]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=14-th Action selection: 8/STOP (P(a|s) = 0.45899999141693115)\u001b[0m\n",
            "      |->> Bounding box moves to: [292 126  93  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0535 0.0451 0.0648 0.049  0.061  0.0448 0.0662 0.0576 0.4589 0.0416\n",
            " 0.0574], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05352692 0.04513992 0.06479427 0.04903391 0.06099594 0.04476246\n",
            " 0.06618815 0.05759102 0.45889178 0.04163899 0.05743657], argmax=8\n",
            "         |->> Hit a STOP on the 14-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [292, 126,  93,  98] -> [292, 126,  93,  98] (Target was [277, 130,  98,  96])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [292, 126,  93,  98] -> [292, 126,  93,  98] w/ P(a|s)=0.45889177918434143 and iou=0.7277985074626866 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.77894086]\n",
            "\u001b[92m>> Total frame loss: 0.7789408564567566\u001b[0m\n",
            "Final bounding box: [292 126  93  98] reached in 14 timesteps (originating from [279 139  96 102]). Target was [277 130  98  96]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 1783 in t=14 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[31m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 7.319582939147949\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 1.6587504148483276\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/Rubik\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Starting bounding box=adnet_datasets/OTB/Rubik/img/1784.jpg for adnet_datasets/OTB/Rubik's frames (index: 0)\n",
            "src:adnet_datasets/OTB/Rubik/img/1774.jpg\n",
            "target:adnet_datasets/OTB/Rubik/img/1784.jpg.\n",
            "\u001b[34m>> Attempting to reach frame 1774 with src: [279, 140,  97,  99] and target: [280, 139,  99,  93]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1775.jpg\n",
            "|->> Beginning tracking for bbox:[279 140  97  99]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 0/LEFT (P(a|s) = 0.08900000154972076)\u001b[0m\n",
            "      |->> Bounding box moves to: [277 140  97  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0885 0.0811 0.0936 0.0878 0.0915 0.0821 0.0957 0.0877 0.1201 0.0821\n",
            " 0.0897], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08852617 0.08106978 0.09361633 0.08778448 0.09152835 0.08213587\n",
            " 0.09572534 0.08770615 0.12010997 0.08214085 0.0896567 ], argmax=8\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 0/LEFT (P(a|s) = 0.07699999958276749)\u001b[0m\n",
            "      |->> Bounding box moves to: [275 140  97  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0774 0.0749 0.1036 0.0893 0.0905 0.0801 0.0969 0.0877 0.137  0.0758\n",
            " 0.0869], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07735047 0.0749012  0.10355066 0.08929287 0.09050497 0.08007774\n",
            " 0.09687275 0.08774957 0.13698652 0.07581833 0.08689488], argmax=8\n",
            "   \u001b[33m|->> #2/t=3-th Action selection: 4/UP (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [275 138  97  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0762 0.0696 0.1067 0.0901 0.0896 0.0762 0.0983 0.0844 0.1544 0.0706\n",
            " 0.0841], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07617403 0.06956375 0.10671684 0.0901114  0.08961804 0.07616273\n",
            " 0.09825271 0.08438684 0.15436435 0.07058366 0.08406573], argmax=8\n",
            "   \u001b[33m|->> #3/t=4-th Action selection: 1/2X LEFT (P(a|s) = 0.06599999964237213)\u001b[0m\n",
            "      |->> Bounding box moves to: [271 138  97  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0817 0.0658 0.0997 0.0888 0.0848 0.0725 0.1003 0.0844 0.1752 0.0669\n",
            " 0.0799], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0817307  0.06579276 0.09973633 0.08875673 0.08479679 0.07246396\n",
            " 0.10027791 0.08441384 0.17520991 0.06687257 0.07994851], argmax=8\n",
            "   \u001b[33m|->> #4/t=5-th Action selection: 7/2X DOWN (P(a|s) = 0.08299999684095383)\u001b[0m\n",
            "      |->> Bounding box moves to: [271 142  97  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0778 0.0556 0.0988 0.0956 0.0838 0.0696 0.0954 0.0829 0.2007 0.0634\n",
            " 0.0765], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07777355 0.05558773 0.09880752 0.09558834 0.08384012 0.06956255\n",
            " 0.09537503 0.08290085 0.20066245 0.06343712 0.07646467], argmax=8\n",
            "   \u001b[33m|->> #5/t=6-th Action selection: 3/2X RIGHT (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [275 142  97  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0743 0.0541 0.0967 0.0903 0.0861 0.0668 0.0901 0.0741 0.2282 0.0635\n",
            " 0.0757], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07432295 0.05410781 0.09672464 0.09029648 0.08614456 0.06675433\n",
            " 0.09010167 0.07412031 0.22821003 0.06352147 0.07569572], argmax=8\n",
            "   \u001b[33m|->> #6/t=7-th Action selection: 7/2X DOWN (P(a|s) = 0.0689999982714653)\u001b[0m\n",
            "      |->> Bounding box moves to: [275 146  97  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0712 0.0581 0.0914 0.0815 0.0845 0.0655 0.0873 0.069  0.2558 0.0611\n",
            " 0.0745], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07120843 0.05812362 0.09137131 0.08149103 0.08448956 0.06552155\n",
            " 0.08733234 0.06903666 0.25584596 0.06107147 0.07450808], argmax=8\n",
            "|->> Revisiting bbox: [275 142  97  99]. ACtion 5 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [279, 140,  97,  99] -> [275, 146,  97,  99] (Target was [280, 139,  99,  93])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.034) for LEFT:bbox transition: [279, 140,  97,  99] -> [277, 140,  97,  99] w/ P(a|s)=0.0885261744260788 and iou=0.8510135800039362 and reward=-0.03413374410911252 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.033) for LEFT:bbox transition: [277, 140,  97,  99] -> [275, 140,  97,  99] w/ P(a|s)=0.07735046744346619 and iou=0.8180939493524068 and reward=-0.032919630651529475 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.016) for UP:bbox transition: [275, 140,  97,  99] -> [275, 138,  97,  99] w/ P(a|s)=0.08961804211139679 and iou=0.8344060854300761 and reward=0.016312136077669348 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-0.064) for 2X LEFT:bbox transition: [275, 138,  97,  99] -> [271, 138,  97,  99] w/ P(a|s)=0.0657927617430687 and iou=0.7701863354037267 and reward=-0.06421975002634939 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (-0.043) for 2X DOWN:bbox transition: [271, 138,  97,  99] -> [271, 142,  97,  99] w/ P(a|s)=0.08290085196495056 and iou=0.7272727272727273 and reward=-0.042913608130999426 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (0.059) for 2X RIGHT:bbox transition: [271, 142,  97,  99] -> [275, 142,  97,  99] w/ P(a|s)=0.09029648452997208 and iou=0.7863247863247863 and reward=0.059052059052059014 and discount=1.0\n",
            "   |->> t=7 Diff-Reward (1.0) for 2X DOWN:bbox transition: [275, 142,  97,  99] -> [275, 146,  97,  99] w/ P(a|s)=0.06903666257858276 and iou=0.7260047715177097 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.0827558  -0.08425479  0.03934811 -0.1747577  -0.1068596   0.14199993\n",
            "  2.6731176 ]\n",
            "\u001b[92m>> Total frame loss: 2.4058377742767334\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1775 with src: [275, 146,  97,  99] and target: [280, 137,  97,  99]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1776.jpg\n",
            "|->> Beginning tracking for bbox:[275 146  97  99]\n",
            "|->> Revisiting bbox: [275 146  97  99]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=8-th Action selection: 8/STOP (P(a|s) = 0.28700000047683716)\u001b[0m\n",
            "      |->> Bounding box moves to: [275 146  97  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0666 0.0537 0.0827 0.0748 0.0859 0.069  0.0852 0.0639 0.2872 0.0582\n",
            " 0.0728], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06656902 0.05372951 0.08267812 0.07482676 0.08587108 0.06895541\n",
            " 0.08520425 0.06394548 0.28717622 0.05820848 0.07283569], argmax=8\n",
            "         |->> Hit a STOP on the 8-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [275, 146,  97,  99] -> [275, 146,  97,  99] (Target was [280, 137,  97,  99])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [275, 146,  97,  99] -> [275, 146,  97,  99] w/ P(a|s)=0.2871762216091156 and iou=0.7578253706754531 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [1.2476592]\n",
            "\u001b[92m>> Total frame loss: 1.2476592063903809\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1776 with src: [275, 146,  97,  99] and target: [278, 137,  96, 104]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1777.jpg\n",
            "|->> Beginning tracking for bbox:[275 146  97  99]\n",
            "|->> Revisiting bbox: [275 146  97  99]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=8-th Action selection: 8/STOP (P(a|s) = 0.30799999833106995)\u001b[0m\n",
            "      |->> Bounding box moves to: [275 146  97  99]\n",
            "         |->> Action Probabilities (Rounded): [0.066  0.0522 0.0856 0.0687 0.0826 0.0623 0.0843 0.0633 0.3078 0.057\n",
            " 0.0702], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06595983 0.0521774  0.08562874 0.06872538 0.08255486 0.06226918\n",
            " 0.08433197 0.06331747 0.3077699  0.05703854 0.07022674], argmax=8\n",
            "         |->> Hit a STOP on the 8-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [275, 146,  97,  99] -> [275, 146,  97,  99] (Target was [278, 137,  96, 104])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [275, 146,  97,  99] -> [275, 146,  97,  99] w/ P(a|s)=0.30776989459991455 and iou=0.8379468893684902 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [1.1784029]\n",
            "\u001b[92m>> Total frame loss: 1.1784029006958008\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1777 with src: [275, 146,  97,  99] and target: [274, 134, 102, 101]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1778.jpg\n",
            "|->> Beginning tracking for bbox:[275 146  97  99]\n",
            "|->> Revisiting bbox: [275 146  97  99]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=8-th Action selection: 8/STOP (P(a|s) = 0.3409999907016754)\u001b[0m\n",
            "      |->> Bounding box moves to: [275 146  97  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0652 0.0491 0.0711 0.0671 0.0759 0.0616 0.0851 0.0604 0.341  0.0513\n",
            " 0.0722], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06524826 0.04911868 0.07107262 0.06711525 0.07591716 0.06163684\n",
            " 0.08509229 0.06036794 0.3409782  0.05128209 0.0721707 ], argmax=8\n",
            "         |->> Hit a STOP on the 8-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [275, 146,  97,  99] -> [275, 146,  97,  99] (Target was [274, 134, 102, 101])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [275, 146,  97,  99] -> [275, 146,  97,  99] w/ P(a|s)=0.34097820520401 and iou=0.7658800567778566 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [1.0759368]\n",
            "\u001b[92m>> Total frame loss: 1.0759367942810059\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1778 with src: [275, 146,  97,  99] and target: [274, 133, 107, 103]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1779.jpg\n",
            "|->> Beginning tracking for bbox:[275 146  97  99]\n",
            "   \u001b[33m|->> #0/t=8-th Action selection: 5/2X UP (P(a|s) = 0.0560000017285347)\u001b[0m\n",
            "      |->> Bounding box moves to: [275 142  97  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0559 0.0416 0.0657 0.0579 0.0699 0.0561 0.0713 0.0561 0.4229 0.0419\n",
            " 0.0608], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05585418 0.04156994 0.06569812 0.05787442 0.0698963  0.05614074\n",
            " 0.07126437 0.05613852 0.42286178 0.04186444 0.06083717], argmax=8\n",
            "|->> Revisiting bbox: [275 142  97  99]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [275, 146,  97,  99] -> [275, 142,  97,  99] (Target was [274, 133, 107, 103])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for 2X UP:bbox transition: [275, 146,  97,  99] -> [275, 142,  97,  99] w/ P(a|s)=0.05614073947072029 and iou=0.7924561098557275 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [2.8798935]\n",
            "\u001b[92m>> Total frame loss: 2.8798935413360596\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1779 with src: [275, 142,  97,  99] and target: [276, 136, 105, 103]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1780.jpg\n",
            "|->> Beginning tracking for bbox:[275 142  97  99]\n",
            "|->> Revisiting bbox: [275 142  97  99]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=9-th Action selection: 8/STOP (P(a|s) = 0.47999998927116394)\u001b[0m\n",
            "      |->> Bounding box moves to: [275 142  97  99]\n",
            "         |->> Action Probabilities (Rounded): [0.049  0.039  0.0622 0.0543 0.0567 0.0407 0.0657 0.0598 0.4804 0.038\n",
            " 0.0542], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.04902669 0.03898442 0.06224271 0.05428947 0.05665068 0.04066931\n",
            " 0.06568227 0.05980472 0.48042953 0.03802856 0.05419165], argmax=8\n",
            "         |->> Hit a STOP on the 9-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [275, 142,  97,  99] -> [275, 142,  97,  99] (Target was [276, 136, 105, 103])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [275, 142,  97,  99] -> [275, 142,  97,  99] w/ P(a|s)=0.4804295301437378 and iou=0.8384656942193409 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.7330747]\n",
            "\u001b[92m>> Total frame loss: 0.7330747246742249\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1780 with src: [275, 142,  97,  99] and target: [275, 133,  99,  98]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1781.jpg\n",
            "|->> Beginning tracking for bbox:[275 142  97  99]\n",
            "   \u001b[33m|->> #0/t=9-th Action selection: 2/RIGHT (P(a|s) = 0.06499999761581421)\u001b[0m\n",
            "      |->> Bounding box moves to: [277 142  97  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0507 0.0412 0.0649 0.0546 0.0594 0.0466 0.0714 0.0582 0.4532 0.0401\n",
            " 0.0597], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05074473 0.04120755 0.06491331 0.0545788  0.05943157 0.04658671\n",
            " 0.07141807 0.05815202 0.45317245 0.04013485 0.05966   ], argmax=8\n",
            "   \u001b[33m|->> #1/t=10-th Action selection: 9/SCALE DOWN (P(a|s) = 0.03999999910593033)\u001b[0m\n",
            "      |->> Bounding box moves to: [278 143  94  96]\n",
            "         |->> Action Probabilities (Rounded): [0.0549 0.0426 0.0543 0.0503 0.0557 0.0417 0.068  0.0571 0.4818 0.0395\n",
            " 0.0543], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05485211 0.04257846 0.05426418 0.05028092 0.05566035 0.0417329\n",
            " 0.06797677 0.05705938 0.48177603 0.03951454 0.05430438], argmax=8\n",
            "   \u001b[33m|->> #2/t=11-th Action selection: 6/DOWN (P(a|s) = 0.06400000303983688)\u001b[0m\n",
            "      |->> Bounding box moves to: [278 145  94  96]\n",
            "         |->> Action Probabilities (Rounded): [0.0509 0.0434 0.0596 0.0504 0.0558 0.0403 0.064  0.0556 0.4899 0.0349\n",
            " 0.0552], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05089644 0.04343654 0.05961328 0.05042865 0.05579852 0.04025907\n",
            " 0.063995   0.05561281 0.48989722 0.03488784 0.05517472], argmax=8\n",
            "   \u001b[33m|->> #3/t=12-th Action selection: 1/2X LEFT (P(a|s) = 0.04600000008940697)\u001b[0m\n",
            "      |->> Bounding box moves to: [274 145  94  96]\n",
            "         |->> Action Probabilities (Rounded): [0.053  0.0461 0.0599 0.0527 0.0622 0.0437 0.0675 0.0563 0.4657 0.0375\n",
            " 0.0554], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05303483 0.04608674 0.05989893 0.05273522 0.06221649 0.04371756\n",
            " 0.06751736 0.05625788 0.4656678  0.03746341 0.05540379], argmax=8\n",
            "   \u001b[33m|->> #4/t=13-th Action selection: 6/DOWN (P(a|s) = 0.06800000369548798)\u001b[0m\n",
            "      |->> Bounding box moves to: [274 147  94  96]\n",
            "         |->> Action Probabilities (Rounded): [0.0534 0.039  0.0694 0.0579 0.0584 0.0422 0.0682 0.051  0.4698 0.0361\n",
            " 0.0544], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05344833 0.03900618 0.06939308 0.05791037 0.05836696 0.04222066\n",
            " 0.06824943 0.05100934 0.46983996 0.03612895 0.05442681], argmax=8\n",
            "   \u001b[33m|->> #5/t=14-th Action selection: 0/LEFT (P(a|s) = 0.05400000140070915)\u001b[0m\n",
            "      |->> Bounding box moves to: [272 147  94  96]\n",
            "         |->> Action Probabilities (Rounded): [0.0543 0.0404 0.07   0.0584 0.064  0.0447 0.0712 0.0538 0.4451 0.0376\n",
            " 0.0605], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05425337 0.04041271 0.07003599 0.05841997 0.06404532 0.04468304\n",
            " 0.07117666 0.05377435 0.4450521  0.03760546 0.06054107], argmax=8\n",
            "|->> Revisiting bbox: [274 147  94  96]. ACtion 2 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [275, 142,  97,  99] -> [272, 147,  94,  96] (Target was [275, 133,  99,  98])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for RIGHT:bbox transition: [275, 142,  97,  99] -> [277, 142,  97,  99] w/ P(a|s)=0.064913310110569 and iou=0.8089392803598201 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.018) for SCALE DOWN:bbox transition: [277, 142,  97,  99] -> [278, 143,  94,  96] w/ P(a|s)=0.039514537900686264 and iou=0.7912760665773867 and reward=-0.017663213782433407 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.032) for DOWN:bbox transition: [278, 143,  94,  96] -> [278, 145,  94,  96] w/ P(a|s)=0.06399500370025635 and iou=0.7596316481864311 and reward=-0.03164441839095555 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-0.014) for 2X LEFT:bbox transition: [278, 145,  94,  96] -> [274, 145,  94,  96] w/ P(a|s)=0.046086739748716354 and iou=0.7455257270693513 and reward=-0.014105921117079867 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (-0.03) for DOWN:bbox transition: [274, 145,  94,  96] -> [274, 147,  94,  96] w/ P(a|s)=0.0682494267821312 and iou=0.7157778999450247 and reward=-0.029747827124326554 and discount=1.0\n",
            "   |->> t=6 Diff-Reward (-1.0) for LEFT:bbox transition: [274, 147,  94,  96] -> [272, 147,  94,  96] w/ P(a|s)=0.054253365844488144 and iou=0.6897671900378993 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.         -0.05707138 -0.08698893 -0.04340716 -0.07986061 -2.9140902 ]\n",
            "\u001b[31m>> Total frame loss: -3.1814184188842773\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1781 with src: [272, 147,  94,  96] and target: [276, 132, 102, 103]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1782.jpg\n",
            "|->> Beginning tracking for bbox:[272 147  94  96]\n",
            "|->> Revisiting bbox: [272 147  94  96]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=15-th Action selection: 8/STOP (P(a|s) = 0.4230000078678131)\u001b[0m\n",
            "      |->> Bounding box moves to: [272 147  94  96]\n",
            "         |->> Action Probabilities (Rounded): [0.0517 0.0399 0.0778 0.0648 0.0648 0.0496 0.0707 0.058  0.4225 0.0397\n",
            " 0.0605], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05174541 0.0398595  0.07778264 0.06478273 0.06476828 0.04964373\n",
            " 0.07073924 0.05798964 0.4225071  0.03966497 0.06051679], argmax=8\n",
            "         |->> Hit a STOP on the 15-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [272, 147,  94,  96] -> [272, 147,  94,  96] (Target was [276, 132, 102, 103])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [272, 147,  94,  96] -> [272, 147,  94,  96] w/ P(a|s)=0.422507107257843 and iou=0.6821705426356589 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.861549]\n",
            "\u001b[31m>> Total frame loss: -0.8615490198135376\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1782 with src: [272, 147,  94,  96] and target: [277, 130,  98,  96]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1783.jpg\n",
            "|->> Beginning tracking for bbox:[272 147  94  96]\n",
            "|->> Revisiting bbox: [272 147  94  96]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=15-th Action selection: 8/STOP (P(a|s) = 0.3930000066757202)\u001b[0m\n",
            "      |->> Bounding box moves to: [272 147  94  96]\n",
            "         |->> Action Probabilities (Rounded): [0.0621 0.0452 0.0789 0.06   0.0663 0.0549 0.0799 0.0573 0.3931 0.0408\n",
            " 0.0616], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0621257  0.04520135 0.07891517 0.06002485 0.06627513 0.05485848\n",
            " 0.07989018 0.05726948 0.39305073 0.04083222 0.06155664], argmax=8\n",
            "         |->> Hit a STOP on the 15-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [272, 147,  94,  96] -> [272, 147,  94,  96] (Target was [277, 130,  98,  96])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [272, 147,  94,  96] -> [272, 147,  94,  96] w/ P(a|s)=0.3930507302284241 and iou=0.616700289448294 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.9338166]\n",
            "\u001b[31m>> Total frame loss: -0.9338166117668152\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1783 with src: [272, 147,  94,  96] and target: [277, 131,  99,  94]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1784.jpg\n",
            "|->> Beginning tracking for bbox:[272 147  94  96]\n",
            "   \u001b[33m|->> #0/t=15-th Action selection: 5/2X UP (P(a|s) = 0.05299999937415123)\u001b[0m\n",
            "      |->> Bounding box moves to: [272 143  94  96]\n",
            "         |->> Action Probabilities (Rounded): [0.0576 0.0425 0.0732 0.0618 0.0671 0.0533 0.0771 0.0595 0.4026 0.0417\n",
            " 0.0637], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05757591 0.04248614 0.07322679 0.06175493 0.06713806 0.05330132\n",
            " 0.07706194 0.05951999 0.402561   0.04165078 0.06372309], argmax=8\n",
            "|->> Revisiting bbox: [272 143  94  96]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [272, 147,  94,  96] -> [272, 143,  94,  96] (Target was [277, 131,  99,  94])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for 2X UP:bbox transition: [272, 147,  94,  96] -> [272, 143,  94,  96] w/ P(a|s)=0.05330131575465202 and iou=0.661530094271211 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.9317942]\n",
            "\u001b[31m>> Total frame loss: -2.9317941665649414\u001b[0m\n",
            "Final bounding box: [272 143  94  96] reached in 16 timesteps (originating from [279 140  97  99]). Target was [277 131  99  94]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 1784 in t=16 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[92m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 7.470268249511719\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 2.2308475971221924\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/Rubik\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Starting bounding box=adnet_datasets/OTB/Rubik/img/1785.jpg for adnet_datasets/OTB/Rubik's frames (index: 0)\n",
            "src:adnet_datasets/OTB/Rubik/img/1775.jpg\n",
            "target:adnet_datasets/OTB/Rubik/img/1785.jpg.\n",
            "\u001b[34m>> Attempting to reach frame 1775 with src: [280, 139,  99,  93] and target: [280, 137,  97,  99]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1776.jpg\n",
            "|->> Beginning tracking for bbox:[280 139  99  93]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 10/SCALE UP (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [278 137 101  95]\n",
            "         |->> Action Probabilities (Rounded): [0.0885 0.0811 0.0936 0.0878 0.0915 0.0821 0.0957 0.0877 0.1201 0.0821\n",
            " 0.0897], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0885249  0.08106814 0.09361324 0.08778311 0.09153464 0.08213496\n",
            " 0.09572705 0.08770997 0.12010726 0.08214078 0.08965595], argmax=8\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 3/2X RIGHT (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [284 137 101  95]\n",
            "         |->> Action Probabilities (Rounded): [0.0859 0.077  0.0942 0.0881 0.0913 0.0795 0.0966 0.0871 0.1368 0.0819\n",
            " 0.0817], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08585671 0.07701308 0.09421774 0.08813713 0.09125641 0.07952804\n",
            " 0.09657861 0.08707225 0.13675255 0.08191456 0.08167303], argmax=8\n",
            "   \u001b[33m|->> #2/t=3-th Action selection: 10/SCALE UP (P(a|s) = 0.08399999886751175)\u001b[0m\n",
            "      |->> Bounding box moves to: [282 135 104  97]\n",
            "         |->> Action Probabilities (Rounded): [0.089  0.0822 0.089  0.0772 0.0899 0.0753 0.0997 0.0852 0.1492 0.0791\n",
            " 0.0843], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08896852 0.08223962 0.08899356 0.07721617 0.08989174 0.07528985\n",
            " 0.09967823 0.0851818  0.14915152 0.07905139 0.08433764], argmax=8\n",
            "|->> Revisiting bbox: [282 135 104  97]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [280, 139,  99,  93] -> [282, 135, 104,  97] (Target was [280, 137,  97,  99])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.002) for SCALE UP:bbox transition: [280, 139,  99,  93] -> [278, 137, 101,  95] w/ P(a|s)=0.08965595066547394 and iou=0.923069217670039 and reward=0.0015246268027390153 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.071) for 2X RIGHT:bbox transition: [278, 137, 101,  95] -> [284, 137, 101,  95] w/ P(a|s)=0.08813712745904922 and iou=0.8525523497056837 and reward=-0.0705168679643553 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (1.0) for SCALE UP:bbox transition: [284, 137, 101,  95] -> [282, 135, 104,  97] w/ P(a|s)=0.08433763682842255 and iou=0.8461466341646353 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.00367706 -0.1712757   2.472927  ]\n",
            "\u001b[92m>> Total frame loss: 2.305328369140625\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1776 with src: [282, 135, 104,  97] and target: [278, 137,  96, 104]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1777.jpg\n",
            "|->> Beginning tracking for bbox:[282 135 104  97]\n",
            "   \u001b[33m|->> #0/t=4-th Action selection: 3/2X RIGHT (P(a|s) = 0.07800000160932541)\u001b[0m\n",
            "      |->> Bounding box moves to: [288 135 104  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0855 0.0749 0.0881 0.0784 0.0886 0.0734 0.0951 0.0833 0.1775 0.0779\n",
            " 0.0773], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08546728 0.07493659 0.08808825 0.07838675 0.08862748 0.07339497\n",
            " 0.09513492 0.08325536 0.17754062 0.07791661 0.07725114], argmax=8\n",
            "   \u001b[33m|->> #1/t=5-th Action selection: 5/2X UP (P(a|s) = 0.0689999982714653)\u001b[0m\n",
            "      |->> Bounding box moves to: [288 131 104  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0853 0.078  0.0865 0.0677 0.0898 0.0688 0.0998 0.0833 0.1881 0.0733\n",
            " 0.0794], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0853437  0.07803433 0.08650278 0.06766221 0.08984582 0.06877537\n",
            " 0.09976075 0.08329725 0.18806942 0.07326654 0.07944182], argmax=8\n",
            "|->> Revisiting bbox: [288 135 104  97]. ACtion 7 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [282, 135, 104,  97] -> [288, 131, 104,  97] (Target was [278, 137,  96, 104])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.085) for 2X RIGHT:bbox transition: [282, 135, 104,  97] -> [288, 135, 104,  97] w/ P(a|s)=0.07838675379753113 and iou=0.6864392539069064 and reward=-0.08482795399990617 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for 2X UP:bbox transition: [288, 135, 104,  97] -> [288, 131, 104,  97] w/ P(a|s)=0.06877537071704865 and iou=0.6390658174097664 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.21598049 -2.6769097 ]\n",
            "\u001b[31m>> Total frame loss: -2.892890214920044\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1777 with src: [288, 131, 104,  97] and target: [274, 134, 102, 101]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1778.jpg\n",
            "|->> Beginning tracking for bbox:[288 131 104  97]\n",
            "|->> Revisiting bbox: [288 131 104  97]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=6-th Action selection: 8/STOP (P(a|s) = 0.23499999940395355)\u001b[0m\n",
            "      |->> Bounding box moves to: [288 131 104  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0798 0.0745 0.0786 0.0659 0.0815 0.0598 0.0946 0.085  0.2352 0.0669\n",
            " 0.0781], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07983437 0.07451204 0.07861923 0.06592067 0.0814582  0.05978638\n",
            " 0.09461275 0.08504502 0.23523197 0.06686442 0.07811497], argmax=8\n",
            "         |->> Hit a STOP on the 6-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [288, 131, 104,  97] -> [288, 131, 104,  97] (Target was [274, 134, 102, 101])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [288, 131, 104,  97] -> [288, 131, 104,  97] w/ P(a|s)=0.23523196578025818 and iou=0.6826208945370523 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-1.4471831]\n",
            "\u001b[31m>> Total frame loss: -1.4471831321716309\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1778 with src: [288, 131, 104,  97] and target: [274, 133, 107, 103]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1779.jpg\n",
            "|->> Beginning tracking for bbox:[288 131 104  97]\n",
            "|->> Revisiting bbox: [288 131 104  97]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=6-th Action selection: 8/STOP (P(a|s) = 0.2329999953508377)\u001b[0m\n",
            "      |->> Bounding box moves to: [288 131 104  97]\n",
            "         |->> Action Probabilities (Rounded): [0.076  0.0672 0.0879 0.0646 0.0822 0.0605 0.1037 0.0863 0.2331 0.0621\n",
            " 0.0763], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.075983   0.06724986 0.08788998 0.06464034 0.08223581 0.06046138\n",
            " 0.10374337 0.08630335 0.23314385 0.06205244 0.07629666], argmax=8\n",
            "         |->> Hit a STOP on the 6-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [288, 131, 104,  97] -> [288, 131, 104,  97] (Target was [274, 133, 107, 103])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [288, 131, 104,  97] -> [288, 131, 104,  97] w/ P(a|s)=0.2331438511610031 and iou=0.7198142414860681 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [1.4560996]\n",
            "\u001b[92m>> Total frame loss: 1.4560996294021606\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1779 with src: [288, 131, 104,  97] and target: [276, 136, 105, 103]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1780.jpg\n",
            "|->> Beginning tracking for bbox:[288 131 104  97]\n",
            "   \u001b[33m|->> #0/t=6-th Action selection: 3/2X RIGHT (P(a|s) = 0.06499999761581421)\u001b[0m\n",
            "      |->> Bounding box moves to: [294 131 104  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0731 0.0687 0.0767 0.0648 0.075  0.0562 0.0956 0.0821 0.2764 0.0597\n",
            " 0.0717], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07311141 0.06868289 0.07665937 0.06477    0.07504069 0.05624843\n",
            " 0.09561571 0.08208159 0.27636927 0.05967921 0.07174148], argmax=8\n",
            "   \u001b[33m|->> #1/t=7-th Action selection: 3/2X RIGHT (P(a|s) = 0.052000001072883606)\u001b[0m\n",
            "      |->> Bounding box moves to: [300 131 104  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0688 0.0599 0.063  0.0524 0.0664 0.0526 0.0866 0.0769 0.3517 0.0512\n",
            " 0.0706], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06875318 0.0598925  0.06295641 0.05237193 0.06635769 0.05256033\n",
            " 0.08664913 0.07687844 0.35169852 0.05123701 0.07064484], argmax=8\n",
            "|->> Revisiting bbox: [300 131 104  97]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [288, 131, 104,  97] -> [300, 131, 104,  97] (Target was [276, 136, 105, 103])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.072) for 2X RIGHT:bbox transition: [288, 131, 104,  97] -> [294, 131, 104,  97] w/ P(a|s)=0.06476999819278717 and iou=0.6205132180789208 and reward=-0.07244863500279941 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [294, 131, 104,  97] -> [300, 131, 104,  97] w/ P(a|s)=0.05237193405628204 and iou=0.5540108542115828 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.1982856 -2.9493845]\n",
            "\u001b[31m>> Total frame loss: -3.147670030593872\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1780 with src: [300, 131, 104,  97] and target: [275, 133,  99,  98]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1781.jpg\n",
            "|->> Beginning tracking for bbox:[300 131 104  97]\n",
            "   \u001b[33m|->> #0/t=8-th Action selection: 0/LEFT (P(a|s) = 0.06499999761581421)\u001b[0m\n",
            "      |->> Bounding box moves to: [297 131 104  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0654 0.0617 0.0575 0.0455 0.0613 0.0455 0.0784 0.0706 0.4073 0.0475\n",
            " 0.0591], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06540205 0.06173775 0.05748695 0.04552833 0.06134648 0.04547331\n",
            " 0.07844368 0.07057135 0.40734923 0.04752195 0.05913898], argmax=8\n",
            "|->> Revisiting bbox: [297 131 104  97]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [300, 131, 104,  97] -> [297, 131, 104,  97] (Target was [275, 133,  99,  98])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for LEFT:bbox transition: [300, 131, 104,  97] -> [297, 131, 104,  97] w/ P(a|s)=0.06540205329656601 and iou=0.586372745490982 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.7272017]\n",
            "\u001b[31m>> Total frame loss: -2.7272017002105713\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1781 with src: [297, 131, 104,  97] and target: [276, 132, 102, 103]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1782.jpg\n",
            "|->> Beginning tracking for bbox:[297 131 104  97]\n",
            "   \u001b[33m|->> #0/t=9-th Action selection: 6/DOWN (P(a|s) = 0.07400000095367432)\u001b[0m\n",
            "      |->> Bounding box moves to: [297 133 104  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0542 0.0485 0.0629 0.0447 0.0594 0.0417 0.0738 0.0636 0.451  0.0426\n",
            " 0.0577], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05415534 0.0484754  0.06286099 0.04465239 0.05936232 0.04170618\n",
            " 0.07383685 0.06360611 0.4510407  0.0425676  0.05773604], argmax=8\n",
            "   \u001b[33m|->> #1/t=10-th Action selection: 0/LEFT (P(a|s) = 0.057999998331069946)\u001b[0m\n",
            "      |->> Bounding box moves to: [294 133 104  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0583 0.0526 0.0616 0.044  0.0628 0.0439 0.0765 0.0576 0.4423 0.04\n",
            " 0.0604], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05826361 0.05257533 0.06160477 0.04404699 0.06283104 0.04391502\n",
            " 0.07646202 0.05764528 0.44227654 0.0399552  0.06042409], argmax=8\n",
            "|->> Revisiting bbox: [297 133 104  97]. ACtion 2 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [297, 131, 104,  97] -> [294, 133, 104,  97] (Target was [276, 132, 102, 103])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.01) for DOWN:bbox transition: [297, 131, 104,  97] -> [297, 133, 104,  97] w/ P(a|s)=0.07383684813976288 and iou=0.6168642537489205 and reward=0.010217350955973092 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for LEFT:bbox transition: [297, 133, 104,  97] -> [294, 133, 104,  97] w/ P(a|s)=0.058263614773750305 and iou=0.6546681664791901 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.02662537 -2.8427775 ]\n",
            "\u001b[31m>> Total frame loss: -2.8161520957946777\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1782 with src: [294, 133, 104,  97] and target: [277, 130,  98,  96]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1783.jpg\n",
            "|->> Beginning tracking for bbox:[294 133 104  97]\n",
            "|->> Revisiting bbox: [294 133 104  97]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=11-th Action selection: 8/STOP (P(a|s) = 0.4399999976158142)\u001b[0m\n",
            "      |->> Bounding box moves to: [294 133 104  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0508 0.0489 0.0687 0.0501 0.0608 0.0468 0.0773 0.0601 0.4396 0.04\n",
            " 0.0568], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05083021 0.04892866 0.06873742 0.05010065 0.06084929 0.04679601\n",
            " 0.07728373 0.06009863 0.4396004  0.03997557 0.05679945], argmax=8\n",
            "         |->> Hit a STOP on the 11-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [294, 133, 104,  97] -> [294, 133, 104,  97] (Target was [277, 130,  98,  96])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [294, 133, 104,  97] -> [294, 133, 104,  97] w/ P(a|s)=0.43960040807724 and iou=0.629691548942573 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.82188916]\n",
            "\u001b[31m>> Total frame loss: -0.8218891620635986\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1783 with src: [294, 133, 104,  97] and target: [277, 131,  99,  94]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1784.jpg\n",
            "|->> Beginning tracking for bbox:[294 133 104  97]\n",
            "   \u001b[33m|->> #0/t=11-th Action selection: 6/DOWN (P(a|s) = 0.07800000160932541)\u001b[0m\n",
            "      |->> Bounding box moves to: [294 135 104  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0645 0.0519 0.0706 0.0527 0.0646 0.0494 0.0781 0.0599 0.4071 0.041\n",
            " 0.06  ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06451734 0.05194347 0.07063682 0.05274859 0.06463423 0.04943876\n",
            " 0.07807408 0.05992035 0.40706697 0.04102662 0.05999278], argmax=8\n",
            "|->> Revisiting bbox: [294 135 104  97]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [294, 133, 104,  97] -> [294, 135, 104,  97] (Target was [277, 131,  99,  94])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for DOWN:bbox transition: [294, 133, 104,  97] -> [294, 135, 104,  97] w/ P(a|s)=0.07807407528162003 and iou=0.6142833361078741 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.5500972]\n",
            "\u001b[31m>> Total frame loss: -2.5500972270965576\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1784 with src: [294, 135, 104,  97] and target: [275, 129, 106, 104]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1785.jpg\n",
            "|->> Beginning tracking for bbox:[294 135 104  97]\n",
            "|->> Revisiting bbox: [294 135 104  97]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=12-th Action selection: 8/STOP (P(a|s) = 0.4309999942779541)\u001b[0m\n",
            "      |->> Bounding box moves to: [294 135 104  97]\n",
            "         |->> Action Probabilities (Rounded): [0.059  0.0446 0.0678 0.0529 0.0641 0.0517 0.07   0.0582 0.4314 0.041\n",
            " 0.0594], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05898995 0.04457094 0.0677788  0.05293152 0.06408387 0.05166386\n",
            " 0.06999496 0.05821531 0.431381   0.04102499 0.05936482], argmax=8\n",
            "         |->> Hit a STOP on the 12-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [294, 135, 104,  97] -> [294, 135, 104,  97] (Target was [275, 129, 106, 104])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [294, 135, 104,  97] -> [294, 135, 104,  97] w/ P(a|s)=0.4313809871673584 and iou=0.665903890160183 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.8407636]\n",
            "\u001b[31m>> Total frame loss: -0.8407636284828186\u001b[0m\n",
            "Final bounding box: [294 135 104  97] reached in 12 timesteps (originating from [280 139  99  93]). Target was [275 129 106 104]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 1785 in t=12 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[31m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 7.9232964515686035\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 2.6644647121429443\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/Rubik\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Starting bounding box=adnet_datasets/OTB/Rubik/img/1786.jpg for adnet_datasets/OTB/Rubik's frames (index: 0)\n",
            "src:adnet_datasets/OTB/Rubik/img/1776.jpg\n",
            "target:adnet_datasets/OTB/Rubik/img/1786.jpg.\n",
            "\u001b[34m>> Attempting to reach frame 1776 with src: [280, 137,  97,  99] and target: [278, 137,  96, 104]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1777.jpg\n",
            "|->> Beginning tracking for bbox:[280 137  97  99]\n",
            "|->> Revisiting bbox: [280 137  97  99]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 8/STOP (P(a|s) = 0.11999999731779099)\u001b[0m\n",
            "      |->> Bounding box moves to: [280 137  97  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0885 0.0811 0.0936 0.0878 0.0915 0.0821 0.0957 0.0877 0.1201 0.0821\n",
            " 0.0897], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08852196 0.08106702 0.09361088 0.08778083 0.09154072 0.08213338\n",
            " 0.09572805 0.08771384 0.12010527 0.08214107 0.08965693], argmax=8\n",
            "         |->> Hit a STOP on the 1-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [280, 137,  97,  99] -> [280, 137,  97,  99] (Target was [278, 137,  96, 104])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [280, 137,  97,  99] -> [280, 137,  97,  99] w/ P(a|s)=0.12010527402162552 and iou=0.9051648672308141 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [2.1193867]\n",
            "\u001b[92m>> Total frame loss: 2.119386672973633\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1777 with src: [280, 137,  97,  99] and target: [274, 134, 102, 101]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1778.jpg\n",
            "|->> Beginning tracking for bbox:[280 137  97  99]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 10/SCALE UP (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [278 135  99 101]\n",
            "         |->> Action Probabilities (Rounded): [0.0887 0.0797 0.0959 0.0865 0.09   0.0804 0.0987 0.0863 0.1241 0.0794\n",
            " 0.0903], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08874731 0.07969897 0.09591953 0.08647913 0.09003653 0.08036827\n",
            " 0.09866048 0.08633489 0.12409197 0.07936985 0.09029303], argmax=8\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 5/2X UP (P(a|s) = 0.07800000160932541)\u001b[0m\n",
            "      |->> Bounding box moves to: [278 129  99 101]\n",
            "         |->> Action Probabilities (Rounded): [0.0827 0.0734 0.09   0.0861 0.0891 0.0783 0.0973 0.0864 0.1576 0.0779\n",
            " 0.0811], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08274983 0.07341903 0.09003178 0.08605623 0.08914927 0.0782644\n",
            " 0.09731304 0.08644981 0.15761743 0.07788404 0.08106517], argmax=8\n",
            "|->> Revisiting bbox: [278 129  99 101]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [280, 137,  97,  99] -> [278, 129,  99, 101] (Target was [274, 134, 102, 101])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.037) for SCALE UP:bbox transition: [280, 137,  97,  99] -> [278, 135,  99, 101] w/ P(a|s)=0.0902930274605751 and iou=0.9332444529092467 and reward=0.03698837974548563 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for 2X UP:bbox transition: [278, 135,  99, 101] -> [278, 129,  99, 101] w/ P(a|s)=0.07826440036296844 and iou=0.8636739190305701 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.08894578 2.5476625 ]\n",
            "\u001b[92m>> Total frame loss: 2.636608362197876\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1778 with src: [278, 129,  99, 101] and target: [274, 133, 107, 103]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1779.jpg\n",
            "|->> Beginning tracking for bbox:[278 129  99 101]\n",
            "   \u001b[33m|->> #0/t=3-th Action selection: 9/SCALE DOWN (P(a|s) = 0.07000000029802322)\u001b[0m\n",
            "      |->> Bounding box moves to: [279 130  96  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0798 0.0692 0.0907 0.0803 0.0852 0.0646 0.0992 0.095  0.1864 0.0701\n",
            " 0.0797], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0798178  0.06922653 0.09066941 0.0802602  0.08515148 0.06458909\n",
            " 0.09917048 0.09497314 0.1863971  0.07007989 0.07966495], argmax=8\n",
            "   \u001b[33m|->> #1/t=4-th Action selection: 3/2X RIGHT (P(a|s) = 0.08399999886751175)\u001b[0m\n",
            "      |->> Bounding box moves to: [283 130  96  97]\n",
            "         |->> Action Probabilities (Rounded): [0.0769 0.0653 0.0878 0.084  0.0816 0.0621 0.1008 0.088  0.2139 0.0612\n",
            " 0.0784], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07692483 0.06532738 0.08776969 0.08395293 0.08160448 0.06206907\n",
            " 0.10080352 0.08803573 0.21394876 0.06117317 0.0783905 ], argmax=8\n",
            "   \u001b[33m|->> #2/t=5-th Action selection: 10/SCALE UP (P(a|s) = 0.07699999958276749)\u001b[0m\n",
            "      |->> Bounding box moves to: [281 128  98  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0776 0.0711 0.0866 0.0705 0.081  0.0598 0.0951 0.083  0.2371 0.0611\n",
            " 0.0772], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07761703 0.0710625  0.08656836 0.07047986 0.08100546 0.05975094\n",
            " 0.09508717 0.08303578 0.23708123 0.0611336  0.07717807], argmax=8\n",
            "   \u001b[33m|->> #3/t=6-th Action selection: 6/DOWN (P(a|s) = 0.09399999678134918)\u001b[0m\n",
            "      |->> Bounding box moves to: [281 130  98  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0733 0.0616 0.0806 0.0717 0.0778 0.0566 0.0942 0.0834 0.2721 0.0593\n",
            " 0.0694], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07333235 0.0616235  0.0806359  0.07169501 0.07775212 0.05659651\n",
            " 0.09417967 0.08341508 0.27206743 0.05929677 0.06940565], argmax=8\n",
            "   \u001b[33m|->> #4/t=7-th Action selection: 6/DOWN (P(a|s) = 0.09000000357627869)\u001b[0m\n",
            "      |->> Bounding box moves to: [281 132  98  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0689 0.0578 0.0818 0.0668 0.0855 0.0569 0.0901 0.0784 0.2866 0.0568\n",
            " 0.0703], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06894421 0.05782335 0.08182563 0.06677705 0.08547762 0.05693702\n",
            " 0.09008859 0.07844505 0.28658316 0.05676677 0.07033152], argmax=8\n",
            "|->> Revisiting bbox: [281 132  98  99]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [278, 129,  99, 101] -> [281, 132,  98,  99] (Target was [274, 133, 107, 103])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.043) for SCALE DOWN:bbox transition: [278, 129,  99, 101] -> [279, 130,  96,  97] w/ P(a|s)=0.07007988542318344 and iou=0.7979485365637987 and reward=-0.043165591490856636 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for 2X RIGHT:bbox transition: [279, 130,  96,  97] -> [283, 130,  96,  97] w/ P(a|s)=0.08395292609930038 and iou=0.7979485365637987 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.002) for SCALE UP:bbox transition: [283, 130,  96,  97] -> [281, 128,  98,  99] w/ P(a|s)=0.07717806845903397 and iou=0.8002779949613413 and reward=0.0023294583975426164 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (0.031) for DOWN:bbox transition: [281, 128,  98,  99] -> [281, 130,  98,  99] w/ P(a|s)=0.0941796749830246 and iou=0.8314626601855943 and reward=0.031184665224253005 and discount=1.0\n",
            "   |->> t=5 Diff-Reward (1.0) for DOWN:bbox transition: [281, 130,  98,  99] -> [281, 132,  98,  99] w/ P(a|s)=0.09008859097957611 and iou=0.8637467398147315 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.1147393   0.          0.00596723  0.07367536  2.4069617 ]\n",
            "\u001b[92m>> Total frame loss: 2.3718650341033936\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1779 with src: [281, 132,  98,  99] and target: [276, 136, 105, 103]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1780.jpg\n",
            "|->> Beginning tracking for bbox:[281 132  98  99]\n",
            "|->> Revisiting bbox: [281 132  98  99]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=8-th Action selection: 8/STOP (P(a|s) = 0.33500000834465027)\u001b[0m\n",
            "      |->> Bounding box moves to: [281 132  98  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0682 0.0547 0.0768 0.0648 0.0758 0.0548 0.0816 0.0665 0.3347 0.0531\n",
            " 0.0691], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06817367 0.05468614 0.07675818 0.0647521  0.07577279 0.05480202\n",
            " 0.08163832 0.06650642 0.33469805 0.05313922 0.06907313], argmax=8\n",
            "         |->> Hit a STOP on the 8-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [281, 132,  98,  99] -> [281, 132,  98,  99] (Target was [276, 136, 105, 103])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [281, 132,  98,  99] -> [281, 132,  98,  99] w/ P(a|s)=0.33469805121421814 and iou=0.8307307932542161 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [1.0945265]\n",
            "\u001b[92m>> Total frame loss: 1.0945265293121338\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1780 with src: [281, 132,  98,  99] and target: [275, 133,  99,  98]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1781.jpg\n",
            "|->> Beginning tracking for bbox:[281 132  98  99]\n",
            "|->> Revisiting bbox: [281 132  98  99]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=8-th Action selection: 8/STOP (P(a|s) = 0.3490000069141388)\u001b[0m\n",
            "      |->> Bounding box moves to: [281 132  98  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0664 0.0523 0.0802 0.0615 0.0721 0.0553 0.0822 0.0653 0.3486 0.047\n",
            " 0.0691], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06644352 0.05227325 0.08020715 0.06150923 0.07206915 0.05525398\n",
            " 0.08222066 0.06530181 0.34857827 0.04699618 0.06914678], argmax=8\n",
            "         |->> Hit a STOP on the 8-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [281, 132,  98,  99] -> [281, 132,  98,  99] (Target was [275, 133,  99,  98])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [281, 132,  98,  99] -> [281, 132,  98,  99] w/ P(a|s)=0.3485782742500305 and iou=0.8857142857142857 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [1.0538925]\n",
            "\u001b[92m>> Total frame loss: 1.0538924932479858\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1781 with src: [281, 132,  98,  99] and target: [276, 132, 102, 103]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1782.jpg\n",
            "|->> Beginning tracking for bbox:[281 132  98  99]\n",
            "   \u001b[33m|->> #0/t=8-th Action selection: 3/2X RIGHT (P(a|s) = 0.0560000017285347)\u001b[0m\n",
            "      |->> Bounding box moves to: [285 132  98  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0629 0.0505 0.0693 0.0562 0.0686 0.0524 0.0799 0.0607 0.3874 0.0462\n",
            " 0.0659], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0628866  0.0504959  0.06929444 0.05620844 0.06861837 0.05238146\n",
            " 0.07987529 0.06073556 0.3874451  0.04616559 0.06589326], argmax=8\n",
            "   \u001b[33m|->> #1/t=9-th Action selection: 3/2X RIGHT (P(a|s) = 0.04800000041723251)\u001b[0m\n",
            "      |->> Bounding box moves to: [289 132  98  99]\n",
            "         |->> Action Probabilities (Rounded): [0.0605 0.0513 0.0577 0.0484 0.0604 0.0512 0.0741 0.06   0.4279 0.0452\n",
            " 0.0632], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06053622 0.05132867 0.05771445 0.04840528 0.06041315 0.05115511\n",
            " 0.07411601 0.06004754 0.4278542  0.04519127 0.06323804], argmax=8\n",
            "   \u001b[33m|->> #2/t=10-th Action selection: 9/SCALE DOWN (P(a|s) = 0.03999999910593033)\u001b[0m\n",
            "      |->> Bounding box moves to: [290 133  95  96]\n",
            "         |->> Action Probabilities (Rounded): [0.0615 0.0534 0.0535 0.0439 0.0615 0.0462 0.0681 0.058  0.4545 0.0403\n",
            " 0.0592], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06151767 0.05335467 0.05352119 0.04386498 0.06145874 0.04622258\n",
            " 0.06809834 0.05801485 0.45445266 0.04026188 0.0592324 ], argmax=8\n",
            "   \u001b[33m|->> #3/t=11-th Action selection: 2/RIGHT (P(a|s) = 0.05700000002980232)\u001b[0m\n",
            "      |->> Bounding box moves to: [292 133  95  96]\n",
            "         |->> Action Probabilities (Rounded): [0.0549 0.0473 0.0571 0.0463 0.063  0.0442 0.0685 0.0547 0.4677 0.0369\n",
            " 0.0594], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05489108 0.04730195 0.05709207 0.04625757 0.06301909 0.04421987\n",
            " 0.06849772 0.05469766 0.46772498 0.03686622 0.05943182], argmax=8\n",
            "|->> Revisiting bbox: [292 133  95  96]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [281, 132,  98,  99] -> [292, 133,  95,  96] (Target was [276, 132, 102, 103])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.069) for 2X RIGHT:bbox transition: [281, 132,  98,  99] -> [285, 132,  98,  99] w/ P(a|s)=0.05620843544602394 and iou=0.8369239160076357 and reward=-0.06859234990466978 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.064) for 2X RIGHT:bbox transition: [285, 132,  98,  99] -> [289, 132,  98,  99] w/ P(a|s)=0.048405278474092484 and iou=0.7730981837325612 and reward=-0.06382573227507449 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.017) for SCALE DOWN:bbox transition: [289, 132,  98,  99] -> [290, 133,  95,  96] w/ P(a|s)=0.040261879563331604 and iou=0.7557702630166399 and reward=-0.017327920715921374 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (1.0) for RIGHT:bbox transition: [290, 133,  95,  96] -> [292, 133,  95,  96] w/ P(a|s)=0.05709207057952881 and iou=0.7261213720316623 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.19745599 -0.19327368 -0.05566335  2.86309   ]\n",
            "\u001b[92m>> Total frame loss: 2.4166970252990723\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1782 with src: [292, 133,  95,  96] and target: [277, 130,  98,  96]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1783.jpg\n",
            "|->> Beginning tracking for bbox:[292 133  95  96]\n",
            "   \u001b[33m|->> #0/t=12-th Action selection: 9/SCALE DOWN (P(a|s) = 0.04100000113248825)\u001b[0m\n",
            "      |->> Bounding box moves to: [293 134  92  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0631 0.0542 0.0552 0.045  0.0668 0.0468 0.0757 0.0587 0.432  0.0408\n",
            " 0.0618], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06308241 0.05424533 0.05517397 0.04499359 0.06679511 0.04680771\n",
            " 0.07568678 0.05865267 0.43202496 0.04075892 0.06177854], argmax=8\n",
            "   \u001b[33m|->> #1/t=13-th Action selection: 7/2X DOWN (P(a|s) = 0.05900000035762787)\u001b[0m\n",
            "      |->> Bounding box moves to: [293 138  92  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0567 0.0531 0.0576 0.0481 0.0667 0.0455 0.0727 0.0594 0.4429 0.0374\n",
            " 0.0599], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0566895  0.05309715 0.05764451 0.04813394 0.06668393 0.04554021\n",
            " 0.0727491  0.05936685 0.44288507 0.03735717 0.05985259], argmax=8\n",
            "   \u001b[33m|->> #2/t=14-th Action selection: 10/SCALE UP (P(a|s) = 0.06300000101327896)\u001b[0m\n",
            "      |->> Bounding box moves to: [291 136  94  95]\n",
            "         |->> Action Probabilities (Rounded): [0.0584 0.0522 0.0622 0.0486 0.0724 0.0511 0.071  0.0551 0.4262 0.0403\n",
            " 0.0626], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05839569 0.0521784  0.06216173 0.04859346 0.07239348 0.05113343\n",
            " 0.07099093 0.05507311 0.426185   0.04027699 0.06261776], argmax=8\n",
            "|->> Revisiting bbox: [291 136  94  95]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [292, 133,  95,  96] -> [291, 136,  94,  95] (Target was [277, 130,  98,  96])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.01) for SCALE DOWN:bbox transition: [292, 133,  95,  96] -> [293, 134,  92,  93] w/ P(a|s)=0.040758922696113586 and iou=0.7239923224568138 and reward=0.009865206164834883 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.053) for 2X DOWN:bbox transition: [293, 134,  92,  93] -> [293, 138,  92,  93] w/ P(a|s)=0.059366848319768906 and iou=0.6713807219947897 and reward=-0.052611600462024066 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (1.0) for SCALE UP:bbox transition: [293, 138,  92,  93] -> [291, 136,  94,  95] w/ P(a|s)=0.06261776387691498 and iou=0.7014288365188347 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.03156945 -0.14857619  2.7707062 ]\n",
            "\u001b[92m>> Total frame loss: 2.6536993980407715\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1783 with src: [291, 136,  94,  95] and target: [277, 131,  99,  94]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1784.jpg\n",
            "|->> Beginning tracking for bbox:[291 136  94  95]\n",
            "   \u001b[33m|->> #0/t=15-th Action selection: 4/UP (P(a|s) = 0.06499999761581421)\u001b[0m\n",
            "      |->> Bounding box moves to: [291 134  94  95]\n",
            "         |->> Action Probabilities (Rounded): [0.0613 0.0527 0.0636 0.0529 0.0647 0.0512 0.0741 0.0555 0.4216 0.0419\n",
            " 0.0606], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06126194 0.05274319 0.06360258 0.05289641 0.06466127 0.05117891\n",
            " 0.07413076 0.05553659 0.42155766 0.04186786 0.06056277], argmax=8\n",
            "   \u001b[33m|->> #1/t=16-th Action selection: 0/LEFT (P(a|s) = 0.06700000166893005)\u001b[0m\n",
            "      |->> Bounding box moves to: [289 134  94  95]\n",
            "         |->> Action Probabilities (Rounded): [0.0673 0.0504 0.0622 0.0506 0.071  0.055  0.0803 0.0594 0.3969 0.0418\n",
            " 0.0651], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06725471 0.05037652 0.06218223 0.05058954 0.07104462 0.05500433\n",
            " 0.08027167 0.05940293 0.39693993 0.04181608 0.06511748], argmax=8\n",
            "|->> Revisiting bbox: [289 134  94  95]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [291, 136,  94,  95] -> [289, 134,  94,  95] (Target was [277, 131,  99,  94])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.028) for UP:bbox transition: [291, 136,  94,  95] -> [291, 134,  94,  95] w/ P(a|s)=0.06466127187013626 and iou=0.7365965146176554 and reward=0.027665767733577096 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for LEFT:bbox transition: [291, 134,  94,  95] -> [289, 134,  94,  95] w/ P(a|s)=0.06725470721721649 and iou=0.7672255063475143 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.07576527 2.6992683 ]\n",
            "\u001b[92m>> Total frame loss: 2.775033712387085\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1784 with src: [289, 134,  94,  95] and target: [275, 129, 106, 104]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1785.jpg\n",
            "|->> Beginning tracking for bbox:[289 134  94  95]\n",
            "|->> Revisiting bbox: [289 134  94  95]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=17-th Action selection: 8/STOP (P(a|s) = 0.42100000381469727)\u001b[0m\n",
            "      |->> Bounding box moves to: [289 134  94  95]\n",
            "         |->> Action Probabilities (Rounded): [0.0567 0.0458 0.0688 0.0551 0.0658 0.0503 0.0753 0.0586 0.421  0.0415\n",
            " 0.0611], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05666501 0.04582177 0.06883702 0.05512347 0.06581618 0.05027609\n",
            " 0.07532808 0.05858804 0.4209551  0.04148704 0.06110218], argmax=8\n",
            "         |->> Hit a STOP on the 17-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [289, 134,  94,  95] -> [289, 134,  94,  95] (Target was [275, 129, 106, 104])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [289, 134,  94,  95] -> [289, 134,  94,  95] w/ P(a|s)=0.420955091714859 and iou=0.7793829142143749 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.8652291]\n",
            "\u001b[92m>> Total frame loss: 0.8652291297912598\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1785 with src: [289, 134,  94,  95] and target: [274, 125, 108, 105]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1786.jpg\n",
            "|->> Beginning tracking for bbox:[289 134  94  95]\n",
            "|->> Revisiting bbox: [289 134  94  95]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=17-th Action selection: 8/STOP (P(a|s) = 0.37700000405311584)\u001b[0m\n",
            "      |->> Bounding box moves to: [289 134  94  95]\n",
            "         |->> Action Probabilities (Rounded): [0.0666 0.051  0.0756 0.0564 0.0687 0.0532 0.0846 0.0603 0.3765 0.0422\n",
            " 0.0649], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06660898 0.05098912 0.07562187 0.05639329 0.06866204 0.05320707\n",
            " 0.08459607 0.06026725 0.37653393 0.0422481  0.06487232], argmax=8\n",
            "         |->> Hit a STOP on the 17-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [289, 134,  94,  95] -> [289, 134,  94,  95] (Target was [274, 125, 108, 105])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [289, 134,  94,  95] -> [289, 134,  94,  95] w/ P(a|s)=0.3765339255332947 and iou=0.7726278968080454 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.97674716]\n",
            "\u001b[92m>> Total frame loss: 0.9767471551895142\u001b[0m\n",
            "Final bounding box: [289 134  94  95] reached in 17 timesteps (originating from [280 137  97  99]). Target was [274 125 108 105]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 1786 in t=17 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[92m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 7.611282825469971\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 2.395498752593994\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/Rubik\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Starting bounding box=adnet_datasets/OTB/Rubik/img/1787.jpg for adnet_datasets/OTB/Rubik's frames (index: 0)\n",
            "src:adnet_datasets/OTB/Rubik/img/1777.jpg\n",
            "target:adnet_datasets/OTB/Rubik/img/1787.jpg.\n",
            "\u001b[34m>> Attempting to reach frame 1777 with src: [278, 137,  96, 104] and target: [274, 134, 102, 101]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1778.jpg\n",
            "|->> Beginning tracking for bbox:[278 137  96 104]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 9/SCALE DOWN (P(a|s) = 0.0820000022649765)\u001b[0m\n",
            "      |->> Bounding box moves to: [279 138  93 100]\n",
            "         |->> Action Probabilities (Rounded): [0.0885 0.0811 0.0936 0.0878 0.0915 0.0821 0.0957 0.0877 0.1201 0.0821\n",
            " 0.0897], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08851972 0.08106543 0.09360913 0.08777795 0.09154546 0.08213247\n",
            " 0.09572923 0.08771662 0.12010501 0.08214065 0.0896583 ], argmax=8\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 5/2X UP (P(a|s) = 0.07800000160932541)\u001b[0m\n",
            "      |->> Bounding box moves to: [279 132  93 100]\n",
            "         |->> Action Probabilities (Rounded): [0.0868 0.0785 0.0921 0.0886 0.0911 0.0781 0.0963 0.0875 0.1379 0.0727\n",
            " 0.0903], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08679997 0.07849564 0.09206497 0.08864474 0.09111296 0.07813881\n",
            " 0.09632408 0.08750231 0.13792346 0.07267353 0.09031956], argmax=8\n",
            "   \u001b[33m|->> #2/t=3-th Action selection: 10/SCALE UP (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [277 130  95 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0836 0.0756 0.0919 0.0827 0.0884 0.0689 0.0994 0.0937 0.1592 0.069\n",
            " 0.0875], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08356437 0.07563119 0.09190628 0.08274412 0.08840919 0.06888203\n",
            " 0.09942081 0.0937455  0.15923962 0.06896169 0.08749516], argmax=8\n",
            "   \u001b[33m|->> #3/t=4-th Action selection: 5/2X UP (P(a|s) = 0.06800000369548798)\u001b[0m\n",
            "      |->> Bounding box moves to: [277 124  95 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0795 0.0684 0.0922 0.0844 0.087  0.0678 0.1041 0.0911 0.1784 0.0692\n",
            " 0.0778], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07950059 0.06838474 0.09220087 0.08442672 0.08699878 0.06782608\n",
            " 0.10407539 0.09112782 0.1784164  0.06922021 0.07782246], argmax=8\n",
            "|->> Revisiting bbox: [277 124  95 103]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [278, 137,  96, 104] -> [277, 124,  95, 103] (Target was [274, 134, 102, 101])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.012) for SCALE DOWN:bbox transition: [278, 137,  96, 104] -> [279, 138,  93, 100] w/ P(a|s)=0.08214065432548523 and iou=0.8525659200453644 and reward=-0.012298944819500557 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.016) for 2X UP:bbox transition: [279, 138,  93, 100] -> [279, 132,  93, 100] w/ P(a|s)=0.0781388059258461 and iou=0.8689931350114416 and reward=0.01642721496607724 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (0.011) for SCALE UP:bbox transition: [279, 132,  93, 100] -> [277, 130,  95, 103] w/ P(a|s)=0.08749516308307648 and iou=0.8804530986706609 and reward=0.011459963659219308 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (1.0) for 2X UP:bbox transition: [277, 130,  95, 103] -> [277, 124,  95, 103] w/ P(a|s)=0.06782608479261398 and iou=0.7851937433345183 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.03073902  0.04187738  0.02791844  2.6908085 ]\n",
            "\u001b[92m>> Total frame loss: 2.729865312576294\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1778 with src: [277, 124,  95, 103] and target: [274, 133, 107, 103]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1779.jpg\n",
            "|->> Beginning tracking for bbox:[277 124  95 103]\n",
            "   \u001b[33m|->> #0/t=5-th Action selection: 5/2X UP (P(a|s) = 0.0560000017285347)\u001b[0m\n",
            "      |->> Bounding box moves to: [277 118  95 103]\n",
            "         |->> Action Probabilities (Rounded): [0.077  0.0671 0.0898 0.0777 0.0846 0.0563 0.1024 0.0986 0.2021 0.0657\n",
            " 0.0786], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07700302 0.0671326  0.08980773 0.07767747 0.08455513 0.05633593\n",
            " 0.10238399 0.09859757 0.20213093 0.06573248 0.07864314], argmax=8\n",
            "|->> Revisiting bbox: [277 124  95 103]. ACtion 7 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [277, 124,  95, 103] -> [277, 118,  95, 103] (Target was [274, 133, 107, 103])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for 2X UP:bbox transition: [277, 124,  95, 103] -> [277, 118,  95, 103] w/ P(a|s)=0.0563359297811985 and iou=0.6717017515667685 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.876423]\n",
            "\u001b[31m>> Total frame loss: -2.876422882080078\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1779 with src: [277, 118,  95, 103] and target: [276, 136, 105, 103]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1780.jpg\n",
            "|->> Beginning tracking for bbox:[277 118  95 103]\n",
            "|->> Revisiting bbox: [277 118  95 103]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=6-th Action selection: 8/STOP (P(a|s) = 0.2329999953508377)\u001b[0m\n",
            "      |->> Bounding box moves to: [277 118  95 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0746 0.0607 0.0873 0.0779 0.0751 0.0513 0.1034 0.1002 0.2326 0.0603\n",
            " 0.0766], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07455202 0.0606964  0.08730912 0.07785834 0.07509386 0.05132067\n",
            " 0.10341623 0.10023579 0.23260397 0.06034938 0.07656427], argmax=8\n",
            "         |->> Hit a STOP on the 6-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [277, 118,  95, 103] -> [277, 118,  95, 103] (Target was [276, 136, 105, 103])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [277, 118,  95, 103] -> [277, 118,  95, 103] w/ P(a|s)=0.23260396718978882 and iou=0.6447105788423154 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-1.458418]\n",
            "\u001b[31m>> Total frame loss: -1.4584180116653442\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1780 with src: [277, 118,  95, 103] and target: [275, 133,  99,  98]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1781.jpg\n",
            "|->> Beginning tracking for bbox:[277 118  95 103]\n",
            "   \u001b[33m|->> #0/t=6-th Action selection: 7/2X DOWN (P(a|s) = 0.09700000286102295)\u001b[0m\n",
            "      |->> Bounding box moves to: [277 124  95 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0721 0.0606 0.0915 0.076  0.0762 0.0532 0.1021 0.0972 0.239  0.0594\n",
            " 0.0727], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07210821 0.06056944 0.09149788 0.07597011 0.07621574 0.05315712\n",
            " 0.10214836 0.09724473 0.23899092 0.05939206 0.07270537], argmax=8\n",
            "   \u001b[33m|->> #1/t=7-th Action selection: 4/UP (P(a|s) = 0.07599999755620956)\u001b[0m\n",
            "      |->> Bounding box moves to: [277 121  95 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0668 0.0535 0.0806 0.0719 0.0756 0.0492 0.0902 0.0811 0.302  0.0574\n",
            " 0.0715], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06684612 0.05345527 0.08062815 0.07191142 0.07564075 0.04918366\n",
            " 0.09023958 0.08110476 0.30204815 0.05743902 0.07150315], argmax=8\n",
            "|->> Revisiting bbox: [277 121  95 103]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [277, 118,  95, 103] -> [277, 121,  95, 103] (Target was [275, 133,  99,  98])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.095) for 2X DOWN:bbox transition: [277, 118,  95, 103] -> [277, 124,  95, 103] w/ P(a|s)=0.0972447320818901 and iou=0.8458842474187743 and reward=0.09455864303304595 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for UP:bbox transition: [277, 124,  95, 103] -> [277, 121,  95, 103] w/ P(a|s)=0.07564075291156769 and iou=0.7973621103117506 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.22037123 2.5817602 ]\n",
            "\u001b[92m>> Total frame loss: 2.802131414413452\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1781 with src: [277, 121,  95, 103] and target: [276, 132, 102, 103]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1782.jpg\n",
            "|->> Beginning tracking for bbox:[277 121  95 103]\n",
            "   \u001b[33m|->> #0/t=8-th Action selection: 10/SCALE UP (P(a|s) = 0.06499999761581421)\u001b[0m\n",
            "      |->> Bounding box moves to: [275 119  97 106]\n",
            "         |->> Action Probabilities (Rounded): [0.063  0.0496 0.0785 0.0678 0.0638 0.0476 0.086  0.0791 0.3511 0.0489\n",
            " 0.0646], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06302673 0.04956853 0.07846066 0.06783905 0.06375317 0.04763839\n",
            " 0.08596992 0.07914851 0.3511067  0.04890169 0.06458666], argmax=8\n",
            "   \u001b[33m|->> #1/t=9-th Action selection: 1/2X LEFT (P(a|s) = 0.04699999839067459)\u001b[0m\n",
            "      |->> Bounding box moves to: [271 119  97 106]\n",
            "         |->> Action Probabilities (Rounded): [0.0604 0.0468 0.0712 0.0636 0.0654 0.046  0.0805 0.071  0.389  0.049\n",
            " 0.0571], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06037355 0.04675135 0.07118358 0.06360218 0.06543505 0.04602629\n",
            " 0.08050143 0.07101122 0.38903558 0.04902954 0.05705014], argmax=8\n",
            "   \u001b[33m|->> #2/t=10-th Action selection: 5/2X UP (P(a|s) = 0.03799999877810478)\u001b[0m\n",
            "      |->> Bounding box moves to: [271 113  97 106]\n",
            "         |->> Action Probabilities (Rounded): [0.0505 0.037  0.0724 0.0619 0.0581 0.0382 0.0828 0.0617 0.443  0.0401\n",
            " 0.0543], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05052164 0.03695066 0.07242151 0.06190817 0.05813339 0.03824714\n",
            " 0.08275554 0.0616894  0.4429709  0.04008163 0.05432006], argmax=8\n",
            "|->> Revisiting bbox: [271 113  97 106]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [277, 121,  95, 103] -> [271, 113,  97, 106] (Target was [276, 132, 102, 103])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.004) for SCALE UP:bbox transition: [277, 121,  95, 103] -> [275, 119,  97, 106] w/ P(a|s)=0.06458666175603867 and iou=0.7527824620573356 and reward=-0.0038619843109442 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.053) for 2X LEFT:bbox transition: [275, 119,  97, 106] -> [271, 119,  97, 106] w/ P(a|s)=0.046751346439123154 and iou=0.6994767822105952 and reward=-0.053305679846740395 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-1.0) for 2X UP:bbox transition: [271, 119,  97, 106] -> [271, 113,  97, 106] w/ P(a|s)=0.03824714198708534 and iou=0.6260951188986232 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.01058086 -0.16327061 -3.2636864 ]\n",
            "\u001b[31m>> Total frame loss: -3.437537908554077\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1782 with src: [271, 113,  97, 106] and target: [277, 130,  98,  96]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1783.jpg\n",
            "|->> Beginning tracking for bbox:[271 113  97 106]\n",
            "|->> Revisiting bbox: [271 113  97 106]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=11-th Action selection: 8/STOP (P(a|s) = 0.460999995470047)\u001b[0m\n",
            "      |->> Bounding box moves to: [271 113  97 106]\n",
            "         |->> Action Probabilities (Rounded): [0.0503 0.0369 0.0674 0.0578 0.054  0.035  0.0792 0.0671 0.4615 0.04\n",
            " 0.0509], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05026149 0.03690157 0.06740822 0.05779615 0.05397641 0.03499907\n",
            " 0.07923034 0.0670769  0.4614637  0.03996252 0.05092361], argmax=8\n",
            "         |->> Hit a STOP on the 11-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [271, 113,  97, 106] -> [271, 113,  97, 106] (Target was [277, 130,  98,  96])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [271, 113,  97, 106] -> [271, 113,  97, 106] w/ P(a|s)=0.46146368980407715 and iou=0.6987317746527478 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.7733519]\n",
            "\u001b[31m>> Total frame loss: -0.7733519077301025\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1783 with src: [271, 113,  97, 106] and target: [277, 131,  99,  94]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1784.jpg\n",
            "|->> Beginning tracking for bbox:[271 113  97 106]\n",
            "|->> Revisiting bbox: [271 113  97 106]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=11-th Action selection: 8/STOP (P(a|s) = 0.40700000524520874)\u001b[0m\n",
            "      |->> Bounding box moves to: [271 113  97 106]\n",
            "         |->> Action Probabilities (Rounded): [0.0519 0.0414 0.0725 0.064  0.0638 0.0431 0.0868 0.0694 0.4073 0.0444\n",
            " 0.0554], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05189257 0.04142886 0.0724967  0.06401116 0.06375282 0.04313073\n",
            " 0.08684805 0.06935494 0.40727392 0.0443887  0.05542152], argmax=8\n",
            "         |->> Hit a STOP on the 11-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [271, 113,  97, 106] -> [271, 113,  97, 106] (Target was [277, 131,  99,  94])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [271, 113,  97, 106] -> [271, 113,  97, 106] w/ P(a|s)=0.40727391839027405 and iou=0.6915371329879102 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.8982693]\n",
            "\u001b[31m>> Total frame loss: -0.8982692956924438\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1784 with src: [271, 113,  97, 106] and target: [275, 129, 106, 104]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1785.jpg\n",
            "|->> Beginning tracking for bbox:[271 113  97 106]\n",
            "   \u001b[33m|->> #0/t=11-th Action selection: 9/SCALE DOWN (P(a|s) = 0.041999999433755875)\u001b[0m\n",
            "      |->> Bounding box moves to: [272 114  94 102]\n",
            "         |->> Action Probabilities (Rounded): [0.0534 0.043  0.0726 0.0594 0.0598 0.0417 0.0845 0.0702 0.4189 0.042\n",
            " 0.0545], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05337132 0.04301488 0.07257779 0.05939265 0.05977453 0.04166535\n",
            " 0.08451995 0.0702381  0.4189438  0.04196626 0.05453533], argmax=8\n",
            "|->> Revisiting bbox: [272 114  94 102]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [271, 113,  97, 106] -> [272, 114,  94, 102] (Target was [275, 129, 106, 104])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for SCALE DOWN:bbox transition: [271, 113,  97, 106] -> [272, 114,  94, 102] w/ P(a|s)=0.041966259479522705 and iou=0.6236313509255612 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-3.1708894]\n",
            "\u001b[31m>> Total frame loss: -3.170889377593994\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1785 with src: [272, 114,  94, 102] and target: [274, 125, 108, 105]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1786.jpg\n",
            "|->> Beginning tracking for bbox:[272 114  94 102]\n",
            "   \u001b[33m|->> #0/t=12-th Action selection: 6/DOWN (P(a|s) = 0.07500000298023224)\u001b[0m\n",
            "      |->> Bounding box moves to: [272 117  94 102]\n",
            "         |->> Action Probabilities (Rounded): [0.0526 0.0399 0.0646 0.0622 0.059  0.0404 0.0749 0.0667 0.4431 0.0378\n",
            " 0.0588], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05260998 0.03989186 0.06457496 0.06215912 0.05899622 0.04036709\n",
            " 0.07491919 0.06665067 0.44314626 0.03784394 0.0588407 ], argmax=8\n",
            "|->> Revisiting bbox: [272 117  94 102]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [272, 114,  94, 102] -> [272, 117,  94, 102] (Target was [274, 125, 108, 105])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for DOWN:bbox transition: [272, 114,  94, 102] -> [272, 117,  94, 102] w/ P(a|s)=0.0749191865324974 and iou=0.7042345276872964 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [2.5913453]\n",
            "\u001b[92m>> Total frame loss: 2.5913453102111816\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1786 with src: [272, 117,  94, 102] and target: [274, 124, 101, 101]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1787.jpg\n",
            "|->> Beginning tracking for bbox:[272 117  94 102]\n",
            "   \u001b[33m|->> #0/t=13-th Action selection: 3/2X RIGHT (P(a|s) = 0.06199999898672104)\u001b[0m\n",
            "      |->> Bounding box moves to: [276 117  94 102]\n",
            "         |->> Action Probabilities (Rounded): [0.0537 0.0394 0.0623 0.0623 0.0647 0.0433 0.071  0.0609 0.4466 0.0395\n",
            " 0.0563], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05366847 0.03940417 0.06225142 0.0622618  0.06468038 0.04333017\n",
            " 0.07102048 0.06090708 0.44659635 0.03953281 0.05634682], argmax=8\n",
            "   \u001b[33m|->> #1/t=14-th Action selection: 9/SCALE DOWN (P(a|s) = 0.039000000804662704)\u001b[0m\n",
            "      |->> Bounding box moves to: [277 118  91  98]\n",
            "         |->> Action Probabilities (Rounded): [0.0536 0.0413 0.0627 0.0549 0.0611 0.0417 0.0698 0.0553 0.4639 0.0387\n",
            " 0.0571], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05357587 0.04128625 0.06266344 0.05488078 0.06106803 0.04165054\n",
            " 0.06975785 0.05532819 0.46393123 0.03871408 0.05714373], argmax=8\n",
            "|->> Revisiting bbox: [277 118  91  98]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [272, 117,  94, 102] -> [277, 118,  91,  98] (Target was [274, 124, 101, 101])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.031) for 2X RIGHT:bbox transition: [272, 117,  94, 102] -> [276, 117,  94, 102] w/ P(a|s)=0.06226179748773575 and iou=0.8223593332719403 and reward=0.031337521343258956 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (1.0) for SCALE DOWN:bbox transition: [276, 117,  94, 102] -> [277, 118,  91,  98] w/ P(a|s)=0.038714077323675156 and iou=0.7790080952824044 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.08700572 3.251552  ]\n",
            "\u001b[92m>> Total frame loss: 3.338557720184326\u001b[0m\n",
            "Final bounding box: [277 118  91  98] reached in 15 timesteps (originating from [278 137  96 104]). Target was [274 124 101 101]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 1787 in t=15 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[31m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 8.565075874328613\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 2.9403765201568604\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/Rubik\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Starting bounding box=adnet_datasets/OTB/Rubik/img/1788.jpg for adnet_datasets/OTB/Rubik's frames (index: 0)\n",
            "src:adnet_datasets/OTB/Rubik/img/1778.jpg\n",
            "target:adnet_datasets/OTB/Rubik/img/1788.jpg.\n",
            "\u001b[34m>> Attempting to reach frame 1778 with src: [274, 134, 102, 101] and target: [274, 133, 107, 103]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1779.jpg\n",
            "|->> Beginning tracking for bbox:[274 134 102 101]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 7/2X DOWN (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [274 140 102 101]\n",
            "         |->> Action Probabilities (Rounded): [0.0885 0.0811 0.0936 0.0878 0.0916 0.0821 0.0957 0.0877 0.1201 0.0821\n",
            " 0.0897], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08851777 0.08106399 0.09360766 0.08777549 0.09155089 0.08213061\n",
            " 0.09573149 0.08771932 0.12010282 0.08214033 0.0896596 ], argmax=8\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 0/LEFT (P(a|s) = 0.0860000029206276)\u001b[0m\n",
            "      |->> Bounding box moves to: [271 140 102 101]\n",
            "         |->> Action Probabilities (Rounded): [0.0862 0.0774 0.0951 0.0854 0.0943 0.0833 0.0915 0.08   0.1374 0.0817\n",
            " 0.0877], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08623916 0.07740165 0.0950821  0.0854359  0.09426243 0.08325241\n",
            " 0.0914861  0.07998426 0.13744745 0.08170887 0.08769962], argmax=8\n",
            "   \u001b[33m|->> #2/t=3-th Action selection: 0/LEFT (P(a|s) = 0.07599999755620956)\u001b[0m\n",
            "      |->> Bounding box moves to: [268 140 102 101]\n",
            "         |->> Action Probabilities (Rounded): [0.0763 0.0721 0.1038 0.0887 0.0918 0.0825 0.0923 0.0785 0.1546 0.0742\n",
            " 0.0853], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07631735 0.07209317 0.10378218 0.08868141 0.09179007 0.08245125\n",
            " 0.09228199 0.07849108 0.15464954 0.07416556 0.08529642], argmax=8\n",
            "   \u001b[33m|->> #3/t=4-th Action selection: 1/2X LEFT (P(a|s) = 0.06700000166893005)\u001b[0m\n",
            "      |->> Bounding box moves to: [262 140 102 101]\n",
            "         |->> Action Probabilities (Rounded): [0.0742 0.0667 0.104  0.0887 0.0924 0.0802 0.0953 0.0754 0.1716 0.0683\n",
            " 0.0833], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07424944 0.06667915 0.10400395 0.08869407 0.09238668 0.0801805\n",
            " 0.09531897 0.07541477 0.17155933 0.06825911 0.08325402], argmax=8\n",
            "|->> Revisiting bbox: [268 140 102 101]. ACtion 3 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [274, 134, 102, 101] -> [262, 140, 102, 101] (Target was [274, 133, 107, 103])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.086) for 2X DOWN:bbox transition: [274, 134, 102, 101] -> [274, 140, 102, 101] w/ P(a|s)=0.08771932125091553 and iou=0.8491891423120285 and reward=-0.08557176867608518 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.045) for LEFT:bbox transition: [274, 140, 102, 101] -> [271, 140, 102, 101] w/ P(a|s)=0.08623915910720825 and iou=0.804128944919198 and reward=-0.045060197392830514 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.043) for LEFT:bbox transition: [271, 140, 102, 101] -> [268, 140, 102, 101] w/ P(a|s)=0.07631734758615494 and iou=0.7612125216816717 and reward=-0.0429164232375262 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [268, 140, 102, 101] -> [262, 140, 102, 101] w/ P(a|s)=0.06667914986610413 and iou=0.6812268390759284 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.20824857 -0.11042592 -0.11041774 -2.707863  ]\n",
            "\u001b[31m>> Total frame loss: -3.136955499649048\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1779 with src: [262, 140, 102, 101] and target: [276, 136, 105, 103]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1780.jpg\n",
            "|->> Beginning tracking for bbox:[262 140 102 101]\n",
            "|->> Revisiting bbox: [262 140 102 101]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=5-th Action selection: 8/STOP (P(a|s) = 0.20499999821186066)\u001b[0m\n",
            "      |->> Bounding box moves to: [262 140 102 101]\n",
            "         |->> Action Probabilities (Rounded): [0.0749 0.0556 0.1026 0.0931 0.0876 0.0736 0.0933 0.0718 0.2053 0.064\n",
            " 0.0781], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07486799 0.05563049 0.10260504 0.09314784 0.08764832 0.07362381\n",
            " 0.09329142 0.07175548 0.20529708 0.06398735 0.07814521], argmax=8\n",
            "         |->> Hit a STOP on the 5-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [262, 140, 102, 101] -> [262, 140, 102, 101] (Target was [276, 136, 105, 103])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [262, 140, 102, 101] -> [262, 140, 102, 101] w/ P(a|s)=0.2052970826625824 and iou=0.7022974607013301 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [1.5832971]\n",
            "\u001b[92m>> Total frame loss: 1.5832971334457397\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1780 with src: [262, 140, 102, 101] and target: [275, 133,  99,  98]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1781.jpg\n",
            "|->> Beginning tracking for bbox:[262 140 102 101]\n",
            "   \u001b[33m|->> #0/t=5-th Action selection: 1/2X LEFT (P(a|s) = 0.05400000140070915)\u001b[0m\n",
            "      |->> Bounding box moves to: [256 140 102 101]\n",
            "         |->> Action Probabilities (Rounded): [0.0761 0.0535 0.0993 0.0935 0.0849 0.0727 0.0939 0.0737 0.2107 0.0629\n",
            " 0.0787], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07612936 0.05352574 0.09928037 0.09346441 0.08491927 0.07274537\n",
            " 0.09390357 0.0737403  0.21074525 0.06287655 0.07866989], argmax=8\n",
            "   \u001b[33m|->> #1/t=6-th Action selection: 7/2X DOWN (P(a|s) = 0.07100000232458115)\u001b[0m\n",
            "      |->> Bounding box moves to: [256 146 102 101]\n",
            "         |->> Action Probabilities (Rounded): [0.0655 0.0451 0.0906 0.0948 0.0858 0.067  0.0869 0.0707 0.2666 0.0559\n",
            " 0.0711], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06552913 0.04507706 0.09055006 0.09482738 0.08584659 0.06698105\n",
            " 0.08688387 0.07074212 0.2665553  0.05589062 0.07111685], argmax=8\n",
            "   \u001b[33m|->> #2/t=7-th Action selection: 7/2X DOWN (P(a|s) = 0.06300000101327896)\u001b[0m\n",
            "      |->> Bounding box moves to: [256 152 102 101]\n",
            "         |->> Action Probabilities (Rounded): [0.0588 0.0436 0.0929 0.0843 0.0815 0.0613 0.0791 0.0626 0.3134 0.0537\n",
            " 0.0687], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05877366 0.04362062 0.09288263 0.08434836 0.08145814 0.06134498\n",
            " 0.07914053 0.06263511 0.31336218 0.05371798 0.06871583], argmax=8\n",
            "|->> Revisiting bbox: [256 152 102 101]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [262, 140, 102, 101] -> [256, 152, 102, 101] (Target was [275, 133,  99,  98])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.074) for 2X LEFT:bbox transition: [262, 140, 102, 101] -> [256, 140, 102, 101] w/ P(a|s)=0.05352574214339256 and iou=0.6066179423339491 and reward=-0.07368445161817194 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.062) for 2X DOWN:bbox transition: [256, 140, 102, 101] -> [256, 146, 102, 101] w/ P(a|s)=0.07074211537837982 and iou=0.5448297165804309 and reward=-0.06178822575351817 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-1.0) for 2X DOWN:bbox transition: [256, 146, 102, 101] -> [256, 152, 102, 101] w/ P(a|s)=0.06263510882854462 and iou=0.4876180560719863 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.21571806 -0.16365936 -2.7704294 ]\n",
            "\u001b[31m>> Total frame loss: -3.1498067378997803\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1781 with src: [256, 152, 102, 101] and target: [276, 132, 102, 103]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1782.jpg\n",
            "|->> Beginning tracking for bbox:[256 152 102 101]\n",
            "   \u001b[33m|->> #0/t=8-th Action selection: 10/SCALE UP (P(a|s) = 0.06599999964237213)\u001b[0m\n",
            "      |->> Bounding box moves to: [254 150 105 104]\n",
            "         |->> Action Probabilities (Rounded): [0.0551 0.0422 0.0859 0.0839 0.0783 0.0603 0.0726 0.0547 0.3484 0.0528\n",
            " 0.0658], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05505355 0.0422204  0.08588003 0.08385319 0.07831464 0.06030097\n",
            " 0.07264946 0.05472976 0.34837377 0.0528418  0.06578246], argmax=8\n",
            "   \u001b[33m|->> #1/t=9-th Action selection: 3/2X RIGHT (P(a|s) = 0.07599999755620956)\u001b[0m\n",
            "      |->> Bounding box moves to: [260 150 105 104]\n",
            "         |->> Action Probabilities (Rounded): [0.0546 0.0388 0.0796 0.0762 0.0755 0.0608 0.0723 0.0512 0.3818 0.0515\n",
            " 0.0578], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05463092 0.03877461 0.07956715 0.0761593  0.07547896 0.06083088\n",
            " 0.07229378 0.05120093 0.3817637  0.05150991 0.05778985], argmax=8\n",
            "   \u001b[33m|->> #2/t=10-th Action selection: 0/LEFT (P(a|s) = 0.05299999937415123)\u001b[0m\n",
            "      |->> Bounding box moves to: [257 150 105 104]\n",
            "         |->> Action Probabilities (Rounded): [0.0531 0.0406 0.0686 0.0591 0.0713 0.0543 0.0693 0.0492 0.4331 0.0456\n",
            " 0.0558], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05311402 0.04055331 0.06862888 0.05914108 0.07130695 0.05430339\n",
            " 0.06932349 0.04920388 0.43307406 0.04556219 0.05578881], argmax=8\n",
            "|->> Revisiting bbox: [257 150 105 104]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [256, 152, 102, 101] -> [257, 150, 105, 104] (Target was [276, 132, 102, 103])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.005) for SCALE UP:bbox transition: [256, 152, 102, 101] -> [254, 150, 105, 104] w/ P(a|s)=0.06578245759010315 and iou=0.49091921230255375 and reward=0.004845794219422772 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.055) for 2X RIGHT:bbox transition: [254, 150, 105, 104] -> [260, 150, 105, 104] w/ P(a|s)=0.07615929841995239 and iou=0.5457759180434312 and reward=0.05485670574087742 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-1.0) for LEFT:bbox transition: [260, 150, 105, 104] -> [257, 150, 105, 104] w/ P(a|s)=0.053114019334316254 and iou=0.5178520827429867 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.01318736  0.14125207 -2.9353144 ]\n",
            "\u001b[31m>> Total frame loss: -2.7808749675750732\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1782 with src: [257, 150, 105, 104] and target: [277, 130,  98,  96]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1783.jpg\n",
            "|->> Beginning tracking for bbox:[257 150 105 104]\n",
            "   \u001b[33m|->> #0/t=11-th Action selection: 10/SCALE UP (P(a|s) = 0.05299999937415123)\u001b[0m\n",
            "      |->> Bounding box moves to: [255 148 108 107]\n",
            "         |->> Action Probabilities (Rounded): [0.0488 0.0355 0.0748 0.0632 0.066  0.052  0.0668 0.0515 0.4471 0.0409\n",
            " 0.0533], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.04878055 0.03548083 0.07484729 0.06323667 0.0660183  0.05202798\n",
            " 0.06682763 0.05145328 0.44710323 0.04090038 0.05332387], argmax=8\n",
            "   \u001b[33m|->> #1/t=12-th Action selection: 2/RIGHT (P(a|s) = 0.07599999755620956)\u001b[0m\n",
            "      |->> Bounding box moves to: [258 148 108 107]\n",
            "         |->> Action Probabilities (Rounded): [0.0513 0.0377 0.0758 0.0617 0.0727 0.0535 0.0696 0.0535 0.4308 0.0427\n",
            " 0.0507], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05125469 0.03768677 0.07580644 0.06171    0.07266223 0.05346854\n",
            " 0.06963049 0.05353528 0.4307799  0.04274288 0.05072288], argmax=8\n",
            "|->> Revisiting bbox: [255 148 108 107]. ACtion 0 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [257, 150, 105, 104] -> [258, 148, 108, 107] (Target was [277, 130,  98,  96])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.005) for SCALE UP:bbox transition: [257, 150, 105, 104] -> [255, 148, 108, 107] w/ P(a|s)=0.05332386866211891 and iou=0.47053872053872053 and reward=0.004718126365083397 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-1.0) for RIGHT:bbox transition: [255, 148, 108, 107] -> [258, 148, 108, 107] w/ P(a|s)=0.07580643892288208 and iou=0.49507916131792895 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.01383058 -2.579572  ]\n",
            "\u001b[31m>> Total frame loss: -2.5657413005828857\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1783 with src: [258, 148, 108, 107] and target: [277, 131,  99,  94]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1784.jpg\n",
            "|->> Beginning tracking for bbox:[258 148 108 107]\n",
            "   \u001b[33m|->> #0/t=13-th Action selection: 3/2X RIGHT (P(a|s) = 0.061000000685453415)\u001b[0m\n",
            "      |->> Bounding box moves to: [264 148 108 107]\n",
            "         |->> Action Probabilities (Rounded): [0.0572 0.0436 0.0661 0.0614 0.0699 0.0527 0.0777 0.0575 0.4116 0.0449\n",
            " 0.0574], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05717285 0.04363016 0.06609168 0.06136036 0.06990406 0.05274339\n",
            " 0.07768507 0.0574901  0.41159064 0.0449081  0.05742365], argmax=8\n",
            "|->> Revisiting bbox: [264 148 108 107]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [258, 148, 108, 107] -> [264, 148, 108, 107] (Target was [277, 131,  99,  94])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for 2X RIGHT:bbox transition: [258, 148, 108, 107] -> [264, 148, 108, 107] w/ P(a|s)=0.06136035919189453 and iou=0.5399719495091164 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.7909913]\n",
            "\u001b[31m>> Total frame loss: -2.7909913063049316\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1784 with src: [264, 148, 108, 107] and target: [275, 129, 106, 104]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1785.jpg\n",
            "|->> Beginning tracking for bbox:[264 148 108 107]\n",
            "   \u001b[33m|->> #0/t=14-th Action selection: 5/2X UP (P(a|s) = 0.05299999937415123)\u001b[0m\n",
            "      |->> Bounding box moves to: [264 142 108 107]\n",
            "         |->> Action Probabilities (Rounded): [0.0622 0.0489 0.0649 0.0505 0.0699 0.0533 0.0722 0.055  0.4181 0.0459\n",
            " 0.0593], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06216289 0.04885119 0.06488167 0.05053924 0.06987282 0.05329456\n",
            " 0.07220621 0.05495856 0.41806832 0.04585631 0.05930813], argmax=8\n",
            "   \u001b[33m|->> #1/t=15-th Action selection: 9/SCALE DOWN (P(a|s) = 0.04699999839067459)\u001b[0m\n",
            "      |->> Bounding box moves to: [265 143 104 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0571 0.0478 0.0627 0.0506 0.0648 0.0456 0.0699 0.0625 0.4361 0.0471\n",
            " 0.0559], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05711398 0.04784048 0.06274149 0.05056785 0.06477259 0.04556902\n",
            " 0.06987699 0.06247652 0.43608782 0.04705218 0.05590101], argmax=8\n",
            "   \u001b[33m|->> #2/t=16-th Action selection: 1/2X LEFT (P(a|s) = 0.050999999046325684)\u001b[0m\n",
            "      |->> Bounding box moves to: [259 143 104 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0588 0.0507 0.0617 0.053  0.0652 0.0438 0.0795 0.0598 0.4236 0.0406\n",
            " 0.0635], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05880955 0.05069748 0.06172152 0.05296131 0.06517742 0.04381023\n",
            " 0.0794521  0.05976274 0.42355174 0.04057408 0.06348175], argmax=8\n",
            "|->> Revisiting bbox: [259 143 104 103]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [264, 148, 108, 107] -> [259, 143, 104, 103] (Target was [275, 129, 106, 104])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.067) for 2X UP:bbox transition: [264, 148, 108, 107] -> [264, 142, 108, 107] w/ P(a|s)=0.05329456180334091 and iou=0.6418236021231731 and reward=0.06665792371368584 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.005) for SCALE DOWN:bbox transition: [264, 142, 108, 107] -> [265, 143, 104, 103] w/ P(a|s)=0.047052182257175446 and iou=0.6372401325700512 and reward=-0.004583469553121944 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-1.0) for 2X LEFT:bbox transition: [265, 143, 104, 103] -> [259, 143, 104, 103] w/ P(a|s)=0.050697483122348785 and iou=0.5732484076433121 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.19543576 -0.01400937 -2.981879  ]\n",
            "\u001b[31m>> Total frame loss: -2.800452709197998\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1785 with src: [259, 143, 104, 103] and target: [274, 125, 108, 105]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1786.jpg\n",
            "|->> Beginning tracking for bbox:[259 143 104 103]\n",
            "   \u001b[33m|->> #0/t=17-th Action selection: 6/DOWN (P(a|s) = 0.08299999684095383)\u001b[0m\n",
            "      |->> Bounding box moves to: [259 146 104 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0548 0.0468 0.0649 0.0555 0.0652 0.0427 0.0827 0.064  0.4263 0.0393\n",
            " 0.0579], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05482369 0.04677554 0.06494154 0.05547022 0.06515097 0.04265273\n",
            " 0.08268797 0.06399055 0.4263189  0.03930608 0.05788181], argmax=8\n",
            "|->> Revisiting bbox: [259 146 104 103]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [259, 143, 104, 103] -> [259, 146, 104, 103] (Target was [274, 125, 108, 105])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-1.0) for DOWN:bbox transition: [259, 143, 104, 103] -> [259, 146, 104, 103] w/ P(a|s)=0.08268797397613525 and iou=0.5128979143798024 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-2.492681]\n",
            "\u001b[31m>> Total frame loss: -2.4926810264587402\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1786 with src: [259, 146, 104, 103] and target: [274, 124, 101, 101]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1787.jpg\n",
            "|->> Beginning tracking for bbox:[259 146 104 103]\n",
            "|->> Revisiting bbox: [259 146 104 103]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=18-th Action selection: 8/STOP (P(a|s) = 0.421999990940094)\u001b[0m\n",
            "      |->> Bounding box moves to: [259 146 104 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0569 0.0412 0.067  0.0574 0.0662 0.0432 0.0771 0.0667 0.4216 0.0445\n",
            " 0.0582], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05694369 0.04119893 0.06698897 0.0573745  0.06624312 0.04316407\n",
            " 0.07714005 0.06665349 0.4215829  0.04452293 0.05818727], argmax=8\n",
            "         |->> Hit a STOP on the 18-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [259, 146, 104, 103] -> [259, 146, 104, 103] (Target was [274, 124, 101, 101])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [259, 146, 104, 103] -> [259, 146, 104, 103] w/ P(a|s)=0.4215829074382782 and iou=0.5064832156749748 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.86373883]\n",
            "\u001b[31m>> Total frame loss: -0.8637388348579407\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1787 with src: [259, 146, 104, 103] and target: [277, 123, 100,  98]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1788.jpg\n",
            "|->> Beginning tracking for bbox:[259 146 104 103]\n",
            "|->> Revisiting bbox: [259 146 104 103]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=18-th Action selection: 8/STOP (P(a|s) = 0.38600000739097595)\u001b[0m\n",
            "      |->> Bounding box moves to: [259 146 104 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0619 0.0461 0.0727 0.0591 0.0682 0.0496 0.0836 0.0674 0.386  0.0429\n",
            " 0.0625], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06186345 0.04608969 0.07272198 0.05907176 0.06816446 0.04958299\n",
            " 0.08361084 0.06744343 0.38604915 0.04294346 0.06245881], argmax=8\n",
            "         |->> Hit a STOP on the 18-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [259, 146, 104, 103] -> [259, 146, 104, 103] (Target was [277, 123, 100,  98])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [259, 146, 104, 103] -> [259, 146, 104, 103] w/ P(a|s)=0.38604915142059326 and iou=0.4586829753946807 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.9517906]\n",
            "\u001b[31m>> Total frame loss: -0.9517905712127686\u001b[0m\n",
            "Final bounding box: [259 146 104 103] reached in 18 timesteps (originating from [274 134 102 101]). Target was [277 123 100  98]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 1788 in t=18 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[31m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 0.0\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.0\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 8.850375175476074\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 3.1718385219573975\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/Rubik\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Starting bounding box=adnet_datasets/OTB/Rubik/img/1789.jpg for adnet_datasets/OTB/Rubik's frames (index: 0)\n",
            "src:adnet_datasets/OTB/Rubik/img/1779.jpg\n",
            "target:adnet_datasets/OTB/Rubik/img/1789.jpg.\n",
            "\u001b[34m>> Attempting to reach frame 1779 with src: [274, 133, 107, 103] and target: [276, 136, 105, 103]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1780.jpg\n",
            "|->> Beginning tracking for bbox:[274 133 107 103]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 4/UP (P(a|s) = 0.09200000017881393)\u001b[0m\n",
            "      |->> Bounding box moves to: [274 130 107 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0885 0.0811 0.0936 0.0878 0.0916 0.0821 0.0957 0.0877 0.1201 0.0821\n",
            " 0.0897], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08851537 0.08106087 0.09360594 0.08777282 0.09155647 0.08212952\n",
            " 0.0957332  0.08772113 0.12010276 0.08214055 0.08966143], argmax=8\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 2/RIGHT (P(a|s) = 0.09300000220537186)\u001b[0m\n",
            "      |->> Bounding box moves to: [277 130 107 103]\n",
            "         |->> Action Probabilities (Rounded): [0.0874 0.0776 0.0933 0.0866 0.0879 0.0775 0.0982 0.0896 0.1381 0.0775\n",
            " 0.0862], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08742807 0.07764535 0.09329852 0.08659606 0.08794267 0.07754719\n",
            " 0.09815687 0.08961651 0.13810666 0.07750385 0.08615825], argmax=8\n",
            "   \u001b[33m|->> #2/t=3-th Action selection: 10/SCALE UP (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [275 128 110 106]\n",
            "         |->> Action Probabilities (Rounded): [0.0961 0.0765 0.082  0.0813 0.0878 0.0745 0.0977 0.0894 0.1531 0.0746\n",
            " 0.0869], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.09609394 0.07653495 0.08204608 0.08131687 0.08779807 0.07452191\n",
            " 0.09769888 0.08941792 0.15307933 0.07462969 0.08686237], argmax=8\n",
            "   \u001b[33m|->> #3/t=4-th Action selection: 6/DOWN (P(a|s) = 0.0989999994635582)\u001b[0m\n",
            "      |->> Bounding box moves to: [275 131 110 106]\n",
            "         |->> Action Probabilities (Rounded): [0.0833 0.0753 0.0917 0.0797 0.0868 0.0697 0.0991 0.0866 0.1748 0.0739\n",
            " 0.079 ], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08329341 0.07532247 0.09171301 0.07969037 0.08683097 0.06968477\n",
            " 0.09914348 0.08657577 0.17478564 0.07391678 0.07904336], argmax=8\n",
            "|->> Revisiting bbox: [275 128 110 106]. ACtion 4 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [274, 133, 107, 103] -> [275, 131, 110, 106] (Target was [276, 136, 105, 103])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.052) for UP:bbox transition: [274, 133, 107, 103] -> [274, 130, 107, 103] w/ P(a|s)=0.09155647456645966 and iou=0.8741738906531629 and reward=-0.05207875578296983 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.015) for RIGHT:bbox transition: [274, 130, 107, 103] -> [277, 130, 107, 103] w/ P(a|s)=0.0932985246181488 and iou=0.8586993530813756 and reward=-0.015474537571787295 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.014) for SCALE UP:bbox transition: [277, 130, 107, 103] -> [275, 128, 110, 106] w/ P(a|s)=0.08686237037181854 and iou=0.8444809191629052 and reward=-0.01421843391847033 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (1.0) for DOWN:bbox transition: [275, 128, 110, 106] -> [275, 131, 110, 106] w/ P(a|s)=0.09914347529411316 and iou=0.8934288121314238 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.12450986 -0.03670485 -0.03474175  2.3111873 ]\n",
            "\u001b[92m>> Total frame loss: 2.1152310371398926\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1780 with src: [275, 131, 110, 106] and target: [275, 133,  99,  98]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1781.jpg\n",
            "|->> Beginning tracking for bbox:[275 131 110 106]\n",
            "   \u001b[33m|->> #0/t=5-th Action selection: 7/2X DOWN (P(a|s) = 0.08100000023841858)\u001b[0m\n",
            "      |->> Bounding box moves to: [275 137 110 106]\n",
            "         |->> Action Probabilities (Rounded): [0.0812 0.0672 0.0894 0.078  0.0922 0.0697 0.0969 0.0812 0.1928 0.0721\n",
            " 0.0794], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08116011 0.06717908 0.08944418 0.07801846 0.09223074 0.06971432\n",
            " 0.09685414 0.08115022 0.19275887 0.07208319 0.07940668], argmax=8\n",
            "|->> Revisiting bbox: [275 131 110 106]. ACtion 5 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [275, 131, 110, 106] -> [275, 137, 110, 106] (Target was [275, 133,  99,  98])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (1.0) for 2X DOWN:bbox transition: [275, 131, 110, 106] -> [275, 137, 110, 106] w/ P(a|s)=0.08115021884441376 and iou=0.7718978102189781 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [2.5114534]\n",
            "\u001b[92m>> Total frame loss: 2.51145339012146\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1781 with src: [275, 137, 110, 106] and target: [276, 132, 102, 103]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1782.jpg\n",
            "|->> Beginning tracking for bbox:[275 137 110 106]\n",
            "   \u001b[33m|->> #0/t=6-th Action selection: 10/SCALE UP (P(a|s) = 0.07800000160932541)\u001b[0m\n",
            "      |->> Bounding box moves to: [273 135 113 109]\n",
            "         |->> Action Probabilities (Rounded): [0.0816 0.065  0.0865 0.0756 0.087  0.0708 0.0924 0.0706 0.2236 0.0686\n",
            " 0.0784], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.08158541 0.06496381 0.08653177 0.07557368 0.08703416 0.07075157\n",
            " 0.09235617 0.0706181  0.22362852 0.0685605  0.07839625], argmax=8\n",
            "   \u001b[33m|->> #1/t=7-th Action selection: 4/UP (P(a|s) = 0.08699999749660492)\u001b[0m\n",
            "      |->> Bounding box moves to: [273 132 113 109]\n",
            "         |->> Action Probabilities (Rounded): [0.0765 0.0613 0.0897 0.0733 0.0874 0.0676 0.0901 0.0695 0.2496 0.0643\n",
            " 0.0707], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07652104 0.06125864 0.08965804 0.07334051 0.0874313  0.06755615\n",
            " 0.0901386  0.06954006 0.24958022 0.06426822 0.07070713], argmax=8\n",
            "   \u001b[33m|->> #2/t=8-th Action selection: 4/UP (P(a|s) = 0.08100000023841858)\u001b[0m\n",
            "      |->> Bounding box moves to: [273 129 113 109]\n",
            "         |->> Action Probabilities (Rounded): [0.0762 0.0578 0.0826 0.0748 0.0809 0.0628 0.0928 0.0705 0.2715 0.0607\n",
            " 0.0694], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07623625 0.05781152 0.08256862 0.07476341 0.0808631  0.06281346\n",
            " 0.09276179 0.0705128  0.27153233 0.06071167 0.06942498], argmax=8\n",
            "|->> Revisiting bbox: [273 129 113 109]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [275, 137, 110, 106] -> [273, 129, 113, 109] (Target was [276, 132, 102, 103])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.013) for SCALE UP:bbox transition: [275, 137, 110, 106] -> [273, 135, 113, 109] w/ P(a|s)=0.07839624583721161 and iou=0.8080487998098709 and reward=-0.01331521005044134 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.045) for UP:bbox transition: [273, 135, 113, 109] -> [273, 132, 113, 109] w/ P(a|s)=0.08743130415678024 and iou=0.8529674433709508 and reward=0.044918643561079885 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (1.0) for UP:bbox transition: [273, 132, 113, 109] -> [273, 129, 113, 109] w/ P(a|s)=0.0808631032705307 and iou=0.8529674433709508 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-0.03390025  0.10946233  2.5149977 ]\n",
            "\u001b[92m>> Total frame loss: 2.590559720993042\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 1782 with src: [273, 129, 113, 109] and target: [277, 130,  98,  96]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Rubik/img/1783.jpg\n",
            "|->> Beginning tracking for bbox:[273 129 113 109]\n",
            "   \u001b[33m|->> #0/t=9-th Action selection: 2/RIGHT (P(a|s) = 0.07599999755620956)\u001b[0m\n",
            "      |->> Bounding box moves to: [276 129 113 109]\n",
            "         |->> Action Probabilities (Rounded): [0.072  0.0524 0.0764 0.0657 0.0725 0.059  0.0862 0.0667 0.3321 0.0545\n",
            " 0.0625], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.0720365  0.05244216 0.07640631 0.0656561  0.07248104 0.05901445\n",
            " 0.08624156 0.06666645 0.3320768  0.05446168 0.062517  ], argmax=8\n",
            "   \u001b[33m|->> #1/t=10-th Action selection: 4/UP (P(a|s) = 0.0689999982714653)\u001b[0m\n",
            "      |->> Bounding box moves to: [276 126 113 109]\n",
            "         |->> Action Probabilities (Rounded): [0.0713 0.05   0.0643 0.0598 0.0689 0.0516 0.084  0.0668 0.3727 0.0485\n",
            " 0.0621], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.07132673 0.04999227 0.06425863 0.05982639 0.06885396 0.05158661\n",
            " 0.08397249 0.06683334 0.37268782 0.04853272 0.06212905], argmax=8\n",
            "   \u001b[33m|->> #2/t=11-th Action selection: 3/2X RIGHT (P(a|s) = 0.05700000002980232)\u001b[0m\n",
            "      |->> Bounding box moves to: [282 126 113 109]\n",
            "         |->> Action Probabilities (Rounded): [0.0544 0.0476 0.0677 0.0572 0.063  0.0444 0.0776 0.0611 0.4302 0.0432\n",
            " 0.0534], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.05437049 0.04763466 0.06774606 0.05722228 0.06303449 0.04444803\n",
            " 0.0776482  0.06113181 0.4301816  0.043166   0.05341633], argmax=8\n",
            "   \u001b[33m|->> #3/t=12-th Action selection: 4/UP (P(a|s) = 0.06700000166893005)\u001b[0m\n",
            "      |->> Bounding box moves to: [282 123 113 109]\n",
            "         |->> Action Probabilities (Rounded): [0.0619 0.0494 0.0621 0.0497 0.0665 0.0475 0.0773 0.0623 0.4164 0.0493\n",
            " 0.0575], argmax=8\n",
            "         |->> Action Probabilities (RAW): [0.06185328 0.04941564 0.06208867 0.04971587 0.06654289 0.04753773\n",
            " 0.07733271 0.06234299 0.41639918 0.0492739  0.05749715], argmax=8\n",
            "|->> Revisiting bbox: [282 123 113 109]. ACtion 8 did nothing. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [273, 129, 113, 109] -> [282, 123, 113, 109] (Target was [277, 130,  98,  96])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for RIGHT:bbox transition: [273, 129, 113, 109] -> [276, 129, 113, 109] w/ P(a|s)=0.07640630751848221 and iou=0.7638223593407486 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for UP:bbox transition: [276, 129, 113, 109] -> [276, 126, 113, 109] w/ P(a|s)=0.068853959441185 and iou=0.7638223593407486 and reward=0.0 and discount=1.0\n",
            "   |->> t=3 Diff-Reward (-0.066) for 2X RIGHT:bbox transition: [276, 126, 113, 109] -> [282, 126, 113, 109] w/ P(a|s)=0.05722228065133095 and iou=0.6976635148863015 and reward=-0.06615884445444709 and discount=1.0\n",
            "   |->> t=4 Diff-Reward (-1.0) for UP:bbox transition: [282, 126, 113, 109] -> [282, 123, 113, 109] w/ P(a|s)=0.06654288619756699 and iou=0.6976635148863015 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [ 0.          0.         -0.18926802 -2.7099087 ]\n"
          ]
        }
      ],
      "source": [
        "model, losses = epochs_train(adnet_model, Adam(learning_rate=LEARNING_RATE), \n",
        "                             datasets, epochs=N_EPOCHS, retry_count=N_RETRIES, \n",
        "                             randomize=RANDOMIZE_TRAINING)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LF9uTq5yY31"
      },
      "outputs": [],
      "source": [
        "# Plot losses\n",
        "fig = plt.figure()\n",
        "all_losses = np.concatenate([v for _, v in losses.items()])\n",
        "plt.plot(np.arange(len(all_losses)), all_losses) \n",
        "plt.xlabel('Number of Episodes')\n",
        "plt.ylabel('Avg Trajectory Loss')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYQ1oThc1c_2"
      },
      "source": [
        "### Save Weights for Reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZTaifbPkHeS",
        "outputId": "7570e3ed-dd9d-4fc3-ff93-ef2a13a415f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: derek_models/19-12-2021_225315/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: derek_models/19-12-2021_225315/assets\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p derek_models\n",
        "\n",
        "dt_string = datetime.now().strftime(\"%d-%m-%Y_%H%M%S\")\n",
        "model.save('derek_models/{0}'.format(dt_string))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "dt_string = datetime.now().strftime(\"%d-%m-%Y_%H%M%S\")\n",
        "model.save_weights(\"checkpoints/derek-{0}.h5\".format(dt_string))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1SsVnMeg8Up"
      },
      "outputs": [],
      "source": [
        "%debug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbUe72jpsol6"
      },
      "outputs": [],
      "source": [
        "# UNTESTED; uncomfirmed if works\n",
        "\n",
        "def move2Frame(model: ADNET, img: np.array, src_frame: int, src_bbox: np.array, \n",
        "               target_frame: int, target_bbox: np.array) -> np.array:\n",
        "  \n",
        "  bbox = src_bbox\n",
        "  actions = []\n",
        "  img = getFrame(dataset, target_frame) \n",
        "  target_bbox = gt[i]\n",
        "  for t in range(model.K):\n",
        "    patch = getPatch(img, bbox)\n",
        "    probs, conf_score = model(patch)\n",
        "    a_prob = tf.reshape(probs, (model.ACTION_DIM)) \n",
        "    a, bbox = selectMaxAction(np.array(img), bbox, a_prob)\n",
        "\n",
        "    actions.append(a)\n",
        "    model.updateActionHistory(a)\n",
        "    if isStop(a):\n",
        "        break  \n",
        "  \n",
        "  target_iou = calculate_IOU(bbox, target_bbox)   \n",
        "  return bbox, target_iou, actions\n",
        "\n",
        "\n",
        "def predict(model: ADNET, d: str, start_frame: int, end_frame: int):\n",
        "  gt = get_ground_truths(\"%s/groundtruth_rect.txt\" % d)\n",
        "  frames = sorted(glob.glob(os.path.join('%s/img' % d, '*.jpg'))) \n",
        "\n",
        "  ious = []\n",
        "  bbox = gt[start_frame]\n",
        "  model.clearActionHistory()\n",
        "  for i in range(start_frame+1, end_frame+1):\n",
        "    img = getFrame(dataset, i) \n",
        "    bbox, iou, actions = move2Frame(model, img, d)\n",
        "    ious.append(iou)\n",
        "  return model, ious\n",
        "\n",
        "\n",
        "def predict(model: ADNET, d: str):\n",
        "  gt = get_ground_truths(\"%s/groundtruth_rect.txt\" % d)\n",
        "  frames = sorted(glob.glob(os.path.join('%s/img' % d, '*.jpg'))) \n",
        "  return predict(model, d, 0, len(frames)-1)\n",
        "\n",
        "\n",
        "\n",
        "rand_idx = 11\n",
        "d = ALL_DATASETS_LIST[rand_idx] \n",
        "model, ious = predict(adnet_model, d)\n",
        "\n",
        "fig = plt.figure()\n",
        "for e in losses:\n",
        "  plt.plot(np.arange(len(ious)), ious) \n",
        "plt.xlabel('Frame')\n",
        "plt.ylabel('IOU')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMtzZ9r5nu8A"
      },
      "source": [
        "### Observations\n",
        "\n",
        "* The paper sums all sequence rewards. However, we found this to produce too much variance. We reduce_mean instead to address this. If we had"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmQvTRA7j9ET"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkTBunYkHcUQ"
      },
      "outputs": [],
      "source": [
        "print(erroneous_datasets)\n",
        "\n",
        "# !ls adnet_datasets/OTB/Diving/img/\n",
        "# ! wc -l adnet_datasets/OTB/Diving/groundtruth_rect.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0g-v8GupB9y"
      },
      "outputs": [],
      "source": [
        "def predict(model: tf.keras.Model,img: np.array,bbox: np.array) -> np.array:\n",
        "  ACTION_DIM=11\n",
        "  K=10\n",
        "  \n",
        "  action_hist = np.zeros((ACTION_DIM * K, 1))\n",
        "  seen_bboxes = set()\n",
        "  for t in range(K):\n",
        "    #model.setActionHistory(action_hist.reshape((1, 1, 1, ACTION_DIM * K)))\n",
        "    model.setActionHistory(action_hist.reshape((1,ACTION_DIM * K))) ### For ADNET_v2\n",
        "    patch = tf.image.resize(img[bbox[1]:(bbox[1] + bbox[3]), \n",
        "                                bbox[0]:(bbox[0] + bbox[2])], [112, 112])\n",
        "    patch = tf.reshape(patch, (1, 112, 112, 3))\n",
        "    a_prob = tf.reshape(model(patch)[0], (ACTION_DIM)) \n",
        "    a, bbox = selectAction(np.array(img), bbox, a_prob)\n",
        "    if isStop(a) or tuple(bbox) in seen_bboxes:\n",
        "      break\n",
        "\n",
        "    action_hist[t * ACTION_DIM + a] = 1 \n",
        "    seen_bboxes.add(tuple(bbox))\n",
        "  return bbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03dOCNAKz6sg"
      },
      "outputs": [],
      "source": [
        "def plotNpImageBBoxGT(img: np.array, bbox: np.array,gbbox: np.array) -> np.array:\n",
        "  '''\n",
        "  Plots the bounding box on an image and returns the bounding box\n",
        "  '''\n",
        "  fig, ax = plt.subplots()\n",
        "  x_pre,y_pre, w_pre, h_pre = bbox\n",
        "  x_gr,y_gr, w_gr, h_gr = gbbox\n",
        "  predicted_rect = patches.Rectangle((x_pre, y_pre), w_pre, h_pre, linewidth=1, edgecolor='r', facecolor='none')\n",
        "  gt_rect = patches.Rectangle((x_gr, y_gr), w_gr, h_gr, linewidth=1, edgecolor='b', facecolor='none')\n",
        "  ax.add_patch(predicted_rect)\n",
        "  ax.add_patch(gt_rect)\n",
        "  plt.imshow(img)\n",
        "  return bbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAvwFremUHsQ"
      },
      "outputs": [],
      "source": [
        "ALL_DATASETS_LIST = glob.glob(\"adnet_datasets/OTB/*\")\n",
        "j = random.randint(0, len(ALL_DATASETS_LIST)) \n",
        "dataset = ALL_DATASETS_LIST[j] \n",
        "frames = sorted(glob.glob(os.path.join('%s/img' % dataset, '*.jpg')))\n",
        "gt = get_ground_truths(\"%s/groundtruth_rect.txt\" % dataset)\n",
        "\n",
        "predicted_bbox = gt[0]\n",
        "for i, frame in enumerate(frames[1:]):\n",
        "  img = cv2.imread(frame)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  print(img.shape)\n",
        "  predicted_bbox=predict(model,img,predicted_bbox)\n",
        "  print(predicted_bbox)\n",
        "  gtbbox=gt[i]\n",
        "  plotNpImageBBoxGT(img,predicted_bbox,gtbbox)\n",
        "  #print(gtbbox)\n",
        "  #print(predicted_bbox)\n",
        "  break\n",
        "  #bbox = \n",
        "  #print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhMMozN6J64i"
      },
      "outputs": [],
      "source": [
        "def test_metrics( model: tf.keras.Model, model2:tf.keras.Model  ):\n",
        "    all_boxes = []\n",
        "    all_gt = []\n",
        "    time_perframe_for_each_video =[]\n",
        "    test_list = glob.glob(\"adnet_datasets/Test/*\")\n",
        "    d = ALL_DATASETS_LIST[rand_idx] \n",
        "    gt = get_ground_truths(\"%s/groundtruth_rect.txt\" % d)\n",
        "  \n",
        "    for  i in range(len(test_list)):  # start with 1\n",
        "      dataset = test_list[i]\n",
        "      print(dataset)\n",
        "      #frames = sorted(glob.glob(os.path.join('%s/img' % dataset, '*.jpg')))\n",
        "      gt = get_ground_truths(\"%s/groundtruth_rect.txt\" % dataset)     \n",
        "      all_gt.append(gt)\n",
        "      frames = sorted(glob.glob(os.path.join('%s/img' % dataset, '*.jpg')))\n",
        "      print(frames)\n",
        "      number_of_frames = len(frames)\n",
        "      #start_frame = random.randint(0, number_of_frames) maybe to test robustnes do not start always with first frame TRE\n",
        "      start_frame = 0\n",
        "      boxes_m1 =[]\n",
        "      boxes_m2 = []\n",
        "      time_perframe = []\n",
        "      predicted_box = gt[0]\n",
        "      predicted_box2 = gt[0]\n",
        "      start = time.time()\n",
        "      for f in range(len(frames) - start_frame):\n",
        "        img = cv2.imread(frames[f])\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        predicted_bbox=predict(model,img,predicted_box)\n",
        "        #predicted_bbox2 = predict(model, img,predicted_bbox) if we want to compare 2 models\n",
        "        boxes_m1.append(predicted_box)\n",
        "        #boxes_m2.append(predicted_bbox)\n",
        "      end = time.time()\n",
        "      time_perframe = (start-end)/len(frames)\n",
        "      all_boxes.append(boxes_m1)\n",
        "      time_perframe_for_each_video.append(time_perframe)\n",
        "    return all_boxes, all_gt , time_perframe_for_each_video\n",
        "\n",
        "\n",
        "\n",
        "all_boxes, all_gt , time_perframe_for_each_video = test_metrics(model , adnet_model)\n",
        "print (all_boxes)\n",
        "print(all_gt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9712yCAxLmtI"
      },
      "source": [
        "# TESTING & DEBUGGING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Me8c91RVoLvD"
      },
      "outputs": [],
      "source": [
        "# Update this with the appropriate dataset\n",
        "TEST_IMAGE_PATH = \"adnet_datasets/OTB/Couple/img/0082.jpg\"\n",
        "TEST_BBOX = get_ground_truths(\"adnet_datasets/OTB/Couple/groundtruth_rect.txt\")[82]\n",
        "TEST_IMAGE = cv2.imread(TEST_IMAGE_PATH)\n",
        "\n",
        "\n",
        "# Update the following two vars\n",
        "src_bbox = np.array([143, 131, 34, 87]) \n",
        "pred_bbox = np.array([138, 41, 32, 89])\n",
        "print(plotNpImageBBoxes(TEST_IMAGE, src_bbox, TEST_BBOX, pred_bbox))\n",
        "\n",
        "\n",
        "print(\"IOU: {0}\".format(calculate_IOU(pred_bbox, src_bbox)))\n",
        "\n",
        "print(\"Test bbox is: {0}\".format(TEST_BBOX))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzbeopDmi6q_"
      },
      "outputs": [],
      "source": [
        "# VERTICAL MOVEMENT TESTING \n",
        "TEST_IMAGE_PATH = \"adnet_datasets/OTB/Skater2/img/0005.jpg\"\n",
        "TEST_BBOX = get_ground_truths(\"adnet_datasets/OTB/Skater2/groundtruth_rect.txt\")[4]\n",
        "TEST_IMAGE = cv2.imread(TEST_IMAGE_PATH)\n",
        "\n",
        "# Test move down\n",
        "print(\"Down-shifted bounding box\")\n",
        "bbox = move2(img, TEST_BBOX, \"down\")\n",
        "print(plotNpImageBBox(img, bbox))\n",
        "\n",
        "print(\"Down-shifted bounding box\")\n",
        "bbox = move2(img, bbox, \"down\")\n",
        "print(plotNpImageBBox(img, bbox))\n",
        "\n",
        "print(\"Down-shifted bounding box\")\n",
        "bbox = move2(img, bbox, \"down\")\n",
        "print(plotNpImageBBox(img, bbox))\n",
        "\n",
        "print(\"Down-shifted bounding box\")\n",
        "bbox = move2(img, bbox, \"down\")\n",
        "print(plotNpImageBBox(img, bbox))\n",
        "\n",
        "\n",
        "print(\"Down-shifted bounding box\")\n",
        "bbox = move2(img, bbox, \"down\")\n",
        "print(plotNpImageBBox(img, bbox))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNBblMU8d4qh"
      },
      "outputs": [],
      "source": [
        "# HORIZONTAL MOVEMENT TESTING \n",
        "TEST_IMAGE_PATH = \"adnet_datasets/OTB/Skater2/img/0005.jpg\"\n",
        "TEST_BBOX = get_ground_truths(\"adnet_datasets/OTB/Skater2/groundtruth_rect.txt\")[4]\n",
        "TEST_IMAGE = cv2.imread(TEST_IMAGE_PATH)\n",
        "\n",
        "img, bbox = TEST_IMAGE, TEST_BBOX\n",
        "print(\"Original bounding box\")\n",
        "print(plotNpImageBBox(img, TEST_BBOX))\n",
        "\n",
        "# Test move left\n",
        "print(\"Left-shifted bounding box\")\n",
        "bbox = move2(img, TEST_BBOX, \"left\")\n",
        "print(plotNpImageBBox(img, bbox))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1MXfEC2IDNk"
      },
      "outputs": [],
      "source": [
        "# MOVEMENT TEST\n",
        "\n",
        "print(\"IOU between {1} and {2} is {0}\".format(calculate_IOU(np.array([143, 131,  34,  87]), np.array([138,  41,  32,  89])), [143, 131,  34,  87], [138,  41,  32,  89]))\n",
        "\n",
        "for i in range(11):\n",
        "  print(selectAction(np.zeros([300, 300, 3]), np.array([252, 65, 25, 30]), i))\n",
        "\n",
        "print(selectAction(np.zeros([300, 300, 3]), np.array([131,7,117,168]), 5))\n",
        "print(\"The following UP should do nothing because 0.03 * 168 * 2 is too large\")\n",
        "print(selectAction(np.zeros([300, 300, 3]), np.array([131,7,117,168]), 5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1j-Ud5nXofHE"
      },
      "outputs": [],
      "source": [
        "print(selectAction(np.zeros([450, 450, 3]), np.array([315,  0, 32,  35]), 5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBBRcPEAohhe"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "safe_reinforce.ipynb",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}