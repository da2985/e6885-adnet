{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c1BWwgpSXW9"
      },
      "source": [
        "### Please use the following two lines to load from Google Drive\n",
        "\n",
        "If your file is not there, upload it to https://drive.google.com/drive/folders/1tsPKyB2E1nW8Qw--kZ9GaeGW2u2-XoV6?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqT6TJ9DLT5v",
        "outputId": "5d575c8c-a23d-4498-a85a-1d2635efc4ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# This must be run within a Google Colab environment \n",
        "from google.colab import drive  \n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2sTHMZwqNPlW"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "sys.path.append('/content/gdrive/EE6885')\n",
        "\n",
        "os.chdir(\"/content/gdrive/My Drive/EE6885\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvlhZxrmdezd",
        "outputId": "dc692f98-af6f-4b9f-82df-72743c70d2c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Basketball  Bolt  CarDark   Crowds  FaceOcc2  Jumping  Matrix\t     Skater\n",
            "Bird2\t    Box   CarScale  Deer    Fish      Lemming  MotorRolling  Skating1\n",
            "BlurCar3    Boy   ClifBar   Doll    Human2    Liquor   Panda\n",
            "Board\t    Car4  Crossing  Dudek   Human6    Man      RedTeam\n"
          ]
        }
      ],
      "source": [
        "!ls adnet_datasets/OTB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNOHmxvDD8wD",
        "outputId": "63b3caef-69d0-4567-d3f2-400246f437e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hdf5storage\n",
            "  Downloading hdf5storage-0.1.18-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.5 MB/s \n",
            "\u001b[?25hCollecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.15.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 22.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py>=2.1 in /usr/local/lib/python3.7/dist-packages (from hdf5storage) (3.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from hdf5storage) (1.19.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.1->hdf5storage) (1.5.2)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons, hdf5storage\n",
            "Successfully installed hdf5storage-0.1.18 tensorflow-addons-0.15.0\n"
          ]
        }
      ],
      "source": [
        "pip install hdf5storage tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gNmhYpyeDLrQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "import tensorflow_probability as tfp\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow.experimental.numpy as tnp\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "import cv2\n",
        "import glob\n",
        "import hdf5storage\n",
        "import math\n",
        "import random\n",
        "import re\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.patches as patches\n",
        "import scipy.io as sio\n",
        "\n",
        "import linecache\n",
        "\n",
        "from typing import Dict, List, Tuple\n",
        "from operator import add\n",
        "import copy\n",
        "\n",
        "from numpy.random import seed\n",
        "from datetime import date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UsXgP5KrEGNW"
      },
      "outputs": [],
      "source": [
        " %load_ext autoreload \n",
        " %autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configurations"
      ],
      "metadata": {
        "id": "HdgRU7dpw6t4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "G3xZrSk9XdEA"
      },
      "outputs": [],
      "source": [
        "#@markdown Network configurations\n",
        "LEARNING_RATE = 1e-4 #@param {type:\"number\"}\n",
        "GOAL_IOU = 0.7 #@param {type:\"number\"}\n",
        "\n",
        "# The length of the action buffer\n",
        "L = 10 #@param {type:\"number\"}\n",
        "# Max Trajectory Length \n",
        "MAX_TRAJECTORY_LENGTH = 20 #@param {type:\"number\"}\n",
        "POLICY_TYPE = \"stochastic\" #@param [\"deterministic\", \"stochastic\"] {type:\"string\"}\n",
        "DROPOUT_4 = 0.5 #@param {type:\"number\"}\n",
        "DROPOUT_5 = 0.5 #@param {type:\"number\"}\n",
        "N_EPOCHS =  5#@param {type:\"number\"}\n",
        "\n",
        "# Number of retries to collect sequence loss sum (to reduce variance)\n",
        "N_RETRIES =   1#@param {type:\"number\"}\n",
        "\n",
        "# Randomizes the order in which frames are trained on from a video clip\n",
        "RANDOMIZE_TRAINING = True #@param {type:\"boolean\"}\n",
        "\n",
        "# The paper uses sum. I thought avg would help address giant swings, but the training was taking way too long\n",
        "# with negligible updates\n",
        "GRAD_ACCUM_SCHEME = \"sum\" #@param [\"avg\", \"sum\"] {type:\"string\"}\n",
        "\n",
        "# Use to avoid overly long trajectories. \n",
        "# During trajectory collection, we were not receiving \n",
        "# enough positvie signals\n",
        "PREMATURE_BREAK = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Loss/Reward Constants\n",
        "# This is a probability offset for adding noise since log(P(a|s)=1)=0\n",
        "PROB_OFFSET = 1e-5 #@param {type:\"number\"} \n",
        "# This is the discount factor\n",
        "GAMMA = 0.99 #@param {type:\"number\"}\n",
        "\n",
        "# final_bbox is used in original Ad Net where  the final bounding box placement \n",
        "# is used in reward calculationfor all actions in a trajectory\n",
        "# individ_bbox individually assign rewards per each bounding box.\n",
        "# only_final_bbox only gives a reward to the final action\n",
        "REWARD_SCHEME = \"only_final_bbox\" #@param [\"only_final_bbox\", \"final_bbox\", \"individ_bbox\"] {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Bounding Box/Patch Constants (probably avoid touching)\n",
        "ALPHA = 0.03 #@param {type:\"number\"}\n",
        "MIN_WINDOW_SIZE = 10 #@param {type:\"number\"}\n",
        "PATCH_X = 112 #@param {type:\"number\"}\n",
        "PATCH_Y = 112 #@param {type:\"number\"}\n",
        "N_CHANNELS = 3 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown ---\n",
        "RANDOM_SEED = 6885\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed(RANDOM_SEED)\n",
        "tf.random.set_seed(RANDOM_SEED)\n",
        "\n",
        "DATASET_PATH = \"adnet_datasets/OTB/*\" #@param {type:\"string\"}\n",
        "ALL_DATASETS_LIST = glob.glob(DATASET_PATH)"
      ],
      "metadata": {
        "id": "AQ4YPvJCt9Dg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Successful Configurations (Minimize Me Please)"
      ],
      "metadata": {
        "id": "QCB-wEWrfk6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### SUCCESSFUL CONFIGS\n",
        "\n",
        "# 12/18 4:41 PM\n",
        "# #@markdown Network configurations\n",
        "# LEARNING_RATE = 1e-4 #@param {type:\"number\"}\n",
        "# # The length of the action buffer\n",
        "# L = 10 #@param {type:\"number\"}\n",
        "# # Max Trajectory Length \n",
        "# MAX_TRAJECTORY_LENGTH = 20 #@param {type:\"number\"}\n",
        "# POLICY_TYPE = \"stochastic\" #@param [\"deterministic\", \"stochastic\"] {type:\"string\"}\n",
        "# DROPOUT_4 = 0.5 #@param {type:\"number\"}\n",
        "# DROPOUT_5 = 0.5 #@param {type:\"number\"}\n",
        "# N_EPOCHS =  1#@param {type:\"number\"}\n",
        "\n",
        "# # Number of retries to collect sequence loss sum (to reduce variance)\n",
        "# N_RETRIES =  4 #@param {type:\"number\"}\n",
        "\n",
        "# # Randomizes the order in which frames are trained on from a video clip\n",
        "# RANDOMIZE_TRAINING = True #@param {type:\"boolean\"}\n",
        "# GRAD_ACCUM_SCHEME = \"sum\" #@param [\"avg\", \"sum\"] {type:\"string\"}\n",
        "# # The paper uses sum\n",
        "\n",
        "\n",
        "# #@markdown ---\n",
        "# #@markdown Loss/Reward Constants\n",
        "# # This is a probability offset for adding noise since log(P(a|s)=1)=0\n",
        "# PROB_OFFSET = 1e-5 #@param {type:\"number\"} \n",
        "# # This is the discount factor\n",
        "# GAMMA = 0.99 #@param {type:\"number\"}\n",
        "# REWARD_SCHEME = \"final_bbox\" #@param [\"final_bbox\", \"individ_bbox\"] {type:\"string\"}\n",
        "\n",
        "# #@markdown ---\n",
        "# #@markdown Bounding Box/Patch Constants (probably avoid touching)\n",
        "# ALPHA = 0.03 #@param {type:\"number\"}\n",
        "# MIN_WINDOW_SIZE = 10 #@param {type:\"number\"}\n",
        "# PATCH_X = 112 #@param {type:\"number\"}\n",
        "# PATCH_Y = 112 #@param {type:\"number\"}\n",
        "# N_CHANNELS = 3 #@param {type:\"number\"}\n",
        "\n",
        "# #@markdown ---\n",
        "# RANDOM_SEED = 6885\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mKjyrVB3fdcT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8s6YHABjUG5"
      },
      "source": [
        "## Model Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfRbj1tuEIyA",
        "outputId": "4aeb4ca2-e89a-4e4b-e143-860dbe544cba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "class ADNET(tf.keras.Model):\n",
        "\n",
        "    ACTION_DIM = 11\n",
        "    K = 10\n",
        "    CONF_SCORE_DIM = 2\n",
        "\n",
        "    def __init__(self):\n",
        "        super(ADNET, self).__init__()\n",
        "\n",
        "        self.action_history = tf.keras.layers.Input(shape = (1,1, ADNET.ACTION_DIM * ADNET.K))\n",
        "\n",
        "        self.conv1 = tf.keras.layers.Conv2D(filters = 96, kernel_size = (7, 7), strides = (2, 2), padding = 'VALID', activation = 'relu', name = 'conv_1')\n",
        "        self.max1  = tf.keras.layers.MaxPooling2D(pool_size=(3,3), strides = (1, 1), padding = 'VALID')\n",
        "        self.conv2 = tf.keras.layers.Conv2D(filters = 256, kernel_size = (5, 5), strides = (2, 2), padding = 'VALID', activation = 'relu', name = 'conv_2')\n",
        "        self.max2  = tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides = (2, 2), padding = 'VALID')\n",
        "        self.conv3 = tf.keras.layers.Conv2D(filters = 512, kernel_size = (3, 3), strides = (2, 2), padding = 'VALID', activation = 'relu', name = 'conv_3')\n",
        "        self.max3  = tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides = (1, 1), padding = 'VALID')\n",
        "        \n",
        "        self.fc1 = tf.keras.layers.Conv2D(filters = 512, kernel_size = (3, 3), padding = 'VALID', activation = 'relu', name = 'fc1')\n",
        "        self.fc2 = tf.keras.layers.Conv2D(filters = 512, kernel_size = (1,1), padding = 'VALID', activation = 'relu', name = 'fc2')\n",
        "        self.fc3 = tf.keras.layers.Conv2D(filters = 11, kernel_size = (1,1), padding = 'VALID', name = 'fc3',activation=\"softmax\")\n",
        "        self.fc4 = tf.keras.layers.Conv2D(filters = 2, kernel_size = (1,1), padding = 'VALID', name = 'fc4',activation=\"softmax\")\n",
        "\n",
        "        # TODO: ADD A SEED\n",
        "        self.dropout1=tf.keras.layers.Dropout(DROPOUT_4)\n",
        "        self.dropout2=tf.keras.layers.Dropout(DROPOUT_5)\n",
        "        \n",
        "\n",
        "    def build(self):\n",
        "      super(ADNET, self).build((None, 112, 112, 3))\n",
        "      self.action_history = np.zeros(shape = (1,1,1,110))\n",
        "\n",
        "\n",
        "    def call(self, input_tensor, training=False):\n",
        "        x = self.conv1(input_tensor)\n",
        "        x = self.max1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.max2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.max3(x)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = tf.keras.layers.Concatenate(axis=-1)([x, self.action_history])\n",
        "        action = self.fc3(x)\n",
        "        confidence = self.fc4(x)\n",
        "        return [action, confidence]\n",
        "\n",
        "\n",
        "    def compile(self, optimizer):\n",
        "   \t\tsuper().compile(optimizer, loss={\n",
        "         'output_1':tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "         'output_2': tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "         })\n",
        "     \n",
        "    def getEmbedding(self,input_tensor):\n",
        "        x = self.conv1(input_tensor)\n",
        "        x = self.max1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.max2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.max3(x)\n",
        "        return tf.reshape(x,(-1,))\n",
        "\n",
        "    def getFC1(self,input_tensor):\n",
        "        x = self.conv1(input_tensor)\n",
        "        x = self.max1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.max2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.max3(x)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "    def setActionHistory(self, action_history):\n",
        "      self.action_history = action_history.reshape(\n",
        "          (1, 1, 1, ADNET.ACTION_DIM * ADNET.K))\n",
        "\n",
        "    def updateActionHistory(self, a: int=8) -> tnp.ndarray:\n",
        "      '''\n",
        "      Left-to-right FIFO queue of actions\n",
        "      '''\n",
        "      ah = np.array(self.action_history).flatten()\n",
        "      ah[ADNET.ACTION_DIM:] = ah[:-ADNET.ACTION_DIM]\n",
        "      ah[:ADNET.ACTION_DIM] = 0 \n",
        "      ah[a] = 1\n",
        "      self.setActionHistory(ah)\n",
        "      return ah\n",
        "\n",
        "    def clearActionHistory(self):\n",
        "      self.action_history = tf.zeros((1, 1, 1, ADNET.ACTION_DIM * ADNET.K))\n",
        "\n",
        "    def getPrettyActionHistory(self):\n",
        "      action_hist = tf.reshape(self.action_history, [-1])\n",
        "      sbuffer = \"[\"\n",
        "      for i, x in enumerate(action_hist):\n",
        "        if i > 0 and i % ADNET.ACTION_DIM == 0:\n",
        "          sbuffer+= \"\\x1b[35m,\\x1b[0m\"\n",
        "        if x == 1:\n",
        "          sbuffer += \"\\x1b[35m{0}\\x1b[0m\".format(int(x))\n",
        "        else:\n",
        "          sbuffer += \"{0}\".format(int(x))\n",
        "      sbuffer += \"]\"\n",
        "      return sbuffer \n",
        "\n",
        "\n",
        "    def debugModelSummary(self):\n",
        "      '''\n",
        "      call model.debugModelSummary().summary() to get around the inconvenience \n",
        "      from model.summary() returning 'multiple' for each layer's output shape\n",
        "      '''\n",
        "      dummyInput = tf.keras.layers.Input(shape = (112,112,3))\n",
        "      return tf.keras.Model(inputs=[dummyInput], outputs = self.call(dummyInput))\n",
        "\n",
        "def setWeights(model, weights, weights2):\n",
        "  model.layers[0].set_weights([weights2[\"conv1f\"],tf.reshape(weights2[\"conv1b\"],(96,))])\n",
        "  model.layers[2].set_weights([weights2[\"conv2f\"],tf.reshape(weights2[\"conv2b\"],(256,))])\n",
        "  model.layers[4].set_weights([weights2[\"conv3f\"],tf.reshape(weights2[\"conv3b\"],(512,))])\n",
        "  \n",
        "  model.layers[6].set_weights([weights[\"fc4f\"],tf.reshape(weights[\"fc4b\"],(512,))])\n",
        "  model.layers[7].set_weights([weights[\"fc5f\"],tf.reshape(weights[\"fc5b\"],(512,))])\n",
        "  model.layers[8].set_weights([weights[\"fc6_1f\"],tf.zeros(11)])\n",
        "  model.layers[9].set_weights([weights[\"fc6_2f\"],tf.zeros(2)])\n",
        "  \n",
        "  return model\n",
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WwHHmGrxq-b6"
      },
      "outputs": [],
      "source": [
        "class ADNET_v2(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(ADNET_v2, self).__init__()\n",
        "\n",
        "        #self.action_history = tf.keras.layers.Input(shape = (1,1,110))\n",
        "        self.action_history = tf.keras.layers.Input(shape = (110))\n",
        "\n",
        "        self.resnet=tf.keras.applications.ResNet50V2(include_top=False,weights=\"imagenet\",input_shape=(112,112,3),pooling=\"max\")\n",
        "        #self.resnet = tf.keras.applications.ResNet50V2(include_top=False,weights=\"imagenet\",input_shape=(112,112,3),pooling=None)\n",
        "        #self.conv1 = tf.keras.layers.Conv2D(filters = 128, kernel_size = (4,4), padding = 'VALID', name = 'fc4',activation=\"relu\")\n",
        "        \n",
        "        self.fc1 = tf.keras.layers.Dense(512,kernel_initializer='glorot_uniform',activation = 'relu', name = 'fc1')\n",
        "        self.fc2 = tf.keras.layers.Dense(512,kernel_initializer='glorot_uniform', activation = 'relu', name = 'fc2')\n",
        "        self.fc3 = tf.keras.layers.Dense(11,kernel_initializer='glorot_uniform', name = 'fc3',activation=\"softmax\")\n",
        "        self.fc4 = tf.keras.layers.Dense(2,kernel_initializer='glorot_uniform',name = 'fc4',activation=\"softmax\")\n",
        "\n",
        "        self.dropout1=tf.keras.layers.Dropout(0)\n",
        "        self.dropout2=tf.keras.layers.Dropout(0)\n",
        "        \n",
        "\n",
        "    def build(self, action_history):\n",
        "      super(ADNET_v2, self).build((None, 112, 112, 3))\n",
        "      self.action_history=action_history\n",
        "      self.resnet.trainable = False\n",
        "\n",
        "\n",
        "    def setActionHistory(self, action_history):\n",
        "      self.action_history=action_history\n",
        "\n",
        "\n",
        "    def call(self, input_tensor, training=False):\n",
        "        x = self.resnet(input_tensor)\n",
        "        #x = self.conv1(x)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x=  self.dropout1(x)\n",
        "        x = self.fc2(x)\n",
        "        x=  self.dropout2(x)\n",
        "        x = tf.keras.layers.Concatenate(axis=-1)([x, self.action_history])\n",
        "        action = self.fc3(x)\n",
        "        confidence = self.fc4(x)\n",
        "        return [action, confidence]\n",
        "\n",
        "     \n",
        "    def debugModelSummary(self):\n",
        "      '''\n",
        "      call model.debugModelSummary().summary() to get around the inconvenience \n",
        "      from model.summary() returning 'multiple' for each layer's output shape\n",
        "      '''\n",
        "      dummyInput = tf.keras.layers.Input(shape = (112,112,3))\n",
        "      return tf.keras.Model(inputs=[dummyInput], outputs = self.call(dummyInput))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ADNET_v3(tf.keras.Model):\n",
        "\n",
        "    ACTION_DIM = 11\n",
        "    K = 10\n",
        "    CONF_SCORE_DIM = 2\n",
        "\n",
        "\n",
        "    def __init__(self):\n",
        "        super(ADNET_v3, self).__init__()\n",
        "\n",
        "        self.conv1 = tf.keras.layers.Conv2D(filters = 96, kernel_size = (7, 7), strides = (2, 2), padding = 'VALID', activation = 'relu', name = 'conv_1')\n",
        "        self.max1  = tf.keras.layers.MaxPooling2D(pool_size=(3,3), strides = (1, 1), padding = 'VALID')\n",
        "        self.conv2 = tf.keras.layers.Conv2D(filters = 256, kernel_size = (5, 5), strides = (2, 2), padding = 'VALID', activation = 'relu', name = 'conv_2')\n",
        "        self.max2  = tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides = (2, 2), padding = 'VALID')\n",
        "        self.conv3 = tf.keras.layers.Conv2D(filters = 512, kernel_size = (3, 3), strides = (2, 2), padding = 'VALID', activation = 'relu', name = 'conv_3')\n",
        "        self.max3  = tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides = (1, 1), padding = 'VALID')\n",
        "        \n",
        "        self.fc1 = tf.keras.layers.Conv2D(filters = 512, kernel_size = (3, 3), padding = 'VALID', activation = 'relu', name = 'fc1')\n",
        "        self.rnn = CustomRNN()\n",
        "        \n",
        "    def build(self,action_history):\n",
        "      super(ADNET_v3, self).build((None, 112, 112, 3))\n",
        "      self.rnn.setActionHistory(action_history)\n",
        "\n",
        "    def call(self, input_tensor, training=False):\n",
        "        x = self.conv1(input_tensor)\n",
        "        x = self.max1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.max2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.max3(x)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        action,confidence = self.rnn(x)\n",
        "        return [action, confidence]\n",
        "\n",
        "    def callForAction(self, input_tensor, training=False):\n",
        "      '''\n",
        "      Wrapper action for model.call() to only output action probabilities.\n",
        "      For RL purposes, this is the only relevant output (as of 12/2/2021).\n",
        "      '''\n",
        "      return self.call(input_tensor, training)[0]\n",
        "\n",
        "    def clearActionHistory(self):\n",
        "      self.rnn.clearActionHistory()\n",
        "\n",
        "    def compile(self, optimizer):\n",
        "      super().compile(optimizer, loss={\n",
        "         'output_1':tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "         'output_2': tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "         })\n",
        "      \n",
        "    def debugModelSummary(self):\n",
        "      '''\n",
        "      call model.debugModelSummary().summary() to get around the inconvenience \n",
        "      from model.summary() returning 'multiple' for each layer's output shape\n",
        "      '''\n",
        "      dummyInput = tf.keras.layers.Input(shape = (112,112,3))\n",
        "      return tf.keras.Model(inputs=[dummyInput], outputs = self.call(dummyInput))\n",
        "\n",
        "class CustomRNN(layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(CustomRNN, self).__init__()\n",
        "        self.projection_1 = tf.keras.layers.Conv2D(filters = 512, kernel_size = (1, 1), padding = 'VALID')\n",
        "        self.projection_2 = tf.keras.layers.Conv2D(filters = 512, kernel_size = (1, 1), padding = 'VALID')\n",
        "        self.action_history = tf.zeros(shape = (1,1,1,512))\n",
        "        self.action_classifier = tf.keras.layers.Conv2D(filters = 11, kernel_size = (1,1), padding = 'VALID',activation=\"softmax\")\n",
        "        self.confidence_classifier = tf.keras.layers.Conv2D(filters = 2, kernel_size = (1,1), padding = 'VALID',trainable=False,activation=\"softmax\")\n",
        "\n",
        "    def call(self, input):\n",
        "        h = self.projection_1(self.action_history)\n",
        "        y = h + self.projection_2(input)\n",
        "        new_action_history = tf.math.tanh(y)\n",
        "        self.setActionHistory(new_action_history)\n",
        "        action = self.action_classifier(y)\n",
        "        confidence = self.confidence_classifier(y)\n",
        "        return action,confidence\n",
        "\n",
        "    def setActionHistory(self, action_history):\n",
        "      self.action_history = action_history\n",
        "    \n",
        "    def clearActionHistory(self):\n",
        "      self.setActionHistory(tf.zeros((1, 1, 1, 512)))"
      ],
      "metadata": {
        "id": "bCLcyTuXD64i"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcjMuA1EjRsE"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xY2WCmjC2gLN"
      },
      "source": [
        "### Plotting & Debugging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "NtQ22_87T8MQ"
      },
      "outputs": [],
      "source": [
        "def get_ground_truths(ground_truth_file: str) -> np.array:\n",
        "  '''\n",
        "  Use me to convert a ground_truth_file to a numpy array\n",
        "  '''\n",
        "  with open(ground_truth_file) as f:\n",
        "    ground_truths = f.readlines()\n",
        "    to_nparray = lambda s: np.array(re.findall('\\d+', s), dtype=int)\n",
        "    truths = list(map(to_nparray, ground_truths))\n",
        "    return np.asarray(truths)\n",
        "  return None\n",
        "\n",
        "def plotNpImageBBox(img: np.array, bbox: np.array) -> np.array:\n",
        "  '''\n",
        "  Plots the bounding box on an image and returns the bounding box\n",
        "  '''\n",
        "  fig, ax = plt.subplots()\n",
        "  x, y, w, h = bbox\n",
        "  rect = patches.Rectangle((x, y), w, h, linewidth=1, edgecolor='r', facecolor='none')\n",
        "  ax.add_patch(rect)\n",
        "  plt.imshow(img)\n",
        "  return bbox\n",
        "\n",
        "def plotNpImageBBoxes(img: np.array, src_bbox: np.array, target_bbox: np.array, \n",
        "                      pred_bbox: np.array) -> np.array:\n",
        "  '''\n",
        "  Plots the bounding boxes on an image and returns the bounding box\n",
        "  '''\n",
        "  fig, ax = plt.subplots()\n",
        "  x1, y1, w1, h1 = src_bbox\n",
        "  x2, y2, w2, h2 = target_bbox\n",
        "  x3, y3, w3, h3 = pred_bbox\n",
        "  rect1 = patches.Rectangle((x1, y1), w1, h1, linewidth=1, edgecolor='b', facecolor='none')\n",
        "  rect2 = patches.Rectangle((x2, y2), w2, h2, linewidth=1, edgecolor='g', facecolor='none')\n",
        "  rect3 = patches.Rectangle((x3, y3), w3, h3, linewidth=1, edgecolor='r', facecolor='none')\n",
        "  ax.add_patch(rect1)\n",
        "  ax.add_patch(rect2)\n",
        "  ax.add_patch(rect3)\n",
        "  plt.imshow(img)\n",
        "  return pred_bbox  \n",
        "\n",
        "def plotImageBBox(img: str, bbox: np.array) -> np.array:\n",
        "  '''\n",
        "  Plots the bounding box on an image (from given filepath) and returns the \n",
        "  bounding box\n",
        "  '''\n",
        "  img = cv2.imread(img)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  plotNpImageBBox(img, bbox)\n",
        "  return bbox\n",
        "\n",
        "def plotDatasetImageBBox(dataset: str, frame_no: int) -> Tuple[np.array, int]:\n",
        "  '''\n",
        "  Plot an image's bounding box. Returns the ground truth and frame number.\n",
        "  WORKS FOR OTB100\n",
        "  '''\n",
        "  imgs = sorted(glob.glob(\"{0}/img/*\".format(dataset)))\n",
        "  gt = get_ground_truths(\"{0}/groundtruth_rect.txt\".format(dataset))\n",
        "  plotImageBBox(imgs[frame_no], gt[frame_no])\n",
        "  return gt[frame_no], frame_no\n",
        "\n",
        "\n",
        "# print(plotDatasetImageBBox(\"adnet_datasets/OTB/Basketball\", 50)[0])\n",
        "#print(plotDatasetImageBBox(\"adnet_datasets/OTB/BlurBody\", 10)[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def standardize_bbox(img: np.array, bbox: np.array):\n",
        "  '''\n",
        "  Refits the bounding box to ensure that it is valid. X and Y get clipped first.\n",
        "  Assumes reasonable bounding boxes and solely for the bad data we found in\n",
        "  our ground truth dataset\n",
        "  '''\n",
        "  x, y, w, h = bbox\n",
        "  nx, ny, nw, nh = bbox\n",
        "\n",
        "  is_invalid = False\n",
        "  import pdb\n",
        "  # pdb.set_trace()\n",
        "  if x < 0 or x + w >= img.shape[1]:\n",
        "    w = np.clip(w, MIN_WINDOW_SIZE, img.shape[1])\n",
        "    # clip whichever keeps the most area    \n",
        "    x1 = np.clip(x, 0, img.shape[1] - 1)\n",
        "    w1 = np.clip(w, MIN_WINDOW_SIZE, img.shape[1] - x1)\n",
        "    x2 = np.clip(x, 0, img.shape[1] - w)\n",
        "    w2 = np.clip(w, MIN_WINDOW_SIZE, img.shape[1])\n",
        "    nx, nw = (x1, w1) if x1 + w1 > x2 + w2 else (x2, w2)\n",
        "    is_invalid = True\n",
        "\n",
        "  if y < 0 or y + h >= img.shape[0]:\n",
        "    h = np.clip(h, MIN_WINDOW_SIZE, img.shape[0])\n",
        "    # clip whichever keeps the most area\n",
        "    y1 = np.clip(y, 0, img.shape[0] - 1)\n",
        "    h1 = np.clip(h, MIN_WINDOW_SIZE, img.shape[0] - y1)\n",
        "    y2 = np.clip(y, 0, img.shape[0] - h)\n",
        "    h2 = np.clip(h, MIN_WINDOW_SIZE, img.shape[0])\n",
        "    ny, nh = (y1, h1) if y1 + h1 > y2 + h2 else (y2, h2)\n",
        "    is_invalid = True\n",
        "  \n",
        "  stdzd_bbox = np.array([nx, ny, nw, nh])\n",
        "  if is_invalid: \n",
        "    print(\"WARNING: Bounding box: {0} had to be standardized to {1}\".format(bbox, stdzd_bbox))\n",
        "  return stdzd_bbox"
      ],
      "metadata": {
        "id": "XBp2Cyrf8nty"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX5bfwFm2c80"
      },
      "source": [
        "### Movement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "VzDdHq04ERNg"
      },
      "outputs": [],
      "source": [
        "STOP_ACTION_INDEX = 8\n",
        "\n",
        "\n",
        "def calculate_IOU(bbox1: np.array, bbox2: np.array):\n",
        "    x1, y1, w1, h1 = bbox1\n",
        "    x2, y2, w2, h2 = bbox2\n",
        "           \n",
        "    i_x1 = max(x1, x2)\n",
        "    i_y1 = max(y1, y2)\n",
        "    i_x2 = min(x1 + w1, x2 + w2)\n",
        "    i_y2 = min(y1 + h1, y2 + h2)\n",
        "    if i_x1 >= i_x2 or i_y1 >= i_y2:\n",
        "      return 0.0\n",
        "\n",
        "    intersection_area = (i_x2 - i_x1) * (i_y2 - i_y1)\n",
        "    box1_area = w1 * h1\n",
        "    box2_area = w2 * h2\n",
        "    \n",
        "    iou = intersection_area / float(box1_area + box2_area - intersection_area)\n",
        "    return iou\n",
        "\n",
        "\n",
        "def move(image: np.array, bbox: np.array, action: str, \n",
        "         stride_magnitude: int=1) -> np.array:\n",
        "  '''\n",
        "  Returns the new bounding box after taking an action: \n",
        "  {\"left\", \"right\", \"up\", \"down\"}. Use stride to indicate the step size.\n",
        "  '''\n",
        "  if action not in set([\"left\", \"right\", \"up\", \"down\"]):\n",
        "    raise RuntimeError(\"Invalid action taken :(\") \n",
        "  \n",
        "  x, y, w, h = bbox\n",
        "  if action in set([\"left\", \"right\"]):\n",
        "    step = max(1, int(ALPHA * w)) * stride_magnitude * (-1 if action==\"left\" else 1)\n",
        "    x = min(max(0, int(x + step)), int(image.shape[1] - w - 1)) \n",
        "  else:\n",
        "    step = max(1, int(ALPHA * h)) * stride_magnitude * (-1 if action==\"up\" else 1)\n",
        "    y = min(max(0, int(y + step)), int(image.shape[0] - h - 1)) \n",
        "\n",
        "  return np.array([x, y, w, h])\n",
        "\n",
        "\n",
        "def scale(image: np.array, bbox: np.array, scaleUp: bool):\n",
        "  x, y, w, h = bbox\n",
        "  deltaW, deltaH = max(2, ALPHA * w), max(2, ALPHA * h)\n",
        "  if not scaleUp: \n",
        "    deltaW *= -1\n",
        "    deltaH *= -1\n",
        "  w = min(image.shape[1], max(MIN_WINDOW_SIZE, int(w + deltaW))) \n",
        "  h = min(image.shape[0], max(MIN_WINDOW_SIZE, int(h + deltaH)))\n",
        "  x = max(0, min(int(x - deltaW / 2), int(image.shape[1] - w - 1)))\n",
        "  y = max(0, min(int(y - deltaH / 2), int(image.shape[0] - h - 1)))\n",
        "  return np.array([x, y, w, h])\n",
        "\n",
        "\n",
        "def selectAction(img: np.array, bbox: np.array, index: int): \n",
        "  if index == 0 :\n",
        "    bbox = move(img, bbox, \"left\")\n",
        "  elif index == 1 :\n",
        "    bbox = move(img, bbox, \"left\", stride_magnitude=2)\n",
        "  elif index == 2 :\n",
        "    bbox = move(img, bbox, \"right\")\n",
        "  elif index == 3 :\n",
        "    bbox = move(img, bbox, \"right\", stride_magnitude=2)  \n",
        "  elif index == 4 :\n",
        "    bbox = move(img, bbox, \"up\")  \n",
        "  elif index == 5 :\n",
        "    bbox = move(img, bbox, \"up\", stride_magnitude=2)\n",
        "  elif index == 6 :\n",
        "    bbox = move(img, bbox, \"down\")\n",
        "  elif index == 7 :\n",
        "    bbox = move(img, bbox, \"down\", stride_magnitude=2)\n",
        "  elif index == 8:\n",
        "    bbox = bbox\n",
        "  elif index == 9 :\n",
        "    bbox = scale(img, bbox, False)     \n",
        "  elif index == 10 :\n",
        "    bbox = scale(img, bbox, True)      \n",
        "\n",
        "  x, y, w, h = bbox\n",
        "\n",
        "  \"\"\"\n",
        "  assert 0 <= x <= img.shape[1] - w, \"x:{0}, w:{1} is out of bounds: [0, {2})\".format(x, w, img.shape[1] - 1)\n",
        "  assert 0 <= y <= img.shape[0] - h, \"y:{0}, h:{1} is out of bounds: [0, {2})\".format(y, h, img.shape[0] - 1)\n",
        "  assert MIN_WINDOW_SIZE <= w <= img.shape[1], \"w:{0}, is invalid\".format(w)\n",
        "  assert MIN_WINDOW_SIZE <= h <= img.shape[0], \"h:{0} is invalid\".format(h)\n",
        "  \"\"\"\n",
        "  return index, bbox\n",
        "\n",
        "\n",
        "def human_readable_action(index: int) -> str:\n",
        "  '''\n",
        "  Map action numbers to human readable strings\n",
        "  '''\n",
        "  def _get_action(index:int) -> str:\n",
        "    if index == 0:\n",
        "      return \"left\"\n",
        "    elif index == 1:\n",
        "      return \"2x left\"\n",
        "    elif index == 2:\n",
        "      return \"right\"\n",
        "    elif index == 3:\n",
        "      return \"2x right\"\n",
        "    elif index == 4:\n",
        "      return \"up\"\n",
        "    elif index == 5:\n",
        "      return \"2x up\"\n",
        "    elif index == 6:\n",
        "      return \"down\"\n",
        "    elif index == 7:\n",
        "      return \"2x down\"\n",
        "    elif index == 8:\n",
        "      return \"stop\"\n",
        "    elif index == 9:\n",
        "      return \"scale down\"\n",
        "    elif index == 10 :\n",
        "      return \"scale up\"\n",
        "  return _get_action(index).upper()\n",
        "\n",
        "\n",
        "def getAction(img: np.array, bbox: np.array, action_probs: np.array):  \n",
        "  \n",
        "  action_probs = np.array(action_probs) + PROB_OFFSET\n",
        "  action_probs /= action_probs.sum()\n",
        "  \n",
        "  a = np.random.choice(np.arange(len(action_probs)), p=action_probs)\n",
        "  if POLICY_TYPE == \"deterministic\":\n",
        "    a = tf.math.argmax(action_probs)\n",
        "  return selectAction(img, bbox, a)\n",
        "\n",
        "\n",
        "def isStop(action: int):\n",
        "  return action == STOP_ACTION_INDEX\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLxdpmQ5jOjL"
      },
      "source": [
        "# REINFORCE Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CP9qJBgVq5B"
      },
      "source": [
        "### Trajectory Loss Function\n",
        "\n",
        "TODO: investigate adding https://www.analyticsvidhya.com/blog/2020/11/baseline-for-policy-gradients/\n",
        "Or rather https://arxiv.org/pdf/1301.2315.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Id7dQxPDVtJ_"
      },
      "outputs": [],
      "source": [
        "def getNonStopScore(bbox1: np.array, bbox2: np.array, gt: np.array) -> float:\n",
        "  # Issues with this blowing up the gradient in the wrong direction\n",
        "\n",
        "  def _dist(x1, y1, x2, y2):\n",
        "    return math.sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2)\n",
        "  \n",
        "  prevIou = calculate_IOU(bbox1, gt) \n",
        "  nextIou = calculate_IOU(bbox2, gt)\n",
        "  x1, y1 = bbox1[:2]\n",
        "  x2, y2 = bbox2[:2]\n",
        "  xg, yg = gt[:2]\n",
        "\n",
        "  # if prevIou == nextIou: EXPERIMENTED WITH USING EUCLIDEAN DISTANCE\n",
        "  #   return -1 * (_dist(x2, y2, xg, yg) - _dist(x1, y1, xg, yg))\n",
        "  result = nextIou - prevIou \n",
        "  return result \n",
        "\n",
        "def seqLosses(action_probs: List[np.array], actions_taken: List[int], \n",
        "              bboxes: List[np.array], \n",
        "              target_bbox: np.array) -> np.array:\n",
        "\n",
        "    assertMsg = \"Invalid trajectory: actions taken ({0}) + 1 != Bboxes length ({1})\".format(\n",
        "              len(actions_taken), len(bboxes)) \n",
        "    assert len(actions_taken) + 1 == len(bboxes), assertMsg\n",
        "          \n",
        "    src_bbox = np.array(bboxes[0])\n",
        "    end_bbox = np.array(bboxes[-1])\n",
        "    print(\"\\x1b[34m>> Calculating frame loss : {0} -> {1} (Target was {2})\\x1b[0m\".format(\n",
        "            np.array2string(src_bbox, separator=', '),\n",
        "            np.array2string(end_bbox, separator=', '),\n",
        "            np.array2string(target_bbox, separator=', ')))\n",
        "    rewards = np.zeros(len(actions_taken))\n",
        "    discounts = np.zeros(len(actions_taken))\n",
        "    for i, a in enumerate(actions_taken):\n",
        "      prev_bbox = np.array(bboxes[i])\n",
        "      next_bbox = np.array(bboxes[i+1])\n",
        "      ###################### CHANGE REWARD CALCULATION HERE ####################\n",
        "      if REWARD_SCHEME == \"final_bbox\":\n",
        "        rewards[i] = 1 if calculate_IOU(end_bbox, target_bbox) > GOAL_IOU\\\n",
        "                      else -1      \n",
        "      else:\n",
        "        if isStop(a):\n",
        "          rewards[i] = 1 if calculate_IOU(next_bbox, target_bbox) > GOAL_IOU else -1\n",
        "        else:\n",
        "          rewards[i] = getNonStopScore(prev_bbox, next_bbox, target_bbox) \n",
        "      ###################### CHANGE REWARD CALCULATION UP ABOVE ################\n",
        "      prob_a = action_probs[i][a]\n",
        "      discounts[i] = GAMMA ** i\n",
        "      print(\"   |->> t={0} {1}-Reward ({2}) for {3}:bbox transition: {4} -> {5} w/ P(a|s)={6} and iou={7} and reward={8} and discount={9}\"\n",
        "            .format(i+1, \"Stop\" if isStop(a) else \"Diff\", \n",
        "                    np.around(rewards[i], decimals=3), \n",
        "                    human_readable_action(a).upper(),\n",
        "                    np.array2string(prev_bbox, separator=', '),\n",
        "                    np.array2string(next_bbox, separator=', '), prob_a, \n",
        "                    calculate_IOU(next_bbox, target_bbox), \n",
        "                    rewards[i], discounts[i]), \n",
        "            )\n",
        "    \n",
        "    gather_idx = [[i, a] for i, a in enumerate(actions_taken)]\n",
        "    p_a = tf.gather_nd(tf.stack(action_probs), gather_idx)\n",
        "    p_a = tf.clip_by_value(p_a, PROB_OFFSET, 1 - PROB_OFFSET) # done to prevent 0 reward   \n",
        "    \n",
        "    entropy = -1 * tf.math.reduce_sum((tf.math.log(action_probs) * action_probs), \n",
        "                                 axis=1) \n",
        "    \n",
        "    discount = tf.convert_to_tensor(discounts, dtype=tf.float32)\n",
        "    losses = -1 * (discount * rewards * tf.math.log(p_a))\n",
        "    \n",
        "    \n",
        "    print(\"   |->> Assigned losses: {0}\".format(losses))\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMujgGmUVu4k"
      },
      "source": [
        "### Tracking Procedure\n",
        "\n",
        "* This function collects trajectories either via argmax deterministic policy or sampling from a stochastic policy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "EqN0GHI5VlAM"
      },
      "outputs": [],
      "source": [
        "def getPatch(img: np.array, bbox: np.array) -> tf.Tensor:\n",
        "  def _patch(img: np.array, bbox: np.array) -> np.array:\n",
        "    x, y, w, h, = bbox\n",
        "    return img[y : (y + h), x : (x + w)]\n",
        "      \n",
        "  patch = tf.image.resize(_patch(img, bbox), [PATCH_X, PATCH_Y])\n",
        "  return tf.reshape(patch, (1, PATCH_X, PATCH_Y, N_CHANNELS))\n",
        "\n",
        "\n",
        "def tracking(model: ADNET, img: np.array, bbox: np.array,\n",
        "             t: int, target_bbox: np.array, \n",
        "             tracking_length: int= MAX_TRAJECTORY_LENGTH):\n",
        "    \"\"\" \n",
        "    Runs tracking until # actions > MAX_ACTIONS_SEQ_LIMIT, STOP is taken, or\n",
        "    oscillation occurs.\n",
        "    \"\"\"\n",
        "    print(\"|->> Beginning tracking for bbox:{0}\".format(bbox)) \n",
        "\n",
        "    patch = getPatch(img, bbox)\n",
        "    actions_taken = []\n",
        "    action_probs = []\n",
        "    bboxes = [tuple(bbox)]\n",
        "    prev_score = None\n",
        "    while len(actions_taken) < tracking_length:\n",
        "      prev_bbox = bbox.copy()\n",
        "      \n",
        "      probs, conf_score = model(patch)\n",
        "      probs = tf.reshape(probs, (model.ACTION_DIM)) \n",
        "      \n",
        "      a, bbox = getAction(np.array(img), bbox, probs)\n",
        "      prev_iou = calculate_IOU(prev_bbox, target_bbox)      \n",
        "      iou = calculate_IOU(bbox, target_bbox)   \n",
        "\n",
        "      if tuple(bbox) in bboxes:\n",
        "        print(\"|->> Revisiting bbox: {0}. Breaking action sequence\"\n",
        "                  .format(bbox))\n",
        "        print(\"   |->> Trajectory ending is FORCED\".format(iou))\n",
        "        a, bbox = 8, prev_bbox\n",
        "        if len(actions_taken) > 0:\n",
        "          # We observed too many trajectory STOPS were leading to gradient updates\n",
        "          # that reduce P(STOP|s) to near 0, which is undesirable. In this case, \n",
        "          # we allow STOPs if selected naturally by the policy or it's the only \n",
        "          # action on a trajectory (a trajectory MUST \n",
        "          # have at least one action). All other STOPs we just forego\n",
        "          # to prevent these harmful gradient updates\n",
        "          break\n",
        "      elif PREMATURE_BREAK and iou < GOAL_IOU  and prev_iou > GOAL_IOU:\n",
        "        # TRAJECTORY IS WORSENING\n",
        "        print(\"             |->> IOU declining: {0}:{1} -> {2}:{3}.\"\n",
        "                  .format(prev_bbox, prev_iou, bbox, iou))\n",
        "        print(\"             |->> Overriding with STOP\"\n",
        "                .format(iou))\n",
        "        a, bbox = 8, prev_bbox\n",
        "      \n",
        "      a_prob = probs[a] \n",
        "      print(\"   \\x1b[33m|->> #{0}/t={1}-th Action selection: {2}/{3} (P(a|s) = {4})\\x1b[0m\"\n",
        "                .format(len(actions_taken), t, a, human_readable_action(a).upper(), \n",
        "                        np.around(a_prob, decimals=3)))\n",
        "      print(\"      |->> Bounding box moves to: {0}\"\n",
        "                .format(bbox))\n",
        "      print(\"         |->> Action Probabilities (Rounded): {0}, argmax={1}\"\n",
        "              .format(np.around(probs.numpy(), decimals=4), np.argmax(probs)))\n",
        "      print(\"         |->> Action Probabilities (RAW): {0}, argmax={1}\"\n",
        "              .format(probs.numpy(), np.argmax(probs)))\n",
        "\n",
        "      if VERBOSE:\n",
        "        print(\"         |->> Overwriting action in buffer {0}\"\n",
        "            .format(model.getPrettyActionHistory() if VERBOSE else \"\"))\n",
        "        \n",
        "      action_probs.append(probs)\n",
        "      actions_taken.append(a)\n",
        "      #model.updateActionHistory(a) no needed rnn does it internally\n",
        "      bboxes.append(tuple(bbox))  \n",
        "      patch = getPatch(img, bbox)      \n",
        "\n",
        "      # Stopping condition\n",
        "      if isStop(a):\n",
        "        print(\"         |->> Hit a STOP on the {0}-th action!\".format(t))\n",
        "        break  \n",
        "      \n",
        "      t += 1\n",
        "\n",
        "    print(\"    \\x1b[31m|->> Completed tracking\\x1b[0m\")\n",
        "    \n",
        "    return action_probs, actions_taken, bboxes, t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akOkB6DOxC_v"
      },
      "source": [
        "### Single Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "4w8_6oDV7900"
      },
      "outputs": [],
      "source": [
        "VERBOSE = False\n",
        "\n",
        "def getFrame(dataset: str, frame: int) -> np.array:\n",
        "  f_path = \"{0}/img/{1}.jpg\".format(dataset, str(frame).zfill(4))\n",
        "  print(\"Frame path: {0}\".format(f_path))\n",
        "  img = cv2.imread(f_path)\n",
        "  return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\n",
        "def train(model: ADNET, opt: tf.keras.optimizers.Optimizer, \n",
        "          dataset: str, start_frame: int, end_frame: int, \n",
        "          retry_count: int=N_RETRIES) -> float:\n",
        "  '''\n",
        "  Run training for a model on a frame sequence {start_frame, end_frame} \n",
        "  n_retries times.\n",
        "  :param: dataset: is the dataset path to train from\n",
        "  :param: retry_count: number of times to train on the frame sequence. \n",
        "  :return: returns the model and average loss\n",
        "  '''\n",
        "\n",
        "  gt = get_ground_truths(\"%s/groundtruth_rect.txt\" % dataset)\n",
        "  frames = sorted(glob.glob(os.path.join('%s/img' % dataset, '*.jpg'))) \n",
        "  loss = 0.0\n",
        "\n",
        "  train_vars = model.trainable_variables\n",
        "  accum_gradient = [tf.zeros_like(this_var) for this_var in train_vars]\n",
        "  for i in range(retry_count):\n",
        "    print(\"\\n\\x1b[36m####################### EPISODE # {0} ############################\\x1b[0m\".format(i+1))\n",
        "    bbox = gt[start_frame]\n",
        "    print(\"Starting bounding box for {0}: frames {1}:{2} is {3}.\".format(dataset, start_frame, end_frame, bbox))\n",
        "    \n",
        "    t = 1    \n",
        "    model.clearActionHistory()\n",
        "    for i in range(start_frame+1, end_frame+1):\n",
        "      with tf.GradientTape() as tape:\n",
        "        target_bbox = gt[i]\n",
        "        prev_bbox = np.array(bbox, copy=True)\n",
        "\n",
        "        print(\"\\x1b[34m>> Attempting to reach frame {0} with src: {1} and target: {2}\\x1b[0m\"\n",
        "            .format(i, np.array2string(bbox, separator=', '), \n",
        "                    np.array2string(target_bbox, separator=', ')))\n",
        "        img = getFrame(dataset, i) \n",
        "        action_probs, taken_actions, bboxes, t = tracking(model, img, \n",
        "                                                          bbox, t, target_bbox)\n",
        "        bbox = np.array(bboxes[-1])\n",
        "\n",
        "\n",
        "        frame_losses = seqLosses(action_probs, taken_actions, bboxes, target_bbox)\n",
        "        total_frame_loss = tf.reduce_sum(frame_losses)\n",
        "        \n",
        "        loss += np.sum(total_frame_loss.numpy())\n",
        "        print(\"{0}>> Total frame loss: {1}\\x1b[0m\".format(\n",
        "              \"\\x1b[92m\" if total_frame_loss > 0 else \"\\x1b[31m\", \n",
        "              total_frame_loss))\n",
        "\n",
        "      gradients = tape.gradient(total_frame_loss, train_vars)\n",
        "      accum_gradient = [(acum_grad + grad) \n",
        "                        for acum_grad, grad in zip(accum_gradient, gradients)]\n",
        "\n",
        "    print(\"Final bounding box: {0} reached in {1} timesteps (originating from {2}). Target was {3}\"\n",
        "          .format(bbox, t, np.array(gt[start_frame]), np.array(gt[end_frame])))\n",
        "    print(\"\\n\\x1b[36m############# END EPISODE # {0} in t={1} timesteps ################\\x1b[0m\"\n",
        "          .format(i+1, t))\n",
        "    \n",
        "\n",
        "  print(\"Avg Loss Across Trajectories: {0}\\x1b[0m\".format(\n",
        "      \"\\x1b[92m\" if loss > 0 else \"\\x1b[31m\"))  \n",
        "  \n",
        "  \n",
        "  \n",
        "  accum_gradient = [g / retry_count if GRAD_ACCUM_SCHEME == \"avg\" else g \n",
        "                    for g in accum_gradient]\n",
        "  for i in range(len(accum_gradient)):\n",
        "      print(\"Layer Name: {}, GRAD NORM = {}\".format(\n",
        "      adnet_model.trainable_variables[i].name, tf.norm(accum_gradient[i])))\n",
        "  opt.apply_gradients(zip(accum_gradient, model.trainable_variables))\n",
        "  return model, loss / retry_count\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Epoch Training Loops"
      ],
      "metadata": {
        "id": "oFKnC5VrgVhn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "otMLmAPjVSiS"
      },
      "outputs": [],
      "source": [
        "def epochs_train(model: ADNET, opt: tf.keras.optimizers.Optimizer, \n",
        "                 datasets: List[str], \n",
        "                 epochs: int=1, retry_count: int=1, action_strategy: str=\"max\",\n",
        "                 seq_length: int=10, randomize: bool=RANDOMIZE_TRAINING):\n",
        "\n",
        "  print(\"TRAINING ON: {0}\".format(datasets))\n",
        "  # Collect list of datasets & trainable frames\n",
        "  dataset_frames = []\n",
        "  for d in datasets:\n",
        "    frames = sorted(glob.glob(os.path.join('%s/img' % d, '*.jpg')))\n",
        "    frames = list(range(len(frames) - L))\n",
        "    for f in frames:\n",
        "      dataset_frames.append((d, f))\n",
        "  if randomize: random.shuffle(dataset_frames)\n",
        "\n",
        "  # Train for n epochs\n",
        "  losses = {}\n",
        "  bad_data_log = []\n",
        "  for e in range(epochs):\n",
        "    epoch_loss = []\n",
        "    \n",
        "    for i, d_frame in enumerate(dataset_frames):\n",
        "      d, start_frame = d_frame\n",
        "      end_frame = start_frame + seq_length\n",
        "\n",
        "      print(\"\\n\\n#############################################\")\n",
        "      print(\"Dataset={0}\".format(d))\n",
        "      print(\"#################################################\")\n",
        "      adnet_model, l = train(model, opt, d, start_frame, end_frame, \n",
        "                             retry_count=retry_count)\n",
        "      epoch_loss.append(l)\n",
        "      print(\"#################################################\")\n",
        "      print(\"#################################################\")\n",
        "      \n",
        "    losses[e] = epoch_loss\n",
        "\n",
        "  print(\"Finished Training On: {0}\".format(datasets))\n",
        "  return model, losses"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Procedure"
      ],
      "metadata": {
        "id": "k5g5kT2HgaoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adnet_model_rnn = ADNET_v3()\n",
        "adnet_model_rnn.build(tf.zeros((1,1,1,512)))\n",
        "adnet_model_rnn.layers[-3].trainable=False\n",
        "\n",
        "temp_model = ADNET()\n",
        "temp_model.build()\n",
        "temp_model.load_weights(\"/content/gdrive/My Drive/EE6885/kaan-weights\")"
      ],
      "metadata": {
        "id": "5IC_1hgaVcw7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f4f6070-efa2-452c-9eed-8dc7eba14bd8"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f8110077790>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### RNN loading model weights\n",
        "### skip pooling layers,also use pre-trained weights from conv layers not fc layers since shapes are not matching\n",
        "adnet_model_rnn.layers[0].set_weights((temp_model.layers[0].get_weights()))\n",
        "adnet_model_rnn.layers[2].set_weights((temp_model.layers[2].get_weights()))\n",
        "adnet_model_rnn.layers[4].set_weights((temp_model.layers[4].get_weights()))\n",
        "adnet_model_rnn.layers[6].set_weights((temp_model.layers[6].get_weights()))"
      ],
      "metadata": {
        "id": "H69T8rt7-O6Q"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ALL_DATASETS_LIST = glob.glob(\"adnet_datasets/OTB/*\")\n",
        "N_VIDEOS = 1\n",
        "datasets = [ALL_DATASETS_LIST[13]]\n",
        "\n",
        "adnet_model_rnn, losses = epochs_train(adnet_model_rnn, Adam(learning_rate=LEARNING_RATE), \n",
        "                             datasets, epochs=N_EPOCHS, retry_count=N_RETRIES, \n",
        "                             randomize=RANDOMIZE_TRAINING)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41yhNXMygPIy",
        "outputId": "b2c36711-e632-4197-81fe-3b42ee3c663d"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            " 5.6797642e-22], argmax=1\n",
            "   \u001b[33m|->> #1/t=59-th Action selection: 5/2X UP (P(a|s) = 0.328000009059906)\u001b[0m\n",
            "      |->> Bounding box moves to: [305  81  98  70]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.6719 0.     0.     0.     0.3281 0.     0.     0.     0.\n",
            " 0.    ], argmax=1\n",
            "         |->> Action Probabilities (RAW): [2.7737595e-14 6.7186046e-01 3.2017352e-15 1.8012147e-19 7.3396371e-17\n",
            " 3.2813951e-01 2.7555947e-13 3.0252023e-11 6.0068672e-17 3.1028494e-15\n",
            " 5.4666997e-20], argmax=1\n",
            "   \u001b[33m|->> #2/t=60-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [305  77  98  70]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [6.96721257e-23 6.63684940e-11 2.87078718e-19 5.50447028e-19\n",
            " 3.44990294e-15 1.00000000e+00 3.89639000e-22 3.90344350e-21\n",
            " 6.44433613e-29 4.27550971e-16 1.12810114e-17], argmax=5\n",
            "   \u001b[33m|->> #3/t=61-th Action selection: 4/UP (P(a|s) = 0.9760000109672546)\u001b[0m\n",
            "      |->> Bounding box moves to: [305  75  98  70]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.9765 0.003  0.     0.     0.     0.\n",
            " 0.0205], argmax=4\n",
            "         |->> Action Probabilities (RAW): [4.6330217e-23 4.7312190e-07 8.3111760e-17 9.2658105e-17 9.7646129e-01\n",
            " 2.9899650e-03 5.1608886e-29 1.3197531e-13 2.6245407e-33 1.1160693e-14\n",
            " 2.0548310e-02], argmax=4\n",
            "   \u001b[33m|->> #4/t=62-th Action selection: 10/SCALE UP (P(a|s) = 0.9819999933242798)\u001b[0m\n",
            "      |->> Bounding box moves to: [303  73 100  72]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.002  0.0156 0.     0.     0.     0.\n",
            " 0.9824], argmax=10\n",
            "         |->> Action Probabilities (RAW): [1.4842976e-18 9.2193680e-10 3.3793053e-23 1.7869639e-20 2.0080172e-03\n",
            " 1.5555194e-02 6.7043336e-33 1.9289455e-10 2.8975523e-36 6.1060223e-17\n",
            " 9.8243678e-01], argmax=10\n",
            "   \u001b[33m|->> #5/t=63-th Action selection: 5/2X UP (P(a|s) = 0.9980000257492065)\u001b[0m\n",
            "      |->> Bounding box moves to: [303  69 100  72]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 0.000e+00 9.000e-04 9.975e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 1.500e-03], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.3849072e-15 1.7350863e-21 2.2007182e-24 7.6773028e-25 9.0837933e-04\n",
            " 9.9754685e-01 5.9126091e-33 3.8657118e-09 0.0000000e+00 6.4655636e-22\n",
            " 1.5447426e-03], argmax=5\n",
            "|->> Revisiting bbox: [303  73 100  72]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [309,  85,  98,  70] -> [303,  69, 100,  72] (Target was [278,  55,  90,  56])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.012) for 2X LEFT:bbox transition: [309,  85,  98,  70] -> [305,  85,  98,  70] w/ P(a|s)=0.9996925592422485 and iou=0.15961800818553887 and reward=0.011634215015560084 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.029) for 2X UP:bbox transition: [305,  85,  98,  70] -> [305,  81,  98,  70] w/ P(a|s)=0.3281395137310028 and iou=0.1888111888111888 and reward=0.029193180625649934 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.031) for 2X UP:bbox transition: [305,  81,  98,  70] -> [305,  77,  98,  70] w/ P(a|s)=1.0 and iou=0.21951219512195122 and reward=0.03070100631076242 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.016) for UP:bbox transition: [305,  77,  98,  70] -> [305,  75,  98,  70] w/ P(a|s)=0.9764612913131714 and iou=0.23546511627906977 and reward=0.01595292115711855 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.017) for SCALE UP:bbox transition: [305,  75,  98,  70] -> [303,  73, 100,  72] w/ P(a|s)=0.9824367761611938 and iou=0.25281473899692936 and reward=0.017349622717859586 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.034) for 2X UP:bbox transition: [303,  73, 100,  72] -> [303,  69, 100,  72] w/ P(a|s)=0.9975468516349792 and iou=0.2870662460567823 and reward=0.03425150705985297 and discount=0.9509900498999999\n",
            "   |->> Assigned losses: [3.5773817e-06 3.2205138e-02 3.0131068e-07 3.6871486e-04 2.9530926e-04\n",
            " 8.0004189e-05]\n",
            "\u001b[92m>> Total frame loss: 0.03295304253697395\u001b[0m\n",
            "Final bounding box: [303  69 100  72] reached in 64 timesteps (originating from [313  15  98  70]). Target was [278  55  90  56]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 12 in t=64 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[92m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 15.938210487365723\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.04521354287862778\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 18.96296501159668\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.05519755557179451\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 19.84102439880371\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.07089309394359589\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 8.744096755981445\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.026293234899640083\n",
            "Layer Name: custom_rnn/conv2d/kernel:0, GRAD NORM = 2.0931801795959473\n",
            "Layer Name: custom_rnn/conv2d/bias:0, GRAD NORM = 0.11037109047174454\n",
            "Layer Name: custom_rnn/conv2d_1/kernel:0, GRAD NORM = 26.114429473876953\n",
            "Layer Name: custom_rnn/conv2d_1/bias:0, GRAD NORM = 0.11037109047174454\n",
            "Layer Name: custom_rnn/conv2d_2/kernel:0, GRAD NORM = 17.74936294555664\n",
            "Layer Name: custom_rnn/conv2d_2/bias:0, GRAD NORM = 0.07257760316133499\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/Deer\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Starting bounding box for adnet_datasets/OTB/Deer: frames 22:32 is [259 143  89  51].\n",
            "\u001b[34m>> Attempting to reach frame 23 with src: [259, 143,  89,  51] and target: [267, 114,  86,  53]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0023.jpg\n",
            "|->> Beginning tracking for bbox:[259 143  89  51]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [259 141  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.2991515e-28 1.5618146e-10 1.2359715e-20 6.6002080e-19 2.3894376e-16\n",
            " 9.9999917e-01 9.6457316e-25 2.3691754e-12 7.0260261e-32 7.2994209e-17\n",
            " 8.2820878e-07], argmax=5\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 5/2X UP (P(a|s) = 0.8289999961853027)\u001b[0m\n",
            "      |->> Bounding box moves to: [259 139  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.     0.8285 0.     0.1715 0.     0.\n",
            " 0.    ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.1430114e-31 7.8718246e-22 8.7853028e-23 1.8790618e-13 8.8732605e-19\n",
            " 8.2853270e-01 1.4619737e-30 1.7146726e-01 2.9896280e-32 2.7199401e-16\n",
            " 4.7604056e-12], argmax=5\n",
            "|->> Revisiting bbox: [259 141  89  51]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [259, 143,  89,  51] -> [259, 139,  89,  51] (Target was [267, 114,  86,  53])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.029) for 2X UP:bbox transition: [259, 143,  89,  51] -> [259, 141,  89,  51] w/ P(a|s)=0.9999991655349731 and iou=0.30124445715920467 and reward=0.029470376353948113 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.031) for 2X UP:bbox transition: [259, 141,  89,  51] -> [259, 139,  89,  51] w/ P(a|s)=0.8285326957702637 and iou=0.3321130472982867 and reward=0.030868590139082053 and discount=0.99\n",
            "   |->> Assigned losses: [2.9510545e-07 5.7482868e-03]\n",
            "\u001b[92m>> Total frame loss: 0.005748582072556019\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 24 with src: [259, 139,  89,  51] and target: [279,  85,  82,  51]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0024.jpg\n",
            "|->> Beginning tracking for bbox:[259 139  89  51]\n",
            "   \u001b[33m|->> #0/t=3-th Action selection: 3/2X RIGHT (P(a|s) = 0.7760000228881836)\u001b[0m\n",
            "      |->> Bounding box moves to: [263 139  89  51]\n",
            "         |->> Action Probabilities (Rounded): [1.000e-04 3.000e-04 0.000e+00 7.757e-01 6.000e-04 2.232e-01 0.000e+00\n",
            " 1.000e-04 0.000e+00 0.000e+00 0.000e+00], argmax=3\n",
            "         |->> Action Probabilities (RAW): [1.3444776e-04 2.8613629e-04 7.8814730e-07 7.7566355e-01 5.8106927e-04\n",
            " 2.2323732e-01 5.3703766e-06 5.4554395e-05 2.9320631e-07 1.9853779e-08\n",
            " 3.6378649e-05], argmax=3\n",
            "   \u001b[33m|->> #1/t=4-th Action selection: 5/2X UP (P(a|s) = 0.44699999690055847)\u001b[0m\n",
            "      |->> Bounding box moves to: [263 137  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.5527 0.     0.4473 0.     0.     0.     0.\n",
            " 0.    ], argmax=3\n",
            "         |->> Action Probabilities (RAW): [5.2100035e-10 5.6756680e-06 3.0305392e-07 5.5265945e-01 2.7040707e-09\n",
            " 4.4733325e-01 6.5821567e-08 1.2569876e-06 1.7392402e-11 2.9168422e-08\n",
            " 2.0143250e-10], argmax=3\n",
            "   \u001b[33m|->> #2/t=5-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263 135  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 1.000e-04 0.000e+00 9.999e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.1487563e-11 2.8736136e-05 1.3206644e-09 6.6313238e-05 1.8365299e-08\n",
            " 9.9990499e-01 1.6080633e-09 6.7602340e-10 3.8246002e-15 2.1719974e-10\n",
            " 1.9321739e-08], argmax=5\n",
            "   \u001b[33m|->> #3/t=6-th Action selection: 5/2X UP (P(a|s) = 0.9850000143051147)\u001b[0m\n",
            "      |->> Bounding box moves to: [263 133  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.0154 0.     0.     0.     0.9845 0.     0.     0.     0.\n",
            " 0.    ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.8684568e-11 1.5427376e-02 5.6218457e-11 3.2212981e-08 3.8450769e-05\n",
            " 9.8453414e-01 5.4299457e-11 8.1518425e-15 1.3038630e-15 2.0091222e-13\n",
            " 1.8434746e-12], argmax=5\n",
            "   \u001b[33m|->> #4/t=7-th Action selection: 1/2X LEFT (P(a|s) = 0.9950000047683716)\u001b[0m\n",
            "      |->> Bounding box moves to: [259 133  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 9.952e-01 0.000e+00 0.000e+00 7.000e-04 4.200e-03 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=1\n",
            "         |->> Action Probabilities (RAW): [1.5123576e-10 9.9516463e-01 5.9092045e-12 1.7950075e-09 6.7299121e-04\n",
            " 4.1624247e-03 1.5149385e-10 3.5760180e-18 3.7868294e-15 4.7698163e-13\n",
            " 6.4672025e-13], argmax=1\n",
            "   \u001b[33m|->> #5/t=8-th Action selection: 5/2X UP (P(a|s) = 0.5260000228881836)\u001b[0m\n",
            "      |->> Bounding box moves to: [259 131  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.0072 0.     0.     0.467  0.5259 0.     0.     0.     0.\n",
            " 0.    ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [5.1465699e-06 7.1652620e-03 3.1879191e-10 8.5096517e-06 4.6695021e-01\n",
            " 5.2587014e-01 7.1341481e-07 3.0421165e-12 3.6269178e-14 7.8937802e-12\n",
            " 3.2510133e-13], argmax=5\n",
            "   \u001b[33m|->> #6/t=9-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [259 129  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [8.54367490e-15 2.52727908e-11 1.15611578e-14 4.12954439e-15\n",
            " 3.23712335e-10 1.00000000e+00 3.51273135e-14 2.97366030e-16\n",
            " 1.34664495e-20 2.43383486e-17 2.10080582e-15], argmax=5\n",
            "   \u001b[33m|->> #7/t=10-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [259 127  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.08213535e-25 2.83114998e-09 1.97340959e-17 5.66628927e-24\n",
            " 7.98595815e-18 1.00000000e+00 1.14701725e-23 2.57240763e-17\n",
            " 3.63525274e-25 7.11536602e-24 2.53807224e-21], argmax=5\n",
            "   \u001b[33m|->> #8/t=11-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [259 125  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [5.4402652e-24 1.7938326e-11 7.3998166e-19 3.4306874e-24 1.8039438e-19\n",
            " 1.0000000e+00 6.8468345e-22 3.0170672e-17 1.2338541e-25 3.4225214e-22\n",
            " 2.3532800e-19], argmax=5\n",
            "   \u001b[33m|->> #9/t=12-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [259 123  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.7553204e-24 1.0721334e-19 4.0226588e-26 4.3878404e-28 5.3310308e-25\n",
            " 1.0000000e+00 3.3017024e-24 5.2963041e-19 1.7954609e-31 4.4944211e-25\n",
            " 2.9897003e-22], argmax=5\n",
            "   \u001b[33m|->> #10/t=13-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [259 121  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [6.3154374e-33 1.8324552e-28 4.7976603e-34 1.6310910e-32 1.0733229e-29\n",
            " 1.0000000e+00 1.1978859e-28 5.2579085e-29 0.0000000e+00 2.1406454e-32\n",
            " 5.3405074e-28], argmax=5\n",
            "   \u001b[33m|->> #11/t=14-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [259 119  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.09783164e-32 1.21052086e-24 1.92256571e-36 7.89209430e-36\n",
            " 6.28984119e-30 1.00000000e+00 3.64364688e-28 3.27662298e-30\n",
            " 0.00000000e+00 9.75982812e-37 2.59598900e-31], argmax=5\n",
            "   \u001b[33m|->> #12/t=15-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [259 117  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.4060445e-28 1.6641776e-22 1.9642853e-31 1.6676995e-28 1.4220915e-27\n",
            " 1.0000000e+00 1.0981896e-21 3.3903000e-19 8.8100547e-34 1.8194569e-29\n",
            " 2.8063244e-30], argmax=5\n",
            "   \u001b[33m|->> #13/t=16-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [259 115  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [9.79733190e-19 1.37417914e-21 2.31130206e-29 2.87034475e-22\n",
            " 2.65489838e-22 1.00000000e+00 2.50624000e-18 4.07909193e-11\n",
            " 4.77293799e-29 1.20009354e-23 6.28696960e-28], argmax=5\n",
            "   \u001b[33m|->> #14/t=17-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [259 113  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 9.999e-01 0.000e+00\n",
            " 1.000e-04 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.7361460e-14 3.0924590e-20 2.6068927e-29 4.6226155e-25 5.8231489e-18\n",
            " 9.9993324e-01 1.4590349e-15 6.6762404e-05 2.6036547e-20 1.6244337e-22\n",
            " 6.3981999e-29], argmax=5\n",
            "   \u001b[33m|->> #15/t=18-th Action selection: 5/2X UP (P(a|s) = 0.996999979019165)\u001b[0m\n",
            "      |->> Bounding box moves to: [259 111  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.     0.9968 0.     0.0032 0.     0.\n",
            " 0.    ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.5264370e-11 2.5055063e-17 2.0218946e-27 1.6513518e-24 1.1658774e-14\n",
            " 9.9675190e-01 3.6050302e-11 3.2480964e-03 1.0914065e-16 6.2892908e-23\n",
            " 6.8081636e-29], argmax=5\n",
            "   \u001b[33m|->> #16/t=19-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [259 109  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 9.996e-01 0.000e+00\n",
            " 4.000e-04 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.3328489e-09 2.0588498e-09 3.1306712e-20 3.2580464e-17 5.1552796e-08\n",
            " 9.9959892e-01 3.6441666e-05 3.6464108e-04 2.4575528e-14 2.5715919e-17\n",
            " 8.1217913e-22], argmax=5\n",
            "   \u001b[33m|->> #17/t=20-th Action selection: 6/DOWN (P(a|s) = 0.996999979019165)\u001b[0m\n",
            "      |->> Bounding box moves to: [259 110  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.     0.     0.9974 0.0026 0.     0.\n",
            " 0.    ], argmax=6\n",
            "         |->> Action Probabilities (RAW): [8.4145526e-09 2.0110067e-08 1.7465192e-20 9.0367785e-10 1.9476172e-09\n",
            " 1.5302619e-05 9.9743086e-01 2.5537843e-03 2.7683408e-15 4.2291618e-15\n",
            " 6.5131518e-23], argmax=6\n",
            "|->> Revisiting bbox: [259 111  89  51]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [259, 139,  89,  51] -> [259, 110,  89,  51] (Target was [279,  85,  82,  51])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X RIGHT:bbox transition: [259, 139,  89,  51] -> [263, 139,  89,  51] w/ P(a|s)=0.7756635546684265 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for 2X UP:bbox transition: [263, 139,  89,  51] -> [263, 137,  89,  51] w/ P(a|s)=0.4473332464694977 and iou=0.0 and reward=0.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.008) for 2X UP:bbox transition: [263, 137,  89,  51] -> [263, 135,  89,  51] w/ P(a|s)=0.999904990196228 and iou=0.008441258094357076 and reward=0.008441258094357076 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.017) for 2X UP:bbox transition: [263, 135,  89,  51] -> [263, 133,  89,  51] w/ P(a|s)=0.9845341444015503 and iou=0.025758645024700072 and reward=0.017317386930342994 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-0.001) for 2X LEFT:bbox transition: [263, 133,  89,  51] -> [259, 133,  89,  51] w/ P(a|s)=0.9951646327972412 and iou=0.024312896405919663 and reward=-0.001445748618780409 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.017) for 2X UP:bbox transition: [259, 133,  89,  51] -> [259, 131,  89,  51] w/ P(a|s)=0.525870144367218 and iou=0.041189111747851004 and reward=0.01687621534193134 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.017) for 2X UP:bbox transition: [259, 131,  89,  51] -> [259, 129,  89,  51] w/ P(a|s)=1.0 and iou=0.05863073561544064 and reward=0.017441623867589635 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (0.018) for 2X UP:bbox transition: [259, 129,  89,  51] -> [259, 127,  89,  51] w/ P(a|s)=1.0 and iou=0.07666666666666666 and reward=0.01803593105122602 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (0.019) for 2X UP:bbox transition: [259, 127,  89,  51] -> [259, 125,  89,  51] w/ P(a|s)=1.0 and iou=0.09532780708364733 and reward=0.018661140416980665 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (0.019) for 2X UP:bbox transition: [259, 125,  89,  51] -> [259, 123,  89,  51] w/ P(a|s)=1.0 and iou=0.11464723926380369 and reward=0.01931943218015636 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (0.02) for 2X UP:bbox transition: [259, 123,  89,  51] -> [259, 121,  89,  51] w/ P(a|s)=1.0 and iou=0.13466042154566746 and reward=0.020013182281863773 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (0.021) for 2X UP:bbox transition: [259, 121,  89,  51] -> [259, 119,  89,  51] w/ P(a|s)=1.0 and iou=0.1554054054054054 and reward=0.020744983859737942 and discount=0.8953382542587164\n",
            "   |->> t=13 Diff-Reward (0.022) for 2X UP:bbox transition: [259, 119,  89,  51] -> [259, 117,  89,  51] w/ P(a|s)=1.0 and iou=0.17692307692307693 and reward=0.021517671517671533 and discount=0.8863848717161292\n",
            "   |->> t=14 Diff-Reward (0.022) for 2X UP:bbox transition: [259, 117,  89,  51] -> [259, 115,  89,  51] w/ P(a|s)=1.0 and iou=0.19925742574257427 and reward=0.022334348819497335 and discount=0.8775210229989678\n",
            "   |->> t=15 Diff-Reward (0.023) for 2X UP:bbox transition: [259, 115,  89,  51] -> [259, 113,  89,  51] w/ P(a|s)=0.9999332427978516 and iou=0.22245584524810766 and reward=0.02319841950553339 and discount=0.8687458127689782\n",
            "   |->> t=16 Diff-Reward (0.024) for 2X UP:bbox transition: [259, 113,  89,  51] -> [259, 111,  89,  51] w/ P(a|s)=0.9967519044876099 and iou=0.24656946826758147 and reward=0.024113623019473812 and discount=0.8600583546412884\n",
            "   |->> t=17 Diff-Reward (0.025) for 2X UP:bbox transition: [259, 111,  89,  51] -> [259, 109,  89,  51] w/ P(a|s)=0.9995989203453064 and iou=0.27165354330708663 and reward=0.02508407503950516 and discount=0.8514577710948755\n",
            "   |->> t=18 Diff-Reward (-0.013) for DOWN:bbox transition: [259, 109,  89,  51] -> [259, 110,  89,  51] w/ P(a|s)=0.9974308609962463 and iou=0.2589865742745777 and reward=-0.012666969032508912 and discount=0.8429431933839268\n",
            "   |->> Assigned losses: [ 0.0000000e+00  0.0000000e+00  7.8607980e-07  2.6190397e-04\n",
            " -6.7315509e-06  1.0314779e-02  1.6443326e-07  1.6833580e-07\n",
            "  1.7242938e-07  1.7672689e-07  1.8124231e-07  1.8599093e-07\n",
            "  1.9098935e-07  1.9625574e-07  1.3454381e-06  6.7472291e-05\n",
            "  8.5679894e-06 -2.7467371e-05]\n",
            "\u001b[92m>> Total frame loss: 0.01062209252268076\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 25 with src: [259, 110,  89,  51] and target: [289,  66,  83,  52]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0025.jpg\n",
            "|->> Beginning tracking for bbox:[259 110  89  51]\n",
            "   \u001b[33m|->> #0/t=21-th Action selection: 5/2X UP (P(a|s) = 0.9150000214576721)\u001b[0m\n",
            "      |->> Bounding box moves to: [259 108  89  51]\n",
            "         |->> Action Probabilities (Rounded): [1.300e-02 4.150e-02 0.000e+00 1.000e-04 1.960e-02 9.146e-01 7.000e-04\n",
            " 0.000e+00 0.000e+00 5.700e-03 4.800e-03], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.3041489e-02 4.1532435e-02 3.0566920e-07 7.3857445e-05 1.9616509e-02\n",
            " 9.1458893e-01 6.5989804e-04 9.3830995e-06 2.9750629e-05 5.6632087e-03\n",
            " 4.7841645e-03], argmax=5\n",
            "   \u001b[33m|->> #1/t=22-th Action selection: 5/2X UP (P(a|s) = 0.32899999618530273)\u001b[0m\n",
            "      |->> Bounding box moves to: [259 106  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 6.707e-01 0.000e+00 0.000e+00 1.000e-04 3.292e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=1\n",
            "         |->> Action Probabilities (RAW): [1.17444697e-05 6.70707762e-01 1.07663226e-10 9.03322750e-09\n",
            " 5.82033354e-05 3.29220742e-01 6.67836787e-07 2.54223683e-15\n",
            " 1.98435348e-11 7.45484741e-09 7.75450758e-07], argmax=1\n",
            "   \u001b[33m|->> #2/t=23-th Action selection: 5/2X UP (P(a|s) = 0.9919999837875366)\u001b[0m\n",
            "      |->> Bounding box moves to: [259 104  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 9.000e-04 0.000e+00 6.500e-03 2.000e-04 9.923e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 1.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.3288104e-08 9.3412719e-04 1.5378508e-14 6.5055271e-03 1.6730225e-04\n",
            " 9.9233127e-01 9.0438412e-10 7.8501574e-18 1.1855474e-10 5.6274790e-10\n",
            " 6.1746185e-05], argmax=5\n",
            "   \u001b[33m|->> #3/t=24-th Action selection: 3/2X RIGHT (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263 104  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.], argmax=3\n",
            "         |->> Action Probabilities (RAW): [2.8600833e-13 1.4902213e-17 1.5608741e-33 9.9999988e-01 2.9874354e-08\n",
            " 8.3645467e-08 4.4275481e-23 3.7164539e-24 1.4543540e-29 2.6985953e-18\n",
            " 1.1782358e-08], argmax=3\n",
            "   \u001b[33m|->> #4/t=25-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263 103  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 0.000e+00 9.999e-01 1.000e-04 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=4\n",
            "         |->> Action Probabilities (RAW): [3.2712003e-34 3.4252176e-10 3.1469630e-34 3.8631958e-16 9.9985635e-01\n",
            " 1.4361096e-04 0.0000000e+00 3.0442912e-21 0.0000000e+00 1.2354951e-32\n",
            " 4.9260160e-28], argmax=4\n",
            "   \u001b[33m|->> #5/t=26-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263 102  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [2.7660028e-35 1.6116329e-16 0.0000000e+00 5.4268109e-16 9.9999928e-01\n",
            " 6.9119108e-07 0.0000000e+00 1.5832773e-26 0.0000000e+00 3.9334423e-35\n",
            " 6.3487133e-27], argmax=4\n",
            "   \u001b[33m|->> #6/t=27-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263 101  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [3.9802024e-37 2.2688753e-19 0.0000000e+00 1.5922384e-16 1.0000000e+00\n",
            " 7.6239044e-14 0.0000000e+00 2.0491693e-29 0.0000000e+00 0.0000000e+00\n",
            " 9.7615208e-26], argmax=4\n",
            "   \u001b[33m|->> #7/t=28-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263 100  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 1.1196995e-22 0.0000000e+00 6.6870030e-22 1.0000000e+00\n",
            " 2.2743543e-17 0.0000000e+00 9.4731973e-30 0.0000000e+00 0.0000000e+00\n",
            " 6.5554785e-25], argmax=4\n",
            "   \u001b[33m|->> #8/t=29-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  99  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [3.8733879e-38 3.0390132e-25 0.0000000e+00 3.9546795e-25 1.0000000e+00\n",
            " 3.0629410e-18 0.0000000e+00 9.1598869e-27 0.0000000e+00 0.0000000e+00\n",
            " 2.4828042e-24], argmax=4\n",
            "   \u001b[33m|->> #9/t=30-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  98  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 6.8157510e-28 0.0000000e+00 1.0178037e-22 1.0000000e+00\n",
            " 6.0234895e-13 0.0000000e+00 5.2947121e-25 0.0000000e+00 0.0000000e+00\n",
            " 5.0015040e-20], argmax=4\n",
            "   \u001b[33m|->> #10/t=31-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  97  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 4.1341203e-29 0.0000000e+00 4.5595112e-17 9.9999678e-01\n",
            " 3.2287828e-06 0.0000000e+00 3.5724885e-23 0.0000000e+00 0.0000000e+00\n",
            " 1.2847820e-13], argmax=4\n",
            "   \u001b[33m|->> #11/t=32-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  96  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 0.000e+00 9.999e-01 1.000e-04 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 7.7559198e-33 0.0000000e+00 4.7929228e-19 9.9989307e-01\n",
            " 1.0696700e-04 0.0000000e+00 2.8640189e-17 0.0000000e+00 0.0000000e+00\n",
            " 3.3233282e-13], argmax=4\n",
            "   \u001b[33m|->> #12/t=33-th Action selection: 4/UP (P(a|s) = 0.9710000157356262)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  95  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.9711 0.0289 0.     0.     0.     0.\n",
            " 0.    ], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 2.3465074e-27 1.7600094e-34 5.8376171e-22 9.7110420e-01\n",
            " 2.8895728e-02 0.0000000e+00 4.0757389e-12 0.0000000e+00 0.0000000e+00\n",
            " 4.7435989e-21], argmax=4\n",
            "   \u001b[33m|->> #13/t=34-th Action selection: 5/2X UP (P(a|s) = 0.996999979019165)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  93  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.0033 0.9967 0.     0.     0.     0.\n",
            " 0.    ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.00000000e+00 1.08232673e-19 4.57252162e-20 1.10337257e-23\n",
            " 3.25036957e-03 9.96749640e-01 0.00000000e+00 4.46015197e-10\n",
            " 8.47304478e-35 0.00000000e+00 9.68767034e-21], argmax=5\n",
            "   \u001b[33m|->> #14/t=35-th Action selection: 4/UP (P(a|s) = 0.7070000171661377)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  92  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.7065 0.2935 0.     0.     0.     0.\n",
            " 0.    ], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 4.3894528e-30 1.2665188e-25 2.0566701e-35 7.0654809e-01\n",
            " 2.9345196e-01 0.0000000e+00 2.1740668e-28 0.0000000e+00 0.0000000e+00\n",
            " 5.5367066e-33], argmax=4\n",
            "   \u001b[33m|->> #15/t=36-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  91  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 0.000e+00 9.999e-01 1.000e-04 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 4.1850093e-30 3.7787606e-32 0.0000000e+00 9.9985301e-01\n",
            " 1.4691181e-04 0.0000000e+00 3.2436709e-31 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00], argmax=4\n",
            "   \u001b[33m|->> #16/t=37-th Action selection: 5/2X UP (P(a|s) = 0.9959999918937683)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  89  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.0035 0.9965 0.     0.     0.     0.\n",
            " 0.    ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 2.5342953e-28 2.7520348e-34 0.0000000e+00 3.5203244e-03\n",
            " 9.9647969e-01 0.0000000e+00 3.1134046e-24 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00], argmax=5\n",
            "   \u001b[33m|->> #17/t=38-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  87  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 1.3751864e-22 2.7974491e-27 1.7973119e-32 4.7564972e-05\n",
            " 9.9995124e-01 6.2647891e-33 1.1969822e-06 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00], argmax=5\n",
            "   \u001b[33m|->> #18/t=39-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  86  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 1.1982332e-28 1.2512458e-31 0.0000000e+00 1.0000000e+00\n",
            " 6.5592680e-14 1.8588864e-27 1.5743700e-12 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00], argmax=4\n",
            "   \u001b[33m|->> #19/t=40-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  85  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00\n",
            " 1.8137254e-22 4.0503168e-32 4.2715720e-20 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00], argmax=4\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [259, 110,  89,  51] -> [263,  85,  89,  51] (Target was [289,  66,  83,  52])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.015) for 2X UP:bbox transition: [259, 110,  89,  51] -> [259, 108,  89,  51] w/ P(a|s)=0.9145889282226562 and iou=0.07138535995160314 and reward=0.015080934328317919 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.016) for 2X UP:bbox transition: [259, 108,  89,  51] -> [259, 106,  89,  51] w/ P(a|s)=0.3292207419872284 and iou=0.08690315453541181 and reward=0.01551779458380867 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.016) for 2X UP:bbox transition: [259, 106,  89,  51] -> [259, 104,  89,  51] w/ P(a|s)=0.9923312664031982 and iou=0.1028770706190061 and reward=0.01597391608359429 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.008) for 2X RIGHT:bbox transition: [259, 104,  89,  51] -> [263, 104,  89,  51] w/ P(a|s)=0.9999998807907104 and iou=0.1106233538191396 and reward=0.0077462832001335 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.009) for UP:bbox transition: [263, 104,  89,  51] -> [263, 103,  89,  51] w/ P(a|s)=0.9998563528060913 and iou=0.11946902654867257 and reward=0.008845672729532975 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.009) for UP:bbox transition: [263, 103,  89,  51] -> [263, 102,  89,  51] w/ P(a|s)=0.9999992847442627 and iou=0.12845673505798394 and reward=0.008987708509311368 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.009) for UP:bbox transition: [263, 102,  89,  51] -> [263, 101,  89,  51] w/ P(a|s)=1.0 and iou=0.13758992805755396 and reward=0.009133192999570022 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (0.009) for UP:bbox transition: [263, 101,  89,  51] -> [263, 100,  89,  51] w/ P(a|s)=1.0 and iou=0.1468721668177697 and reward=0.00928223876021575 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (0.009) for UP:bbox transition: [263, 100,  89,  51] -> [263,  99,  89,  51] w/ P(a|s)=1.0 and iou=0.1563071297989031 and reward=0.009434962981133388 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (0.01) for UP:bbox transition: [263,  99,  89,  51] -> [263,  98,  89,  51] w/ P(a|s)=1.0 and iou=0.16589861751152074 and reward=0.009591487712617641 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (0.01) for UP:bbox transition: [263,  98,  89,  51] -> [263,  97,  89,  51] w/ P(a|s)=0.9999967813491821 and iou=0.17565055762081785 and reward=0.009751940109297114 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (0.01) for UP:bbox transition: [263,  97,  89,  51] -> [263,  96,  89,  51] w/ P(a|s)=0.999893069267273 and iou=0.18556701030927836 and reward=0.009916452688460503 and discount=0.8953382542587164\n",
            "   |->> t=13 Diff-Reward (0.01) for UP:bbox transition: [263,  96,  89,  51] -> [263,  95,  89,  51] w/ P(a|s)=0.9711042046546936 and iou=0.1956521739130435 and reward=0.01008516360376513 and discount=0.8863848717161292\n",
            "   |->> t=14 Diff-Reward (0.021) for 2X UP:bbox transition: [263,  95,  89,  51] -> [263,  93,  89,  51] w/ P(a|s)=0.9967496395111084 and iou=0.21634615384615385 and reward=0.020693979933110368 and discount=0.8775210229989678\n",
            "   |->> t=15 Diff-Reward (0.011) for UP:bbox transition: [263,  93,  89,  51] -> [263,  92,  89,  51] w/ P(a|s)=0.7065480947494507 and iou=0.22696411251212414 and reward=0.01061795866597029 and discount=0.8687458127689782\n",
            "   |->> t=16 Diff-Reward (0.011) for UP:bbox transition: [263,  92,  89,  51] -> [263,  91,  89,  51] w/ P(a|s)=0.9998530149459839 and iou=0.23776908023483365 and reward=0.010804967722709502 and discount=0.8600583546412884\n",
            "   |->> t=17 Diff-Reward (0.022) for 2X UP:bbox transition: [263,  91,  89,  51] -> [263,  89,  89,  51] w/ P(a|s)=0.9964796900749207 and iou=0.2599601593625498 and reward=0.022191079127716146 and discount=0.8514577710948755\n",
            "   |->> t=18 Diff-Reward (0.023) for 2X UP:bbox transition: [263,  89,  89,  51] -> [263,  87,  89,  51] w/ P(a|s)=0.9999512434005737 and iou=0.2829614604462475 and reward=0.02300130108369769 and discount=0.8429431933839268\n",
            "   |->> t=19 Diff-Reward (0.012) for UP:bbox transition: [263,  87,  89,  51] -> [263,  86,  89,  51] w/ P(a|s)=1.0 and iou=0.2947799385875128 and reward=0.011818478141265298 and discount=0.8345137614500875\n",
            "   |->> t=20 Diff-Reward (0.012) for UP:bbox transition: [263,  86,  89,  51] -> [263,  85,  89,  51] w/ P(a|s)=1.0 and iou=0.3068181818181818 and reward=0.012038243230669043 and discount=0.8261686238355866\n",
            "   |->> Assigned losses: [1.34643447e-03 1.70682780e-02 1.20524695e-04 7.52645590e-08\n",
            " 1.22067479e-06 8.55887166e-08 8.61044001e-08 8.66344578e-08\n",
            " 8.71792878e-08 8.77393305e-08 8.83150051e-08 9.49443745e-07\n",
            " 2.62114743e-04 5.91207390e-05 3.20419227e-03 1.36601830e-06\n",
            " 6.66327905e-05 9.45354486e-07 9.87612623e-08 9.95917446e-08]\n",
            "\u001b[92m>> Total frame loss: 0.022132575511932373\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 26 with src: [263,  85,  89,  51] and target: [285,  48,  84,  49]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0026.jpg\n",
            "|->> Beginning tracking for bbox:[263  85  89  51]\n",
            "   \u001b[33m|->> #0/t=41-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  84  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 1.3656265e-18 0.0000000e+00 3.1320279e-24 9.9999976e-01\n",
            " 5.7417071e-23 0.0000000e+00 1.2543395e-28 0.0000000e+00 1.7019392e-23\n",
            " 2.3710722e-07], argmax=4\n",
            "   \u001b[33m|->> #1/t=42-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  83  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.00000000e+00 1.12195025e-18 0.00000000e+00 2.48791347e-24\n",
            " 9.99988079e-01 4.14163531e-26 0.00000000e+00 3.15484964e-22\n",
            " 0.00000000e+00 1.56657353e-29 1.19246015e-05], argmax=4\n",
            "   \u001b[33m|->> #2/t=43-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  82  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 1.9398706e-21 0.0000000e+00 5.8783432e-29 9.9999988e-01\n",
            " 8.8101387e-30 0.0000000e+00 7.6204120e-22 0.0000000e+00 2.2286792e-33\n",
            " 1.2600985e-07], argmax=4\n",
            "   \u001b[33m|->> #3/t=44-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  81  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 1.3510114e-23 1.5046704e-36 5.8690481e-28 1.0000000e+00\n",
            " 2.8937601e-31 0.0000000e+00 2.0367126e-17 0.0000000e+00 1.1764172e-34\n",
            " 1.4662564e-09], argmax=4\n",
            "   \u001b[33m|->> #4/t=45-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  80  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 1.6743924e-21 6.1389299e-32 1.4343036e-23 1.0000000e+00\n",
            " 8.6571559e-30 0.0000000e+00 3.0075616e-11 0.0000000e+00 1.6136264e-32\n",
            " 3.8848689e-09], argmax=4\n",
            "   \u001b[33m|->> #5/t=46-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  79  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 0.000e+00 9.997e-01 0.000e+00 0.000e+00\n",
            " 3.000e-04 0.000e+00 0.000e+00 0.000e+00], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 2.7056784e-30 0.0000000e+00 4.9045575e-19 9.9969387e-01\n",
            " 0.0000000e+00 0.0000000e+00 3.0615812e-04 0.0000000e+00 5.6278155e-37\n",
            " 6.0494327e-14], argmax=4\n",
            "   \u001b[33m|->> #6/t=47-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  78  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.00000000e+00 8.77783362e-33 0.00000000e+00 1.26272284e-22\n",
            " 9.99993682e-01 0.00000000e+00 0.00000000e+00 6.37077392e-06\n",
            " 0.00000000e+00 0.00000000e+00 1.00066965e-14], argmax=4\n",
            "   \u001b[33m|->> #7/t=48-th Action selection: 4/UP (P(a|s) = 0.9959999918937683)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  77  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.9955 0.     0.     0.     0.     0.\n",
            " 0.0045], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 2.7517523e-27 3.3527401e-35 8.1140328e-10 9.9550003e-01\n",
            " 0.0000000e+00 0.0000000e+00 2.2921925e-07 0.0000000e+00 0.0000000e+00\n",
            " 4.4996645e-03], argmax=4\n",
            "   \u001b[33m|->> #8/t=49-th Action selection: 4/UP (P(a|s) = 0.9980000257492065)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  76  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.9981 0.     0.     0.     0.     0.\n",
            " 0.0019], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 2.0253081e-30 2.7708099e-33 1.8597749e-08 9.9811256e-01\n",
            " 0.0000000e+00 0.0000000e+00 4.1775394e-12 0.0000000e+00 0.0000000e+00\n",
            " 1.8874536e-03], argmax=4\n",
            "   \u001b[33m|->> #9/t=50-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  75  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 5.8205263e-30 8.1330273e-35 6.9433727e-27 1.0000000e+00\n",
            " 0.0000000e+00 0.0000000e+00 4.1936579e-10 0.0000000e+00 0.0000000e+00\n",
            " 5.5249560e-13], argmax=4\n",
            "   \u001b[33m|->> #10/t=51-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  74  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 2.0525223e-32 8.2555681e-33 0.0000000e+00 1.0000000e+00\n",
            " 0.0000000e+00 0.0000000e+00 9.1896335e-20 0.0000000e+00 0.0000000e+00\n",
            " 7.8989374e-27], argmax=4\n",
            "   \u001b[33m|->> #11/t=52-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  73  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 3.8768330e-30 1.7443811e-31 0.0000000e+00 1.0000000e+00\n",
            " 2.4484593e-36 0.0000000e+00 7.3730708e-28 0.0000000e+00 0.0000000e+00\n",
            " 5.3079459e-37], argmax=4\n",
            "   \u001b[33m|->> #12/t=53-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  72  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 1.0835998e-21 2.5637233e-28 8.8254222e-35 1.0000000e+00\n",
            " 6.9498787e-38 0.0000000e+00 1.9092935e-28 0.0000000e+00 3.4325695e-33\n",
            " 0.0000000e+00], argmax=4\n",
            "   \u001b[33m|->> #13/t=54-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  71  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 7.5123106e-25 0.0000000e+00 2.9851207e-36 1.0000000e+00\n",
            " 0.0000000e+00 0.0000000e+00 1.5536795e-34 0.0000000e+00 3.7808946e-36\n",
            " 0.0000000e+00], argmax=4\n",
            "   \u001b[33m|->> #14/t=55-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  70  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 1.0626226e-33 0.0000000e+00 6.5643304e-27 1.0000000e+00\n",
            " 0.0000000e+00 0.0000000e+00 6.3453457e-29 0.0000000e+00 2.6667260e-35\n",
            " 2.3271028e-29], argmax=4\n",
            "   \u001b[33m|->> #15/t=56-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  69  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 7.6036876e-37 6.8440159e-29 7.9005049e-12 1.0000000e+00\n",
            " 1.3711142e-31 0.0000000e+00 5.3153880e-20 0.0000000e+00 2.5662290e-35\n",
            " 2.1275214e-18], argmax=4\n",
            "   \u001b[33m|->> #16/t=57-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  68  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 0.0000000e+00 5.2029374e-30 3.8410054e-14 1.0000000e+00\n",
            " 1.4487887e-37 0.0000000e+00 1.7763944e-21 0.0000000e+00 0.0000000e+00\n",
            " 2.0917903e-18], argmax=4\n",
            "   \u001b[33m|->> #17/t=58-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  67  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 2.3300780e-37 1.0075729e-32 1.0082931e-15 1.0000000e+00\n",
            " 6.0695126e-33 0.0000000e+00 1.3970815e-14 0.0000000e+00 1.7350922e-36\n",
            " 6.8346283e-20], argmax=4\n",
            "   \u001b[33m|->> #18/t=59-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  66  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.00000000e+00 9.76237038e-35 2.02726815e-35 1.19804069e-14\n",
            " 1.00000000e+00 2.72689740e-26 8.91892922e-36 3.83223586e-08\n",
            " 0.00000000e+00 1.34783555e-30 7.29254125e-20], argmax=4\n",
            "   \u001b[33m|->> #19/t=60-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  65  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 4.0636352e-35 6.9335742e-36 3.6597917e-13 1.0000000e+00\n",
            " 3.0124767e-33 5.2400372e-33 6.5624780e-12 0.0000000e+00 7.5796243e-29\n",
            " 2.4912614e-21], argmax=4\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [263,  85,  89,  51] -> [263,  65,  89,  51] (Target was [285,  48,  84,  49])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.009) for UP:bbox transition: [263,  85,  89,  51] -> [263,  84,  89,  51] w/ P(a|s)=0.9999997615814209 and iou=0.111896197327852 and reward=0.00948886068283862 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.01) for UP:bbox transition: [263,  84,  89,  51] -> [263,  83,  89,  51] w/ P(a|s)=0.9999880790710449 and iou=0.12154982506155242 and reward=0.009653627733700418 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.01) for UP:bbox transition: [263,  83,  89,  51] -> [263,  82,  89,  51] w/ P(a|s)=0.9999998807907104 and iou=0.13137254901960785 and reward=0.009822723958055432 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.01) for UP:bbox transition: [263,  82,  89,  51] -> [263,  81,  89,  51] w/ P(a|s)=1.0 and iou=0.14136885137808256 and reward=0.009996302358474707 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.01) for UP:bbox transition: [263,  81,  89,  51] -> [263,  80,  89,  51] w/ P(a|s)=1.0 and iou=0.1515433741351783 and reward=0.010174522757095739 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.01) for UP:bbox transition: [263,  80,  89,  51] -> [263,  79,  89,  51] w/ P(a|s)=0.9996938705444336 and iou=0.16190092629883207 and reward=0.010357552163653777 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.011) for UP:bbox transition: [263,  79,  89,  51] -> [263,  78,  89,  51] w/ P(a|s)=0.9999936819076538 and iou=0.17244649146572744 and reward=0.010545565166895365 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (0.011) for UP:bbox transition: [263,  78,  89,  51] -> [263,  77,  89,  51] w/ P(a|s)=0.9955000281333923 and iou=0.18318523581681476 and reward=0.01073874435108732 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (0.011) for UP:bbox transition: [263,  77,  89,  51] -> [263,  76,  89,  51] w/ P(a|s)=0.9981125593185425 and iou=0.1941225165562914 and reward=0.01093728073947664 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (0.011) for UP:bbox transition: [263,  76,  89,  51] -> [263,  75,  89,  51] w/ P(a|s)=1.0 and iou=0.20526389082300514 and reward=0.011141374266713744 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (0.011) for UP:bbox transition: [263,  75,  89,  51] -> [263,  74,  89,  51] w/ P(a|s)=1.0 and iou=0.2166151251054259 and reward=0.011351234282420769 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (0.012) for UP:bbox transition: [263,  74,  89,  51] -> [263,  73,  89,  51] w/ P(a|s)=1.0 and iou=0.22818220519369944 and reward=0.011567080088273535 and discount=0.8953382542587164\n",
            "   |->> t=13 Diff-Reward (0.012) for UP:bbox transition: [263,  73,  89,  51] -> [263,  72,  89,  51] w/ P(a|s)=1.0 and iou=0.23997134670487105 and reward=0.011789141511171608 and discount=0.8863848717161292\n",
            "   |->> t=14 Diff-Reward (0.012) for UP:bbox transition: [263,  72,  89,  51] -> [263,  71,  89,  51] w/ P(a|s)=1.0 and iou=0.2519890062201649 and reward=0.01201765951529385 and discount=0.8775210229989678\n",
            "   |->> t=15 Diff-Reward (0.012) for UP:bbox transition: [263,  71,  89,  51] -> [263,  70,  89,  51] w/ P(a|s)=1.0 and iou=0.2642418930762489 and reward=0.012252886856084 and discount=0.8687458127689782\n",
            "   |->> t=16 Diff-Reward (0.012) for UP:bbox transition: [263,  70,  89,  51] -> [263,  69,  89,  51] w/ P(a|s)=1.0 and iou=0.2767369818557309 and reward=0.012495088779482022 and discount=0.8600583546412884\n",
            "   |->> t=17 Diff-Reward (0.013) for UP:bbox transition: [263,  69,  89,  51] -> [263,  68,  89,  51] w/ P(a|s)=1.0 and iou=0.2894815256257449 and reward=0.012744543770013994 and discount=0.8514577710948755\n",
            "   |->> t=18 Diff-Reward (0.013) for UP:bbox transition: [263,  68,  89,  51] -> [263,  67,  89,  51] w/ P(a|s)=1.0 and iou=0.30248306997742663 and reward=0.013001544351681715 and discount=0.8429431933839268\n",
            "   |->> t=19 Diff-Reward (0.013) for UP:bbox transition: [263,  67,  89,  51] -> [263,  66,  89,  51] w/ P(a|s)=1.0 and iou=0.315749467923381 and reward=0.013266397945954356 and discount=0.8345137614500875\n",
            "   |->> t=20 Diff-Reward (0.014) for UP:bbox transition: [263,  66,  89,  51] -> [263,  65,  89,  51] w/ P(a|s)=1.0 and iou=0.32928889571494396 and reward=0.013539427791562975 and discount=0.8261686238355866\n",
            "   |->> Assigned losses: [9.50179455e-08 1.13930085e-07 9.64037383e-08 9.71262324e-08\n",
            " 9.78692825e-08 3.01581508e-06 9.94197222e-08 4.51428168e-05\n",
            " 1.90666506e-05 1.01917102e-07 1.02798452e-07 1.03705659e-07\n",
            " 1.04639589e-07 1.05601231e-07 1.06591528e-07 1.07611527e-07\n",
            " 1.08662320e-07 1.09745024e-07 1.10860817e-07 1.12010966e-07]\n",
            "\u001b[92m>> Total frame loss: 6.899919389979914e-05\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 27 with src: [263,  65,  89,  51] and target: [269,  32,  89,  52]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0027.jpg\n",
            "|->> Beginning tracking for bbox:[263  65  89  51]\n",
            "   \u001b[33m|->> #0/t=61-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  63  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 7.0212306e-26 0.0000000e+00 3.1932671e-31 5.3202170e-27\n",
            " 1.0000000e+00 0.0000000e+00 5.8586647e-22 0.0000000e+00 0.0000000e+00\n",
            " 1.9664896e-31], argmax=5\n",
            "   \u001b[33m|->> #1/t=62-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  61  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 9.0666890e-26 0.0000000e+00 1.8919645e-29 1.9197545e-18\n",
            " 1.0000000e+00 0.0000000e+00 1.0159288e-17 0.0000000e+00 0.0000000e+00\n",
            " 1.1657606e-30], argmax=5\n",
            "   \u001b[33m|->> #2/t=63-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  60  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.00000000e+00 6.04971802e-13 8.78292343e-38 5.64332261e-29\n",
            " 1.00000000e+00 2.01048955e-10 1.44015644e-34 1.51307865e-30\n",
            " 1.45283360e-38 0.00000000e+00 0.00000000e+00], argmax=4\n",
            "   \u001b[33m|->> #3/t=64-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  59  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 1.0930053e-17 0.0000000e+00 2.2228642e-32 1.0000000e+00\n",
            " 3.5327759e-17 1.3722413e-28 9.9472150e-34 8.7957025e-37 0.0000000e+00\n",
            " 0.0000000e+00], argmax=4\n",
            "   \u001b[33m|->> #4/t=65-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  58  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 4.0418440e-24 0.0000000e+00 8.3162837e-34 1.0000000e+00\n",
            " 7.0361991e-24 4.3366354e-29 3.7419356e-30 3.1637486e-35 8.3097969e-38\n",
            " 0.0000000e+00], argmax=4\n",
            "   \u001b[33m|->> #5/t=66-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  57  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 4.7366258e-29 0.0000000e+00 2.3570123e-38 1.0000000e+00\n",
            " 1.0817540e-28 8.1141677e-32 9.8824403e-31 1.5005025e-37 0.0000000e+00\n",
            " 0.0000000e+00], argmax=4\n",
            "   \u001b[33m|->> #6/t=67-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  56  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 6.9443204e-36 0.0000000e+00 0.0000000e+00 1.0000000e+00\n",
            " 1.6135055e-37 4.8641236e-37 4.7895939e-35 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00], argmax=4\n",
            "   \u001b[33m|->> #7/t=68-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  55  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00\n",
            " 0.0000000e+00 4.5685996e-38 4.7557563e-32 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00], argmax=4\n",
            "   \u001b[33m|->> #8/t=69-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  54  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0782817e-34 1.0000000e+00\n",
            " 4.6574824e-30 0.0000000e+00 2.5677141e-30 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00], argmax=4\n",
            "   \u001b[33m|->> #9/t=70-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  53  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 0.0000000e+00 0.0000000e+00 2.0628275e-33 1.0000000e+00\n",
            " 9.3372033e-34 3.9063073e-34 5.4063270e-35 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00], argmax=4\n",
            "   \u001b[33m|->> #10/t=71-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  52  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 0.0000000e+00 0.0000000e+00 1.1703679e-30 1.0000000e+00\n",
            " 0.0000000e+00 8.0772777e-36 4.9275089e-37 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00], argmax=4\n",
            "   \u001b[33m|->> #11/t=72-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  51  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 0.0000000e+00 0.0000000e+00 7.8006840e-21 1.0000000e+00\n",
            " 0.0000000e+00 2.3392177e-35 2.0592759e-31 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00], argmax=4\n",
            "   \u001b[33m|->> #12/t=73-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  50  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0363473e-14 1.0000000e+00\n",
            " 9.0132515e-38 3.2647636e-34 3.2955400e-22 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00], argmax=4\n",
            "   \u001b[33m|->> #13/t=74-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  49  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 0.0000000e+00 0.0000000e+00 7.5915386e-16 1.0000000e+00\n",
            " 0.0000000e+00 2.2555058e-36 1.1168831e-16 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00], argmax=4\n",
            "   \u001b[33m|->> #14/t=75-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  48  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 0.0000000e+00 0.0000000e+00 1.6629011e-08 1.0000000e+00\n",
            " 7.0843660e-36 4.6797997e-29 2.4337321e-10 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00], argmax=4\n",
            "   \u001b[33m|->> #15/t=76-th Action selection: 4/UP (P(a|s) = 0.9990000128746033)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  47  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 0.000e+00 9.992e-01 0.000e+00 0.000e+00\n",
            " 8.000e-04 0.000e+00 0.000e+00 0.000e+00], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 1.6296132e-33 0.0000000e+00 2.0239586e-11 9.9918967e-01\n",
            " 2.7077119e-21 9.6091964e-14 8.1026682e-04 1.1441854e-34 4.0632081e-28\n",
            " 7.7283903e-38], argmax=4\n",
            "   \u001b[33m|->> #16/t=77-th Action selection: 4/UP (P(a|s) = 0.9990000128746033)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  46  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 0.000e+00 9.991e-01 0.000e+00 8.000e-04\n",
            " 1.000e-04 0.000e+00 0.000e+00 0.000e+00], argmax=4\n",
            "         |->> Action Probabilities (RAW): [4.76032953e-36 2.51051853e-28 0.00000000e+00 6.10344775e-10\n",
            " 9.99147773e-01 1.15704966e-20 7.87482539e-04 6.47851557e-05\n",
            " 6.36717247e-24 1.20821990e-26 9.17829359e-29], argmax=4\n",
            "   \u001b[33m|->> #17/t=78-th Action selection: 4/UP (P(a|s) = 0.9150000214576721)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  45  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 0.000e+00 9.154e-01 0.000e+00 8.440e-02\n",
            " 2.000e-04 0.000e+00 0.000e+00 0.000e+00], argmax=4\n",
            "         |->> Action Probabilities (RAW): [1.1184878e-31 1.4751536e-28 0.0000000e+00 1.5259473e-10 9.1542584e-01\n",
            " 3.5261886e-22 8.4420159e-02 1.5405152e-04 2.0808351e-25 8.4044837e-25\n",
            " 1.9311901e-29], argmax=4\n",
            "   \u001b[33m|->> #18/t=79-th Action selection: 4/UP (P(a|s) = 0.9959999918937683)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  44  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0.    0.    0.    0.    0.996 0.    0.    0.004 0.    0.    0.   ], argmax=4\n",
            "         |->> Action Probabilities (RAW): [1.1594384e-33 1.0956625e-27 0.0000000e+00 1.0365574e-08 9.9604011e-01\n",
            " 4.8325345e-21 2.0080599e-09 3.9598998e-03 1.7638104e-25 1.7263246e-20\n",
            " 2.2678122e-32], argmax=4\n",
            "|->> Revisiting bbox: [263  46  89  51]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [263,  65,  89,  51] -> [263,  44,  89,  51] (Target was [269,  32,  89,  52])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.027) for 2X UP:bbox transition: [263,  65,  89,  51] -> [263,  63,  89,  51] w/ P(a|s)=1.0 and iou=0.23477909482758622 and reward=0.027005708793330613 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.028) for 2X UP:bbox transition: [263,  63,  89,  51] -> [263,  61,  89,  51] w/ P(a|s)=1.0 and iou=0.26302011573436207 and reward=0.028241020906775854 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.015) for UP:bbox transition: [263,  61,  89,  51] -> [263,  60,  89,  51] w/ P(a|s)=1.0 and iou=0.2776306620209059 and reward=0.014610546286543846 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.015) for UP:bbox transition: [263,  60,  89,  51] -> [263,  59,  89,  51] w/ P(a|s)=1.0 and iou=0.29258319232938523 and reward=0.014952530308479317 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.015) for UP:bbox transition: [263,  59,  89,  51] -> [263,  58,  89,  51] w/ P(a|s)=1.0 and iou=0.3078898558995577 and reward=0.015306663570172463 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.016) for UP:bbox transition: [263,  58,  89,  51] -> [263,  57,  89,  51] w/ P(a|s)=1.0 and iou=0.3235633843488305 and reward=0.015673528449272778 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.016) for UP:bbox transition: [263,  57,  89,  51] -> [263,  56,  89,  51] w/ P(a|s)=1.0 and iou=0.33961712699108576 and reward=0.016053742642255286 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (0.016) for UP:bbox transition: [263,  56,  89,  51] -> [263,  55,  89,  51] w/ P(a|s)=1.0 and iou=0.35606508875739645 and reward=0.016447961766310693 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (0.017) for UP:bbox transition: [263,  55,  89,  51] -> [263,  54,  89,  51] w/ P(a|s)=1.0 and iou=0.3729219709450352 and reward=0.016856882187638755 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (0.017) for UP:bbox transition: [263,  54,  89,  51] -> [263,  53,  89,  51] w/ P(a|s)=1.0 and iou=0.39020321504397937 and reward=0.01728124409894416 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (0.018) for UP:bbox transition: [263,  53,  89,  51] -> [263,  52,  89,  51] w/ P(a|s)=1.0 and iou=0.4079250499155276 and reward=0.017721834871548214 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (0.018) for UP:bbox transition: [263,  52,  89,  51] -> [263,  51,  89,  51] w/ P(a|s)=1.0 and iou=0.4261045426260112 and reward=0.018179492710483636 and discount=0.8953382542587164\n",
            "   |->> t=13 Diff-Reward (0.019) for UP:bbox transition: [263,  51,  89,  51] -> [263,  50,  89,  51] w/ P(a|s)=1.0 and iou=0.44475965327029154 and reward=0.018655110644280326 and discount=0.8863848717161292\n",
            "   |->> t=14 Diff-Reward (0.019) for UP:bbox transition: [263,  50,  89,  51] -> [263,  49,  89,  51] w/ P(a|s)=1.0 and iou=0.463909294155222 and reward=0.01914964088493043 and discount=0.8775210229989678\n",
            "   |->> t=15 Diff-Reward (0.02) for UP:bbox transition: [263,  49,  89,  51] -> [263,  48,  89,  51] w/ P(a|s)=1.0 and iou=0.4835733937530345 and reward=0.019664099597812512 and discount=0.8687458127689782\n",
            "   |->> t=16 Diff-Reward (0.02) for UP:bbox transition: [263,  48,  89,  51] -> [263,  47,  89,  51] w/ P(a|s)=0.9991896748542786 and iou=0.5037729658792651 and reward=0.020199572126230636 and discount=0.8600583546412884\n",
            "   |->> t=17 Diff-Reward (0.021) for UP:bbox transition: [263,  47,  89,  51] -> [263,  46,  89,  51] w/ P(a|s)=0.9991477727890015 and iou=0.5245301846000333 and reward=0.02075721872076819 and discount=0.8514577710948755\n",
            "   |->> t=18 Diff-Reward (0.021) for UP:bbox transition: [263,  46,  89,  51] -> [263,  45,  89,  51] w/ P(a|s)=0.9154258370399475 and iou=0.5458684654300169 and reward=0.02133828082998357 and discount=0.8429431933839268\n",
            "   |->> t=19 Diff-Reward (0.022) for UP:bbox transition: [263,  45,  89,  51] -> [263,  44,  89,  51] w/ P(a|s)=0.9960401058197021 and iou=0.5678125534462117 and reward=0.02194408801619485 and discount=0.8345137614500875\n",
            "   |->> Assigned losses: [2.70425204e-07 2.79967196e-07 1.43393152e-07 1.45282002e-07\n",
            " 1.47235625e-07 1.49256863e-07 1.51348814e-07 1.53514719e-07\n",
            " 1.55758016e-07 1.58082315e-07 1.60491567e-07 1.62989807e-07\n",
            " 1.65581454e-07 1.68271171e-07 1.71063903e-07 1.40833317e-05\n",
            " 1.50685955e-05 1.58943434e-03 7.26600920e-05]\n",
            "\u001b[92m>> Total frame loss: 0.0016938289627432823\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 28 with src: [263,  44,  89,  51] and target: [246,  26,  86,  54]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0028.jpg\n",
            "|->> Beginning tracking for bbox:[263  44  89  51]\n",
            "   \u001b[33m|->> #0/t=80-th Action selection: 1/2X LEFT (P(a|s) = 0.9909999966621399)\u001b[0m\n",
            "      |->> Bounding box moves to: [259  44  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 9.906e-01 0.000e+00 0.000e+00 0.000e+00 9.300e-03 1.000e-04\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=1\n",
            "         |->> Action Probabilities (RAW): [1.1315406e-09 9.9061817e-01 5.1123633e-20 5.1990923e-21 3.4757400e-06\n",
            " 9.2776306e-03 8.6740998e-05 1.4033748e-05 3.9695536e-24 6.6653878e-20\n",
            " 1.3879673e-35], argmax=1\n",
            "   \u001b[33m|->> #1/t=81-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [259  42  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.5028610e-23 3.4162178e-09 1.9328268e-33 3.4172350e-31 2.8010851e-14\n",
            " 1.0000000e+00 1.3387383e-14 1.0390453e-17 4.1415033e-37 1.2891284e-32\n",
            " 0.0000000e+00], argmax=5\n",
            "   \u001b[33m|->> #2/t=82-th Action selection: 1/2X LEFT (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [255  42  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.], argmax=1\n",
            "         |->> Action Probabilities (RAW): [8.3270094e-20 1.0000000e+00 4.4072077e-24 2.1069359e-24 2.4259796e-09\n",
            " 1.3408685e-08 4.5261234e-13 4.9805879e-13 1.4715375e-28 2.2281540e-24\n",
            " 8.1782713e-33], argmax=1\n",
            "   \u001b[33m|->> #3/t=83-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [255  41  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [6.7789841e-35 1.4505505e-10 5.7940828e-35 1.1598689e-24 1.0000000e+00\n",
            " 2.9452908e-08 7.8242751e-24 4.2861066e-09 1.8181094e-38 5.7588206e-37\n",
            " 0.0000000e+00], argmax=4\n",
            "   \u001b[33m|->> #4/t=84-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [255  40  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 2.1174490e-18 3.0926877e-36 2.1175051e-26 1.0000000e+00\n",
            " 6.2692455e-21 4.6244342e-28 7.0310691e-18 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00], argmax=4\n",
            "   \u001b[33m|->> #5/t=85-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [255  39  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 3.3717690e-25 0.0000000e+00 8.4639521e-27 1.0000000e+00\n",
            " 4.0422458e-31 8.1373998e-36 1.1055968e-27 0.0000000e+00 0.0000000e+00\n",
            " 1.9755426e-38], argmax=4\n",
            "   \u001b[33m|->> #6/t=86-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [255  38  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 2.0545276e-32 0.0000000e+00 3.4586725e-26 1.0000000e+00\n",
            " 5.6030585e-37 0.0000000e+00 1.7293503e-28 0.0000000e+00 0.0000000e+00\n",
            " 1.2461967e-38], argmax=4\n",
            "   \u001b[33m|->> #7/t=87-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [255  37  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [9.5081100e-35 4.5967880e-27 0.0000000e+00 1.2548936e-30 1.0000000e+00\n",
            " 3.3987008e-36 1.0279016e-37 1.4483301e-22 0.0000000e+00 0.0000000e+00\n",
            " 3.5523907e-36], argmax=4\n",
            "   \u001b[33m|->> #8/t=88-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [255  36  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [1.4130169e-28 2.8951735e-31 0.0000000e+00 1.8599664e-25 1.0000000e+00\n",
            " 1.1285476e-34 2.4136591e-33 1.6401282e-14 0.0000000e+00 0.0000000e+00\n",
            " 8.0480484e-31], argmax=4\n",
            "   \u001b[33m|->> #9/t=89-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [255  35  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [8.6036611e-29 3.5772172e-31 0.0000000e+00 1.1222340e-24 1.0000000e+00\n",
            " 3.2919513e-34 2.9388690e-32 8.9941914e-15 0.0000000e+00 0.0000000e+00\n",
            " 2.2675177e-26], argmax=4\n",
            "   \u001b[33m|->> #10/t=90-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [255  34  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [5.2970300e-27 9.1629977e-27 0.0000000e+00 1.6063455e-21 1.0000000e+00\n",
            " 7.0587531e-32 1.1408265e-28 7.5698153e-10 0.0000000e+00 2.6357722e-32\n",
            " 9.8340024e-24], argmax=4\n",
            "   \u001b[33m|->> #11/t=91-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [255  33  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [2.1695783e-29 3.6280884e-26 0.0000000e+00 8.1917607e-18 1.0000000e+00\n",
            " 2.1522795e-33 2.4356905e-26 2.2252048e-18 0.0000000e+00 8.7301642e-34\n",
            " 2.5397665e-29], argmax=4\n",
            "   \u001b[33m|->> #12/t=92-th Action selection: 3/2X RIGHT (P(a|s) = 0.9860000014305115)\u001b[0m\n",
            "      |->> Bounding box moves to: [259  33  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0.    0.    0.    0.986 0.014 0.    0.    0.    0.    0.    0.   ], argmax=3\n",
            "         |->> Action Probabilities (RAW): [5.9534272e-25 7.5136884e-14 0.0000000e+00 9.8596442e-01 1.4035569e-02\n",
            " 4.0726334e-26 1.8768283e-12 1.0674658e-22 2.4461766e-37 6.9755046e-29\n",
            " 1.1981177e-27], argmax=3\n",
            "   \u001b[33m|->> #13/t=93-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [259  32  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [3.5581575e-27 2.3709041e-27 4.2418463e-32 1.1130446e-27 1.0000000e+00\n",
            " 3.7422961e-28 2.2047286e-21 1.6804858e-19 9.8916129e-37 2.0485383e-27\n",
            " 9.4192783e-25], argmax=4\n",
            "   \u001b[33m|->> #14/t=94-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [259  31  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [7.4553844e-25 1.5037385e-24 3.1600858e-25 3.1566433e-23 1.0000000e+00\n",
            " 6.8071277e-27 3.3320887e-20 1.1200045e-19 7.1975585e-33 6.1816506e-25\n",
            " 3.9365166e-23], argmax=4\n",
            "   \u001b[33m|->> #15/t=95-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [259  30  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [1.8181809e-28 6.7681233e-30 3.0630190e-28 4.7318495e-25 1.0000000e+00\n",
            " 1.5524488e-32 1.6101790e-22 1.5004176e-21 6.9483714e-37 1.1923228e-30\n",
            " 1.1413614e-29], argmax=4\n",
            "   \u001b[33m|->> #16/t=96-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [259  29  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [2.8212033e-21 5.9308688e-22 1.4807272e-28 2.8718649e-16 1.0000000e+00\n",
            " 1.3481571e-26 3.1435819e-15 9.6752941e-14 5.9334516e-36 5.2555653e-28\n",
            " 2.3886091e-32], argmax=4\n",
            "   \u001b[33m|->> #17/t=97-th Action selection: 4/UP (P(a|s) = 0.8579999804496765)\u001b[0m\n",
            "      |->> Bounding box moves to: [259  28  89  51]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.8584 0.     0.     0.1416 0.     0.\n",
            " 0.    ], argmax=4\n",
            "         |->> Action Probabilities (RAW): [4.91962637e-10 1.58767398e-14 1.93408184e-22 4.32046150e-08\n",
            " 8.58403802e-01 6.89267504e-14 4.71749750e-10 1.41596183e-01\n",
            " 6.70299969e-32 4.51551305e-20 1.22989915e-20], argmax=4\n",
            "|->> Revisiting bbox: [259  30  89  51]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [263,  44,  89,  51] -> [259,  28,  89,  51] (Target was [246,  26,  86,  54])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.03) for 2X LEFT:bbox transition: [263,  44,  89,  51] -> [259,  44,  89,  51] w/ P(a|s)=0.9906181693077087 and iou=0.40091533180778033 and reward=0.030113719626857827 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.032) for 2X UP:bbox transition: [259,  44,  89,  51] -> [259,  42,  89,  51] w/ P(a|s)=1.0 and iou=0.4328288344515525 and reward=0.031913502643772185 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.035) for 2X LEFT:bbox transition: [259,  42,  89,  51] -> [255,  42,  89,  51] w/ P(a|s)=1.0 and iou=0.46763624740290877 and reward=0.034807412951356254 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.018) for UP:bbox transition: [255,  42,  89,  51] -> [255,  41,  89,  51] w/ P(a|s)=1.0 and iou=0.48592233009708735 and reward=0.018286082694178585 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.019) for UP:bbox transition: [255,  41,  89,  51] -> [255,  40,  89,  51] w/ P(a|s)=1.0 and iou=0.5046698345076192 and reward=0.0187475044105318 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.019) for UP:bbox transition: [255,  40,  89,  51] -> [255,  39,  89,  51] w/ P(a|s)=1.0 and iou=0.5238964487222038 and reward=0.019226614214584603 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.02) for UP:bbox transition: [255,  39,  89,  51] -> [255,  38,  89,  51] w/ P(a|s)=1.0 and iou=0.5436207766011094 and reward=0.019724327878905656 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (0.02) for UP:bbox transition: [255,  38,  89,  51] -> [255,  37,  89,  51] w/ P(a|s)=1.0 and iou=0.5638623978201635 and reward=0.02024162121905404 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (0.021) for UP:bbox transition: [255,  37,  89,  51] -> [255,  36,  89,  51] w/ P(a|s)=1.0 and iou=0.5846419327006039 and reward=0.020779534880440487 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (0.021) for UP:bbox transition: [255,  36,  89,  51] -> [255,  35,  89,  51] w/ P(a|s)=1.0 and iou=0.6059811122770199 and reward=0.021339179576415956 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (0.022) for UP:bbox transition: [255,  35,  89,  51] -> [255,  34,  89,  51] w/ P(a|s)=1.0 and iou=0.6279028541038822 and reward=0.02192174182686235 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (0.023) for UP:bbox transition: [255,  34,  89,  51] -> [255,  33,  89,  51] w/ P(a|s)=1.0 and iou=0.650431344356578 and reward=0.022528490252695765 and discount=0.8953382542587164\n",
            "   |->> t=13 Diff-Reward (-0.054) for 2X RIGHT:bbox transition: [255,  33,  89,  51] -> [259,  33,  89,  51] w/ P(a|s)=0.9859644174575806 and iou=0.5964881780250347 and reward=-0.05394316633154328 and discount=0.8863848717161292\n",
            "   |->> t=14 Diff-Reward (0.021) for UP:bbox transition: [259,  33,  89,  51] -> [259,  32,  89,  51] w/ P(a|s)=1.0 and iou=0.6170100369783412 and reward=0.020521858953306493 and discount=0.8775210229989678\n",
            "   |->> t=15 Diff-Reward (0.021) for UP:bbox transition: [259,  32,  89,  51] -> [259,  31,  89,  51] w/ P(a|s)=1.0 and iou=0.6380663574741349 and reward=0.021056320495793646 and discount=0.8687458127689782\n",
            "   |->> t=16 Diff-Reward (0.022) for UP:bbox transition: [259,  31,  89,  51] -> [259,  30,  89,  51] w/ P(a|s)=1.0 and iou=0.6596782938731249 and reward=0.02161193639899006 and discount=0.8600583546412884\n",
            "   |->> t=17 Diff-Reward (0.022) for UP:bbox transition: [259,  30,  89,  51] -> [259,  29,  89,  51] w/ P(a|s)=1.0 and iou=0.6818681318681319 and reward=0.022189837995006956 and discount=0.8514577710948755\n",
            "   |->> t=18 Diff-Reward (0.0) for UP:bbox transition: [259,  29,  89,  51] -> [259,  28,  89,  51] w/ P(a|s)=0.8584038019180298 and iou=0.6818681318681319 and reward=0.0 and discount=0.8429431933839268\n",
            "   |->> Assigned losses: [ 2.8385545e-04  3.1637433e-07  3.4161243e-07  1.7767151e-07\n",
            "  1.8033325e-07  1.8309241e-07  1.8595375e-07  1.8892230e-07\n",
            "  1.9200340e-07  1.9520279e-07  1.9852654e-07  2.0198111e-07\n",
            " -6.7585718e-04  1.8032908e-07  1.8317525e-07  1.8612862e-07\n",
            "  1.8919464e-07  0.0000000e+00]\n",
            "\u001b[31m>> Total frame loss: -0.00038890118594281375\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 29 with src: [259,  28,  89,  51] and target: [241,  24,  87,  54]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0029.jpg\n",
            "|->> Beginning tracking for bbox:[259  28  89  51]\n",
            "   \u001b[33m|->> #0/t=98-th Action selection: 10/SCALE UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [257  27  91  53]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.], argmax=10\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 2.9372101e-32 1.6240542e-35 3.8631970e-35 2.5661408e-20\n",
            " 1.5871888e-21 0.0000000e+00 1.0805585e-12 0.0000000e+00 0.0000000e+00\n",
            " 1.0000000e+00], argmax=10\n",
            "   \u001b[33m|->> #1/t=99-th Action selection: 10/SCALE UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [255  26  93  55]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.], argmax=10\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 4.6704723e-24 9.3966619e-21 1.2961052e-20 8.2626682e-14\n",
            " 1.6070922e-17 0.0000000e+00 2.5633444e-06 0.0000000e+00 0.0000000e+00\n",
            " 9.9999738e-01], argmax=10\n",
            "   \u001b[33m|->> #2/t=100-th Action selection: 10/SCALE UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [253  25  95  57]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.], argmax=10\n",
            "         |->> Action Probabilities (RAW): [0.00000000e+00 6.53533521e-23 5.24203328e-19 5.71030282e-21\n",
            " 1.18445129e-10 1.85177852e-14 0.00000000e+00 1.00121774e-07\n",
            " 0.00000000e+00 0.00000000e+00 9.99999881e-01], argmax=10\n",
            "   \u001b[33m|->> #3/t=101-th Action selection: 10/SCALE UP (P(a|s) = 0.9990000128746033)\u001b[0m\n",
            "      |->> Bounding box moves to: [251  24  97  59]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 0.000e+00 8.000e-04 0.000e+00 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 9.992e-01], argmax=10\n",
            "         |->> Action Probabilities (RAW): [9.9803829e-38 9.6773225e-19 9.8400868e-24 8.3906820e-22 8.3453988e-04\n",
            " 7.3456567e-14 0.0000000e+00 1.6368829e-13 0.0000000e+00 1.0034785e-29\n",
            " 9.9916553e-01], argmax=10\n",
            "   \u001b[33m|->> #4/t=102-th Action selection: 4/UP (P(a|s) = 0.46799999475479126)\u001b[0m\n",
            "      |->> Bounding box moves to: [251  23  97  59]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.4679 0.     0.     0.     0.     0.\n",
            " 0.5321], argmax=10\n",
            "         |->> Action Probabilities (RAW): [7.0192237e-36 3.4746089e-21 3.2325119e-26 1.2720216e-27 4.6793383e-01\n",
            " 2.9051401e-20 0.0000000e+00 3.6681595e-26 0.0000000e+00 2.1195148e-24\n",
            " 5.3206617e-01], argmax=10\n",
            "   \u001b[33m|->> #5/t=103-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [251  22  97  59]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 2.7198347e-32 3.1116732e-26 0.0000000e+00 1.0000000e+00\n",
            " 1.9233467e-25 0.0000000e+00 8.4594785e-24 0.0000000e+00 1.0531919e-32\n",
            " 6.4631220e-21], argmax=4\n",
            "   \u001b[33m|->> #6/t=104-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [251  21  97  59]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 3.4961388e-38 2.1857285e-28 0.0000000e+00 1.0000000e+00\n",
            " 5.2202856e-33 0.0000000e+00 1.4168829e-26 0.0000000e+00 2.7948725e-37\n",
            " 1.9939899e-34], argmax=4\n",
            "   \u001b[33m|->> #7/t=105-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [251  20  97  59]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 1.4928795e-31 7.7163395e-20 1.6283593e-35 1.0000000e+00\n",
            " 1.2451716e-36 0.0000000e+00 4.8883239e-22 0.0000000e+00 3.2295635e-32\n",
            " 1.3560446e-32], argmax=4\n",
            "   \u001b[33m|->> #8/t=106-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [251  19  97  59]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [7.4041494e-38 9.7783443e-23 4.8247718e-14 6.8377286e-21 1.0000000e+00\n",
            " 1.0460818e-15 1.0783275e-33 6.2183986e-12 0.0000000e+00 3.8457193e-25\n",
            " 4.5381713e-29], argmax=4\n",
            "   \u001b[33m|->> #9/t=107-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [251  18  97  59]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [3.6590243e-35 1.6943327e-25 2.2289765e-18 6.8851921e-18 9.9999988e-01\n",
            " 5.7214661e-10 3.3011376e-30 1.6899330e-07 0.0000000e+00 9.9569625e-28\n",
            " 1.4547330e-34], argmax=4\n",
            "|->> Revisiting bbox: [251  20  97  59]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [259,  28,  89,  51] -> [251,  18,  97,  59] (Target was [241,  24,  87,  54])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.018) for SCALE UP:bbox transition: [259,  28,  89,  51] -> [257,  27,  91,  53] w/ P(a|s)=1.0 and iou=0.6137288135593221 and reward=0.017564998110903174 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.017) for SCALE UP:bbox transition: [257,  27,  91,  53] -> [255,  26,  93,  55] w/ P(a|s)=0.9999973773956299 and iou=0.630879175668938 and reward=0.017150362109615958 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.017) for SCALE UP:bbox transition: [255,  26,  93,  55] -> [253,  25,  95,  57] w/ P(a|s)=0.9999998807907104 and iou=0.647605083088954 and reward=0.016725907420016006 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.016) for SCALE UP:bbox transition: [253,  25,  95,  57] -> [251,  24,  97,  59] w/ P(a|s)=0.9991655349731445 and iou=0.6638990898930225 and reward=0.01629400680406845 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.0) for UP:bbox transition: [251,  24,  97,  59] -> [251,  23,  97,  59] w/ P(a|s)=0.4679338335990906 and iou=0.6638990898930225 and reward=0.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.0) for UP:bbox transition: [251,  23,  97,  59] -> [251,  22,  97,  59] w/ P(a|s)=1.0 and iou=0.6638990898930225 and reward=0.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.0) for UP:bbox transition: [251,  22,  97,  59] -> [251,  21,  97,  59] w/ P(a|s)=1.0 and iou=0.6638990898930225 and reward=0.0 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (0.0) for UP:bbox transition: [251,  21,  97,  59] -> [251,  20,  97,  59] w/ P(a|s)=1.0 and iou=0.6638990898930225 and reward=0.0 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (0.0) for UP:bbox transition: [251,  20,  97,  59] -> [251,  19,  97,  59] w/ P(a|s)=1.0 and iou=0.6638990898930225 and reward=0.0 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (-0.02) for UP:bbox transition: [251,  19,  97,  59] -> [251,  18,  97,  59] w/ P(a|s)=0.9999998807907104 and iou=0.6436908517350157 and reward=-0.020208238158006764 and discount=0.9135172474836408\n",
            "   |->> Assigned losses: [ 1.7588941e-07  1.7002003e-07  1.6415406e-07  1.3198448e-05\n",
            "  0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
            "  0.0000000e+00 -1.8485736e-07]\n",
            "\u001b[92m>> Total frame loss: 1.3523653251468204e-05\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 30 with src: [251,  18,  97,  59] and target: [238,  24,  86,  54]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0030.jpg\n",
            "|->> Beginning tracking for bbox:[251  18  97  59]\n",
            "   \u001b[33m|->> #0/t=108-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [251  20  97  59]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 2.3283969e-29 1.2310909e-21 1.4750866e-30 2.0257044e-13\n",
            " 7.0312388e-21 0.0000000e+00 9.9999905e-01 0.0000000e+00 6.0685005e-29\n",
            " 9.1491813e-07], argmax=7\n",
            "   \u001b[33m|->> #1/t=109-th Action selection: 10/SCALE UP (P(a|s) = 0.16899999976158142)\u001b[0m\n",
            "      |->> Bounding box moves to: [249  19  99  61]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.     0.     0.     0.8309 0.     0.\n",
            " 0.1691], argmax=7\n",
            "         |->> Action Probabilities (RAW): [2.2774795e-38 1.5507747e-29 8.0258971e-33 4.5067462e-24 1.1796486e-13\n",
            " 3.9322356e-23 0.0000000e+00 8.3090901e-01 0.0000000e+00 0.0000000e+00\n",
            " 1.6909105e-01], argmax=7\n",
            "   \u001b[33m|->> #2/t=110-th Action selection: 10/SCALE UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [247  18 101  63]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.], argmax=10\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 9.5171485e-27 3.4420097e-26 8.5691513e-26 1.0207847e-17\n",
            " 8.2801290e-20 0.0000000e+00 4.8444138e-10 0.0000000e+00 7.7562268e-38\n",
            " 1.0000000e+00], argmax=10\n",
            "   \u001b[33m|->> #3/t=111-th Action selection: 10/SCALE UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [245  17 104  65]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.], argmax=10\n",
            "         |->> Action Probabilities (RAW): [5.9876642e-34 1.8338154e-24 6.5857925e-22 4.3783452e-27 4.7900926e-14\n",
            " 4.9894223e-20 0.0000000e+00 3.9836181e-08 0.0000000e+00 7.9313801e-31\n",
            " 1.0000000e+00], argmax=10\n",
            "   \u001b[33m|->> #4/t=112-th Action selection: 7/2X DOWN (P(a|s) = 0.8510000109672546)\u001b[0m\n",
            "      |->> Bounding box moves to: [245  19 104  65]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.0012 0.     0.     0.8507 0.     0.\n",
            " 0.1481], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.0654633e-27 9.4070017e-17 8.5037885e-13 1.9370847e-27 1.2011457e-03\n",
            " 4.9895719e-14 2.7131551e-37 8.5074097e-01 0.0000000e+00 1.1720444e-21\n",
            " 1.4805785e-01], argmax=7\n",
            "   \u001b[33m|->> #5/t=113-th Action selection: 10/SCALE UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [243  18 107  67]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.], argmax=10\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 3.0262324e-31 0.0000000e+00 4.7627489e-38 5.9164776e-21\n",
            " 5.1614475e-21 0.0000000e+00 8.4583116e-25 0.0000000e+00 0.0000000e+00\n",
            " 1.0000000e+00], argmax=10\n",
            "   \u001b[33m|->> #6/t=114-th Action selection: 10/SCALE UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [241  16 110  69]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.], argmax=10\n",
            "         |->> Action Probabilities (RAW): [6.5935146e-28 1.2017558e-24 8.5781690e-28 7.6697737e-33 2.0778360e-15\n",
            " 3.6828789e-13 0.0000000e+00 5.7931368e-11 0.0000000e+00 2.3433489e-31\n",
            " 1.0000000e+00], argmax=10\n",
            "   \u001b[33m|->> #7/t=115-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [241  14 110  69]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 0.000e+00 9.997e-01 0.000e+00 0.000e+00\n",
            " 3.000e-04 0.000e+00 0.000e+00 0.000e+00], argmax=4\n",
            "         |->> Action Probabilities (RAW): [2.7332194e-21 1.2207207e-15 2.0139283e-13 1.8744674e-29 9.9969637e-01\n",
            " 2.2160906e-09 1.1489267e-33 2.6098450e-04 0.0000000e+00 1.9795122e-17\n",
            " 4.2655043e-05], argmax=4\n",
            "   \u001b[33m|->> #8/t=116-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [241  12 110  69]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 7.1786076e-34 5.0677146e-31 4.6689178e-31 1.0000000e+00\n",
            " 1.2456587e-32 0.0000000e+00 4.9335216e-17 0.0000000e+00 3.0007652e-34\n",
            " 1.2169930e-10], argmax=4\n",
            "   \u001b[33m|->> #9/t=117-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [241  10 110  69]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.00000000e+00 2.72640507e-21 7.07699905e-19 1.17767595e-24\n",
            " 1.00000000e+00 1.26441710e-23 0.00000000e+00 1.43315317e-18\n",
            " 0.00000000e+00 3.66213623e-29 6.31941166e-11], argmax=4\n",
            "   \u001b[33m|->> #10/t=118-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [241   8 110  69]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 1.5819298e-20 1.1815895e-25 4.3167566e-31 9.9999940e-01\n",
            " 5.5747325e-18 0.0000000e+00 3.5593482e-13 0.0000000e+00 4.3215298e-18\n",
            " 6.5390259e-07], argmax=4\n",
            "   \u001b[33m|->> #11/t=119-th Action selection: 10/SCALE UP (P(a|s) = 0.8529999852180481)\u001b[0m\n",
            "      |->> Bounding box moves to: [239   6 113  71]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.     0.     0.     0.1475 0.     0.\n",
            " 0.8525], argmax=10\n",
            "         |->> Action Probabilities (RAW): [4.7528407e-19 5.1943696e-19 8.9895217e-20 4.4997207e-22 1.5988405e-07\n",
            " 2.3110057e-15 2.8492439e-35 1.4748034e-01 0.0000000e+00 6.3715968e-16\n",
            " 8.5251951e-01], argmax=10\n",
            "   \u001b[33m|->> #12/t=120-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [239  10 113  71]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 0.000e+00 5.000e-04 0.000e+00 0.000e+00\n",
            " 9.995e-01 0.000e+00 0.000e+00 0.000e+00], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.4346292e-14 2.8575411e-24 7.2788606e-24 2.5465626e-20 4.6272491e-04\n",
            " 2.0199593e-21 1.2641861e-32 9.9953592e-01 0.0000000e+00 8.1365568e-17\n",
            " 1.4485341e-06], argmax=7\n",
            "   \u001b[33m|->> #13/t=121-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [239   8 113  71]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [2.4336801e-37 1.2047137e-21 6.0690712e-26 4.1821588e-31 1.0000000e+00\n",
            " 4.3121293e-18 0.0000000e+00 2.5360463e-16 0.0000000e+00 1.7326021e-17\n",
            " 3.8165343e-10], argmax=4\n",
            "   \u001b[33m|->> #14/t=122-th Action selection: 7/2X DOWN (P(a|s) = 0.46700000762939453)\u001b[0m\n",
            "      |->> Bounding box moves to: [239  12 113  71]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.0086 0.     0.     0.4669 0.     0.\n",
            " 0.5245], argmax=10\n",
            "         |->> Action Probabilities (RAW): [3.7192792e-22 1.2067177e-15 5.7675556e-19 5.8004382e-24 8.6217113e-03\n",
            " 1.2760962e-13 1.2519100e-37 4.6687028e-01 0.0000000e+00 3.9262441e-11\n",
            " 5.2450806e-01], argmax=10\n",
            "|->> Revisiting bbox: [239  10 113  71]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [251,  18,  97,  59] -> [239,  12, 113,  71] (Target was [238,  24,  86,  54])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.018) for 2X DOWN:bbox transition: [251,  18,  97,  59] -> [251,  20,  97,  59] w/ P(a|s)=0.9999990463256836 and iou=0.6135408560311284 and reward=0.018126882500811403 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.003) for SCALE UP:bbox transition: [251,  20,  97,  59] -> [249,  19,  99,  61] w/ P(a|s)=0.16909104585647583 and iou=0.6105834464043419 and reward=-0.002957409626786478 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-0.003) for SCALE UP:bbox transition: [249,  19,  99,  61] -> [247,  18, 101,  63] w/ P(a|s)=1.0 and iou=0.607095926412615 and reward=-0.0034875199917269173 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-0.009) for SCALE UP:bbox transition: [247,  18, 101,  63] -> [245,  17, 104,  65] w/ P(a|s)=1.0 and iou=0.5976463995516952 and reward=-0.009449526860919821 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.0) for 2X DOWN:bbox transition: [245,  17, 104,  65] -> [245,  19, 104,  65] w/ P(a|s)=0.8507409691810608 and iou=0.5976463995516952 and reward=0.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-0.01) for SCALE UP:bbox transition: [245,  19, 104,  65] -> [243,  18, 107,  67] w/ P(a|s)=1.0 and iou=0.5879822556795268 and reward=-0.009664143872168407 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (-0.01) for SCALE UP:bbox transition: [243,  18, 107,  67] -> [241,  16, 110,  69] w/ P(a|s)=1.0 and iou=0.5781733746130031 and reward=-0.009808881066523667 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (0.0) for UP:bbox transition: [241,  16, 110,  69] -> [241,  14, 110,  69] w/ P(a|s)=0.9996963739395142 and iou=0.5781733746130031 and reward=0.0 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (0.0) for UP:bbox transition: [241,  14, 110,  69] -> [241,  12, 110,  69] w/ P(a|s)=1.0 and iou=0.5781733746130031 and reward=0.0 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (0.0) for UP:bbox transition: [241,  12, 110,  69] -> [241,  10, 110,  69] w/ P(a|s)=1.0 and iou=0.5781733746130031 and reward=0.0 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (-0.017) for UP:bbox transition: [241,  10, 110,  69] -> [241,   8, 110,  69] w/ P(a|s)=0.9999994039535522 and iou=0.5614550095724314 and reward=-0.01671836504057167 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (-0.01) for SCALE UP:bbox transition: [241,   8, 110,  69] -> [239,   6, 113,  71] w/ P(a|s)=0.8525195121765137 and iou=0.551948051948052 and reward=-0.009506957624379475 and discount=0.8953382542587164\n",
            "   |->> t=13 Diff-Reward (0.016) for 2X DOWN:bbox transition: [239,   6, 113,  71] -> [239,  10, 113,  71] w/ P(a|s)=0.9995359182357788 and iou=0.568280302092361 and reward=0.016332250144309057 and discount=0.8863848717161292\n",
            "   |->> t=14 Diff-Reward (0.0) for UP:bbox transition: [239,  10, 113,  71] -> [239,   8, 113,  71] w/ P(a|s)=1.0 and iou=0.568280302092361 and reward=0.0 and discount=0.8775210229989678\n",
            "   |->> t=15 Diff-Reward (0.0) for 2X DOWN:bbox transition: [239,   8, 113,  71] -> [239,  12, 113,  71] w/ P(a|s)=0.4668702781200409 and iou=0.568280302092361 and reward=0.0 and discount=0.8687458127689782\n",
            "   |->> Assigned losses: [ 1.8151590e-07 -5.2036950e-03 -3.4227771e-08 -9.1813632e-08\n",
            "  0.0000000e+00 -9.2030305e-08 -9.2474544e-08  0.0000000e+00\n",
            "  0.0000000e+00  0.0000000e+00 -1.5140398e-07 -1.3581585e-03\n",
            "  6.7199126e-06  0.0000000e+00  0.0000000e+00]\n",
            "\u001b[31m>> Total frame loss: -0.006555413827300072\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 31 with src: [239,  12, 113,  71] and target: [243,  26,  85,  60]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0031.jpg\n",
            "|->> Beginning tracking for bbox:[239  12 113  71]\n",
            "   \u001b[33m|->> #0/t=123-th Action selection: 10/SCALE UP (P(a|s) = 0.9990000128746033)\u001b[0m\n",
            "      |->> Bounding box moves to: [237  10 116  73]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.     0.     0.     0.0012 0.     0.\n",
            " 0.9988], argmax=10\n",
            "         |->> Action Probabilities (RAW): [1.8624376e-26 2.2726314e-31 2.5945150e-24 6.5717209e-10 2.2221998e-10\n",
            " 1.3251999e-23 0.0000000e+00 1.2153977e-03 0.0000000e+00 1.6401063e-19\n",
            " 9.9878460e-01], argmax=10\n",
            "   \u001b[33m|->> #1/t=124-th Action selection: 10/SCALE UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [235   8 119  75]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.], argmax=10\n",
            "         |->> Action Probabilities (RAW): [2.6920068e-29 1.4607802e-28 3.1594890e-26 7.1258803e-13 1.2701895e-05\n",
            " 1.6906056e-17 0.0000000e+00 1.8346755e-07 0.0000000e+00 2.2021986e-18\n",
            " 9.9998713e-01], argmax=10\n",
            "   \u001b[33m|->> #2/t=125-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [235   6 119  75]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 0.000e+00 9.999e-01 0.000e+00 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 1.000e-04], argmax=4\n",
            "         |->> Action Probabilities (RAW): [1.11747468e-30 1.88931586e-21 3.61051413e-23 2.85377428e-14\n",
            " 9.99880552e-01 2.08667077e-11 9.22314807e-38 4.10456700e-08\n",
            " 0.00000000e+00 2.26454674e-10 1.19482764e-04], argmax=4\n",
            "   \u001b[33m|->> #3/t=126-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [235   4 119  75]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 0.000e+00 9.999e-01 0.000e+00 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 1.000e-04], argmax=4\n",
            "         |->> Action Probabilities (RAW): [3.3520976e-29 1.2842078e-18 8.7643330e-24 4.3146808e-15 9.9989569e-01\n",
            " 4.4836890e-09 5.9703252e-33 4.4479188e-07 0.0000000e+00 2.1347921e-09\n",
            " 1.0379812e-04], argmax=4\n",
            "|->> Revisiting bbox: [235   8 119  75]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [239,  12, 113,  71] -> [235,   4, 119,  75] (Target was [243,  26,  85,  60])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.03) for SCALE UP:bbox transition: [239,  12, 113,  71] -> [237,  10, 116,  73] w/ P(a|s)=0.998784601688385 and iou=0.555428178378998 and reward=-0.029858122659900288 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.028) for SCALE UP:bbox transition: [237,  10, 116,  73] -> [235,   8, 119,  75] w/ P(a|s)=0.9999871253967285 and iou=0.5277777777777778 and reward=-0.02765040060122026 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-0.028) for UP:bbox transition: [235,   8, 119,  75] -> [235,   6, 119,  75] w/ P(a|s)=0.9998805522918701 and iou=0.5 and reward=-0.02777777777777779 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-0.027) for UP:bbox transition: [235,   6, 119,  75] -> [235,   4, 119,  75] w/ P(a|s)=0.9998956918716431 and iou=0.4732142857142857 and reward=-0.0267857142857143 and discount=0.970299\n",
            "   |->> Assigned losses: [-3.6311587e-05 -3.5243033e-07 -3.2521580e-06 -2.7111257e-06]\n",
            "\u001b[31m>> Total frame loss: -4.262729999027215e-05\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 32 with src: [235,   4, 119,  75] and target: [253,  34,  85,  58]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0032.jpg\n",
            "|->> Beginning tracking for bbox:[235   4 119  75]\n",
            "   \u001b[33m|->> #0/t=127-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [235   8 119  75]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [6.61992017e-09 5.34666844e-09 1.37947154e-10 1.12386656e-10\n",
            " 1.97166762e-11 1.77044473e-11 2.54038071e-07 9.99996901e-01\n",
            " 1.43550300e-16 2.62840899e-06 2.43696121e-07], argmax=7\n",
            "   \u001b[33m|->> #1/t=128-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [235  12 119  75]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [7.2096030e-22 3.0256826e-12 3.8116627e-15 1.6235268e-20 1.0126510e-17\n",
            " 1.4177930e-15 2.3477602e-11 9.9999940e-01 4.6079209e-25 6.2919992e-07\n",
            " 7.6248856e-15], argmax=7\n",
            "   \u001b[33m|->> #2/t=129-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [235  16 119  75]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.2318854e-22 6.1157091e-13 1.5426385e-23 7.1239371e-27 1.1572812e-13\n",
            " 4.3077059e-11 8.4830490e-21 1.0000000e+00 5.8031566e-26 9.1451047e-15\n",
            " 1.1156288e-20], argmax=7\n",
            "|->> Revisiting bbox: [235  12 119  75]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [235,   4, 119,  75] -> [235,  16, 119,  75] (Target was [253,  34,  85,  58])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.048) for 2X DOWN:bbox transition: [235,   4, 119,  75] -> [235,   8, 119,  75] w/ P(a|s)=0.9999969005584717 and iou=0.4298245614035088 and reward=0.04846862920011896 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.052) for 2X DOWN:bbox transition: [235,   8, 119,  75] -> [235,  12, 119,  75] w/ P(a|s)=0.9999994039535522 and iou=0.4818181818181818 and reward=0.051993620414673036 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.056) for 2X DOWN:bbox transition: [235,  12, 119,  75] -> [235,  16, 119,  75] w/ P(a|s)=1.0 and iou=0.5377358490566038 and reward=0.05591766723842195 and discount=0.9801\n",
            "   |->> Assigned losses: [4.8534696e-07 5.1543844e-07 5.4879609e-07]\n",
            "\u001b[92m>> Total frame loss: 1.549581611470785e-06\u001b[0m\n",
            "Final bounding box: [235  16 119  75] reached in 130 timesteps (originating from [259 143  89  51]). Target was [253  34  85  58]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 33 in t=130 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[92m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 3.665072441101074\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.00767653901129961\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 4.115693092346191\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.013516450300812721\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 5.902712345123291\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.020774103701114655\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 2.0076754093170166\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.01327577605843544\n",
            "Layer Name: custom_rnn/conv2d/kernel:0, GRAD NORM = 0.6610552072525024\n",
            "Layer Name: custom_rnn/conv2d/bias:0, GRAD NORM = 0.03771581873297691\n",
            "Layer Name: custom_rnn/conv2d_1/kernel:0, GRAD NORM = 6.189828395843506\n",
            "Layer Name: custom_rnn/conv2d_1/bias:0, GRAD NORM = 0.03771581873297691\n",
            "Layer Name: custom_rnn/conv2d_2/kernel:0, GRAD NORM = 4.242537975311279\n",
            "Layer Name: custom_rnn/conv2d_2/bias:0, GRAD NORM = 0.024979794397950172\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/Deer\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Starting bounding box for adnet_datasets/OTB/Deer: frames 18:28 is [216  65  94  64].\n",
            "\u001b[34m>> Attempting to reach frame 19 with src: [216,  65,  94,  64] and target: [224,  92,  93,  62]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0019.jpg\n",
            "|->> Beginning tracking for bbox:[216  65  94  64]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [216  67  94  64]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.9486571e-31 1.4182983e-28 4.3233329e-24 1.0797852e-17 1.3971640e-18\n",
            " 5.6005091e-17 2.1399106e-32 1.0000000e+00 6.6538905e-32 1.6098912e-21\n",
            " 1.5587316e-19], argmax=7\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [216  69  94  64]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [2.9572537e-26 7.1752806e-23 2.2518360e-20 7.4017931e-19 4.3623107e-18\n",
            " 2.9866123e-10 5.9073364e-31 1.0000000e+00 8.8741303e-29 1.2660910e-17\n",
            " 5.4518799e-16], argmax=7\n",
            "   \u001b[33m|->> #2/t=3-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [216  71  94  64]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [3.0599613e-16 2.2868597e-18 2.3094792e-17 6.4859463e-17 1.9885703e-12\n",
            " 1.4233498e-06 4.0992547e-26 9.9999833e-01 3.7440288e-22 4.2487728e-16\n",
            " 2.5880172e-07], argmax=7\n",
            "|->> Revisiting bbox: [216  69  94  64]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [216,  65,  94,  64] -> [216,  71,  94,  64] (Target was [224,  92,  93,  62])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.028) for 2X DOWN:bbox transition: [216,  65,  94,  64] -> [216,  67,  94,  64] w/ P(a|s)=1.0 and iou=0.3979591836734694 and reward=0.02795918367346939 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.029) for 2X DOWN:bbox transition: [216,  67,  94,  64] -> [216,  69,  94,  64] w/ P(a|s)=1.0 and iou=0.4270833333333333 and reward=0.02912414965986393 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.03) for 2X DOWN:bbox transition: [216,  69,  94,  64] -> [216,  71,  94,  64] w/ P(a|s)=0.9999983310699463 and iou=0.4574468085106383 and reward=0.030363475177304977 and discount=0.9801\n",
            "   |->> Assigned losses: [2.7997291e-07 2.8872208e-07 2.9799804e-07]\n",
            "\u001b[92m>> Total frame loss: 8.666930284562113e-07\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 20 with src: [216,  71,  94,  64] and target: [236, 115,  89,  63]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0020.jpg\n",
            "|->> Beginning tracking for bbox:[216  71  94  64]\n",
            "   \u001b[33m|->> #0/t=4-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [216  73  94  64]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [2.1330414e-12 7.7638923e-16 3.1020253e-19 6.9428263e-13 1.4484608e-17\n",
            " 4.9090914e-12 9.0810952e-17 1.0000000e+00 8.8810276e-24 8.5618842e-14\n",
            " 3.7940973e-15], argmax=7\n",
            "   \u001b[33m|->> #1/t=5-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [216  75  94  64]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [4.4897232e-11 3.1859911e-16 4.8186596e-20 1.3740656e-11 3.4938832e-17\n",
            " 9.2685183e-15 2.8790730e-15 1.0000000e+00 2.6014406e-24 1.2306117e-16\n",
            " 1.2914367e-17], argmax=7\n",
            "   \u001b[33m|->> #2/t=6-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [216  77  94  64]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [6.0403420e-25 1.1265134e-26 1.6237106e-31 2.9615497e-22 3.2600269e-31\n",
            " 9.6754847e-24 1.8072996e-25 1.0000000e+00 4.9471563e-36 1.1702598e-24\n",
            " 5.1555088e-27], argmax=7\n",
            "   \u001b[33m|->> #3/t=7-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [216  79  94  64]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [7.9139715e-31 1.2888530e-32 7.6645601e-35 1.0437869e-28 9.8867519e-36\n",
            " 1.7513540e-25 5.8407222e-30 1.0000000e+00 0.0000000e+00 1.2139947e-30\n",
            " 3.6595906e-31], argmax=7\n",
            "   \u001b[33m|->> #4/t=8-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [216  81  94  64]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.4338386e-38 4.1845163e-33 1.4299463e-35 4.3441192e-29 7.1769812e-37\n",
            " 1.3631146e-23 1.4909348e-36 1.0000000e+00 0.0000000e+00 4.2390921e-34\n",
            " 0.0000000e+00], argmax=7\n",
            "   \u001b[33m|->> #5/t=9-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [216  83  94  64]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [3.40215740e-25 1.26255665e-23 3.16179790e-25 2.30265065e-22\n",
            " 1.62812587e-17 2.49985071e-19 1.27798259e-27 1.00000000e+00\n",
            " 6.84403198e-32 1.17533313e-24 2.33797957e-26], argmax=7\n",
            "   \u001b[33m|->> #6/t=10-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [216  85  94  64]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.7385518e-27 2.1809037e-30 2.1650452e-31 3.4760890e-28 1.6027892e-21\n",
            " 5.6534676e-23 2.8549452e-31 1.0000000e+00 1.6217141e-35 3.1965627e-28\n",
            " 5.1639049e-30], argmax=7\n",
            "   \u001b[33m|->> #7/t=11-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [216  87  94  64]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [2.5211258e-30 1.9027508e-27 0.0000000e+00 2.2301680e-25 2.0124550e-24\n",
            " 2.8759881e-23 2.1013045e-36 1.0000000e+00 0.0000000e+00 3.1302667e-28\n",
            " 5.0266830e-32], argmax=7\n",
            "   \u001b[33m|->> #8/t=12-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [216  89  94  64]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [6.2944148e-26 1.6342554e-24 9.5043479e-33 8.8980012e-20 4.7698367e-17\n",
            " 3.4437817e-19 1.6895404e-29 1.0000000e+00 7.5768913e-33 3.3082943e-25\n",
            " 4.1725742e-27], argmax=7\n",
            "   \u001b[33m|->> #9/t=13-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [216  91  94  64]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [2.1266401e-15 7.2111293e-12 3.7418623e-16 2.1113729e-13 7.6400095e-09\n",
            " 6.2640959e-09 2.8870299e-19 1.0000000e+00 3.1273518e-22 1.5996965e-12\n",
            " 2.0792734e-13], argmax=7\n",
            "   \u001b[33m|->> #10/t=14-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [216  93  94  64]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [2.6452393e-14 3.1482578e-10 2.2006829e-13 3.5618245e-19 3.6016365e-09\n",
            " 1.5800262e-07 5.5500002e-16 9.9999988e-01 5.1226444e-15 4.5993751e-08\n",
            " 1.9532676e-12], argmax=7\n",
            "   \u001b[33m|->> #11/t=15-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [216  95  94  64]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [6.7631934e-15 9.5756146e-12 6.0762511e-19 5.0823636e-26 5.8043685e-13\n",
            " 1.3517214e-10 1.4872066e-16 1.0000000e+00 2.0079806e-20 4.2334574e-13\n",
            " 4.2071784e-19], argmax=7\n",
            "   \u001b[33m|->> #12/t=16-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [216  97  94  64]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [2.3291513e-10 2.9927243e-08 1.1031442e-18 8.5553165e-20 6.6025794e-09\n",
            " 1.4596311e-06 8.4142627e-13 9.9999857e-01 2.3373044e-21 6.8799508e-09\n",
            " 9.3062981e-17], argmax=7\n",
            "|->> Revisiting bbox: [216  95  94  64]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [216,  71,  94,  64] -> [216,  97,  94,  64] (Target was [236, 115,  89,  63])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.017) for 2X DOWN:bbox transition: [216,  71,  94,  64] -> [216,  73,  94,  64] w/ P(a|s)=1.0 and iou=0.16288144072036018 and reward=0.0169680028814565 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.017) for 2X DOWN:bbox transition: [216,  73,  94,  64] -> [216,  75,  94,  64] w/ P(a|s)=1.0 and iou=0.1803595003554382 and reward=0.017478059635078036 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.018) for 2X DOWN:bbox transition: [216,  75,  94,  64] -> [216,  77,  94,  64] w/ P(a|s)=1.0 and iou=0.19837096607897722 and reward=0.01801146572353901 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.019) for 2X DOWN:bbox transition: [216,  77,  94,  64] -> [216,  79,  94,  64] w/ P(a|s)=1.0 and iou=0.21694063448853523 and reward=0.01856966840955801 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.019) for 2X DOWN:bbox transition: [216,  79,  94,  64] -> [216,  81,  94,  64] w/ P(a|s)=1.0 and iou=0.23609486334148677 and reward=0.019154228852951538 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.02) for 2X DOWN:bbox transition: [216,  81,  94,  64] -> [216,  83,  94,  64] w/ P(a|s)=1.0 and iou=0.25586169638033496 and reward=0.019766833038848186 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.02) for 2X DOWN:bbox transition: [216,  83,  94,  64] -> [216,  85,  94,  64] w/ P(a|s)=1.0 and iou=0.2762710003294169 and reward=0.02040930394908197 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (0.021) for 2X DOWN:bbox transition: [216,  85,  94,  64] -> [216,  87,  94,  64] w/ P(a|s)=1.0 and iou=0.2973546154704766 and reward=0.021083615141059664 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (0.022) for 2X DOWN:bbox transition: [216,  87,  94,  64] -> [216,  89,  94,  64] w/ P(a|s)=1.0 and iou=0.3191465213937124 and reward=0.02179190592323582 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (0.023) for 2X DOWN:bbox transition: [216,  89,  94,  64] -> [216,  91,  94,  64] w/ P(a|s)=1.0 and iou=0.3416830197391204 and reward=0.022536498345407996 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (0.023) for 2X DOWN:bbox transition: [216,  91,  94,  64] -> [216,  93,  94,  64] w/ P(a|s)=0.9999998807907104 and iou=0.3650029359953024 and reward=0.023319916256182016 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (0.024) for 2X DOWN:bbox transition: [216,  93,  94,  64] -> [216,  95,  94,  64] w/ P(a|s)=1.0 and iou=0.3891478427154297 and reward=0.024144906720127257 and discount=0.8953382542587164\n",
            "   |->> t=13 Diff-Reward (0.025) for 2X DOWN:bbox transition: [216,  95,  94,  64] -> [216,  97,  94,  64] w/ P(a|s)=0.9999985694885254 and iou=0.41416230684998173 and reward=0.02501446413455205 and discount=0.8863848717161292\n",
            "   |->> Assigned losses: [1.6991130e-07 1.7326863e-07 1.7677098e-07 1.8042689e-07 1.8424554e-07\n",
            " 1.8823683e-07 1.9241146e-07 1.9678095e-07 2.0135774e-07 2.0615541e-07\n",
            " 2.1118861e-07 2.1647324e-07 2.2202663e-07]\n",
            "\u001b[92m>> Total frame loss: 2.5192541670548962e-06\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 21 with src: [216,  97,  94,  64] and target: [252, 138,  94,  58]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0021.jpg\n",
            "|->> Beginning tracking for bbox:[216  97  94  64]\n",
            "   \u001b[33m|->> #0/t=17-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [216  99  94  64]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [2.5123396e-07 2.9606717e-18 2.6861355e-25 7.2739060e-16 1.7293372e-26\n",
            " 1.5097605e-17 7.3178438e-07 9.9999905e-01 1.3250708e-31 1.0618811e-16\n",
            " 2.1560912e-25], argmax=7\n",
            "   \u001b[33m|->> #1/t=18-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [216 101  94  64]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.4452425e-14 1.3916224e-24 3.6854205e-33 3.9494110e-21 1.6133543e-26\n",
            " 1.1399702e-27 1.9008915e-14 1.0000000e+00 9.8766397e-38 6.3209129e-24\n",
            " 1.3162531e-35], argmax=7\n",
            "   \u001b[33m|->> #2/t=19-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [216 103  94  64]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [8.6757594e-17 1.0134484e-23 2.0310699e-34 2.8322467e-20 1.6982754e-23\n",
            " 2.7417819e-26 5.2996415e-18 1.0000000e+00 2.4735547e-35 3.3730684e-25\n",
            " 2.8825825e-35], argmax=7\n",
            "   \u001b[33m|->> #3/t=20-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [216 105  94  64]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [2.2235326e-11 7.2850055e-20 6.8206111e-29 1.7398430e-15 1.2166116e-19\n",
            " 5.4631764e-19 2.6225762e-15 1.0000000e+00 1.6275843e-26 8.5184235e-22\n",
            " 1.1003399e-30], argmax=7\n",
            "   \u001b[33m|->> #4/t=21-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [216 107  94  64]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.9826089e-08 1.9768553e-22 1.3063228e-29 9.7260728e-16 2.7682770e-18\n",
            " 4.0972435e-19 7.8380154e-17 1.0000000e+00 1.1135183e-23 1.0172409e-22\n",
            " 2.1683963e-28], argmax=7\n",
            "   \u001b[33m|->> #5/t=22-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [216 109  94  64]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.4337522e-14 6.1557877e-33 1.3149126e-36 4.7557414e-23 5.8381397e-22\n",
            " 4.2245991e-25 3.6214726e-22 1.0000000e+00 2.0847314e-34 9.0416251e-31\n",
            " 1.1796375e-37], argmax=7\n",
            "   \u001b[33m|->> #6/t=23-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [216 111  94  64]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [2.3658523e-28 0.0000000e+00 0.0000000e+00 3.0055928e-31 5.7876092e-28\n",
            " 3.2490737e-33 4.6815043e-33 1.0000000e+00 0.0000000e+00 1.6566544e-35\n",
            " 0.0000000e+00], argmax=7\n",
            "   \u001b[33m|->> #7/t=24-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [216 113  94  64]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [4.1127994e-31 0.0000000e+00 0.0000000e+00 5.1719200e-26 6.4062392e-24\n",
            " 1.8322003e-24 3.2018194e-30 1.0000000e+00 0.0000000e+00 5.3346531e-32\n",
            " 0.0000000e+00], argmax=7\n",
            "   \u001b[33m|->> #8/t=25-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [216 115  94  64]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [3.2656839e-20 5.0369986e-29 1.3737620e-33 1.5422197e-17 1.0749235e-13\n",
            " 5.2914170e-19 6.8623932e-22 1.0000000e+00 4.5260106e-32 3.1554103e-26\n",
            " 3.2418961e-31], argmax=7\n",
            "   \u001b[33m|->> #9/t=26-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [216 117  94  64]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [4.9297893e-20 3.9610586e-21 4.5773300e-27 1.0537963e-14 2.7619873e-09\n",
            " 1.6585344e-14 3.7685045e-17 1.0000000e+00 5.5174585e-28 8.2867877e-22\n",
            " 7.2542145e-30], argmax=7\n",
            "   \u001b[33m|->> #10/t=27-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [216 119  94  64]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [3.3418872e-22 5.9979192e-22 4.7529106e-31 7.6293178e-21 2.4466038e-19\n",
            " 5.1287398e-17 7.9316960e-20 1.0000000e+00 1.3009028e-36 3.7862462e-30\n",
            " 6.8552536e-36], argmax=7\n",
            "   \u001b[33m|->> #11/t=28-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [216 121  94  64]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.6734361e-19 1.2981360e-22 1.1561141e-24 4.0169270e-17 2.5079959e-21\n",
            " 9.4798547e-10 1.7862861e-16 1.0000000e+00 6.8704149e-35 6.7013407e-26\n",
            " 2.0702033e-28], argmax=7\n",
            "|->> Revisiting bbox: [216 119  94  64]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [216,  97,  94,  64] -> [216, 121,  94,  64] (Target was [252, 138,  94,  58])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.013) for 2X DOWN:bbox transition: [216,  97,  94,  64] -> [216,  99,  94,  64] w/ P(a|s)=0.9999990463256836 and iou=0.1447394689558794 and reward=0.013103392381969808 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.013) for 2X DOWN:bbox transition: [216,  99,  94,  64] -> [216, 101,  94,  64] w/ P(a|s)=1.0 and iou=0.15814986871339123 and reward=0.01341039975751182 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.014) for 2X DOWN:bbox transition: [216, 101,  94,  64] -> [216, 103,  94,  64] w/ P(a|s)=1.0 and iou=0.1718781933374208 and reward=0.013728324624029564 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.014) for 2X DOWN:bbox transition: [216, 103,  94,  64] -> [216, 105,  94,  64] w/ P(a|s)=1.0 and iou=0.1859358841778697 and reward=0.014057690840448889 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.014) for 2X DOWN:bbox transition: [216, 105,  94,  64] -> [216, 107,  94,  64] w/ P(a|s)=1.0 and iou=0.20033493824576093 and reward=0.014399054067891243 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.015) for 2X DOWN:bbox transition: [216, 107,  94,  64] -> [216, 109,  94,  64] w/ P(a|s)=1.0 and iou=0.21508794236066964 and reward=0.014753004114908708 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.015) for 2X DOWN:bbox transition: [216, 109,  94,  64] -> [216, 111,  94,  64] w/ P(a|s)=1.0 and iou=0.23020810984767218 and reward=0.01512016748700254 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (0.016) for 2X DOWN:bbox transition: [216, 111,  94,  64] -> [216, 113,  94,  64] w/ P(a|s)=1.0 and iou=0.24570932000868997 and reward=0.015501210161017798 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (0.016) for 2X DOWN:bbox transition: [216, 113,  94,  64] -> [216, 115,  94,  64] w/ P(a|s)=1.0 and iou=0.2616061606160616 and reward=0.01589684060737165 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (0.016) for 2X DOWN:bbox transition: [216, 115,  94,  64] -> [216, 117,  94,  64] w/ P(a|s)=1.0 and iou=0.2779139737018052 and reward=0.016307813085743583 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (0.017) for 2X DOWN:bbox transition: [216, 117,  94,  64] -> [216, 119,  94,  64] w/ P(a|s)=1.0 and iou=0.29464890494468277 and reward=0.01673493124287756 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (0.017) for 2X DOWN:bbox transition: [216, 119,  94,  64] -> [216, 121,  94,  64] w/ P(a|s)=1.0 and iou=0.3118279569892473 and reward=0.017179052044564547 and discount=0.8953382542587164\n",
            "   |->> Assigned losses: [1.3121252e-07 1.3294392e-07 1.3473471e-07 1.3658756e-07 1.3850527e-07\n",
            " 1.4049084e-07 1.4254741e-07 1.4467835e-07 1.4688719e-07 1.4917774e-07\n",
            " 1.5155400e-07 1.5402027e-07]\n",
            "\u001b[92m>> Total frame loss: 1.703339648884139e-06\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 22 with src: [216, 121,  94,  64] and target: [259, 143,  89,  51]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0022.jpg\n",
            "|->> Beginning tracking for bbox:[216 121  94  64]\n",
            "   \u001b[33m|->> #0/t=29-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [216 123  94  64]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [5.0147534e-31 0.0000000e+00 0.0000000e+00 1.1798082e-30 1.9028796e-29\n",
            " 1.0884750e-23 5.8976977e-24 1.0000000e+00 0.0000000e+00 1.8840671e-33\n",
            " 0.0000000e+00], argmax=7\n",
            "   \u001b[33m|->> #1/t=30-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [216 125  94  64]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.2205076e-33 0.0000000e+00 0.0000000e+00 1.7182629e-21 1.7444893e-29\n",
            " 6.1054851e-25 3.6801670e-25 1.0000000e+00 0.0000000e+00 1.4390405e-28\n",
            " 3.3098645e-37], argmax=7\n",
            "   \u001b[33m|->> #2/t=31-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [216 127  94  64]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [4.2703803e-36 0.0000000e+00 0.0000000e+00 1.7152173e-14 7.4554718e-32\n",
            " 6.8851527e-22 5.0982498e-25 1.0000000e+00 0.0000000e+00 3.1376122e-32\n",
            " 1.1360832e-37], argmax=7\n",
            "   \u001b[33m|->> #3/t=32-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [216 129  94  64]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [2.0683317e-29 0.0000000e+00 0.0000000e+00 5.8757044e-12 1.4007786e-23\n",
            " 7.0413758e-18 2.2594030e-17 1.0000000e+00 1.8797759e-31 2.2219923e-31\n",
            " 4.6036732e-32], argmax=7\n",
            "   \u001b[33m|->> #4/t=33-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [216 131  94  64]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [4.2153670e-20 3.1186301e-29 1.5083907e-25 1.5974904e-09 2.9056734e-11\n",
            " 1.7136886e-11 6.0378483e-07 9.9999940e-01 7.1449412e-20 8.2464149e-23\n",
            " 5.7854187e-21], argmax=7\n",
            "   \u001b[33m|->> #5/t=34-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [216 133  94  64]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [2.2700180e-15 6.6781556e-26 5.5997217e-19 1.5257169e-07 2.0661198e-06\n",
            " 3.0436949e-13 8.4472533e-13 9.9999785e-01 5.4360378e-18 4.5054937e-13\n",
            " 3.9746761e-12], argmax=7\n",
            "   \u001b[33m|->> #6/t=35-th Action selection: 10/SCALE UP (P(a|s) = 0.02199999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [214 132  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.4286 0.1674 0.     0.     0.3821 0.     0.\n",
            " 0.0219], argmax=3\n",
            "         |->> Action Probabilities (RAW): [2.1366694e-07 2.6731755e-13 8.0282704e-11 4.2861617e-01 1.6736037e-01\n",
            " 3.9622237e-06 1.2537266e-09 3.8208610e-01 6.2439351e-12 1.1268218e-06\n",
            " 2.1932079e-02], argmax=3\n",
            "   \u001b[33m|->> #7/t=36-th Action selection: 7/2X DOWN (P(a|s) = 0.7670000195503235)\u001b[0m\n",
            "      |->> Bounding box moves to: [214 134  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 1.325e-01 1.000e-04 1.003e-01 0.000e+00\n",
            " 7.670e-01 0.000e+00 1.000e-04 0.000e+00], argmax=7\n",
            "         |->> Action Probabilities (RAW): [5.1355925e-10 4.5485779e-15 6.1503569e-10 1.3250019e-01 5.6852907e-05\n",
            " 1.0032389e-01 1.3119348e-09 7.6703840e-01 1.4917373e-10 7.2558592e-05\n",
            " 8.0562168e-06], argmax=7\n",
            "   \u001b[33m|->> #8/t=37-th Action selection: 3/2X RIGHT (P(a|s) = 0.9739999771118164)\u001b[0m\n",
            "      |->> Bounding box moves to: [218 134  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.9744 0.     0.     0.     0.0255 0.     0.\n",
            " 0.    ], argmax=3\n",
            "         |->> Action Probabilities (RAW): [2.6600568e-09 3.8440803e-13 7.7722496e-13 9.7442752e-01 5.2030850e-07\n",
            " 1.8161791e-05 1.7334859e-09 2.5544310e-02 1.1197003e-14 1.2983804e-09\n",
            " 9.3961007e-06], argmax=3\n",
            "   \u001b[33m|->> #9/t=38-th Action selection: 7/2X DOWN (P(a|s) = 0.9710000157356262)\u001b[0m\n",
            "      |->> Bounding box moves to: [218 136  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 2.810e-02 1.000e-04 2.000e-04 0.000e+00\n",
            " 9.711e-01 0.000e+00 0.000e+00 4.000e-04], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.9145052e-07 1.9546536e-11 8.1025286e-10 2.8139971e-02 1.4571687e-04\n",
            " 2.1663023e-04 8.0391906e-08 9.7109580e-01 2.2875896e-11 4.7219871e-08\n",
            " 4.0152323e-04], argmax=7\n",
            "   \u001b[33m|->> #10/t=39-th Action selection: 3/2X RIGHT (P(a|s) = 0.5630000233650208)\u001b[0m\n",
            "      |->> Bounding box moves to: [222 136  96  66]\n",
            "         |->> Action Probabilities (Rounded): [1.000e-04 0.000e+00 0.000e+00 5.629e-01 0.000e+00 4.200e-03 0.000e+00\n",
            " 4.328e-01 0.000e+00 0.000e+00 0.000e+00], argmax=3\n",
            "         |->> Action Probabilities (RAW): [9.9684075e-05 3.1990246e-09 1.2335174e-09 5.6291437e-01 1.1964329e-05\n",
            " 4.1935937e-03 7.5894314e-07 4.3277073e-01 4.6002378e-13 8.2878232e-11\n",
            " 8.8279949e-06], argmax=3\n",
            "   \u001b[33m|->> #11/t=40-th Action selection: 7/2X DOWN (P(a|s) = 0.9769999980926514)\u001b[0m\n",
            "      |->> Bounding box moves to: [222 138  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0.    0.    0.    0.    0.    0.023 0.    0.977 0.    0.    0.   ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.7929744e-12 2.6646930e-17 9.3060960e-15 7.6975488e-11 6.5605209e-11\n",
            " 2.2950025e-02 4.7767851e-10 9.7704995e-01 4.6111432e-22 5.2391942e-17\n",
            " 1.6260266e-16], argmax=7\n",
            "|->> Revisiting bbox: [222 136  96  66]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [216, 121,  94,  64] -> [222, 138,  96,  66] (Target was [259, 143,  89,  51])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.015) for 2X DOWN:bbox transition: [216, 121,  94,  64] -> [216, 123,  94,  64] w/ P(a|s)=1.0 and iou=0.2700036096739261 and reward=0.015397642718024518 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.016) for 2X DOWN:bbox transition: [216, 123,  94,  64] -> [216, 125,  94,  64] w/ P(a|s)=1.0 and iou=0.28578389572420515 and reward=0.015780286050279035 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.016) for 2X DOWN:bbox transition: [216, 125,  94,  64] -> [216, 127,  94,  64] w/ P(a|s)=1.0 and iou=0.3019612680399655 and reward=0.01617737231576033 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.017) for 2X DOWN:bbox transition: [216, 127,  94,  64] -> [216, 129,  94,  64] w/ P(a|s)=1.0 and iou=0.3185509056839475 and reward=0.016589637643982025 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.008) for 2X DOWN:bbox transition: [216, 129,  94,  64] -> [216, 131,  94,  64] w/ P(a|s)=0.9999994039535522 and iou=0.327005280362082 and reward=0.00845437467813448 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.0) for 2X DOWN:bbox transition: [216, 131,  94,  64] -> [216, 133,  94,  64] w/ P(a|s)=0.9999978542327881 and iou=0.327005280362082 and reward=0.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (-0.013) for SCALE UP:bbox transition: [216, 133,  94,  64] -> [214, 132,  96,  66] w/ P(a|s)=0.021932078525424004 and iou=0.31435823060188545 and reward=-0.012647049760196538 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (0.0) for 2X DOWN:bbox transition: [214, 132,  96,  66] -> [214, 134,  96,  66] w/ P(a|s)=0.7670384049415588 and iou=0.31435823060188545 and reward=0.0 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (0.033) for 2X RIGHT:bbox transition: [214, 134,  96,  66] -> [218, 134,  96,  66] w/ P(a|s)=0.9744275212287903 and iou=0.3475836431226766 and reward=0.03322541252079114 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (0.0) for 2X DOWN:bbox transition: [218, 134,  96,  66] -> [218, 136,  96,  66] w/ P(a|s)=0.9710958003997803 and iou=0.3475836431226766 and reward=0.0 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (0.035) for 2X RIGHT:bbox transition: [218, 136,  96,  66] -> [222, 136,  96,  66] w/ P(a|s)=0.5629143714904785 and iou=0.38253241800152554 and reward=0.034948774878848954 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (0.0) for 2X DOWN:bbox transition: [222, 136,  96,  66] -> [222, 138,  96,  66] w/ P(a|s)=0.9770499467849731 and iou=0.38253241800152554 and reward=0.0 and discount=0.8953382542587164\n",
            "   |->> Assigned losses: [ 1.5418630e-07  1.5643778e-07  1.5877055e-07  1.6118850e-07\n",
            "  8.1323087e-08  0.0000000e+00 -4.5482211e-02  0.0000000e+00\n",
            "  7.9421460e-04  0.0000000e+00  1.8162284e-02  0.0000000e+00]\n",
            "\u001b[31m>> Total frame loss: -0.026525000110268593\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 23 with src: [222, 138,  96,  66] and target: [267, 114,  86,  53]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0023.jpg\n",
            "|->> Beginning tracking for bbox:[222 138  96  66]\n",
            "   \u001b[33m|->> #0/t=41-th Action selection: 5/2X UP (P(a|s) = 0.9829999804496765)\u001b[0m\n",
            "      |->> Bounding box moves to: [222 136  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e-04 9.835e-01 0.000e+00\n",
            " 1.450e-02 0.000e+00 0.000e+00 1.800e-03], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.1527085e-09 1.0756615e-14 1.1192915e-15 4.1120111e-05 1.1217684e-04\n",
            " 9.8345876e-01 1.8638011e-15 1.4549958e-02 2.1802251e-16 4.4075649e-11\n",
            " 1.8379535e-03], argmax=5\n",
            "   \u001b[33m|->> #1/t=42-th Action selection: 5/2X UP (P(a|s) = 0.3619999885559082)\u001b[0m\n",
            "      |->> Bounding box moves to: [222 134  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.0027 0.0158 0.3617 0.     0.6179 0.     0.\n",
            " 0.002 ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [2.4514815e-10 1.4765931e-19 1.0375370e-15 2.7128228e-03 1.5768206e-02\n",
            " 3.6166570e-01 6.8086926e-13 6.1787295e-01 2.0320719e-16 3.5305573e-14\n",
            " 1.9802777e-03], argmax=7\n",
            "   \u001b[33m|->> #2/t=43-th Action selection: 5/2X UP (P(a|s) = 0.9980000257492065)\u001b[0m\n",
            "      |->> Bounding box moves to: [222 132  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.     0.9981 0.     0.0019 0.     0.\n",
            " 0.    ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.5924454e-13 2.3399691e-20 3.6287320e-16 2.9240438e-05 4.3183664e-07\n",
            " 9.9811029e-01 4.8911521e-11 1.8577086e-03 5.8809597e-18 6.7407576e-13\n",
            " 2.2082756e-06], argmax=5\n",
            "   \u001b[33m|->> #3/t=44-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [222 130  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.02787162e-11 2.01891211e-13 3.27575063e-16 3.82746339e-06\n",
            " 1.37541783e-05 9.99963045e-01 1.58561414e-10 1.82667554e-05\n",
            " 2.43141195e-20 1.06160543e-13 1.19948982e-06], argmax=5\n",
            "|->> Revisiting bbox: [222 132  96  66]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [222, 138,  96,  66] -> [222, 130,  96,  66] (Target was [267, 114,  86,  53])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.013) for 2X UP:bbox transition: [222, 138,  96,  66] -> [222, 136,  96,  66] w/ P(a|s)=0.9834587574005127 and iou=0.1697626973048427 and reward=0.01267294690654211 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.013) for 2X UP:bbox transition: [222, 136,  96,  66] -> [222, 134,  96,  66] w/ P(a|s)=0.3616656959056854 and iou=0.18271631744653133 and reward=0.012953620141688632 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.013) for 2X UP:bbox transition: [222, 134,  96,  66] -> [222, 132,  96,  66] w/ P(a|s)=0.998110294342041 and iou=0.19596003952135252 and reward=0.01324372207482119 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.014) for 2X UP:bbox transition: [222, 132,  96,  66] -> [222, 130,  96,  66] w/ P(a|s)=0.9999630451202393 and iou=0.20950371932941045 and reward=0.013543679808057929 and discount=0.970299\n",
            "   |->> Assigned losses: [2.1137937e-04 1.3042543e-02 2.4551910e-05 4.8564851e-07]\n",
            "\u001b[92m>> Total frame loss: 0.01327896025031805\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 24 with src: [222, 130,  96,  66] and target: [279,  85,  82,  51]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0024.jpg\n",
            "|->> Beginning tracking for bbox:[222 130  96  66]\n",
            "   \u001b[33m|->> #0/t=45-th Action selection: 3/2X RIGHT (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [226 130  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.], argmax=3\n",
            "         |->> Action Probabilities (RAW): [6.0931302e-26 5.0295216e-18 1.7343138e-19 9.9999285e-01 7.1565523e-06\n",
            " 1.5542280e-16 7.0902869e-22 1.9553187e-27 1.4345894e-37 1.8331921e-26\n",
            " 3.9867945e-17], argmax=3\n",
            "   \u001b[33m|->> #1/t=46-th Action selection: 3/2X RIGHT (P(a|s) = 0.9959999918937683)\u001b[0m\n",
            "      |->> Bounding box moves to: [230 130  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.996  0.0029 0.     0.     0.     0.     0.\n",
            " 0.0011], argmax=3\n",
            "         |->> Action Probabilities (RAW): [1.4879738e-12 9.0967617e-08 2.7818497e-22 9.9601269e-01 2.9106615e-03\n",
            " 1.9089632e-06 7.9241170e-07 1.5411634e-19 2.5940545e-24 4.6177748e-16\n",
            " 1.0738823e-03], argmax=3\n",
            "   \u001b[33m|->> #2/t=47-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [230 129  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [1.1585922e-22 2.7709395e-18 1.6614495e-30 3.7407431e-19 1.0000000e+00\n",
            " 4.2151255e-10 8.0222214e-28 3.4679015e-22 0.0000000e+00 3.1123634e-25\n",
            " 4.1743419e-12], argmax=4\n",
            "   \u001b[33m|->> #3/t=48-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [230 128  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [1.6393018e-22 2.3799636e-21 6.4101654e-34 2.6816066e-22 9.9999988e-01\n",
            " 9.4996111e-08 4.3830315e-31 1.3379368e-25 0.0000000e+00 1.2136907e-27\n",
            " 6.7913143e-17], argmax=4\n",
            "   \u001b[33m|->> #4/t=49-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [230 127  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [3.7273202e-15 2.6351000e-17 1.1390702e-28 1.1683572e-14 9.9998522e-01\n",
            " 1.4760924e-05 1.1455998e-25 1.2053722e-20 5.3842377e-38 5.3035919e-24\n",
            " 2.0930588e-12], argmax=4\n",
            "   \u001b[33m|->> #5/t=50-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [230 126  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [3.0661900e-11 3.6574138e-12 3.9282976e-22 2.8517810e-10 9.9999988e-01\n",
            " 1.1341584e-07 3.1563540e-23 6.7906157e-13 4.7099900e-31 1.2664747e-21\n",
            " 4.4778661e-09], argmax=4\n",
            "   \u001b[33m|->> #6/t=51-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [230 125  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [5.2739719e-13 2.4984058e-12 9.1912116e-20 1.2042529e-08 1.0000000e+00\n",
            " 8.6397745e-10 5.9048051e-26 1.2899802e-12 1.3632079e-31 5.3539018e-23\n",
            " 1.6506456e-09], argmax=4\n",
            "   \u001b[33m|->> #7/t=52-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [230 124  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 1.000e-04 9.999e-01 0.000e+00 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=4\n",
            "         |->> Action Probabilities (RAW): [4.3843929e-15 7.4411779e-12 4.2242430e-20 5.6270597e-05 9.9994373e-01\n",
            " 2.2929799e-11 6.0142977e-25 3.2629590e-13 4.9454047e-29 8.5534635e-23\n",
            " 3.0361107e-08], argmax=4\n",
            "   \u001b[33m|->> #8/t=53-th Action selection: 4/UP (P(a|s) = 0.9570000171661377)\u001b[0m\n",
            "      |->> Bounding box moves to: [230 123  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.0428 0.9572 0.     0.     0.     0.     0.\n",
            " 0.    ], argmax=4\n",
            "         |->> Action Probabilities (RAW): [1.93133008e-17 8.93605448e-13 1.64915230e-17 4.27717566e-02\n",
            " 9.57228184e-01 1.15125990e-11 2.38862586e-24 3.80529848e-15\n",
            " 1.56385165e-27 1.08997258e-18 4.84654024e-08], argmax=4\n",
            "   \u001b[33m|->> #9/t=54-th Action selection: 4/UP (P(a|s) = 0.8130000233650208)\u001b[0m\n",
            "      |->> Bounding box moves to: [230 122  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.1874 0.8126 0.     0.     0.     0.     0.\n",
            " 0.    ], argmax=4\n",
            "         |->> Action Probabilities (RAW): [7.9493370e-19 5.3285818e-15 4.1309961e-16 1.8735425e-01 8.1264466e-01\n",
            " 1.8789677e-12 6.6903451e-24 1.6032978e-14 1.5746912e-25 1.2794342e-17\n",
            " 1.0992972e-06], argmax=4\n",
            "   \u001b[33m|->> #10/t=55-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [230 121  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [5.0594807e-17 1.1513243e-18 5.0726198e-14 1.7002741e-08 9.9999559e-01\n",
            " 1.6420616e-14 4.1880795e-31 2.9559150e-15 1.3131393e-33 3.7367742e-20\n",
            " 4.3689711e-06], argmax=4\n",
            "   \u001b[33m|->> #11/t=56-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [230 120  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [7.0897217e-20 3.1032614e-23 3.0187233e-18 3.3167994e-17 1.0000000e+00\n",
            " 1.8472806e-18 1.1737993e-34 1.5488677e-20 0.0000000e+00 2.4889398e-24\n",
            " 2.3276059e-09], argmax=4\n",
            "   \u001b[33m|->> #12/t=57-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [230 119  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [2.8783256e-23 8.1669839e-26 9.5555252e-20 2.2963350e-22 1.0000000e+00\n",
            " 3.4236381e-18 1.8112579e-36 2.2814989e-23 0.0000000e+00 1.0669283e-25\n",
            " 2.0341981e-12], argmax=4\n",
            "   \u001b[33m|->> #13/t=58-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [230 118  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [3.0322143e-26 1.1433252e-24 1.2253574e-21 9.6929114e-26 1.0000000e+00\n",
            " 4.4913737e-16 1.2554848e-34 1.5652870e-25 0.0000000e+00 1.7694914e-26\n",
            " 3.3088267e-16], argmax=4\n",
            "   \u001b[33m|->> #14/t=59-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [230 117  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [1.5597707e-21 3.8100058e-16 8.8744415e-20 9.3510951e-21 1.0000000e+00\n",
            " 2.2657665e-15 4.3625280e-25 4.8834298e-19 8.0573968e-36 1.2714705e-21\n",
            " 8.8318824e-14], argmax=4\n",
            "   \u001b[33m|->> #15/t=60-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [230 116  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [4.1172650e-20 4.5665795e-15 2.7405261e-19 1.5734721e-16 1.0000000e+00\n",
            " 9.6253059e-17 5.9218652e-24 9.8311858e-17 6.1388976e-35 7.2663786e-21\n",
            " 1.4688385e-15], argmax=4\n",
            "   \u001b[33m|->> #16/t=61-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [230 115  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [1.27873586e-16 5.95258079e-15 7.86754724e-18 4.08922091e-10\n",
            " 1.00000000e+00 3.80745652e-12 1.14208520e-20 1.00522164e-13\n",
            " 1.17655817e-31 6.75495140e-20 3.01001323e-14], argmax=4\n",
            "   \u001b[33m|->> #17/t=62-th Action selection: 4/UP (P(a|s) = 0.9710000157356262)\u001b[0m\n",
            "      |->> Bounding box moves to: [230 114  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.0289 0.9711 0.     0.     0.     0.     0.\n",
            " 0.    ], argmax=4\n",
            "         |->> Action Probabilities (RAW): [6.0187175e-11 6.4353501e-12 9.0624712e-14 2.8877478e-02 9.7112232e-01\n",
            " 3.8440870e-08 1.5224658e-16 2.0912071e-07 1.3701422e-26 8.8220260e-15\n",
            " 1.7400627e-10], argmax=4\n",
            "   \u001b[33m|->> #18/t=63-th Action selection: 3/2X RIGHT (P(a|s) = 0.9879999756813049)\u001b[0m\n",
            "      |->> Bounding box moves to: [234 114  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.9882 0.0093 0.     0.     0.0026 0.     0.\n",
            " 0.    ], argmax=3\n",
            "         |->> Action Probabilities (RAW): [1.6751839e-09 1.0294941e-07 2.8332941e-08 9.8816234e-01 9.2594419e-03\n",
            " 5.1459494e-07 9.1179243e-12 2.5776033e-03 2.3805491e-20 8.7002148e-09\n",
            " 3.7008562e-08], argmax=3\n",
            "   \u001b[33m|->> #19/t=64-th Action selection: 3/2X RIGHT (P(a|s) = 0.9959999918937683)\u001b[0m\n",
            "      |->> Bounding box moves to: [238 114  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.9963 0.0036 0.     0.     0.     0.     0.\n",
            " 0.    ], argmax=3\n",
            "         |->> Action Probabilities (RAW): [1.48379956e-17 1.88422545e-17 2.17848192e-16 9.96347964e-01\n",
            " 3.64666013e-03 1.98953918e-13 7.64086235e-25 1.09791884e-10\n",
            " 3.89020510e-32 1.61783541e-17 5.36140578e-06], argmax=3\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [222, 130,  96,  66] -> [238, 114,  96,  66] (Target was [279,  85,  82,  51])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.002) for 2X RIGHT:bbox transition: [222, 130,  96,  66] -> [226, 130,  96,  66] w/ P(a|s)=0.999992847442627 and iou=0.025146198830409357 and reward=0.0023924065316929047 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.002) for 2X RIGHT:bbox transition: [226, 130,  96,  66] -> [230, 130,  96,  66] w/ P(a|s)=0.9960126876831055 and iou=0.027549824150058615 and reward=0.002403625319649258 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.005) for UP:bbox transition: [230, 130,  96,  66] -> [230, 129,  96,  66] w/ P(a|s)=1.0 and iou=0.032289724212385906 and reward=0.004739900062327291 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.005) for UP:bbox transition: [230, 129,  96,  66] -> [230, 128,  96,  66] w/ P(a|s)=0.9999998807907104 and iou=0.037073555511733386 and reward=0.00478383129934748 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.005) for UP:bbox transition: [230, 128,  96,  66] -> [230, 127,  96,  66] w/ P(a|s)=0.9999852180480957 and iou=0.04190193164933135 and reward=0.004828376137597963 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.005) for UP:bbox transition: [230, 127,  96,  66] -> [230, 126,  96,  66] w/ P(a|s)=0.9999998807907104 and iou=0.046775477707006366 and reward=0.004873546057675017 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.005) for UP:bbox transition: [230, 126,  96,  66] -> [230, 125,  96,  66] w/ P(a|s)=1.0 and iou=0.05169483051694831 and reward=0.004919352809941942 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (0.005) for UP:bbox transition: [230, 125,  96,  66] -> [230, 124,  96,  66] w/ P(a|s)=0.999943733215332 and iou=0.056660638939119955 and reward=0.004965808422171647 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (0.005) for UP:bbox transition: [230, 124,  96,  66] -> [230, 123,  96,  66] w/ P(a|s)=0.9572281837463379 and iou=0.06167356414656304 and reward=0.005012925207443085 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (0.005) for UP:bbox transition: [230, 123,  96,  66] -> [230, 122,  96,  66] w/ P(a|s)=0.8126446604728699 and iou=0.0667342799188641 and reward=0.005060715772301064 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (0.005) for UP:bbox transition: [230, 122,  96,  66] -> [230, 121,  96,  66] w/ P(a|s)=0.9999955892562866 and iou=0.07184347294405381 and reward=0.005109193025189709 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (0.005) for UP:bbox transition: [230, 121,  96,  66] -> [230, 120,  96,  66] w/ P(a|s)=1.0 and iou=0.07700184312922384 and reward=0.0051583701851700275 and discount=0.8953382542587164\n",
            "   |->> t=13 Diff-Reward (0.005) for UP:bbox transition: [230, 120,  96,  66] -> [230, 119,  96,  66] w/ P(a|s)=1.0 and iou=0.08221010392015639 and reward=0.005208260790932548 and discount=0.8863848717161292\n",
            "   |->> t=14 Diff-Reward (0.005) for UP:bbox transition: [230, 119,  96,  66] -> [230, 118,  96,  66] w/ P(a|s)=1.0 and iou=0.08746898263027296 and reward=0.005258878710116571 and discount=0.8775210229989678\n",
            "   |->> t=15 Diff-Reward (0.005) for UP:bbox transition: [230, 118,  96,  66] -> [230, 117,  96,  66] w/ P(a|s)=1.0 and iou=0.09277922077922078 and reward=0.005310238148947821 and discount=0.8687458127689782\n",
            "   |->> t=16 Diff-Reward (0.005) for UP:bbox transition: [230, 117,  96,  66] -> [230, 116,  96,  66] w/ P(a|s)=1.0 and iou=0.09814157444142828 and reward=0.005362353662207497 and discount=0.8600583546412884\n",
            "   |->> t=17 Diff-Reward (0.005) for UP:bbox transition: [230, 116,  96,  66] -> [230, 115,  96,  66] w/ P(a|s)=1.0 and iou=0.10355681460497325 and reward=0.005415240163544971 and discount=0.8514577710948755\n",
            "   |->> t=18 Diff-Reward (0.005) for UP:bbox transition: [230, 115,  96,  66] -> [230, 114,  96,  66] w/ P(a|s)=0.9711223244667053 and iou=0.10902572754112189 and reward=0.005468912936148637 and discount=0.8429431933839268\n",
            "   |->> t=19 Diff-Reward (0.01) for 2X RIGHT:bbox transition: [230, 114,  96,  66] -> [234, 114,  96,  66] w/ P(a|s)=0.9881623387336731 and iou=0.1194125159642401 and reward=0.010386788423118215 and discount=0.8345137614500875\n",
            "   |->> t=20 Diff-Reward (0.011) for 2X RIGHT:bbox transition: [234, 114,  96,  66] -> [238, 114,  96,  66] w/ P(a|s)=0.996347963809967 and iou=0.12999570262140095 and reward=0.010583186657160848 and discount=0.8261686238355866\n",
            "   |->> Assigned losses: [2.3956675e-08 9.5071318e-06 4.6519080e-08 4.6480736e-08 6.8560958e-08\n",
            " 4.6410104e-08 4.6377860e-08 2.6043577e-07 2.0220327e-04 9.5910433e-04\n",
            " 4.6269605e-08 4.6247816e-08 4.6228163e-08 4.6210666e-08 4.6195353e-08\n",
            " 4.6182237e-08 4.6171333e-08 1.3508560e-04 1.0322003e-04 3.1990017e-05]\n",
            "\u001b[92m>> Total frame loss: 0.0014419725630432367\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 25 with src: [238, 114,  96,  66] and target: [289,  66,  83,  52]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0025.jpg\n",
            "|->> Beginning tracking for bbox:[238 114  96  66]\n",
            "   \u001b[33m|->> #0/t=65-th Action selection: 4/UP (P(a|s) = 0.5989999771118164)\u001b[0m\n",
            "      |->> Bounding box moves to: [238 113  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 1.053e-01 0.000e+00 2.872e-01 5.986e-01 8.800e-03 0.000e+00\n",
            " 1.000e-04 0.000e+00 0.000e+00 0.000e+00], argmax=4\n",
            "         |->> Action Probabilities (RAW): [5.04415993e-08 1.05324335e-01 8.93704851e-07 2.87178189e-01\n",
            " 5.98560989e-01 8.80067609e-03 4.59779329e-07 1.27633088e-04\n",
            " 3.72053558e-16 6.76976515e-06 9.79627117e-08], argmax=4\n",
            "   \u001b[33m|->> #1/t=66-th Action selection: 3/2X RIGHT (P(a|s) = 0.2759999930858612)\u001b[0m\n",
            "      |->> Bounding box moves to: [242 113  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.0208 0.     0.2761 0.5167 0.1863 0.     0.     0.     0.\n",
            " 0.    ], argmax=4\n",
            "         |->> Action Probabilities (RAW): [6.0687846e-08 2.0833241e-02 9.5021244e-09 2.7611023e-01 5.1671726e-01\n",
            " 1.8633445e-01 1.1360490e-06 8.7368545e-07 1.1772032e-18 6.2673877e-07\n",
            " 2.1324377e-06], argmax=4\n",
            "   \u001b[33m|->> #2/t=67-th Action selection: 5/2X UP (P(a|s) = 0.9929999709129333)\u001b[0m\n",
            "      |->> Bounding box moves to: [242 111  96  66]\n",
            "         |->> Action Probabilities (Rounded): [1.000e-04 3.800e-03 0.000e+00 1.900e-03 2.000e-04 9.929e-01 2.000e-04\n",
            " 6.000e-04 0.000e+00 2.000e-04 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.4156719e-04 3.7887171e-03 1.2683654e-05 1.9205137e-03 2.1074187e-04\n",
            " 9.9287635e-01 1.6264444e-04 6.1746559e-04 3.5626146e-10 2.3040085e-04\n",
            " 3.8813130e-05], argmax=5\n",
            "   \u001b[33m|->> #3/t=68-th Action selection: 5/2X UP (P(a|s) = 0.7229999899864197)\u001b[0m\n",
            "      |->> Bounding box moves to: [242 109  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0.0083 0.0285 0.0032 0.0955 0.1025 0.7234 0.0258 0.001  0.     0.0058\n",
            " 0.006 ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [8.3266171e-03 2.8490929e-02 3.1944355e-03 9.5497847e-02 1.0246755e-01\n",
            " 7.2340047e-01 2.5838446e-02 9.7459060e-04 2.1935659e-07 5.7810633e-03\n",
            " 6.0279197e-03], argmax=5\n",
            "   \u001b[33m|->> #4/t=69-th Action selection: 4/UP (P(a|s) = 0.32199999690055847)\u001b[0m\n",
            "      |->> Bounding box moves to: [242 108  96  66]\n",
            "         |->> Action Probabilities (Rounded): [3.400e-03 8.200e-03 6.000e-04 3.000e-04 3.220e-01 5.955e-01 8.500e-03\n",
            " 3.000e-04 0.000e+00 1.090e-02 5.030e-02], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.4133974e-03 8.2030194e-03 6.2442577e-04 2.5046253e-04 3.2199165e-01\n",
            " 5.9553903e-01 8.5305199e-03 3.2005666e-04 8.4118589e-08 1.0867225e-02\n",
            " 5.0260209e-02], argmax=5\n",
            "   \u001b[33m|->> #5/t=70-th Action selection: 4/UP (P(a|s) = 0.2840000092983246)\u001b[0m\n",
            "      |->> Bounding box moves to: [242 107  96  66]\n",
            "         |->> Action Probabilities (Rounded): [3.600e-03 5.400e-03 0.000e+00 0.000e+00 2.840e-01 6.968e-01 9.700e-03\n",
            " 0.000e+00 0.000e+00 0.000e+00 5.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.6391662e-03 5.3766593e-03 3.8695666e-06 3.6171286e-06 2.8397575e-01\n",
            " 6.9683337e-01 9.6799247e-03 1.5809714e-07 7.5158817e-11 1.4737132e-05\n",
            " 4.7281646e-04], argmax=5\n",
            "   \u001b[33m|->> #6/t=71-th Action selection: 5/2X UP (P(a|s) = 0.8209999799728394)\u001b[0m\n",
            "      |->> Bounding box moves to: [242 105  96  66]\n",
            "         |->> Action Probabilities (Rounded): [2.000e-04 1.000e-04 0.000e+00 0.000e+00 1.780e-01 8.209e-01 8.000e-04\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.5915126e-04 1.2022787e-04 4.1830109e-10 1.5176407e-07 1.7799762e-01\n",
            " 8.2088989e-01 8.2594814e-04 6.6615919e-12 8.8994743e-14 1.1404840e-08\n",
            " 6.9118628e-06], argmax=5\n",
            "   \u001b[33m|->> #7/t=72-th Action selection: 4/UP (P(a|s) = 0.9160000085830688)\u001b[0m\n",
            "      |->> Bounding box moves to: [242 104  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.9165 0.0835 0.     0.     0.     0.\n",
            " 0.    ], argmax=4\n",
            "         |->> Action Probabilities (RAW): [9.2145193e-08 4.1636858e-07 2.1333334e-19 2.0321022e-05 9.1648775e-01\n",
            " 8.3488032e-02 2.4985784e-06 1.8556380e-18 2.5081796e-22 4.4111185e-15\n",
            " 7.4189353e-07], argmax=4\n",
            "   \u001b[33m|->> #8/t=73-th Action selection: 4/UP (P(a|s) = 0.9990000128746033)\u001b[0m\n",
            "      |->> Bounding box moves to: [242 103  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 6.000e-04 9.992e-01 1.000e-04 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=4\n",
            "         |->> Action Probabilities (RAW): [3.7917922e-09 3.4133180e-07 7.0732898e-25 6.4731005e-04 9.9923122e-01\n",
            " 1.2075717e-04 2.8468481e-08 1.0915843e-20 5.7335218e-26 1.1320435e-16\n",
            " 3.1164865e-07], argmax=4\n",
            "   \u001b[33m|->> #9/t=74-th Action selection: 4/UP (P(a|s) = 0.9980000257492065)\u001b[0m\n",
            "      |->> Bounding box moves to: [242 102  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.0017 0.9983 0.     0.     0.     0.     0.\n",
            " 0.    ], argmax=4\n",
            "         |->> Action Probabilities (RAW): [3.7224144e-13 5.2534052e-08 6.6402157e-31 1.6705546e-03 9.9832898e-01\n",
            " 3.4016705e-07 2.3911007e-08 4.1503354e-23 1.5048368e-33 6.9361065e-20\n",
            " 1.5457898e-09], argmax=4\n",
            "   \u001b[33m|->> #10/t=75-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [242 101  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [6.8038848e-17 1.3545476e-08 2.0679289e-35 8.5918973e-06 9.9999142e-01\n",
            " 4.0993139e-10 4.1236905e-12 3.2482750e-27 0.0000000e+00 6.7881574e-22\n",
            " 2.3031710e-11], argmax=4\n",
            "   \u001b[33m|->> #11/t=76-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [242 100  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 5.000e-04 9.995e-01 0.000e+00 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=4\n",
            "         |->> Action Probabilities (RAW): [2.4736075e-15 6.8180483e-10 2.3468941e-36 4.5014004e-04 9.9954981e-01\n",
            " 5.0679804e-14 2.8781204e-13 4.9658083e-32 0.0000000e+00 9.1564712e-25\n",
            " 3.6998735e-10], argmax=4\n",
            "   \u001b[33m|->> #12/t=77-th Action selection: 4/UP (P(a|s) = 0.9739999771118164)\u001b[0m\n",
            "      |->> Bounding box moves to: [242  99  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.0263 0.9737 0.     0.     0.     0.     0.\n",
            " 0.    ], argmax=4\n",
            "         |->> Action Probabilities (RAW): [5.4230302e-14 1.0849375e-13 2.8205209e-38 2.6335197e-02 9.7366476e-01\n",
            " 1.8115913e-18 2.4148473e-17 7.7964220e-37 0.0000000e+00 3.1689777e-27\n",
            " 8.4731144e-10], argmax=4\n",
            "   \u001b[33m|->> #13/t=78-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [242  98  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 2.000e-04 9.998e-01 0.000e+00 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=4\n",
            "         |->> Action Probabilities (RAW): [5.3931377e-16 9.0350410e-17 0.0000000e+00 1.5576862e-04 9.9984419e-01\n",
            " 3.1753683e-21 2.6913987e-27 0.0000000e+00 0.0000000e+00 8.4277585e-31\n",
            " 2.1140660e-13], argmax=4\n",
            "   \u001b[33m|->> #14/t=79-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [242  97  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [9.0744710e-21 2.7629124e-16 0.0000000e+00 3.3344950e-05 9.9996662e-01\n",
            " 1.9133435e-19 2.4473960e-37 0.0000000e+00 0.0000000e+00 2.7935092e-38\n",
            " 9.9382071e-17], argmax=4\n",
            "   \u001b[33m|->> #15/t=80-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [242  96  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [4.1635928e-26 2.0023693e-17 0.0000000e+00 3.3765891e-14 1.0000000e+00\n",
            " 5.7546642e-24 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            " 3.8582673e-18], argmax=4\n",
            "   \u001b[33m|->> #16/t=81-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [242  95  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [6.7609357e-34 2.9331987e-19 0.0000000e+00 2.0741512e-25 1.0000000e+00\n",
            " 8.8312036e-30 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            " 5.5593311e-21], argmax=4\n",
            "   \u001b[33m|->> #17/t=82-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [242  94  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [5.6156588e-38 5.7698048e-18 0.0000000e+00 2.0291246e-28 1.0000000e+00\n",
            " 5.0761839e-33 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            " 3.6804704e-28], argmax=4\n",
            "   \u001b[33m|->> #18/t=83-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [242  93  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.00000000e+00 7.57450610e-22 0.00000000e+00 3.19999501e-33\n",
            " 1.00000000e+00 3.25024946e-34 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 1.42734585e-36], argmax=4\n",
            "   \u001b[33m|->> #19/t=84-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [242  92  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.000000e+00 1.961386e-25 0.000000e+00 0.000000e+00 1.000000e+00\n",
            " 1.970113e-34 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
            " 0.000000e+00], argmax=4\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [238, 114,  96,  66] -> [242,  92,  96,  66] (Target was [289,  66,  83,  52])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.004) for UP:bbox transition: [238, 114,  96,  66] -> [238, 113,  96,  66] w/ P(a|s)=0.5985609889030457 and iou=0.02157859403471756 and reward=0.004389900375435667 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.002) for 2X RIGHT:bbox transition: [238, 113,  96,  66] -> [242, 113,  96,  66] w/ P(a|s)=0.2761102318763733 and iou=0.023541846833861825 and reward=0.0019632527991442633 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.01) for 2X UP:bbox transition: [242, 113,  96,  66] -> [242, 111,  96,  66] w/ P(a|s)=0.9928763508796692 and iou=0.03327189834125521 and reward=0.009730051507393388 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.01) for 2X UP:bbox transition: [242, 111,  96,  66] -> [242, 109,  96,  66] w/ P(a|s)=0.7234004735946655 and iou=0.04318871804916267 and reward=0.009916819707907455 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.005) for UP:bbox transition: [242, 109,  96,  66] -> [242, 108,  96,  66] w/ P(a|s)=0.3219916522502899 and iou=0.048218854556189725 and reward=0.005030136507027057 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.005) for UP:bbox transition: [242, 108,  96,  66] -> [242, 107,  96,  66] w/ P(a|s)=0.283975750207901 and iou=0.05329773558785721 and reward=0.0050788810316674884 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.01) for 2X UP:bbox transition: [242, 107,  96,  66] -> [242, 105,  96,  66] w/ P(a|s)=0.8208898901939392 and iou=0.06360459311033449 and reward=0.01030685752247728 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (0.005) for UP:bbox transition: [242, 105,  96,  66] -> [242, 104,  96,  66] w/ P(a|s)=0.9164877533912659 and iou=0.06883403572145294 and reward=0.005229442611118448 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (0.005) for UP:bbox transition: [242, 104,  96,  66] -> [242, 103,  96,  66] w/ P(a|s)=0.999231219291687 and iou=0.07411515579308259 and reward=0.005281120071629647 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (0.005) for UP:bbox transition: [242, 103,  96,  66] -> [242, 102,  96,  66] w/ P(a|s)=0.9983289837837219 and iou=0.07944872314552087 and reward=0.005333567352438284 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (0.005) for UP:bbox transition: [242, 102,  96,  66] -> [242, 101,  96,  66] w/ P(a|s)=0.9999914169311523 and iou=0.08483552296567878 and reward=0.0053867998201579115 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (0.005) for UP:bbox transition: [242, 101,  96,  66] -> [242, 100,  96,  66] w/ P(a|s)=0.9995498061180115 and iou=0.0902763561924258 and reward=0.005440833226747016 and discount=0.8953382542587164\n",
            "   |->> t=13 Diff-Reward (0.005) for UP:bbox transition: [242, 100,  96,  66] -> [242,  99,  96,  66] w/ P(a|s)=0.9736647605895996 and iou=0.09577203991358914 and reward=0.005495683721163339 and discount=0.8863848717161292\n",
            "   |->> t=14 Diff-Reward (0.006) for UP:bbox transition: [242,  99,  96,  66] -> [242,  98,  96,  66] w/ P(a|s)=0.9998441934585571 and iou=0.10132340777502068 and reward=0.005551367861431539 and discount=0.8775210229989678\n",
            "   |->> t=15 Diff-Reward (0.006) for UP:bbox transition: [242,  98,  96,  66] -> [242,  97,  96,  66] w/ P(a|s)=0.9999666213989258 and iou=0.10693131040216149 and reward=0.0056079026271408094 and discount=0.8687458127689782\n",
            "   |->> t=16 Diff-Reward (0.006) for UP:bbox transition: [242,  97,  96,  66] -> [242,  96,  96,  66] w/ P(a|s)=1.0 and iou=0.11259661583455191 and reward=0.0056653054323904245 and discount=0.8600583546412884\n",
            "   |->> t=17 Diff-Reward (0.006) for UP:bbox transition: [242,  96,  96,  66] -> [242,  95,  96,  66] w/ P(a|s)=1.0 and iou=0.11832020997375328 and reward=0.005723594139201371 and discount=0.8514577710948755\n",
            "   |->> t=18 Diff-Reward (0.006) for UP:bbox transition: [242,  95,  96,  66] -> [242,  94,  96,  66] w/ P(a|s)=1.0 and iou=0.12410299704516674 and reward=0.005782787071413456 and discount=0.8429431933839268\n",
            "   |->> t=19 Diff-Reward (0.006) for UP:bbox transition: [242,  94,  96,  66] -> [242,  93,  96,  66] w/ P(a|s)=1.0 and iou=0.1299459000742548 and reward=0.005842903029088062 and discount=0.8345137614500875\n",
            "   |->> t=20 Diff-Reward (0.006) for UP:bbox transition: [242,  93,  96,  66] -> [242,  92,  96,  66] w/ P(a|s)=1.0 and iou=0.13584986137769248 and reward=0.005903961303437677 and discount=0.8261686238355866\n",
            "   |->> Assigned losses: [2.2530148e-03 2.5013522e-03 6.8177258e-05 3.1156205e-03 5.4756859e-03\n",
            " 6.0802810e-03 1.9151837e-03 4.2506069e-04 3.7478055e-06 8.1485123e-06\n",
            " 4.8783654e-08 2.1935618e-06 1.3000610e-04 7.5906166e-07 1.6261798e-07\n",
            " 4.8791350e-08 4.8800413e-08 4.8812051e-08 4.8826294e-08 4.8843159e-08]\n",
            "\u001b[92m>> Total frame loss: 0.021979687735438347\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 26 with src: [242,  92,  96,  66] and target: [285,  48,  84,  49]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0026.jpg\n",
            "|->> Beginning tracking for bbox:[242  92  96  66]\n",
            "   \u001b[33m|->> #0/t=85-th Action selection: 1/2X LEFT (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [238  92  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.], argmax=1\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 1.0000000e+00 4.5435630e-27 0.0000000e+00 1.6192071e-09\n",
            " 3.7456171e-09 4.3425351e-26 4.2048155e-36 0.0000000e+00 8.1179885e-29\n",
            " 0.0000000e+00], argmax=1\n",
            "   \u001b[33m|->> #1/t=86-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [238  90  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 3.000e-04 0.000e+00 0.000e+00 0.000e+00 9.997e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [5.9331327e-22 2.5119245e-04 2.6088629e-18 9.8387971e-11 2.4386480e-07\n",
            " 9.9974853e-01 5.1909089e-21 1.4790765e-13 0.0000000e+00 1.6394535e-21\n",
            " 1.0232002e-28], argmax=5\n",
            "   \u001b[33m|->> #2/t=87-th Action selection: 5/2X UP (P(a|s) = 0.9800000190734863)\u001b[0m\n",
            "      |->> Bounding box moves to: [238  88  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.0205 0.     0.     0.     0.9795 0.     0.     0.     0.\n",
            " 0.    ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.2075337e-20 2.0473236e-02 5.5599670e-15 6.5524637e-16 5.5029022e-07\n",
            " 9.7952616e-01 2.4474676e-24 2.8092697e-13 2.5296179e-35 3.5177637e-21\n",
            " 5.6951611e-23], argmax=5\n",
            "   \u001b[33m|->> #3/t=88-th Action selection: 5/2X UP (P(a|s) = 0.9950000047683716)\u001b[0m\n",
            "      |->> Bounding box moves to: [238  86  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.0047 0.     0.     0.     0.9953 0.     0.     0.     0.\n",
            " 0.    ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.5156157e-28 4.6623447e-03 8.1208832e-25 8.3719844e-19 5.2242349e-08\n",
            " 9.9533761e-01 2.0438326e-33 6.8138903e-13 0.0000000e+00 1.7982956e-34\n",
            " 1.0615518e-27], argmax=5\n",
            "   \u001b[33m|->> #4/t=89-th Action selection: 5/2X UP (P(a|s) = 0.9879999756813049)\u001b[0m\n",
            "      |->> Bounding box moves to: [238  84  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 1.130e-02 0.000e+00 0.000e+00 4.000e-04 9.883e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 1.1255424e-02 4.5423229e-29 2.4239748e-16 4.4459669e-04\n",
            " 9.8828822e-01 0.0000000e+00 1.1727948e-05 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00], argmax=5\n",
            "   \u001b[33m|->> #5/t=90-th Action selection: 1/2X LEFT (P(a|s) = 0.9800000190734863)\u001b[0m\n",
            "      |->> Bounding box moves to: [234  84  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 9.801e-01 0.000e+00 0.000e+00 6.000e-04 6.000e-03 0.000e+00\n",
            " 1.330e-02 0.000e+00 0.000e+00 0.000e+00], argmax=1\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 9.8011106e-01 6.5277241e-32 1.1735824e-20 6.2986091e-04\n",
            " 5.9877057e-03 0.0000000e+00 1.3271340e-02 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00], argmax=1\n",
            "|->> Revisiting bbox: [238  84  96  66]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [242,  92,  96,  66] -> [234,  84,  96,  66] (Target was [285,  48,  84,  49])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.002) for 2X LEFT:bbox transition: [242,  92,  96,  66] -> [238,  92,  96,  66] w/ P(a|s)=1.0 and iou=0.02400313510336044 and reward=-0.0020104115737770885 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.01) for 2X UP:bbox transition: [238,  92,  96,  66] -> [238,  90,  96,  66] w/ P(a|s)=0.9997485280036926 and iou=0.033930161242457214 and reward=0.009927026139096774 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.01) for 2X UP:bbox transition: [238,  90,  96,  66] -> [238,  88,  96,  66] w/ P(a|s)=0.979526162147522 and iou=0.044051543302367394 and reward=0.01012138205991018 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.01) for 2X UP:bbox transition: [238,  88,  96,  66] -> [238,  86,  96,  66] w/ P(a|s)=0.9953376054763794 and iou=0.05437304549581358 and reward=0.010321502193446186 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.011) for 2X UP:bbox transition: [238,  86,  96,  66] -> [238,  84,  96,  66] w/ P(a|s)=0.9882882237434387 and iou=0.06490066225165562 and reward=0.010527616755842045 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-0.006) for 2X LEFT:bbox transition: [238,  84,  96,  66] -> [234,  84,  96,  66] w/ P(a|s)=0.9801110625267029 and iou=0.05928853754940711 and reward=-0.005612124702248512 and discount=0.9509900498999999\n",
            "   |->> Assigned losses: [-2.01315178e-08  2.47171624e-06  2.05207703e-04  4.68028120e-05\n",
            "  1.19137716e-04 -1.07218541e-04]\n",
            "\u001b[92m>> Total frame loss: 0.00026638127746991813\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 27 with src: [234,  84,  96,  66] and target: [269,  32,  89,  52]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0027.jpg\n",
            "|->> Beginning tracking for bbox:[234  84  96  66]\n",
            "   \u001b[33m|->> #0/t=91-th Action selection: 1/2X LEFT (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [230  84  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 9.998e-01 0.000e+00 0.000e+00 2.000e-04 0.000e+00 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=1\n",
            "         |->> Action Probabilities (RAW): [1.1586458e-30 9.9976808e-01 9.8237836e-22 8.4738633e-15 2.3191847e-04\n",
            " 2.3538591e-09 5.7544062e-16 7.7339436e-26 9.9254833e-38 3.1165256e-24\n",
            " 2.7305515e-27], argmax=1\n",
            "   \u001b[33m|->> #1/t=92-th Action selection: 1/2X LEFT (P(a|s) = 0.9769999980926514)\u001b[0m\n",
            "      |->> Bounding box moves to: [226  84  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.9771 0.     0.     0.0229 0.     0.     0.     0.     0.\n",
            " 0.    ], argmax=1\n",
            "         |->> Action Probabilities (RAW): [5.7612752e-35 9.7707886e-01 1.4107947e-28 1.2641652e-28 2.2921087e-02\n",
            " 3.1937816e-10 8.6678966e-18 9.4582903e-32 0.0000000e+00 7.7624141e-26\n",
            " 0.0000000e+00], argmax=1\n",
            "   \u001b[33m|->> #2/t=93-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [226  83  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [4.8397279e-23 3.0204084e-05 1.6593689e-19 1.1939337e-16 9.9996972e-01\n",
            " 1.2643483e-07 2.0676841e-15 3.3272009e-19 3.5548200e-35 4.0241694e-16\n",
            " 5.3882724e-27], argmax=4\n",
            "   \u001b[33m|->> #3/t=94-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [226  82  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [2.6724111e-33 1.5886394e-10 3.5224600e-29 6.1239328e-26 1.0000000e+00\n",
            " 3.6079121e-14 4.0065501e-25 4.8148155e-29 0.0000000e+00 2.7556464e-24\n",
            " 0.0000000e+00], argmax=4\n",
            "   \u001b[33m|->> #4/t=95-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [226  81  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 1.6755594e-16 2.5919241e-37 1.5155099e-31 1.0000000e+00\n",
            " 2.6995412e-19 5.3336128e-33 4.6530795e-37 0.0000000e+00 4.2090010e-30\n",
            " 0.0000000e+00], argmax=4\n",
            "   \u001b[33m|->> #5/t=96-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [226  80  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 2.1381879e-18 0.0000000e+00 5.0982799e-36 1.0000000e+00\n",
            " 2.3144424e-22 5.5928086e-37 0.0000000e+00 0.0000000e+00 1.8008290e-34\n",
            " 0.0000000e+00], argmax=4\n",
            "   \u001b[33m|->> #6/t=97-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [226  79  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 4.7386064e-17 0.0000000e+00 0.0000000e+00 1.0000000e+00\n",
            " 6.3633169e-26 0.0000000e+00 0.0000000e+00 0.0000000e+00 7.5614245e-38\n",
            " 0.0000000e+00], argmax=4\n",
            "   \u001b[33m|->> #7/t=98-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [226  78  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.000000e+00 3.700648e-11 0.000000e+00 0.000000e+00 1.000000e+00\n",
            " 2.684540e-25 9.267814e-37 0.000000e+00 0.000000e+00 0.000000e+00\n",
            " 0.000000e+00], argmax=4\n",
            "   \u001b[33m|->> #8/t=99-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [226  77  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 2.5453423e-07 0.0000000e+00 0.0000000e+00 9.9999976e-01\n",
            " 2.6899314e-25 3.0774146e-34 0.0000000e+00 0.0000000e+00 2.5287431e-38\n",
            " 0.0000000e+00], argmax=4\n",
            "   \u001b[33m|->> #9/t=100-th Action selection: 1/2X LEFT (P(a|s) = 0.9729999899864197)\u001b[0m\n",
            "      |->> Bounding box moves to: [222  77  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.9732 0.     0.     0.0268 0.     0.     0.     0.     0.\n",
            " 0.    ], argmax=1\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 9.7316551e-01 0.0000000e+00 0.0000000e+00 2.6834494e-02\n",
            " 6.7094191e-23 1.0083166e-32 2.7294151e-37 0.0000000e+00 2.0542926e-35\n",
            " 0.0000000e+00], argmax=1\n",
            "   \u001b[33m|->> #10/t=101-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [222  76  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [2.0211079e-26 5.8809971e-12 4.5469289e-26 2.7521131e-19 1.0000000e+00\n",
            " 2.3001898e-17 5.5999086e-25 6.8916522e-27 0.0000000e+00 4.6800869e-21\n",
            " 3.8124376e-29], argmax=4\n",
            "   \u001b[33m|->> #11/t=102-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [222  75  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [1.4629803e-27 6.8386952e-13 5.3349920e-27 2.5071923e-21 1.0000000e+00\n",
            " 6.6851328e-17 5.4542267e-25 5.2591200e-26 0.0000000e+00 4.5043611e-24\n",
            " 1.7045503e-32], argmax=4\n",
            "   \u001b[33m|->> #12/t=103-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [222  74  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [7.3323365e-30 1.8220674e-15 8.8730376e-31 4.4915053e-26 1.0000000e+00\n",
            " 2.9241189e-17 1.1837675e-28 1.3499056e-28 0.0000000e+00 2.2777018e-28\n",
            " 0.0000000e+00], argmax=4\n",
            "   \u001b[33m|->> #13/t=104-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [222  73  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 6.5867253e-21 0.0000000e+00 0.0000000e+00 1.0000000e+00\n",
            " 2.9674174e-23 0.0000000e+00 1.1637525e-37 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00], argmax=4\n",
            "   \u001b[33m|->> #14/t=105-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [222  72  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 6.1158705e-21 0.0000000e+00 0.0000000e+00 1.0000000e+00\n",
            " 2.8383734e-24 0.0000000e+00 4.5802761e-37 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00], argmax=4\n",
            "   \u001b[33m|->> #15/t=106-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [222  71  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [3.6666903e-38 4.9493735e-25 0.0000000e+00 0.0000000e+00 1.0000000e+00\n",
            " 1.6458068e-21 0.0000000e+00 5.5786529e-32 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00], argmax=4\n",
            "   \u001b[33m|->> #16/t=107-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [222  70  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [1.2124914e-36 5.8471307e-34 0.0000000e+00 0.0000000e+00 1.0000000e+00\n",
            " 1.5218689e-26 0.0000000e+00 2.2430035e-37 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00], argmax=4\n",
            "   \u001b[33m|->> #17/t=108-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [222  69  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [2.8728562e-35 3.3845501e-34 0.0000000e+00 0.0000000e+00 1.0000000e+00\n",
            " 1.3970205e-25 0.0000000e+00 4.7971020e-38 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00], argmax=4\n",
            "   \u001b[33m|->> #18/t=109-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [222  68  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [3.4870205e-35 9.9208502e-32 0.0000000e+00 0.0000000e+00 1.0000000e+00\n",
            " 9.0620551e-26 0.0000000e+00 2.8826924e-35 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00], argmax=4\n",
            "   \u001b[33m|->> #19/t=110-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [222  67  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [5.6599365e-32 1.4177837e-29 0.0000000e+00 0.0000000e+00 1.0000000e+00\n",
            " 6.0115193e-24 0.0000000e+00 3.2552906e-32 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00], argmax=4\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [234,  84,  96,  66] -> [222,  67,  96,  66] (Target was [269,  32,  89,  52])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X LEFT:bbox transition: [234,  84,  96,  66] -> [230,  84,  96,  66] w/ P(a|s)=0.999768078327179 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for 2X LEFT:bbox transition: [230,  84,  96,  66] -> [226,  84,  96,  66] w/ P(a|s)=0.9770788550376892 and iou=0.0 and reward=0.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.005) for UP:bbox transition: [226,  84,  96,  66] -> [226,  83,  96,  66] w/ P(a|s)=0.9999697208404541 and iou=0.004857483273760425 and reward=0.004857483273760425 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.005) for UP:bbox transition: [226,  83,  96,  66] -> [226,  82,  96,  66] w/ P(a|s)=1.0 and iou=0.009762387179959477 and reward=0.004904903906199052 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.005) for UP:bbox transition: [226,  82,  96,  66] -> [226,  81,  96,  66] w/ P(a|s)=1.0 and iou=0.014715409532623786 and reward=0.004953022352664309 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.005) for UP:bbox transition: [226,  81,  96,  66] -> [226,  80,  96,  66] w/ P(a|s)=1.0 and iou=0.019717261904761904 and reward=0.005001852372138118 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.005) for UP:bbox transition: [226,  80,  96,  66] -> [226,  79,  96,  66] w/ P(a|s)=1.0 and iou=0.024768669969155995 and reward=0.005051408064394091 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (0.005) for UP:bbox transition: [226,  79,  96,  66] -> [226,  78,  96,  66] w/ P(a|s)=1.0 and iou=0.02987037384933308 and reward=0.0051017038801770866 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (0.005) for UP:bbox transition: [226,  78,  96,  66] -> [226,  77,  96,  66] w/ P(a|s)=0.9999997615814209 and iou=0.035023128481072405 and reward=0.005152754631739323 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (-0.003) for 2X LEFT:bbox transition: [226,  77,  96,  66] -> [222,  77,  96,  66] w/ P(a|s)=0.9731655120849609 and iou=0.032294510874682235 and reward=-0.00272861760639017 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (0.005) for UP:bbox transition: [222,  77,  96,  66] -> [222,  76,  96,  66] w/ P(a|s)=1.0 and iou=0.037079076806659096 and reward=0.004784565931976861 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (0.005) for UP:bbox transition: [222,  76,  96,  66] -> [222,  75,  96,  66] w/ P(a|s)=1.0 and iou=0.04190820108334125 and reward=0.0048291242766821535 and discount=0.8953382542587164\n",
            "   |->> t=13 Diff-Reward (0.005) for UP:bbox transition: [222,  75,  96,  66] -> [222,  74,  96,  66] w/ P(a|s)=1.0 and iou=0.04678250907007829 and reward=0.004874307986737041 and discount=0.8863848717161292\n",
            "   |->> t=14 Diff-Reward (0.005) for UP:bbox transition: [222,  74,  96,  66] -> [222,  73,  96,  66] w/ P(a|s)=1.0 and iou=0.05170263788968825 and reward=0.004920128819609959 and discount=0.8775210229989678\n",
            "   |->> t=15 Diff-Reward (0.005) for UP:bbox transition: [222,  73,  96,  66] -> [222,  72,  96,  66] w/ P(a|s)=1.0 and iou=0.0566692367000771 and reward=0.004966598810388849 and discount=0.8687458127689782\n",
            "   |->> t=16 Diff-Reward (0.005) for UP:bbox transition: [222,  72,  96,  66] -> [222,  71,  96,  66] w/ P(a|s)=1.0 and iou=0.06168296697976179 and reward=0.005013730279684693 and discount=0.8600583546412884\n",
            "   |->> t=17 Diff-Reward (0.005) for UP:bbox transition: [222,  71,  96,  66] -> [222,  70,  96,  66] w/ P(a|s)=1.0 and iou=0.06674450282156061 and reward=0.005061535841798817 and discount=0.8514577710948755\n",
            "   |->> t=18 Diff-Reward (0.005) for UP:bbox transition: [222,  70,  96,  66] -> [222,  69,  96,  66] w/ P(a|s)=1.0 and iou=0.07185453123472481 and reward=0.0051100284131642 and discount=0.8429431933839268\n",
            "   |->> t=19 Diff-Reward (0.005) for UP:bbox transition: [222,  69,  96,  66] -> [222,  68,  96,  66] w/ P(a|s)=1.0 and iou=0.07701375245579568 and reward=0.0051592212210708754 and discount=0.8345137614500875\n",
            "   |->> t=20 Diff-Reward (0.005) for UP:bbox transition: [222,  68,  96,  66] -> [222,  67,  96,  66] w/ P(a|s)=1.0 and iou=0.08222288026848287 and reward=0.005209127812687189 and discount=0.8261686238355866\n",
            "   |->> Assigned losses: [ 0.0000000e+00  0.0000000e+00  1.4415579e-07  4.7657103e-08\n",
            "  4.7643390e-08  4.7631950e-08  4.7622830e-08  4.7616030e-08\n",
            "  4.7611579e-08 -6.7802546e-05  4.3329734e-08  4.3295930e-08\n",
            "  4.3264020e-08  4.3234014e-08  4.3205930e-08  4.3179785e-08\n",
            "  4.3155584e-08  4.3133344e-08  4.3113094e-08  4.3094840e-08]\n",
            "\u001b[31m>> Total frame loss: -6.6940592660103e-05\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 28 with src: [222,  67,  96,  66] and target: [246,  26,  86,  54]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0028.jpg\n",
            "|->> Beginning tracking for bbox:[222  67  96  66]\n",
            "   \u001b[33m|->> #0/t=111-th Action selection: 1/2X LEFT (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [218  67  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.], argmax=1\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 1.0000000e+00 1.9045078e-20 3.9300427e-34 8.0831316e-29\n",
            " 1.6224218e-17 0.0000000e+00 5.3866003e-37 0.0000000e+00 1.3636998e-34\n",
            " 0.0000000e+00], argmax=1\n",
            "   \u001b[33m|->> #1/t=112-th Action selection: 1/2X LEFT (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [214  67  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.], argmax=1\n",
            "         |->> Action Probabilities (RAW): [4.2871911e-29 1.0000000e+00 3.9132888e-11 1.4555225e-10 5.9438362e-18\n",
            " 1.3107900e-11 1.2409429e-27 4.3440494e-23 0.0000000e+00 1.6956682e-21\n",
            " 1.2501023e-36], argmax=1\n",
            "   \u001b[33m|->> #2/t=113-th Action selection: 5/2X UP (P(a|s) = 0.8820000290870667)\u001b[0m\n",
            "      |->> Bounding box moves to: [214  65  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.1164 0.     0.     0.0017 0.8819 0.     0.     0.     0.\n",
            " 0.    ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.90460559e-19 1.16420396e-01 2.06023462e-11 7.83502985e-11\n",
            " 1.72430056e-03 8.81855309e-01 1.08530849e-12 2.65930559e-11\n",
            " 1.74328402e-33 4.62168498e-11 3.56908284e-17], argmax=5\n",
            "   \u001b[33m|->> #3/t=114-th Action selection: 1/2X LEFT (P(a|s) = 0.9879999756813049)\u001b[0m\n",
            "      |->> Bounding box moves to: [210  65  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 9.878e-01 0.000e+00 1.000e-04 1.210e-02 0.000e+00 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=1\n",
            "         |->> Action Probabilities (RAW): [4.9077220e-20 9.8779154e-01 5.3230326e-10 9.0032976e-05 1.2118370e-02\n",
            " 1.4672409e-09 2.0381877e-18 6.2789393e-20 0.0000000e+00 3.0964854e-15\n",
            " 1.5139036e-23], argmax=1\n",
            "   \u001b[33m|->> #4/t=115-th Action selection: 4/UP (P(a|s) = 0.2370000034570694)\u001b[0m\n",
            "      |->> Bounding box moves to: [210  64  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.7626 0.     0.     0.2374 0.     0.     0.     0.     0.\n",
            " 0.    ], argmax=1\n",
            "         |->> Action Probabilities (RAW): [5.1030514e-38 7.6259470e-01 2.3404700e-29 5.1510340e-28 2.3740530e-01\n",
            " 1.9642347e-10 5.8672072e-26 5.2180333e-30 0.0000000e+00 1.0561990e-25\n",
            " 0.0000000e+00], argmax=1\n",
            "   \u001b[33m|->> #5/t=116-th Action selection: 1/2X LEFT (P(a|s) = 0.9990000128746033)\u001b[0m\n",
            "      |->> Bounding box moves to: [206  64  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 9.992e-01 0.000e+00 0.000e+00 8.000e-04 0.000e+00 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=1\n",
            "         |->> Action Probabilities (RAW): [1.5922222e-33 9.9917114e-01 1.4187894e-27 5.1507687e-25 8.2890649e-04\n",
            " 4.7311571e-10 1.3960016e-24 1.5418507e-27 0.0000000e+00 2.6085319e-24\n",
            " 0.0000000e+00], argmax=1\n",
            "   \u001b[33m|->> #6/t=117-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [206  63  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [1.6873634e-21 2.6418409e-10 6.9137781e-17 1.2507736e-15 9.9999976e-01\n",
            " 2.1261819e-07 1.6787626e-18 1.6765611e-18 2.3497347e-35 9.8516166e-15\n",
            " 1.7665625e-20], argmax=4\n",
            "   \u001b[33m|->> #7/t=118-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [206  62  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [1.0590507e-22 1.7819463e-09 1.1475328e-16 5.8950147e-18 9.9999964e-01\n",
            " 3.8658453e-07 1.0546744e-18 9.8931299e-20 6.1547259e-34 5.2972191e-16\n",
            " 1.9730230e-19], argmax=4\n",
            "   \u001b[33m|->> #8/t=119-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [206  61  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [6.9727894e-25 1.0005788e-10 3.6691725e-20 3.0103898e-23 1.0000000e+00\n",
            " 5.6140501e-09 1.7503967e-20 1.9368539e-21 2.7647389e-35 6.5148885e-19\n",
            " 7.2721429e-22], argmax=4\n",
            "   \u001b[33m|->> #9/t=120-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [206  60  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [2.0656687e-27 1.6272601e-09 5.3343434e-26 4.9716402e-27 1.0000000e+00\n",
            " 3.0398770e-10 4.0588483e-20 1.3312500e-21 8.3614819e-35 3.2044716e-22\n",
            " 1.1639766e-26], argmax=4\n",
            "   \u001b[33m|->> #10/t=121-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [206  59  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [3.5881755e-25 7.1170921e-12 1.7806419e-28 1.1461394e-28 1.0000000e+00\n",
            " 2.0968981e-08 3.6882275e-21 1.6002709e-15 2.1259209e-35 8.0961047e-26\n",
            " 8.8445045e-26], argmax=4\n",
            "   \u001b[33m|->> #11/t=122-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [206  58  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [3.5830306e-26 3.0249783e-21 1.8063571e-38 2.7663183e-37 1.0000000e+00\n",
            " 3.8616235e-11 2.5118991e-31 2.6514584e-21 0.0000000e+00 0.0000000e+00\n",
            " 1.4138321e-34], argmax=4\n",
            "   \u001b[33m|->> #12/t=123-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [206  57  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [4.7074097e-21 3.2529360e-22 1.9004153e-34 1.6326916e-31 9.9999988e-01\n",
            " 1.4030788e-07 1.0377599e-28 2.0796671e-23 0.0000000e+00 0.0000000e+00\n",
            " 2.8851525e-30], argmax=4\n",
            "   \u001b[33m|->> #13/t=124-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [206  56  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [1.0656410e-21 1.3884529e-22 3.6215473e-34 1.1882493e-31 1.0000000e+00\n",
            " 7.1107804e-09 1.4630666e-31 2.0106593e-24 0.0000000e+00 0.0000000e+00\n",
            " 1.0347458e-32], argmax=4\n",
            "   \u001b[33m|->> #14/t=125-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [206  55  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [4.9968053e-23 6.7159855e-24 5.3853497e-36 3.0308043e-33 1.0000000e+00\n",
            " 6.2115226e-12 3.2437665e-37 1.4030783e-23 0.0000000e+00 0.0000000e+00\n",
            " 3.9143714e-37], argmax=4\n",
            "   \u001b[33m|->> #15/t=126-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [206  54  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [1.8140686e-25 3.8950616e-25 0.0000000e+00 8.0909081e-36 1.0000000e+00\n",
            " 2.5669893e-15 0.0000000e+00 3.4081083e-24 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00], argmax=4\n",
            "   \u001b[33m|->> #16/t=127-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [206  53  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [1.9537159e-26 2.4104094e-27 0.0000000e+00 0.0000000e+00 1.0000000e+00\n",
            " 4.3114343e-20 0.0000000e+00 3.6655960e-25 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00], argmax=4\n",
            "   \u001b[33m|->> #17/t=128-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [206  52  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [2.4215079e-25 1.3787373e-28 0.0000000e+00 0.0000000e+00 1.0000000e+00\n",
            " 7.4386352e-22 0.0000000e+00 3.8651073e-23 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00], argmax=4\n",
            "   \u001b[33m|->> #18/t=129-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [206  51  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [2.4244160e-28 3.4283664e-27 0.0000000e+00 0.0000000e+00 1.0000000e+00\n",
            " 5.1117545e-29 0.0000000e+00 1.5768329e-21 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00], argmax=4\n",
            "   \u001b[33m|->> #19/t=130-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [206  50  96  66]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [6.9258550e-36 1.2439105e-26 0.0000000e+00 0.0000000e+00 1.0000000e+00\n",
            " 2.1477388e-38 0.0000000e+00 1.4959932e-22 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00], argmax=4\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [222,  67,  96,  66] -> [206,  50,  96,  66] (Target was [246,  26,  86,  54])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.006) for 2X LEFT:bbox transition: [222,  67,  96,  66] -> [218,  67,  96,  66] w/ P(a|s)=1.0 and iou=0.0875594294770206 and reward=-0.0056305346806855006 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.006) for 2X LEFT:bbox transition: [218,  67,  96,  66] -> [214,  67,  96,  66] w/ P(a|s)=1.0 and iou=0.08198659834450138 and reward=-0.005572831132519218 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.014) for 2X UP:bbox transition: [214,  67,  96,  66] -> [214,  65,  96,  66] w/ P(a|s)=0.881855309009552 and iou=0.09580838323353294 and reward=0.01382178488903156 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-0.007) for 2X LEFT:bbox transition: [214,  65,  96,  66] -> [210,  65,  96,  66] w/ P(a|s)=0.9877915382385254 and iou=0.08928571428571429 and reward=-0.006522668947818652 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.007) for UP:bbox transition: [210,  65,  96,  66] -> [210,  64,  96,  66] w/ P(a|s)=0.23740530014038086 and iou=0.09580838323353294 and reward=0.006522668947818652 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-0.007) for 2X LEFT:bbox transition: [210,  64,  96,  66] -> [206,  64,  96,  66] w/ P(a|s)=0.9991711378097534 and iou=0.08885362951209837 and reward=-0.006954753721434573 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.006) for UP:bbox transition: [206,  64,  96,  66] -> [206,  63,  96,  66] w/ P(a|s)=0.9999997615814209 and iou=0.09493418428400478 and reward=0.006080554771906416 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (0.006) for UP:bbox transition: [206,  63,  96,  66] -> [206,  62,  96,  66] w/ P(a|s)=0.9999996423721313 and iou=0.10108303249097472 and reward=0.00614884820696994 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (0.006) for UP:bbox transition: [206,  62,  96,  66] -> [206,  61,  96,  66] w/ P(a|s)=1.0 and iou=0.1073013311819282 and reward=0.006218298690953472 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (0.006) for UP:bbox transition: [206,  61,  96,  66] -> [206,  60,  96,  66] w/ P(a|s)=1.0 and iou=0.11359026369168357 and reward=0.006288932509755374 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (0.006) for UP:bbox transition: [206,  60,  96,  66] -> [206,  59,  96,  66] w/ P(a|s)=1.0 and iou=0.11995104039167687 and reward=0.006360776699993298 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (0.006) for UP:bbox transition: [206,  59,  96,  66] -> [206,  58,  96,  66] w/ P(a|s)=1.0 and iou=0.12638489946655723 and reward=0.006433859074880366 and discount=0.8953382542587164\n",
            "   |->> t=13 Diff-Reward (0.007) for UP:bbox transition: [206,  58,  96,  66] -> [206,  57,  96,  66] w/ P(a|s)=0.9999998807907104 and iou=0.13289310771770532 and reward=0.00650820825114809 and discount=0.8863848717161292\n",
            "   |->> t=14 Diff-Reward (0.007) for UP:bbox transition: [206,  57,  96,  66] -> [206,  56,  96,  66] w/ P(a|s)=1.0 and iou=0.13947696139476962 and reward=0.006583853677064294 and discount=0.8775210229989678\n",
            "   |->> t=15 Diff-Reward (0.007) for UP:bbox transition: [206,  56,  96,  66] -> [206,  55,  96,  66] w/ P(a|s)=1.0 and iou=0.14613778705636743 and reward=0.006660825661597813 and discount=0.8687458127689782\n",
            "   |->> t=16 Diff-Reward (0.007) for UP:bbox transition: [206,  55,  96,  66] -> [206,  54,  96,  66] w/ P(a|s)=1.0 and iou=0.15287694246115077 and reward=0.006739155404783342 and discount=0.8600583546412884\n",
            "   |->> t=17 Diff-Reward (0.007) for UP:bbox transition: [206,  54,  96,  66] -> [206,  53,  96,  66] w/ P(a|s)=1.0 and iou=0.1596958174904943 and reward=0.00681887502934353 and discount=0.8514577710948755\n",
            "   |->> t=18 Diff-Reward (0.007) for UP:bbox transition: [206,  53,  96,  66] -> [206,  52,  96,  66] w/ P(a|s)=1.0 and iou=0.1665958351041224 and reward=0.006900017613628101 and discount=0.8429431933839268\n",
            "   |->> t=19 Diff-Reward (0.007) for UP:bbox transition: [206,  52,  96,  66] -> [206,  51,  96,  66] w/ P(a|s)=1.0 and iou=0.1735784523300556 and reward=0.006982617225933185 and discount=0.8345137614500875\n",
            "   |->> t=20 Diff-Reward (0.007) for UP:bbox transition: [206,  51,  96,  66] -> [206,  50,  96,  66] w/ P(a|s)=1.0 and iou=0.18064516129032257 and reward=0.007066708960266982 and discount=0.8261686238355866\n",
            "   |->> Assigned losses: [-5.6382092e-08 -5.5246229e-08  1.7031936e-03 -7.7742145e-05\n",
            "  9.0099201e-03 -5.4842862e-06  5.7325245e-08  5.7389403e-08\n",
            "  5.7457232e-08  5.7528787e-08  5.7604133e-08  5.7683319e-08\n",
            "  5.7766403e-08  5.7853448e-08  5.7944515e-08  5.8039671e-08\n",
            "  5.8138980e-08  5.8242506e-08  5.8350327e-08  5.8462508e-08]\n",
            "\u001b[92m>> Total frame loss: 0.010630584321916103\u001b[0m\n",
            "Final bounding box: [206  50  96  66] reached in 131 timesteps (originating from [216  65  94  64]). Target was [246  26  86  54]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 29 in t=131 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[92m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 6.283923149108887\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.00028501718770712614\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 4.49841833114624\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.011222963221371174\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 7.45779275894165\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.0312829315662384\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 2.4748146533966064\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.013153430074453354\n",
            "Layer Name: custom_rnn/conv2d/kernel:0, GRAD NORM = 0.9486835598945618\n",
            "Layer Name: custom_rnn/conv2d/bias:0, GRAD NORM = 0.04819747805595398\n",
            "Layer Name: custom_rnn/conv2d_1/kernel:0, GRAD NORM = 6.6086273193359375\n",
            "Layer Name: custom_rnn/conv2d_1/bias:0, GRAD NORM = 0.04819747805595398\n",
            "Layer Name: custom_rnn/conv2d_2/kernel:0, GRAD NORM = 4.737795352935791\n",
            "Layer Name: custom_rnn/conv2d_2/bias:0, GRAD NORM = 0.03277020528912544\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/Deer\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Starting bounding box for adnet_datasets/OTB/Deer: frames 35:45 is [312 101  81  55].\n",
            "\u001b[34m>> Attempting to reach frame 36 with src: [312, 101,  81,  55] and target: [338, 127,  85,  59]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0036.jpg\n",
            "|->> Beginning tracking for bbox:[312 101  81  55]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 7/2X DOWN (P(a|s) = 0.6790000200271606)\u001b[0m\n",
            "      |->> Bounding box moves to: [312 103  81  55]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 3.212e-01 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            " 6.787e-01 0.000e+00 1.000e-04 0.000e+00], argmax=7\n",
            "         |->> Action Probabilities (RAW): [2.5744470e-13 3.2115942e-01 1.3628434e-07 4.8738058e-10 8.1266455e-07\n",
            " 2.8166638e-05 5.1483519e-11 6.7870373e-01 3.9076251e-10 9.2577597e-05\n",
            " 1.5094787e-05], argmax=7\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 1/2X LEFT (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [308 103  81  55]\n",
            "         |->> Action Probabilities (Rounded): [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.], argmax=1\n",
            "         |->> Action Probabilities (RAW): [3.3900272e-20 1.0000000e+00 6.1715097e-13 2.6691691e-12 1.7252181e-14\n",
            " 4.5302156e-10 2.5559661e-16 4.1284780e-09 6.2430624e-22 5.4817019e-12\n",
            " 4.5995027e-10], argmax=1\n",
            "   \u001b[33m|->> #2/t=3-th Action selection: 1/2X LEFT (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [304 103  81  55]\n",
            "         |->> Action Probabilities (Rounded): [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.], argmax=1\n",
            "         |->> Action Probabilities (RAW): [2.8602261e-20 9.9999988e-01 2.5389902e-15 4.0097015e-09 1.0001296e-15\n",
            " 6.8026893e-08 3.2908985e-14 3.0979859e-08 8.9718798e-23 1.3188700e-11\n",
            " 1.8219475e-09], argmax=1\n",
            "   \u001b[33m|->> #3/t=4-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [304 101  81  55]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.2432804e-17 1.3897294e-06 2.3153481e-14 2.2237656e-15 3.5479565e-13\n",
            " 9.9999619e-01 8.4305189e-16 2.4285573e-06 3.0080789e-18 1.0045193e-11\n",
            " 1.1138969e-11], argmax=5\n",
            "   \u001b[33m|->> #4/t=5-th Action selection: 5/2X UP (P(a|s) = 0.7760000228881836)\u001b[0m\n",
            "      |->> Bounding box moves to: [304  99  81  55]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.0973 0.     0.     0.     0.7763 0.     0.1263 0.     0.\n",
            " 0.    ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.3675464e-17 9.7332008e-02 5.0773647e-12 8.0439570e-12 2.4979571e-10\n",
            " 7.7633637e-01 1.8715018e-13 1.2633160e-01 7.5697963e-16 1.8067113e-10\n",
            " 8.6419394e-10], argmax=5\n",
            "|->> Revisiting bbox: [304 101  81  55]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [312, 101,  81,  55] -> [304,  99,  81,  55] (Target was [338, 127,  85,  59])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.017) for 2X DOWN:bbox transition: [312, 101,  81,  55] -> [312, 103,  81,  55] w/ P(a|s)=0.6787037253379822 and iou=0.21957501609787508 and reward=0.017035333558192534 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.019) for 2X LEFT:bbox transition: [312, 103,  81,  55] -> [308, 103,  81,  55] w/ P(a|s)=1.0 and iou=0.2004056280897452 and reward=-0.019169388008129867 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-0.019) for 2X LEFT:bbox transition: [308, 103,  81,  55] -> [304, 103,  81,  55] w/ P(a|s)=0.9999998807907104 and iou=0.18182952701859478 and reward=-0.01857610107115043 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-0.014) for 2X UP:bbox transition: [304, 103,  81,  55] -> [304, 101,  81,  55] w/ P(a|s)=0.9999961853027344 and iou=0.16812631059578143 and reward=-0.013703216422813358 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-0.013) for 2X UP:bbox transition: [304, 101,  81,  55] -> [304,  99,  81,  55] w/ P(a|s)=0.7763363718986511 and iou=0.1547372271674186 and reward=-0.013389083428362814 and discount=0.96059601\n",
            "   |->> Assigned losses: [ 6.6023944e-03 -1.9003562e-07 -1.8231252e-07 -1.3314340e-07\n",
            " -3.2561382e-03]\n",
            "\u001b[92m>> Total frame loss: 0.0033457509707659483\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 37 with src: [304,  99,  81,  55] and target: [354, 158,  87,  54]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0037.jpg\n",
            "|->> Beginning tracking for bbox:[304  99  81  55]\n",
            "   \u001b[33m|->> #0/t=6-th Action selection: 5/2X UP (P(a|s) = 0.7749999761581421)\u001b[0m\n",
            "      |->> Bounding box moves to: [304  97  81  55]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 0.000e+00 2.000e-04 7.754e-01 0.000e+00\n",
            " 2.243e-01 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.7561466e-06 4.5278415e-05 1.9596460e-07 3.9712745e-06 2.0609047e-04\n",
            " 7.7540559e-01 7.0469655e-06 2.2432707e-01 9.8766222e-09 1.7429776e-06\n",
            " 1.8200632e-07], argmax=5\n",
            "|->> Revisiting bbox: [304  99  81  55]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [304,  99,  81,  55] -> [304,  97,  81,  55] (Target was [354, 158,  87,  54])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X UP:bbox transition: [304,  99,  81,  55] -> [304,  97,  81,  55] w/ P(a|s)=0.7754055857658386 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 38 with src: [304,  97,  81,  55] and target: [380, 179,  81,  53]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0038.jpg\n",
            "|->> Beginning tracking for bbox:[304  97  81  55]\n",
            "   \u001b[33m|->> #0/t=7-th Action selection: 5/2X UP (P(a|s) = 0.49799999594688416)\u001b[0m\n",
            "      |->> Bounding box moves to: [304  95  81  55]\n",
            "         |->> Action Probabilities (Rounded): [9.000e-04 3.600e-03 2.800e-03 9.820e-02 9.020e-02 4.979e-01 5.700e-03\n",
            " 2.981e-01 0.000e+00 2.400e-03 1.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [9.23987769e-04 3.63059179e-03 2.77725304e-03 9.82285962e-02\n",
            " 9.02427435e-02 4.97940004e-01 5.69080608e-03 2.98052698e-01\n",
            " 5.10404197e-06 2.38954439e-03 1.18723874e-04], argmax=5\n",
            "   \u001b[33m|->> #1/t=8-th Action selection: 1/2X LEFT (P(a|s) = 0.3490000069141388)\u001b[0m\n",
            "      |->> Bounding box moves to: [300  95  81  55]\n",
            "         |->> Action Probabilities (Rounded): [1.000e-03 3.489e-01 1.000e-04 5.242e-01 5.060e-02 6.280e-02 1.600e-03\n",
            " 9.000e-03 0.000e+00 1.700e-03 0.000e+00], argmax=3\n",
            "         |->> Action Probabilities (RAW): [9.9851203e-04 3.4891969e-01 1.0554749e-04 5.2416748e-01 5.0644528e-02\n",
            " 6.2778719e-02 1.6272372e-03 9.0464689e-03 3.3038683e-07 1.7033430e-03\n",
            " 8.1422631e-06], argmax=3\n",
            "   \u001b[33m|->> #2/t=9-th Action selection: 5/2X UP (P(a|s) = 0.2680000066757202)\u001b[0m\n",
            "      |->> Bounding box moves to: [300  93  81  55]\n",
            "         |->> Action Probabilities (Rounded): [1.000e-03 5.428e-01 1.000e-04 1.010e-01 2.960e-02 2.679e-01 1.480e-02\n",
            " 4.070e-02 0.000e+00 2.100e-03 0.000e+00], argmax=1\n",
            "         |->> Action Probabilities (RAW): [1.04558934e-03 5.42798877e-01 8.30610879e-05 1.01038769e-01\n",
            " 2.95669008e-02 2.67912596e-01 1.47664575e-02 4.06623743e-02\n",
            " 2.62687445e-05 2.08919821e-03 9.87962449e-06], argmax=1\n",
            "   \u001b[33m|->> #3/t=10-th Action selection: 5/2X UP (P(a|s) = 0.9419999718666077)\u001b[0m\n",
            "      |->> Bounding box moves to: [300  91  81  55]\n",
            "         |->> Action Probabilities (Rounded): [1.500e-03 5.100e-02 0.000e+00 9.000e-04 2.700e-03 9.416e-01 1.000e-03\n",
            " 1.300e-03 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.5073960e-03 5.0985079e-02 1.0107436e-05 9.3885144e-04 2.7281647e-03\n",
            " 9.4155043e-01 9.7554742e-04 1.2622764e-03 1.1345101e-07 2.0440242e-05\n",
            " 2.1582464e-05], argmax=5\n",
            "|->> Revisiting bbox: [300  93  81  55]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [304,  97,  81,  55] -> [300,  91,  81,  55] (Target was [380, 179,  81,  53])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X UP:bbox transition: [304,  97,  81,  55] -> [304,  95,  81,  55] w/ P(a|s)=0.4979400038719177 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for 2X LEFT:bbox transition: [304,  95,  81,  55] -> [300,  95,  81,  55] w/ P(a|s)=0.34891968965530396 and iou=0.0 and reward=0.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X UP:bbox transition: [300,  95,  81,  55] -> [300,  93,  81,  55] w/ P(a|s)=0.2679125964641571 and iou=0.0 and reward=0.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.0) for 2X UP:bbox transition: [300,  93,  81,  55] -> [300,  91,  81,  55] w/ P(a|s)=0.9415504336357117 and iou=0.0 and reward=0.0 and discount=0.970299\n",
            "   |->> Assigned losses: [0. 0. 0. 0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 39 with src: [300,  91,  81,  55] and target: [392, 182,  91,  54]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0039.jpg\n",
            "|->> Beginning tracking for bbox:[300  91  81  55]\n",
            "   \u001b[33m|->> #0/t=11-th Action selection: 4/UP (P(a|s) = 0.7110000252723694)\u001b[0m\n",
            "      |->> Bounding box moves to: [300  90  81  55]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.0065 0.     0.2431 0.7105 0.0026 0.0029 0.0316 0.     0.0028\n",
            " 0.    ], argmax=4\n",
            "         |->> Action Probabilities (RAW): [2.4348345e-05 6.4727897e-03 1.9552181e-06 2.4314898e-01 7.1050280e-01\n",
            " 2.6105065e-03 2.8704796e-03 3.1561494e-02 1.1584696e-11 2.8041136e-03\n",
            " 2.5790571e-06], argmax=4\n",
            "   \u001b[33m|->> #1/t=12-th Action selection: 4/UP (P(a|s) = 0.9020000100135803)\u001b[0m\n",
            "      |->> Bounding box moves to: [300  89  81  55]\n",
            "         |->> Action Probabilities (Rounded): [0.00e+00 6.72e-02 0.00e+00 2.94e-02 9.02e-01 0.00e+00 1.20e-03 0.00e+00\n",
            " 0.00e+00 2.00e-04 0.00e+00], argmax=4\n",
            "         |->> Action Probabilities (RAW): [4.8609905e-07 6.7221127e-02 1.7003737e-09 2.9354488e-02 9.0199512e-01\n",
            " 4.5090633e-06 1.2171837e-03 5.1248931e-06 2.2858988e-14 2.0187754e-04\n",
            " 6.2954983e-09], argmax=4\n",
            "   \u001b[33m|->> #2/t=13-th Action selection: 1/2X LEFT (P(a|s) = 0.7599999904632568)\u001b[0m\n",
            "      |->> Bounding box moves to: [296  89  81  55]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 7.602e-01 0.000e+00 1.240e-02 2.126e-01 0.000e+00 1.440e-02\n",
            " 0.000e+00 0.000e+00 3.000e-04 0.000e+00], argmax=1\n",
            "         |->> Action Probabilities (RAW): [3.42172427e-07 7.60224462e-01 7.66981409e-11 1.24413166e-02\n",
            " 2.12599561e-01 1.07300571e-06 1.43969469e-02 1.83835198e-07\n",
            " 1.92358726e-15 3.36149824e-04 1.26787505e-08], argmax=1\n",
            "|->> Revisiting bbox: [300  89  81  55]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [300,  91,  81,  55] -> [296,  89,  81,  55] (Target was [392, 182,  91,  54])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for UP:bbox transition: [300,  91,  81,  55] -> [300,  90,  81,  55] w/ P(a|s)=0.7105028033256531 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for UP:bbox transition: [300,  90,  81,  55] -> [300,  89,  81,  55] w/ P(a|s)=0.9019951224327087 and iou=0.0 and reward=0.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X LEFT:bbox transition: [300,  89,  81,  55] -> [296,  89,  81,  55] w/ P(a|s)=0.760224461555481 and iou=0.0 and reward=0.0 and discount=0.9801\n",
            "   |->> Assigned losses: [0. 0. 0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 40 with src: [296,  89,  81,  55] and target: [419, 172,  86,  51]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0040.jpg\n",
            "|->> Beginning tracking for bbox:[296  89  81  55]\n",
            "   \u001b[33m|->> #0/t=14-th Action selection: 1/2X LEFT (P(a|s) = 0.9129999876022339)\u001b[0m\n",
            "      |->> Bounding box moves to: [292  89  81  55]\n",
            "         |->> Action Probabilities (Rounded): [1.00e-04 9.13e-01 3.40e-03 2.60e-03 0.00e+00 1.10e-03 7.47e-02 3.80e-03\n",
            " 0.00e+00 1.20e-03 0.00e+00], argmax=1\n",
            "         |->> Action Probabilities (RAW): [9.6238531e-05 9.1302621e-01 3.3818670e-03 2.5757640e-03 4.6627385e-05\n",
            " 1.0873089e-03 7.4747033e-02 3.7903911e-03 5.8041802e-08 1.2152025e-03\n",
            " 3.3353612e-05], argmax=1\n",
            "   \u001b[33m|->> #1/t=15-th Action selection: 1/2X LEFT (P(a|s) = 0.7870000004768372)\u001b[0m\n",
            "      |->> Bounding box moves to: [288  89  81  55]\n",
            "         |->> Action Probabilities (Rounded): [1.000e-04 7.866e-01 1.000e-02 6.000e-03 0.000e+00 1.300e-03 1.948e-01\n",
            " 2.000e-04 0.000e+00 9.000e-04 0.000e+00], argmax=1\n",
            "         |->> Action Probabilities (RAW): [6.0897513e-05 7.8663230e-01 9.9536413e-03 6.0457154e-03 7.2226708e-06\n",
            " 1.3066113e-03 1.9483803e-01 2.1875622e-04 8.0811766e-09 9.1117492e-04\n",
            " 2.5699090e-05], argmax=1\n",
            "   \u001b[33m|->> #2/t=16-th Action selection: 1/2X LEFT (P(a|s) = 0.9359999895095825)\u001b[0m\n",
            "      |->> Bounding box moves to: [284  89  81  55]\n",
            "         |->> Action Probabilities (Rounded): [0.00e+00 9.36e-01 7.80e-03 2.50e-03 0.00e+00 3.00e-03 4.86e-02 4.00e-04\n",
            " 0.00e+00 1.50e-03 0.00e+00], argmax=1\n",
            "         |->> Action Probabilities (RAW): [4.4437675e-05 9.3604374e-01 7.7983565e-03 2.5287655e-03 2.2506951e-05\n",
            " 2.9921820e-03 4.8644301e-02 4.0533187e-04 7.4596912e-08 1.5021019e-03\n",
            " 1.8294773e-05], argmax=1\n",
            "   \u001b[33m|->> #3/t=17-th Action selection: 1/2X LEFT (P(a|s) = 0.8920000195503235)\u001b[0m\n",
            "      |->> Bounding box moves to: [280  89  81  55]\n",
            "         |->> Action Probabilities (Rounded): [1.00e-04 8.92e-01 4.70e-03 1.39e-02 3.00e-04 2.90e-03 7.58e-02 8.30e-03\n",
            " 0.00e+00 2.00e-03 1.00e-04], argmax=1\n",
            "         |->> Action Probabilities (RAW): [6.46042390e-05 8.92032743e-01 4.65941289e-03 1.38613535e-02\n",
            " 2.73167185e-04 2.90297018e-03 7.58418515e-02 8.29062425e-03\n",
            " 9.50217668e-07 1.96166337e-03 1.10598688e-04], argmax=1\n",
            "   \u001b[33m|->> #4/t=18-th Action selection: 1/2X LEFT (P(a|s) = 0.9559999704360962)\u001b[0m\n",
            "      |->> Bounding box moves to: [276  89  81  55]\n",
            "         |->> Action Probabilities (Rounded): [1.000e-04 9.558e-01 3.100e-03 1.400e-02 5.000e-04 2.700e-03 1.210e-02\n",
            " 9.600e-03 0.000e+00 1.900e-03 1.000e-04], argmax=1\n",
            "         |->> Action Probabilities (RAW): [6.0030492e-05 9.5584375e-01 3.1362718e-03 1.4023300e-02 5.3931441e-04\n",
            " 2.6871790e-03 1.2114786e-02 9.6108727e-03 2.2430443e-06 1.9134940e-03\n",
            " 6.8687012e-05], argmax=1\n",
            "   \u001b[33m|->> #5/t=19-th Action selection: 1/2X LEFT (P(a|s) = 0.9449999928474426)\u001b[0m\n",
            "      |->> Bounding box moves to: [272  89  81  55]\n",
            "         |->> Action Probabilities (Rounded): [2.000e-04 9.446e-01 5.900e-03 1.180e-02 1.500e-03 1.500e-03 1.170e-02\n",
            " 2.100e-02 0.000e+00 1.500e-03 2.000e-04], argmax=1\n",
            "         |->> Action Probabilities (RAW): [2.0754496e-04 9.4461381e-01 5.9430823e-03 1.1797773e-02 1.5308881e-03\n",
            " 1.4669409e-03 1.1711786e-02 2.0995772e-02 3.6307044e-06 1.5262424e-03\n",
            " 2.0258798e-04], argmax=1\n",
            "   \u001b[33m|->> #6/t=20-th Action selection: 1/2X LEFT (P(a|s) = 0.9470000267028809)\u001b[0m\n",
            "      |->> Bounding box moves to: [268  89  81  55]\n",
            "         |->> Action Probabilities (Rounded): [2.000e-04 9.469e-01 6.400e-03 8.000e-03 7.000e-04 1.500e-03 1.790e-02\n",
            " 1.680e-02 0.000e+00 1.400e-03 2.000e-04], argmax=1\n",
            "         |->> Action Probabilities (RAW): [2.0027636e-04 9.4687361e-01 6.4398390e-03 7.9998560e-03 6.6168502e-04\n",
            " 1.4827247e-03 1.7889615e-02 1.6841304e-02 3.1971767e-06 1.3723277e-03\n",
            " 2.3570567e-04], argmax=1\n",
            "   \u001b[33m|->> #7/t=21-th Action selection: 1/2X LEFT (P(a|s) = 0.9100000262260437)\u001b[0m\n",
            "      |->> Bounding box moves to: [264  89  81  55]\n",
            "         |->> Action Probabilities (Rounded): [3.000e-04 9.101e-01 1.120e-02 2.230e-02 2.300e-03 4.700e-03 2.310e-02\n",
            " 2.340e-02 0.000e+00 2.100e-03 5.000e-04], argmax=1\n",
            "         |->> Action Probabilities (RAW): [2.6258119e-04 9.1007113e-01 1.1233759e-02 2.2297019e-02 2.2663379e-03\n",
            " 4.6561253e-03 2.3112645e-02 2.3437556e-02 7.2217094e-06 2.1298458e-03\n",
            " 5.2581792e-04], argmax=1\n",
            "   \u001b[33m|->> #8/t=22-th Action selection: 1/2X LEFT (P(a|s) = 0.8799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [260  89  81  55]\n",
            "         |->> Action Probabilities (Rounded): [3.000e-04 8.802e-01 7.000e-03 3.470e-02 4.500e-03 4.800e-03 1.170e-02\n",
            " 5.300e-02 0.000e+00 3.200e-03 5.000e-04], argmax=1\n",
            "         |->> Action Probabilities (RAW): [3.0858390e-04 8.8016641e-01 7.0205047e-03 3.4683701e-02 4.4809440e-03\n",
            " 4.8405943e-03 1.1694029e-02 5.2985299e-02 3.4138215e-05 3.2467453e-03\n",
            " 5.3895573e-04], argmax=1\n",
            "   \u001b[33m|->> #9/t=23-th Action selection: 1/2X LEFT (P(a|s) = 0.7889999747276306)\u001b[0m\n",
            "      |->> Bounding box moves to: [256  89  81  55]\n",
            "         |->> Action Probabilities (Rounded): [5.000e-04 7.894e-01 1.700e-02 9.550e-02 7.800e-03 6.000e-03 1.360e-02\n",
            " 6.310e-02 0.000e+00 6.200e-03 8.000e-04], argmax=1\n",
            "         |->> Action Probabilities (RAW): [5.1382615e-04 7.8935891e-01 1.7016754e-02 9.5485881e-02 7.8444043e-03\n",
            " 5.9750942e-03 1.3645292e-02 6.3135296e-02 3.5787387e-05 6.1818142e-03\n",
            " 8.0698088e-04], argmax=1\n",
            "   \u001b[33m|->> #10/t=24-th Action selection: 1/2X LEFT (P(a|s) = 0.777999997138977)\u001b[0m\n",
            "      |->> Bounding box moves to: [252  89  81  55]\n",
            "         |->> Action Probabilities (Rounded): [1.700e-03 7.775e-01 8.800e-03 1.214e-01 7.000e-03 7.000e-03 1.290e-02\n",
            " 5.200e-02 1.000e-04 1.060e-02 8.000e-04], argmax=1\n",
            "         |->> Action Probabilities (RAW): [1.72629848e-03 7.77548552e-01 8.80859420e-03 1.21449873e-01\n",
            " 6.95589511e-03 7.04032322e-03 1.29366005e-02 5.20009771e-02\n",
            " 6.97599753e-05 1.06160771e-02 8.47086310e-04], argmax=1\n",
            "   \u001b[33m|->> #11/t=25-th Action selection: 1/2X LEFT (P(a|s) = 0.8939999938011169)\u001b[0m\n",
            "      |->> Bounding box moves to: [248  89  81  55]\n",
            "         |->> Action Probabilities (Rounded): [1.000e-03 8.937e-01 9.000e-04 6.010e-02 3.200e-03 1.000e-03 6.400e-03\n",
            " 2.220e-02 0.000e+00 1.130e-02 2.000e-04], argmax=1\n",
            "         |->> Action Probabilities (RAW): [9.8318467e-04 8.9366746e-01 9.2676288e-04 6.0140464e-02 3.2130447e-03\n",
            " 9.8125869e-04 6.3920938e-03 2.2161374e-02 1.9030378e-05 1.1283346e-02\n",
            " 2.3195337e-04], argmax=1\n",
            "|->> Revisiting bbox: [252  89  81  55]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [296,  89,  81,  55] -> [248,  89,  81,  55] (Target was [419, 172,  86,  51])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X LEFT:bbox transition: [296,  89,  81,  55] -> [292,  89,  81,  55] w/ P(a|s)=0.9130262136459351 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for 2X LEFT:bbox transition: [292,  89,  81,  55] -> [288,  89,  81,  55] w/ P(a|s)=0.7866322994232178 and iou=0.0 and reward=0.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X LEFT:bbox transition: [288,  89,  81,  55] -> [284,  89,  81,  55] w/ P(a|s)=0.9360437393188477 and iou=0.0 and reward=0.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.0) for 2X LEFT:bbox transition: [284,  89,  81,  55] -> [280,  89,  81,  55] w/ P(a|s)=0.8920327425003052 and iou=0.0 and reward=0.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.0) for 2X LEFT:bbox transition: [280,  89,  81,  55] -> [276,  89,  81,  55] w/ P(a|s)=0.9558437466621399 and iou=0.0 and reward=0.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.0) for 2X LEFT:bbox transition: [276,  89,  81,  55] -> [272,  89,  81,  55] w/ P(a|s)=0.9446138143539429 and iou=0.0 and reward=0.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.0) for 2X LEFT:bbox transition: [272,  89,  81,  55] -> [268,  89,  81,  55] w/ P(a|s)=0.9468736052513123 and iou=0.0 and reward=0.0 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (0.0) for 2X LEFT:bbox transition: [268,  89,  81,  55] -> [264,  89,  81,  55] w/ P(a|s)=0.9100711345672607 and iou=0.0 and reward=0.0 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (0.0) for 2X LEFT:bbox transition: [264,  89,  81,  55] -> [260,  89,  81,  55] w/ P(a|s)=0.8801664113998413 and iou=0.0 and reward=0.0 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (0.0) for 2X LEFT:bbox transition: [260,  89,  81,  55] -> [256,  89,  81,  55] w/ P(a|s)=0.789358913898468 and iou=0.0 and reward=0.0 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (0.0) for 2X LEFT:bbox transition: [256,  89,  81,  55] -> [252,  89,  81,  55] w/ P(a|s)=0.7775485515594482 and iou=0.0 and reward=0.0 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (0.0) for 2X LEFT:bbox transition: [252,  89,  81,  55] -> [248,  89,  81,  55] w/ P(a|s)=0.893667459487915 and iou=0.0 and reward=0.0 and discount=0.8953382542587164\n",
            "   |->> Assigned losses: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 41 with src: [248,  89,  81,  55] and target: [433, 151,  81,  56]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0041.jpg\n",
            "|->> Beginning tracking for bbox:[248  89  81  55]\n",
            "   \u001b[33m|->> #0/t=26-th Action selection: 5/2X UP (P(a|s) = 0.5120000243186951)\u001b[0m\n",
            "      |->> Bounding box moves to: [248  87  81  55]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 4.642e-01 0.000e+00 0.000e+00 2.380e-02 5.119e-01 0.000e+00\n",
            " 1.000e-04 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.2424900e-06 4.6421269e-01 1.9962620e-09 7.6269913e-07 2.3781156e-02\n",
            " 5.1189536e-01 3.0234197e-08 6.1172606e-05 1.4833410e-12 2.8432808e-08\n",
            " 4.5535682e-05], argmax=5\n",
            "   \u001b[33m|->> #1/t=27-th Action selection: 5/2X UP (P(a|s) = 0.9900000095367432)\u001b[0m\n",
            "      |->> Bounding box moves to: [248  85  81  55]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.0061 0.     0.     0.     0.9897 0.     0.0041 0.     0.\n",
            " 0.    ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.9921560e-10 6.1209286e-03 7.8064369e-12 4.4409724e-08 6.0564304e-08\n",
            " 9.8974204e-01 3.4748964e-13 4.1368585e-03 7.7453794e-15 3.7507739e-08\n",
            " 3.5314893e-10], argmax=5\n",
            "   \u001b[33m|->> #2/t=28-th Action selection: 5/2X UP (P(a|s) = 0.8920000195503235)\u001b[0m\n",
            "      |->> Bounding box moves to: [248  83  81  55]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.1082 0.     0.     0.     0.8918 0.     0.     0.     0.\n",
            " 0.    ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [5.5127094e-11 1.0819091e-01 4.6286607e-13 1.5069766e-10 1.8398292e-07\n",
            " 8.9180672e-01 1.2179748e-11 2.1085873e-06 1.2659123e-17 5.3716462e-09\n",
            " 7.7451312e-10], argmax=5\n",
            "   \u001b[33m|->> #3/t=29-th Action selection: 5/2X UP (P(a|s) = 0.32199999690055847)\u001b[0m\n",
            "      |->> Bounding box moves to: [248  81  81  55]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 6.638e-01 0.000e+00 0.000e+00 3.000e-04 3.225e-01 0.000e+00\n",
            " 1.330e-02 0.000e+00 1.000e-04 0.000e+00], argmax=1\n",
            "         |->> Action Probabilities (RAW): [1.24659355e-05 6.63751125e-01 4.39478285e-08 7.79936909e-06\n",
            " 3.01476073e-04 3.22491527e-01 9.99908025e-06 1.33310463e-02\n",
            " 5.21369503e-10 7.47684389e-05 1.97695772e-05], argmax=1\n",
            "   \u001b[33m|->> #4/t=30-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [248  79  81  55]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.1106486e-06 1.0984103e-05 9.2227941e-11 1.4983215e-06 5.4770112e-06\n",
            " 9.9996960e-01 8.9379782e-08 2.5458642e-06 9.2222417e-16 5.2741540e-09\n",
            " 8.6432046e-06], argmax=5\n",
            "|->> Revisiting bbox: [248  81  81  55]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [248,  89,  81,  55] -> [248,  79,  81,  55] (Target was [433, 151,  81,  56])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X UP:bbox transition: [248,  89,  81,  55] -> [248,  87,  81,  55] w/ P(a|s)=0.5118953585624695 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for 2X UP:bbox transition: [248,  87,  81,  55] -> [248,  85,  81,  55] w/ P(a|s)=0.9897420406341553 and iou=0.0 and reward=0.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X UP:bbox transition: [248,  85,  81,  55] -> [248,  83,  81,  55] w/ P(a|s)=0.8918067216873169 and iou=0.0 and reward=0.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.0) for 2X UP:bbox transition: [248,  83,  81,  55] -> [248,  81,  81,  55] w/ P(a|s)=0.32249152660369873 and iou=0.0 and reward=0.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.0) for 2X UP:bbox transition: [248,  81,  81,  55] -> [248,  79,  81,  55] w/ P(a|s)=0.9999696016311646 and iou=0.0 and reward=0.0 and discount=0.96059601\n",
            "   |->> Assigned losses: [0. 0. 0. 0. 0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 42 with src: [248,  79,  81,  55] and target: [434, 130,  84,  58]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0042.jpg\n",
            "|->> Beginning tracking for bbox:[248  79  81  55]\n",
            "   \u001b[33m|->> #0/t=31-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [248  81  81  55]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 2.000e-04\n",
            " 9.998e-01 0.000e+00 0.000e+00 0.000e+00], argmax=7\n",
            "         |->> Action Probabilities (RAW): [3.7920517e-11 2.5157467e-15 2.9783713e-17 7.0466599e-10 1.4553716e-12\n",
            " 2.5970701e-08 2.1707099e-04 9.9978298e-01 6.6399686e-18 9.6416139e-12\n",
            " 8.0489011e-11], argmax=7\n",
            "   \u001b[33m|->> #1/t=32-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [248  83  81  55]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [8.7451144e-11 2.7614377e-10 2.8158372e-14 7.1016465e-12 3.5902284e-14\n",
            " 6.2064569e-11 3.3938452e-08 9.9999988e-01 9.7411645e-20 1.1537648e-07\n",
            " 5.3272139e-08], argmax=7\n",
            "   \u001b[33m|->> #2/t=33-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [248  85  81  55]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [4.8231370e-09 1.8981576e-05 1.2391063e-10 3.1538794e-09 9.8248952e-12\n",
            " 1.9554816e-05 5.4136063e-07 9.9995804e-01 3.2501016e-11 6.2205821e-08\n",
            " 2.8012889e-06], argmax=7\n",
            "   \u001b[33m|->> #3/t=34-th Action selection: 7/2X DOWN (P(a|s) = 0.13199999928474426)\u001b[0m\n",
            "      |->> Bounding box moves to: [248  87  81  55]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 1.000e-04 1.418e-01 6.985e-01 2.620e-02 1.100e-03\n",
            " 1.318e-01 0.000e+00 0.000e+00 4.000e-04], argmax=4\n",
            "         |->> Action Probabilities (RAW): [7.7884588e-06 9.9228209e-06 1.2086291e-04 1.4178519e-01 6.9854105e-01\n",
            " 2.6210107e-02 1.1285804e-03 1.3182060e-01 1.2598491e-09 2.0809868e-05\n",
            " 3.5511970e-04], argmax=4\n",
            "   \u001b[33m|->> #4/t=35-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [248  86  81  55]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [4.5655939e-17 9.5485821e-14 5.7777739e-17 9.5562811e-12 9.9999869e-01\n",
            " 1.1922936e-08 5.6500333e-15 1.3415512e-06 1.9511884e-26 1.9171507e-14\n",
            " 2.1887364e-14], argmax=4\n",
            "|->> Revisiting bbox: [248  85  81  55]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [248,  79,  81,  55] -> [248,  86,  81,  55] (Target was [434, 130,  84,  58])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X DOWN:bbox transition: [248,  79,  81,  55] -> [248,  81,  81,  55] w/ P(a|s)=0.9997829794883728 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for 2X DOWN:bbox transition: [248,  81,  81,  55] -> [248,  83,  81,  55] w/ P(a|s)=0.9999998807907104 and iou=0.0 and reward=0.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X DOWN:bbox transition: [248,  83,  81,  55] -> [248,  85,  81,  55] w/ P(a|s)=0.9999580383300781 and iou=0.0 and reward=0.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.0) for 2X DOWN:bbox transition: [248,  85,  81,  55] -> [248,  87,  81,  55] w/ P(a|s)=0.13182060420513153 and iou=0.0 and reward=0.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.0) for UP:bbox transition: [248,  87,  81,  55] -> [248,  86,  81,  55] w/ P(a|s)=0.9999986886978149 and iou=0.0 and reward=0.0 and discount=0.96059601\n",
            "   |->> Assigned losses: [0. 0. 0. 0. 0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 43 with src: [248,  86,  81,  55] and target: [410, 116,  76,  60]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0043.jpg\n",
            "|->> Beginning tracking for bbox:[248  86  81  55]\n",
            "   \u001b[33m|->> #0/t=36-th Action selection: 6/DOWN (P(a|s) = 0.8489999771118164)\u001b[0m\n",
            "      |->> Bounding box moves to: [248  87  81  55]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 5.300e-03 0.000e+00 9.000e-04 7.400e-03 2.000e-04 8.493e-01\n",
            " 1.179e-01 0.000e+00 1.900e-02 0.000e+00], argmax=6\n",
            "         |->> Action Probabilities (RAW): [5.7940597e-06 5.3127650e-03 1.2948112e-06 8.5024541e-04 7.3742219e-03\n",
            " 1.8607393e-04 8.4934837e-01 1.1789104e-01 5.0533240e-09 1.9029992e-02\n",
            " 2.2377313e-07], argmax=6\n",
            "   \u001b[33m|->> #1/t=37-th Action selection: 6/DOWN (P(a|s) = 0.9179999828338623)\u001b[0m\n",
            "      |->> Bounding box moves to: [248  88  81  55]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 3.140e-02 1.000e-04 0.000e+00 0.000e+00 1.100e-03 9.177e-01\n",
            " 4.630e-02 0.000e+00 3.400e-03 0.000e+00], argmax=6\n",
            "         |->> Action Probabilities (RAW): [1.3985504e-06 3.1394202e-02 7.4043062e-05 2.9254550e-05 3.7166585e-05\n",
            " 1.0959038e-03 9.1767043e-01 4.6283096e-02 1.0855309e-07 3.4142707e-03\n",
            " 1.4777030e-08], argmax=6\n",
            "   \u001b[33m|->> #2/t=38-th Action selection: 1/2X LEFT (P(a|s) = 0.5619999766349792)\u001b[0m\n",
            "      |->> Bounding box moves to: [244  88  81  55]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 5.616e-01 4.000e-04 8.220e-02 3.000e-04 5.470e-02 2.840e-02\n",
            " 2.692e-01 0.000e+00 2.800e-03 2.000e-04], argmax=1\n",
            "         |->> Action Probabilities (RAW): [3.2246582e-05 5.6156772e-01 4.4529513e-04 8.2220361e-02 3.1568925e-04\n",
            " 5.4748919e-02 2.8390847e-02 2.6924685e-01 4.9803480e-06 2.8162082e-03\n",
            " 2.1083174e-04], argmax=1\n",
            "   \u001b[33m|->> #3/t=39-th Action selection: 5/2X UP (P(a|s) = 0.6919999718666077)\u001b[0m\n",
            "      |->> Bounding box moves to: [244  86  81  55]\n",
            "         |->> Action Probabilities (Rounded): [1.000e-04 3.710e-02 0.000e+00 4.210e-02 4.000e-04 6.925e-01 1.240e-02\n",
            " 2.123e-01 0.000e+00 6.000e-04 2.500e-03], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.17091724e-04 3.70691232e-02 2.55796585e-05 4.20664921e-02\n",
            " 3.86847212e-04 6.92494988e-01 1.23808160e-02 2.12338388e-01\n",
            " 3.17296835e-05 6.34500466e-04 2.45442055e-03], argmax=5\n",
            "   \u001b[33m|->> #4/t=40-th Action selection: 6/DOWN (P(a|s) = 0.9129999876022339)\u001b[0m\n",
            "      |->> Bounding box moves to: [244  87  81  55]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 4.770e-02 0.000e+00 9.000e-04 1.500e-03 2.000e-04 9.126e-01\n",
            " 2.230e-02 0.000e+00 1.480e-02 0.000e+00], argmax=6\n",
            "         |->> Action Probabilities (RAW): [4.7652484e-05 4.7666289e-02 6.4436895e-06 8.5194071e-04 1.5469311e-03\n",
            " 2.2710154e-04 9.1260415e-01 2.2258326e-02 4.6713959e-07 1.4789306e-02\n",
            " 1.4661014e-06], argmax=6\n",
            "|->> Revisiting bbox: [244  88  81  55]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [248,  86,  81,  55] -> [244,  87,  81,  55] (Target was [410, 116,  76,  60])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for DOWN:bbox transition: [248,  86,  81,  55] -> [248,  87,  81,  55] w/ P(a|s)=0.8493483662605286 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for DOWN:bbox transition: [248,  87,  81,  55] -> [248,  88,  81,  55] w/ P(a|s)=0.9176704287528992 and iou=0.0 and reward=0.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X LEFT:bbox transition: [248,  88,  81,  55] -> [244,  88,  81,  55] w/ P(a|s)=0.5615677237510681 and iou=0.0 and reward=0.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.0) for 2X UP:bbox transition: [244,  88,  81,  55] -> [244,  86,  81,  55] w/ P(a|s)=0.6924949884414673 and iou=0.0 and reward=0.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.0) for DOWN:bbox transition: [244,  86,  81,  55] -> [244,  87,  81,  55] w/ P(a|s)=0.9126041531562805 and iou=0.0 and reward=0.0 and discount=0.96059601\n",
            "   |->> Assigned losses: [0. 0. 0. 0. 0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 44 with src: [244,  87,  81,  55] and target: [372, 110,  79,  58]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0044.jpg\n",
            "|->> Beginning tracking for bbox:[244  87  81  55]\n",
            "   \u001b[33m|->> #0/t=41-th Action selection: 3/2X RIGHT (P(a|s) = 0.6110000014305115)\u001b[0m\n",
            "      |->> Bounding box moves to: [248  87  81  55]\n",
            "         |->> Action Probabilities (Rounded): [1.000e-04 1.789e-01 2.000e-04 6.115e-01 9.000e-04 7.800e-03 7.170e-02\n",
            " 1.148e-01 0.000e+00 1.240e-02 1.700e-03], argmax=3\n",
            "         |->> Action Probabilities (RAW): [5.2515305e-05 1.7886661e-01 2.2435353e-04 6.1145592e-01 9.1609376e-04\n",
            " 7.7784024e-03 7.1690746e-02 1.1481967e-01 3.0971696e-06 1.2444226e-02\n",
            " 1.7484223e-03], argmax=3\n",
            "   \u001b[33m|->> #1/t=42-th Action selection: 3/2X RIGHT (P(a|s) = 0.7350000143051147)\u001b[0m\n",
            "      |->> Bounding box moves to: [252  87  81  55]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 1.110e-02 1.000e-04 7.346e-01 2.200e-03 1.040e-02 3.400e-03\n",
            " 2.374e-01 0.000e+00 6.000e-04 2.000e-04], argmax=3\n",
            "         |->> Action Probabilities (RAW): [1.7448527e-05 1.1090769e-02 5.0920411e-05 7.3462451e-01 2.1600246e-03\n",
            " 1.0449994e-02 3.3987693e-03 2.3744348e-01 8.4304055e-08 5.9641129e-04\n",
            " 1.6763651e-04], argmax=3\n",
            "   \u001b[33m|->> #2/t=43-th Action selection: 3/2X RIGHT (P(a|s) = 0.5699999928474426)\u001b[0m\n",
            "      |->> Bounding box moves to: [256  87  81  55]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.0082 0.     0.5698 0.0033 0.0202 0.0035 0.3941 0.     0.0007\n",
            " 0.    ], argmax=3\n",
            "         |->> Action Probabilities (RAW): [2.4445691e-05 8.2071656e-03 4.6744961e-05 5.6983393e-01 3.3040673e-03\n",
            " 2.0214453e-02 3.4866368e-03 3.9411926e-01 9.8712725e-08 7.2047015e-04\n",
            " 4.2668209e-05], argmax=3\n",
            "   \u001b[33m|->> #3/t=44-th Action selection: 3/2X RIGHT (P(a|s) = 0.335999995470047)\u001b[0m\n",
            "      |->> Bounding box moves to: [260  87  81  55]\n",
            "         |->> Action Probabilities (Rounded): [1.000e-04 6.660e-02 0.000e+00 3.361e-01 6.700e-03 1.205e-01 8.000e-04\n",
            " 4.672e-01 0.000e+00 2.000e-03 1.000e-04], argmax=7\n",
            "         |->> Action Probabilities (RAW): [7.5881246e-05 6.6643618e-02 4.3691907e-05 3.3606112e-01 6.7113359e-03\n",
            " 1.2045693e-01 7.7405066e-04 4.6718419e-01 7.1410182e-07 1.9939502e-03\n",
            " 5.4501867e-05], argmax=7\n",
            "   \u001b[33m|->> #4/t=45-th Action selection: 5/2X UP (P(a|s) = 0.08100000023841858)\u001b[0m\n",
            "      |->> Bounding box moves to: [260  85  81  55]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.0489 0.     0.2415 0.0133 0.0809 0.0007 0.6138 0.     0.0009\n",
            " 0.    ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [2.4678342e-05 4.8850577e-02 2.1607531e-05 2.4151419e-01 1.3293856e-02\n",
            " 8.0914512e-02 6.6398695e-04 6.1379397e-01 1.6476596e-07 9.0159546e-04\n",
            " 2.0857131e-05], argmax=7\n",
            "|->> Revisiting bbox: [260  87  81  55]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [244,  87,  81,  55] -> [260,  85,  81,  55] (Target was [372, 110,  79,  58])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X RIGHT:bbox transition: [244,  87,  81,  55] -> [248,  87,  81,  55] w/ P(a|s)=0.6114559173583984 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for 2X RIGHT:bbox transition: [248,  87,  81,  55] -> [252,  87,  81,  55] w/ P(a|s)=0.7346245050430298 and iou=0.0 and reward=0.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X RIGHT:bbox transition: [252,  87,  81,  55] -> [256,  87,  81,  55] w/ P(a|s)=0.5698339343070984 and iou=0.0 and reward=0.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.0) for 2X RIGHT:bbox transition: [256,  87,  81,  55] -> [260,  87,  81,  55] w/ P(a|s)=0.33606112003326416 and iou=0.0 and reward=0.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.0) for 2X UP:bbox transition: [260,  87,  81,  55] -> [260,  85,  81,  55] w/ P(a|s)=0.08091451227664948 and iou=0.0 and reward=0.0 and discount=0.96059601\n",
            "   |->> Assigned losses: [0. 0. 0. 0. 0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 45 with src: [260,  85,  81,  55] and target: [351, 111,  79,  58]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0045.jpg\n",
            "|->> Beginning tracking for bbox:[260  85  81  55]\n",
            "   \u001b[33m|->> #0/t=46-th Action selection: 5/2X UP (P(a|s) = 0.7139999866485596)\u001b[0m\n",
            "      |->> Bounding box moves to: [260  83  81  55]\n",
            "         |->> Action Probabilities (Rounded): [4.000e-04 1.478e-01 0.000e+00 1.310e-01 2.100e-03 7.136e-01 1.500e-03\n",
            " 2.100e-03 0.000e+00 1.500e-03 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.90754547e-04 1.47785723e-01 3.59743638e-07 1.30951881e-01\n",
            " 2.07873713e-03 7.13621140e-01 1.48508663e-03 2.13844515e-03\n",
            " 1.20748584e-08 1.54269498e-03 5.06381411e-06], argmax=5\n",
            "   \u001b[33m|->> #1/t=47-th Action selection: 5/2X UP (P(a|s) = 0.7070000171661377)\u001b[0m\n",
            "      |->> Bounding box moves to: [260  81  81  55]\n",
            "         |->> Action Probabilities (Rounded): [1.000e-04 1.012e-01 0.000e+00 1.588e-01 0.000e+00 7.067e-01 3.210e-02\n",
            " 3.000e-04 0.000e+00 8.000e-04 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [7.4458629e-05 1.0119447e-01 7.3381045e-07 1.5882275e-01 4.9126596e-05\n",
            " 7.0667666e-01 3.2060232e-02 2.7947855e-04 3.8175307e-09 8.4192195e-04\n",
            " 1.2752443e-07], argmax=5\n",
            "   \u001b[33m|->> #2/t=48-th Action selection: 6/DOWN (P(a|s) = 0.9279999732971191)\u001b[0m\n",
            "      |->> Bounding box moves to: [260  82  81  55]\n",
            "         |->> Action Probabilities (Rounded): [1.000e-04 2.400e-02 4.000e-04 3.230e-02 1.000e-04 1.170e-02 9.277e-01\n",
            " 3.100e-03 0.000e+00 4.000e-04 2.000e-04], argmax=6\n",
            "         |->> Action Probabilities (RAW): [7.7414079e-05 2.4044007e-02 4.0397776e-04 3.2281063e-02 8.1824619e-05\n",
            " 1.1707641e-02 9.2773306e-01 3.0773350e-03 3.4792158e-06 4.2541785e-04\n",
            " 1.6479981e-04], argmax=6\n",
            "|->> Revisiting bbox: [260  83  81  55]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [260,  85,  81,  55] -> [260,  82,  81,  55] (Target was [351, 111,  79,  58])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X UP:bbox transition: [260,  85,  81,  55] -> [260,  83,  81,  55] w/ P(a|s)=0.7136211395263672 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for 2X UP:bbox transition: [260,  83,  81,  55] -> [260,  81,  81,  55] w/ P(a|s)=0.7066766619682312 and iou=0.0 and reward=0.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.0) for DOWN:bbox transition: [260,  81,  81,  55] -> [260,  82,  81,  55] w/ P(a|s)=0.9277330636978149 and iou=0.0 and reward=0.0 and discount=0.9801\n",
            "   |->> Assigned losses: [0. 0. 0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "Final bounding box: [260  82  81  55] reached in 49 timesteps (originating from [312 101  81  55]). Target was [351 111  79  58]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 46 in t=49 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[92m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 0.9011319875717163\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.0017423825338482857\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 1.3409343957901\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.003439725376665592\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 1.259406566619873\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.005662752781063318\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 0.5458582639694214\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.00495201675221324\n",
            "Layer Name: custom_rnn/conv2d/kernel:0, GRAD NORM = 0.1082703173160553\n",
            "Layer Name: custom_rnn/conv2d/bias:0, GRAD NORM = 0.012358598411083221\n",
            "Layer Name: custom_rnn/conv2d_1/kernel:0, GRAD NORM = 1.3432670831680298\n",
            "Layer Name: custom_rnn/conv2d_1/bias:0, GRAD NORM = 0.012358598411083221\n",
            "Layer Name: custom_rnn/conv2d_2/kernel:0, GRAD NORM = 0.9263948798179626\n",
            "Layer Name: custom_rnn/conv2d_2/bias:0, GRAD NORM = 0.008744380436837673\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/Deer\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Starting bounding box for adnet_datasets/OTB/Deer: frames 45:55 is [351 111  79  58].\n",
            "\u001b[34m>> Attempting to reach frame 46 with src: [351, 111,  79,  58] and target: [335, 103,  90,  59]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0046.jpg\n",
            "|->> Beginning tracking for bbox:[351 111  79  58]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 5/2X UP (P(a|s) = 0.9950000047683716)\u001b[0m\n",
            "      |->> Bounding box moves to: [351 109  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.0015 0.     0.     0.     0.9947 0.     0.0038 0.     0.\n",
            " 0.    ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.9169139e-21 1.4799419e-03 1.1508927e-22 5.9304964e-11 5.1788200e-15\n",
            " 9.9474984e-01 3.1197421e-20 3.7693949e-03 3.9506708e-32 2.9914343e-15\n",
            " 8.1122454e-07], argmax=5\n",
            "|->> Revisiting bbox: [351 111  79  58]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [351, 111,  79,  58] -> [351, 109,  79,  58] (Target was [335, 103,  90,  59])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.04) for 2X UP:bbox transition: [351, 111,  79,  58] -> [351, 109,  79,  58] w/ P(a|s)=0.9947498440742493 and iou=0.6569514237855947 and reward=0.040083166185071684 and discount=1.0\n",
            "   |->> Assigned losses: [0.000211]\n",
            "\u001b[92m>> Total frame loss: 0.00021099724108353257\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 47 with src: [351, 109,  79,  58] and target: [327, 102,  90,  55]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0047.jpg\n",
            "|->> Beginning tracking for bbox:[351 109  79  58]\n",
            "   \u001b[33m|->> #0/t=2-th Action selection: 1/2X LEFT (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [347 109  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.], argmax=1\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.2123197e-33 2.5460726e-36\n",
            " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00], argmax=1\n",
            "   \u001b[33m|->> #1/t=3-th Action selection: 1/2X LEFT (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [343 109  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.], argmax=1\n",
            "         |->> Action Probabilities (RAW): [2.05989071e-29 1.00000000e+00 2.53556723e-20 8.42966579e-20\n",
            " 3.63764979e-19 2.93257682e-16 1.57461625e-27 5.87023343e-21\n",
            " 1.61059343e-26 7.97440052e-23 3.40988535e-19], argmax=1\n",
            "   \u001b[33m|->> #2/t=4-th Action selection: 1/2X LEFT (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [339 109  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.], argmax=1\n",
            "         |->> Action Probabilities (RAW): [2.9504292e-31 1.0000000e+00 6.7453553e-25 1.5370028e-19 1.3277367e-19\n",
            " 5.6829013e-21 2.3177073e-33 1.7815419e-17 2.3787160e-32 4.3879828e-24\n",
            " 3.1912642e-27], argmax=1\n",
            "   \u001b[33m|->> #3/t=5-th Action selection: 1/2X LEFT (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [335 109  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.], argmax=1\n",
            "         |->> Action Probabilities (RAW): [1.2202376e-33 1.0000000e+00 1.4093595e-31 7.6181137e-23 9.9374039e-24\n",
            " 2.1170496e-14 1.5144380e-27 6.8643772e-16 0.0000000e+00 3.9869121e-18\n",
            " 4.2739777e-23], argmax=1\n",
            "   \u001b[33m|->> #4/t=6-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [335 107  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 1.9539575e-23 0.0000000e+00 0.0000000e+00 1.7276117e-33\n",
            " 1.0000000e+00 1.2781568e-29 1.5407637e-29 0.0000000e+00 6.3479202e-34\n",
            " 0.0000000e+00], argmax=5\n",
            "   \u001b[33m|->> #5/t=7-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [335 105  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [8.8698683e-36 1.8865223e-30 0.0000000e+00 5.0392240e-38 1.0864590e-30\n",
            " 1.0000000e+00 4.2533693e-31 3.4190815e-19 0.0000000e+00 0.0000000e+00\n",
            " 4.3960271e-38], argmax=5\n",
            "   \u001b[33m|->> #6/t=8-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [335 103  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.5475622e-26 5.0929141e-29 0.0000000e+00 2.0661516e-25 3.0881150e-20\n",
            " 1.0000000e+00 4.1029555e-25 1.3064451e-10 5.5911132e-33 0.0000000e+00\n",
            " 6.3486066e-24], argmax=5\n",
            "   \u001b[33m|->> #7/t=9-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [335 101  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.15797762e-32 9.07942873e-33 0.00000000e+00 2.60665061e-28\n",
            " 3.77812913e-27 1.00000000e+00 1.14318274e-29 9.81941056e-11\n",
            " 9.75040848e-38 0.00000000e+00 2.57104584e-23], argmax=5\n",
            "   \u001b[33m|->> #8/t=10-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [335  99  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [8.6355323e-34 2.0156973e-31 0.0000000e+00 3.8356327e-28 4.3055196e-26\n",
            " 9.9999595e-01 2.3623358e-27 3.9965739e-06 4.6918500e-35 1.9610515e-30\n",
            " 6.5459196e-21], argmax=5\n",
            "|->> Revisiting bbox: [335 101  79  58]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [351, 109,  79,  58] -> [335,  99,  79,  58] (Target was [327, 102,  90,  55])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.047) for 2X LEFT:bbox transition: [351, 109,  79,  58] -> [347, 109,  79,  58] w/ P(a|s)=1.0 and iou=0.5443940375891121 and reward=0.04659391188200962 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.05) for 2X LEFT:bbox transition: [347, 109,  79,  58] -> [343, 109,  79,  58] w/ P(a|s)=1.0 and iou=0.5939799331103679 and reward=0.04958589552125581 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.053) for 2X LEFT:bbox transition: [343, 109,  79,  58] -> [339, 109,  79,  58] w/ P(a|s)=1.0 and iou=0.6468555632342778 and reward=0.052875630123909945 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.014) for 2X LEFT:bbox transition: [339, 109,  79,  58] -> [335, 109,  79,  58] w/ P(a|s)=1.0 and iou=0.6606271777003484 and reward=0.013771614466070559 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.047) for 2X UP:bbox transition: [335, 109,  79,  58] -> [335, 107,  79,  58] w/ P(a|s)=1.0 and iou=0.7076316732353995 and reward=0.04700449553505115 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.05) for 2X UP:bbox transition: [335, 107,  79,  58] -> [335, 105,  79,  58] w/ P(a|s)=1.0 and iou=0.7573746312684366 and reward=0.04974295803303708 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.053) for 2X UP:bbox transition: [335, 105,  79,  58] -> [335, 103,  79,  58] w/ P(a|s)=1.0 and iou=0.810102544625902 and reward=0.052727913357465406 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (0.028) for 2X UP:bbox transition: [335, 103,  79,  58] -> [335, 101,  79,  58] w/ P(a|s)=1.0 and iou=0.8376711008289955 and reward=0.02756855620309351 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (0.0) for 2X UP:bbox transition: [335, 101,  79,  58] -> [335,  99,  79,  58] w/ P(a|s)=0.9999959468841553 and iou=0.8376711008289955 and reward=0.0 and discount=0.9227446944279201\n",
            "   |->> Assigned losses: [4.6657422e-07 4.9156949e-07 5.1894040e-07 1.3380797e-07 4.5213878e-07\n",
            " 4.7369537e-07 4.9709945e-07 2.5730719e-07 0.0000000e+00]\n",
            "\u001b[92m>> Total frame loss: 3.291132770755212e-06\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 48 with src: [335,  99,  79,  58] and target: [319,  95,  88,  60]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0048.jpg\n",
            "|->> Beginning tracking for bbox:[335  99  79  58]\n",
            "   \u001b[33m|->> #0/t=11-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [335 101  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.7922191e-29 1.3127666e-07 1.6077438e-20 6.5750069e-19 1.1746279e-19\n",
            " 9.4604527e-14 1.6543479e-29 9.9999988e-01 0.0000000e+00 2.6936858e-28\n",
            " 1.5664854e-09], argmax=7\n",
            "   \u001b[33m|->> #1/t=12-th Action selection: 1/2X LEFT (P(a|s) = 0.9860000014305115)\u001b[0m\n",
            "      |->> Bounding box moves to: [331 101  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.9859 0.     0.     0.     0.     0.     0.0141 0.     0.\n",
            " 0.    ], argmax=1\n",
            "         |->> Action Probabilities (RAW): [1.5091197e-26 9.8588943e-01 4.2026200e-14 2.4352702e-14 1.2750293e-13\n",
            " 4.5681534e-10 5.2341950e-26 1.4110407e-02 2.8350306e-36 2.3808403e-22\n",
            " 9.9879045e-08], argmax=1\n",
            "             |->> IOU declining: [331 101  79  58]:0.7127474817645015 -> [331 103  79  58]:0.6686971235194585.\n",
            "             |->> Overriding with STOP\n",
            "   \u001b[33m|->> #2/t=13-th Action selection: 8/STOP (P(a|s) = 0.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [331 101  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [3.9359616e-28 2.0600979e-09 7.5504629e-23 2.0680016e-18 1.5962235e-19\n",
            " 2.8980389e-11 2.4253700e-32 9.9999881e-01 0.0000000e+00 1.2585148e-25\n",
            " 1.2035272e-06], argmax=7\n",
            "         |->> Hit a STOP on the 13-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [335,  99,  79,  58] -> [331, 101,  79,  58] (Target was [319,  95,  88,  60])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.041) for 2X DOWN:bbox transition: [335,  99,  79,  58] -> [335, 101,  79,  58] w/ P(a|s)=0.9999998807907104 and iou=0.6508202209574824 and reward=-0.040774976298092236 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.062) for 2X LEFT:bbox transition: [335, 101,  79,  58] -> [331, 101,  79,  58] w/ P(a|s)=0.9858894348144531 and iou=0.7127474817645015 and reward=0.06192726080701916 and discount=0.99\n",
            "   |->> t=3 Stop-Reward (1.0) for STOP:bbox transition: [331, 101,  79,  58] -> [331, 101,  79,  58] w/ P(a|s)=0.0 and iou=0.7127474817645015 and reward=1.0 and discount=0.9801\n",
            "   |->> Assigned losses: [-4.0830554e-07  8.7125180e-04  1.1283817e+01]\n",
            "\u001b[92m>> Total frame loss: 11.284687995910645\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 49 with src: [331, 101,  79,  58] and target: [318,  95,  90,  62]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0049.jpg\n",
            "|->> Beginning tracking for bbox:[331 101  79  58]\n",
            "   \u001b[33m|->> #0/t=13-th Action selection: 1/2X LEFT (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [327 101  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.], argmax=1\n",
            "         |->> Action Probabilities (RAW): [7.3495876e-37 9.9999976e-01 4.4308932e-23 1.2237879e-28 2.0277428e-17\n",
            " 2.4304046e-07 3.1292643e-27 1.5340349e-16 0.0000000e+00 3.1506676e-28\n",
            " 1.9919943e-15], argmax=1\n",
            "   \u001b[33m|->> #1/t=14-th Action selection: 1/2X LEFT (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [323 101  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 9.999e-01 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            " 1.000e-04 0.000e+00 0.000e+00 0.000e+00], argmax=1\n",
            "         |->> Action Probabilities (RAW): [6.1630146e-32 9.9987197e-01 7.2324264e-15 1.0513293e-13 2.5307328e-18\n",
            " 4.1793796e-10 2.3576249e-33 1.2799952e-04 7.2294672e-32 3.0542113e-23\n",
            " 1.9325236e-11], argmax=1\n",
            "   \u001b[33m|->> #2/t=15-th Action selection: 1/2X LEFT (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [319 101  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.], argmax=1\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 1.0000000e+00 3.9326563e-32 1.1514898e-29 5.1934813e-29\n",
            " 4.0642886e-19 1.8334694e-35 2.1543927e-16 0.0000000e+00 2.5205956e-31\n",
            " 3.3969312e-25], argmax=1\n",
            "   \u001b[33m|->> #3/t=16-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [319  99  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 7.2832976e-31 0.0000000e+00 0.0000000e+00 1.5561961e-32\n",
            " 1.0000000e+00 5.8578335e-31 9.2783324e-27 0.0000000e+00 0.0000000e+00\n",
            " 8.1898689e-37], argmax=5\n",
            "   \u001b[33m|->> #4/t=17-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [319  97  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [9.3799720e-34 1.0965938e-30 0.0000000e+00 4.8196560e-26 2.8337350e-22\n",
            " 1.0000000e+00 9.3127225e-28 2.8246098e-11 9.8877234e-38 0.0000000e+00\n",
            " 1.8652779e-21], argmax=5\n",
            "   \u001b[33m|->> #5/t=18-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [319  95  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 0.0000000e+00 0.0000000e+00 1.6963285e-28 9.4384150e-32\n",
            " 1.0000000e+00 1.0010766e-37 2.4805621e-08 0.0000000e+00 0.0000000e+00\n",
            " 1.7003950e-23], argmax=5\n",
            "   \u001b[33m|->> #6/t=19-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [319  93  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 0.0000000e+00 0.0000000e+00 2.3076998e-28 3.3166527e-29\n",
            " 1.0000000e+00 1.2520292e-38 2.1036581e-10 0.0000000e+00 3.0637545e-36\n",
            " 1.0801763e-25], argmax=5\n",
            "|->> Revisiting bbox: [319  95  79  58]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [331, 101,  79,  58] -> [319,  93,  79,  58] (Target was [318,  95,  90,  62])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.034) for 2X LEFT:bbox transition: [331, 101,  79,  58] -> [327, 101,  79,  58] w/ P(a|s)=0.9999997615814209 and iou=0.771000348553503 and reward=0.03390633145948585 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for 2X LEFT:bbox transition: [327, 101,  79,  58] -> [323, 101,  79,  58] w/ P(a|s)=0.9998719692230225 and iou=0.771000348553503 and reward=0.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X LEFT:bbox transition: [323, 101,  79,  58] -> [319, 101,  79,  58] w/ P(a|s)=1.0 and iou=0.771000348553503 and reward=0.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.05) for 2X UP:bbox transition: [319, 101,  79,  58] -> [319,  99,  79,  58] w/ P(a|s)=1.0 and iou=0.821146953405018 and reward=0.05014660485151501 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.0) for 2X UP:bbox transition: [319,  99,  79,  58] -> [319,  97,  79,  58] w/ P(a|s)=1.0 and iou=0.821146953405018 and reward=0.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.0) for 2X UP:bbox transition: [319,  97,  79,  58] -> [319,  95,  79,  58] w/ P(a|s)=1.0 and iou=0.821146953405018 and reward=0.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (-0.05) for 2X UP:bbox transition: [319,  95,  79,  58] -> [319,  93,  79,  58] w/ P(a|s)=1.0 and iou=0.771000348553503 and reward=-0.05014660485151501 and discount=0.941480149401\n",
            "   |->> Assigned losses: [ 3.3952549e-07  0.0000000e+00  0.0000000e+00  4.8723524e-07\n",
            "  0.0000000e+00  0.0000000e+00 -4.7276387e-07]\n",
            "\u001b[92m>> Total frame loss: 3.5399682474235306e-07\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 50 with src: [319,  93,  79,  58] and target: [319, 103,  86,  57]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0050.jpg\n",
            "|->> Beginning tracking for bbox:[319  93  79  58]\n",
            "   \u001b[33m|->> #0/t=20-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [319  95  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 0.0000000e+00 0.0000000e+00 3.6800494e-28 2.2217063e-29\n",
            " 2.7722934e-25 0.0000000e+00 1.0000000e+00 0.0000000e+00 4.3287504e-37\n",
            " 1.0974320e-28], argmax=7\n",
            "   \u001b[33m|->> #1/t=21-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [319  97  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 0.0000000e+00 6.3718218e-25 1.8803926e-16 2.3288249e-22\n",
            " 4.6662387e-12 0.0000000e+00 1.0000000e+00 0.0000000e+00 4.3766743e-35\n",
            " 5.0333925e-12], argmax=7\n",
            "   \u001b[33m|->> #2/t=22-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [319  99  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 9.7552463e-22 1.3914114e-29 8.6296734e-18 1.7592810e-33\n",
            " 3.4843032e-07 1.3521700e-32 9.9999964e-01 0.0000000e+00 7.8592760e-38\n",
            " 9.3328314e-09], argmax=7\n",
            "|->> Revisiting bbox: [319  97  79  58]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [319,  93,  79,  58] -> [319,  99,  79,  58] (Target was [319, 103,  86,  57])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.048) for 2X DOWN:bbox transition: [319,  93,  79,  58] -> [319,  95,  79,  58] w/ P(a|s)=1.0 and iou=0.7137694253704373 and reward=0.047571252496227845 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.05) for 2X DOWN:bbox transition: [319,  95,  79,  58] -> [319,  97,  79,  58] w/ P(a|s)=1.0 and iou=0.7641369047619048 and reward=0.05036747939146746 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.053) for 2X DOWN:bbox transition: [319,  97,  79,  58] -> [319,  99,  79,  58] w/ P(a|s)=0.9999996423721313 and iou=0.8175546186278267 and reward=0.05341771386592198 and discount=0.9801\n",
            "   |->> Assigned losses: [4.7636095e-07 4.9931771e-07 5.2426060e-07]\n",
            "\u001b[92m>> Total frame loss: 1.4999392305981019e-06\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 51 with src: [319,  99,  79,  58] and target: [330, 117,  81,  53]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0051.jpg\n",
            "|->> Beginning tracking for bbox:[319  99  79  58]\n",
            "   \u001b[33m|->> #0/t=23-th Action selection: 7/2X DOWN (P(a|s) = 0.9020000100135803)\u001b[0m\n",
            "      |->> Bounding box moves to: [319 101  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.     0.0977 0.     0.9023 0.     0.\n",
            " 0.    ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.1172189e-33 2.6870154e-21 2.8288350e-28 1.2533605e-19 2.4194859e-18\n",
            " 9.7690940e-02 1.2346810e-36 9.0230912e-01 0.0000000e+00 1.2802118e-21\n",
            " 2.6284248e-16], argmax=7\n",
            "|->> Revisiting bbox: [319  99  79  58]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [319,  99,  79,  58] -> [319, 101,  79,  58] (Target was [330, 117,  81,  53])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.033) for 2X DOWN:bbox transition: [319,  99,  79,  58] -> [319, 101,  79,  58] w/ P(a|s)=0.9023091197013855 and iou=0.4744974248213989 and reward=0.03258028428524945 and discount=1.0\n",
            "   |->> Assigned losses: [0.00334919]\n",
            "\u001b[92m>> Total frame loss: 0.0033491915091872215\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 52 with src: [319, 101,  79,  58] and target: [341, 129,  85,  53]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0052.jpg\n",
            "|->> Beginning tracking for bbox:[319 101  79  58]\n",
            "   \u001b[33m|->> #0/t=24-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [319 103  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            " 2.2647311e-36 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00], argmax=7\n",
            "   \u001b[33m|->> #1/t=25-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [319 105  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            " 1.7409078e-27 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00], argmax=7\n",
            "   \u001b[33m|->> #2/t=26-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [319 107  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 9.2687324e-37 0.0000000e+00 2.4785227e-35 4.4555455e-35\n",
            " 3.2286511e-25 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00], argmax=7\n",
            "   \u001b[33m|->> #3/t=27-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [319 109  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 7.4099457e-37\n",
            " 6.9021249e-34 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00], argmax=7\n",
            "   \u001b[33m|->> #4/t=28-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [319 111  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.9959734e-37\n",
            " 6.1957097e-36 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00], argmax=7\n",
            "   \u001b[33m|->> #5/t=29-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [319 113  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [6.9720254e-38 2.1283757e-31 0.0000000e+00 0.0000000e+00 7.9055147e-33\n",
            " 6.7396010e-23 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00], argmax=7\n",
            "   \u001b[33m|->> #6/t=30-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [319 115  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.4265517e-27 8.2161385e-18 0.0000000e+00 9.4942102e-31 1.1256537e-19\n",
            " 2.0142461e-07 6.1721236e-27 9.9999976e-01 1.1583171e-31 2.6195073e-29\n",
            " 1.2202773e-36], argmax=7\n",
            "   \u001b[33m|->> #7/t=31-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [319 117  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [5.4021683e-33 1.7818765e-23 0.0000000e+00 4.1619340e-37 4.3276264e-15\n",
            " 6.4823930e-10 2.7535273e-29 1.0000000e+00 3.1692670e-36 4.0431095e-31\n",
            " 0.0000000e+00], argmax=7\n",
            "   \u001b[33m|->> #8/t=32-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [319 119  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [6.5530804e-25 1.9000671e-20 0.0000000e+00 3.9496230e-36 1.1231360e-05\n",
            " 2.2090075e-12 1.4243803e-23 9.9998879e-01 4.1522183e-35 9.4512268e-28\n",
            " 5.0920642e-35], argmax=7\n",
            "   \u001b[33m|->> #9/t=33-th Action selection: 7/2X DOWN (P(a|s) = 0.9929999709129333)\u001b[0m\n",
            "      |->> Bounding box moves to: [319 121  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.0066 0.     0.     0.9934 0.     0.\n",
            " 0.    ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.4205049e-12 4.4195020e-10 7.4274028e-26 2.2606525e-28 6.5532741e-03\n",
            " 1.7833761e-07 1.7259487e-17 9.9344653e-01 1.9193487e-24 1.6756331e-15\n",
            " 3.7765826e-25], argmax=7\n",
            "   \u001b[33m|->> #10/t=34-th Action selection: 1/2X LEFT (P(a|s) = 0.6990000009536743)\u001b[0m\n",
            "      |->> Bounding box moves to: [315 121  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 6.990e-01 0.000e+00 0.000e+00 0.000e+00 1.070e-02 0.000e+00\n",
            " 2.902e-01 0.000e+00 1.000e-04 0.000e+00], argmax=1\n",
            "         |->> Action Probabilities (RAW): [3.5009498e-13 6.9899499e-01 3.4013961e-16 8.8916817e-23 4.6226301e-05\n",
            " 1.0667664e-02 1.6316852e-11 2.9021969e-01 1.9957196e-18 7.1391136e-05\n",
            " 5.3803126e-17], argmax=1\n",
            "   \u001b[33m|->> #11/t=35-th Action selection: 5/2X UP (P(a|s) = 0.9990000128746033)\u001b[0m\n",
            "      |->> Bounding box moves to: [315 119  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 3.000e-04 0.000e+00 0.000e+00 0.000e+00 9.993e-01 0.000e+00\n",
            " 5.000e-04 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.4883374e-08 2.6850647e-04 6.0788596e-11 2.9122711e-11 1.6713335e-08\n",
            " 9.9925035e-01 4.3861217e-10 4.8114604e-04 6.4845286e-18 1.1191749e-09\n",
            " 1.0063989e-10], argmax=5\n",
            "|->> Revisiting bbox: [315 121  79  58]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [319, 101,  79,  58] -> [315, 119,  79,  58] (Target was [341, 129,  85,  53])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.019) for 2X DOWN:bbox transition: [319, 101,  79,  58] -> [319, 103,  79,  58] w/ P(a|s)=1.0 and iou=0.25113589425857086 and reward=0.01933434891493524 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.02) for 2X DOWN:bbox transition: [319, 103,  79,  58] -> [319, 105,  79,  58] w/ P(a|s)=1.0 and iou=0.2710868652958456 and reward=0.019950971037274723 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.021) for 2X DOWN:bbox transition: [319, 105,  79,  58] -> [319, 107,  79,  58] w/ P(a|s)=1.0 and iou=0.29168443496801705 and reward=0.020597569672171467 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.021) for 2X DOWN:bbox transition: [319, 107,  79,  58] -> [319, 109,  79,  58] w/ P(a|s)=1.0 and iou=0.3129605548331166 and reward=0.02127611986509953 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.022) for 2X DOWN:bbox transition: [319, 109,  79,  58] -> [319, 111,  79,  58] w/ P(a|s)=1.0 and iou=0.33494931687968266 and reward=0.02198876204656608 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.023) for 2X DOWN:bbox transition: [319, 111,  79,  58] -> [319, 113,  79,  58] w/ P(a|s)=1.0 and iou=0.3576871358135365 and reward=0.02273781893385385 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.024) for 2X DOWN:bbox transition: [319, 113,  79,  58] -> [319, 115,  79,  58] w/ P(a|s)=0.9999997615814209 and iou=0.3812129502963976 and reward=0.023525814482861118 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (0.024) for 2X DOWN:bbox transition: [319, 115,  79,  58] -> [319, 117,  79,  58] w/ P(a|s)=1.0 and iou=0.40556844547563803 and reward=0.024355495179240405 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (0.025) for 2X DOWN:bbox transition: [319, 117,  79,  58] -> [319, 119,  79,  58] w/ P(a|s)=0.9999887943267822 and iou=0.4307982994803968 and reward=0.025229854004758745 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (0.026) for 2X DOWN:bbox transition: [319, 119,  79,  58] -> [319, 121,  79,  58] w/ P(a|s)=0.9934465289115906 and iou=0.45695045695045694 and reward=0.026152157470060167 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (-0.045) for 2X LEFT:bbox transition: [319, 121,  79,  58] -> [315, 121,  79,  58] w/ P(a|s)=0.6989949941635132 and iou=0.41168246077365234 and reward=-0.045267996176804604 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (-0.023) for 2X UP:bbox transition: [315, 121,  79,  58] -> [315, 119,  79,  58] w/ P(a|s)=0.9992503523826599 and iou=0.38881247134342045 and reward=-0.022869989430231885 and discount=0.8953382542587164\n",
            "   |->> Assigned losses: [ 1.9360704e-07  1.9778383e-07  2.0215194e-07  2.0672336e-07\n",
            "  2.1151108e-07  2.1652913e-07  2.2179276e-07  2.2731855e-07\n",
            "  2.6087753e-07  1.5708063e-04 -1.4660937e-02 -1.5355823e-05]\n",
            "\u001b[31m>> Total frame loss: -0.014517273753881454\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 53 with src: [315, 119,  79,  58] and target: [347, 152,  86,  53]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0053.jpg\n",
            "|->> Beginning tracking for bbox:[315 119  79  58]\n",
            "   \u001b[33m|->> #0/t=36-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [315 121  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00 3.9795205e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00], argmax=7\n",
            "   \u001b[33m|->> #1/t=37-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [315 123  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 0.0000000e+00 0.0000000e+00 1.4658326e-30 0.0000000e+00\n",
            " 0.0000000e+00 5.0009140e-27 1.0000000e+00 0.0000000e+00 3.0000296e-36\n",
            " 0.0000000e+00], argmax=7\n",
            "   \u001b[33m|->> #2/t=38-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [315 125  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 0.0000000e+00 0.0000000e+00 1.8607309e-27 4.4639586e-31\n",
            " 2.0389924e-30 2.6386276e-26 1.0000000e+00 0.0000000e+00 7.0687605e-29\n",
            " 1.1229161e-37], argmax=7\n",
            "   \u001b[33m|->> #3/t=39-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [315 127  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 8.5054848e-33 0.0000000e+00 2.1669260e-19 1.6124557e-34\n",
            " 2.7873147e-21 4.9230837e-26 1.0000000e+00 2.1690631e-31 4.6444281e-21\n",
            " 1.1126398e-37], argmax=7\n",
            "   \u001b[33m|->> #4/t=40-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [315 129  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [3.3604410e-34 1.5138322e-26 0.0000000e+00 2.6056497e-18 3.7179092e-27\n",
            " 2.9252042e-30 1.6561724e-22 1.0000000e+00 1.8268018e-28 1.3356999e-15\n",
            " 8.2017118e-31], argmax=7\n",
            "   \u001b[33m|->> #5/t=41-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [315 131  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.75061177e-26 4.81829308e-27 1.04515776e-35 2.12220345e-11\n",
            " 7.85944470e-19 2.26081098e-22 1.41747800e-18 1.00000000e+00\n",
            " 8.38045581e-26 9.99586872e-11 6.72227591e-21], argmax=7\n",
            "   \u001b[33m|->> #6/t=42-th Action selection: 7/2X DOWN (P(a|s) = 0.9950000047683716)\u001b[0m\n",
            "      |->> Bounding box moves to: [315 133  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.0054 0.     0.     0.     0.9946 0.     0.\n",
            " 0.    ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [9.1853915e-16 3.6596329e-19 9.4440087e-18 5.4423250e-03 5.9423206e-07\n",
            " 1.1478002e-12 3.8891694e-12 9.9455005e-01 1.2131350e-16 7.0227129e-06\n",
            " 3.8506749e-09], argmax=7\n",
            "   \u001b[33m|->> #7/t=43-th Action selection: 3/2X RIGHT (P(a|s) = 0.9449999928474426)\u001b[0m\n",
            "      |->> Bounding box moves to: [319 133  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.9454 0.     0.     0.     0.0546 0.     0.\n",
            " 0.    ], argmax=3\n",
            "         |->> Action Probabilities (RAW): [4.77444744e-13 1.41987125e-11 2.04579951e-12 9.45358217e-01\n",
            " 1.68582858e-07 5.74151349e-09 7.32466998e-15 5.46355247e-02\n",
            " 1.55788780e-13 6.12843587e-06 2.68052136e-10], argmax=3\n",
            "   \u001b[33m|->> #8/t=44-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [319 135  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [2.3552541e-20 2.4395327e-13 2.0957121e-14 1.0424503e-12 1.1966869e-13\n",
            " 9.3274227e-13 6.0404811e-17 9.9999988e-01 2.2140435e-19 1.6841410e-07\n",
            " 2.1476374e-18], argmax=7\n",
            "   \u001b[33m|->> #9/t=45-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [319 137  79  58]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [2.3955864e-18 1.6039822e-11 6.7784892e-19 8.0012478e-13 6.6661069e-16\n",
            " 6.7492934e-08 1.8183120e-12 9.9998760e-01 1.7715966e-19 1.2337009e-05\n",
            " 2.7196028e-18], argmax=7\n",
            "   \u001b[33m|->> #10/t=46-th Action selection: 9/SCALE DOWN (P(a|s) = 0.24699999392032623)\u001b[0m\n",
            "      |->> Bounding box moves to: [320 138  76  56]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.     0.     0.     0.7527 0.     0.2473\n",
            " 0.    ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [7.6467964e-12 2.3077803e-06 2.7777802e-09 1.4690942e-08 6.5252443e-14\n",
            " 9.2874052e-06 3.4083921e-08 7.5268507e-01 2.1467936e-16 2.4730329e-01\n",
            " 9.8797684e-13], argmax=7\n",
            "   \u001b[33m|->> #11/t=47-th Action selection: 7/2X DOWN (P(a|s) = 0.8970000147819519)\u001b[0m\n",
            "      |->> Bounding box moves to: [320 140  76  56]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.     0.     0.     0.8966 0.     0.1034\n",
            " 0.    ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [3.0080845e-13 1.3304076e-08 9.1471275e-10 9.0202455e-08 7.4007692e-12\n",
            " 5.9587921e-07 3.8554671e-08 8.9661252e-01 2.7984546e-15 1.0338677e-01\n",
            " 2.7773048e-13], argmax=7\n",
            "   \u001b[33m|->> #12/t=48-th Action selection: 7/2X DOWN (P(a|s) = 0.9959999918937683)\u001b[0m\n",
            "      |->> Bounding box moves to: [320 142  76  56]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 2.200e-03 0.000e+00 0.000e+00 0.000e+00 1.500e-03 0.000e+00\n",
            " 9.963e-01 0.000e+00 1.000e-04 0.000e+00], argmax=7\n",
            "         |->> Action Probabilities (RAW): [7.2304419e-11 2.1659788e-03 6.8337675e-07 4.4982655e-05 2.3710693e-06\n",
            " 1.4748155e-03 3.3871747e-06 9.9625325e-01 4.2520038e-17 5.2693777e-05\n",
            " 1.8386514e-06], argmax=7\n",
            "|->> Revisiting bbox: [320 140  76  56]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [315, 119,  79,  58] -> [320, 142,  76,  56] (Target was [347, 152,  86,  53])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.014) for 2X DOWN:bbox transition: [315, 119,  79,  58] -> [315, 121,  79,  58] w/ P(a|s)=1.0 and iou=0.16122474907889722 and reward=0.013704347321207316 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.014) for 2X DOWN:bbox transition: [315, 121,  79,  58] -> [315, 123,  79,  58] w/ P(a|s)=1.0 and iou=0.17526038318117526 and reward=0.014035634102278038 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.014) for 2X DOWN:bbox transition: [315, 123,  79,  58] -> [315, 125,  79,  58] w/ P(a|s)=1.0 and iou=0.18963946375113888 and reward=0.01437908056996362 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.015) for 2X DOWN:bbox transition: [315, 125,  79,  58] -> [315, 127,  79,  58] w/ P(a|s)=1.0 and iou=0.20437475293187507 and reward=0.014735289180736189 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.015) for 2X DOWN:bbox transition: [315, 127,  79,  58] -> [315, 129,  79,  58] w/ P(a|s)=1.0 and iou=0.21947965310206805 and reward=0.015104900170192975 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.015) for 2X DOWN:bbox transition: [315, 129,  79,  58] -> [315, 131,  79,  58] w/ P(a|s)=1.0 and iou=0.23496824753411702 and reward=0.015488594432048974 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.016) for 2X DOWN:bbox transition: [315, 131,  79,  58] -> [315, 133,  79,  58] w/ P(a|s)=0.9945500493049622 and iou=0.25085534419050226 and reward=0.01588709665638524 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (0.027) for 2X RIGHT:bbox transition: [315, 133,  79,  58] -> [319, 133,  79,  58] w/ P(a|s)=0.9453582167625427 and iou=0.27814291707453503 and reward=0.027287572884032774 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (0.018) for 2X DOWN:bbox transition: [319, 133,  79,  58] -> [319, 135,  79,  58] w/ P(a|s)=0.9999998807907104 and iou=0.2966378209675131 and reward=0.018494903892978087 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (0.019) for 2X DOWN:bbox transition: [319, 135,  79,  58] -> [319, 137,  79,  58] w/ P(a|s)=0.9999876022338867 and iou=0.3156758312940838 and reward=0.019038010326570654 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (-0.011) for SCALE DOWN:bbox transition: [319, 137,  79,  58] -> [320, 138,  76,  56] w/ P(a|s)=0.2473032921552658 and iou=0.3046181172291297 and reward=-0.011057714064954094 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (0.019) for 2X DOWN:bbox transition: [320, 138,  76,  56] -> [320, 140,  76,  56] w/ P(a|s)=0.8966125249862671 and iou=0.32382096725743464 and reward=0.019202850028304963 and discount=0.8953382542587164\n",
            "   |->> t=13 Diff-Reward (0.02) for 2X DOWN:bbox transition: [320, 140,  76,  56] -> [320, 142,  76,  56] w/ P(a|s)=0.996253252029419 and iou=0.3435975609756098 and reward=0.01977659371817514 and discount=0.8863848717161292\n",
            "   |->> Assigned losses: [ 1.3723027e-07  1.3914217e-07  1.4112145e-07  1.4317125e-07\n",
            "  1.4529483e-07  1.4749575e-07  8.1739963e-05  1.4291599e-03\n",
            "  1.7089336e-07  2.1561773e-07 -1.3971955e-02  1.8763026e-03\n",
            "  6.5802618e-05]\n",
            "\u001b[31m>> Total frame loss: -0.010517708957195282\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 54 with src: [320, 142,  76,  56] and target: [345, 167,  92,  53]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0054.jpg\n",
            "|->> Beginning tracking for bbox:[320 142  76  56]\n",
            "   \u001b[33m|->> #0/t=49-th Action selection: 7/2X DOWN (P(a|s) = 0.9980000257492065)\u001b[0m\n",
            "      |->> Bounding box moves to: [320 144  76  56]\n",
            "         |->> Action Probabilities (Rounded): [0.    0.    0.    0.002 0.    0.    0.    0.998 0.    0.    0.   ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [4.9791930e-20 1.0870052e-17 3.2902650e-29 1.9611649e-03 1.4301387e-14\n",
            " 7.1246841e-12 5.2912101e-06 9.9803358e-01 9.7814391e-16 1.6296351e-14\n",
            " 9.7136092e-25], argmax=7\n",
            "   \u001b[33m|->> #1/t=50-th Action selection: 7/2X DOWN (P(a|s) = 0.9959999918937683)\u001b[0m\n",
            "      |->> Bounding box moves to: [320 146  76  56]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.0035 0.     0.     0.     0.9965 0.     0.\n",
            " 0.    ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.3752653e-28 6.5541756e-26 2.0966295e-35 3.5069808e-03 4.0426255e-19\n",
            " 1.5116714e-07 5.3111606e-13 9.9649292e-01 1.3158165e-20 2.5207458e-19\n",
            " 3.4645952e-30], argmax=7\n",
            "   \u001b[33m|->> #2/t=51-th Action selection: 3/2X RIGHT (P(a|s) = 0.9819999933242798)\u001b[0m\n",
            "      |->> Bounding box moves to: [324 146  76  56]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.9821 0.     0.     0.     0.0179 0.     0.\n",
            " 0.    ], argmax=3\n",
            "         |->> Action Probabilities (RAW): [1.7885666e-31 1.0424449e-26 0.0000000e+00 9.8206389e-01 5.6916898e-24\n",
            " 5.5337167e-14 4.2173942e-17 1.7936150e-02 3.7635490e-20 2.4051655e-15\n",
            " 2.0412271e-25], argmax=3\n",
            "   \u001b[33m|->> #3/t=52-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [324 148  76  56]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [4.6174878e-21 0.0000000e+00 1.8366695e-34 3.4032379e-08 1.6055478e-15\n",
            " 9.0767273e-18 1.6071376e-19 1.0000000e+00 2.4471099e-25 9.4423232e-28\n",
            " 1.8943460e-12], argmax=7\n",
            "   \u001b[33m|->> #4/t=53-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [324 150  76  56]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 2.000e-04 0.000e+00 0.000e+00 0.000e+00\n",
            " 9.998e-01 0.000e+00 0.000e+00 0.000e+00], argmax=7\n",
            "         |->> Action Probabilities (RAW): [8.10861782e-16 2.86652191e-21 1.02529814e-17 1.73416425e-04\n",
            " 1.45254253e-08 4.10910887e-15 5.53632439e-18 9.99826491e-01\n",
            " 7.77828654e-23 1.89769045e-13 7.75741071e-08], argmax=7\n",
            "   \u001b[33m|->> #5/t=54-th Action selection: 7/2X DOWN (P(a|s) = 0.9990000128746033)\u001b[0m\n",
            "      |->> Bounding box moves to: [324 152  76  56]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 7.000e-04 0.000e+00 0.000e+00 0.000e+00\n",
            " 9.993e-01 0.000e+00 0.000e+00 0.000e+00], argmax=7\n",
            "         |->> Action Probabilities (RAW): [4.5804882e-18 2.0203587e-17 4.2781035e-13 7.1135134e-04 2.8183326e-06\n",
            " 3.1189251e-10 1.3230411e-14 9.9928540e-01 5.6451917e-20 2.9310014e-12\n",
            " 3.0137303e-07], argmax=7\n",
            "   \u001b[33m|->> #6/t=55-th Action selection: 7/2X DOWN (P(a|s) = 0.9819999933242798)\u001b[0m\n",
            "      |->> Bounding box moves to: [324 154  76  56]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 1.680e-02 1.000e-04 0.000e+00 0.000e+00\n",
            " 9.825e-01 0.000e+00 0.000e+00 6.000e-04], argmax=7\n",
            "         |->> Action Probabilities (RAW): [6.0115291e-17 1.3691574e-15 1.1646511e-08 1.6846368e-02 5.2624120e-05\n",
            " 3.0865145e-08 1.9083241e-14 9.8249108e-01 3.4408765e-17 1.7791882e-10\n",
            " 6.0984731e-04], argmax=7\n",
            "   \u001b[33m|->> #7/t=56-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [324 156  76  56]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [2.0961550e-21 1.3246237e-20 2.1011740e-14 6.3450820e-12 1.0864636e-13\n",
            " 2.6847043e-16 1.3301363e-15 9.9999928e-01 9.0885864e-22 4.7735263e-14\n",
            " 7.1616745e-07], argmax=7\n",
            "   \u001b[33m|->> #8/t=57-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [324 158  76  56]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [4.9291609e-15 2.4087910e-12 4.8321898e-08 3.7002543e-10 2.1620926e-10\n",
            " 2.5272600e-14 6.4222022e-13 9.9999976e-01 1.5036954e-20 1.6510325e-09\n",
            " 2.0023370e-07], argmax=7\n",
            "   \u001b[33m|->> #9/t=58-th Action selection: 3/2X RIGHT (P(a|s) = 0.7710000276565552)\u001b[0m\n",
            "      |->> Bounding box moves to: [328 158  76  56]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 1.787e-01 7.714e-01 4.510e-02 0.000e+00 0.000e+00\n",
            " 3.100e-03 0.000e+00 1.000e-04 1.600e-03], argmax=3\n",
            "         |->> Action Probabilities (RAW): [7.6221893e-12 3.2318570e-05 1.7865741e-01 7.7139640e-01 4.5108169e-02\n",
            " 8.7392027e-06 3.0482262e-12 3.0960627e-03 7.9878222e-15 9.2745518e-05\n",
            " 1.6082134e-03], argmax=3\n",
            "   \u001b[33m|->> #10/t=59-th Action selection: 7/2X DOWN (P(a|s) = 0.9850000143051147)\u001b[0m\n",
            "      |->> Bounding box moves to: [328 160  76  56]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.     0.0153 0.     0.9847 0.     0.\n",
            " 0.    ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [8.1896891e-21 6.8511980e-15 2.7548379e-13 1.0246612e-13 6.6941695e-17\n",
            " 1.5337982e-02 1.1636241e-11 9.8466206e-01 5.4412162e-26 7.8104373e-10\n",
            " 4.7648018e-13], argmax=7\n",
            "|->> Revisiting bbox: [328 158  76  56]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [320, 142,  76,  56] -> [328, 160,  76,  56] (Target was [345, 167,  92,  53])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.017) for 2X DOWN:bbox transition: [320, 142,  76,  56] -> [320, 144,  76,  56] w/ P(a|s)=0.9980335831642151 and iou=0.22593636729762384 and reward=0.016560125740214232 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.017) for 2X DOWN:bbox transition: [320, 144,  76,  56] -> [320, 146,  76,  56] w/ P(a|s)=0.9964929223060608 and iou=0.24295630869742751 and reward=0.017019941399803673 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.024) for 2X RIGHT:bbox transition: [320, 146,  76,  56] -> [324, 146,  76,  56] w/ P(a|s)=0.982063889503479 and iou=0.26710142916608853 and reward=0.02414512046866102 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.02) for 2X DOWN:bbox transition: [324, 146,  76,  56] -> [324, 148,  76,  56] w/ P(a|s)=1.0 and iou=0.28674087642665913 and reward=0.019639447260570597 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.02) for 2X DOWN:bbox transition: [324, 148,  76,  56] -> [324, 150,  76,  56] w/ P(a|s)=0.9998264908790588 and iou=0.3069987118935165 and reward=0.020257835466857388 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.021) for 2X DOWN:bbox transition: [324, 150,  76,  56] -> [324, 152,  76,  56] w/ P(a|s)=0.9992853999137878 and iou=0.3279046095681256 and reward=0.020905897674609097 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.022) for 2X DOWN:bbox transition: [324, 152,  76,  56] -> [324, 154,  76,  56] w/ P(a|s)=0.9824910759925842 and iou=0.3494901728978868 and reward=0.021585563329761193 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (0.022) for 2X DOWN:bbox transition: [324, 154,  76,  56] -> [324, 156,  76,  56] w/ P(a|s)=0.9999992847442627 and iou=0.3717890941865705 and reward=0.022298921288683715 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (0.023) for 2X DOWN:bbox transition: [324, 156,  76,  56] -> [324, 158,  76,  56] w/ P(a|s)=0.9999997615814209 and iou=0.39483733007484345 and reward=0.023048235888272928 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (0.041) for 2X RIGHT:bbox transition: [324, 158,  76,  56] -> [328, 158,  76,  56] w/ P(a|s)=0.7713963985443115 and iou=0.4360748545368769 and reward=0.04123752446203344 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (0.027) for 2X DOWN:bbox transition: [328, 158,  76,  56] -> [328, 160,  76,  56] w/ P(a|s)=0.9846620559692383 and iou=0.4632270469476045 and reward=0.027152192410727638 and discount=0.9043820750088044\n",
            "   |->> Assigned losses: [3.2596170e-05 5.9197217e-05 4.2830408e-04 1.9082110e-07 3.3767108e-06\n",
            " 1.4212257e-05 3.5897488e-04 2.0812381e-07 2.1296624e-07 9.7776661e-03\n",
            " 3.7955618e-04]\n",
            "\u001b[92m>> Total frame loss: 0.011054495349526405\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 55 with src: [328, 160,  76,  56] and target: [353, 164,  80,  54]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0055.jpg\n",
            "|->> Beginning tracking for bbox:[328 160  76  56]\n",
            "   \u001b[33m|->> #0/t=60-th Action selection: 5/2X UP (P(a|s) = 0.8830000162124634)\u001b[0m\n",
            "      |->> Bounding box moves to: [328 158  76  56]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.0731 0.0018 0.8827 0.     0.0051 0.     0.\n",
            " 0.0373], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.7047866e-09 1.2810530e-14 4.9560716e-12 7.3106162e-02 1.8157994e-03\n",
            " 8.8268310e-01 9.4971906e-09 5.1258095e-03 7.1388625e-17 4.1909308e-07\n",
            " 3.7268642e-02], argmax=5\n",
            "   \u001b[33m|->> #1/t=61-th Action selection: 10/SCALE UP (P(a|s) = 0.6740000247955322)\u001b[0m\n",
            "      |->> Bounding box moves to: [326 157  78  58]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 8.710e-02 4.000e-04 1.000e-04 0.000e+00\n",
            " 2.386e-01 0.000e+00 0.000e+00 6.738e-01], argmax=10\n",
            "         |->> Action Probabilities (RAW): [4.9198597e-12 1.6710330e-20 2.0194927e-11 8.7137662e-02 4.4798874e-04\n",
            " 8.0146805e-05 5.0612834e-07 2.3856044e-01 5.5384918e-20 3.1865014e-08\n",
            " 6.7377329e-01], argmax=10\n",
            "   \u001b[33m|->> #2/t=62-th Action selection: 7/2X DOWN (P(a|s) = 0.7279999852180481)\u001b[0m\n",
            "      |->> Bounding box moves to: [326 159  78  58]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.0087 0.     0.     0.     0.7283 0.     0.\n",
            " 0.263 ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.4476192e-12 5.8135019e-19 1.6442949e-09 8.7407483e-03 4.7048070e-06\n",
            " 2.7965788e-07 1.2219696e-08 7.2827697e-01 5.2519187e-20 3.0154180e-08\n",
            " 2.6297730e-01], argmax=7\n",
            "   \u001b[33m|->> #3/t=63-th Action selection: 7/2X DOWN (P(a|s) = 0.12300000339746475)\u001b[0m\n",
            "      |->> Bounding box moves to: [326 161  78  58]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 7.122e-01 1.390e-02 2.000e-04 0.000e+00\n",
            " 1.234e-01 0.000e+00 0.000e+00 1.503e-01], argmax=3\n",
            "         |->> Action Probabilities (RAW): [7.6247918e-11 5.2735275e-18 1.4706012e-09 7.1216971e-01 1.3921974e-02\n",
            " 2.1153476e-04 2.1911433e-09 1.2342346e-01 7.5411416e-17 2.8225890e-07\n",
            " 1.5027303e-01], argmax=3\n",
            "   \u001b[33m|->> #4/t=64-th Action selection: 7/2X DOWN (P(a|s) = 0.20499999821186066)\u001b[0m\n",
            "      |->> Bounding box moves to: [326 163  78  58]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.4135 0.     0.     0.     0.2053 0.     0.\n",
            " 0.3812], argmax=3\n",
            "         |->> Action Probabilities (RAW): [5.1751640e-14 5.2583389e-24 1.3140831e-15 4.1345361e-01 3.7415748e-06\n",
            " 1.2028647e-13 7.5796081e-13 2.0529954e-01 6.5357296e-23 8.9968333e-10\n",
            " 3.8124308e-01], argmax=3\n",
            "   \u001b[33m|->> #5/t=65-th Action selection: 3/2X RIGHT (P(a|s) = 0.9929999709129333)\u001b[0m\n",
            "      |->> Bounding box moves to: [330 163  78  58]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.993  0.     0.     0.     0.0069 0.     0.\n",
            " 0.    ], argmax=3\n",
            "         |->> Action Probabilities (RAW): [1.4732763e-13 2.0387687e-14 4.4800711e-13 9.9303049e-01 2.0542469e-05\n",
            " 1.0565715e-15 2.6369938e-14 6.9303741e-03 8.4975881e-26 4.1209626e-07\n",
            " 1.8172981e-05], argmax=3\n",
            "   \u001b[33m|->> #6/t=66-th Action selection: 5/2X UP (P(a|s) = 0.12300000339746475)\u001b[0m\n",
            "      |->> Bounding box moves to: [330 161  78  58]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.     0.1234 0.     0.8766 0.     0.\n",
            " 0.    ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [3.7418599e-15 3.9171449e-15 1.6191942e-15 4.4994563e-06 2.9214645e-08\n",
            " 1.2341127e-01 1.8001821e-11 8.7658417e-01 7.0845702e-22 2.8371878e-11\n",
            " 7.5454807e-16], argmax=7\n",
            "   \u001b[33m|->> #7/t=67-th Action selection: 4/UP (P(a|s) = 0.9959999918937683)\u001b[0m\n",
            "      |->> Bounding box moves to: [330 160  78  58]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 7.000e-04 9.961e-01 0.000e+00 0.000e+00\n",
            " 3.200e-03 0.000e+00 0.000e+00 0.000e+00], argmax=4\n",
            "         |->> Action Probabilities (RAW): [7.1547021e-07 2.3524027e-13 1.6696383e-16 7.3561631e-04 9.9607086e-01\n",
            " 3.4207506e-08 1.3233331e-14 3.1907491e-03 5.2874914e-23 4.5193174e-09\n",
            " 2.0677974e-06], argmax=4\n",
            "   \u001b[33m|->> #8/t=68-th Action selection: 4/UP (P(a|s) = 0.8550000190734863)\u001b[0m\n",
            "      |->> Bounding box moves to: [330 159  78  58]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 4.000e-04 8.547e-01 0.000e+00 0.000e+00\n",
            " 1.449e-01 0.000e+00 0.000e+00 0.000e+00], argmax=4\n",
            "         |->> Action Probabilities (RAW): [5.3420535e-11 6.2981098e-13 1.5241315e-16 4.3933556e-04 8.5466725e-01\n",
            " 2.3331065e-06 7.8504149e-15 1.4489096e-01 2.0066536e-23 1.1429878e-07\n",
            " 5.4241145e-09], argmax=4\n",
            "|->> Revisiting bbox: [330 161  78  58]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [328, 160,  76,  56] -> [330, 159,  78,  58] (Target was [353, 164,  80,  54])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.025) for 2X UP:bbox transition: [328, 160,  76,  56] -> [328, 158,  76,  56] w/ P(a|s)=0.8826830983161926 and iou=0.423166279455692 and reward=-0.02450421345450382 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.007) for SCALE UP:bbox transition: [328, 158,  76,  56] -> [326, 157,  78,  58] w/ P(a|s)=0.6737732887268066 and iou=0.4166266218164344 and reward=-0.006539657639257623 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.024) for 2X DOWN:bbox transition: [326, 157,  78,  58] -> [326, 159,  78,  58] w/ P(a|s)=0.7282769680023193 and iou=0.44015632633121643 and reward=0.023529704514782035 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.012) for 2X DOWN:bbox transition: [326, 159,  78,  58] -> [326, 161,  78,  58] w/ P(a|s)=0.12342345714569092 and iou=0.4522167487684729 and reward=0.012060422437256468 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.0) for 2X DOWN:bbox transition: [326, 161,  78,  58] -> [326, 163,  78,  58] w/ P(a|s)=0.20529954135417938 and iou=0.4522167487684729 and reward=0.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.053) for 2X RIGHT:bbox transition: [326, 163,  78,  58] -> [330, 163,  78,  58] w/ P(a|s)=0.9930304884910583 and iou=0.5056179775280899 and reward=0.053401228759617 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.0) for 2X UP:bbox transition: [330, 163,  78,  58] -> [330, 161,  78,  58] w/ P(a|s)=0.12341126799583435 and iou=0.5056179775280899 and reward=0.0 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (0.0) for UP:bbox transition: [330, 161,  78,  58] -> [330, 160,  78,  58] w/ P(a|s)=0.9960708618164062 and iou=0.5056179775280899 and reward=0.0 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (-0.014) for UP:bbox transition: [330, 160,  78,  58] -> [330, 159,  78,  58] w/ P(a|s)=0.8546672463417053 and iou=0.49165120593692024 and reward=-0.013966771591169658 and discount=0.9227446944279201\n",
            "   |->> Assigned losses: [-0.00305786 -0.00255644  0.00731219  0.0244826   0.          0.00035518\n",
            "  0.          0.         -0.00202393]\n",
            "\u001b[92m>> Total frame loss: 0.02451174147427082\u001b[0m\n",
            "Final bounding box: [330 159  78  58] reached in 69 timesteps (originating from [351 111  79  58]). Target was [353 164  80  54]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 56 in t=69 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[92m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 4.710920810699463\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.00077316869283095\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 4.6645708084106445\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.01183706521987915\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 5.635693073272705\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.023758573457598686\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 3.5774266719818115\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.013952852226793766\n",
            "Layer Name: custom_rnn/conv2d/kernel:0, GRAD NORM = 1.0905992984771729\n",
            "Layer Name: custom_rnn/conv2d/bias:0, GRAD NORM = 0.06826755404472351\n",
            "Layer Name: custom_rnn/conv2d_1/kernel:0, GRAD NORM = 11.097737312316895\n",
            "Layer Name: custom_rnn/conv2d_1/bias:0, GRAD NORM = 0.06826755404472351\n",
            "Layer Name: custom_rnn/conv2d_2/kernel:0, GRAD NORM = 7.456401824951172\n",
            "Layer Name: custom_rnn/conv2d_2/bias:0, GRAD NORM = 0.0469219908118248\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/Deer\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Starting bounding box for adnet_datasets/OTB/Deer: frames 27:37 is [269  32  89  52].\n",
            "\u001b[34m>> Attempting to reach frame 28 with src: [269,  32,  89,  52] and target: [246,  26,  86,  54]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0028.jpg\n",
            "|->> Beginning tracking for bbox:[269  32  89  52]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [269  31  89  52]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [3.0080639e-24 2.1247930e-32 6.9323639e-23 3.6099257e-27 9.9999809e-01\n",
            " 3.4783169e-32 1.4910439e-31 1.9657982e-06 0.0000000e+00 4.1599199e-25\n",
            " 2.4070259e-25], argmax=4\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [269  33  89  52]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.0497485e-22 5.4830642e-31 4.9379613e-20 1.9143968e-24 1.4535408e-05\n",
            " 3.0636022e-30 1.2637021e-34 9.9998546e-01 0.0000000e+00 9.4081579e-24\n",
            " 8.7632467e-24], argmax=7\n",
            "|->> Revisiting bbox: [269  32  89  52]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [269,  32,  89,  52] -> [269,  33,  89,  52] (Target was [246,  26,  86,  54])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.015) for UP:bbox transition: [269,  32,  89,  52] -> [269,  31,  89,  52] w/ P(a|s)=0.9999980926513672 and iou=0.49911075181891673 and reward=0.015115873457841211 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.03) for 2X DOWN:bbox transition: [269,  31,  89,  52] -> [269,  33,  89,  52] w/ P(a|s)=0.9999854564666748 and iou=0.4691807954365394 and reward=-0.029929956382377332 and discount=0.99\n",
            "   |->> Assigned losses: [ 1.5136477e-07 -4.3093758e-07]\n",
            "\u001b[31m>> Total frame loss: -2.795728164528555e-07\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 29 with src: [269,  33,  89,  52] and target: [241,  24,  87,  54]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0029.jpg\n",
            "|->> Beginning tracking for bbox:[269  33  89  52]\n",
            "   \u001b[33m|->> #0/t=3-th Action selection: 10/SCALE UP (P(a|s) = 0.7829999923706055)\u001b[0m\n",
            "      |->> Bounding box moves to: [267  32  91  54]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.2174 0.     0.     0.     0.     0.     0.     0.     0.\n",
            " 0.7826], argmax=10\n",
            "         |->> Action Probabilities (RAW): [5.2560044e-19 2.1735498e-01 1.1232981e-26 2.3915355e-15 7.1137727e-12\n",
            " 2.7738707e-07 2.7062169e-21 1.2126397e-26 1.4483029e-34 1.1704452e-18\n",
            " 7.8264475e-01], argmax=10\n",
            "   \u001b[33m|->> #1/t=4-th Action selection: 10/SCALE UP (P(a|s) = 0.8600000143051147)\u001b[0m\n",
            "      |->> Bounding box moves to: [265  31  93  56]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.     0.1396 0.     0.     0.     0.\n",
            " 0.8604], argmax=10\n",
            "         |->> Action Probabilities (RAW): [7.5019755e-19 1.2421332e-08 1.0847467e-21 4.1362866e-20 2.1214883e-12\n",
            " 1.3958777e-01 2.2556328e-14 2.9728127e-24 4.2608034e-35 1.1530561e-21\n",
            " 8.6041224e-01], argmax=10\n",
            "   \u001b[33m|->> #2/t=5-th Action selection: 5/2X UP (P(a|s) = 0.9039999842643738)\u001b[0m\n",
            "      |->> Bounding box moves to: [265  29  93  56]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.     0.9036 0.     0.     0.     0.\n",
            " 0.0964], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.6946223e-19 6.4636196e-12 1.3787472e-21 1.3206886e-13 7.8568081e-07\n",
            " 9.0358311e-01 1.1554456e-06 5.0391270e-23 2.7919877e-27 6.6019497e-19\n",
            " 9.6414909e-02], argmax=5\n",
            "   \u001b[33m|->> #3/t=6-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [265  27  93  56]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.5017394e-26 4.2104955e-22 1.1086051e-32 5.8362190e-24 1.9980460e-14\n",
            " 1.0000000e+00 1.4469391e-21 3.7717819e-18 9.0834169e-32 3.4605353e-25\n",
            " 2.3904674e-18], argmax=5\n",
            "   \u001b[33m|->> #4/t=7-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [265  25  93  56]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 8.6165278e-28 0.0000000e+00 1.3295617e-38 2.8031354e-20\n",
            " 9.9996412e-01 0.0000000e+00 1.9304604e-31 0.0000000e+00 0.0000000e+00\n",
            " 3.5897396e-05], argmax=5\n",
            "   \u001b[33m|->> #5/t=8-th Action selection: 5/2X UP (P(a|s) = 0.9399999976158142)\u001b[0m\n",
            "      |->> Bounding box moves to: [265  23  93  56]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.     0.9403 0.     0.     0.     0.\n",
            " 0.0597], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.8099262e-36 5.3335835e-30 0.0000000e+00 0.0000000e+00 6.8760010e-21\n",
            " 9.4025624e-01 0.0000000e+00 2.1321110e-20 3.0309433e-34 0.0000000e+00\n",
            " 5.9743725e-02], argmax=5\n",
            "   \u001b[33m|->> #6/t=9-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [265  21  93  56]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.9571677e-28 8.9031546e-29 4.5483635e-36 4.0154692e-33 5.3620372e-08\n",
            " 1.0000000e+00 0.0000000e+00 3.5672070e-13 7.1493501e-31 4.6118946e-34\n",
            " 6.9368240e-11], argmax=5\n",
            "   \u001b[33m|->> #7/t=10-th Action selection: 5/2X UP (P(a|s) = 0.9190000295639038)\u001b[0m\n",
            "      |->> Bounding box moves to: [265  19  93  56]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.0808 0.9192 0.     0.     0.     0.\n",
            " 0.    ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [4.2816992e-33 2.7116312e-20 4.2945871e-19 1.0338206e-17 8.0777101e-02\n",
            " 9.1922295e-01 1.2759284e-36 3.2814427e-09 7.7303977e-30 2.4378884e-19\n",
            " 5.5286006e-14], argmax=5\n",
            "   \u001b[33m|->> #8/t=11-th Action selection: 5/2X UP (P(a|s) = 0.9940000176429749)\u001b[0m\n",
            "      |->> Bounding box moves to: [265  17  93  56]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.0045 0.994  0.     0.     0.     0.\n",
            " 0.0015], argmax=5\n",
            "         |->> Action Probabilities (RAW): [8.6606692e-33 9.6734498e-16 8.3235081e-20 4.4354020e-25 4.5211557e-03\n",
            " 9.9395978e-01 2.5135896e-34 4.8422713e-08 3.2130559e-33 6.3141216e-21\n",
            " 1.5190319e-03], argmax=5\n",
            "   \u001b[33m|->> #9/t=12-th Action selection: 5/2X UP (P(a|s) = 0.996999979019165)\u001b[0m\n",
            "      |->> Bounding box moves to: [265  15  93  56]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.     0.9974 0.     0.0026 0.     0.\n",
            " 0.    ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [4.62219156e-20 1.92310469e-12 4.10517853e-16 3.31579308e-27\n",
            " 1.04569814e-07 9.97438908e-01 9.37976972e-22 2.56079226e-03\n",
            " 1.82078621e-31 5.42364197e-24 1.08078495e-07], argmax=5\n",
            "|->> Revisiting bbox: [265  17  93  56]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [269,  33,  89,  52] -> [265,  15,  93,  56] (Target was [241,  24,  87,  54])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.014) for SCALE UP:bbox transition: [269,  33,  89,  52] -> [267,  32,  91,  54] w/ P(a|s)=0.7826447486877441 and iou=0.4122832794593006 and reward=0.014291973807973979 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.014) for SCALE UP:bbox transition: [267,  32,  91,  54] -> [265,  31,  93,  56] w/ P(a|s)=0.8604122400283813 and iou=0.4263498920086393 and reward=0.01406661254933872 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.026) for 2X UP:bbox transition: [265,  31,  93,  56] -> [265,  29,  93,  56] w/ P(a|s)=0.9035831093788147 and iou=0.4527056753189617 and reward=0.0263557833103224 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.027) for 2X UP:bbox transition: [265,  29,  93,  56] -> [265,  27,  93,  56] w/ P(a|s)=1.0 and iou=0.48005378753922007 and reward=0.027348112220258347 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.028) for 2X UP:bbox transition: [265,  27,  93,  56] -> [265,  25,  93,  56] w/ P(a|s)=0.9999641180038452 and iou=0.5084513476473276 and reward=0.02839756010810751 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.015) for 2X UP:bbox transition: [265,  25,  93,  56] -> [265,  23,  93,  56] w/ P(a|s)=0.9402562379837036 and iou=0.5230627306273062 and reward=0.01461138297997866 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (-0.015) for 2X UP:bbox transition: [265,  23,  93,  56] -> [265,  21,  93,  56] w/ P(a|s)=1.0 and iou=0.5084513476473276 and reward=-0.01461138297997866 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (-0.028) for 2X UP:bbox transition: [265,  21,  93,  56] -> [265,  19,  93,  56] w/ P(a|s)=0.9192229509353638 and iou=0.48005378753922007 and reward=-0.02839756010810751 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (-0.027) for 2X UP:bbox transition: [265,  19,  93,  56] -> [265,  17,  93,  56] w/ P(a|s)=0.9939597845077515 and iou=0.4527056753189617 and reward=-0.027348112220258347 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (-0.026) for 2X UP:bbox transition: [265,  17,  93,  56] -> [265,  15,  93,  56] w/ P(a|s)=0.997438907623291 and iou=0.4263498920086393 and reward=-0.0263557833103224 and discount=0.9135172474836408\n",
            "   |->> Assigned losses: [ 3.5026253e-03  2.0936776e-03  2.6189631e-03  2.6572016e-07\n",
            "  9.7882764e-07  8.5598876e-04 -1.3775077e-07 -2.2293415e-03\n",
            " -1.5288901e-04 -6.1741142e-05]\n",
            "\u001b[92m>> Total frame loss: 0.006628389935940504\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 30 with src: [265,  15,  93,  56] and target: [238,  24,  86,  54]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0030.jpg\n",
            "|->> Beginning tracking for bbox:[265  15  93  56]\n",
            "   \u001b[33m|->> #0/t=13-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [265  13  93  56]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 0.0000000e+00 4.7818730e-27 0.0000000e+00 8.1969912e-23\n",
            " 1.0000000e+00 0.0000000e+00 8.7735205e-14 0.0000000e+00 0.0000000e+00\n",
            " 2.8796100e-16], argmax=5\n",
            "|->> Revisiting bbox: [265  15  93  56]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [265,  15,  93,  56] -> [265,  13,  93,  56] (Target was [238,  24,  86,  54])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.023) for 2X UP:bbox transition: [265,  15,  93,  56] -> [265,  13,  93,  56] w/ P(a|s)=1.0 and iou=0.3689037098791163 and reward=-0.02281828475289388 and discount=1.0\n",
            "   |->> Assigned losses: [-2.2849386e-07]\n",
            "\u001b[31m>> Total frame loss: -2.2849386027701257e-07\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 31 with src: [265,  13,  93,  56] and target: [243,  26,  85,  60]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0031.jpg\n",
            "|->> Beginning tracking for bbox:[265  13  93  56]\n",
            "   \u001b[33m|->> #0/t=14-th Action selection: 5/2X UP (P(a|s) = 0.9710000157356262)\u001b[0m\n",
            "      |->> Bounding box moves to: [265  11  93  56]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 2.000e-04 0.000e+00 0.000e+00 9.708e-01 0.000e+00\n",
            " 2.900e-02 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.6999905e-17 6.4647202e-07 2.0834530e-04 2.8593354e-19 1.0829645e-13\n",
            " 9.7081035e-01 1.5304220e-19 2.8980305e-02 3.9111187e-23 5.8238134e-09\n",
            " 3.1642273e-07], argmax=5\n",
            "|->> Revisiting bbox: [265  13  93  56]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [265,  13,  93,  56] -> [265,  11,  93,  56] (Target was [243,  26,  85,  60])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.022) for 2X UP:bbox transition: [265,  13,  93,  56] -> [265,  11,  93,  56] w/ P(a|s)=0.9708103537559509 and iou=0.33436893203883494 and reward=-0.02212534352373907 and discount=1.0\n",
            "   |->> Assigned losses: [-0.00065544]\n",
            "\u001b[31m>> Total frame loss: -0.0006554442807100713\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 32 with src: [265,  11,  93,  56] and target: [253,  34,  85,  58]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0032.jpg\n",
            "|->> Beginning tracking for bbox:[265  11  93  56]\n",
            "   \u001b[33m|->> #0/t=15-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [265  13  93  56]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [2.5658579e-08 1.7736394e-20 1.2546664e-26 4.4842328e-17 2.8757277e-21\n",
            " 4.6786339e-09 6.2547025e-12 1.0000000e+00 4.6363558e-21 7.0941889e-19\n",
            " 4.7591832e-18], argmax=7\n",
            "   \u001b[33m|->> #1/t=16-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [265  15  93  56]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.0766498e-06 1.6988515e-14 4.9559729e-28 3.4557306e-17 6.1428358e-17\n",
            " 1.0663588e-15 5.7386687e-12 9.9999893e-01 5.5642893e-21 2.5032739e-19\n",
            " 1.2000468e-15], argmax=7\n",
            "   \u001b[33m|->> #2/t=17-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [265  17  93  56]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.5682607e-09 9.1265130e-14 7.5397607e-27 1.7213033e-21 1.3067034e-22\n",
            " 2.4075228e-16 1.7289382e-12 9.9999011e-01 3.8651281e-23 5.7996597e-14\n",
            " 9.9269964e-06], argmax=7\n",
            "   \u001b[33m|->> #3/t=18-th Action selection: 7/2X DOWN (P(a|s) = 0.8849999904632568)\u001b[0m\n",
            "      |->> Bounding box moves to: [265  19  93  56]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 3.000e-04 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            " 8.847e-01 0.000e+00 1.150e-01 0.000e+00], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.2127039e-06 3.4221823e-04 2.7404651e-19 6.4363295e-22 1.3021752e-20\n",
            " 3.0048254e-13 3.6699050e-11 8.8470179e-01 1.2630514e-19 1.1495472e-01\n",
            " 7.8144105e-08], argmax=7\n",
            "   \u001b[33m|->> #4/t=19-th Action selection: 9/SCALE DOWN (P(a|s) = 0.9700000286102295)\u001b[0m\n",
            "      |->> Bounding box moves to: [266  20  90  54]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.     0.     0.     0.0297 0.     0.9703\n",
            " 0.    ], argmax=9\n",
            "         |->> Action Probabilities (RAW): [4.1697272e-13 1.8584349e-11 2.5884691e-21 4.2915142e-29 1.1886552e-21\n",
            " 1.8597558e-09 3.6750025e-20 2.9722830e-02 2.7644056e-26 9.7027719e-01\n",
            " 9.1931103e-09], argmax=9\n",
            "   \u001b[33m|->> #5/t=20-th Action selection: 7/2X DOWN (P(a|s) = 0.9980000257492065)\u001b[0m\n",
            "      |->> Bounding box moves to: [266  22  90  54]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 2.000e-04 0.000e+00\n",
            " 9.982e-01 0.000e+00 1.700e-03 0.000e+00], argmax=7\n",
            "         |->> Action Probabilities (RAW): [4.6463336e-16 6.7323835e-10 2.6153413e-23 5.2329539e-29 4.1227623e-21\n",
            " 1.5229425e-04 1.4312116e-20 9.9818170e-01 1.7481752e-26 1.6660382e-03\n",
            " 1.5443241e-09], argmax=7\n",
            "   \u001b[33m|->> #6/t=21-th Action selection: 7/2X DOWN (P(a|s) = 0.8489999771118164)\u001b[0m\n",
            "      |->> Bounding box moves to: [266  24  90  54]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.     0.0084 0.     0.8491 0.     0.1425\n",
            " 0.    ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [3.45072752e-15 2.83900881e-09 1.98043986e-20 7.50514377e-24\n",
            " 2.29888051e-16 8.35612230e-03 1.22887466e-23 8.49095881e-01\n",
            " 2.70522980e-33 1.42521486e-01 2.64716127e-05], argmax=7\n",
            "   \u001b[33m|->> #7/t=22-th Action selection: 10/SCALE UP (P(a|s) = 0.9010000228881836)\u001b[0m\n",
            "      |->> Bounding box moves to: [264  23  92  56]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.     0.     0.     0.     0.     0.0991\n",
            " 0.9009], argmax=10\n",
            "         |->> Action Probabilities (RAW): [8.9878302e-19 5.1790860e-08 1.1530517e-27 2.5049092e-20 9.1747465e-13\n",
            " 1.4323927e-12 2.5968081e-26 2.9903413e-06 1.1528569e-29 9.9053472e-02\n",
            " 9.0094358e-01], argmax=10\n",
            "   \u001b[33m|->> #8/t=23-th Action selection: 10/SCALE UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [262  22  94  58]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.], argmax=10\n",
            "         |->> Action Probabilities (RAW): [1.79263075e-27 4.80081415e-13 5.66947373e-29 2.65372778e-26\n",
            " 3.38085983e-11 4.23481070e-18 1.09766384e-32 7.22580145e-13\n",
            " 2.77295285e-37 2.38058405e-07 9.99999762e-01], argmax=10\n",
            "   \u001b[33m|->> #9/t=24-th Action selection: 10/SCALE UP (P(a|s) = 0.9940000176429749)\u001b[0m\n",
            "      |->> Bounding box moves to: [260  21  96  60]\n",
            "         |->> Action Probabilities (Rounded): [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.006 0.994], argmax=10\n",
            "         |->> Action Probabilities (RAW): [9.7108438e-27 1.3771607e-10 6.4347006e-21 2.9647729e-26 2.5249501e-06\n",
            " 1.3559415e-14 5.9603322e-34 2.8014093e-09 6.5322689e-36 5.9661134e-03\n",
            " 9.9403137e-01], argmax=10\n",
            "   \u001b[33m|->> #10/t=25-th Action selection: 9/SCALE DOWN (P(a|s) = 0.7770000100135803)\u001b[0m\n",
            "      |->> Bounding box moves to: [261  22  93  58]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.     0.     0.     0.0055 0.     0.7766\n",
            " 0.2179], argmax=9\n",
            "         |->> Action Probabilities (RAW): [2.1291585e-20 1.6247221e-06 9.6358595e-22 9.3186344e-25 5.5826640e-06\n",
            " 2.2723436e-12 7.8966184e-34 5.4701744e-03 4.5549848e-33 7.7661121e-01\n",
            " 2.1791145e-01], argmax=9\n",
            "   \u001b[33m|->> #11/t=26-th Action selection: 10/SCALE UP (P(a|s) = 0.4000000059604645)\u001b[0m\n",
            "      |->> Bounding box moves to: [259  21  95  60]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.     0.     0.     0.     0.     0.5998\n",
            " 0.4001], argmax=9\n",
            "         |->> Action Probabilities (RAW): [2.6598577e-20 3.6091842e-07 3.5702434e-20 1.3775990e-24 1.7627863e-05\n",
            " 6.3236222e-10 1.0237126e-33 2.7169166e-05 5.4528362e-31 5.9982342e-01\n",
            " 4.0013137e-01], argmax=9\n",
            "   \u001b[33m|->> #12/t=27-th Action selection: 10/SCALE UP (P(a|s) = 0.28700000047683716)\u001b[0m\n",
            "      |->> Bounding box moves to: [257  20  97  62]\n",
            "         |->> Action Probabilities (Rounded): [0.00e+00 3.00e-04 0.00e+00 0.00e+00 4.60e-03 0.00e+00 0.00e+00 1.00e-04\n",
            " 0.00e+00 7.08e-01 2.87e-01], argmax=9\n",
            "         |->> Action Probabilities (RAW): [1.1856382e-14 2.8002667e-04 9.0279321e-15 3.1832821e-20 4.6459772e-03\n",
            " 2.9767216e-11 5.9895218e-28 6.4484368e-05 2.9784179e-27 7.0797247e-01\n",
            " 2.8703707e-01], argmax=9\n",
            "   \u001b[33m|->> #13/t=28-th Action selection: 4/UP (P(a|s) = 0.9769999980926514)\u001b[0m\n",
            "      |->> Bounding box moves to: [257  19  97  62]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 2.100e-02 0.000e+00 0.000e+00 9.768e-01 0.000e+00 0.000e+00\n",
            " 6.000e-04 0.000e+00 1.500e-03 0.000e+00], argmax=4\n",
            "         |->> Action Probabilities (RAW): [6.5545590e-11 2.1039667e-02 3.5056051e-12 1.1874297e-14 9.7679728e-01\n",
            " 6.0688371e-11 1.6100929e-21 6.3217035e-04 7.9368211e-24 1.5040236e-03\n",
            " 2.6840718e-05], argmax=4\n",
            "   \u001b[33m|->> #14/t=29-th Action selection: 4/UP (P(a|s) = 0.4169999957084656)\u001b[0m\n",
            "      |->> Bounding box moves to: [257  18  97  62]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.059  0.     0.     0.4168 0.     0.     0.5242 0.     0.\n",
            " 0.    ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [3.0114153e-09 5.8958832e-02 2.1349619e-12 5.1686179e-17 4.1679749e-01\n",
            " 5.2316331e-08 5.8287544e-23 5.2424097e-01 1.9113379e-27 2.6191854e-06\n",
            " 9.7538178e-10], argmax=7\n",
            "|->> Revisiting bbox: [257  20  97  62]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [265,  11,  93,  56] -> [257,  18,  97,  62] (Target was [253,  34,  85,  58])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.025) for 2X DOWN:bbox transition: [265,  11,  93,  56] -> [265,  13,  93,  56] w/ P(a|s)=1.0 and iou=0.336937887379665 and reward=0.025254616581372846 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.026) for 2X DOWN:bbox transition: [265,  13,  93,  56] -> [265,  15,  93,  56] w/ P(a|s)=0.999998927116394 and iou=0.36318407960199006 and reward=0.02624619222232505 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.027) for 2X DOWN:bbox transition: [265,  15,  93,  56] -> [265,  17,  93,  56] w/ P(a|s)=0.9999901056289673 and iou=0.3904814154436977 and reward=0.027297335841707626 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.028) for 2X DOWN:bbox transition: [265,  17,  93,  56] -> [265,  19,  93,  56] w/ P(a|s)=0.8847017884254456 and iou=0.41889433170048984 and reward=0.028412916256792153 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-0.002) for SCALE DOWN:bbox transition: [265,  19,  93,  56] -> [266,  20,  90,  54] w/ P(a|s)=0.9702771902084351 and iou=0.41678726483357453 and reward=-0.002107066866915308 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.03) for 2X DOWN:bbox transition: [266,  20,  90,  54] -> [266,  22,  90,  54] w/ P(a|s)=0.9981817007064819 and iou=0.4469405852793379 and reward=0.030153320445763354 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.031) for 2X DOWN:bbox transition: [266,  22,  90,  54] -> [266,  24,  90,  54] w/ P(a|s)=0.84909588098526 and iou=0.47840531561461797 and reward=0.03146473033528008 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (0.015) for SCALE UP:bbox transition: [266,  24,  90,  54] -> [264,  23,  92,  56] w/ P(a|s)=0.9009435772895813 and iou=0.4931872037914692 and reward=0.014781888176851221 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (0.015) for SCALE UP:bbox transition: [264,  23,  92,  56] -> [262,  22,  94,  58] w/ P(a|s)=0.9999997615814209 and iou=0.5076967760673831 and reward=0.014509572275913873 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (0.014) for SCALE UP:bbox transition: [262,  22,  94,  58] -> [260,  21,  96,  60] w/ P(a|s)=0.9940313696861267 and iou=0.5219248291571754 and reward=0.014228053089792358 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (0.0) for SCALE DOWN:bbox transition: [260,  21,  96,  60] -> [261,  22,  93,  58] w/ P(a|s)=0.7766112089157104 and iou=0.52226481863757 and reward=0.000339989480394598 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (0.015) for SCALE UP:bbox transition: [261,  22,  93,  58] -> [259,  21,  95,  60] w/ P(a|s)=0.40013137459754944 and iou=0.5367934075466243 and reward=0.014528588909054285 and discount=0.8953382542587164\n",
            "   |->> t=13 Diff-Reward (0.014) for SCALE UP:bbox transition: [259,  21,  95,  60] -> [257,  20,  97,  62] w/ P(a|s)=0.28703707456588745 and iou=0.5510204081632653 and reward=0.01422700061664095 and discount=0.8863848717161292\n",
            "   |->> t=14 Diff-Reward (-0.018) for UP:bbox transition: [257,  20,  97,  62] -> [257,  19,  97,  62] w/ P(a|s)=0.9767972826957703 and iou=0.5334174022698613 and reward=-0.01760300589340391 and discount=0.8775210229989678\n",
            "   |->> t=15 Diff-Reward (-0.017) for UP:bbox transition: [257,  19,  97,  62] -> [257,  18,  97,  62] w/ P(a|s)=0.4167974889278412 and iou=0.516209476309227 and reward=-0.017207925960634363 and discount=0.8687458127689782\n",
            "   |->> Assigned losses: [ 2.5289040e-07  2.6019148e-07  2.6790585e-07  3.3773337e-03\n",
            " -6.1072344e-05  5.2188116e-05  4.8458925e-03  1.4371868e-03\n",
            "  1.3406880e-07  7.7810146e-05  7.7735785e-05  1.1914839e-02\n",
            "  1.5739841e-02 -3.6263611e-04 -1.3082963e-02]\n",
            "\u001b[92m>> Total frame loss: 0.02401706948876381\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 33 with src: [257,  18,  97,  62] and target: [271,  49,  85,  56]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0033.jpg\n",
            "|->> Beginning tracking for bbox:[257  18  97  62]\n",
            "   \u001b[33m|->> #0/t=30-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [257  20  97  62]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [2.3736219e-17 3.0637721e-17 4.0121059e-23 9.1676841e-19 2.4090446e-23\n",
            " 4.7364018e-17 1.4181706e-10 1.0000000e+00 5.7018987e-22 5.8829949e-19\n",
            " 9.6977005e-15], argmax=7\n",
            "   \u001b[33m|->> #1/t=31-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [257  22  97  62]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.57097399e-20 9.12930043e-18 1.19083336e-20 5.19785077e-18\n",
            " 1.84845733e-26 4.64181334e-18 1.02021325e-08 1.00000000e+00\n",
            " 6.06772549e-27 2.43265613e-17 3.89869750e-13], argmax=7\n",
            "   \u001b[33m|->> #2/t=32-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [257  24  97  62]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [9.3942565e-17 5.0980091e-14 3.8654573e-15 7.9384450e-14 4.3213906e-20\n",
            " 2.0556502e-13 1.3435473e-06 9.9999869e-01 7.0552958e-25 5.3883650e-13\n",
            " 8.5146992e-09], argmax=7\n",
            "   \u001b[33m|->> #3/t=33-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [257  26  97  62]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [5.9025046e-12 1.0301294e-10 1.3468499e-13 3.0777438e-15 5.1233372e-15\n",
            " 1.4653705e-12 2.0757792e-08 9.9999785e-01 8.4314569e-18 2.1437868e-06\n",
            " 1.3103772e-11], argmax=7\n",
            "   \u001b[33m|->> #4/t=34-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [257  28  97  62]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [2.8313163e-21 8.6556366e-15 3.6958529e-18 1.2592363e-18 3.1546562e-16\n",
            " 5.5518029e-15 9.2495416e-17 1.0000000e+00 6.9408179e-23 1.0466064e-12\n",
            " 6.4493399e-18], argmax=7\n",
            "   \u001b[33m|->> #5/t=35-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [257  30  97  62]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.57583718e-18 4.86961328e-13 3.94168271e-17 4.63307170e-19\n",
            " 5.79399321e-13 2.49119319e-11 1.13052737e-23 1.00000000e+00\n",
            " 1.02099655e-29 2.74278321e-13 1.33295971e-10], argmax=7\n",
            "   \u001b[33m|->> #6/t=36-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [257  32  97  62]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            " 9.998e-01 0.000e+00 0.000e+00 2.000e-04], argmax=7\n",
            "         |->> Action Probabilities (RAW): [7.8630192e-19 1.5351408e-11 2.2917503e-15 3.9047312e-19 4.6905552e-10\n",
            " 2.7730254e-10 2.0399938e-26 9.9977952e-01 3.8923234e-29 2.6354216e-10\n",
            " 2.2054769e-04], argmax=7\n",
            "   \u001b[33m|->> #7/t=37-th Action selection: 7/2X DOWN (P(a|s) = 0.8299999833106995)\u001b[0m\n",
            "      |->> Bounding box moves to: [257  34  97  62]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.     0.     0.     0.8299 0.     0.\n",
            " 0.1701], argmax=7\n",
            "         |->> Action Probabilities (RAW): [3.7061424e-17 8.9701068e-12 4.9781363e-15 7.6087730e-14 2.7849872e-11\n",
            " 1.1939709e-12 5.4573449e-24 8.2994574e-01 1.6308096e-24 3.2796557e-09\n",
            " 1.7005420e-01], argmax=7\n",
            "   \u001b[33m|->> #8/t=38-th Action selection: 7/2X DOWN (P(a|s) = 0.9259999990463257)\u001b[0m\n",
            "      |->> Bounding box moves to: [257  36  97  62]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 5.000e-04 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            " 9.257e-01 0.000e+00 5.100e-03 6.870e-02], argmax=7\n",
            "         |->> Action Probabilities (RAW): [4.8090104e-19 5.0149119e-04 1.3781113e-07 4.6766824e-15 3.7652013e-12\n",
            " 2.8680909e-06 1.6147006e-17 9.2571867e-01 3.0690953e-20 5.0717504e-03\n",
            " 6.8705022e-02], argmax=7\n",
            "   \u001b[33m|->> #9/t=39-th Action selection: 1/2X LEFT (P(a|s) = 0.5289999842643738)\u001b[0m\n",
            "      |->> Bounding box moves to: [253  36  97  62]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.529  0.     0.     0.     0.     0.     0.4699 0.     0.\n",
            " 0.001 ], argmax=1\n",
            "         |->> Action Probabilities (RAW): [1.65458314e-19 5.29049456e-01 3.69709993e-14 2.96560194e-18\n",
            " 1.09623820e-11 6.65318248e-06 5.63100294e-20 4.69940066e-01\n",
            " 1.36360672e-25 1.08958266e-10 1.00381626e-03], argmax=1\n",
            "   \u001b[33m|->> #10/t=40-th Action selection: 1/2X LEFT (P(a|s) = 0.6460000276565552)\u001b[0m\n",
            "      |->> Bounding box moves to: [249  36  97  62]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.6461 0.     0.     0.     0.0009 0.     0.2736 0.     0.\n",
            " 0.0794], argmax=1\n",
            "         |->> Action Probabilities (RAW): [4.1505118e-19 6.4607519e-01 6.7447289e-14 8.8830080e-22 2.1261458e-12\n",
            " 8.6851441e-04 2.4992733e-17 2.7362233e-01 3.4076761e-27 3.7541776e-07\n",
            " 7.9433560e-02], argmax=1\n",
            "   \u001b[33m|->> #11/t=41-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [249  34  97  62]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.6906222e-15 6.7480634e-08 7.8641135e-21 7.8874133e-17 5.7384233e-15\n",
            " 9.9999976e-01 2.3769062e-13 1.0440182e-08 6.0384545e-24 9.5223228e-08\n",
            " 1.9935825e-08], argmax=5\n",
            "   \u001b[33m|->> #12/t=42-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [249  32  97  62]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.0290237e-15 2.0563702e-14 4.4700940e-20 4.0435966e-16 1.4332843e-11\n",
            " 9.9999833e-01 3.8379893e-14 4.4575499e-10 3.0774158e-23 1.6476966e-06\n",
            " 4.9406523e-09], argmax=5\n",
            "   \u001b[33m|->> #13/t=43-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [249  30  97  62]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.1530473e-19 6.8656944e-21 2.8210649e-20 2.4117066e-19 1.7996601e-13\n",
            " 9.9999988e-01 2.5529106e-20 1.4086805e-07 2.1398843e-26 3.8113016e-11\n",
            " 9.0721236e-10], argmax=5\n",
            "|->> Revisiting bbox: [249  32  97  62]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [257,  18,  97,  62] -> [249,  30,  97,  62] (Target was [271,  49,  85,  56])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.027) for 2X DOWN:bbox transition: [257,  18,  97,  62] -> [257,  20,  97,  62] w/ P(a|s)=1.0 and iou=0.34088363410080896 and reward=0.027141407543072094 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.028) for 2X DOWN:bbox transition: [257,  20,  97,  62] -> [257,  22,  97,  62] w/ P(a|s)=1.0 and iou=0.36917016139280723 and reward=0.028286527291998265 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.03) for 2X DOWN:bbox transition: [257,  22,  97,  62] -> [257,  24,  97,  62] w/ P(a|s)=0.9999986886978149 and iou=0.3986758405815916 and reward=0.029505679188784384 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.031) for 2X DOWN:bbox transition: [257,  24,  97,  62] -> [257,  26,  97,  62] w/ P(a|s)=0.9999978542327881 and iou=0.4294812259519703 and reward=0.03080538537037869 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.032) for 2X DOWN:bbox transition: [257,  26,  97,  62] -> [257,  28,  97,  62] w/ P(a|s)=1.0 and iou=0.461674128340795 and reward=0.03219290238882472 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.034) for 2X DOWN:bbox transition: [257,  28,  97,  62] -> [257,  30,  97,  62] w/ P(a|s)=1.0 and iou=0.4953504510756419 and reward=0.033676322734846886 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.035) for 2X DOWN:bbox transition: [257,  30,  97,  62] -> [257,  32,  97,  62] w/ P(a|s)=0.9997795224189758 and iou=0.5306151441966188 and reward=0.03526469312097691 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (0.037) for 2X DOWN:bbox transition: [257,  32,  97,  62] -> [257,  34,  97,  62] w/ P(a|s)=0.8299457430839539 and iou=0.5675832969591154 and reward=0.03696815276249654 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (0.039) for 2X DOWN:bbox transition: [257,  34,  97,  62] -> [257,  36,  97,  62] w/ P(a|s)=0.9257186651229858 and iou=0.6063813925749217 and reward=0.03879809561580638 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (-0.046) for 2X LEFT:bbox transition: [257,  36,  97,  62] -> [253,  36,  97,  62] w/ P(a|s)=0.5290494561195374 and iou=0.5607706794147472 and reward=-0.04561071316017451 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (-0.043) for 2X LEFT:bbox transition: [253,  36,  97,  62] -> [249,  36,  97,  62] w/ P(a|s)=0.6460751891136169 and iou=0.5176785462741231 and reward=-0.0430921331406241 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (-0.031) for 2X UP:bbox transition: [249,  36,  97,  62] -> [249,  34,  97,  62] w/ P(a|s)=0.9999997615814209 and iou=0.486273968823286 and reward=-0.031404577450837134 and discount=0.8953382542587164\n",
            "   |->> t=13 Diff-Reward (-0.03) for 2X UP:bbox transition: [249,  34,  97,  62] -> [249,  32,  97,  62] w/ P(a|s)=0.9999983310699463 and iou=0.45614272198945804 and reward=-0.03013124683382795 and discount=0.8863848717161292\n",
            "   |->> t=14 Diff-Reward (-0.029) for 2X UP:bbox transition: [249,  32,  97,  62] -> [249,  30,  97,  62] w/ P(a|s)=0.9999998807907104 and iou=0.4272089018413035 and reward=-0.028933820148154543 and discount=0.8775210229989678\n",
            "   |->> Assigned losses: [ 2.7178402e-07  2.8041833e-07  2.8957933e-07  2.9931178e-07\n",
            "  3.0966524e-07  3.2069499e-07  7.3208848e-06  6.4225611e-03\n",
            "  2.7632765e-03 -2.6527744e-02 -1.7024396e-02 -2.8156043e-07\n",
            " -2.6744283e-07 -2.5424643e-07]\n",
            "\u001b[31m>> Total frame loss: -0.034358009696006775\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 34 with src: [249,  30,  97,  62] and target: [285,  69,  84,  60]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0034.jpg\n",
            "|->> Beginning tracking for bbox:[249  30  97  62]\n",
            "   \u001b[33m|->> #0/t=44-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [249  32  97  62]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [8.0635680e-12 3.3794971e-09 1.8831287e-15 2.3261334e-12 7.6503245e-15\n",
            " 1.9886995e-15 1.3809413e-15 1.0000000e+00 1.4269189e-24 2.2222014e-11\n",
            " 5.9041055e-19], argmax=7\n",
            "   \u001b[33m|->> #1/t=45-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [249  34  97  62]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.6127182e-14 4.1355371e-14 3.5075942e-19 2.1240327e-12 5.3402592e-22\n",
            " 6.8670818e-14 1.5382712e-17 1.0000000e+00 4.8312946e-24 2.8654102e-15\n",
            " 2.7078053e-17], argmax=7\n",
            "   \u001b[33m|->> #2/t=46-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [249  36  97  62]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.0536944e-24 2.9599994e-24 7.9605549e-27 3.8985309e-22 1.4188507e-35\n",
            " 1.9870914e-23 2.6098980e-25 1.0000000e+00 1.6835558e-38 1.0320413e-25\n",
            " 2.1034350e-31], argmax=7\n",
            "   \u001b[33m|->> #3/t=47-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [249  38  97  62]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [5.66638986e-19 1.76336080e-17 2.72507267e-22 7.67595418e-17\n",
            " 4.02076250e-23 1.61597971e-17 7.84520873e-21 1.00000000e+00\n",
            " 9.13128376e-26 1.29223437e-18 1.01473945e-25], argmax=7\n",
            "   \u001b[33m|->> #4/t=48-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [249  40  97  62]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [4.70150748e-28 3.64555698e-25 1.31441538e-37 2.49963456e-24\n",
            " 2.93707871e-30 1.37014000e-26 7.96671003e-30 1.00000000e+00\n",
            " 1.07563706e-32 8.90303684e-25 2.48916462e-34], argmax=7\n",
            "   \u001b[33m|->> #5/t=49-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [249  42  97  62]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.3538200e-20 3.6154627e-25 1.6415371e-36 6.0867167e-18 4.2215746e-23\n",
            " 1.6632001e-22 5.1164863e-25 1.0000000e+00 4.0264561e-31 4.6610178e-23\n",
            " 1.2907211e-27], argmax=7\n",
            "   \u001b[33m|->> #6/t=50-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [249  44  97  62]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [2.6948735e-24 1.4182245e-33 0.0000000e+00 2.7052614e-20 1.6809663e-27\n",
            " 1.8632596e-27 6.7409135e-30 1.0000000e+00 2.3687303e-38 8.8907246e-31\n",
            " 9.4649115e-33], argmax=7\n",
            "   \u001b[33m|->> #7/t=51-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [249  46  97  62]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [6.6025619e-32 6.1930637e-36 0.0000000e+00 6.3731170e-23 5.7701641e-23\n",
            " 1.8089084e-23 5.3975417e-30 1.0000000e+00 2.0820748e-36 8.6452753e-30\n",
            " 1.9270128e-31], argmax=7\n",
            "   \u001b[33m|->> #8/t=52-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [249  48  97  62]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [2.3082340e-38 0.0000000e+00 0.0000000e+00 1.3254618e-23 3.3677918e-28\n",
            " 9.1365547e-24 3.5045886e-32 1.0000000e+00 2.9667392e-30 1.6363922e-35\n",
            " 1.2665709e-37], argmax=7\n",
            "   \u001b[33m|->> #9/t=53-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [249  50  97  62]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [2.4962481e-27 1.8365636e-35 2.5662290e-35 6.9930411e-23 1.8336061e-16\n",
            " 4.0166952e-18 2.3294802e-24 1.0000000e+00 1.1245089e-25 4.2234733e-24\n",
            " 3.6424052e-23], argmax=7\n",
            "   \u001b[33m|->> #10/t=54-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [249  52  97  62]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [2.6181103e-13 1.3969895e-23 4.4636164e-24 1.9565888e-13 2.1620093e-07\n",
            " 7.4257892e-11 9.5675781e-16 9.9999976e-01 8.9379873e-24 2.1458726e-14\n",
            " 6.9283689e-12], argmax=7\n",
            "   \u001b[33m|->> #11/t=55-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [249  54  97  62]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.14329466e-12 2.30304653e-13 7.49114990e-20 1.05162390e-09\n",
            " 3.41651258e-07 1.27383842e-07 5.49991270e-08 9.99999523e-01\n",
            " 2.39417694e-21 1.15514965e-14 4.74084549e-10], argmax=7\n",
            "|->> Revisiting bbox: [249  52  97  62]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [249,  30,  97,  62] -> [249,  54,  97,  62] (Target was [285,  69,  84,  60])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.015) for 2X DOWN:bbox transition: [249,  30,  97,  62] -> [249,  32,  97,  62] w/ P(a|s)=1.0 and iou=0.16003777941022143 and reward=0.014664242989125165 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.015) for 2X DOWN:bbox transition: [249,  32,  97,  62] -> [249,  34,  97,  62] w/ P(a|s)=1.0 and iou=0.17508238545763793 and reward=0.015044606047416503 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.015) for 2X DOWN:bbox transition: [249,  34,  97,  62] -> [249,  36,  97,  62] w/ P(a|s)=1.0 and iou=0.1905223478729133 and reward=0.015439962415275371 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.016) for 2X DOWN:bbox transition: [249,  36,  97,  62] -> [249,  38,  97,  62] w/ P(a|s)=1.0 and iou=0.2063734584742988 and reward=0.0158511106013855 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.016) for 2X DOWN:bbox transition: [249,  38,  97,  62] -> [249,  40,  97,  62] w/ P(a|s)=1.0 and iou=0.22265236146443979 and reward=0.01627890299014098 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.017) for 2X DOWN:bbox transition: [249,  40,  97,  62] -> [249,  42,  97,  62] w/ P(a|s)=1.0 and iou=0.23937661172777217 and reward=0.01672425026333238 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.017) for 2X DOWN:bbox transition: [249,  42,  97,  62] -> [249,  44,  97,  62] w/ P(a|s)=1.0 and iou=0.2565647379788564 and reward=0.017188126251084263 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (0.018) for 2X DOWN:bbox transition: [249,  44,  97,  62] -> [249,  46,  97,  62] w/ P(a|s)=1.0 and iou=0.27423631123919306 and reward=0.017671573260336637 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (0.018) for 2X DOWN:bbox transition: [249,  46,  97,  62] -> [249,  48,  97,  62] w/ P(a|s)=1.0 and iou=0.2924120191745586 and reward=0.018175707935365548 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (0.019) for 2X DOWN:bbox transition: [249,  48,  97,  62] -> [249,  50,  97,  62] w/ P(a|s)=1.0 and iou=0.31111374688649035 and reward=0.018701727711931737 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (0.019) for 2X DOWN:bbox transition: [249,  50,  97,  62] -> [249,  52,  97,  62] w/ P(a|s)=0.9999997615814209 and iou=0.33036466482127813 and reward=0.01925091793478778 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (0.02) for 2X DOWN:bbox transition: [249,  52,  97,  62] -> [249,  54,  97,  62] w/ P(a|s)=0.9999995231628418 and iou=0.3501893245389031 and reward=0.01982465971762498 and discount=0.8953382542587164\n",
            "   |->> Assigned losses: [1.4684231e-07 1.4914461e-07 1.5153333e-07 1.5401281e-07 1.5658762e-07\n",
            " 1.5926273e-07 1.6204336e-07 1.6493513e-07 1.6794398e-07 1.7107638e-07\n",
            " 1.7433916e-07 1.7773969e-07]\n",
            "\u001b[92m>> Total frame loss: 1.9354611140443012e-06\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 35 with src: [249,  54,  97,  62] and target: [312, 101,  81,  55]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0035.jpg\n",
            "|->> Beginning tracking for bbox:[249  54  97  62]\n",
            "   \u001b[33m|->> #0/t=56-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [249  56  97  62]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [5.5458157e-14 3.7983964e-16 5.1345435e-21 2.4421064e-14 1.4519696e-15\n",
            " 6.7778294e-10 2.6368966e-11 1.0000000e+00 1.1958989e-22 2.3193636e-16\n",
            " 3.7162406e-17], argmax=7\n",
            "   \u001b[33m|->> #1/t=57-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [249  58  97  62]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.0461936e-15 8.1997833e-21 1.1948762e-24 1.4891433e-15 7.6078269e-17\n",
            " 3.4364676e-14 7.3846680e-13 1.0000000e+00 2.2086451e-19 9.0357850e-19\n",
            " 3.0458482e-18], argmax=7\n",
            "   \u001b[33m|->> #2/t=58-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [249  60  97  62]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [2.5823732e-20 1.2286267e-25 9.2966439e-28 4.2055825e-15 5.6739184e-26\n",
            " 7.0618573e-15 3.5697998e-17 1.0000000e+00 9.9805942e-25 4.7492355e-22\n",
            " 3.4261477e-25], argmax=7\n",
            "   \u001b[33m|->> #3/t=59-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [249  62  97  62]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [8.1934002e-22 3.2089147e-28 7.0672813e-28 4.7144795e-18 2.4108727e-24\n",
            " 5.6089754e-17 7.5347308e-16 1.0000000e+00 3.9954614e-29 5.1287044e-23\n",
            " 8.3571786e-27], argmax=7\n",
            "   \u001b[33m|->> #4/t=60-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [249  64  97  62]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [3.9340957e-25 2.5260327e-32 1.8694417e-32 8.7312677e-18 4.3534457e-20\n",
            " 1.1689255e-17 1.0907727e-17 1.0000000e+00 9.7611763e-28 3.3471851e-20\n",
            " 6.5055832e-24], argmax=7\n",
            "   \u001b[33m|->> #5/t=61-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [249  66  97  62]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 1.000e-04 0.000e+00 0.000e+00 0.000e+00\n",
            " 9.999e-01 0.000e+00 0.000e+00 0.000e+00], argmax=7\n",
            "         |->> Action Probabilities (RAW): [3.5102509e-12 4.7286803e-19 8.4913878e-21 1.2765155e-04 3.2417497e-06\n",
            " 4.6127635e-09 6.2227779e-12 9.9986863e-01 1.6422102e-14 4.6156245e-07\n",
            " 4.6698933e-11], argmax=7\n",
            "   \u001b[33m|->> #6/t=62-th Action selection: 7/2X DOWN (P(a|s) = 0.9959999918937683)\u001b[0m\n",
            "      |->> Bounding box moves to: [249  68  97  62]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.0045 0.     0.     0.     0.9955 0.     0.\n",
            " 0.    ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [3.1564679e-14 3.6816945e-21 1.1933615e-22 4.4711758e-03 6.6169200e-08\n",
            " 1.2012082e-07 3.0101841e-13 9.9552864e-01 3.9446532e-15 3.2200824e-09\n",
            " 1.9196714e-11], argmax=7\n",
            "   \u001b[33m|->> #7/t=63-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [249  70  97  62]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.9972538e-19 3.7160457e-28 5.3409652e-30 1.1261477e-06 1.8448326e-13\n",
            " 4.1353988e-14 8.6037059e-13 9.9999893e-01 8.8239133e-24 5.9416337e-17\n",
            " 2.3211922e-17], argmax=7\n",
            "   \u001b[33m|->> #8/t=64-th Action selection: 7/2X DOWN (P(a|s) = 0.27399998903274536)\u001b[0m\n",
            "      |->> Bounding box moves to: [249  72  97  62]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.7264 0.     0.     0.     0.2736 0.     0.\n",
            " 0.    ], argmax=3\n",
            "         |->> Action Probabilities (RAW): [2.8190009e-14 2.2982547e-24 5.2952441e-25 7.2644943e-01 1.2617928e-08\n",
            " 3.6184475e-10 8.3315655e-12 2.7355051e-01 4.4258900e-20 1.1553754e-12\n",
            " 6.6916937e-11], argmax=3\n",
            "   \u001b[33m|->> #9/t=65-th Action selection: 7/2X DOWN (P(a|s) = 0.6389999985694885)\u001b[0m\n",
            "      |->> Bounding box moves to: [249  74  97  62]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 3.507e-01 9.600e-03 4.000e-04 0.000e+00\n",
            " 6.393e-01 0.000e+00 0.000e+00 0.000e+00], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.9315776e-11 4.3021110e-13 4.6674158e-12 3.5074866e-01 9.5502445e-03\n",
            " 3.8378811e-04 2.8941716e-07 6.3926327e-01 5.6800410e-14 4.2342432e-05\n",
            " 1.1353300e-05], argmax=7\n",
            "   \u001b[33m|->> #10/t=66-th Action selection: 7/2X DOWN (P(a|s) = 0.06700000166893005)\u001b[0m\n",
            "      |->> Bounding box moves to: [249  76  97  62]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 8.596e-01 7.210e-02 2.000e-04 0.000e+00\n",
            " 6.740e-02 0.000e+00 2.000e-04 6.000e-04], argmax=3\n",
            "         |->> Action Probabilities (RAW): [4.9971646e-08 1.3060789e-09 2.4797000e-08 8.5955954e-01 7.2102554e-02\n",
            " 1.7114068e-04 5.3096720e-08 6.7392774e-02 1.4740140e-10 1.5431296e-04\n",
            " 6.1951997e-04], argmax=3\n",
            "   \u001b[33m|->> #11/t=67-th Action selection: 3/2X RIGHT (P(a|s) = 0.9380000233650208)\u001b[0m\n",
            "      |->> Bounding box moves to: [253  76  97  62]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 9.379e-01 2.000e-04 6.000e-04 0.000e+00\n",
            " 1.000e-03 0.000e+00 3.200e-03 5.700e-02], argmax=3\n",
            "         |->> Action Probabilities (RAW): [5.2208975e-07 5.5686193e-09 1.5370270e-07 9.3788064e-01 1.7025910e-04\n",
            " 6.3812407e-04 2.3538649e-05 1.0312668e-03 3.5144661e-11 3.2399164e-03\n",
            " 5.7015549e-02], argmax=3\n",
            "   \u001b[33m|->> #12/t=68-th Action selection: 7/2X DOWN (P(a|s) = 0.828000009059906)\u001b[0m\n",
            "      |->> Bounding box moves to: [253  78  97  62]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 1.448e-01 3.000e-04 2.570e-02 0.000e+00\n",
            " 8.278e-01 0.000e+00 8.000e-04 5.000e-04], argmax=7\n",
            "         |->> Action Probabilities (RAW): [5.3278141e-06 6.8250442e-06 1.9299487e-06 1.4476660e-01 2.7156671e-04\n",
            " 2.5744485e-02 3.7703735e-06 8.2784718e-01 3.2399635e-11 8.0566067e-04\n",
            " 5.4660399e-04], argmax=7\n",
            "   \u001b[33m|->> #13/t=69-th Action selection: 7/2X DOWN (P(a|s) = 0.6679999828338623)\u001b[0m\n",
            "      |->> Bounding box moves to: [253  80  97  62]\n",
            "         |->> Action Probabilities (Rounded): [6.000e-04 2.900e-03 0.000e+00 3.100e-03 7.000e-04 1.080e-01 2.700e-03\n",
            " 6.678e-01 0.000e+00 2.140e-01 2.000e-04], argmax=7\n",
            "         |->> Action Probabilities (RAW): [6.0662563e-04 2.9306689e-03 9.1438696e-06 3.0802963e-03 6.7361910e-04\n",
            " 1.0799684e-01 2.7261237e-03 6.6783863e-01 1.8770110e-09 2.1395805e-01\n",
            " 1.8006380e-04], argmax=7\n",
            "   \u001b[33m|->> #14/t=70-th Action selection: 9/SCALE DOWN (P(a|s) = 0.9559999704360962)\u001b[0m\n",
            "      |->> Bounding box moves to: [254  81  94  60]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 4.000e-04 0.000e+00 0.000e+00 0.000e+00 1.990e-02 0.000e+00\n",
            " 2.370e-02 0.000e+00 9.557e-01 2.000e-04], argmax=9\n",
            "         |->> Action Probabilities (RAW): [1.4813117e-05 4.3223755e-04 1.5360026e-06 6.9273909e-08 9.3946128e-06\n",
            " 1.9888027e-02 3.3744861e-06 2.3736773e-02 6.2528243e-13 9.5568520e-01\n",
            " 2.2853132e-04], argmax=9\n",
            "   \u001b[33m|->> #15/t=71-th Action selection: 9/SCALE DOWN (P(a|s) = 0.7689999938011169)\u001b[0m\n",
            "      |->> Bounding box moves to: [255  82  91  58]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 5.000e-04 0.000e+00 0.000e+00 1.000e-04 7.310e-02 0.000e+00\n",
            " 1.565e-01 0.000e+00 7.691e-01 6.000e-04], argmax=9\n",
            "         |->> Action Probabilities (RAW): [3.8947175e-05 5.0945219e-04 3.8138887e-06 4.9975524e-06 7.4996795e-05\n",
            " 7.3102646e-02 3.8378384e-06 1.5648760e-01 8.7907225e-12 7.6913518e-01\n",
            " 6.3861551e-04], argmax=9\n",
            "   \u001b[33m|->> #16/t=72-th Action selection: 5/2X UP (P(a|s) = 0.47699999809265137)\u001b[0m\n",
            "      |->> Bounding box moves to: [255  80  91  58]\n",
            "         |->> Action Probabilities (Rounded): [1.000e-04 1.100e-03 0.000e+00 5.000e-04 9.000e-04 4.770e-01 0.000e+00\n",
            " 4.111e-01 0.000e+00 1.083e-01 8.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [5.5704160e-05 1.1231611e-03 2.6570544e-05 5.3988601e-04 9.1008120e-04\n",
            " 4.7702312e-01 4.6805366e-05 4.1112730e-01 1.9436976e-09 1.0831369e-01\n",
            " 8.3371456e-04], argmax=5\n",
            "   \u001b[33m|->> #17/t=73-th Action selection: 5/2X UP (P(a|s) = 0.22200000286102295)\u001b[0m\n",
            "      |->> Bounding box moves to: [255  78  91  58]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 2.080e-02 1.000e-04 2.000e-03 1.300e-03 2.224e-01 1.000e-04\n",
            " 5.796e-01 0.000e+00 1.731e-01 5.000e-04], argmax=7\n",
            "         |->> Action Probabilities (RAW): [3.1088188e-05 2.0834109e-02 1.2436164e-04 1.9552161e-03 1.2966254e-03\n",
            " 2.2236489e-01 1.0048300e-04 5.7964408e-01 2.8399021e-09 1.7310712e-01\n",
            " 5.4199924e-04], argmax=7\n",
            "   \u001b[33m|->> #18/t=74-th Action selection: 5/2X UP (P(a|s) = 0.4690000116825104)\u001b[0m\n",
            "      |->> Bounding box moves to: [255  76  91  58]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 3.400e-03 2.600e-03 1.212e-01 3.940e-02 4.694e-01 1.000e-04\n",
            " 2.712e-01 0.000e+00 7.910e-02 1.360e-02], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.1627115e-05 3.4290168e-03 2.6369882e-03 1.2124467e-01 3.9360534e-02\n",
            " 4.6936470e-01 9.2895847e-05 2.7117884e-01 5.2699786e-08 7.9110727e-02\n",
            " 1.3559904e-02], argmax=5\n",
            "   \u001b[33m|->> #19/t=75-th Action selection: 3/2X RIGHT (P(a|s) = 0.41999998688697815)\u001b[0m\n",
            "      |->> Bounding box moves to: [259  76  91  58]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 1.000e-04 5.000e-04 4.204e-01 1.020e-02 3.690e-02 0.000e+00\n",
            " 2.821e-01 0.000e+00 2.446e-01 5.200e-03], argmax=3\n",
            "         |->> Action Probabilities (RAW): [4.17731684e-07 9.93111898e-05 4.98702924e-04 4.20429081e-01\n",
            " 1.02182785e-02 3.68989184e-02 5.93634059e-06 2.82129794e-01\n",
            " 2.39454545e-09 2.44567990e-01 5.15163923e-03], argmax=3\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [249,  54,  97,  62] -> [259,  76,  91,  58] (Target was [312, 101,  81,  55])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.007) for 2X DOWN:bbox transition: [249,  54,  97,  62] -> [249,  56,  97,  62] w/ P(a|s)=1.0 and iou=0.05843696289556162 and reward=0.0072270020561199105 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.007) for 2X DOWN:bbox transition: [249,  56,  97,  62] -> [249,  58,  97,  62] w/ P(a|s)=1.0 and iou=0.06576402321083172 and reward=0.007327060315270098 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.007) for 2X DOWN:bbox transition: [249,  58,  97,  62] -> [249,  60,  97,  62] w/ P(a|s)=1.0 and iou=0.07319323423885186 and reward=0.007429211028020147 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.008) for 2X DOWN:bbox transition: [249,  60,  97,  62] -> [249,  62,  97,  62] w/ P(a|s)=1.0 and iou=0.08072674718695158 and reward=0.007533512948099716 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.008) for 2X DOWN:bbox transition: [249,  62,  97,  62] -> [249,  64,  97,  62] w/ P(a|s)=1.0 and iou=0.08836677409294105 and reward=0.007640026905989472 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.008) for 2X DOWN:bbox transition: [249,  64,  97,  62] -> [249,  66,  97,  62] w/ P(a|s)=0.999868631362915 and iou=0.0961155899905769 and reward=0.007748815897635847 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.008) for 2X DOWN:bbox transition: [249,  66,  97,  62] -> [249,  68,  97,  62] w/ P(a|s)=0.9955286383628845 and iou=0.10397553516819572 and reward=0.007859945177618816 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (0.008) for 2X DOWN:bbox transition: [249,  68,  97,  62] -> [249,  70,  97,  62] w/ P(a|s)=0.999998927116394 and iou=0.11194901752522571 and reward=0.007973482357029993 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (0.008) for 2X DOWN:bbox transition: [249,  70,  97,  62] -> [249,  72,  97,  62] w/ P(a|s)=0.27355051040649414 and iou=0.12003851503156093 and reward=0.008089497506335225 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (0.008) for 2X DOWN:bbox transition: [249,  72,  97,  62] -> [249,  74,  97,  62] w/ P(a|s)=0.6392632722854614 and iou=0.1282465782950749 and reward=0.008208063263513976 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (0.008) for 2X DOWN:bbox transition: [249,  74,  97,  62] -> [249,  76,  97,  62] w/ P(a|s)=0.06739277392625809 and iou=0.1365758332428618 and reward=0.008329254947786885 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (0.019) for 2X RIGHT:bbox transition: [249,  76,  97,  62] -> [253,  76,  97,  62] w/ P(a|s)=0.9378806352615356 and iou=0.15513626834381553 and reward=0.01856043510095373 and discount=0.8953382542587164\n",
            "   |->> t=13 Diff-Reward (0.01) for 2X DOWN:bbox transition: [253,  76,  97,  62] -> [253,  78,  97,  62] w/ P(a|s)=0.8278471827507019 and iou=0.1649048625792812 and reward=0.009768594235465666 and discount=0.8863848717161292\n",
            "   |->> t=14 Diff-Reward (0.01) for 2X DOWN:bbox transition: [253,  78,  97,  62] -> [253,  80,  97,  62] w/ P(a|s)=0.6678386330604553 and iou=0.17484008528784648 and reward=0.009935222708565283 and discount=0.8775210229989678\n",
            "   |->> t=15 Diff-Reward (-0.008) for SCALE DOWN:bbox transition: [253,  80,  97,  62] -> [254,  81,  94,  60] w/ P(a|s)=0.9556851983070374 and iou=0.1663778162911612 and reward=-0.008462268996685285 and discount=0.8687458127689782\n",
            "   |->> t=16 Diff-Reward (-0.009) for SCALE DOWN:bbox transition: [254,  81,  94,  60] -> [255,  82,  91,  58] w/ P(a|s)=0.7691351771354675 and iou=0.15772570476983466 and reward=-0.008652111521326528 and discount=0.8600583546412884\n",
            "   |->> t=17 Diff-Reward (-0.009) for 2X UP:bbox transition: [255,  82,  91,  58] -> [255,  80,  91,  58] w/ P(a|s)=0.4770231246948242 and iou=0.14843657817109143 and reward=-0.00928912659874323 and discount=0.8514577710948755\n",
            "   |->> t=18 Diff-Reward (-0.009) for 2X UP:bbox transition: [255,  80,  91,  58] -> [255,  78,  91,  58] w/ P(a|s)=0.2223648875951767 and iou=0.13929532950953996 and reward=-0.009141248661551471 and discount=0.8429431933839268\n",
            "   |->> t=19 Diff-Reward (-0.009) for 2X UP:bbox transition: [255,  78,  91,  58] -> [255,  76,  91,  58] w/ P(a|s)=0.4693647027015686 and iou=0.13029845546394148 and reward=-0.008996874045598485 and discount=0.8345137614500875\n",
            "   |->> t=20 Diff-Reward (0.018) for 2X RIGHT:bbox transition: [255,  76,  91,  58] -> [259,  76,  91,  58] w/ P(a|s)=0.4204290807247162 and iou=0.14789479891496637 and reward=0.0175963434510249 and discount=0.8261686238355866\n",
            "   |->> Assigned losses: [ 7.2368529e-08  7.2636773e-08  7.2912940e-08  7.3197235e-08\n",
            "  7.3489829e-08  9.6812516e-07  3.3162196e-05  7.4419361e-08\n",
            "  9.6760532e-03  3.3549897e-03  2.0317677e-02  1.0657470e-03\n",
            "  1.6358660e-03  3.5196806e-03 -3.3322204e-04 -1.9532614e-03\n",
            " -5.8543864e-03 -1.1584803e-02 -5.6788763e-03  1.2596485e-02]\n",
            "\u001b[92m>> Total frame loss: 0.026796521618962288\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 36 with src: [259,  76,  91,  58] and target: [338, 127,  85,  59]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0036.jpg\n",
            "|->> Beginning tracking for bbox:[259  76  91  58]\n",
            "   \u001b[33m|->> #0/t=76-th Action selection: 5/2X UP (P(a|s) = 0.765999972820282)\u001b[0m\n",
            "      |->> Bounding box moves to: [259  74  91  58]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 6.750e-02 0.000e+00 8.270e-02 3.500e-03 7.662e-01 5.000e-04\n",
            " 7.920e-02 0.000e+00 3.000e-04 1.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.1157079e-05 6.7481011e-02 3.3824006e-05 8.2654916e-02 3.5151853e-03\n",
            " 7.6619768e-01 5.3023029e-04 7.9152085e-02 2.1052476e-07 3.2850687e-04\n",
            " 8.5108346e-05], argmax=5\n",
            "   \u001b[33m|->> #1/t=77-th Action selection: 1/2X LEFT (P(a|s) = 0.8230000138282776)\u001b[0m\n",
            "      |->> Bounding box moves to: [255  74  91  58]\n",
            "         |->> Action Probabilities (Rounded): [8.200e-03 8.230e-01 1.000e-04 9.400e-03 1.100e-03 1.054e-01 1.810e-02\n",
            " 3.180e-02 0.000e+00 2.000e-04 2.700e-03], argmax=1\n",
            "         |->> Action Probabilities (RAW): [8.2352394e-03 8.2301134e-01 1.0226358e-04 9.3562948e-03 1.1496017e-03\n",
            " 1.0539814e-01 1.8054610e-02 3.1849150e-02 2.4203764e-08 1.9286513e-04\n",
            " 2.6505594e-03], argmax=1\n",
            "   \u001b[33m|->> #2/t=78-th Action selection: 5/2X UP (P(a|s) = 0.546999990940094)\u001b[0m\n",
            "      |->> Bounding box moves to: [255  72  91  58]\n",
            "         |->> Action Probabilities (Rounded): [1.600e-03 2.162e-01 5.000e-04 6.190e-02 9.270e-02 5.469e-01 1.180e-02\n",
            " 3.580e-02 0.000e+00 2.000e-04 3.230e-02], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.6119236e-03 2.1616480e-01 5.3860020e-04 6.1896343e-02 9.2732430e-02\n",
            " 5.4688871e-01 1.1778906e-02 3.5811968e-02 5.8290095e-07 2.2643252e-04\n",
            " 3.2349296e-02], argmax=5\n",
            "   \u001b[33m|->> #3/t=79-th Action selection: 1/2X LEFT (P(a|s) = 0.4050000011920929)\u001b[0m\n",
            "      |->> Bounding box moves to: [251  72  91  58]\n",
            "         |->> Action Probabilities (Rounded): [5.000e-04 4.052e-01 0.000e+00 0.000e+00 1.480e-02 4.300e-03 3.770e-02\n",
            " 5.371e-01 0.000e+00 1.000e-04 2.000e-04], argmax=7\n",
            "         |->> Action Probabilities (RAW): [5.2305567e-04 4.0522841e-01 3.9873530e-06 3.8798997e-05 1.4819218e-02\n",
            " 4.3320288e-03 3.7722778e-02 5.3705138e-01 6.8170411e-06 1.1759951e-04\n",
            " 1.5591235e-04], argmax=7\n",
            "   \u001b[33m|->> #4/t=80-th Action selection: 5/2X UP (P(a|s) = 0.13099999725818634)\u001b[0m\n",
            "      |->> Bounding box moves to: [251  70  91  58]\n",
            "         |->> Action Probabilities (Rounded): [1.900e-03 8.880e-02 0.000e+00 3.000e-04 8.000e-04 1.308e-01 4.500e-03\n",
            " 7.728e-01 0.000e+00 1.000e-04 1.000e-04], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.8846866e-03 8.8761158e-02 1.3094212e-06 2.8625739e-04 8.1685540e-04\n",
            " 1.3077383e-01 4.5073517e-03 7.7277678e-01 5.7123289e-06 1.0807843e-04\n",
            " 7.7869801e-05], argmax=7\n",
            "   \u001b[33m|->> #5/t=81-th Action selection: 5/2X UP (P(a|s) = 0.5339999794960022)\u001b[0m\n",
            "      |->> Bounding box moves to: [251  68  91  58]\n",
            "         |->> Action Probabilities (Rounded): [0.0101 0.0569 0.     0.145  0.0007 0.5336 0.0033 0.2471 0.     0.0011\n",
            " 0.0021], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.0129964e-02 5.6886658e-02 1.0074999e-05 1.4499988e-01 6.8893994e-04\n",
            " 5.3363931e-01 3.2839242e-03 2.4709678e-01 6.1780765e-06 1.1125556e-03\n",
            " 2.1456294e-03], argmax=5\n",
            "   \u001b[33m|->> #6/t=82-th Action selection: 3/2X RIGHT (P(a|s) = 0.2840000092983246)\u001b[0m\n",
            "      |->> Bounding box moves to: [255  68  91  58]\n",
            "         |->> Action Probabilities (Rounded): [0.0055 0.1695 0.0021 0.2841 0.0209 0.1492 0.2459 0.0525 0.0009 0.0514\n",
            " 0.0181], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.00547199 0.16947614 0.00205188 0.28406528 0.02086969 0.14923817\n",
            " 0.24589957 0.0524957  0.00087051 0.0514372  0.01812384], argmax=3\n",
            "   \u001b[33m|->> #7/t=83-th Action selection: 5/2X UP (P(a|s) = 0.22300000488758087)\u001b[0m\n",
            "      |->> Bounding box moves to: [255  66  91  58]\n",
            "         |->> Action Probabilities (Rounded): [0.0059 0.1299 0.0012 0.2603 0.0043 0.2225 0.335  0.0364 0.0011 0.0028\n",
            " 0.0008], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.00585121 0.12988438 0.00116492 0.26025292 0.00428401 0.22254662\n",
            " 0.33497375 0.03636221 0.00114724 0.00275698 0.00077579], argmax=6\n",
            "   \u001b[33m|->> #8/t=84-th Action selection: 3/2X RIGHT (P(a|s) = 0.7760000228881836)\u001b[0m\n",
            "      |->> Bounding box moves to: [259  66  91  58]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 1.000e-04 0.000e+00 7.764e-01 2.460e-02 5.870e-02 1.960e-02\n",
            " 1.204e-01 0.000e+00 1.000e-04 1.000e-04], argmax=3\n",
            "         |->> Action Probabilities (RAW): [9.6178164e-06 1.4096315e-04 8.8832003e-06 7.7640247e-01 2.4583267e-02\n",
            " 5.8705136e-02 1.9564571e-02 1.2043060e-01 9.7840211e-07 9.8241231e-05\n",
            " 5.5223132e-05], argmax=3\n",
            "   \u001b[33m|->> #9/t=85-th Action selection: 3/2X RIGHT (P(a|s) = 0.8989999890327454)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  66  91  58]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 3.000e-04 0.000e+00 8.988e-01 4.200e-02 2.720e-02 1.210e-02\n",
            " 1.940e-02 0.000e+00 0.000e+00 1.000e-04], argmax=3\n",
            "         |->> Action Probabilities (RAW): [6.8174154e-06 2.8746371e-04 2.1734106e-06 8.9882559e-01 4.2048257e-02\n",
            " 2.7183486e-02 1.2122428e-02 1.9417915e-02 4.1283025e-07 1.1761499e-05\n",
            " 9.3772418e-05], argmax=3\n",
            "   \u001b[33m|->> #10/t=86-th Action selection: 3/2X RIGHT (P(a|s) = 0.5189999938011169)\u001b[0m\n",
            "      |->> Bounding box moves to: [267  66  91  58]\n",
            "         |->> Action Probabilities (Rounded): [3.000e-04 7.000e-04 0.000e+00 5.189e-01 2.680e-02 4.203e-01 1.250e-02\n",
            " 1.870e-02 0.000e+00 3.000e-04 1.400e-03], argmax=3\n",
            "         |->> Action Probabilities (RAW): [3.0219156e-04 6.5551291e-04 4.5222121e-05 5.1887292e-01 2.6786651e-02\n",
            " 4.2031074e-01 1.2511398e-02 1.8739337e-02 8.5887696e-06 3.4903464e-04\n",
            " 1.4184195e-03], argmax=3\n",
            "   \u001b[33m|->> #11/t=87-th Action selection: 4/UP (P(a|s) = 0.43799999356269836)\u001b[0m\n",
            "      |->> Bounding box moves to: [267  65  91  58]\n",
            "         |->> Action Probabilities (Rounded): [1.100e-02 3.200e-03 9.000e-04 2.297e-01 4.376e-01 1.989e-01 2.750e-02\n",
            " 8.960e-02 2.000e-04 6.000e-04 9.000e-04], argmax=4\n",
            "         |->> Action Probabilities (RAW): [1.1002815e-02 3.2226914e-03 8.7508466e-04 2.2965206e-01 4.3756223e-01\n",
            " 1.9890027e-01 2.7469264e-02 8.9597270e-02 1.6440825e-04 6.4482901e-04\n",
            " 9.0905558e-04], argmax=4\n",
            "   \u001b[33m|->> #12/t=88-th Action selection: 3/2X RIGHT (P(a|s) = 0.3310000002384186)\u001b[0m\n",
            "      |->> Bounding box moves to: [271  65  91  58]\n",
            "         |->> Action Probabilities (Rounded): [2.000e-04 4.360e-02 1.000e-04 3.310e-01 2.710e-02 1.131e-01 1.282e-01\n",
            " 3.565e-01 0.000e+00 1.000e-04 1.000e-04], argmax=7\n",
            "         |->> Action Probabilities (RAW): [2.4504052e-04 4.3633465e-02 9.7688382e-05 3.3095124e-01 2.7059276e-02\n",
            " 1.1313332e-01 1.2819107e-01 3.5651013e-01 2.7728358e-05 9.6995020e-05\n",
            " 5.4092998e-05], argmax=7\n",
            "   \u001b[33m|->> #13/t=89-th Action selection: 7/2X DOWN (P(a|s) = 0.414000004529953)\u001b[0m\n",
            "      |->> Bounding box moves to: [271  67  91  58]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.0107 0.     0.2746 0.0067 0.0605 0.2331 0.4143 0.     0.\n",
            " 0.    ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.4169395e-05 1.0694813e-02 2.8395114e-06 2.7461296e-01 6.7385267e-03\n",
            " 6.0454637e-02 2.3306906e-01 4.1432968e-01 1.7790244e-05 1.9454568e-05\n",
            " 4.6147990e-05], argmax=7\n",
            "|->> Revisiting bbox: [271  65  91  58]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [259,  76,  91,  58] -> [271,  67,  91,  58] (Target was [338, 127,  85,  59])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.002) for 2X UP:bbox transition: [259,  76,  91,  58] -> [259,  74,  91,  58] w/ P(a|s)=0.766197681427002 and iou=0.005863383172090296 and reward=-0.0023646509154794963 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.002) for 2X LEFT:bbox transition: [259,  74,  91,  58] -> [255,  74,  91,  58] w/ P(a|s)=0.8230113387107849 and iou=0.0039012971813127866 and reward=-0.001962085990777509 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-0.002) for 2X UP:bbox transition: [255,  74,  91,  58] -> [255,  72,  91,  58] w/ P(a|s)=0.5468887090682983 and iou=0.0023371311714869996 and reward=-0.001564166009825787 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-0.001) for 2X LEFT:bbox transition: [255,  72,  91,  58] -> [251,  72,  91,  58] w/ P(a|s)=0.4052284061908722 and iou=0.0011672016340822876 and reward=-0.001169929537404712 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-0.001) for 2X UP:bbox transition: [251,  72,  91,  58] -> [251,  70,  91,  58] w/ P(a|s)=0.13077382743358612 and iou=0.000388764700165225 and reward=-0.0007784369339170626 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-0.0) for 2X UP:bbox transition: [251,  70,  91,  58] -> [251,  68,  91,  58] w/ P(a|s)=0.5336393117904663 and iou=0.0 and reward=-0.000388764700165225 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.0) for 2X RIGHT:bbox transition: [251,  68,  91,  58] -> [255,  68,  91,  58] w/ P(a|s)=0.28406527638435364 and iou=0.0 and reward=0.0 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (0.0) for 2X UP:bbox transition: [255,  68,  91,  58] -> [255,  66,  91,  58] w/ P(a|s)=0.22254662215709686 and iou=0.0 and reward=0.0 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (0.0) for 2X RIGHT:bbox transition: [255,  66,  91,  58] -> [259,  66,  91,  58] w/ P(a|s)=0.776402473449707 and iou=0.0 and reward=0.0 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (0.0) for 2X RIGHT:bbox transition: [259,  66,  91,  58] -> [263,  66,  91,  58] w/ P(a|s)=0.8988255858421326 and iou=0.0 and reward=0.0 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (0.0) for 2X RIGHT:bbox transition: [263,  66,  91,  58] -> [267,  66,  91,  58] w/ P(a|s)=0.5188729166984558 and iou=0.0 and reward=0.0 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (0.0) for UP:bbox transition: [267,  66,  91,  58] -> [267,  65,  91,  58] w/ P(a|s)=0.4375622272491455 and iou=0.0 and reward=0.0 and discount=0.8953382542587164\n",
            "   |->> t=13 Diff-Reward (0.0) for 2X RIGHT:bbox transition: [267,  65,  91,  58] -> [271,  65,  91,  58] w/ P(a|s)=0.3309512436389923 and iou=0.0 and reward=0.0 and discount=0.8863848717161292\n",
            "   |->> t=14 Diff-Reward (0.0) for 2X DOWN:bbox transition: [271,  65,  91,  58] -> [271,  67,  91,  58] w/ P(a|s)=0.4143296778202057 and iou=0.0 and reward=0.0 and discount=0.8775210229989678\n",
            "   |->> Assigned losses: [-0.00062974 -0.00037836 -0.0009252  -0.00102541 -0.00152116 -0.00023219\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.        ]\n",
            "\u001b[31m>> Total frame loss: -0.0047120810486376286\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 37 with src: [271,  67,  91,  58] and target: [354, 158,  87,  54]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0037.jpg\n",
            "|->> Beginning tracking for bbox:[271  67  91  58]\n",
            "   \u001b[33m|->> #0/t=90-th Action selection: 1/2X LEFT (P(a|s) = 0.7860000133514404)\u001b[0m\n",
            "      |->> Bounding box moves to: [267  67  91  58]\n",
            "         |->> Action Probabilities (Rounded): [5.000e-04 7.864e-01 0.000e+00 9.000e-03 6.000e-04 4.210e-02 9.920e-02\n",
            " 5.710e-02 0.000e+00 5.000e-04 4.700e-03], argmax=1\n",
            "         |->> Action Probabilities (RAW): [4.9618474e-04 7.8637314e-01 4.2634168e-05 8.9597292e-03 5.5027968e-04\n",
            " 4.2086903e-02 9.9213064e-02 5.7146557e-02 3.0312221e-06 4.6427106e-04\n",
            " 4.6643233e-03], argmax=1\n",
            "   \u001b[33m|->> #1/t=91-th Action selection: 1/2X LEFT (P(a|s) = 0.8859999775886536)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  67  91  58]\n",
            "         |->> Action Probabilities (Rounded): [1.90e-03 8.86e-01 0.00e+00 2.30e-03 3.00e-04 8.20e-03 9.72e-02 2.70e-03\n",
            " 0.00e+00 1.00e-04 1.30e-03], argmax=1\n",
            "         |->> Action Probabilities (RAW): [1.9007053e-03 8.8601965e-01 1.3607429e-05 2.2693069e-03 2.7815587e-04\n",
            " 8.1633674e-03 9.7173505e-02 2.6943805e-03 2.7340360e-07 1.4521305e-04\n",
            " 1.3418612e-03], argmax=1\n",
            "   \u001b[33m|->> #2/t=92-th Action selection: 6/DOWN (P(a|s) = 0.05700000002980232)\u001b[0m\n",
            "      |->> Bounding box moves to: [263  68  91  58]\n",
            "         |->> Action Probabilities (Rounded): [6.50e-03 9.15e-01 0.00e+00 2.50e-03 5.00e-04 1.12e-02 5.71e-02 3.70e-03\n",
            " 0.00e+00 7.00e-04 2.70e-03], argmax=1\n",
            "         |->> Action Probabilities (RAW): [6.5436033e-03 9.1499329e-01 3.7166887e-05 2.4977548e-03 5.4125465e-04\n",
            " 1.1167909e-02 5.7149462e-02 3.7119265e-03 2.6905465e-07 7.0585305e-04\n",
            " 2.6515345e-03], argmax=1\n",
            "   \u001b[33m|->> #3/t=93-th Action selection: 1/2X LEFT (P(a|s) = 0.16500000655651093)\u001b[0m\n",
            "      |->> Bounding box moves to: [259  68  91  58]\n",
            "         |->> Action Probabilities (Rounded): [2.300e-03 1.649e-01 0.000e+00 1.360e-02 7.400e-03 6.500e-03 7.994e-01\n",
            " 2.700e-03 0.000e+00 2.600e-03 5.000e-04], argmax=6\n",
            "         |->> Action Probabilities (RAW): [2.2949914e-03 1.6494577e-01 3.2771546e-05 1.3611615e-02 7.3898216e-03\n",
            " 6.4867954e-03 7.9940492e-01 2.7078486e-03 2.9117913e-07 2.6418653e-03\n",
            " 4.8334393e-04], argmax=6\n",
            "   \u001b[33m|->> #4/t=94-th Action selection: 6/DOWN (P(a|s) = 0.7749999761581421)\u001b[0m\n",
            "      |->> Bounding box moves to: [259  69  91  58]\n",
            "         |->> Action Probabilities (Rounded): [1.700e-03 8.280e-02 1.000e-04 4.180e-02 5.400e-03 1.870e-02 7.747e-01\n",
            " 6.410e-02 0.000e+00 1.020e-02 6.000e-04], argmax=6\n",
            "         |->> Action Probabilities (RAW): [1.6766341e-03 8.2795590e-02 6.1654158e-05 4.1844003e-02 5.3546652e-03\n",
            " 1.8678563e-02 7.7471161e-01 6.4054064e-02 2.5326810e-07 1.0232446e-02\n",
            " 5.9047638e-04], argmax=6\n",
            "   \u001b[33m|->> #5/t=95-th Action selection: 9/SCALE DOWN (P(a|s) = 0.004000000189989805)\u001b[0m\n",
            "      |->> Bounding box moves to: [260  70  88  56]\n",
            "         |->> Action Probabilities (Rounded): [2.800e-03 7.664e-01 1.000e-04 2.110e-02 1.670e-02 9.800e-02 8.560e-02\n",
            " 5.100e-03 0.000e+00 3.800e-03 5.000e-04], argmax=1\n",
            "         |->> Action Probabilities (RAW): [2.7708584e-03 7.6637375e-01 8.3021841e-05 2.1069374e-02 1.6738489e-02\n",
            " 9.7983889e-02 8.5625723e-02 5.0992030e-03 6.6527770e-07 3.7878146e-03\n",
            " 4.6725650e-04], argmax=1\n",
            "   \u001b[33m|->> #6/t=96-th Action selection: 1/2X LEFT (P(a|s) = 0.5059999823570251)\u001b[0m\n",
            "      |->> Bounding box moves to: [256  70  88  56]\n",
            "         |->> Action Probabilities (Rounded): [3.400e-03 5.055e-01 1.000e-04 1.890e-02 6.080e-02 9.980e-02 2.777e-01\n",
            " 2.470e-02 0.000e+00 7.000e-03 2.200e-03], argmax=1\n",
            "         |->> Action Probabilities (RAW): [3.3946466e-03 5.0550914e-01 6.8569490e-05 1.8895991e-02 6.0771052e-02\n",
            " 9.9778235e-02 2.7766702e-01 2.4734575e-02 9.7122415e-07 6.9890679e-03\n",
            " 2.1906933e-03], argmax=1\n",
            "|->> Revisiting bbox: [260  70  88  56]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [271,  67,  91,  58] -> [256,  70,  88,  56] (Target was [354, 158,  87,  54])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X LEFT:bbox transition: [271,  67,  91,  58] -> [267,  67,  91,  58] w/ P(a|s)=0.7863731384277344 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for 2X LEFT:bbox transition: [267,  67,  91,  58] -> [263,  67,  91,  58] w/ P(a|s)=0.8860196471214294 and iou=0.0 and reward=0.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.0) for DOWN:bbox transition: [263,  67,  91,  58] -> [263,  68,  91,  58] w/ P(a|s)=0.05714946240186691 and iou=0.0 and reward=0.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.0) for 2X LEFT:bbox transition: [263,  68,  91,  58] -> [259,  68,  91,  58] w/ P(a|s)=0.16494576632976532 and iou=0.0 and reward=0.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.0) for DOWN:bbox transition: [259,  68,  91,  58] -> [259,  69,  91,  58] w/ P(a|s)=0.7747116088867188 and iou=0.0 and reward=0.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.0) for SCALE DOWN:bbox transition: [259,  69,  91,  58] -> [260,  70,  88,  56] w/ P(a|s)=0.003787814639508724 and iou=0.0 and reward=0.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.0) for 2X LEFT:bbox transition: [260,  70,  88,  56] -> [256,  70,  88,  56] w/ P(a|s)=0.5055091381072998 and iou=0.0 and reward=0.0 and discount=0.941480149401\n",
            "   |->> Assigned losses: [0. 0. 0. 0. 0. 0. 0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "Final bounding box: [256  70  88  56] reached in 97 timesteps (originating from [269  32  89  52]). Target was [354 158  87  54]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 38 in t=97 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[92m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 17.297372817993164\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.028905116021633148\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 11.53669548034668\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.03992937132716179\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 16.013824462890625\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.05042291432619095\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 9.088640213012695\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.03725837543606758\n",
            "Layer Name: custom_rnn/conv2d/kernel:0, GRAD NORM = 2.087326765060425\n",
            "Layer Name: custom_rnn/conv2d/bias:0, GRAD NORM = 0.14007115364074707\n",
            "Layer Name: custom_rnn/conv2d_1/kernel:0, GRAD NORM = 24.77132225036621\n",
            "Layer Name: custom_rnn/conv2d_1/bias:0, GRAD NORM = 0.14007115364074707\n",
            "Layer Name: custom_rnn/conv2d_2/kernel:0, GRAD NORM = 17.658349990844727\n",
            "Layer Name: custom_rnn/conv2d_2/bias:0, GRAD NORM = 0.09872858971357346\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/Deer\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Starting bounding box for adnet_datasets/OTB/Deer: frames 7:17 is [321 146  99  60].\n",
            "\u001b[34m>> Attempting to reach frame 8 with src: [321, 146,  99,  60] and target: [317, 124,  93,  55]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0008.jpg\n",
            "|->> Beginning tracking for bbox:[321 146  99  60]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [321 148  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [6.1680085e-26 2.1706423e-10 6.1440110e-18 2.3979264e-13 1.0542483e-11\n",
            " 2.1801337e-12 9.7860418e-21 1.0000000e+00 7.7627706e-30 6.4266575e-15\n",
            " 2.4554115e-19], argmax=7\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [321 150  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 3.2933744e-13 9.1159262e-28 1.8370004e-10 1.9586764e-13\n",
            " 1.1994367e-12 3.1143970e-38 1.0000000e+00 0.0000000e+00 8.2712793e-15\n",
            " 1.7028337e-18], argmax=7\n",
            "   \u001b[33m|->> #2/t=3-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [321 152  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [3.2364251e-32 2.3446333e-14 5.0412409e-19 5.6749472e-10 6.5395502e-11\n",
            " 1.3798260e-05 3.6130285e-32 9.9998617e-01 4.9595194e-29 1.0421354e-09\n",
            " 6.8597222e-10], argmax=7\n",
            "|->> Revisiting bbox: [321 150  99  60]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [321, 146,  99,  60] -> [321, 152,  99,  60] (Target was [317, 124,  93,  55])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.029) for 2X DOWN:bbox transition: [321, 146,  99,  60] -> [321, 148,  99,  60] w/ P(a|s)=1.0 and iou=0.3325699132111861 and reward=-0.029218704674992768 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.028) for 2X DOWN:bbox transition: [321, 148,  99,  60] -> [321, 150,  99,  60] w/ P(a|s)=1.0 and iou=0.30457871135237197 and reward=-0.027991201858814152 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-0.027) for 2X DOWN:bbox transition: [321, 150,  99,  60] -> [321, 152,  99,  60] w/ P(a|s)=0.9999861717224121 and iou=0.2777392510402219 and reward=-0.026839460312150065 and discount=0.9801\n",
            "   |->> Assigned losses: [-2.9258533e-07 -2.7749061e-07 -3.6376028e-07]\n",
            "\u001b[31m>> Total frame loss: -9.338361905975034e-07\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 9 with src: [321, 152,  99,  60] and target: [319,  96,  89,  62]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0009.jpg\n",
            "|->> Beginning tracking for bbox:[321 152  99  60]\n",
            "   \u001b[33m|->> #0/t=4-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [321 150  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.2555036e-27 4.6876878e-33 1.4143776e-33 5.2033272e-10 4.4534270e-25\n",
            " 1.0000000e+00 5.5122955e-31 4.3361952e-26 0.0000000e+00 1.0318269e-36\n",
            " 1.7319139e-33], argmax=5\n",
            "   \u001b[33m|->> #1/t=5-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [321 148  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.22828308e-30 2.57291921e-31 1.20843964e-32 1.80818305e-09\n",
            " 2.69284488e-27 1.00000000e+00 1.03805886e-32 2.99487034e-30\n",
            " 0.00000000e+00 2.82275511e-35 4.56663305e-37], argmax=5\n",
            "   \u001b[33m|->> #2/t=6-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [321 146  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.0582154e-29 1.5653428e-30 4.1840558e-32 5.4386563e-13 9.5833544e-25\n",
            " 1.0000000e+00 2.6003387e-32 1.8069747e-26 0.0000000e+00 1.8055185e-36\n",
            " 8.5983109e-37], argmax=5\n",
            "   \u001b[33m|->> #3/t=7-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [321 144  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.4543460e-27 3.5421142e-32 2.8153069e-32 2.9672669e-14 3.6390221e-20\n",
            " 1.0000000e+00 8.7560541e-32 2.7037779e-26 0.0000000e+00 9.3924940e-36\n",
            " 4.3501464e-33], argmax=5\n",
            "   \u001b[33m|->> #4/t=8-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [321 142  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.92527580e-19 1.93117851e-23 7.79455209e-22 2.67801189e-12\n",
            " 2.30132287e-16 1.00000000e+00 1.02672203e-22 1.07483863e-22\n",
            " 1.60073029e-28 2.50780761e-26 1.69264036e-25], argmax=5\n",
            "   \u001b[33m|->> #5/t=9-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [321 140  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [8.62895211e-18 5.03083191e-15 2.18736488e-19 8.83786805e-13\n",
            " 2.65201916e-14 1.00000000e+00 6.33310335e-16 4.23585931e-19\n",
            " 1.45865476e-21 2.15592574e-20 1.00095436e-22], argmax=5\n",
            "   \u001b[33m|->> #6/t=10-th Action selection: 1/2X LEFT (P(a|s) = 0.10999999940395355)\u001b[0m\n",
            "      |->> Bounding box moves to: [317 140  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.1104 0.     0.     0.     0.8896 0.     0.     0.     0.\n",
            " 0.    ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.4018987e-17 1.1038878e-01 1.7064564e-17 2.8396964e-06 1.2549249e-11\n",
            " 8.8960844e-01 2.1693178e-10 1.9971363e-17 2.0041441e-15 2.0673437e-16\n",
            " 5.6211204e-17], argmax=5\n",
            "   \u001b[33m|->> #7/t=11-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [317 138  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [5.8439020e-17 2.2030034e-07 1.2504190e-25 4.0818433e-20 2.8823302e-19\n",
            " 9.9999976e-01 1.0753567e-19 1.0034229e-24 4.0789864e-24 2.5498130e-22\n",
            " 1.9782862e-24], argmax=5\n",
            "   \u001b[33m|->> #8/t=12-th Action selection: 1/2X LEFT (P(a|s) = 0.8989999890327454)\u001b[0m\n",
            "      |->> Bounding box moves to: [313 138  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.8992 0.     0.     0.     0.1008 0.     0.     0.     0.\n",
            " 0.    ], argmax=1\n",
            "         |->> Action Probabilities (RAW): [2.07188104e-14 8.99154425e-01 2.62432768e-22 5.24325835e-17\n",
            " 1.01649673e-13 1.00845575e-01 1.86478433e-16 1.27026217e-15\n",
            " 1.24849189e-20 1.42593444e-16 6.41460693e-22], argmax=1\n",
            "   \u001b[33m|->> #9/t=13-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [313 136  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 3.5289643e-17 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            " 1.0000000e+00 0.0000000e+00 1.3352058e-30 0.0000000e+00 1.2713286e-38\n",
            " 0.0000000e+00], argmax=5\n",
            "   \u001b[33m|->> #10/t=14-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [313 134  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 1.8253256e-20 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            " 1.0000000e+00 0.0000000e+00 1.8174807e-28 0.0000000e+00 1.9002705e-34\n",
            " 3.3432275e-36], argmax=5\n",
            "   \u001b[33m|->> #11/t=15-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [313 132  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 3.1415789e-23 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            " 1.0000000e+00 0.0000000e+00 1.8093005e-32 0.0000000e+00 4.0780059e-32\n",
            " 4.9200385e-35], argmax=5\n",
            "   \u001b[33m|->> #12/t=16-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [313 130  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 1.6778984e-26 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            " 1.0000000e+00 0.0000000e+00 2.4450774e-31 0.0000000e+00 1.2264349e-33\n",
            " 5.6459946e-36], argmax=5\n",
            "   \u001b[33m|->> #13/t=17-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [313 128  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 1.8694760e-26 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            " 1.0000000e+00 0.0000000e+00 2.6132659e-32 0.0000000e+00 7.6227801e-34\n",
            " 4.8740793e-37], argmax=5\n",
            "   \u001b[33m|->> #14/t=18-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [313 126  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 2.8579084e-24 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            " 1.0000000e+00 0.0000000e+00 4.5864645e-30 0.0000000e+00 2.2399077e-30\n",
            " 7.8187897e-38], argmax=5\n",
            "   \u001b[33m|->> #15/t=19-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [313 124  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 1.3838240e-25 0.0000000e+00 0.0000000e+00 2.2086980e-32\n",
            " 1.0000000e+00 0.0000000e+00 2.9733844e-26 0.0000000e+00 1.3624191e-29\n",
            " 2.2927935e-34], argmax=5\n",
            "   \u001b[33m|->> #16/t=20-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [313 122  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 1.6319762e-23 0.0000000e+00 6.0869831e-37 8.2888491e-28\n",
            " 1.0000000e+00 2.1149595e-36 4.7870077e-17 0.0000000e+00 3.2314787e-29\n",
            " 1.3486424e-31], argmax=5\n",
            "   \u001b[33m|->> #17/t=21-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [313 120  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.00000000e+00 1.50649225e-27 0.00000000e+00 1.13244115e-35\n",
            " 4.55996715e-29 1.00000000e+00 1.29244443e-36 1.74525239e-09\n",
            " 3.77936608e-36 1.56027883e-33 1.96542908e-34], argmax=5\n",
            "   \u001b[33m|->> #18/t=22-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [313 118  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 9.999e-01 0.000e+00\n",
            " 1.000e-04 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [9.6377783e-32 9.8962157e-26 2.3366499e-38 2.2247622e-30 2.6984307e-29\n",
            " 9.9989879e-01 1.2549361e-27 1.0125559e-04 2.8822584e-27 8.1130461e-30\n",
            " 6.2114444e-33], argmax=5\n",
            "|->> Revisiting bbox: [313 120  99  60]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [321, 152,  99,  60] -> [313, 118,  99,  60] (Target was [319,  96,  89,  62])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.017) for 2X UP:bbox transition: [321, 152,  99,  60] -> [321, 150,  99,  60] w/ P(a|s)=1.0 and iou=0.06467199405314997 and reward=0.01693973362886321 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.017) for 2X UP:bbox transition: [321, 150,  99,  60] -> [321, 148,  99,  60] w/ P(a|s)=1.0 and iou=0.08216849263316962 and reward=0.017496498580019657 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.018) for 2X UP:bbox transition: [321, 148,  99,  60] -> [321, 146,  99,  60] w/ P(a|s)=1.0 and iou=0.10024966391396198 and reward=0.018081171280792355 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.019) for 2X UP:bbox transition: [321, 146,  99,  60] -> [321, 144,  99,  60] w/ P(a|s)=1.0 and iou=0.1189453125 and reward=0.01869564858603802 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.019) for 2X UP:bbox transition: [321, 144,  99,  60] -> [321, 142,  99,  60] w/ P(a|s)=1.0 and iou=0.1382873037949533 and reward=0.0193419912949533 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.02) for 2X UP:bbox transition: [321, 142,  99,  60] -> [321, 140,  99,  60] w/ P(a|s)=1.0 and iou=0.1583097452486858 and reward=0.020022441453732498 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.004) for 2X LEFT:bbox transition: [321, 140,  99,  60] -> [317, 140,  99,  60] w/ P(a|s)=0.11038877815008163 and iou=0.16254058441558442 and reward=0.00423083916689862 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (0.021) for 2X UP:bbox transition: [317, 140,  99,  60] -> [317, 138,  99,  60] w/ P(a|s)=0.9999997615814209 and iou=0.1839222979954536 and reward=0.021381713579869177 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (0.0) for 2X LEFT:bbox transition: [317, 138,  99,  60] -> [313, 138,  99,  60] w/ P(a|s)=0.8991544246673584 and iou=0.1839222979954536 and reward=0.0 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (0.022) for 2X UP:bbox transition: [313, 138,  99,  60] -> [313, 136,  99,  60] w/ P(a|s)=1.0 and iou=0.20610526315789474 and reward=0.022182965162441143 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (0.023) for 2X UP:bbox transition: [313, 136,  99,  60] -> [313, 134,  99,  60] w/ P(a|s)=1.0 and iou=0.22913537867410427 and reward=0.023030115516209537 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (0.024) for 2X UP:bbox transition: [313, 134,  99,  60] -> [313, 132,  99,  60] w/ P(a|s)=1.0 and iou=0.2530621172353456 and reward=0.023926738561241334 and discount=0.8953382542587164\n",
            "   |->> t=13 Diff-Reward (0.025) for 2X UP:bbox transition: [313, 132,  99,  60] -> [313, 130,  99,  60] w/ P(a|s)=1.0 and iou=0.2779388802141423 and reward=0.024876762978796707 and discount=0.8863848717161292\n",
            "   |->> t=14 Diff-Reward (0.026) for 2X UP:bbox transition: [313, 130,  99,  60] -> [313, 128,  99,  60] w/ P(a|s)=1.0 and iou=0.3038233955393719 and reward=0.025884515325229562 and discount=0.8775210229989678\n",
            "   |->> t=15 Diff-Reward (0.027) for 2X UP:bbox transition: [313, 128,  99,  60] -> [313, 126,  99,  60] w/ P(a|s)=1.0 and iou=0.3307781649245064 and reward=0.026954769385134525 and discount=0.8687458127689782\n",
            "   |->> t=16 Diff-Reward (0.028) for 2X UP:bbox transition: [313, 126,  99,  60] -> [313, 124,  99,  60] w/ P(a|s)=1.0 and iou=0.3588709677419355 and reward=0.028092802817429097 and discount=0.8600583546412884\n",
            "   |->> t=17 Diff-Reward (0.029) for 2X UP:bbox transition: [313, 124,  99,  60] -> [313, 122,  99,  60] w/ P(a|s)=1.0 and iou=0.3881754300944996 and reward=0.02930446235256412 and discount=0.8514577710948755\n",
            "   |->> t=18 Diff-Reward (0.031) for 2X UP:bbox transition: [313, 122,  99,  60] -> [313, 120,  99,  60] w/ P(a|s)=1.0 and iou=0.4187716691431402 and reward=0.03059623904864056 and discount=0.8429431933839268\n",
            "   |->> t=19 Diff-Reward (0.032) for 2X UP:bbox transition: [313, 120,  99,  60] -> [313, 118,  99,  60] w/ P(a|s)=0.9998987913131714 and iou=0.45074702456318055 and reward=0.031975355420040374 and discount=0.8345137614500875\n",
            "   |->> Assigned losses: [1.6962822e-07 1.7345143e-07 1.7745509e-07 1.8165096e-07 1.8605165e-07\n",
            " 1.9067095e-07 8.7780776e-03 1.9956317e-07 0.0000000e+00 2.0292143e-07\n",
            " 2.0856413e-07 2.1451724e-07 2.2080440e-07 2.2745168e-07 2.3448762e-07\n",
            " 2.4194384e-07 2.4985522e-07 2.5826046e-07 2.7007766e-06]\n",
            "\u001b[92m>> Total frame loss: 0.008784116245806217\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 10 with src: [313, 118,  99,  60] and target: [306,  75,  85,  56]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0010.jpg\n",
            "|->> Beginning tracking for bbox:[313 118  99  60]\n",
            "   \u001b[33m|->> #0/t=23-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [313 116  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [4.3982986e-20 1.6944384e-15 2.9772791e-25 9.6042383e-20 7.4650304e-18\n",
            " 1.0000000e+00 7.6793534e-24 6.9371829e-18 7.4086192e-29 7.1714771e-23\n",
            " 1.0024102e-22], argmax=5\n",
            "   \u001b[33m|->> #1/t=24-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [313 114  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [7.9474032e-23 6.4629037e-20 2.2875591e-35 8.4730536e-29 3.1274591e-22\n",
            " 1.0000000e+00 1.6394216e-36 1.2608252e-21 7.1466163e-33 4.8515213e-30\n",
            " 1.3662840e-32], argmax=5\n",
            "   \u001b[33m|->> #2/t=25-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [313 112  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.9190856e-28 9.4767560e-19 8.2825803e-38 5.1658600e-36 1.6649318e-31\n",
            " 1.0000000e+00 1.3084178e-36 3.6436228e-26 5.3534200e-35 9.6104736e-34\n",
            " 1.2203933e-37], argmax=5\n",
            "   \u001b[33m|->> #3/t=26-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [313 110  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.8599493e-28 2.6606487e-13 6.1407976e-34 1.7091787e-33 2.7665288e-30\n",
            " 1.0000000e+00 8.8706307e-32 4.0317782e-29 6.1575126e-37 2.0589999e-32\n",
            " 5.7215084e-37], argmax=5\n",
            "   \u001b[33m|->> #4/t=27-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [313 108  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [5.6406797e-35 2.5659966e-18 0.0000000e+00 0.0000000e+00 1.5750640e-38\n",
            " 1.0000000e+00 3.0164395e-36 1.5602110e-36 0.0000000e+00 1.1971632e-37\n",
            " 0.0000000e+00], argmax=5\n",
            "   \u001b[33m|->> #5/t=28-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [313 106  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 1.7577385e-18 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            " 1.0000000e+00 0.0000000e+00 3.0675232e-34 0.0000000e+00 6.8727143e-37\n",
            " 0.0000000e+00], argmax=5\n",
            "   \u001b[33m|->> #6/t=29-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [313 104  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 2.8882960e-27 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            " 1.0000000e+00 0.0000000e+00 6.7058516e-38 0.0000000e+00 0.0000000e+00\n",
            " 9.0806562e-37], argmax=5\n",
            "   \u001b[33m|->> #7/t=30-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [313 102  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 4.7744679e-29 0.0000000e+00 0.0000000e+00 4.8263864e-35\n",
            " 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            " 3.9680621e-28], argmax=5\n",
            "   \u001b[33m|->> #8/t=31-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [313 100  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.6604759e-35 7.9165942e-32 0.0000000e+00 0.0000000e+00 2.5489374e-30\n",
            " 1.0000000e+00 1.0934326e-36 7.7213315e-31 0.0000000e+00 8.9775237e-32\n",
            " 2.9013583e-28], argmax=5\n",
            "   \u001b[33m|->> #9/t=32-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [313  98  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.3008587e-35 3.6073804e-30 3.4465155e-34 5.5080807e-35 3.4038448e-25\n",
            " 1.0000000e+00 0.0000000e+00 2.3187951e-18 0.0000000e+00 2.4921839e-28\n",
            " 6.6186746e-25], argmax=5\n",
            "   \u001b[33m|->> #10/t=33-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [313  96  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [7.8312233e-34 1.7537982e-28 7.0859718e-33 2.6782161e-27 9.0068591e-23\n",
            " 1.0000000e+00 0.0000000e+00 4.3697186e-12 0.0000000e+00 2.6637159e-28\n",
            " 5.4598319e-23], argmax=5\n",
            "   \u001b[33m|->> #11/t=34-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [313  94  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [8.6845167e-21 5.1833806e-24 8.2575821e-26 5.1451172e-19 1.6000588e-13\n",
            " 1.0000000e+00 8.9278193e-35 3.3545586e-10 8.3091252e-32 1.1357713e-22\n",
            " 2.1539388e-18], argmax=5\n",
            "   \u001b[33m|->> #12/t=35-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [313  92  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [4.89411137e-13 9.31003050e-19 1.28662936e-22 6.01814709e-10\n",
            " 9.27473653e-09 1.00000000e+00 6.92092916e-25 1.12708465e-08\n",
            " 2.62468044e-28 3.18781612e-15 1.32909768e-11], argmax=5\n",
            "|->> Revisiting bbox: [313  94  99  60]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [313, 118,  99,  60] -> [313,  92,  99,  60] (Target was [306,  75,  85,  56])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.018) for 2X UP:bbox transition: [313, 118,  99,  60] -> [313, 116,  99,  60] w/ P(a|s)=1.0 and iou=0.12277019937040923 and reward=0.0180830220010101 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.019) for 2X UP:bbox transition: [313, 116,  99,  60] -> [313, 114,  99,  60] w/ P(a|s)=1.0 and iou=0.14145508854277788 and reward=0.018684889172368657 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.019) for 2X UP:bbox transition: [313, 114,  99,  60] -> [313, 112,  99,  60] w/ P(a|s)=1.0 and iou=0.16077240182252114 and reward=0.01931731327974326 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.02) for 2X UP:bbox transition: [313, 112,  99,  60] -> [313, 110,  99,  60] w/ P(a|s)=1.0 and iou=0.1807548002648422 and reward=0.019982398442321053 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.021) for 2X UP:bbox transition: [313, 110,  99,  60] -> [313, 108,  99,  60] w/ P(a|s)=1.0 and iou=0.20143723332584773 and reward=0.020682433061005534 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.021) for 2X UP:bbox transition: [313, 108,  99,  60] -> [313, 106,  99,  60] w/ P(a|s)=1.0 and iou=0.22285714285714286 and reward=0.021419909531295134 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.022) for 2X UP:bbox transition: [313, 106,  99,  60] -> [313, 104,  99,  60] w/ P(a|s)=1.0 and iou=0.24505468931812893 and reward=0.022197546460986067 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (0.023) for 2X UP:bbox transition: [313, 104,  99,  60] -> [313, 102,  99,  60] w/ P(a|s)=1.0 and iou=0.2680730030812989 and reward=0.023018313763169956 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (0.024) for 2X UP:bbox transition: [313, 102,  99,  60] -> [313, 100,  99,  60] w/ P(a|s)=1.0 and iou=0.2919584641390968 and reward=0.02388546105779793 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (0.025) for 2X UP:bbox transition: [313, 100,  99,  60] -> [313,  98,  99,  60] w/ P(a|s)=1.0 and iou=0.31676101402904255 and reward=0.024802549889945735 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (0.026) for 2X UP:bbox transition: [313,  98,  99,  60] -> [313,  96,  99,  60] w/ P(a|s)=1.0 and iou=0.342534504391468 and reward=0.025773490362425433 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (0.027) for 2X UP:bbox transition: [313,  96,  99,  60] -> [313,  94,  99,  60] w/ P(a|s)=1.0 and iou=0.36933708727924236 and reward=0.026802582887774373 and discount=0.8953382542587164\n",
            "   |->> t=13 Diff-Reward (0.028) for 2X UP:bbox transition: [313,  94,  99,  60] -> [313,  92,  99,  60] w/ P(a|s)=1.0 and iou=0.39723165317315223 and reward=0.027894565893909873 and discount=0.8863848717161292\n",
            "   |->> Assigned losses: [1.8107670e-07 1.8523252e-07 1.8958706e-07 1.9415329e-07 1.9894543e-07\n",
            " 2.0397886e-07 2.0927034e-07 2.1483817e-07 2.2070225e-07 2.2688441e-07\n",
            " 2.3340853e-07 2.4030086e-07 2.4759021e-07]\n",
            "\u001b[92m>> Total frame loss: 2.7459686862130184e-06\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 11 with src: [313,  92,  99,  60] and target: [278,  55,  90,  56]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0011.jpg\n",
            "|->> Beginning tracking for bbox:[313  92  99  60]\n",
            "   \u001b[33m|->> #0/t=36-th Action selection: 1/2X LEFT (P(a|s) = 0.23999999463558197)\u001b[0m\n",
            "      |->> Bounding box moves to: [309  92  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.2403 0.     0.     0.     0.7597 0.     0.     0.     0.\n",
            " 0.    ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.4300186e-07 2.4027325e-01 2.9462284e-09 7.9701986e-06 8.9264624e-08\n",
            " 7.5971746e-01 3.5203351e-12 9.2355401e-07 3.9192236e-13 5.9775431e-08\n",
            " 4.2988256e-15], argmax=5\n",
            "   \u001b[33m|->> #1/t=37-th Action selection: 5/2X UP (P(a|s) = 0.9929999709129333)\u001b[0m\n",
            "      |->> Bounding box moves to: [309  90  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.0068 0.     0.     0.     0.9932 0.     0.     0.     0.\n",
            " 0.    ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.7629886e-09 6.8407841e-03 2.3599248e-10 2.4407247e-09 4.0068423e-07\n",
            " 9.9315888e-01 9.9798274e-11 1.2009210e-10 1.3000472e-13 3.3932608e-09\n",
            " 8.5495948e-14], argmax=5\n",
            "   \u001b[33m|->> #2/t=38-th Action selection: 5/2X UP (P(a|s) = 0.8140000104904175)\u001b[0m\n",
            "      |->> Bounding box moves to: [309  88  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.1862 0.     0.     0.     0.8138 0.     0.     0.     0.\n",
            " 0.    ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.5134335e-08 1.8616009e-01 6.4279563e-12 6.4714054e-12 9.3221271e-09\n",
            " 8.1383991e-01 3.2683477e-11 2.3133732e-12 7.8581060e-13 5.5795620e-12\n",
            " 1.5414857e-12], argmax=5\n",
            "   \u001b[33m|->> #3/t=39-th Action selection: 1/2X LEFT (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [305  88  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.], argmax=1\n",
            "         |->> Action Probabilities (RAW): [3.0279572e-17 9.9999046e-01 7.6770968e-13 3.2553201e-18 1.0809983e-18\n",
            " 9.5662253e-06 3.9181689e-17 2.2568233e-17 4.9528540e-19 7.7420807e-16\n",
            " 8.1831934e-24], argmax=1\n",
            "   \u001b[33m|->> #4/t=40-th Action selection: 5/2X UP (P(a|s) = 0.9990000128746033)\u001b[0m\n",
            "      |->> Bounding box moves to: [305  86  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.0012 0.     0.     0.     0.9988 0.     0.     0.     0.\n",
            " 0.    ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.46256566e-15 1.15357328e-03 2.15768726e-15 1.02993515e-17\n",
            " 3.69482124e-15 9.98846412e-01 1.53748999e-14 1.94409239e-10\n",
            " 1.47690822e-16 7.89977805e-12 1.38912159e-16], argmax=5\n",
            "   \u001b[33m|->> #5/t=41-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [305  84  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 3.000e-04 0.000e+00 0.000e+00 0.000e+00 9.997e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [4.8696317e-21 2.9161904e-04 2.2964359e-22 6.9469182e-25 1.7916415e-22\n",
            " 9.9970835e-01 1.2211569e-19 9.5366285e-16 2.3606142e-25 4.1439883e-17\n",
            " 6.5246032e-26], argmax=5\n",
            "   \u001b[33m|->> #6/t=42-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [305  82  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.0796445e-18 6.4838339e-08 5.9651158e-19 7.8117354e-20 1.1716459e-14\n",
            " 9.9999988e-01 7.7740321e-22 8.7976994e-18 5.7626289e-27 1.5100103e-16\n",
            " 1.0757682e-17], argmax=5\n",
            "   \u001b[33m|->> #7/t=43-th Action selection: 5/2X UP (P(a|s) = 0.9909999966621399)\u001b[0m\n",
            "      |->> Bounding box moves to: [305  80  99  60]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.0087 0.     0.     0.     0.9913 0.     0.     0.     0.\n",
            " 0.    ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [9.0893494e-20 8.6836871e-03 1.7585057e-12 4.9139282e-15 3.2990621e-07\n",
            " 9.9131584e-01 5.4904708e-20 5.1529603e-13 1.7604924e-27 3.2295445e-14\n",
            " 1.0118133e-07], argmax=5\n",
            "   \u001b[33m|->> #8/t=44-th Action selection: 10/SCALE UP (P(a|s) = 0.781000018119812)\u001b[0m\n",
            "      |->> Bounding box moves to: [303  79 101  62]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.0132 0.2057 0.     0.     0.     0.\n",
            " 0.7812], argmax=10\n",
            "         |->> Action Probabilities (RAW): [5.3919437e-18 1.8380530e-06 6.6338706e-19 8.2420583e-16 1.3167518e-02\n",
            " 2.0566921e-01 3.9985402e-25 2.5828353e-16 1.4426351e-31 2.9775841e-14\n",
            " 7.8116143e-01], argmax=10\n",
            "   \u001b[33m|->> #9/t=45-th Action selection: 5/2X UP (P(a|s) = 0.9980000257492065)\u001b[0m\n",
            "      |->> Bounding box moves to: [303  77 101  62]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.     0.9981 0.     0.     0.     0.\n",
            " 0.0019], argmax=5\n",
            "         |->> Action Probabilities (RAW): [4.6354900e-18 1.7127806e-09 1.2689344e-21 2.9386296e-17 1.1637098e-09\n",
            " 9.9805498e-01 3.4698740e-26 2.0454008e-15 4.1929246e-36 7.3483572e-19\n",
            " 1.9450430e-03], argmax=5\n",
            "   \u001b[33m|->> #10/t=46-th Action selection: 5/2X UP (P(a|s) = 0.6660000085830688)\u001b[0m\n",
            "      |->> Bounding box moves to: [303  75 101  62]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.     0.6664 0.     0.     0.     0.\n",
            " 0.3336], argmax=5\n",
            "         |->> Action Probabilities (RAW): [7.5002147e-17 8.7815362e-15 4.1516110e-26 7.2210831e-19 5.4333159e-06\n",
            " 6.6643471e-01 3.6296313e-34 8.1045573e-11 5.9632273e-38 1.8147146e-19\n",
            " 3.3355996e-01], argmax=5\n",
            "|->> Revisiting bbox: [303  77 101  62]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [313,  92,  99,  60] -> [303,  75, 101,  62] (Target was [278,  55,  90,  56])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.009) for 2X LEFT:bbox transition: [313,  92,  99,  60] -> [309,  92,  99,  60] w/ P(a|s)=0.24027325212955475 and iou=0.113703215336241 and reward=0.008519521325169033 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.013) for 2X UP:bbox transition: [309,  92,  99,  60] -> [309,  90,  99,  60] w/ P(a|s)=0.9931588768959045 and iou=0.12719433323067447 and reward=0.013491117894433469 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.014) for 2X UP:bbox transition: [309,  90,  99,  60] -> [309,  88,  99,  60] w/ P(a|s)=0.8138399124145508 and iou=0.14101631507845785 and reward=0.013821981847783382 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.011) for 2X LEFT:bbox transition: [309,  88,  99,  60] -> [305,  88,  99,  60] w/ P(a|s)=0.9999904632568359 and iou=0.15203021718602455 and reward=0.011013902107566698 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.015) for 2X UP:bbox transition: [305,  88,  99,  60] -> [305,  86,  99,  60] w/ P(a|s)=0.9988464117050171 and iou=0.1674641148325359 and reward=0.015433897646511346 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.016) for 2X UP:bbox transition: [305,  86,  99,  60] -> [305,  84,  99,  60] w/ P(a|s)=0.999708354473114 and iou=0.18331716779825413 and reward=0.015853052965718234 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.016) for 2X UP:bbox transition: [305,  84,  99,  60] -> [305,  82,  99,  60] w/ P(a|s)=0.9999998807907104 and iou=0.19960668633235004 and reward=0.01628951853409591 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (0.017) for 2X UP:bbox transition: [305,  82,  99,  60] -> [305,  80,  99,  60] w/ P(a|s)=0.9913158416748047 and iou=0.21635094715852443 and reward=0.01674426082617439 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (0.009) for SCALE UP:bbox transition: [305,  80,  99,  60] -> [303,  79, 101,  62] w/ P(a|s)=0.7811614274978638 and iou=0.22554760355671222 and reward=0.009196656398187786 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (0.018) for 2X UP:bbox transition: [303,  79, 101,  62] -> [303,  77, 101,  62] w/ P(a|s)=0.9980549812316895 and iou=0.24307083150021996 and reward=0.017523227943507746 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (0.018) for 2X UP:bbox transition: [303,  77, 101,  62] -> [303,  75, 101,  62] w/ P(a|s)=0.6664347052574158 and iou=0.26110243249274717 and reward=0.018031600992527208 and discount=0.9043820750088044\n",
            "   |->> Assigned losses: [1.2148653e-02 9.1685433e-05 2.7905526e-03 1.0701344e-07 1.7112672e-05\n",
            " 4.3975174e-06 1.5357163e-07 1.3612337e-04 2.0958579e-03 3.1165731e-05\n",
            " 6.6177798e-03]\n",
            "\u001b[92m>> Total frame loss: 0.023933589458465576\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 12 with src: [303,  75, 101,  62] and target: [253,  44,  91,  63]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0012.jpg\n",
            "|->> Beginning tracking for bbox:[303  75 101  62]\n",
            "   \u001b[33m|->> #0/t=47-th Action selection: 1/2X LEFT (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [297  75 101  62]\n",
            "         |->> Action Probabilities (Rounded): [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.], argmax=1\n",
            "         |->> Action Probabilities (RAW): [1.0324759e-11 9.9998295e-01 1.2338684e-14 4.6329194e-09 7.6234193e-12\n",
            " 4.2012683e-08 8.8788126e-12 1.7064200e-05 9.0039652e-21 7.7757129e-10\n",
            " 7.3771200e-10], argmax=1\n",
            "   \u001b[33m|->> #1/t=48-th Action selection: 1/2X LEFT (P(a|s) = 0.996999979019165)\u001b[0m\n",
            "      |->> Bounding box moves to: [291  75 101  62]\n",
            "         |->> Action Probabilities (Rounded): [0.    0.997 0.    0.    0.    0.    0.    0.003 0.    0.    0.   ], argmax=1\n",
            "         |->> Action Probabilities (RAW): [2.0562816e-12 9.9695301e-01 1.6459886e-14 3.5834774e-10 7.4774518e-12\n",
            " 5.9604965e-09 4.6764486e-09 3.0469061e-03 7.9847635e-20 7.1577233e-10\n",
            " 1.3684060e-11], argmax=1\n",
            "   \u001b[33m|->> #2/t=49-th Action selection: 1/2X LEFT (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [285  75 101  62]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 9.999e-01 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            " 1.000e-04 0.000e+00 0.000e+00 0.000e+00], argmax=1\n",
            "         |->> Action Probabilities (RAW): [1.2955917e-16 9.9990046e-01 2.9521184e-15 9.8009198e-11 4.7466786e-15\n",
            " 8.0375360e-09 2.2398004e-11 9.9568679e-05 2.7035763e-22 2.6424780e-12\n",
            " 1.8386912e-08], argmax=1\n",
            "   \u001b[33m|->> #3/t=50-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [285  77 101  62]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 4.000e-04 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            " 9.996e-01 0.000e+00 0.000e+00 0.000e+00], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.0619475e-24 3.5998295e-04 1.1354567e-21 1.0356452e-13 5.8432263e-14\n",
            " 1.4453046e-06 1.5588963e-08 9.9963856e-01 1.9015099e-29 2.1443155e-11\n",
            " 1.4576220e-09], argmax=7\n",
            "|->> Revisiting bbox: [285  75 101  62]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [303,  75, 101,  62] -> [285,  77, 101,  62] (Target was [253,  44,  91,  63])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.021) for 2X LEFT:bbox transition: [303,  75, 101,  62] -> [297,  75, 101,  62] w/ P(a|s)=0.9999829530715942 and iou=0.14336097607473072 and reward=0.020549031864302944 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.021) for 2X LEFT:bbox transition: [297,  75, 101,  62] -> [291,  75, 101,  62] w/ P(a|s)=0.996953010559082 and iou=0.16467618215360716 and reward=0.021315206078876436 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.022) for 2X LEFT:bbox transition: [291,  75, 101,  62] -> [285,  75, 101,  62] w/ P(a|s)=0.9999004602432251 and iou=0.18680122687246462 and reward=0.022125044718857456 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-0.014) for 2X DOWN:bbox transition: [285,  75, 101,  62] -> [285,  77, 101,  62] w/ P(a|s)=0.999638557434082 and iou=0.17310513447432763 and reward=-0.013696092398136989 and discount=0.970299\n",
            "   |->> Assigned losses: [ 3.5030084e-07  6.4395892e-05  2.1586029e-06 -4.8041884e-06]\n",
            "\u001b[92m>> Total frame loss: 6.210060382727534e-05\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 13 with src: [285,  77, 101,  62] and target: [236,  38,  81,  59]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0013.jpg\n",
            "|->> Beginning tracking for bbox:[285  77 101  62]\n",
            "   \u001b[33m|->> #0/t=51-th Action selection: 1/2X LEFT (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [279  77 101  62]\n",
            "         |->> Action Probabilities (Rounded): [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.], argmax=1\n",
            "         |->> Action Probabilities (RAW): [6.0858672e-30 1.0000000e+00 9.8560842e-24 1.3699414e-26 5.7825168e-26\n",
            " 3.3045502e-09 6.2600619e-23 4.9860081e-16 1.2882814e-34 1.0589358e-11\n",
            " 1.4685156e-27], argmax=1\n",
            "   \u001b[33m|->> #1/t=52-th Action selection: 7/2X DOWN (P(a|s) = 0.9980000257492065)\u001b[0m\n",
            "      |->> Bounding box moves to: [279  79 101  62]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 1.600e-03 0.000e+00 0.000e+00 0.000e+00 3.000e-04 0.000e+00\n",
            " 9.981e-01 0.000e+00 0.000e+00 0.000e+00], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.10255865e-14 1.60762225e-03 1.05204656e-18 4.40951858e-20\n",
            " 2.56615487e-16 2.64027447e-04 3.70445672e-13 9.98128355e-01\n",
            " 4.64834766e-19 2.84151946e-09 8.05403938e-11], argmax=7\n",
            "   \u001b[33m|->> #2/t=53-th Action selection: 1/2X LEFT (P(a|s) = 0.8870000243186951)\u001b[0m\n",
            "      |->> Bounding box moves to: [273  79 101  62]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 8.866e-01 0.000e+00 0.000e+00 0.000e+00 1.000e-04 0.000e+00\n",
            " 1.134e-01 0.000e+00 0.000e+00 0.000e+00], argmax=1\n",
            "         |->> Action Probabilities (RAW): [4.7308264e-12 8.8658494e-01 9.7780384e-10 1.5605095e-09 1.8342251e-09\n",
            " 5.8084523e-05 7.3605989e-08 1.1335674e-01 2.1746777e-15 1.8123380e-08\n",
            " 9.3539057e-08], argmax=1\n",
            "   \u001b[33m|->> #3/t=54-th Action selection: 1/2X LEFT (P(a|s) = 0.6520000100135803)\u001b[0m\n",
            "      |->> Bounding box moves to: [267  79 101  62]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.6523 0.     0.     0.     0.0011 0.     0.3467 0.     0.\n",
            " 0.    ], argmax=1\n",
            "         |->> Action Probabilities (RAW): [9.5267679e-14 6.5227091e-01 2.2178405e-11 5.0620176e-12 2.4315314e-08\n",
            " 1.0582519e-03 4.5412435e-08 3.4667030e-01 1.2304438e-15 4.4379055e-07\n",
            " 7.7489681e-12], argmax=1\n",
            "   \u001b[33m|->> #4/t=55-th Action selection: 7/2X DOWN (P(a|s) = 0.8679999709129333)\u001b[0m\n",
            "      |->> Bounding box moves to: [267  81 101  62]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.0376 0.     0.     0.     0.0947 0.     0.8677 0.     0.\n",
            " 0.    ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [3.3794665e-11 3.7568983e-02 2.0750723e-10 1.3129794e-14 3.4393641e-05\n",
            " 9.4676390e-02 2.1466003e-07 8.6772007e-01 5.1155103e-13 8.7047489e-09\n",
            " 6.3396094e-10], argmax=7\n",
            "|->> Revisiting bbox: [267  79 101  62]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [285,  77, 101,  62] -> [267,  81, 101,  62] (Target was [236,  38,  81,  59])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.012) for 2X LEFT:bbox transition: [285,  77, 101,  62] -> [279,  77, 101,  62] w/ P(a|s)=1.0 and iou=0.07392277015854488 and reward=0.01239022521094369 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.008) for 2X DOWN:bbox transition: [279,  77, 101,  62] -> [279,  79, 101,  62] w/ P(a|s)=0.998128354549408 and iou=0.06604229023848605 and reward=-0.00788047992005883 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.011) for 2X LEFT:bbox transition: [279,  79, 101,  62] -> [273,  79, 101,  62] w/ P(a|s)=0.8865849375724792 and iou=0.07727583178846717 and reward=0.011233541549981116 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.011) for 2X LEFT:bbox transition: [273,  79, 101,  62] -> [267,  79, 101,  62] w/ P(a|s)=0.6522709131240845 and iou=0.08874864411793709 and reward=0.011472812329469922 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-0.011) for 2X DOWN:bbox transition: [267,  79, 101,  62] -> [267,  81, 101,  62] w/ P(a|s)=0.8677200675010681 and iou=0.07811737135045406 and reward=-0.010631272767483033 and discount=0.96059601\n",
            "   |->> Assigned losses: [ 1.2407114e-07 -1.4615652e-05  1.3253647e-03  4.7566760e-03\n",
            " -1.4489918e-03]\n",
            "\u001b[92m>> Total frame loss: 0.004618557635694742\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 14 with src: [267,  81, 101,  62] and target: [221,  35,  79,  58]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0014.jpg\n",
            "|->> Beginning tracking for bbox:[267  81 101  62]\n",
            "   \u001b[33m|->> #0/t=56-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [267  79 101  62]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 1.000e-04 0.000e+00 0.000e+00 9.999e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [6.1358102e-10 1.5833190e-06 5.2390787e-05 5.3392853e-08 8.3072081e-08\n",
            " 9.9994588e-01 1.3945548e-09 1.4862447e-08 4.5461347e-12 2.9439335e-09\n",
            " 3.8562465e-08], argmax=5\n",
            "   \u001b[33m|->> #1/t=57-th Action selection: 5/2X UP (P(a|s) = 0.8759999871253967)\u001b[0m\n",
            "      |->> Bounding box moves to: [267  77 101  62]\n",
            "         |->> Action Probabilities (Rounded): [2.000e-04 2.260e-02 9.330e-02 1.900e-03 2.600e-03 8.759e-01 1.000e-04\n",
            " 2.600e-03 0.000e+00 1.000e-04 7.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.6655325e-04 2.2586180e-02 9.3284845e-02 1.9467229e-03 2.6449400e-03\n",
            " 8.7586212e-01 8.3207844e-05 2.6459340e-03 2.2077970e-07 1.2064048e-04\n",
            " 6.5865583e-04], argmax=5\n",
            "   \u001b[33m|->> #2/t=58-th Action selection: 5/2X UP (P(a|s) = 0.9929999709129333)\u001b[0m\n",
            "      |->> Bounding box moves to: [267  75 101  62]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 9.000e-04 2.000e-04 1.000e-04 8.000e-04 9.932e-01 0.000e+00\n",
            " 4.500e-03 0.000e+00 0.000e+00 3.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [4.5658893e-05 9.3657698e-04 1.6201011e-04 5.4103304e-05 7.9535122e-04\n",
            " 9.9321306e-01 1.1513865e-05 4.5041093e-03 1.0496108e-07 8.7178851e-06\n",
            " 2.6887376e-04], argmax=5\n",
            "   \u001b[33m|->> #3/t=59-th Action selection: 4/UP (P(a|s) = 0.07699999958276749)\u001b[0m\n",
            "      |->> Bounding box moves to: [267  74 101  62]\n",
            "         |->> Action Probabilities (Rounded): [1.000e-04 2.000e-04 6.000e-04 2.600e-03 7.720e-02 8.317e-01 1.000e-04\n",
            " 2.220e-02 0.000e+00 0.000e+00 6.530e-02], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.10388435e-04 1.55032758e-04 6.25087821e-04 2.60568899e-03\n",
            " 7.72448182e-02 8.31696510e-01 7.84571603e-05 2.21740119e-02\n",
            " 4.77719141e-07 1.57950435e-05 6.52937740e-02], argmax=5\n",
            "   \u001b[33m|->> #4/t=60-th Action selection: 5/2X UP (P(a|s) = 0.8669999837875366)\u001b[0m\n",
            "      |->> Bounding box moves to: [267  72 101  62]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 1.000e-04 1.100e-03 3.900e-03 1.740e-02 8.674e-01 1.000e-04\n",
            " 6.990e-02 0.000e+00 0.000e+00 4.010e-02], argmax=5\n",
            "         |->> Action Probabilities (RAW): [4.7167028e-05 7.7292600e-05 1.1221025e-03 3.9389273e-03 1.7395381e-02\n",
            " 8.6738807e-01 5.4948083e-05 6.9861121e-02 4.4429129e-08 7.9520987e-06\n",
            " 4.0107042e-02], argmax=5\n",
            "   \u001b[33m|->> #5/t=61-th Action selection: 5/2X UP (P(a|s) = 0.9990000128746033)\u001b[0m\n",
            "      |->> Bounding box moves to: [267  70 101  62]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 9.993e-01 0.000e+00\n",
            " 7.000e-04 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [4.2124711e-12 1.5700842e-06 2.8914880e-07 2.0384874e-08 3.9819342e-06\n",
            " 9.9925309e-01 3.6629459e-08 7.4039074e-04 6.9200505e-13 1.5920020e-09\n",
            " 6.1814279e-07], argmax=5\n",
            "|->> Revisiting bbox: [267  72 101  62]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [267,  81, 101,  62] -> [267,  70, 101,  62] (Target was [221,  35,  79,  58])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.007) for 2X UP:bbox transition: [267,  81, 101,  62] -> [267,  79, 101,  62] w/ P(a|s)=0.999945878982544 and iou=0.04450009632055481 and reward=0.006598105508916215 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.007) for 2X UP:bbox transition: [267,  79, 101,  62] -> [267,  77, 101,  62] w/ P(a|s)=0.8758621215820312 and iou=0.051182628925940284 and reward=0.006682532605385476 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.007) for 2X UP:bbox transition: [267,  77, 101,  62] -> [267,  75, 101,  62] w/ P(a|s)=0.9932130575180054 and iou=0.057951219512195125 and reward=0.006768590586254841 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.003) for UP:bbox transition: [267,  75, 101,  62] -> [267,  74, 101,  62] w/ P(a|s)=0.0772448182106018 and iou=0.06136830772242341 and reward=0.003417088210228285 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.007) for 2X UP:bbox transition: [267,  74, 101,  62] -> [267,  72, 101,  62] w/ P(a|s)=0.8673880696296692 and iou=0.06826913604570978 and reward=0.006900828323286368 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.007) for 2X UP:bbox transition: [267,  72, 101,  62] -> [267,  70, 101,  62] w/ P(a|s)=0.9992530941963196 and iou=0.0752602875557759 and reward=0.006991151510066129 and discount=0.9509900498999999\n",
            "   |->> Assigned losses: [3.5710588e-07 8.7688945e-04 4.5177349e-05 8.4905000e-03 9.4308687e-04\n",
            " 4.9676701e-06]\n",
            "\u001b[92m>> Total frame loss: 0.010360978543758392\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 15 with src: [267,  70, 101,  62] and target: [212,  33,  82,  60]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0015.jpg\n",
            "|->> Beginning tracking for bbox:[267  70 101  62]\n",
            "   \u001b[33m|->> #0/t=62-th Action selection: 5/2X UP (P(a|s) = 0.9409999847412109)\u001b[0m\n",
            "      |->> Bounding box moves to: [267  68 101  62]\n",
            "         |->> Action Probabilities (Rounded): [2.000e-04 1.000e-04 1.000e-04 3.000e-04 2.900e-02 9.412e-01 3.000e-04\n",
            " 2.690e-02 0.000e+00 1.000e-04 1.800e-03], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.04805256e-04 7.28688319e-05 9.07844151e-05 2.99480744e-04\n",
            " 2.90259160e-02 9.41210270e-01 2.75590341e-04 2.68872008e-02\n",
            " 1.40058855e-05 1.36105999e-04 1.78295374e-03], argmax=5\n",
            "   \u001b[33m|->> #1/t=63-th Action selection: 5/2X UP (P(a|s) = 0.9449999928474426)\u001b[0m\n",
            "      |->> Bounding box moves to: [267  66 101  62]\n",
            "         |->> Action Probabilities (Rounded): [5.000e-04 1.830e-02 2.000e-03 1.540e-02 3.900e-03 9.454e-01 8.500e-03\n",
            " 3.200e-03 1.000e-04 1.000e-04 2.300e-03], argmax=5\n",
            "         |->> Action Probabilities (RAW): [5.4560974e-04 1.8318325e-02 2.0205651e-03 1.5418953e-02 3.9373189e-03\n",
            " 9.4543391e-01 8.5456753e-03 3.1808100e-03 1.3497713e-04 1.2901565e-04\n",
            " 2.3348432e-03], argmax=5\n",
            "   \u001b[33m|->> #2/t=64-th Action selection: 1/2X LEFT (P(a|s) = 0.14800000190734863)\u001b[0m\n",
            "      |->> Bounding box moves to: [261  66 101  62]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 1.483e-01 3.000e-04 3.700e-03 3.400e-03 8.358e-01 8.000e-04\n",
            " 7.300e-03 1.000e-04 0.000e+00 4.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.0553074e-05 1.4826855e-01 2.5029003e-04 3.7089379e-03 3.3620633e-03\n",
            " 8.3578187e-01 7.8479701e-04 7.2746025e-03 1.2246968e-04 2.2232562e-05\n",
            " 3.9372023e-04], argmax=5\n",
            "   \u001b[33m|->> #3/t=65-th Action selection: 5/2X UP (P(a|s) = 0.9789999723434448)\u001b[0m\n",
            "      |->> Bounding box moves to: [261  64 101  62]\n",
            "         |->> Action Probabilities (Rounded): [4.000e-04 1.780e-02 0.000e+00 7.000e-04 3.000e-04 9.786e-01 1.100e-03\n",
            " 7.000e-04 4.000e-04 0.000e+00 1.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [4.0962728e-04 1.7758545e-02 6.1211404e-06 6.6471921e-04 2.5684683e-04\n",
            " 9.7856003e-01 1.0964458e-03 7.4576796e-04 3.8487016e-04 6.1292540e-06\n",
            " 1.1087934e-04], argmax=5\n",
            "   \u001b[33m|->> #4/t=66-th Action selection: 5/2X UP (P(a|s) = 0.9570000171661377)\u001b[0m\n",
            "      |->> Bounding box moves to: [261  62 101  62]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 1.000e-04 2.400e-03 1.000e-04 9.569e-01 0.000e+00\n",
            " 4.050e-02 0.000e+00 0.000e+00 1.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [9.0325329e-06 8.7563340e-06 5.5966218e-05 2.3825394e-03 7.5938951e-05\n",
            " 9.5691472e-01 8.0669206e-06 4.0482450e-02 2.9395278e-07 9.8932423e-07\n",
            " 6.1180013e-05], argmax=5\n",
            "|->> Revisiting bbox: [261  64 101  62]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [267,  70, 101,  62] -> [261,  62, 101,  62] (Target was [212,  33,  82,  60])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.005) for 2X UP:bbox transition: [267,  70, 101,  62] -> [267,  68, 101,  62] w/ P(a|s)=0.9412102699279785 and iou=0.06424288569525079 and reward=0.00544163581361079 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.005) for 2X UP:bbox transition: [267,  68, 101,  62] -> [267,  66, 101,  62] w/ P(a|s)=0.9454339146614075 and iou=0.06974074428393763 and reward=0.005497858588686844 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.017) for 2X LEFT:bbox transition: [267,  66, 101,  62] -> [261,  66, 101,  62] w/ P(a|s)=0.14826855063438416 and iou=0.08658050723933534 and reward=0.016839762955397714 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.007) for 2X UP:bbox transition: [261,  66, 101,  62] -> [261,  64, 101,  62] w/ P(a|s)=0.9785600304603577 and iou=0.09359413202933985 and reward=0.007013624790004502 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.007) for 2X UP:bbox transition: [261,  64, 101,  62] -> [261,  62, 101,  62] w/ P(a|s)=0.9569147229194641 and iou=0.10069888768579585 and reward=0.007104755656456005 and discount=0.96059601\n",
            "   |->> Assigned losses: [0.0003297  0.00030541 0.03150292 0.00014749 0.00030057]\n",
            "\u001b[92m>> Total frame loss: 0.032586097717285156\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 16 with src: [261,  62, 101,  62] and target: [204,  39,  88,  60]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0016.jpg\n",
            "|->> Beginning tracking for bbox:[261  62 101  62]\n",
            "   \u001b[33m|->> #0/t=67-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [261  60 101  62]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 9.999e-01 0.000e+00\n",
            " 1.000e-04 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [4.41838238e-05 1.42740328e-06 5.70064107e-10 8.75001547e-07\n",
            " 3.76722210e-06 9.99872446e-01 1.18524686e-05 6.54009782e-05\n",
            " 3.67754655e-12 1.13856945e-11 2.55750709e-09], argmax=5\n",
            "   \u001b[33m|->> #1/t=68-th Action selection: 5/2X UP (P(a|s) = 0.9800000190734863)\u001b[0m\n",
            "      |->> Bounding box moves to: [261  58 101  62]\n",
            "         |->> Action Probabilities (Rounded): [1.000e-04 2.000e-04 0.000e+00 1.000e-04 1.000e-04 9.805e-01 1.870e-02\n",
            " 4.000e-04 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [7.8048179e-05 1.7400816e-04 6.2505444e-07 1.0983249e-04 5.9198555e-05\n",
            " 9.8047775e-01 1.8653171e-02 4.4727561e-04 1.4949356e-08 1.1571578e-07\n",
            " 2.1558137e-08], argmax=5\n",
            "   \u001b[33m|->> #2/t=69-th Action selection: 5/2X UP (P(a|s) = 0.9490000009536743)\u001b[0m\n",
            "      |->> Bounding box moves to: [261  56 101  62]\n",
            "         |->> Action Probabilities (Rounded): [1.40e-03 0.00e+00 0.00e+00 2.00e-04 1.00e-04 9.49e-01 4.44e-02 4.90e-03\n",
            " 0.00e+00 0.00e+00 0.00e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.4074447e-03 8.2335437e-06 1.2804440e-08 2.1201526e-04 6.7208341e-05\n",
            " 9.4900066e-01 4.4433165e-02 4.8711435e-03 1.9070101e-10 8.2012406e-08\n",
            " 2.4575919e-09], argmax=5\n",
            "   \u001b[33m|->> #3/t=70-th Action selection: 5/2X UP (P(a|s) = 0.9010000228881836)\u001b[0m\n",
            "      |->> Bounding box moves to: [261  54 101  62]\n",
            "         |->> Action Probabilities (Rounded): [4.000e-04 0.000e+00 0.000e+00 1.000e-04 0.000e+00 9.007e-01 1.320e-02\n",
            " 8.560e-02 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.54339427e-04 4.43000135e-06 1.66661640e-09 1.11790709e-04\n",
            " 3.43982174e-06 9.00668919e-01 1.32234674e-02 8.56336206e-02\n",
            " 7.79807954e-11 2.90298896e-08 1.31944716e-11], argmax=5\n",
            "   \u001b[33m|->> #4/t=71-th Action selection: 5/2X UP (P(a|s) = 0.6589999794960022)\u001b[0m\n",
            "      |->> Bounding box moves to: [261  52 101  62]\n",
            "         |->> Action Probabilities (Rounded): [2.000e-04 0.000e+00 0.000e+00 0.000e+00 0.000e+00 6.587e-01 2.680e-02\n",
            " 3.143e-01 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.9462367e-04 1.4622748e-05 8.3696126e-09 3.2422220e-05 3.2367830e-06\n",
            " 6.5866005e-01 2.6770061e-02 3.1432369e-01 7.6472467e-10 1.3540252e-06\n",
            " 5.3718047e-10], argmax=5\n",
            "   \u001b[33m|->> #5/t=72-th Action selection: 5/2X UP (P(a|s) = 0.7400000095367432)\u001b[0m\n",
            "      |->> Bounding box moves to: [261  50 101  62]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 1.000e-04 0.000e+00 1.000e-04 0.000e+00 7.404e-01 2.680e-02\n",
            " 2.326e-01 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.8083987e-05 1.1845629e-04 6.9618501e-08 8.5547457e-05 6.7329910e-07\n",
            " 7.4036145e-01 2.6796501e-02 2.3260808e-01 8.2678380e-09 9.9354486e-07\n",
            " 3.8230390e-08], argmax=5\n",
            "   \u001b[33m|->> #6/t=73-th Action selection: 6/DOWN (P(a|s) = 0.949999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [261  51 101  62]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 7.000e-04 0.000e+00 1.300e-03 2.000e-04 4.560e-02 9.495e-01\n",
            " 2.400e-03 0.000e+00 3.000e-04 0.000e+00], argmax=6\n",
            "         |->> Action Probabilities (RAW): [1.5064825e-05 7.2995992e-04 1.4094256e-07 1.3318330e-03 1.5759797e-04\n",
            " 4.5580141e-02 9.4952744e-01 2.3951922e-03 6.5627845e-09 2.6243881e-04\n",
            " 2.5639400e-07], argmax=6\n",
            "   \u001b[33m|->> #7/t=74-th Action selection: 5/2X UP (P(a|s) = 0.37299999594688416)\u001b[0m\n",
            "      |->> Bounding box moves to: [261  49 101  62]\n",
            "         |->> Action Probabilities (Rounded): [4.000e-04 1.210e-02 0.000e+00 1.700e-03 1.000e-04 3.727e-01 6.056e-01\n",
            " 7.200e-03 0.000e+00 2.000e-04 0.000e+00], argmax=6\n",
            "         |->> Action Probabilities (RAW): [3.7380151e-04 1.2140888e-02 2.0956820e-06 1.6801486e-03 9.5447191e-05\n",
            " 3.7273347e-01 6.0557157e-01 7.2065541e-03 6.7457813e-07 1.9417172e-04\n",
            " 1.2467539e-06], argmax=6\n",
            "|->> Revisiting bbox: [261  50 101  62]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [261,  62, 101,  62] -> [261,  49, 101,  62] (Target was [204,  39,  88,  60])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.007) for 2X UP:bbox transition: [261,  62, 101,  62] -> [261,  60, 101,  62] w/ P(a|s)=0.9998724460601807 and iou=0.1170037743153005 and reward=0.006662263973790161 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.007) for 2X UP:bbox transition: [261,  60, 101,  62] -> [261,  58, 101,  62] w/ P(a|s)=0.9804777503013611 and iou=0.12374647064550677 and reward=0.0067426963302062715 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.007) for 2X UP:bbox transition: [261,  58, 101,  62] -> [261,  56, 101,  62] w/ P(a|s)=0.9490006566047668 and iou=0.13057106474679206 and reward=0.006824594101285289 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.007) for 2X UP:bbox transition: [261,  56, 101,  62] -> [261,  54, 101,  62] w/ P(a|s)=0.9006689190864563 and iou=0.13747905784961073 and reward=0.006907993102818671 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.007) for 2X UP:bbox transition: [261,  54, 101,  62] -> [261,  52, 101,  62] w/ P(a|s)=0.6586600542068481 and iou=0.14447198810114031 and reward=0.006992930251529583 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.007) for 2X UP:bbox transition: [261,  52, 101,  62] -> [261,  50, 101,  62] w/ P(a|s)=0.7403614521026611 and iou=0.15155143170707372 and reward=0.007079443605933405 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (-0.004) for DOWN:bbox transition: [261,  50, 101,  62] -> [261,  51, 101,  62] w/ P(a|s)=0.9495274424552917 and iou=0.1480007957032027 and reward=-0.0035506360038710105 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (0.007) for 2X UP:bbox transition: [261,  51, 101,  62] -> [261,  49, 101,  62] w/ P(a|s)=0.372733473777771 and iou=0.15512409927942353 and reward=0.0071233035762208186 and discount=0.9320653479069899\n",
            "   |->> Assigned losses: [ 8.4985220e-07  1.3160511e-04  3.5012970e-04  7.0123252e-04\n",
            "  2.8048272e-03  2.0238964e-03 -1.7312921e-04  6.5523530e-03]\n",
            "\u001b[92m>> Total frame loss: 0.012391764670610428\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 17 with src: [261,  49, 101,  62] and target: [206,  54,  88,  56]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Deer/img/0017.jpg\n",
            "|->> Beginning tracking for bbox:[261  49 101  62]\n",
            "   \u001b[33m|->> #0/t=75-th Action selection: 1/2X LEFT (P(a|s) = 0.9990000128746033)\u001b[0m\n",
            "      |->> Bounding box moves to: [255  49 101  62]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 9.991e-01 0.000e+00 9.000e-04 0.000e+00 0.000e+00 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=1\n",
            "         |->> Action Probabilities (RAW): [2.2313094e-10 9.9905485e-01 5.0468316e-13 9.3730108e-04 2.4576423e-08\n",
            " 5.1212442e-06 2.7601177e-06 8.3209739e-10 4.0953200e-13 5.7785040e-12\n",
            " 2.6403641e-12], argmax=1\n",
            "   \u001b[33m|->> #1/t=76-th Action selection: 1/2X LEFT (P(a|s) = 0.9940000176429749)\u001b[0m\n",
            "      |->> Bounding box moves to: [249  49 101  62]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 9.939e-01 0.000e+00 6.100e-03 0.000e+00 0.000e+00 1.000e-04\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=1\n",
            "         |->> Action Probabilities (RAW): [2.4547455e-09 9.9386239e-01 3.3893681e-13 6.0531329e-03 2.2517778e-08\n",
            " 2.8012940e-07 8.4203246e-05 3.6761886e-15 2.2169122e-17 2.9150064e-08\n",
            " 3.6859273e-11], argmax=1\n",
            "   \u001b[33m|->> #2/t=77-th Action selection: 1/2X LEFT (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [243  49 101  62]\n",
            "         |->> Action Probabilities (Rounded): [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.], argmax=1\n",
            "         |->> Action Probabilities (RAW): [1.0771690e-11 9.9999917e-01 1.5925274e-10 3.7415315e-08 7.9725191e-07\n",
            " 4.1987830e-11 1.8620014e-11 5.0536897e-18 3.5334387e-29 3.2483710e-14\n",
            " 1.6850994e-12], argmax=1\n",
            "   \u001b[33m|->> #3/t=78-th Action selection: 1/2X LEFT (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [237  49 101  62]\n",
            "         |->> Action Probabilities (Rounded): [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.], argmax=1\n",
            "         |->> Action Probabilities (RAW): [6.9572215e-32 1.0000000e+00 3.1381815e-28 4.1757355e-23 9.9728234e-19\n",
            " 2.0255028e-23 3.2258936e-25 8.5641362e-37 2.8941266e-37 3.5934548e-37\n",
            " 0.0000000e+00], argmax=1\n",
            "   \u001b[33m|->> #4/t=79-th Action selection: 1/2X LEFT (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [231  49 101  62]\n",
            "         |->> Action Probabilities (Rounded): [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.], argmax=1\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 1.0000000e+00 8.0731584e-34 3.3771834e-28 5.6962764e-19\n",
            " 6.5653622e-33 4.9598052e-33 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00], argmax=1\n",
            "   \u001b[33m|->> #5/t=80-th Action selection: 1/2X LEFT (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [225  49 101  62]\n",
            "         |->> Action Probabilities (Rounded): [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.], argmax=1\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 1.0000000e+00 7.0465475e-37 4.6582159e-28 7.8982603e-23\n",
            " 8.7152084e-30 2.5443721e-37 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            " 0.0000000e+00], argmax=1\n",
            "   \u001b[33m|->> #6/t=81-th Action selection: 1/2X LEFT (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [219  49 101  62]\n",
            "         |->> Action Probabilities (Rounded): [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.], argmax=1\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 1.0000000e+00 1.5414797e-38 0.0000000e+00 4.6924561e-29\n",
            " 1.2638677e-30 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.9700427e-37\n",
            " 0.0000000e+00], argmax=1\n",
            "   \u001b[33m|->> #7/t=82-th Action selection: 1/2X LEFT (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [213  49 101  62]\n",
            "         |->> Action Probabilities (Rounded): [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.], argmax=1\n",
            "         |->> Action Probabilities (RAW): [0.0000000e+00 1.0000000e+00 7.4636162e-23 4.4338334e-13 4.4898504e-23\n",
            " 7.8185906e-13 1.7991826e-25 5.4440288e-37 1.4066499e-27 1.9772823e-25\n",
            " 1.4648454e-27], argmax=1\n",
            "   \u001b[33m|->> #8/t=83-th Action selection: 1/2X LEFT (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [207  49 101  62]\n",
            "         |->> Action Probabilities (Rounded): [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.], argmax=1\n",
            "         |->> Action Probabilities (RAW): [1.0345732e-30 1.0000000e+00 3.7850045e-30 8.5594700e-36 4.6283544e-27\n",
            " 5.2257304e-12 3.0681316e-34 1.0788025e-22 0.0000000e+00 8.5556789e-22\n",
            " 3.6401024e-29], argmax=1\n",
            "   \u001b[33m|->> #9/t=84-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [207  47 101  62]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.8544641e-25 3.1799452e-08 3.3460081e-29 5.0316775e-22 1.5960678e-18\n",
            " 1.0000000e+00 6.6489012e-29 3.3847672e-13 2.9886908e-26 3.2855807e-10\n",
            " 3.1869633e-16], argmax=5\n",
            "   \u001b[33m|->> #10/t=85-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [207  45 101  62]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.6718749e-24 7.1040018e-09 6.8834855e-33 4.3752598e-18 2.6308591e-14\n",
            " 1.0000000e+00 9.7012522e-30 1.2603393e-14 1.0878858e-30 2.2397561e-13\n",
            " 9.9849122e-11], argmax=5\n",
            "             |->> IOU declining: [207  45 101  62]:0.7008663930688555 -> [207  43 101  62]:0.657041314971124.\n",
            "             |->> Overriding with STOP\n",
            "   \u001b[33m|->> #11/t=86-th Action selection: 8/STOP (P(a|s) = 0.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [207  45 101  62]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.5198130e-22 1.0495580e-10 9.4732488e-27 8.6499015e-13 3.9897468e-08\n",
            " 1.0000000e+00 9.9790081e-30 1.2104541e-20 1.6300903e-31 2.6693892e-15\n",
            " 6.2707278e-10], argmax=5\n",
            "         |->> Hit a STOP on the 86-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [261,  49, 101,  62] -> [207,  45, 101,  62] (Target was [206,  54,  88,  56])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.045) for 2X LEFT:bbox transition: [261,  49, 101,  62] -> [255,  49, 101,  62] w/ P(a|s)=0.9990548491477966 and iou=0.24250499666888742 and reward=0.04468868324563757 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.048) for 2X LEFT:bbox transition: [255,  49, 101,  62] -> [249,  49, 101,  62] w/ P(a|s)=0.9938623905181885 and iou=0.2906574394463668 and reward=0.048152442777479376 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.052) for 2X LEFT:bbox transition: [249,  49, 101,  62] -> [243,  49, 101,  62] w/ P(a|s)=0.9999991655349731 and iou=0.34269258459323254 and reward=0.05203514514686575 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.056) for 2X LEFT:bbox transition: [243,  49, 101,  62] -> [237,  49, 101,  62] w/ P(a|s)=1.0 and iou=0.39909977494373594 and reward=0.0564071903505034 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.061) for 2X LEFT:bbox transition: [237,  49, 101,  62] -> [231,  49, 101,  62] w/ P(a|s)=1.0 and iou=0.46045418950665623 and reward=0.06135441456292029 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.067) for 2X LEFT:bbox transition: [231,  49, 101,  62] -> [225,  49, 101,  62] w/ P(a|s)=1.0 and iou=0.5274365274365275 and reward=0.06698233792987124 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.073) for 2X LEFT:bbox transition: [225,  49, 101,  62] -> [219,  49, 101,  62] w/ P(a|s)=1.0 and iou=0.6008583690987125 and reward=0.07342184166218502 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (0.081) for 2X LEFT:bbox transition: [219,  49, 101,  62] -> [213,  49, 101,  62] w/ P(a|s)=1.0 and iou=0.6816952209197475 and reward=0.08083685182103506 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (0.089) for 2X LEFT:bbox transition: [213,  49, 101,  62] -> [207,  49, 101,  62] w/ P(a|s)=1.0 and iou=0.7711301044634378 and reward=0.08943488354369022 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (-0.024) for 2X UP:bbox transition: [207,  49, 101,  62] -> [207,  47, 101,  62] w/ P(a|s)=1.0 and iou=0.747072599531616 and reward=-0.024057504931821794 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (-0.046) for 2X UP:bbox transition: [207,  47, 101,  62] -> [207,  45, 101,  62] w/ P(a|s)=1.0 and iou=0.7008663930688555 and reward=-0.046206206462760524 and discount=0.9043820750088044\n",
            "   |->> t=12 Stop-Reward (1.0) for STOP:bbox transition: [207,  45, 101,  62] -> [207,  45, 101,  62] w/ P(a|s)=1.6300903423799137e-31 and iou=0.7008663930688555 and reward=1.0 and discount=0.8953382542587164\n",
            "   |->> Assigned losses: [ 4.2257518e-05  2.9348704e-04  5.1069162e-07  5.4806446e-07\n",
            "  5.9017140e-07  6.3786359e-07  6.9219425e-07  7.5447929e-07\n",
            "  8.2638053e-07 -2.2006901e-07 -4.1845021e-07  1.0307962e+01]\n",
            "\u001b[92m>> Total frame loss: 10.308302879333496\u001b[0m\n",
            "Final bounding box: [207  45 101  62] reached in 86 timesteps (originating from [321 146  99  60]). Target was [206  54  88  56]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 18 in t=86 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[92m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 2.0124852657318115\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.0008736085146665573\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 0.8777925968170166\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.0018642995273694396\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 4.866488933563232\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.01884937472641468\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 1.293099284172058\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.020811233669519424\n",
            "Layer Name: custom_rnn/conv2d/kernel:0, GRAD NORM = 0.8441552519798279\n",
            "Layer Name: custom_rnn/conv2d/bias:0, GRAD NORM = 0.04758233577013016\n",
            "Layer Name: custom_rnn/conv2d_1/kernel:0, GRAD NORM = 3.784324884414673\n",
            "Layer Name: custom_rnn/conv2d_1/bias:0, GRAD NORM = 0.04758233577013016\n",
            "Layer Name: custom_rnn/conv2d_2/kernel:0, GRAD NORM = 2.5182440280914307\n",
            "Layer Name: custom_rnn/conv2d_2/bias:0, GRAD NORM = 0.030956819653511047\n",
            "#################################################\n",
            "#################################################\n",
            "Finished Training On: ['adnet_datasets/OTB/Deer']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot losses\n",
        "fig = plt.figure()\n",
        "all_losses = np.concatenate([v for _, v in losses.items()])\n",
        "plt.plot(np.arange(len(all_losses)), all_losses) \n",
        "plt.xlabel('Number of Episodes')\n",
        "plt.ylabel('Avg Trajectory Loss')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "K8lR0icde6QZ",
        "outputId": "53bc9102-3cfe-4d54-d620-16d8c87aab42"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Avg Trajectory Loss')"
            ]
          },
          "metadata": {},
          "execution_count": 79
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model: tf.keras.Model,img: np.array,bbox: np.array) -> np.array:\n",
        "  ACTION_DIM=11\n",
        "  seen_bboxes = set()\n",
        "  for t in range(MAX_TRAJECTORY_LENGTH):\n",
        "    patch = getPatch(img, bbox)\n",
        "    a_prob, score = model(patch)\n",
        "    maxaction = np.argmax(a_prob)\n",
        "    a, bbox = selectAction(np.array(img), bbox, maxaction)\n",
        "    if isStop(a) or tuple(bbox) in seen_bboxes:\n",
        "      break \n",
        "  return bbox"
      ],
      "metadata": {
        "id": "PMkii6HvD9-9"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getPredictedBoxes(model: tf.keras.Model,dataset_index: int):\n",
        "  dataset = ALL_DATASETS_LIST[dataset_index]\n",
        "  model.clearActionHistory()\n",
        "  gt = get_ground_truths(\"%s/groundtruth_rect.txt\" % dataset)     \n",
        "  frames = sorted(glob.glob(os.path.join('%s/img' % dataset, '*.jpg')))\n",
        "  number_of_frames = len(frames)\n",
        "  start_frame = 1\n",
        "  predicted_boxes =[]\n",
        "  predicted_box = gt[0]\n",
        "  imgs = []\n",
        "  for f in range(len(frames)-10):\n",
        "    img = cv2.imread(frames[f + start_frame])\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    predicted_box = predict(model,img, predicted_box)\n",
        "    predicted_box = standardize_bbox(img,predicted_box)\n",
        "    predicted_boxes.append(predicted_box)\n",
        "    imgs.append(img)\n",
        "  return predicted_boxes,gt,imgs"
      ],
      "metadata": {
        "id": "jiY06CRLEC6O"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotNpImageBBoxesVideo(img: np.array,target_bbox: np.array, \n",
        "                      pred_bbox: np.array,directory) -> np.array:\n",
        "  '''\n",
        "  Plots the bounding boxes on an image and returns the bounding box\n",
        "  '''\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.imshow(img)\n",
        "  x2, y2, w2, h2 = target_bbox\n",
        "  x3, y3, w3, h3 = pred_bbox\n",
        "  rect2 = patches.Rectangle((x2, y2), w2, h2, linewidth=1, edgecolor='g', facecolor='none')\n",
        "  rect3 = patches.Rectangle((x3, y3), w3, h3, linewidth=1, edgecolor='r', facecolor='none')\n",
        "  ax.add_patch(rect2)\n",
        "  ax.add_patch(rect3)\n",
        "  plt.savefig(directory)\n",
        "  plt.close()\n",
        "  return img"
      ],
      "metadata": {
        "id": "rXhWZCCAEHLK"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createVideo(imageDir,videoDirectory):\n",
        "  img_array = []\n",
        "  for filename in glob.glob(imageDir+'/*.jpg'):\n",
        "      img = cv2.imread(filename)\n",
        "      height, width, layers = img.shape\n",
        "      size = (width,height)\n",
        "      img_array.append(img)\n",
        "  out = cv2.VideoWriter(videoDirectory+\".mp4\",cv2.VideoWriter_fourcc(*'MP4V'), 15, size)\n",
        "  for i in range(len(img_array)):\n",
        "      out.write(img_array[i])\n",
        "  out.release()"
      ],
      "metadata": {
        "id": "BgBY0Hd1EJzT"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_boxes,gt,imgs = getPredictedBoxes(adnet_model_rnn,13)\n",
        "#first you need to save the figures to create the video\n",
        "for i in range(len(imgs)):\n",
        "  plotNpImageBBoxesVideo(imgs[i],gt[i+1],predicted_boxes[i],\"/content/gdrive/MyDrive/deer-images/{}\".format(str(i)+\".jpg\"))\n",
        "createVideo(\"/content/gdrive/MyDrive/deer-images/\",\"/content/deer-1\")"
      ],
      "metadata": {
        "id": "-ncQIZiFEP5-"
      },
      "execution_count": 107,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "rnn-safe-reinforce.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}