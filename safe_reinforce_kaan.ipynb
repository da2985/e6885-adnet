{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c1BWwgpSXW9"
      },
      "source": [
        "### Please use the following two lines to load from Google Drive\n",
        "\n",
        "If your file is not there, upload it to https://drive.google.com/drive/folders/1tsPKyB2E1nW8Qw--kZ9GaeGW2u2-XoV6?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqT6TJ9DLT5v",
        "outputId": "a60d6194-28ca-446f-87b1-9487b20f68f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# This must be run within a Google Colab environment \n",
        "from google.colab import drive  \n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2sTHMZwqNPlW"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "sys.path.append('/content/gdrive/EE6885')\n",
        "\n",
        "os.chdir(\"/content/gdrive/My Drive/EE6885\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvlhZxrmdezd",
        "outputId": "47a3ea87-94ab-4072-f427-87d54ae8f4cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Basketball  Bolt  CarDark   Crossing  Dudek\tHuman6\t Man\t       RedTeam\n",
            "Bird2\t    Box   CarScale  Crowds    FaceOcc2\tJumping  Matrix        Skater\n",
            "BlurCar3    Boy   ClifBar   Deer      Fish\tLemming  MotorRolling  Skating1\n",
            "Board\t    Car4  Coupon    Doll      Human2\tLiquor\t Panda\n"
          ]
        }
      ],
      "source": [
        "!ls adnet_datasets/OTB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNOHmxvDD8wD",
        "outputId": "f8bc5dc6-8e5a-4eef-e868-db9c7f00ba36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hdf5storage\n",
            "  Downloading hdf5storage-0.1.18-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████▏                         | 10 kB 26.6 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 20 kB 33.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 30 kB 40.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 40 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 51 kB 16.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 53 kB 2.1 MB/s \n",
            "\u001b[?25hCollecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.15.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 37.8 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 47.8 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 55.0 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 61.9 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 63.0 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61 kB 18.9 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 20.9 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 22.9 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92 kB 25.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |█████                           | 174 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |███████                         | 245 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 256 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |████████                        | 276 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 286 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 307 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 337 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 358 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 368 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 389 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 399 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 430 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 440 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 460 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 471 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 481 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 501 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 512 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 532 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 542 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 552 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 563 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 573 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 583 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 604 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 614 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 624 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 634 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 645 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 655 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 675 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 686 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 696 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 706 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 716 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 727 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 737 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 747 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 757 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 768 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 778 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 788 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 798 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 808 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 819 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 829 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 849 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 860 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 870 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 880 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 890 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 901 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 911 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 921 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 931 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 942 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 952 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 962 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 972 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 983 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 993 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0 MB 27.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0 MB 27.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.0 MB 27.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0 MB 27.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0 MB 27.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1 MB 27.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1 MB 27.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.1 MB 27.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1 MB 27.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1 MB 27.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.1 MB 27.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 27.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from hdf5storage) (1.19.5)\n",
            "Requirement already satisfied: h5py>=2.1 in /usr/local/lib/python3.7/dist-packages (from hdf5storage) (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.1->hdf5storage) (1.5.2)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons, hdf5storage\n",
            "Successfully installed hdf5storage-0.1.18 tensorflow-addons-0.15.0\n"
          ]
        }
      ],
      "source": [
        "pip install hdf5storage tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gNmhYpyeDLrQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "import tensorflow_probability as tfp\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow.experimental.numpy as tnp\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "import cv2\n",
        "import glob\n",
        "import hdf5storage\n",
        "import math\n",
        "import random\n",
        "import re\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.patches as patches\n",
        "import scipy.io as sio\n",
        "\n",
        "import linecache\n",
        "\n",
        "from typing import Dict, List, Tuple\n",
        "from operator import add\n",
        "import copy\n",
        "\n",
        "from numpy.random import seed\n",
        "from datetime import date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UsXgP5KrEGNW"
      },
      "outputs": [],
      "source": [
        " %load_ext autoreload \n",
        " %autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configurations"
      ],
      "metadata": {
        "id": "HdgRU7dpw6t4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "G3xZrSk9XdEA"
      },
      "outputs": [],
      "source": [
        "#@markdown Network configurations\n",
        "LEARNING_RATE = 1e-4 #@param {type:\"number\"}\n",
        "GOAL_IOU = 0.7 #@param {type:\"number\"}\n",
        "\n",
        "# The length of the action buffer\n",
        "L = 10 #@param {type:\"number\"}\n",
        "# Max Trajectory Length \n",
        "MAX_TRAJECTORY_LENGTH = 20 #@param {type:\"number\"}\n",
        "POLICY_TYPE = \"stochastic\" #@param [\"deterministic\", \"stochastic\"] {type:\"string\"}\n",
        "DROPOUT_4 = 0.5 #@param {type:\"number\"}\n",
        "DROPOUT_5 = 0.5 #@param {type:\"number\"}\n",
        "N_EPOCHS =  5#@param {type:\"number\"}\n",
        "\n",
        "# Number of retries to collect sequence loss sum (to reduce variance)\n",
        "N_RETRIES =   1#@param {type:\"number\"}\n",
        "\n",
        "# Randomizes the order in which frames are trained on from a video clip\n",
        "RANDOMIZE_TRAINING = True #@param {type:\"boolean\"}\n",
        "\n",
        "# The paper uses sum. I thought avg would help address giant swings, but the training was taking way too long\n",
        "# with negligible updates\n",
        "GRAD_ACCUM_SCHEME = \"sum\" #@param [\"avg\", \"sum\"] {type:\"string\"}\n",
        "\n",
        "# Use to avoid overly long trajectories. \n",
        "# During trajectory collection, we were not receiving \n",
        "# enough positvie signals\n",
        "PREMATURE_BREAK = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Loss/Reward Constants\n",
        "# This is a probability offset for adding noise since log(P(a|s)=1)=0\n",
        "PROB_OFFSET = 1e-5 #@param {type:\"number\"} \n",
        "# This is the discount factor\n",
        "GAMMA = 0.99 #@param {type:\"number\"}\n",
        "\n",
        "# final_bbox is used in original Ad Net where  the final bounding box placement \n",
        "# is used in reward calculationfor all actions in a trajectory\n",
        "# individ_bbox individually assign rewards per each bounding box.\n",
        "# only_final_bbox only gives a reward to the final action\n",
        "REWARD_SCHEME = \"only_final_bbox\" #@param [\"only_final_bbox\", \"final_bbox\", \"individ_bbox\"] {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Bounding Box/Patch Constants (probably avoid touching)\n",
        "ALPHA = 0.03 #@param {type:\"number\"}\n",
        "MIN_WINDOW_SIZE = 10 #@param {type:\"number\"}\n",
        "PATCH_X = 112 #@param {type:\"number\"}\n",
        "PATCH_Y = 112 #@param {type:\"number\"}\n",
        "N_CHANNELS = 3 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown ---\n",
        "RANDOM_SEED = 6885\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed(RANDOM_SEED)\n",
        "tf.random.set_seed(RANDOM_SEED)\n",
        "\n",
        "DATASET_PATH = \"adnet_datasets/OTB/*\" #@param {type:\"string\"}\n",
        "ALL_DATASETS_LIST = glob.glob(DATASET_PATH)"
      ],
      "metadata": {
        "id": "AQ4YPvJCt9Dg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Successful Configurations (Minimize Me Please)"
      ],
      "metadata": {
        "id": "QCB-wEWrfk6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### SUCCESSFUL CONFIGS\n",
        "\n",
        "# 12/18 4:41 PM\n",
        "# #@markdown Network configurations\n",
        "# LEARNING_RATE = 1e-4 #@param {type:\"number\"}\n",
        "# # The length of the action buffer\n",
        "# L = 10 #@param {type:\"number\"}\n",
        "# # Max Trajectory Length \n",
        "# MAX_TRAJECTORY_LENGTH = 20 #@param {type:\"number\"}\n",
        "# POLICY_TYPE = \"stochastic\" #@param [\"deterministic\", \"stochastic\"] {type:\"string\"}\n",
        "# DROPOUT_4 = 0.5 #@param {type:\"number\"}\n",
        "# DROPOUT_5 = 0.5 #@param {type:\"number\"}\n",
        "# N_EPOCHS =  1#@param {type:\"number\"}\n",
        "\n",
        "# # Number of retries to collect sequence loss sum (to reduce variance)\n",
        "# N_RETRIES =  4 #@param {type:\"number\"}\n",
        "\n",
        "# # Randomizes the order in which frames are trained on from a video clip\n",
        "# RANDOMIZE_TRAINING = True #@param {type:\"boolean\"}\n",
        "# GRAD_ACCUM_SCHEME = \"sum\" #@param [\"avg\", \"sum\"] {type:\"string\"}\n",
        "# # The paper uses sum\n",
        "\n",
        "\n",
        "# #@markdown ---\n",
        "# #@markdown Loss/Reward Constants\n",
        "# # This is a probability offset for adding noise since log(P(a|s)=1)=0\n",
        "# PROB_OFFSET = 1e-5 #@param {type:\"number\"} \n",
        "# # This is the discount factor\n",
        "# GAMMA = 0.99 #@param {type:\"number\"}\n",
        "# REWARD_SCHEME = \"final_bbox\" #@param [\"final_bbox\", \"individ_bbox\"] {type:\"string\"}\n",
        "\n",
        "# #@markdown ---\n",
        "# #@markdown Bounding Box/Patch Constants (probably avoid touching)\n",
        "# ALPHA = 0.03 #@param {type:\"number\"}\n",
        "# MIN_WINDOW_SIZE = 10 #@param {type:\"number\"}\n",
        "# PATCH_X = 112 #@param {type:\"number\"}\n",
        "# PATCH_Y = 112 #@param {type:\"number\"}\n",
        "# N_CHANNELS = 3 #@param {type:\"number\"}\n",
        "\n",
        "# #@markdown ---\n",
        "# RANDOM_SEED = 6885\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mKjyrVB3fdcT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8s6YHABjUG5"
      },
      "source": [
        "## Model Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfRbj1tuEIyA",
        "outputId": "f7c85d7a-fd9e-44f1-949d-7b06ba1dfbeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "class ADNET(tf.keras.Model):\n",
        "\n",
        "    ACTION_DIM = 11\n",
        "    K = 10\n",
        "    CONF_SCORE_DIM = 2\n",
        "\n",
        "    def __init__(self):\n",
        "        super(ADNET, self).__init__()\n",
        "\n",
        "        self.action_history = tf.keras.layers.Input(shape = (1,1, ADNET.ACTION_DIM * ADNET.K))\n",
        "\n",
        "        self.conv1 = tf.keras.layers.Conv2D(filters = 96, kernel_size = (7, 7), strides = (2, 2), padding = 'VALID', activation = 'relu', name = 'conv_1')\n",
        "        self.max1  = tf.keras.layers.MaxPooling2D(pool_size=(3,3), strides = (1, 1), padding = 'VALID')\n",
        "        self.conv2 = tf.keras.layers.Conv2D(filters = 256, kernel_size = (5, 5), strides = (2, 2), padding = 'VALID', activation = 'relu', name = 'conv_2')\n",
        "        self.max2  = tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides = (2, 2), padding = 'VALID')\n",
        "        self.conv3 = tf.keras.layers.Conv2D(filters = 512, kernel_size = (3, 3), strides = (2, 2), padding = 'VALID', activation = 'relu', name = 'conv_3')\n",
        "        self.max3  = tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides = (1, 1), padding = 'VALID')\n",
        "        \n",
        "        self.fc1 = tf.keras.layers.Conv2D(filters = 512, kernel_size = (3, 3), padding = 'VALID', activation = 'relu', name = 'fc1')\n",
        "        self.fc2 = tf.keras.layers.Conv2D(filters = 512, kernel_size = (1,1), padding = 'VALID', activation = 'relu', name = 'fc2')\n",
        "        self.fc3 = tf.keras.layers.Conv2D(filters = 11, kernel_size = (1,1), padding = 'VALID', name = 'fc3',activation=\"softmax\")\n",
        "        self.fc4 = tf.keras.layers.Conv2D(filters = 2, kernel_size = (1,1), padding = 'VALID', name = 'fc4',activation=\"softmax\")\n",
        "\n",
        "        # TODO: ADD A SEED\n",
        "        self.dropout1=tf.keras.layers.Dropout(DROPOUT_4)\n",
        "        self.dropout2=tf.keras.layers.Dropout(DROPOUT_5)\n",
        "        \n",
        "\n",
        "    def build(self):\n",
        "      super(ADNET, self).build((None, 112, 112, 3))\n",
        "      self.action_history = np.zeros(shape = (1,1,1,110))\n",
        "\n",
        "\n",
        "    def call(self, input_tensor, training=False):\n",
        "        x = self.conv1(input_tensor)\n",
        "        x = self.max1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.max2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.max3(x)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = tf.keras.layers.Concatenate(axis=-1)([x, self.action_history])\n",
        "        action = self.fc3(x)\n",
        "        confidence = self.fc4(x)\n",
        "        return [action, confidence]\n",
        "\n",
        "\n",
        "    def compile(self, optimizer):\n",
        "   \t\tsuper().compile(optimizer, loss={\n",
        "         'output_1':tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "         'output_2': tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "         })\n",
        "     \n",
        "    def getEmbedding(self,input_tensor):\n",
        "        x = self.conv1(input_tensor)\n",
        "        x = self.max1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.max2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.max3(x)\n",
        "        return tf.reshape(x,(-1,))\n",
        "\n",
        "    def getFC1(self,input_tensor):\n",
        "        x = self.conv1(input_tensor)\n",
        "        x = self.max1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.max2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.max3(x)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "    def setActionHistory(self, action_history):\n",
        "      self.action_history = action_history.reshape(\n",
        "          (1, 1, 1, ADNET.ACTION_DIM * ADNET.K))\n",
        "\n",
        "    def updateActionHistory(self, a: int=8) -> tnp.ndarray:\n",
        "      '''\n",
        "      Left-to-right FIFO queue of actions\n",
        "      '''\n",
        "      ah = np.array(self.action_history).flatten()\n",
        "      ah[ADNET.ACTION_DIM:] = ah[:-ADNET.ACTION_DIM]\n",
        "      ah[:ADNET.ACTION_DIM] = 0 \n",
        "      ah[a] = 1\n",
        "      self.setActionHistory(ah)\n",
        "      return ah\n",
        "\n",
        "    def clearActionHistory(self):\n",
        "      self.action_history = tf.zeros((1, 1, 1, ADNET.ACTION_DIM * ADNET.K))\n",
        "\n",
        "    def getPrettyActionHistory(self):\n",
        "      action_hist = tf.reshape(self.action_history, [-1])\n",
        "      sbuffer = \"[\"\n",
        "      for i, x in enumerate(action_hist):\n",
        "        if i > 0 and i % ADNET.ACTION_DIM == 0:\n",
        "          sbuffer+= \"\\x1b[35m,\\x1b[0m\"\n",
        "        if x == 1:\n",
        "          sbuffer += \"\\x1b[35m{0}\\x1b[0m\".format(int(x))\n",
        "        else:\n",
        "          sbuffer += \"{0}\".format(int(x))\n",
        "      sbuffer += \"]\"\n",
        "      return sbuffer \n",
        "\n",
        "\n",
        "    def debugModelSummary(self):\n",
        "      '''\n",
        "      call model.debugModelSummary().summary() to get around the inconvenience \n",
        "      from model.summary() returning 'multiple' for each layer's output shape\n",
        "      '''\n",
        "      dummyInput = tf.keras.layers.Input(shape = (112,112,3))\n",
        "      return tf.keras.Model(inputs=[dummyInput], outputs = self.call(dummyInput))\n",
        "\n",
        "def setWeights(model, weights, weights2):\n",
        "  model.layers[0].set_weights([weights2[\"conv1f\"],tf.reshape(weights2[\"conv1b\"],(96,))])\n",
        "  model.layers[2].set_weights([weights2[\"conv2f\"],tf.reshape(weights2[\"conv2b\"],(256,))])\n",
        "  model.layers[4].set_weights([weights2[\"conv3f\"],tf.reshape(weights2[\"conv3b\"],(512,))])\n",
        "  \n",
        "  model.layers[6].set_weights([weights[\"fc4f\"],tf.reshape(weights[\"fc4b\"],(512,))])\n",
        "  model.layers[7].set_weights([weights[\"fc5f\"],tf.reshape(weights[\"fc5b\"],(512,))])\n",
        "  model.layers[8].set_weights([weights[\"fc6_1f\"],tf.zeros(11)])\n",
        "  model.layers[9].set_weights([weights[\"fc6_2f\"],tf.zeros(2)])\n",
        "  \n",
        "  return model\n",
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "WwHHmGrxq-b6"
      },
      "outputs": [],
      "source": [
        "class ADNET_v2(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(ADNET_v2, self).__init__()\n",
        "\n",
        "        #self.action_history = tf.keras.layers.Input(shape = (1,1,110))\n",
        "        self.action_history = tf.keras.layers.Input(shape = (110))\n",
        "\n",
        "        self.resnet=tf.keras.applications.ResNet50V2(include_top=False,weights=\"imagenet\",input_shape=(112,112,3),pooling=\"max\")\n",
        "        #self.resnet = tf.keras.applications.ResNet50V2(include_top=False,weights=\"imagenet\",input_shape=(112,112,3),pooling=None)\n",
        "        #self.conv1 = tf.keras.layers.Conv2D(filters = 128, kernel_size = (4,4), padding = 'VALID', name = 'fc4',activation=\"relu\")\n",
        "        \n",
        "        self.fc1 = tf.keras.layers.Dense(512,kernel_initializer='glorot_uniform',activation = 'relu', name = 'fc1')\n",
        "        self.fc2 = tf.keras.layers.Dense(512,kernel_initializer='glorot_uniform', activation = 'relu', name = 'fc2')\n",
        "        self.fc3 = tf.keras.layers.Dense(11,kernel_initializer='glorot_uniform', name = 'fc3',activation=\"softmax\")\n",
        "        self.fc4 = tf.keras.layers.Dense(2,kernel_initializer='glorot_uniform',name = 'fc4',activation=\"softmax\")\n",
        "\n",
        "        self.dropout1=tf.keras.layers.Dropout(0)\n",
        "        self.dropout2=tf.keras.layers.Dropout(0)\n",
        "        \n",
        "\n",
        "    def build(self, action_history):\n",
        "      super(ADNET_v2, self).build((None, 112, 112, 3))\n",
        "      self.action_history=action_history\n",
        "      self.resnet.trainable = False\n",
        "\n",
        "\n",
        "    def setActionHistory(self, action_history):\n",
        "      self.action_history=action_history\n",
        "\n",
        "\n",
        "    def call(self, input_tensor, training=False):\n",
        "        x = self.resnet(input_tensor)\n",
        "        #x = self.conv1(x)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x=  self.dropout1(x)\n",
        "        x = self.fc2(x)\n",
        "        x=  self.dropout2(x)\n",
        "        x = tf.keras.layers.Concatenate(axis=-1)([x, self.action_history])\n",
        "        action = self.fc3(x)\n",
        "        confidence = self.fc4(x)\n",
        "        return [action, confidence]\n",
        "\n",
        "     \n",
        "    def debugModelSummary(self):\n",
        "      '''\n",
        "      call model.debugModelSummary().summary() to get around the inconvenience \n",
        "      from model.summary() returning 'multiple' for each layer's output shape\n",
        "      '''\n",
        "      dummyInput = tf.keras.layers.Input(shape = (112,112,3))\n",
        "      return tf.keras.Model(inputs=[dummyInput], outputs = self.call(dummyInput))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ADNET_v3(tf.keras.Model):\n",
        "\n",
        "    ACTION_DIM = 11\n",
        "    K = 10\n",
        "    CONF_SCORE_DIM = 2\n",
        "\n",
        "\n",
        "    def __init__(self):\n",
        "        super(ADNET_v3, self).__init__()\n",
        "\n",
        "        self.conv1 = tf.keras.layers.Conv2D(filters = 96, kernel_size = (7, 7), strides = (2, 2), padding = 'VALID', activation = 'relu', name = 'conv_1')\n",
        "        self.max1  = tf.keras.layers.MaxPooling2D(pool_size=(3,3), strides = (1, 1), padding = 'VALID')\n",
        "        self.conv2 = tf.keras.layers.Conv2D(filters = 256, kernel_size = (5, 5), strides = (2, 2), padding = 'VALID', activation = 'relu', name = 'conv_2')\n",
        "        self.max2  = tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides = (2, 2), padding = 'VALID')\n",
        "        self.conv3 = tf.keras.layers.Conv2D(filters = 512, kernel_size = (3, 3), strides = (2, 2), padding = 'VALID', activation = 'relu', name = 'conv_3')\n",
        "        self.max3  = tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides = (1, 1), padding = 'VALID')\n",
        "        \n",
        "        self.fc1 = tf.keras.layers.Conv2D(filters = 512, kernel_size = (3, 3), padding = 'VALID', activation = 'relu', name = 'fc1')\n",
        "        self.rnn = CustomRNN()\n",
        "        \n",
        "    def build(self,action_history):\n",
        "      super(ADNET_v3, self).build((None, 112, 112, 3))\n",
        "      self.rnn.setActionHistory(action_history)\n",
        "\n",
        "    def call(self, input_tensor, training=False):\n",
        "        x = self.conv1(input_tensor)\n",
        "        x = self.max1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.max2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.max3(x)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        action,confidence = self.rnn(x)\n",
        "        return [action, confidence]\n",
        "\n",
        "    def callForAction(self, input_tensor, training=False):\n",
        "      '''\n",
        "      Wrapper action for model.call() to only output action probabilities.\n",
        "      For RL purposes, this is the only relevant output (as of 12/2/2021).\n",
        "      '''\n",
        "      return self.call(input_tensor, training)[0]\n",
        "\n",
        "    def clearActionHistory(self):\n",
        "      self.rnn.clearActionHistory()\n",
        "\n",
        "    def compile(self, optimizer):\n",
        "      super().compile(optimizer, loss={\n",
        "         'output_1':tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "         'output_2': tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "         })\n",
        "      \n",
        "    def debugModelSummary(self):\n",
        "      '''\n",
        "      call model.debugModelSummary().summary() to get around the inconvenience \n",
        "      from model.summary() returning 'multiple' for each layer's output shape\n",
        "      '''\n",
        "      dummyInput = tf.keras.layers.Input(shape = (112,112,3))\n",
        "      return tf.keras.Model(inputs=[dummyInput], outputs = self.call(dummyInput))\n",
        "\n",
        "class CustomRNN(layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(CustomRNN, self).__init__()\n",
        "        self.projection_1 = tf.keras.layers.Conv2D(filters = 256, kernel_size = (1, 1), padding = 'VALID')\n",
        "        self.projection_2 = tf.keras.layers.Conv2D(filters = 256, kernel_size = (1, 1), padding = 'VALID')\n",
        "        self.action_history = tf.zeros(shape = (1,1,1,256))\n",
        "        self.action_classifier = tf.keras.layers.Conv2D(filters = 11, kernel_size = (1,1), padding = 'VALID',activation=\"softmax\")\n",
        "        self.confidence_classifier = tf.keras.layers.Conv2D(filters = 2, kernel_size = (1,1), padding = 'VALID',trainable=False,activation=\"softmax\")\n",
        "\n",
        "    def call(self, input):\n",
        "        h = self.projection_1(self.action_history)\n",
        "        y = h + self.projection_2(input)\n",
        "        new_action_history = tf.math.tanh(y)\n",
        "        self.setActionHistory(new_action_history)\n",
        "        action = self.action_classifier(y)\n",
        "        confidence = self.confidence_classifier(y)\n",
        "        return action,confidence\n",
        "\n",
        "    def setActionHistory(self, action_history):\n",
        "      self.action_history = action_history\n",
        "    \n",
        "    def clearActionHistory(self):\n",
        "      self.setActionHistory(tf.zeros((1, 1, 1, 256)))"
      ],
      "metadata": {
        "id": "bCLcyTuXD64i"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcjMuA1EjRsE"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xY2WCmjC2gLN"
      },
      "source": [
        "### Plotting & Debugging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "NtQ22_87T8MQ"
      },
      "outputs": [],
      "source": [
        "def get_ground_truths(ground_truth_file: str) -> np.array:\n",
        "  '''\n",
        "  Use me to convert a ground_truth_file to a numpy array\n",
        "  '''\n",
        "  with open(ground_truth_file) as f:\n",
        "    ground_truths = f.readlines()\n",
        "    to_nparray = lambda s: np.array(re.findall('\\d+', s), dtype=int)\n",
        "    truths = list(map(to_nparray, ground_truths))\n",
        "    return np.asarray(truths)\n",
        "  return None\n",
        "\n",
        "def plotNpImageBBox(img: np.array, bbox: np.array) -> np.array:\n",
        "  '''\n",
        "  Plots the bounding box on an image and returns the bounding box\n",
        "  '''\n",
        "  fig, ax = plt.subplots()\n",
        "  x, y, w, h = bbox\n",
        "  rect = patches.Rectangle((x, y), w, h, linewidth=1, edgecolor='r', facecolor='none')\n",
        "  ax.add_patch(rect)\n",
        "  plt.imshow(img)\n",
        "  return bbox\n",
        "\n",
        "def plotNpImageBBoxes(img: np.array, src_bbox: np.array, target_bbox: np.array, \n",
        "                      pred_bbox: np.array) -> np.array:\n",
        "  '''\n",
        "  Plots the bounding boxes on an image and returns the bounding box\n",
        "  '''\n",
        "  fig, ax = plt.subplots()\n",
        "  x1, y1, w1, h1 = src_bbox\n",
        "  x2, y2, w2, h2 = target_bbox\n",
        "  x3, y3, w3, h3 = pred_bbox\n",
        "  rect1 = patches.Rectangle((x1, y1), w1, h1, linewidth=1, edgecolor='b', facecolor='none')\n",
        "  rect2 = patches.Rectangle((x2, y2), w2, h2, linewidth=1, edgecolor='g', facecolor='none')\n",
        "  rect3 = patches.Rectangle((x3, y3), w3, h3, linewidth=1, edgecolor='r', facecolor='none')\n",
        "  ax.add_patch(rect1)\n",
        "  ax.add_patch(rect2)\n",
        "  ax.add_patch(rect3)\n",
        "  plt.imshow(img)\n",
        "  return pred_bbox  \n",
        "\n",
        "def plotImageBBox(img: str, bbox: np.array) -> np.array:\n",
        "  '''\n",
        "  Plots the bounding box on an image (from given filepath) and returns the \n",
        "  bounding box\n",
        "  '''\n",
        "  img = cv2.imread(img)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  plotNpImageBBox(img, bbox)\n",
        "  return bbox\n",
        "\n",
        "def plotDatasetImageBBox(dataset: str, frame_no: int) -> Tuple[np.array, int]:\n",
        "  '''\n",
        "  Plot an image's bounding box. Returns the ground truth and frame number.\n",
        "  WORKS FOR OTB100\n",
        "  '''\n",
        "  imgs = sorted(glob.glob(\"{0}/img/*\".format(dataset)))\n",
        "  gt = get_ground_truths(\"{0}/groundtruth_rect.txt\".format(dataset))\n",
        "  plotImageBBox(imgs[frame_no], gt[frame_no])\n",
        "  return gt[frame_no], frame_no\n",
        "\n",
        "\n",
        "# print(plotDatasetImageBBox(\"adnet_datasets/OTB/Basketball\", 50)[0])\n",
        "#print(plotDatasetImageBBox(\"adnet_datasets/OTB/BlurBody\", 10)[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX5bfwFm2c80"
      },
      "source": [
        "### Movement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "VzDdHq04ERNg"
      },
      "outputs": [],
      "source": [
        "STOP_ACTION_INDEX = 8\n",
        "\n",
        "\n",
        "def calculate_IOU(bbox1: np.array, bbox2: np.array):\n",
        "    x1, y1, w1, h1 = bbox1\n",
        "    x2, y2, w2, h2 = bbox2\n",
        "           \n",
        "    i_x1 = max(x1, x2)\n",
        "    i_y1 = max(y1, y2)\n",
        "    i_x2 = min(x1 + w1, x2 + w2)\n",
        "    i_y2 = min(y1 + h1, y2 + h2)\n",
        "    if i_x1 >= i_x2 or i_y1 >= i_y2:\n",
        "      return 0.0\n",
        "\n",
        "    intersection_area = (i_x2 - i_x1) * (i_y2 - i_y1)\n",
        "    box1_area = w1 * h1\n",
        "    box2_area = w2 * h2\n",
        "    \n",
        "    iou = intersection_area / float(box1_area + box2_area - intersection_area)\n",
        "    return iou\n",
        "\n",
        "\n",
        "def move(image: np.array, bbox: np.array, action: str, \n",
        "         stride_magnitude: int=1) -> np.array:\n",
        "  '''\n",
        "  Returns the new bounding box after taking an action: \n",
        "  {\"left\", \"right\", \"up\", \"down\"}. Use stride to indicate the step size.\n",
        "  '''\n",
        "  if action not in set([\"left\", \"right\", \"up\", \"down\"]):\n",
        "    raise RuntimeError(\"Invalid action taken :(\") \n",
        "  \n",
        "  x, y, w, h = bbox\n",
        "  if action in set([\"left\", \"right\"]):\n",
        "    step = max(1, int(ALPHA * w)) * stride_magnitude * (-1 if action==\"left\" else 1)\n",
        "    x = min(max(0, int(x + step)), int(image.shape[1] - w - 1)) \n",
        "  else:\n",
        "    step = max(1, int(ALPHA * h)) * stride_magnitude * (-1 if action==\"up\" else 1)\n",
        "    y = min(max(0, int(y + step)), int(image.shape[0] - h - 1)) \n",
        "\n",
        "  return np.array([x, y, w, h])\n",
        "\n",
        "\n",
        "def scale(image: np.array, bbox: np.array, scaleUp: bool):\n",
        "  x, y, w, h = bbox\n",
        "  deltaW, deltaH = max(2, ALPHA * w), max(2, ALPHA * h)\n",
        "  if not scaleUp: \n",
        "    deltaW *= -1\n",
        "    deltaH *= -1\n",
        "  w = min(image.shape[1], max(MIN_WINDOW_SIZE, int(w + deltaW))) \n",
        "  h = min(image.shape[0], max(MIN_WINDOW_SIZE, int(h + deltaH)))\n",
        "  x = max(0, min(int(x - deltaW / 2), int(image.shape[1] - w - 1)))\n",
        "  y = max(0, min(int(y - deltaH / 2), int(image.shape[0] - h - 1)))\n",
        "  return np.array([x, y, w, h])\n",
        "\n",
        "\n",
        "def selectAction(img: np.array, bbox: np.array, index: int): \n",
        "  if index == 0 :\n",
        "    bbox = move(img, bbox, \"left\")\n",
        "  elif index == 1 :\n",
        "    bbox = move(img, bbox, \"left\", stride_magnitude=2)\n",
        "  elif index == 2 :\n",
        "    bbox = move(img, bbox, \"right\")\n",
        "  elif index == 3 :\n",
        "    bbox = move(img, bbox, \"right\", stride_magnitude=2)  \n",
        "  elif index == 4 :\n",
        "    bbox = move(img, bbox, \"up\")  \n",
        "  elif index == 5 :\n",
        "    bbox = move(img, bbox, \"up\", stride_magnitude=2)\n",
        "  elif index == 6 :\n",
        "    bbox = move(img, bbox, \"down\")\n",
        "  elif index == 7 :\n",
        "    bbox = move(img, bbox, \"down\", stride_magnitude=2)\n",
        "  elif index == 8:\n",
        "    bbox = bbox\n",
        "  elif index == 9 :\n",
        "    bbox = scale(img, bbox, False)     \n",
        "  elif index == 10 :\n",
        "    bbox = scale(img, bbox, True)      \n",
        "\n",
        "  x, y, w, h = bbox\n",
        "\n",
        "  \"\"\"\n",
        "  assert 0 <= x <= img.shape[1] - w, \"x:{0}, w:{1} is out of bounds: [0, {2})\".format(x, w, img.shape[1] - 1)\n",
        "  assert 0 <= y <= img.shape[0] - h, \"y:{0}, h:{1} is out of bounds: [0, {2})\".format(y, h, img.shape[0] - 1)\n",
        "  assert MIN_WINDOW_SIZE <= w <= img.shape[1], \"w:{0}, is invalid\".format(w)\n",
        "  assert MIN_WINDOW_SIZE <= h <= img.shape[0], \"h:{0} is invalid\".format(h)\n",
        "  \"\"\"\n",
        "  return index, bbox\n",
        "\n",
        "\n",
        "def human_readable_action(index: int) -> str:\n",
        "  '''\n",
        "  Map action numbers to human readable strings\n",
        "  '''\n",
        "  def _get_action(index:int) -> str:\n",
        "    if index == 0:\n",
        "      return \"left\"\n",
        "    elif index == 1:\n",
        "      return \"2x left\"\n",
        "    elif index == 2:\n",
        "      return \"right\"\n",
        "    elif index == 3:\n",
        "      return \"2x right\"\n",
        "    elif index == 4:\n",
        "      return \"up\"\n",
        "    elif index == 5:\n",
        "      return \"2x up\"\n",
        "    elif index == 6:\n",
        "      return \"down\"\n",
        "    elif index == 7:\n",
        "      return \"2x down\"\n",
        "    elif index == 8:\n",
        "      return \"stop\"\n",
        "    elif index == 9:\n",
        "      return \"scale down\"\n",
        "    elif index == 10 :\n",
        "      return \"scale up\"\n",
        "  return _get_action(index).upper()\n",
        "\n",
        "\n",
        "def getAction(img: np.array, bbox: np.array, action_probs: np.array):  \n",
        "  \n",
        "  action_probs = np.array(action_probs) + PROB_OFFSET\n",
        "  action_probs /= action_probs.sum()\n",
        "  \n",
        "  a = np.random.choice(np.arange(len(action_probs)), p=action_probs)\n",
        "  if POLICY_TYPE == \"deterministic\":\n",
        "    a = tf.math.argmax(action_probs)\n",
        "  return selectAction(img, bbox, a)\n",
        "\n",
        "\n",
        "def isStop(action: int):\n",
        "  return action == STOP_ACTION_INDEX\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLxdpmQ5jOjL"
      },
      "source": [
        "# REINFORCE Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CP9qJBgVq5B"
      },
      "source": [
        "### Trajectory Loss Function\n",
        "\n",
        "TODO: investigate adding https://www.analyticsvidhya.com/blog/2020/11/baseline-for-policy-gradients/\n",
        "Or rather https://arxiv.org/pdf/1301.2315.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Id7dQxPDVtJ_"
      },
      "outputs": [],
      "source": [
        "def getNonStopScore(bbox1: np.array, bbox2: np.array, gt: np.array) -> float:\n",
        "  # Issues with this blowing up the gradient in the wrong direction\n",
        "\n",
        "  def _dist(x1, y1, x2, y2):\n",
        "    return math.sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2)\n",
        "  \n",
        "  prevIou = calculate_IOU(bbox1, gt) \n",
        "  nextIou = calculate_IOU(bbox2, gt)\n",
        "  x1, y1 = bbox1[:2]\n",
        "  x2, y2 = bbox2[:2]\n",
        "  xg, yg = gt[:2]\n",
        "\n",
        "  # if prevIou == nextIou: EXPERIMENTED WITH USING EUCLIDEAN DISTANCE\n",
        "  #   return -1 * (_dist(x2, y2, xg, yg) - _dist(x1, y1, xg, yg))\n",
        "  result = nextIou - prevIou \n",
        "  return result \n",
        "\n",
        "def seqLosses(action_probs: List[np.array], actions_taken: List[int], \n",
        "              bboxes: List[np.array], \n",
        "              target_bbox: np.array) -> np.array:\n",
        "\n",
        "    assertMsg = \"Invalid trajectory: actions taken ({0}) + 1 != Bboxes length ({1})\".format(\n",
        "              len(actions_taken), len(bboxes)) \n",
        "    assert len(actions_taken) + 1 == len(bboxes), assertMsg\n",
        "          \n",
        "    src_bbox = np.array(bboxes[0])\n",
        "    end_bbox = np.array(bboxes[-1])\n",
        "    print(\"\\x1b[34m>> Calculating frame loss : {0} -> {1} (Target was {2})\\x1b[0m\".format(\n",
        "            np.array2string(src_bbox, separator=', '),\n",
        "            np.array2string(end_bbox, separator=', '),\n",
        "            np.array2string(target_bbox, separator=', ')))\n",
        "    rewards = np.zeros(len(actions_taken))\n",
        "    discounts = np.zeros(len(actions_taken))\n",
        "    for i, a in enumerate(actions_taken):\n",
        "      prev_bbox = np.array(bboxes[i])\n",
        "      next_bbox = np.array(bboxes[i+1])\n",
        "      ###################### CHANGE REWARD CALCULATION HERE ####################\n",
        "      if REWARD_SCHEME == \"final_bbox\":\n",
        "        rewards[i] = 1 if calculate_IOU(end_bbox, target_bbox) > GOAL_IOU\\\n",
        "                      else -1      \n",
        "      else:\n",
        "        if isStop(a):\n",
        "          rewards[i] = 1 if calculate_IOU(next_bbox, target_bbox) > GOAL_IOU else -1\n",
        "        else:\n",
        "          rewards[i] = getNonStopScore(prev_bbox, next_bbox, target_bbox) \n",
        "      ###################### CHANGE REWARD CALCULATION UP ABOVE ################\n",
        "      prob_a = action_probs[i][a]\n",
        "      discounts[i] = GAMMA ** i\n",
        "      print(\"   |->> t={0} {1}-Reward ({2}) for {3}:bbox transition: {4} -> {5} w/ P(a|s)={6} and iou={7} and reward={8} and discount={9}\"\n",
        "            .format(i+1, \"Stop\" if isStop(a) else \"Diff\", \n",
        "                    np.around(rewards[i], decimals=3), \n",
        "                    human_readable_action(a).upper(),\n",
        "                    np.array2string(prev_bbox, separator=', '),\n",
        "                    np.array2string(next_bbox, separator=', '), prob_a, \n",
        "                    calculate_IOU(next_bbox, target_bbox), \n",
        "                    rewards[i], discounts[i]), \n",
        "            )\n",
        "    \n",
        "    gather_idx = [[i, a] for i, a in enumerate(actions_taken)]\n",
        "    p_a = tf.gather_nd(tf.stack(action_probs), gather_idx)\n",
        "    p_a = tf.clip_by_value(p_a, PROB_OFFSET, 1 - PROB_OFFSET) # done to prevent 0 reward   \n",
        "    \n",
        "    entropy = -1 * tf.math.reduce_sum((tf.math.log(action_probs) * action_probs), \n",
        "                                 axis=1) \n",
        "    \n",
        "    discount = tf.convert_to_tensor(discounts, dtype=tf.float32)\n",
        "    losses = -1 * (discount * rewards * tf.math.log(p_a))\n",
        "    \n",
        "    \n",
        "    print(\"   |->> Assigned losses: {0}\".format(losses))\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMujgGmUVu4k"
      },
      "source": [
        "### Tracking Procedure\n",
        "\n",
        "* This function collects trajectories either via argmax deterministic policy or sampling from a stochastic policy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "EqN0GHI5VlAM"
      },
      "outputs": [],
      "source": [
        "def getPatch(img: np.array, bbox: np.array) -> tf.Tensor:\n",
        "  def _patch(img: np.array, bbox: np.array) -> np.array:\n",
        "    x, y, w, h, = bbox\n",
        "    return img[y : (y + h), x : (x + w)]\n",
        "      \n",
        "  patch = tf.image.resize(_patch(img, bbox), [PATCH_X, PATCH_Y])\n",
        "  return tf.reshape(patch, (1, PATCH_X, PATCH_Y, N_CHANNELS))\n",
        "\n",
        "\n",
        "def tracking(model: ADNET, img: np.array, bbox: np.array,\n",
        "             t: int, target_bbox: np.array, \n",
        "             tracking_length: int= MAX_TRAJECTORY_LENGTH):\n",
        "    \"\"\" \n",
        "    Runs tracking until # actions > MAX_ACTIONS_SEQ_LIMIT, STOP is taken, or\n",
        "    oscillation occurs.\n",
        "    \"\"\"\n",
        "    print(\"|->> Beginning tracking for bbox:{0}\".format(bbox)) \n",
        "\n",
        "    patch = getPatch(img, bbox)\n",
        "    actions_taken = []\n",
        "    action_probs = []\n",
        "    bboxes = [tuple(bbox)]\n",
        "    prev_score = None\n",
        "    while len(actions_taken) < tracking_length:\n",
        "      prev_bbox = bbox.copy()\n",
        "      \n",
        "      probs, conf_score = model(patch)\n",
        "      probs = tf.reshape(probs, (model.ACTION_DIM)) \n",
        "      \n",
        "      a, bbox = getAction(np.array(img), bbox, probs)\n",
        "      prev_iou = calculate_IOU(prev_bbox, target_bbox)      \n",
        "      iou = calculate_IOU(bbox, target_bbox)   \n",
        "\n",
        "      if tuple(bbox) in bboxes:\n",
        "        print(\"|->> Revisiting bbox: {0}. Breaking action sequence\"\n",
        "                  .format(bbox))\n",
        "        print(\"   |->> Trajectory ending is FORCED\".format(iou))\n",
        "        a, bbox = 8, prev_bbox\n",
        "        if len(actions_taken) > 0:\n",
        "          # We observed too many trajectory STOPS were leading to gradient updates\n",
        "          # that reduce P(STOP|s) to near 0, which is undesirable. In this case, \n",
        "          # we allow STOPs if selected naturally by the policy or it's the only \n",
        "          # action on a trajectory (a trajectory MUST \n",
        "          # have at least one action). All other STOPs we just forego\n",
        "          # to prevent these harmful gradient updates\n",
        "          break\n",
        "      elif PREMATURE_BREAK and iou < GOAL_IOU  and prev_iou > GOAL_IOU:\n",
        "        # TRAJECTORY IS WORSENING\n",
        "        print(\"             |->> IOU declining: {0}:{1} -> {2}:{3}.\"\n",
        "                  .format(prev_bbox, prev_iou, bbox, iou))\n",
        "        print(\"             |->> Overriding with STOP\"\n",
        "                .format(iou))\n",
        "        a, bbox = 8, prev_bbox\n",
        "      \n",
        "      a_prob = probs[a] \n",
        "      print(\"   \\x1b[33m|->> #{0}/t={1}-th Action selection: {2}/{3} (P(a|s) = {4})\\x1b[0m\"\n",
        "                .format(len(actions_taken), t, a, human_readable_action(a).upper(), \n",
        "                        np.around(a_prob, decimals=3)))\n",
        "      print(\"      |->> Bounding box moves to: {0}\"\n",
        "                .format(bbox))\n",
        "      print(\"         |->> Action Probabilities (Rounded): {0}, argmax={1}\"\n",
        "              .format(np.around(probs.numpy(), decimals=4), np.argmax(probs)))\n",
        "      print(\"         |->> Action Probabilities (RAW): {0}, argmax={1}\"\n",
        "              .format(probs.numpy(), np.argmax(probs)))\n",
        "\n",
        "      if VERBOSE:\n",
        "        print(\"         |->> Overwriting action in buffer {0}\"\n",
        "            .format(model.getPrettyActionHistory() if VERBOSE else \"\"))\n",
        "        \n",
        "      action_probs.append(probs)\n",
        "      actions_taken.append(a)\n",
        "      model.updateActionHistory(a)\n",
        "      bboxes.append(tuple(bbox))  \n",
        "      patch = getPatch(img, bbox)      \n",
        "\n",
        "      # Stopping condition\n",
        "      if isStop(a):\n",
        "        print(\"         |->> Hit a STOP on the {0}-th action!\".format(t))\n",
        "        break  \n",
        "      \n",
        "      t += 1\n",
        "\n",
        "    print(\"    \\x1b[31m|->> Completed tracking\\x1b[0m\")\n",
        "    \n",
        "    return action_probs, actions_taken, bboxes, t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akOkB6DOxC_v"
      },
      "source": [
        "### Single Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "4w8_6oDV7900"
      },
      "outputs": [],
      "source": [
        "VERBOSE = False\n",
        "\n",
        "def getFrame(dataset: str, frame: int) -> np.array:\n",
        "  f_path = \"{0}/img/{1}.jpg\".format(dataset, str(frame).zfill(4))\n",
        "  print(\"Frame path: {0}\".format(f_path))\n",
        "  img = cv2.imread(f_path)\n",
        "  return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\n",
        "def train(model: ADNET, opt: tf.keras.optimizers.Optimizer, \n",
        "          dataset: str, start_frame: int, end_frame: int, \n",
        "          retry_count: int=N_RETRIES) -> float:\n",
        "  '''\n",
        "  Run training for a model on a frame sequence {start_frame, end_frame} \n",
        "  n_retries times.\n",
        "  :param: dataset: is the dataset path to train from\n",
        "  :param: retry_count: number of times to train on the frame sequence. \n",
        "  :return: returns the model and average loss\n",
        "  '''\n",
        "\n",
        "  gt = get_ground_truths(\"%s/groundtruth_rect.txt\" % dataset)\n",
        "  frames = sorted(glob.glob(os.path.join('%s/img' % dataset, '*.jpg'))) \n",
        "  loss = 0.0\n",
        "\n",
        "  train_vars = model.trainable_variables\n",
        "  accum_gradient = [tf.zeros_like(this_var) for this_var in train_vars]\n",
        "  for i in range(retry_count):\n",
        "    print(\"\\n\\x1b[36m####################### EPISODE # {0} ############################\\x1b[0m\".format(i+1))\n",
        "    bbox = gt[start_frame]\n",
        "    print(\"Starting bounding box for {0}: frames {1}:{2} is {3}.\".format(dataset, start_frame, end_frame, bbox))\n",
        "    \n",
        "    t = 1    \n",
        "    model.clearActionHistory()\n",
        "    for i in range(start_frame+1, end_frame+1):\n",
        "      with tf.GradientTape() as tape:\n",
        "        target_bbox = gt[i]\n",
        "        prev_bbox = np.array(bbox, copy=True)\n",
        "\n",
        "        print(\"\\x1b[34m>> Attempting to reach frame {0} with src: {1} and target: {2}\\x1b[0m\"\n",
        "            .format(i, np.array2string(bbox, separator=', '), \n",
        "                    np.array2string(target_bbox, separator=', ')))\n",
        "        img = getFrame(dataset, i) \n",
        "        action_probs, taken_actions, bboxes, t = tracking(model, img, \n",
        "                                                          bbox, t, target_bbox)\n",
        "        bbox = np.array(bboxes[-1])\n",
        "\n",
        "\n",
        "        frame_losses = seqLosses(action_probs, taken_actions, bboxes, target_bbox)\n",
        "        total_frame_loss = tf.reduce_sum(frame_losses)\n",
        "        \n",
        "        loss += np.sum(total_frame_loss.numpy())\n",
        "        print(\"{0}>> Total frame loss: {1}\\x1b[0m\".format(\n",
        "              \"\\x1b[92m\" if total_frame_loss > 0 else \"\\x1b[31m\", \n",
        "              total_frame_loss))\n",
        "\n",
        "      gradients = tape.gradient(total_frame_loss, train_vars)\n",
        "      accum_gradient = [(acum_grad + grad) \n",
        "                        for acum_grad, grad in zip(accum_gradient, gradients)]\n",
        "\n",
        "    print(\"Final bounding box: {0} reached in {1} timesteps (originating from {2}). Target was {3}\"\n",
        "          .format(bbox, t, np.array(gt[start_frame]), np.array(gt[end_frame])))\n",
        "    print(\"\\n\\x1b[36m############# END EPISODE # {0} in t={1} timesteps ################\\x1b[0m\"\n",
        "          .format(i+1, t))\n",
        "    \n",
        "\n",
        "  print(\"Avg Loss Across Trajectories: {0}\\x1b[0m\".format(\n",
        "      \"\\x1b[92m\" if loss > 0 else \"\\x1b[31m\"))  \n",
        "  \n",
        "  \n",
        "  \n",
        "  accum_gradient = [g / retry_count if GRAD_ACCUM_SCHEME == \"avg\" else g \n",
        "                    for g in accum_gradient]\n",
        "  for i in range(len(accum_gradient)):\n",
        "      print(\"Layer Name: {}, GRAD NORM = {}\".format(\n",
        "      adnet_model.trainable_variables[i].name, tf.norm(accum_gradient[i])))\n",
        "  opt.apply_gradients(zip(accum_gradient, model.trainable_variables))\n",
        "  return model, loss / retry_count\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Epoch Training Loops"
      ],
      "metadata": {
        "id": "oFKnC5VrgVhn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "otMLmAPjVSiS"
      },
      "outputs": [],
      "source": [
        "def epochs_train(model: ADNET, opt: tf.keras.optimizers.Optimizer, \n",
        "                 datasets: List[str], \n",
        "                 epochs: int=1, retry_count: int=1, action_strategy: str=\"max\",\n",
        "                 seq_length: int=10, randomize: bool=RANDOMIZE_TRAINING):\n",
        "\n",
        "  print(\"TRAINING ON: {0}\".format(datasets))\n",
        "  # Collect list of datasets & trainable frames\n",
        "  dataset_frames = []\n",
        "  for d in datasets:\n",
        "    frames = sorted(glob.glob(os.path.join('%s/img' % d, '*.jpg')))\n",
        "    frames = list(range(len(frames) - L))\n",
        "    for f in frames:\n",
        "      dataset_frames.append((d, f))\n",
        "  if randomize: random.shuffle(dataset_frames)\n",
        "\n",
        "  # Train for n epochs\n",
        "  losses = {}\n",
        "  bad_data_log = []\n",
        "  for e in range(epochs):\n",
        "    epoch_loss = []\n",
        "    \n",
        "    for i, d_frame in enumerate(dataset_frames):\n",
        "      d, start_frame = d_frame\n",
        "      end_frame = start_frame + seq_length\n",
        "\n",
        "      print(\"\\n\\n#############################################\")\n",
        "      print(\"Dataset={0}\".format(d))\n",
        "      print(\"#################################################\")\n",
        "      adnet_model, l = train(model, opt, d, start_frame, end_frame, \n",
        "                             retry_count=retry_count)\n",
        "      epoch_loss.append(l)\n",
        "      print(\"#################################################\")\n",
        "      print(\"#################################################\")\n",
        "      \n",
        "    losses[e] = epoch_loss\n",
        "\n",
        "  print(\"Finished Training On: {0}\".format(datasets))\n",
        "  return model, losses"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Procedure"
      ],
      "metadata": {
        "id": "k5g5kT2HgaoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adnet_model = ADNET()\n",
        "adnet_model.build()\n",
        "#YIFAN_WEIGHTS_PATH = \"yifanweights.mat\"\n",
        "#weights = hdf5storage.loadmat(YIFAN_WEIGHTS_PATH)\n",
        "#adnet_model = setWeights(adnet_model,weights,weights)\n",
        "adnet_model.load_weights(\"/content/gdrive/My Drive/EE6885/kaan-weights\")\n",
        "adnet_model.layers[-3].trainable=False\n",
        "# adnet_model.layers[0].trainable=False\n",
        "# adnet_model.layers[1].trainable=False\n",
        "# adnet_model.layers[2].trainable=False\n",
        "# adnet_model.layers[3].trainable=False\n",
        "# adnet_model.layers[4].trainable=False\n",
        "# adnet_model.layers[5].trainable=False"
      ],
      "metadata": {
        "id": "5IC_1hgaVcw7"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rand_idx = 37\n",
        "#N_VIDEOS = 3\n",
        "#datasets = np.random.choice(len(ALL_DATASETS_LIST), size=N_VIDEOS, replace=False)\n",
        "#datasets = list(map(lambda rand_idx: ALL_DATASETS_LIST[rand_idx], datasets))\n",
        "ALL_DATASETS_LIST = glob.glob(\"adnet_datasets/OTB/*\")\n",
        "N_VIDEOS = 1\n",
        "datasets = [ALL_DATASETS_LIST[26]]\n",
        "\n",
        "model, losses = epochs_train(adnet_model, Adam(learning_rate=LEARNING_RATE), \n",
        "                             datasets, epochs=N_EPOCHS, retry_count=N_RETRIES, \n",
        "                             randomize=RANDOMIZE_TRAINING)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41yhNXMygPIy",
        "outputId": "0fe9206e-a539-497f-f0ba-f97485512959"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "      |->> Bounding box moves to: [309   0  64  58]\n",
            "         |->> Action Probabilities (Rounded): [1.16e-02 8.95e-01 0.00e+00 0.00e+00 1.90e-03 9.11e-02 0.00e+00 0.00e+00\n",
            " 0.00e+00 1.00e-04 3.00e-04], argmax=1\n",
            "         |->> Action Probabilities (RAW): [1.1630615e-02 8.9500403e-01 1.8933143e-08 7.9496083e-11 1.9166162e-03\n",
            " 9.1100372e-02 1.2396431e-07 2.3598320e-06 8.0605983e-10 6.7632900e-05\n",
            " 2.7828672e-04], argmax=1\n",
            "|->> Revisiting bbox: [309   0  64  58]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [313,   0,  64,  58] -> [309,   0,  64,  58] (Target was [288,   6,  64,  72])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.022) for 2X LEFT:bbox transition: [313,   0,  64,  58] -> [311,   0,  64,  58] w/ P(a|s)=0.981427788734436 and iou=0.3445378151260504 and reward=0.022223765539273577 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.023) for 2X LEFT:bbox transition: [311,   0,  64,  58] -> [309,   0,  64,  58] w/ P(a|s)=0.8950040340423584 and iou=0.36752136752136755 and reward=0.02298355239531713 and discount=0.99\n",
            "   |->> Assigned losses: [0.00041663 0.002524  ]\n",
            "\u001b[92m>> Total frame loss: 0.0029406282119452953\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 75 with src: [309,   0,  64,  58] and target: [276,  22,  70,  88]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0075.jpg\n",
            "|->> Beginning tracking for bbox:[309   0  64  58]\n",
            "|->> Revisiting bbox: [309   0  64  58]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=7-th Action selection: 8/STOP (P(a|s) = 0.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [309   0  64  58]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.     0.9999 0.     0.     0.     0.\n",
            " 0.    ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [5.3237540e-07 3.6254112e-06 3.6822343e-07 1.2575071e-05 9.7454849e-06\n",
            " 9.9994969e-01 1.5148617e-08 3.3583877e-08 1.5320426e-09 3.5716727e-08\n",
            " 2.3389797e-05], argmax=5\n",
            "         |->> Hit a STOP on the 7-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [309,   0,  64,  58] -> [309,   0,  64,  58] (Target was [276,  22,  70,  88])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [309,   0,  64,  58] -> [309,   0,  64,  58] w/ P(a|s)=1.5320426038911705e-09 and iou=0.1559718969555035 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-11.512925]\n",
            "\u001b[31m>> Total frame loss: -11.512925148010254\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 76 with src: [309,   0,  64,  58] and target: [288,  59,  67,  92]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0076.jpg\n",
            "|->> Beginning tracking for bbox:[309   0  64  58]\n",
            "|->> Revisiting bbox: [309   0  64  58]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=7-th Action selection: 8/STOP (P(a|s) = 0.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [309   0  64  58]\n",
            "         |->> Action Probabilities (Rounded): [5.000e-04 6.660e-02 8.300e-03 2.000e-03 5.000e-04 9.169e-01 0.000e+00\n",
            " 2.300e-03 0.000e+00 4.000e-04 2.400e-03], argmax=5\n",
            "         |->> Action Probabilities (RAW): [5.4185191e-04 6.6629700e-02 8.2843276e-03 2.0495991e-03 4.8018788e-04\n",
            " 9.1689891e-01 4.3877761e-05 2.2572665e-03 7.4458330e-06 3.5836984e-04\n",
            " 2.4484820e-03], argmax=5\n",
            "         |->> Hit a STOP on the 7-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [309,   0,  64,  58] -> [309,   0,  64,  58] (Target was [288,  59,  67,  92])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [309,   0,  64,  58] -> [309,   0,  64,  58] w/ P(a|s)=7.4458330345805734e-06 and iou=0.0 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-11.512925]\n",
            "\u001b[31m>> Total frame loss: -11.512925148010254\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 77 with src: [309,   0,  64,  58] and target: [310, 103,  65,  90]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0077.jpg\n",
            "|->> Beginning tracking for bbox:[309   0  64  58]\n",
            "   \u001b[33m|->> #0/t=7-th Action selection: 10/SCALE UP (P(a|s) = 0.9909999966621399)\u001b[0m\n",
            "      |->> Bounding box moves to: [308   0  66  60]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 8.000e-04 0.000e+00 0.000e+00 4.000e-04 8.100e-03 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 9.907e-01], argmax=10\n",
            "         |->> Action Probabilities (RAW): [5.6455059e-07 7.9647399e-04 2.4860656e-06 1.3562718e-06 3.6745961e-04\n",
            " 8.0913352e-03 1.5796228e-12 8.1100488e-08 8.2438700e-10 2.2087941e-06\n",
            " 9.9073797e-01], argmax=10\n",
            "|->> Revisiting bbox: [308   0  66  60]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [309,   0,  64,  58] -> [308,   0,  66,  60] (Target was [310, 103,  65,  90])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for SCALE UP:bbox transition: [309,   0,  64,  58] -> [308,   0,  66,  60] w/ P(a|s)=0.9907379746437073 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 78 with src: [308,   0,  66,  60] and target: [324, 138,  70,  94]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0078.jpg\n",
            "|->> Beginning tracking for bbox:[308   0  66  60]\n",
            "   \u001b[33m|->> #0/t=8-th Action selection: 10/SCALE UP (P(a|s) = 0.5370000004768372)\u001b[0m\n",
            "      |->> Bounding box moves to: [307   0  68  62]\n",
            "         |->> Action Probabilities (Rounded): [8.270e-02 1.140e-02 6.010e-02 3.900e-02 8.000e-04 1.500e-03 2.104e-01\n",
            " 9.000e-03 4.790e-02 2.000e-04 5.368e-01], argmax=10\n",
            "         |->> Action Probabilities (RAW): [8.2671091e-02 1.1436833e-02 6.0149219e-02 3.9028291e-02 8.3880423e-04\n",
            " 1.4809164e-03 2.1044272e-01 9.0232259e-03 4.7930595e-02 1.8063963e-04\n",
            " 5.3681761e-01], argmax=10\n",
            "   \u001b[33m|->> #1/t=9-th Action selection: 6/DOWN (P(a|s) = 0.10599999874830246)\u001b[0m\n",
            "      |->> Bounding box moves to: [307   1  68  62]\n",
            "         |->> Action Probabilities (Rounded): [0.1912 0.0808 0.0291 0.0036 0.0628 0.1797 0.1061 0.0461 0.1012 0.0387\n",
            " 0.1608], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.19120388 0.08076147 0.02907034 0.0035968  0.06277094 0.17969644\n",
            " 0.10609949 0.04607889 0.1012395  0.03866844 0.16081382], argmax=0\n",
            "|->> Revisiting bbox: [307   0  68  62]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [308,   0,  66,  60] -> [307,   1,  68,  62] (Target was [324, 138,  70,  94])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for SCALE UP:bbox transition: [308,   0,  66,  60] -> [307,   0,  68,  62] w/ P(a|s)=0.5368176102638245 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for DOWN:bbox transition: [307,   0,  68,  62] -> [307,   1,  68,  62] w/ P(a|s)=0.10609948635101318 and iou=0.0 and reward=0.0 and discount=0.99\n",
            "   |->> Assigned losses: [0. 0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 79 with src: [307,   1,  68,  62] and target: [337, 158,  68,  90]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0079.jpg\n",
            "|->> Beginning tracking for bbox:[307   1  68  62]\n",
            "   \u001b[33m|->> #0/t=10-th Action selection: 5/2X UP (P(a|s) = 0.6629999876022339)\u001b[0m\n",
            "      |->> Bounding box moves to: [307   0  68  62]\n",
            "         |->> Action Probabilities (Rounded): [6.500e-03 2.600e-03 2.720e-02 1.700e-03 1.392e-01 6.630e-01 2.000e-04\n",
            " 1.000e-04 4.700e-03 2.240e-02 1.324e-01], argmax=5\n",
            "         |->> Action Probabilities (RAW): [6.5298118e-03 2.5734790e-03 2.7217556e-02 1.6592487e-03 1.3917485e-01\n",
            " 6.6299480e-01 1.5624607e-04 1.3222471e-04 4.7267010e-03 2.2432366e-02\n",
            " 1.3240272e-01], argmax=5\n",
            "|->> Revisiting bbox: [307   0  68  62]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [307,   1,  68,  62] -> [307,   0,  68,  62] (Target was [337, 158,  68,  90])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X UP:bbox transition: [307,   1,  68,  62] -> [307,   0,  68,  62] w/ P(a|s)=0.6629948019981384 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 80 with src: [307,   0,  68,  62] and target: [344, 162,  61,  90]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0080.jpg\n",
            "|->> Beginning tracking for bbox:[307   0  68  62]\n",
            "   \u001b[33m|->> #0/t=11-th Action selection: 7/2X DOWN (P(a|s) = 0.9300000071525574)\u001b[0m\n",
            "      |->> Bounding box moves to: [307   2  68  62]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.0022 0.0654 0.     0.     0.     0.9303 0.     0.\n",
            " 0.0021], argmax=7\n",
            "         |->> Action Probabilities (RAW): [9.4034524e-13 1.7755440e-07 2.1978470e-03 6.5366045e-02 9.1558857e-13\n",
            " 1.2136979e-09 6.5376575e-08 9.3031782e-01 3.3926995e-13 2.0408531e-11\n",
            " 2.1180639e-03], argmax=7\n",
            "   \u001b[33m|->> #1/t=12-th Action selection: 7/2X DOWN (P(a|s) = 0.996999979019165)\u001b[0m\n",
            "      |->> Bounding box moves to: [307   4  68  62]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 1.200e-03 0.000e+00 2.000e-04 0.000e+00\n",
            " 9.971e-01 0.000e+00 0.000e+00 1.500e-03], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.80572979e-09 1.43958205e-05 1.07320429e-05 1.15066220e-03\n",
            " 6.31286065e-11 1.50117819e-04 1.44726030e-07 9.97135758e-01\n",
            " 1.72657080e-11 2.41661492e-05 1.51394145e-03], argmax=7\n",
            "   \u001b[33m|->> #2/t=13-th Action selection: 1/2X LEFT (P(a|s) = 0.6119999885559082)\u001b[0m\n",
            "      |->> Bounding box moves to: [303   4  68  62]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.6122 0.     0.     0.     0.0983 0.     0.2894 0.     0.\n",
            " 0.    ], argmax=1\n",
            "         |->> Action Probabilities (RAW): [1.9745443e-11 6.1219525e-01 1.8435530e-06 3.8162690e-07 2.7161044e-11\n",
            " 9.8322794e-02 1.0693118e-13 2.8943440e-01 1.9922143e-15 3.0166079e-06\n",
            " 4.2281143e-05], argmax=1\n",
            "|->> Revisiting bbox: [307   4  68  62]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [307,   0,  68,  62] -> [303,   4,  68,  62] (Target was [344, 162,  61,  90])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X DOWN:bbox transition: [307,   0,  68,  62] -> [307,   2,  68,  62] w/ P(a|s)=0.9303178191184998 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for 2X DOWN:bbox transition: [307,   2,  68,  62] -> [307,   4,  68,  62] w/ P(a|s)=0.9971357583999634 and iou=0.0 and reward=0.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X LEFT:bbox transition: [307,   4,  68,  62] -> [303,   4,  68,  62] w/ P(a|s)=0.6121952533721924 and iou=0.0 and reward=0.0 and discount=0.9801\n",
            "   |->> Assigned losses: [0. 0. 0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "Final bounding box: [303   4  68  62] reached in 14 timesteps (originating from [313   3  64  58]). Target was [344 162  61  90]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 81 in t=14 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[31m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 4.954107761383057\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.004224518779665232\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 4.711672782897949\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.011343197897076607\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 5.208888530731201\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.02297443337738514\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 3.230039358139038\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.009542926214635372\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 1.7113819122314453\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.007009006105363369\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 2.748645067214966\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 0.02565438486635685\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/Matrix\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Starting bounding box for adnet_datasets/OTB/Matrix: frames 75:85 is [276  22  70  88].\n",
            "\u001b[34m>> Attempting to reach frame 76 with src: [276,  22,  70,  88] and target: [288,  59,  67,  92]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0076.jpg\n",
            "|->> Beginning tracking for bbox:[276  22  70  88]\n",
            "|->> Revisiting bbox: [276  22  70  88]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 8/STOP (P(a|s) = 0.03200000151991844)\u001b[0m\n",
            "      |->> Bounding box moves to: [276  22  70  88]\n",
            "         |->> Action Probabilities (Rounded): [0.1904 0.0924 0.0061 0.     0.0407 0.015  0.5462 0.0384 0.0322 0.0368\n",
            " 0.0019], argmax=6\n",
            "         |->> Action Probabilities (RAW): [1.9035082e-01 9.2389010e-02 6.0710851e-03 5.0662373e-07 4.0704694e-02\n",
            " 1.5024197e-02 5.4623324e-01 3.8396250e-02 3.2166343e-02 3.6775071e-02\n",
            " 1.8888263e-03], argmax=6\n",
            "         |->> Hit a STOP on the 1-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [276,  22,  70,  88] -> [276,  22,  70,  88] (Target was [288,  59,  67,  92])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [276,  22,  70,  88] -> [276,  22,  70,  88] w/ P(a|s)=0.03216634318232536 and iou=0.31582319026265215 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-3.4368346]\n",
            "\u001b[31m>> Total frame loss: -3.4368345737457275\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 77 with src: [276,  22,  70,  88] and target: [310, 103,  65,  90]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0077.jpg\n",
            "|->> Beginning tracking for bbox:[276  22  70  88]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 5/2X UP (P(a|s) = 0.9559999704360962)\u001b[0m\n",
            "      |->> Bounding box moves to: [276  18  70  88]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 1.000e-04 1.000e-04 4.300e-02 9.563e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 5.000e-04 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [8.6438213e-06 1.3645302e-05 1.1254123e-04 1.0956569e-04 4.2990819e-02\n",
            " 9.5630270e-01 2.7239907e-13 2.2825006e-09 1.3628536e-11 4.6097039e-04\n",
            " 1.0542850e-06], argmax=5\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 5/2X UP (P(a|s) = 0.718999981880188)\u001b[0m\n",
            "      |->> Bounding box moves to: [276  14  70  88]\n",
            "         |->> Action Probabilities (Rounded): [4.000e-04 0.000e+00 7.800e-03 2.213e-01 1.650e-02 7.186e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 3.540e-02], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.7987161e-04 3.7910451e-07 7.7856816e-03 2.2131687e-01 1.6531246e-02\n",
            " 7.1860427e-01 2.0756279e-09 2.0505075e-05 2.6998233e-16 1.1477336e-10\n",
            " 3.5361160e-02], argmax=5\n",
            "   \u001b[33m|->> #2/t=3-th Action selection: 10/SCALE UP (P(a|s) = 0.25999999046325684)\u001b[0m\n",
            "      |->> Bounding box moves to: [274  12  72  90]\n",
            "         |->> Action Probabilities (Rounded): [0.1532 0.0924 0.102  0.0207 0.0548 0.0657 0.0742 0.0905 0.0485 0.0378\n",
            " 0.2602], argmax=10\n",
            "         |->> Action Probabilities (RAW): [0.15319388 0.09241559 0.10202286 0.020664   0.05481492 0.0656892\n",
            " 0.07423663 0.09052052 0.04852574 0.03775093 0.26016566], argmax=10\n",
            "   \u001b[33m|->> #3/t=4-th Action selection: 1/2X LEFT (P(a|s) = 0.1080000028014183)\u001b[0m\n",
            "      |->> Bounding box moves to: [270  12  72  90]\n",
            "         |->> Action Probabilities (Rounded): [0.2212 0.1078 0.0755 0.0014 0.0499 0.0893 0.0659 0.0037 0.0826 0.0143\n",
            " 0.2885], argmax=10\n",
            "         |->> Action Probabilities (RAW): [0.22118363 0.10779586 0.07552632 0.00137739 0.04990127 0.0892814\n",
            " 0.06594961 0.00368907 0.08257461 0.01425184 0.288469  ], argmax=10\n",
            "   \u001b[33m|->> #4/t=5-th Action selection: 7/2X DOWN (P(a|s) = 0.9049999713897705)\u001b[0m\n",
            "      |->> Bounding box moves to: [270  16  72  90]\n",
            "         |->> Action Probabilities (Rounded): [1.660e-02 1.150e-02 5.000e-04 1.000e-04 0.000e+00 2.000e-04 3.990e-02\n",
            " 9.049e-01 0.000e+00 0.000e+00 2.630e-02], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.66272353e-02 1.15424255e-02 4.74136526e-04 5.98882507e-05\n",
            " 1.03823531e-07 2.00598326e-04 3.99444513e-02 9.04882669e-01\n",
            " 3.71935784e-07 2.15550290e-06 2.62660179e-02], argmax=7\n",
            "   \u001b[33m|->> #5/t=6-th Action selection: 3/2X RIGHT (P(a|s) = 0.859000027179718)\u001b[0m\n",
            "      |->> Bounding box moves to: [274  16  72  90]\n",
            "         |->> Action Probabilities (Rounded): [3.000e-04 0.000e+00 0.000e+00 8.586e-01 0.000e+00 1.406e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 5.000e-04], argmax=3\n",
            "         |->> Action Probabilities (RAW): [2.8040222e-04 1.6985742e-06 1.4890372e-06 8.5861981e-01 1.0162819e-06\n",
            " 1.4058700e-01 1.2725559e-09 2.6437205e-12 3.3136115e-15 1.1886655e-07\n",
            " 5.0847593e-04], argmax=3\n",
            "   \u001b[33m|->> #6/t=7-th Action selection: 3/2X RIGHT (P(a|s) = 0.531000018119812)\u001b[0m\n",
            "      |->> Bounding box moves to: [278  16  72  90]\n",
            "         |->> Action Probabilities (Rounded): [3.500e-03 0.000e+00 6.000e-04 5.313e-01 1.000e-04 4.519e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 1.260e-02], argmax=3\n",
            "         |->> Action Probabilities (RAW): [3.5098202e-03 3.8933057e-09 6.1305269e-04 5.3127778e-01 5.0050192e-05\n",
            " 4.5190552e-01 1.1377317e-06 8.6413439e-07 1.2808930e-15 6.0799266e-13\n",
            " 1.2641797e-02], argmax=3\n",
            "   \u001b[33m|->> #7/t=8-th Action selection: 5/2X UP (P(a|s) = 0.843999981880188)\u001b[0m\n",
            "      |->> Bounding box moves to: [278  12  72  90]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 3.000e-04 0.000e+00 0.000e+00 1.552e-01 8.440e-01 0.000e+00\n",
            " 1.000e-04 0.000e+00 0.000e+00 4.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.5645679e-05 2.6750905e-04 3.7562681e-05 2.1062796e-07 1.5520342e-01\n",
            " 8.4403598e-01 7.3478388e-09 5.5495730e-05 2.4081572e-11 1.1107791e-06\n",
            " 3.8291831e-04], argmax=5\n",
            "   \u001b[33m|->> #8/t=9-th Action selection: 2/RIGHT (P(a|s) = 0.6959999799728394)\u001b[0m\n",
            "      |->> Bounding box moves to: [280  12  72  90]\n",
            "         |->> Action Probabilities (Rounded): [0.0053 0.0032 0.6963 0.0061 0.0025 0.0117 0.0416 0.     0.0059 0.0051\n",
            " 0.2224], argmax=2\n",
            "         |->> Action Probabilities (RAW): [5.2936231e-03 3.1672330e-03 6.9627249e-01 6.0774251e-03 2.4665832e-03\n",
            " 1.1668847e-02 4.1592214e-02 4.8858339e-05 5.8590625e-03 5.1278966e-03\n",
            " 2.2242577e-01], argmax=2\n",
            "|->> Revisiting bbox: [278  12  72  90]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [276,  22,  70,  88] -> [280,  12,  72,  90] (Target was [310, 103,  65,  90])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.012) for 2X UP:bbox transition: [276,  22,  70,  88] -> [276,  18,  70,  88] w/ P(a|s)=0.9563027024269104 and iou=0.009074105192404638 and reward=-0.01235811117092246 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.009) for 2X UP:bbox transition: [276,  18,  70,  88] -> [276,  14,  70,  88] w/ P(a|s)=0.7186042666435242 and iou=0.0 and reward=-0.009074105192404638 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.0) for SCALE UP:bbox transition: [276,  14,  70,  88] -> [274,  12,  72,  90] w/ P(a|s)=0.26016566157341003 and iou=0.0 and reward=0.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.0) for 2X LEFT:bbox transition: [274,  12,  72,  90] -> [270,  12,  72,  90] w/ P(a|s)=0.10779585689306259 and iou=0.0 and reward=0.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.008) for 2X DOWN:bbox transition: [270,  12,  72,  90] -> [270,  16,  72,  90] w/ P(a|s)=0.9048826694488525 and iou=0.00784698381559588 and reward=0.00784698381559588 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.001) for 2X RIGHT:bbox transition: [270,  16,  72,  90] -> [274,  16,  72,  90] w/ P(a|s)=0.8586198091506958 and iou=0.008836524300441826 and reward=0.0009895404848459452 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.001) for 2X RIGHT:bbox transition: [274,  16,  72,  90] -> [278,  16,  72,  90] w/ P(a|s)=0.5312777757644653 and iou=0.009828009828009828 and reward=0.0009914855275680017 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (-0.01) for 2X UP:bbox transition: [278,  16,  72,  90] -> [278,  12,  72,  90] w/ P(a|s)=0.8440359830856323 and iou=0.0 and reward=-0.009828009828009828 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (0.0) for RIGHT:bbox transition: [278,  12,  72,  90] -> [280,  12,  72,  90] w/ P(a|s)=0.6962724924087524 and iou=0.0 and reward=0.0 and discount=0.9227446944279201\n",
            "   |->> Assigned losses: [-0.00055217 -0.0029685   0.          0.          0.0007534   0.00014344\n",
            "  0.00059039 -0.00155323  0.        ]\n",
            "\u001b[31m>> Total frame loss: -0.0035866713151335716\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 78 with src: [280,  12,  72,  90] and target: [324, 138,  70,  94]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0078.jpg\n",
            "|->> Beginning tracking for bbox:[280  12  72  90]\n",
            "   \u001b[33m|->> #0/t=10-th Action selection: 5/2X UP (P(a|s) = 0.6499999761581421)\u001b[0m\n",
            "      |->> Bounding box moves to: [280   8  72  90]\n",
            "         |->> Action Probabilities (Rounded): [1.040e-02 4.000e-04 2.726e-01 2.500e-03 2.780e-02 6.496e-01 3.000e-04\n",
            " 1.000e-04 1.000e-04 1.000e-04 3.610e-02], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.0431348e-02 4.3211464e-04 2.7263790e-01 2.4518182e-03 2.7805602e-02\n",
            " 6.4960372e-01 3.2333456e-04 5.7825946e-05 8.3927167e-05 5.7289715e-05\n",
            " 3.6115140e-02], argmax=5\n",
            "   \u001b[33m|->> #1/t=11-th Action selection: 5/2X UP (P(a|s) = 0.9430000185966492)\u001b[0m\n",
            "      |->> Bounding box moves to: [280   4  72  90]\n",
            "         |->> Action Probabilities (Rounded): [4.870e-02 3.200e-03 0.000e+00 0.000e+00 5.200e-03 9.426e-01 2.000e-04\n",
            " 0.000e+00 0.000e+00 0.000e+00 1.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [4.8689403e-02 3.2173230e-03 1.0191239e-05 7.6074098e-09 5.1985779e-03\n",
            " 9.4256133e-01 1.7230189e-04 1.4346226e-06 1.2245784e-08 1.8535621e-08\n",
            " 1.4948449e-04], argmax=5\n",
            "   \u001b[33m|->> #2/t=12-th Action selection: 5/2X UP (P(a|s) = 0.800000011920929)\u001b[0m\n",
            "      |->> Bounding box moves to: [280   0  72  90]\n",
            "         |->> Action Probabilities (Rounded): [1.612e-01 3.020e-02 3.000e-04 0.000e+00 3.900e-03 8.005e-01 4.000e-04\n",
            " 3.000e-04 0.000e+00 1.000e-04 3.100e-03], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.6122991e-01 3.0219812e-02 2.9268389e-04 3.1271491e-06 3.9183553e-03\n",
            " 8.0048114e-01 3.5268965e-04 2.7299239e-04 4.1494700e-06 8.8496068e-05\n",
            " 3.1366521e-03], argmax=5\n",
            "   \u001b[33m|->> #3/t=13-th Action selection: 1/2X LEFT (P(a|s) = 0.6589999794960022)\u001b[0m\n",
            "      |->> Bounding box moves to: [276   0  72  90]\n",
            "         |->> Action Probabilities (Rounded): [0.2961 0.659  0.     0.     0.     0.0079 0.0093 0.0058 0.     0.\n",
            " 0.0219], argmax=1\n",
            "         |->> Action Probabilities (RAW): [2.9611668e-01 6.5897465e-01 1.1458765e-07 2.0564144e-09 2.4656461e-05\n",
            " 7.8952732e-03 9.3277972e-03 5.7755616e-03 5.8575198e-09 1.9135387e-08\n",
            " 2.1885276e-02], argmax=1\n",
            "|->> Revisiting bbox: [276   0  72  90]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [280,  12,  72,  90] -> [276,   0,  72,  90] (Target was [324, 138,  70,  94])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X UP:bbox transition: [280,  12,  72,  90] -> [280,   8,  72,  90] w/ P(a|s)=0.6496037244796753 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for 2X UP:bbox transition: [280,   8,  72,  90] -> [280,   4,  72,  90] w/ P(a|s)=0.9425613284111023 and iou=0.0 and reward=0.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X UP:bbox transition: [280,   4,  72,  90] -> [280,   0,  72,  90] w/ P(a|s)=0.8004811406135559 and iou=0.0 and reward=0.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.0) for 2X LEFT:bbox transition: [280,   0,  72,  90] -> [276,   0,  72,  90] w/ P(a|s)=0.6589746475219727 and iou=0.0 and reward=0.0 and discount=0.970299\n",
            "   |->> Assigned losses: [0. 0. 0. 0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 79 with src: [276,   0,  72,  90] and target: [337, 158,  68,  90]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0079.jpg\n",
            "|->> Beginning tracking for bbox:[276   0  72  90]\n",
            "   \u001b[33m|->> #0/t=14-th Action selection: 10/SCALE UP (P(a|s) = 0.22499999403953552)\u001b[0m\n",
            "      |->> Bounding box moves to: [274   0  74  92]\n",
            "         |->> Action Probabilities (Rounded): [0.0194 0.0072 0.2715 0.1885 0.0965 0.1141 0.0171 0.0036 0.0163 0.041\n",
            " 0.2248], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.01943013 0.00720494 0.27151993 0.18847565 0.09650888 0.11412887\n",
            " 0.01707573 0.00356367 0.01632235 0.04097517 0.22479464], argmax=2\n",
            "|->> Revisiting bbox: [274   0  74  92]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [276,   0,  72,  90] -> [274,   0,  74,  92] (Target was [337, 158,  68,  90])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for SCALE UP:bbox transition: [276,   0,  72,  90] -> [274,   0,  74,  92] w/ P(a|s)=0.2247946411371231 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 80 with src: [274,   0,  74,  92] and target: [344, 162,  61,  90]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0080.jpg\n",
            "|->> Beginning tracking for bbox:[274   0  74  92]\n",
            "|->> Revisiting bbox: [274   0  74  92]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=15-th Action selection: 8/STOP (P(a|s) = 0.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [274   0  74  92]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 1.000e-04 2.000e-04 1.230e-02 9.864e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 7.000e-04 3.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.7782125e-06 2.2111049e-05 6.9795038e-05 1.6362520e-04 1.2310040e-02\n",
            " 9.8642647e-01 7.5274471e-08 2.6526474e-09 1.7132317e-07 6.8868883e-04\n",
            " 3.1725108e-04], argmax=5\n",
            "         |->> Hit a STOP on the 15-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [274,   0,  74,  92] -> [274,   0,  74,  92] (Target was [344, 162,  61,  90])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [274,   0,  74,  92] -> [274,   0,  74,  92] w/ P(a|s)=1.7132316543211346e-07 and iou=0.0 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-11.512925]\n",
            "\u001b[31m>> Total frame loss: -11.512925148010254\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 81 with src: [274,   0,  74,  92] and target: [336, 173,  61,  79]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0081.jpg\n",
            "|->> Beginning tracking for bbox:[274   0  74  92]\n",
            "|->> Revisiting bbox: [274   0  74  92]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=15-th Action selection: 8/STOP (P(a|s) = 0.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [274   0  74  92]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 1.000e-04 0.000e+00 0.000e+00 0.000e+00 9.998e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 1.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [4.2792828e-07 1.3682844e-04 2.1224766e-06 3.2616086e-08 7.5796279e-06\n",
            " 9.9980193e-01 1.0370327e-12 5.8438795e-14 2.3717299e-14 7.4884440e-08\n",
            " 5.0895058e-05], argmax=5\n",
            "         |->> Hit a STOP on the 15-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [274,   0,  74,  92] -> [274,   0,  74,  92] (Target was [336, 173,  61,  79])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [274,   0,  74,  92] -> [274,   0,  74,  92] w/ P(a|s)=2.371729860574899e-14 and iou=0.0 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-11.512925]\n",
            "\u001b[31m>> Total frame loss: -11.512925148010254\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 82 with src: [274,   0,  74,  92] and target: [328, 169,  61,  79]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0082.jpg\n",
            "|->> Beginning tracking for bbox:[274   0  74  92]\n",
            "|->> Revisiting bbox: [274   0  74  92]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=15-th Action selection: 8/STOP (P(a|s) = 0.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [274   0  74  92]\n",
            "         |->> Action Probabilities (Rounded): [8.000e-04 1.470e-02 0.000e+00 0.000e+00 2.200e-03 9.748e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 3.600e-03 3.900e-03], argmax=5\n",
            "         |->> Action Probabilities (RAW): [7.6733739e-04 1.4741556e-02 4.3353488e-08 2.3223558e-08 2.1550888e-03\n",
            " 9.7476691e-01 3.4832399e-05 6.3953536e-07 9.4667707e-10 3.6041052e-03\n",
            " 3.9295694e-03], argmax=5\n",
            "         |->> Hit a STOP on the 15-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [274,   0,  74,  92] -> [274,   0,  74,  92] (Target was [328, 169,  61,  79])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [274,   0,  74,  92] -> [274,   0,  74,  92] w/ P(a|s)=9.466770700683469e-10 and iou=0.0 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-11.512925]\n",
            "\u001b[31m>> Total frame loss: -11.512925148010254\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 83 with src: [274,   0,  74,  92] and target: [320, 164,  61,  79]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0083.jpg\n",
            "|->> Beginning tracking for bbox:[274   0  74  92]\n",
            "|->> Revisiting bbox: [274   0  74  92]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=15-th Action selection: 8/STOP (P(a|s) = 0.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [274   0  74  92]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 1.000e-04 0.000e+00 9.999e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.14653546e-11 5.14070528e-08 4.15809396e-08 1.04150626e-04\n",
            " 3.50768943e-08 9.99895692e-01 5.42475261e-18 2.27693944e-16\n",
            " 1.01010011e-17 3.46425555e-10 1.23508648e-10], argmax=5\n",
            "         |->> Hit a STOP on the 15-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [274,   0,  74,  92] -> [274,   0,  74,  92] (Target was [320, 164,  61,  79])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [274,   0,  74,  92] -> [274,   0,  74,  92] w/ P(a|s)=1.0101001072086153e-17 and iou=0.0 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-11.512925]\n",
            "\u001b[31m>> Total frame loss: -11.512925148010254\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 84 with src: [274,   0,  74,  92] and target: [300, 149,  61,  79]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0084.jpg\n",
            "|->> Beginning tracking for bbox:[274   0  74  92]\n",
            "   \u001b[33m|->> #0/t=15-th Action selection: 1/2X LEFT (P(a|s) = 0.06700000166893005)\u001b[0m\n",
            "      |->> Bounding box moves to: [270   0  74  92]\n",
            "         |->> Action Probabilities (Rounded): [0.1742 0.0668 0.0211 0.0057 0.0108 0.0155 0.1643 0.3878 0.0102 0.0118\n",
            " 0.1318], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.17418633 0.06682998 0.02114634 0.00565587 0.01077003 0.01554573\n",
            " 0.1642827  0.38779792 0.01020779 0.01182202 0.1317553 ], argmax=7\n",
            "   \u001b[33m|->> #1/t=16-th Action selection: 0/LEFT (P(a|s) = 0.032999999821186066)\u001b[0m\n",
            "      |->> Bounding box moves to: [268   0  74  92]\n",
            "         |->> Action Probabilities (Rounded): [3.260e-02 1.401e-01 1.000e-04 1.000e-04 1.210e-02 8.113e-01 1.200e-03\n",
            " 2.000e-04 0.000e+00 1.700e-03 6.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.2631256e-02 1.4007150e-01 8.8459034e-05 9.7494798e-05 1.2093386e-02\n",
            " 8.1127840e-01 1.1885768e-03 2.4148612e-04 1.5792066e-05 1.7000097e-03\n",
            " 5.9370464e-04], argmax=5\n",
            "   \u001b[33m|->> #2/t=17-th Action selection: 0/LEFT (P(a|s) = 0.7879999876022339)\u001b[0m\n",
            "      |->> Bounding box moves to: [266   0  74  92]\n",
            "         |->> Action Probabilities (Rounded): [7.876e-01 8.600e-03 7.030e-02 2.000e-04 1.093e-01 1.250e-02 7.000e-03\n",
            " 0.000e+00 3.800e-03 6.000e-04 1.000e-04], argmax=0\n",
            "         |->> Action Probabilities (RAW): [7.8760821e-01 8.5861618e-03 7.0268229e-02 2.2118846e-04 1.0931145e-01\n",
            " 1.2460232e-02 6.9931140e-03 3.0248979e-05 3.7938319e-03 5.8321870e-04\n",
            " 1.4414861e-04], argmax=0\n",
            "   \u001b[33m|->> #3/t=18-th Action selection: 0/LEFT (P(a|s) = 0.5600000023841858)\u001b[0m\n",
            "      |->> Bounding box moves to: [264   0  74  92]\n",
            "         |->> Action Probabilities (Rounded): [5.597e-01 2.630e-02 2.700e-03 1.900e-03 2.500e-03 3.320e-02 2.544e-01\n",
            " 7.490e-02 1.000e-04 0.000e+00 4.430e-02], argmax=0\n",
            "         |->> Action Probabilities (RAW): [5.5969673e-01 2.6259935e-02 2.7078383e-03 1.8843578e-03 2.4752575e-03\n",
            " 3.3209350e-02 2.5441864e-01 7.4928343e-02 8.1930899e-05 4.6827014e-07\n",
            " 4.4337135e-02], argmax=0\n",
            "|->> Revisiting bbox: [264   0  74  92]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [274,   0,  74,  92] -> [264,   0,  74,  92] (Target was [300, 149,  61,  79])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X LEFT:bbox transition: [274,   0,  74,  92] -> [270,   0,  74,  92] w/ P(a|s)=0.06682997941970825 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for LEFT:bbox transition: [270,   0,  74,  92] -> [268,   0,  74,  92] w/ P(a|s)=0.03263125568628311 and iou=0.0 and reward=0.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.0) for LEFT:bbox transition: [268,   0,  74,  92] -> [266,   0,  74,  92] w/ P(a|s)=0.7876082062721252 and iou=0.0 and reward=0.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.0) for LEFT:bbox transition: [266,   0,  74,  92] -> [264,   0,  74,  92] w/ P(a|s)=0.5596967339515686 and iou=0.0 and reward=0.0 and discount=0.970299\n",
            "   |->> Assigned losses: [0. 0. 0. 0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 85 with src: [264,   0,  74,  92] and target: [281, 128,  61,  79]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0085.jpg\n",
            "|->> Beginning tracking for bbox:[264   0  74  92]\n",
            "|->> Revisiting bbox: [264   0  74  92]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=19-th Action selection: 8/STOP (P(a|s) = 0.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [264   0  74  92]\n",
            "         |->> Action Probabilities (Rounded): [0.0024 0.     0.     0.     0.4117 0.0119 0.     0.     0.     0.574\n",
            " 0.    ], argmax=9\n",
            "         |->> Action Probabilities (RAW): [2.3504472e-03 8.5298376e-07 1.3679194e-05 1.1837510e-07 4.1166851e-01\n",
            " 1.1929278e-02 6.9894048e-07 8.8625793e-06 2.4618992e-06 5.7402503e-01\n",
            " 7.1449563e-08], argmax=9\n",
            "         |->> Hit a STOP on the 19-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [264,   0,  74,  92] -> [264,   0,  74,  92] (Target was [281, 128,  61,  79])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [264,   0,  74,  92] -> [264,   0,  74,  92] w/ P(a|s)=2.461899157424341e-06 and iou=0.0 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-11.512925]\n",
            "\u001b[31m>> Total frame loss: -11.512925148010254\u001b[0m\n",
            "Final bounding box: [264   0  74  92] reached in 19 timesteps (originating from [276  22  70  88]). Target was [281 128  61  79]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 86 in t=19 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[31m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 256.78668212890625\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.04397307336330414\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 84.21671295166016\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.19556915760040283\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 103.86448669433594\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.3227827847003937\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 69.86502075195312\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.17718516290187836\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 45.73377990722656\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.17651234567165375\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 94.83140563964844\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 1.1332751512527466\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/Matrix\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Starting bounding box for adnet_datasets/OTB/Matrix: frames 58:68 is [296   6  53  59].\n",
            "\u001b[34m>> Attempting to reach frame 59 with src: [296,   6,  53,  59] and target: [294,   5,  48,  62]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0059.jpg\n",
            "|->> Beginning tracking for bbox:[296   6  53  59]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 0/LEFT (P(a|s) = 0.9110000133514404)\u001b[0m\n",
            "      |->> Bounding box moves to: [295   6  53  59]\n",
            "         |->> Action Probabilities (Rounded): [9.11e-01 8.83e-02 0.00e+00 0.00e+00 0.00e+00 1.00e-04 0.00e+00 0.00e+00\n",
            " 0.00e+00 6.00e-04 0.00e+00], argmax=0\n",
            "         |->> Action Probabilities (RAW): [9.1104269e-01 8.8285409e-02 1.5117865e-09 5.3884464e-10 2.1125776e-05\n",
            " 5.8557380e-05 9.4584802e-06 1.5921057e-07 8.8954444e-09 5.6306855e-04\n",
            " 1.9434359e-05], argmax=0\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 0/LEFT (P(a|s) = 0.9599999785423279)\u001b[0m\n",
            "      |->> Bounding box moves to: [294   6  53  59]\n",
            "         |->> Action Probabilities (Rounded): [9.598e-01 5.900e-03 0.000e+00 0.000e+00 2.800e-03 4.000e-03 5.900e-03\n",
            " 0.000e+00 1.000e-04 2.040e-02 1.000e-03], argmax=0\n",
            "         |->> Action Probabilities (RAW): [9.5983118e-01 5.8536595e-03 1.3997320e-05 4.1498245e-07 2.8446193e-03\n",
            " 4.0435363e-03 5.9382841e-03 1.3251550e-05 1.1131846e-04 2.0373538e-02\n",
            " 9.7615947e-04], argmax=0\n",
            "   \u001b[33m|->> #2/t=3-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [294   4  53  59]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.6183897e-07 3.2971993e-06 5.1467447e-07 6.1566958e-08 3.1575495e-05\n",
            " 9.9996126e-01 1.2596955e-07 2.6125660e-10 1.8910444e-09 1.7765263e-09\n",
            " 3.0202805e-06], argmax=5\n",
            "   \u001b[33m|->> #3/t=4-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [294   2  53  59]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [6.3441047e-16 3.2391104e-11 3.1015373e-13 1.7339461e-11 6.0713489e-08\n",
            " 9.9999988e-01 3.3642279e-17 5.6908634e-13 3.4298746e-17 2.9954953e-17\n",
            " 6.7162602e-11], argmax=5\n",
            "|->> Revisiting bbox: [294   4  53  59]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [296,   6,  53,  59] -> [294,   2,  53,  59] (Target was [294,   5,  48,  62])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.032) for LEFT:bbox transition: [296,   6,  53,  59] -> [295,   6,  53,  59] w/ P(a|s)=0.9110426902770996 and iou=0.8327327327327327 and reward=0.03190653031313995 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.033) for LEFT:bbox transition: [295,   6,  53,  59] -> [294,   6,  53,  59] w/ P(a|s)=0.959831178188324 and iou=0.8657902782023846 and reward=0.033057545469651894 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-0.027) for 2X UP:bbox transition: [294,   6,  53,  59] -> [294,   4,  53,  59] w/ P(a|s)=0.999961256980896 and iou=0.8388068695390177 and reward=-0.026983408663366903 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-0.052) for 2X UP:bbox transition: [294,   4,  53,  59] -> [294,   2,  53,  59] w/ P(a|s)=0.9999998807907104 and iou=0.7871156661786237 and reward=-0.05169120336039401 and discount=0.970299\n",
            "   |->> Assigned losses: [ 2.9725886e-03  1.3417359e-03 -1.0246347e-06 -5.0224287e-07]\n",
            "\u001b[92m>> Total frame loss: 0.004312797915190458\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 60 with src: [294,   2,  53,  59] and target: [291,   9,  52,  58]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0060.jpg\n",
            "|->> Beginning tracking for bbox:[294   2  53  59]\n",
            "   \u001b[33m|->> #0/t=5-th Action selection: 6/DOWN (P(a|s) = 0.8679999709129333)\u001b[0m\n",
            "      |->> Bounding box moves to: [294   3  53  59]\n",
            "         |->> Action Probabilities (Rounded): [0.0184 0.     0.     0.     0.0428 0.0688 0.8676 0.     0.     0.0024\n",
            " 0.    ], argmax=6\n",
            "         |->> Action Probabilities (RAW): [1.8437214e-02 5.0210826e-08 5.4727758e-14 6.6635314e-17 4.2751126e-02\n",
            " 6.8840027e-02 8.6758155e-01 4.5565852e-07 3.9236010e-12 2.3895882e-03\n",
            " 8.1136681e-11], argmax=6\n",
            "   \u001b[33m|->> #1/t=6-th Action selection: 6/DOWN (P(a|s) = 0.7110000252723694)\u001b[0m\n",
            "      |->> Bounding box moves to: [294   4  53  59]\n",
            "         |->> Action Probabilities (Rounded): [1.300e-02 3.000e-04 0.000e+00 0.000e+00 3.580e-02 2.363e-01 7.112e-01\n",
            " 0.000e+00 0.000e+00 3.400e-03 0.000e+00], argmax=6\n",
            "         |->> Action Probabilities (RAW): [1.3017727e-02 2.5371608e-04 5.9221881e-12 1.1925404e-14 3.5790849e-02\n",
            " 2.3631875e-01 7.1119541e-01 7.0917019e-07 8.4719055e-12 3.4228687e-03\n",
            " 4.6448494e-09], argmax=6\n",
            "   \u001b[33m|->> #2/t=7-th Action selection: 0/LEFT (P(a|s) = 0.4779999852180481)\u001b[0m\n",
            "      |->> Bounding box moves to: [293   4  53  59]\n",
            "         |->> Action Probabilities (Rounded): [4.784e-01 4.706e-01 0.000e+00 0.000e+00 1.000e-04 9.000e-04 3.920e-02\n",
            " 0.000e+00 0.000e+00 1.070e-02 0.000e+00], argmax=0\n",
            "         |->> Action Probabilities (RAW): [4.7843775e-01 4.7061613e-01 1.4438268e-06 2.5903957e-10 9.6566546e-05\n",
            " 8.6445705e-04 3.9231572e-02 1.4774202e-05 1.1120148e-08 1.0737192e-02\n",
            " 2.7670643e-08], argmax=0\n",
            "   \u001b[33m|->> #3/t=8-th Action selection: 5/2X UP (P(a|s) = 0.6710000038146973)\u001b[0m\n",
            "      |->> Bounding box moves to: [293   2  53  59]\n",
            "         |->> Action Probabilities (Rounded): [1.800e-03 1.600e-03 0.000e+00 0.000e+00 3.257e-01 6.707e-01 1.000e-04\n",
            " 1.000e-04 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.7904508e-03 1.6427954e-03 5.1513682e-09 1.5927096e-08 3.2568106e-01\n",
            " 6.7066175e-01 1.1128930e-04 1.0834851e-04 4.3005170e-06 4.1756479e-08\n",
            " 9.7227969e-11], argmax=5\n",
            "             |->> IOU declining: [293   2  53  59]:0.7338413773638159 -> [293   0  53  59]:0.6862475981334065.\n",
            "             |->> Overriding with STOP\n",
            "   \u001b[33m|->> #4/t=9-th Action selection: 8/STOP (P(a|s) = 0.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [293   2  53  59]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [6.7327751e-06 2.5231464e-12 3.8029838e-14 7.6254488e-18 1.3780310e-05\n",
            " 9.9997950e-01 9.5182873e-10 7.2458486e-16 7.2080131e-19 1.5715503e-16\n",
            " 6.7990934e-21], argmax=5\n",
            "         |->> Hit a STOP on the 9-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [294,   2,  53,  59] -> [293,   2,  53,  59] (Target was [291,   9,  52,  58])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.024) for DOWN:bbox transition: [294,   2,  53,  59] -> [294,   3,  53,  59] w/ P(a|s)=0.8675815463066101 and iou=0.7323745064861816 and reward=0.023612336806070333 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.024) for DOWN:bbox transition: [294,   3,  53,  59] -> [294,   4,  53,  59] w/ P(a|s)=0.7111954092979431 and iou=0.7566485559050615 and reward=0.024274049418879895 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.028) for LEFT:bbox transition: [294,   4,  53,  59] -> [293,   4,  53,  59] w/ P(a|s)=0.47843775153160095 and iou=0.7841998257333721 and reward=0.027551269828310576 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-0.05) for 2X UP:bbox transition: [293,   4,  53,  59] -> [293,   2,  53,  59] w/ P(a|s)=0.6706617474555969 and iou=0.7338413773638159 and reward=-0.050358448369556164 and discount=0.970299\n",
            "   |->> t=5 Stop-Reward (1.0) for STOP:bbox transition: [293,   2,  53,  59] -> [293,   2,  53,  59] w/ P(a|s)=7.20801308369587e-19 and iou=0.7338413773638159 and reward=1.0 and discount=0.96059601\n",
            "   |->> Assigned losses: [ 3.3540325e-03  8.1900638e-03  1.9907398e-02 -1.9520199e-02\n",
            "  1.1059270e+01]\n",
            "\u001b[92m>> Total frame loss: 11.07120132446289\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 61 with src: [293,   2,  53,  59] and target: [299,  11,  48,  54]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0061.jpg\n",
            "|->> Beginning tracking for bbox:[293   2  53  59]\n",
            "   \u001b[33m|->> #0/t=9-th Action selection: 5/2X UP (P(a|s) = 0.9760000109672546)\u001b[0m\n",
            "      |->> Bounding box moves to: [293   0  53  59]\n",
            "         |->> Action Probabilities (Rounded): [7.000e-04 4.700e-03 1.300e-03 3.800e-03 1.100e-03 9.762e-01 0.000e+00\n",
            " 6.000e-04 0.000e+00 1.000e-04 1.150e-02], argmax=5\n",
            "         |->> Action Probabilities (RAW): [6.8970054e-04 4.6705049e-03 1.2561578e-03 3.8492058e-03 1.1309000e-03\n",
            " 9.7618628e-01 4.4859684e-05 5.8001227e-04 1.5067050e-05 6.9737936e-05\n",
            " 1.1507552e-02], argmax=5\n",
            "|->> Revisiting bbox: [293   2  53  59]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [293,   2,  53,  59] -> [293,   0,  53,  59] (Target was [299,  11,  48,  54])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.046) for 2X UP:bbox transition: [293,   2,  53,  59] -> [293,   0,  53,  59] w/ P(a|s)=0.9761862754821777 and iou=0.651458273173549 and reward=-0.0460780877644148 and discount=1.0\n",
            "   |->> Assigned losses: [-0.00111057]\n",
            "\u001b[31m>> Total frame loss: -0.0011105674784630537\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 62 with src: [293,   0,  53,  59] and target: [307,   5,  56,  60]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0062.jpg\n",
            "|->> Beginning tracking for bbox:[293   0  53  59]\n",
            "   \u001b[33m|->> #0/t=10-th Action selection: 7/2X DOWN (P(a|s) = 0.9449999928474426)\u001b[0m\n",
            "      |->> Bounding box moves to: [293   2  53  59]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 1.000e-04 3.970e-02 7.000e-04 1.300e-02 0.000e+00\n",
            " 9.446e-01 0.000e+00 0.000e+00 1.800e-03], argmax=7\n",
            "         |->> Action Probabilities (RAW): [7.72963233e-07 8.36008894e-06 1.30551882e-04 3.97379883e-02\n",
            " 7.24734331e-04 1.30337905e-02 9.77927630e-06 9.44556057e-01\n",
            " 1.68154521e-08 2.43609612e-08 1.79784850e-03], argmax=7\n",
            "|->> Revisiting bbox: [293   0  53  59]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [293,   0,  53,  59] -> [293,   2,  53,  59] (Target was [307,   5,  56,  60])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.027) for 2X DOWN:bbox transition: [293,   0,  53,  59] -> [293,   2,  53,  59] w/ P(a|s)=0.9445560574531555 and iou=0.5075528700906344 and reward=0.02684070391852761 and discount=1.0\n",
            "   |->> Assigned losses: [0.001531]\n",
            "\u001b[92m>> Total frame loss: 0.0015310001326724887\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 63 with src: [293,   2,  53,  59] and target: [320,   2,  56,  62]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0063.jpg\n",
            "|->> Beginning tracking for bbox:[293   2  53  59]\n",
            "   \u001b[33m|->> #0/t=11-th Action selection: 5/2X UP (P(a|s) = 0.9980000257492065)\u001b[0m\n",
            "      |->> Bounding box moves to: [293   0  53  59]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.0024 0.     0.9976 0.     0.     0.     0.\n",
            " 0.    ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [5.3017846e-10 6.8080485e-06 7.5321611e-07 2.4062532e-03 5.6514949e-07\n",
            " 9.9757832e-01 5.9526474e-11 1.6457124e-13 2.3361224e-09 4.8568232e-08\n",
            " 7.1696350e-06], argmax=5\n",
            "   \u001b[33m|->> #1/t=12-th Action selection: 9/SCALE DOWN (P(a|s) = 0.06599999964237213)\u001b[0m\n",
            "      |->> Bounding box moves to: [294   1  51  57]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 9.400e-03 4.670e-02 1.796e-01 3.000e-04 6.679e-01 2.030e-02\n",
            " 9.300e-03 0.000e+00 6.590e-02 5.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [4.4491029e-05 9.4223637e-03 4.6685185e-02 1.7958334e-01 2.7130684e-04\n",
            " 6.6785574e-01 2.0344328e-02 9.3285711e-03 2.1246351e-05 6.5932438e-02\n",
            " 5.1088713e-04], argmax=5\n",
            "   \u001b[33m|->> #2/t=13-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [294   0  51  57]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.3873234e-17 5.4881691e-15 6.7056281e-21 3.6112144e-19 1.1695724e-13\n",
            " 1.0000000e+00 2.8568213e-22 4.1284671e-18 8.0660450e-27 6.0156240e-17\n",
            " 5.8022414e-21], argmax=5\n",
            "|->> Revisiting bbox: [294   0  51  57]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [293,   2,  53,  59] -> [294,   0,  51,  57] (Target was [320,   2,  56,  62])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.013) for 2X UP:bbox transition: [293,   2,  53,  59] -> [293,   0,  53,  59] w/ P(a|s)=0.9975783228874207 and iou=0.28962282587453586 and reward=-0.013239957935928082 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.008) for SCALE DOWN:bbox transition: [293,   0,  53,  59] -> [294,   1,  51,  57] w/ P(a|s)=0.06593243777751923 and iou=0.28118096003213494 and reward=-0.00844186584240092 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-0.006) for 2X UP:bbox transition: [294,   1,  51,  57] -> [294,   0,  51,  57] w/ P(a|s)=1.0 and iou=0.2747801758593125 and reward=-0.006400784172822416 and discount=0.9801\n",
            "   |->> Assigned losses: [-3.2101791e-05 -2.2724940e-02 -6.2819595e-08]\n",
            "\u001b[31m>> Total frame loss: -0.02275710552930832\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 64 with src: [294,   0,  51,  57] and target: [333,   2,  51,  60]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0064.jpg\n",
            "|->> Beginning tracking for bbox:[294   0  51  57]\n",
            "|->> Revisiting bbox: [294   0  51  57]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=14-th Action selection: 8/STOP (P(a|s) = 0.0010000000474974513)\u001b[0m\n",
            "      |->> Bounding box moves to: [294   0  51  57]\n",
            "         |->> Action Probabilities (Rounded): [1.440e-02 1.000e-04 1.640e-02 4.900e-03 3.640e-02 2.767e-01 7.900e-03\n",
            " 0.000e+00 9.000e-04 3.600e-03 6.388e-01], argmax=10\n",
            "         |->> Action Probabilities (RAW): [1.4404097e-02 6.9081092e-05 1.6371910e-02 4.8619825e-03 3.6384802e-02\n",
            " 2.7666008e-01 7.8987423e-03 4.9668732e-05 8.5456396e-04 3.6114326e-03\n",
            " 6.3883364e-01], argmax=10\n",
            "         |->> Hit a STOP on the 14-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [294,   0,  51,  57] -> [294,   0,  51,  57] (Target was [333,   2,  51,  60])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [294,   0,  51,  57] -> [294,   0,  51,  57] w/ P(a|s)=0.0008545639575459063 and iou=0.1243640474844545 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-7.0649195]\n",
            "\u001b[31m>> Total frame loss: -7.064919471740723\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 65 with src: [294,   0,  51,  57] and target: [329,   2,  53,  62]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0065.jpg\n",
            "|->> Beginning tracking for bbox:[294   0  51  57]\n",
            "   \u001b[33m|->> #0/t=14-th Action selection: 7/2X DOWN (P(a|s) = 0.5730000138282776)\u001b[0m\n",
            "      |->> Bounding box moves to: [294   2  51  57]\n",
            "         |->> Action Probabilities (Rounded): [1.000e-04 0.000e+00 0.000e+00 0.000e+00 1.000e-04 4.186e-01 4.600e-03\n",
            " 5.729e-01 0.000e+00 0.000e+00 3.700e-03], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.0178949e-04 8.0116371e-07 1.5822490e-06 1.5380332e-05 8.1657738e-05\n",
            " 4.1860947e-01 4.5680860e-03 5.7291609e-01 1.2041041e-08 2.9132524e-10\n",
            " 3.7051460e-03], argmax=7\n",
            "|->> Revisiting bbox: [294   0  51  57]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [294,   0,  51,  57] -> [294,   2,  51,  57] (Target was [329,   2,  53,  62])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.007) for 2X DOWN:bbox transition: [294,   0,  51,  57] -> [294,   2,  51,  57] w/ P(a|s)=0.5729160904884338 and iou=0.1726945654232153 and reward=0.007063095443919226 and discount=1.0\n",
            "   |->> Assigned losses: [0.00393426]\n",
            "\u001b[92m>> Total frame loss: 0.003934257198125124\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 66 with src: [294,   2,  51,  57] and target: [321,   7,  54,  61]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0066.jpg\n",
            "|->> Beginning tracking for bbox:[294   2  51  57]\n",
            "   \u001b[33m|->> #0/t=15-th Action selection: 5/2X UP (P(a|s) = 0.5260000228881836)\u001b[0m\n",
            "      |->> Bounding box moves to: [294   0  51  57]\n",
            "         |->> Action Probabilities (Rounded): [0.0201 0.4538 0.     0.     0.     0.5261 0.     0.     0.     0.\n",
            " 0.    ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.0053087e-02 4.5380375e-01 3.6380521e-10 6.4161143e-09 1.5547981e-05\n",
            " 5.2611691e-01 2.9370337e-06 2.2014144e-07 1.8673613e-11 1.3767254e-06\n",
            " 6.1555206e-06], argmax=5\n",
            "|->> Revisiting bbox: [294   0  51  57]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [294,   2,  51,  57] -> [294,   0,  51,  57] (Target was [321,   7,  54,  61])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.012) for 2X UP:bbox transition: [294,   2,  51,  57] -> [294,   0,  51,  57] w/ P(a|s)=0.5261169075965881 and iou=0.23995200959808038 and reward=-0.012016494338927486 and discount=1.0\n",
            "   |->> Assigned losses: [-0.00771738]\n",
            "\u001b[31m>> Total frame loss: -0.007717375177890062\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 67 with src: [294,   0,  51,  57] and target: [323,   9,  55,  59]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0067.jpg\n",
            "|->> Beginning tracking for bbox:[294   0  51  57]\n",
            "   \u001b[33m|->> #0/t=16-th Action selection: 1/2X LEFT (P(a|s) = 0.9990000128746033)\u001b[0m\n",
            "      |->> Bounding box moves to: [292   0  51  57]\n",
            "         |->> Action Probabilities (Rounded): [1.000e-04 9.988e-01 0.000e+00 0.000e+00 0.000e+00 1.100e-03 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=1\n",
            "         |->> Action Probabilities (RAW): [8.7202112e-05 9.9881184e-01 2.8011666e-12 2.3553693e-13 4.2484904e-10\n",
            " 1.0540659e-03 2.7968788e-05 8.5209003e-06 9.5034972e-13 9.7201025e-11\n",
            " 1.0501627e-05], argmax=1\n",
            "   \u001b[33m|->> #1/t=17-th Action selection: 1/2X LEFT (P(a|s) = 0.9919999837875366)\u001b[0m\n",
            "      |->> Bounding box moves to: [290   0  51  57]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.9922 0.     0.     0.     0.0078 0.     0.     0.     0.\n",
            " 0.    ], argmax=1\n",
            "         |->> Action Probabilities (RAW): [3.7646794e-07 9.9218094e-01 3.6346797e-14 8.8315435e-16 1.6689121e-07\n",
            " 7.8166015e-03 2.6126855e-13 1.2193480e-10 1.4417348e-12 1.0713834e-09\n",
            " 1.8672960e-06], argmax=1\n",
            "|->> Revisiting bbox: [290   0  51  57]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [294,   0,  51,  57] -> [290,   0,  51,  57] (Target was [323,   9,  55,  59])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.022) for 2X LEFT:bbox transition: [294,   0,  51,  57] -> [292,   0,  51,  57] w/ P(a|s)=0.9988118410110474 and iou=0.18489984591679506 and reward=-0.02232150416169787 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.022) for 2X LEFT:bbox transition: [292,   0,  51,  57] -> [290,   0,  51,  57] w/ P(a|s)=0.9921809434890747 and iou=0.16338880484114976 and reward=-0.021511041075645304 and discount=0.99\n",
            "   |->> Assigned losses: [-2.6537264e-05 -1.6716849e-04]\n",
            "\u001b[31m>> Total frame loss: -0.00019370575319044292\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 68 with src: [290,   0,  51,  57] and target: [323,   8,  58,  62]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0068.jpg\n",
            "|->> Beginning tracking for bbox:[290   0  51  57]\n",
            "|->> Revisiting bbox: [290   0  51  57]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=18-th Action selection: 8/STOP (P(a|s) = 0.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [290   0  51  57]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.0955 0.     0.     0.     0.9045 0.     0.     0.     0.\n",
            " 0.    ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [4.2786976e-07 9.5484242e-02 2.2834308e-07 2.8477061e-05 1.4802226e-08\n",
            " 9.0448499e-01 3.6853951e-09 4.3739612e-07 6.7972542e-12 5.2862435e-07\n",
            " 6.7814079e-07], argmax=5\n",
            "         |->> Hit a STOP on the 18-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [290,   0,  51,  57] -> [290,   0,  51,  57] (Target was [323,   8,  58,  62])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [290,   0,  51,  57] -> [290,   0,  51,  57] w/ P(a|s)=6.797254165774591e-12 and iou=0.1569115815691158 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-11.512925]\n",
            "\u001b[31m>> Total frame loss: -11.512925148010254\u001b[0m\n",
            "Final bounding box: [290   0  51  57] reached in 18 timesteps (originating from [296   6  53  59]). Target was [323   8  58  62]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 69 in t=18 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[31m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 414.3216857910156\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.3443874716758728\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 167.33580017089844\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.41763240098953247\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 215.292724609375\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.9594452381134033\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 111.70068359375\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.43843066692352295\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 45.7809944152832\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.36045408248901367\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 81.89099884033203\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 1.21373450756073\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/Matrix\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Starting bounding box for adnet_datasets/OTB/Matrix: frames 66:76 is [321   7  54  61].\n",
            "\u001b[34m>> Attempting to reach frame 67 with src: [321,   7,  54,  61] and target: [323,   9,  55,  59]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0067.jpg\n",
            "|->> Beginning tracking for bbox:[321   7  54  61]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 7/2X DOWN (P(a|s) = 0.12099999934434891)\u001b[0m\n",
            "      |->> Bounding box moves to: [321   9  54  61]\n",
            "         |->> Action Probabilities (Rounded): [4.100e-03 2.300e-02 1.627e-01 2.710e-02 6.100e-03 6.545e-01 4.000e-04\n",
            " 1.205e-01 0.000e+00 2.000e-04 1.400e-03], argmax=5\n",
            "         |->> Action Probabilities (RAW): [4.12070099e-03 2.29687840e-02 1.62733957e-01 2.70619765e-02\n",
            " 6.09194441e-03 6.54545248e-01 3.82732862e-04 1.20513916e-01\n",
            " 3.55140764e-05 1.59403353e-04 1.38587516e-03], argmax=5\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 0/LEFT (P(a|s) = 0.625)\u001b[0m\n",
            "      |->> Bounding box moves to: [320   9  54  61]\n",
            "         |->> Action Probabilities (Rounded): [6.25e-01 2.42e-01 1.20e-03 3.00e-04 5.14e-02 4.01e-02 8.30e-03 2.70e-03\n",
            " 2.00e-03 1.43e-02 1.26e-02], argmax=0\n",
            "         |->> Action Probabilities (RAW): [6.2502366e-01 2.4204865e-01 1.1661259e-03 2.9108877e-04 5.1405415e-02\n",
            " 4.0057834e-02 8.3336439e-03 2.6930762e-03 2.0415189e-03 1.4308135e-02\n",
            " 1.2630846e-02], argmax=0\n",
            "   \u001b[33m|->> #2/t=3-th Action selection: 5/2X UP (P(a|s) = 0.7020000219345093)\u001b[0m\n",
            "      |->> Bounding box moves to: [320   7  54  61]\n",
            "         |->> Action Probabilities (Rounded): [7.000e-04 2.200e-03 4.000e-04 5.200e-03 2.891e-01 7.020e-01 0.000e+00\n",
            " 2.000e-04 0.000e+00 2.000e-04 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [6.5381732e-04 2.1899175e-03 3.8066204e-04 5.1904400e-03 2.8914735e-01\n",
            " 7.0201081e-01 1.7842947e-06 2.2651959e-04 1.8616649e-06 1.7601854e-04\n",
            " 2.0843168e-05], argmax=5\n",
            "   \u001b[33m|->> #3/t=4-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [320   5  54  61]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.0621631e-07 3.4419622e-07 1.5521198e-07 5.9842513e-08 4.1672938e-05\n",
            " 9.9995458e-01 5.5973004e-08 2.8856350e-06 7.3145587e-11 2.1267661e-08\n",
            " 4.8995124e-09], argmax=5\n",
            "   \u001b[33m|->> #4/t=5-th Action selection: 0/LEFT (P(a|s) = 0.7900000214576721)\u001b[0m\n",
            "      |->> Bounding box moves to: [319   5  54  61]\n",
            "         |->> Action Probabilities (Rounded): [7.896e-01 0.000e+00 2.160e-02 0.000e+00 9.000e-04 6.260e-02 2.000e-04\n",
            " 1.000e-04 8.040e-02 4.000e-02 4.500e-03], argmax=0\n",
            "         |->> Action Probabilities (RAW): [7.89603233e-01 2.40327677e-06 2.16170885e-02 7.46001206e-06\n",
            " 9.08040151e-04 6.26260638e-02 2.40625392e-04 1.13534465e-04\n",
            " 8.04309100e-02 3.99564542e-02 4.49421583e-03], argmax=0\n",
            "   \u001b[33m|->> #5/t=6-th Action selection: 0/LEFT (P(a|s) = 0.8669999837875366)\u001b[0m\n",
            "      |->> Bounding box moves to: [318   5  54  61]\n",
            "         |->> Action Probabilities (Rounded): [0.8671 0.0082 0.0019 0.     0.0141 0.0183 0.0022 0.0128 0.0401 0.0181\n",
            " 0.0172], argmax=0\n",
            "         |->> Action Probabilities (RAW): [8.6710781e-01 8.1875147e-03 1.9015667e-03 3.1474988e-07 1.4131630e-02\n",
            " 1.8285127e-02 2.1625380e-03 1.2789896e-02 4.0065855e-02 1.8146837e-02\n",
            " 1.7220959e-02], argmax=0\n",
            "   \u001b[33m|->> #6/t=7-th Action selection: 7/2X DOWN (P(a|s) = 0.1550000011920929)\u001b[0m\n",
            "      |->> Bounding box moves to: [318   7  54  61]\n",
            "         |->> Action Probabilities (Rounded): [3.050e-01 5.366e-01 4.000e-04 0.000e+00 1.000e-04 8.000e-04 5.000e-04\n",
            " 1.554e-01 1.000e-04 3.000e-04 8.000e-04], argmax=1\n",
            "         |->> Action Probabilities (RAW): [3.04998934e-01 5.36644042e-01 3.77496646e-04 3.25636442e-08\n",
            " 1.12311165e-04 7.94041553e-04 4.79837239e-04 1.55428082e-01\n",
            " 9.13398544e-05 2.92438519e-04 7.81507115e-04], argmax=1\n",
            "   \u001b[33m|->> #7/t=8-th Action selection: 0/LEFT (P(a|s) = 0.9440000057220459)\u001b[0m\n",
            "      |->> Bounding box moves to: [317   7  54  61]\n",
            "         |->> Action Probabilities (Rounded): [0.9436 0.0489 0.     0.     0.     0.0075 0.     0.     0.     0.\n",
            " 0.    ], argmax=0\n",
            "         |->> Action Probabilities (RAW): [9.4360632e-01 4.8878569e-02 8.6406038e-09 1.2377902e-11 8.1099853e-07\n",
            " 7.4942051e-03 1.6613061e-05 9.1023807e-08 5.6176601e-09 4.6877902e-09\n",
            " 3.3469505e-06], argmax=0\n",
            "   \u001b[33m|->> #8/t=9-th Action selection: 0/LEFT (P(a|s) = 0.15600000321865082)\u001b[0m\n",
            "      |->> Bounding box moves to: [316   7  54  61]\n",
            "         |->> Action Probabilities (Rounded): [1.562e-01 8.182e-01 0.000e+00 0.000e+00 3.600e-03 1.710e-02 5.000e-04\n",
            " 2.000e-04 0.000e+00 4.100e-03 0.000e+00], argmax=1\n",
            "         |->> Action Probabilities (RAW): [1.5622213e-01 8.1822932e-01 3.4334823e-06 3.9340936e-08 3.6206320e-03\n",
            " 1.7113904e-02 4.9598282e-04 1.8333436e-04 5.9133623e-07 4.1275891e-03\n",
            " 3.0581186e-06], argmax=1\n",
            "   \u001b[33m|->> #9/t=10-th Action selection: 7/2X DOWN (P(a|s) = 0.8930000066757202)\u001b[0m\n",
            "      |->> Bounding box moves to: [316   9  54  61]\n",
            "         |->> Action Probabilities (Rounded): [3.000e-03 1.042e-01 0.000e+00 0.000e+00 1.000e-04 0.000e+00 0.000e+00\n",
            " 8.927e-01 0.000e+00 0.000e+00 0.000e+00], argmax=7\n",
            "         |->> Action Probabilities (RAW): [3.04558664e-03 1.04215786e-01 1.73257433e-07 1.39118561e-09\n",
            " 5.55928054e-05 7.66938138e-06 1.33794647e-05 8.92656744e-01\n",
            " 4.18501012e-09 5.09727306e-06 3.45732865e-08], argmax=7\n",
            "   \u001b[33m|->> #10/t=11-th Action selection: 10/SCALE UP (P(a|s) = 0.7960000038146973)\u001b[0m\n",
            "      |->> Bounding box moves to: [315   8  56  63]\n",
            "         |->> Action Probabilities (Rounded): [2.000e-02 0.000e+00 7.300e-03 0.000e+00 4.500e-03 1.187e-01 1.000e-04\n",
            " 4.980e-02 2.900e-03 8.000e-04 7.958e-01], argmax=10\n",
            "         |->> Action Probabilities (RAW): [1.9987550e-02 2.8304277e-05 7.3341778e-03 9.8783394e-06 4.5016557e-03\n",
            " 1.1873214e-01 1.2901631e-04 4.9829800e-02 2.8735560e-03 7.6880812e-04\n",
            " 7.9580522e-01], argmax=10\n",
            "|->> Revisiting bbox: [316   9  54  61]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [321,   7,  54,  61] -> [315,   8,  56,  63] (Target was [323,   9,  55,  59])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X DOWN:bbox transition: [321,   7,  54,  61] -> [321,   9,  54,  61] w/ P(a|s)=0.120513916015625 and iou=0.8838951310861424 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.031) for LEFT:bbox transition: [321,   9,  54,  61] -> [320,   9,  54,  61] w/ P(a|s)=0.6250236630439758 and iou=0.8524079320113315 and reward=-0.0314871990748109 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X UP:bbox transition: [320,   9,  54,  61] -> [320,   7,  54,  61] w/ P(a|s)=0.7020108103752136 and iou=0.8524079320113315 and reward=0.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-0.052) for 2X UP:bbox transition: [320,   7,  54,  61] -> [320,   5,  54,  61] w/ P(a|s)=0.9999545812606812 and iou=0.800385462555066 and reward=-0.05202246945626543 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-0.028) for LEFT:bbox transition: [320,   5,  54,  61] -> [319,   5,  54,  61] w/ P(a|s)=0.7896032333374023 and iou=0.7725670913526701 and reward=-0.027818371202395942 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-0.027) for LEFT:bbox transition: [319,   5,  54,  61] -> [318,   5,  54,  61] w/ P(a|s)=0.8671078085899353 and iou=0.7455953016550988 and reward=-0.026971789697571302 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.047) for 2X DOWN:bbox transition: [318,   5,  54,  61] -> [318,   7,  54,  61] w/ P(a|s)=0.15542808175086975 and iou=0.7924890350877193 and reward=0.04689373343262049 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (-0.029) for LEFT:bbox transition: [318,   7,  54,  61] -> [317,   7,  54,  61] w/ P(a|s)=0.9436063170433044 and iou=0.7639600755327758 and reward=-0.0285289595549435 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (-0.028) for LEFT:bbox transition: [317,   7,  54,  61] -> [316,   7,  54,  61] w/ P(a|s)=0.1562221348285675 and iou=0.7363250132766861 and reward=-0.027635062256089693 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (0.0) for 2X DOWN:bbox transition: [316,   7,  54,  61] -> [316,   9,  54,  61] w/ P(a|s)=0.8926567435264587 and iou=0.7363250132766861 and reward=0.0 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (-0.018) for SCALE UP:bbox transition: [316,   9,  54,  61] -> [315,   8,  56,  63] w/ P(a|s)=0.7958052158355713 and iou=0.7185993402689672 and reward=-0.01772567300771888 and discount=0.9043820750088044\n",
            "   |->> Assigned losses: [ 0.0000000e+00 -1.4649928e-02  0.0000000e+00 -2.2926697e-06\n",
            " -6.3124476e-03 -3.6574700e-03  8.2187518e-02 -1.5434991e-03\n",
            " -4.7340345e-02  0.0000000e+00 -3.6614437e-03]\n",
            "\u001b[92m>> Total frame loss: 0.0050200894474983215\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 68 with src: [315,   8,  56,  63] and target: [323,   8,  58,  62]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0068.jpg\n",
            "|->> Beginning tracking for bbox:[315   8  56  63]\n",
            "             |->> IOU declining: [315   8  56  63]:0.7174541947926711 -> [315   6  56  63]:0.6978074356530028.\n",
            "             |->> Overriding with STOP\n",
            "   \u001b[33m|->> #0/t=12-th Action selection: 8/STOP (P(a|s) = 0.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [315   8  56  63]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 1.000e-04 1.000e-04 0.000e+00 9.997e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 1.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.4357984e-07 1.1320695e-09 1.0904928e-04 1.3302283e-04 9.1567526e-06\n",
            " 9.9968529e-01 2.4684783e-07 1.2700380e-06 1.6565307e-13 2.9982814e-08\n",
            " 6.1594459e-05], argmax=5\n",
            "         |->> Hit a STOP on the 12-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [315,   8,  56,  63] -> [315,   8,  56,  63] (Target was [323,   8,  58,  62])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [315,   8,  56,  63] -> [315,   8,  56,  63] w/ P(a|s)=1.656530679771881e-13 and iou=0.7174541947926711 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [11.512925]\n",
            "\u001b[92m>> Total frame loss: 11.512925148010254\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 69 with src: [315,   8,  56,  63] and target: [317,   2,  63,  67]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0069.jpg\n",
            "|->> Beginning tracking for bbox:[315   8  56  63]\n",
            "   \u001b[33m|->> #0/t=12-th Action selection: 9/SCALE DOWN (P(a|s) = 0.07400000095367432)\u001b[0m\n",
            "      |->> Bounding box moves to: [316   9  54  61]\n",
            "         |->> Action Probabilities (Rounded): [0.0296 0.0713 0.0146 0.0023 0.0669 0.4449 0.0089 0.0519 0.0079 0.0739\n",
            " 0.2278], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.02957927 0.07126187 0.01463679 0.0022847  0.06693871 0.44490826\n",
            " 0.00893632 0.05190362 0.00789817 0.07386517 0.22778715], argmax=5\n",
            "   \u001b[33m|->> #1/t=13-th Action selection: 4/UP (P(a|s) = 0.20100000500679016)\u001b[0m\n",
            "      |->> Bounding box moves to: [316   8  54  61]\n",
            "         |->> Action Probabilities (Rounded): [0.0989 0.0359 0.0913 0.0494 0.201  0.0363 0.0806 0.048  0.0761 0.0608\n",
            " 0.2217], argmax=10\n",
            "         |->> Action Probabilities (RAW): [0.09887931 0.03589306 0.09125672 0.04942273 0.20102876 0.03629985\n",
            " 0.08059622 0.0480278  0.07611141 0.06081844 0.22166573], argmax=10\n",
            "   \u001b[33m|->> #2/t=14-th Action selection: 9/SCALE DOWN (P(a|s) = 0.4050000011920929)\u001b[0m\n",
            "      |->> Bounding box moves to: [317   9  52  59]\n",
            "         |->> Action Probabilities (Rounded): [0.0056 0.0016 0.1449 0.0755 0.0772 0.0096 0.0366 0.0959 0.0629 0.4051\n",
            " 0.085 ], argmax=9\n",
            "         |->> Action Probabilities (RAW): [0.00563386 0.00155879 0.14489104 0.07550211 0.07723382 0.00959665\n",
            " 0.03659338 0.09592995 0.06291231 0.40512097 0.08502716], argmax=9\n",
            "   \u001b[33m|->> #3/t=15-th Action selection: 6/DOWN (P(a|s) = 0.03799999877810478)\u001b[0m\n",
            "      |->> Bounding box moves to: [317  10  52  59]\n",
            "         |->> Action Probabilities (Rounded): [0.0141 0.0071 0.5504 0.0601 0.1206 0.0415 0.0384 0.0408 0.0303 0.0511\n",
            " 0.0456], argmax=2\n",
            "         |->> Action Probabilities (RAW): [0.01414759 0.00705721 0.5504095  0.06010807 0.12059867 0.04146307\n",
            " 0.03841706 0.04084587 0.03030267 0.05109    0.04556031], argmax=2\n",
            "   \u001b[33m|->> #4/t=16-th Action selection: 6/DOWN (P(a|s) = 0.5059999823570251)\u001b[0m\n",
            "      |->> Bounding box moves to: [317  11  52  59]\n",
            "         |->> Action Probabilities (Rounded): [0.0166 0.0168 0.0382 0.0036 0.0302 0.0029 0.506  0.0927 0.2113 0.0458\n",
            " 0.0361], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.01658328 0.01675756 0.03820134 0.00356108 0.03015865 0.00292663\n",
            " 0.5059868  0.09267583 0.21126673 0.04575411 0.03612795], argmax=6\n",
            "             |->> IOU declining: [317  11  52  59]:0.7058272876199392 -> [315  11  52  59]:0.6607427660059239.\n",
            "             |->> Overriding with STOP\n",
            "   \u001b[33m|->> #5/t=17-th Action selection: 8/STOP (P(a|s) = 0.020999999716877937)\u001b[0m\n",
            "      |->> Bounding box moves to: [317  11  52  59]\n",
            "         |->> Action Probabilities (Rounded): [0.0261 0.2842 0.0042 0.0285 0.0304 0.4069 0.0195 0.1162 0.0205 0.0193\n",
            " 0.0443], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.02610589 0.28416234 0.00417415 0.02850353 0.03039168 0.4068833\n",
            " 0.01948796 0.11619597 0.02052909 0.01930929 0.04425674], argmax=5\n",
            "         |->> Hit a STOP on the 17-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [315,   8,  56,  63] -> [317,  11,  52,  59] (Target was [317,   2,  63,  67])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.006) for SCALE DOWN:bbox transition: [315,   8,  56,  63] -> [316,   9,  54,  61] w/ P(a|s)=0.07386516779661179 and iou=0.7335640138408305 and reward=-0.005829925553108906 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.021) for UP:bbox transition: [316,   9,  54,  61] -> [316,   8,  54,  61] w/ P(a|s)=0.2010287642478943 and iou=0.755021018215787 and reward=0.021457004374956568 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-0.028) for SCALE DOWN:bbox transition: [316,   8,  54,  61] -> [317,   9,  52,  59] w/ P(a|s)=0.40512096881866455 and iou=0.7268419805733238 and reward=-0.02817903764246321 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.0) for DOWN:bbox transition: [317,   9,  52,  59] -> [317,  10,  52,  59] w/ P(a|s)=0.03841705992817879 and iou=0.7268419805733238 and reward=0.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-0.021) for DOWN:bbox transition: [317,  10,  52,  59] -> [317,  11,  52,  59] w/ P(a|s)=0.5059868097305298 and iou=0.7058272876199392 and reward=-0.02101469295338465 and discount=0.96059601\n",
            "   |->> t=6 Stop-Reward (1.0) for STOP:bbox transition: [317,  11,  52,  59] -> [317,  11,  52,  59] w/ P(a|s)=0.020529093220829964 and iou=0.7058272876199392 and reward=1.0 and discount=0.9509900498999999\n",
            "   |->> Assigned losses: [-0.01518995  0.0340794  -0.02495503  0.         -0.01375203  3.6954637 ]\n",
            "\u001b[92m>> Total frame loss: 3.6756460666656494\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 70 with src: [317,  11,  52,  59] and target: [313,   3,  64,  58]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0070.jpg\n",
            "|->> Beginning tracking for bbox:[317  11  52  59]\n",
            "   \u001b[33m|->> #0/t=17-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [317   9  52  59]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 9.998e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 2.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.3322398e-05 1.7330766e-09 2.4241453e-09 2.0602042e-09 1.5364727e-05\n",
            " 9.9978536e-01 8.0983224e-18 1.1300307e-15 2.5460414e-13 1.8341509e-11\n",
            " 1.8590265e-04], argmax=5\n",
            "   \u001b[33m|->> #1/t=18-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [317   7  52  59]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [4.94846963e-09 3.67087952e-13 3.60168677e-23 1.39343561e-14\n",
            " 3.04223174e-10 1.00000000e+00 1.00811066e-18 1.02215705e-23\n",
            " 1.25885426e-22 8.46266306e-19 5.38398959e-15], argmax=5\n",
            "   \u001b[33m|->> #2/t=19-th Action selection: 0/LEFT (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [316   7  52  59]\n",
            "         |->> Action Probabilities (Rounded): [9.998e-01 1.000e-04 0.000e+00 0.000e+00 0.000e+00 2.000e-04 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=0\n",
            "         |->> Action Probabilities (RAW): [9.9979168e-01 5.6099376e-05 2.0228468e-18 1.1566637e-15 4.0977096e-12\n",
            " 1.5221813e-04 1.8226160e-11 6.5455181e-25 9.7658488e-20 3.4242796e-20\n",
            " 2.6482390e-09], argmax=0\n",
            "   \u001b[33m|->> #3/t=20-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [316   5  52  59]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.1482302e-08 7.9812965e-26 1.6242269e-21 1.4102245e-17 5.3228889e-15\n",
            " 1.0000000e+00 5.3264745e-26 6.2277053e-19 1.1318632e-19 2.2714324e-32\n",
            " 2.9422791e-17], argmax=5\n",
            "   \u001b[33m|->> #4/t=21-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [316   3  52  59]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.37354789e-06 1.10401626e-16 7.56908705e-08 1.23505187e-19\n",
            " 4.85234164e-09 9.99998212e-01 7.84570542e-13 3.80593463e-07\n",
            " 6.84561599e-16 4.48039467e-17 1.27597311e-20], argmax=5\n",
            "   \u001b[33m|->> #5/t=22-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [316   1  52  59]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.9172136e-07 5.0817328e-10 2.4923931e-08 9.4649399e-11 6.1202900e-06\n",
            " 9.9999368e-01 3.4091244e-18 4.3600736e-09 1.5731749e-15 5.3766636e-10\n",
            " 2.5698896e-10], argmax=5\n",
            "   \u001b[33m|->> #6/t=23-th Action selection: 0/LEFT (P(a|s) = 0.9679999947547913)\u001b[0m\n",
            "      |->> Bounding box moves to: [315   1  52  59]\n",
            "         |->> Action Probabilities (Rounded): [9.68e-01 1.00e-04 3.14e-02 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
            " 0.00e+00 0.00e+00 5.00e-04], argmax=0\n",
            "         |->> Action Probabilities (RAW): [9.6803659e-01 7.7584773e-05 3.1416263e-02 9.4141284e-10 7.2944560e-11\n",
            " 2.6108731e-08 2.3236667e-14 7.1528753e-08 1.7417191e-12 2.9413573e-06\n",
            " 4.6661985e-04], argmax=0\n",
            "|->> Revisiting bbox: [316   1  52  59]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [317,  11,  52,  59] -> [315,   1,  52,  59] (Target was [313,   3,  64,  58])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.041) for 2X UP:bbox transition: [317,  11,  52,  59] -> [317,   9,  52,  59] w/ P(a|s)=0.9997853636741638 and iou=0.6633954857703631 and reward=0.04138591639237266 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.044) for 2X UP:bbox transition: [317,   9,  52,  59] -> [317,   7,  52,  59] w/ P(a|s)=1.0 and iou=0.7069486404833837 and reward=0.04355315471302057 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.0) for LEFT:bbox transition: [317,   7,  52,  59] -> [316,   7,  52,  59] w/ P(a|s)=0.99979168176651 and iou=0.7069486404833837 and reward=0.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.046) for 2X UP:bbox transition: [316,   7,  52,  59] -> [316,   5,  52,  59] w/ P(a|s)=1.0 and iou=0.7528438469493278 and reward=0.04589520646594414 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.048) for 2X UP:bbox transition: [316,   5,  52,  59] -> [316,   3,  52,  59] w/ P(a|s)=0.9999982118606567 and iou=0.8012752391073327 and reward=0.04843139215800485 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-0.025) for 2X UP:bbox transition: [316,   3,  52,  59] -> [316,   1,  52,  59] w/ P(a|s)=0.9999936819076538 and iou=0.7767295597484277 and reward=-0.024545679358904948 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.0) for LEFT:bbox transition: [316,   1,  52,  59] -> [315,   1,  52,  59] w/ P(a|s)=0.9680365920066833 and iou=0.7767295597484277 and reward=0.0 and discount=0.941480149401\n",
            "   |->> Assigned losses: [ 8.8838742e-06  4.3176394e-07  0.0000000e+00  4.4592775e-07\n",
            "  4.6586416e-07 -2.3374513e-07  0.0000000e+00]\n",
            "\u001b[92m>> Total frame loss: 9.993685125664342e-06\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 71 with src: [315,   1,  52,  59] and target: [314,   2,  62,  58]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0071.jpg\n",
            "|->> Beginning tracking for bbox:[315   1  52  59]\n",
            "   \u001b[33m|->> #0/t=24-th Action selection: 1/2X LEFT (P(a|s) = 0.824999988079071)\u001b[0m\n",
            "      |->> Bounding box moves to: [313   1  52  59]\n",
            "         |->> Action Probabilities (Rounded): [8.520e-02 8.254e-01 0.000e+00 0.000e+00 1.120e-02 1.900e-03 2.000e-04\n",
            " 1.100e-03 0.000e+00 0.000e+00 7.480e-02], argmax=1\n",
            "         |->> Action Probabilities (RAW): [8.5187055e-02 8.2544905e-01 3.1310883e-05 3.6285135e-06 1.1204779e-02\n",
            " 1.8876093e-03 2.2445498e-04 1.1442462e-03 3.8386775e-06 3.1863492e-05\n",
            " 7.4832104e-02], argmax=1\n",
            "   \u001b[33m|->> #1/t=25-th Action selection: 7/2X DOWN (P(a|s) = 0.13500000536441803)\u001b[0m\n",
            "      |->> Bounding box moves to: [313   3  52  59]\n",
            "         |->> Action Probabilities (Rounded): [0.0473 0.2803 0.0068 0.2422 0.1216 0.0522 0.0029 0.1351 0.0207 0.0682\n",
            " 0.0227], argmax=1\n",
            "         |->> Action Probabilities (RAW): [0.04728036 0.28026366 0.0067916  0.2422042  0.12158713 0.05224582\n",
            " 0.00289651 0.1351271  0.02070558 0.06816308 0.02273493], argmax=1\n",
            "   \u001b[33m|->> #2/t=26-th Action selection: 1/2X LEFT (P(a|s) = 0.8080000281333923)\u001b[0m\n",
            "      |->> Bounding box moves to: [311   3  52  59]\n",
            "         |->> Action Probabilities (Rounded): [4.900e-03 8.079e-01 3.900e-03 3.000e-04 1.720e-02 1.860e-02 0.000e+00\n",
            " 1.980e-02 2.400e-03 4.300e-03 1.207e-01], argmax=1\n",
            "         |->> Action Probabilities (RAW): [4.9031712e-03 8.0788147e-01 3.9241249e-03 2.6660634e-04 1.7234679e-02\n",
            " 1.8559659e-02 1.0528818e-05 1.9829771e-02 2.4132284e-03 4.2573232e-03\n",
            " 1.2071947e-01], argmax=1\n",
            "             |->> IOU declining: [311   3  52  59]:0.7215189873417721 -> [310   3  52  59]:0.6965376782077393.\n",
            "             |->> Overriding with STOP\n",
            "   \u001b[33m|->> #3/t=27-th Action selection: 8/STOP (P(a|s) = 0.012000000104308128)\u001b[0m\n",
            "      |->> Bounding box moves to: [311   3  52  59]\n",
            "         |->> Action Probabilities (Rounded): [3.710e-02 1.000e-04 7.410e-02 2.200e-03 1.989e-01 4.790e-02 1.800e-03\n",
            " 0.000e+00 1.190e-02 3.100e-03 6.228e-01], argmax=10\n",
            "         |->> Action Probabilities (RAW): [3.71039845e-02 1.14517476e-04 7.41116554e-02 2.24302965e-03\n",
            " 1.98945671e-01 4.78928573e-02 1.76647236e-03 2.62734629e-05\n",
            " 1.18789366e-02 3.13079194e-03 6.22785866e-01], argmax=10\n",
            "         |->> Hit a STOP on the 27-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [315,   1,  52,  59] -> [311,   3,  52,  59] (Target was [314,   2,  62,  58])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.029) for 2X LEFT:bbox transition: [315,   1,  52,  59] -> [313,   1,  52,  59] w/ P(a|s)=0.8254490494728088 and iou=0.7981651376146789 and reward=-0.028589248350233354 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.024) for 2X DOWN:bbox transition: [313,   1,  52,  59] -> [313,   3,  52,  59] w/ P(a|s)=0.13512709736824036 and iou=0.7737556561085973 and reward=-0.024409481506081576 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-0.052) for 2X LEFT:bbox transition: [313,   3,  52,  59] -> [311,   3,  52,  59] w/ P(a|s)=0.8078814744949341 and iou=0.7215189873417721 and reward=-0.0522366687668252 and discount=0.9801\n",
            "   |->> t=4 Stop-Reward (1.0) for STOP:bbox transition: [311,   3,  52,  59] -> [311,   3,  52,  59] w/ P(a|s)=0.011878936551511288 and iou=0.7215189873417721 and reward=1.0 and discount=0.970299\n",
            "   |->> Assigned losses: [-0.00548421 -0.04836798 -0.0109224   4.3013244 ]\n",
            "\u001b[92m>> Total frame loss: 4.2365498542785645\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 72 with src: [311,   3,  52,  59] and target: [307,   3,  69,  53]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0072.jpg\n",
            "|->> Beginning tracking for bbox:[311   3  52  59]\n",
            "   \u001b[33m|->> #0/t=27-th Action selection: 3/2X RIGHT (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [313   3  52  59]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.9999 0.     0.     0.     0.     0.     0.\n",
            " 0.    ], argmax=3\n",
            "         |->> Action Probabilities (RAW): [2.4298529e-07 4.0223763e-06 1.5560610e-05 9.9993479e-01 8.6014616e-06\n",
            " 2.4161020e-05 2.0642524e-06 4.5602340e-07 9.9551436e-08 5.1001111e-06\n",
            " 4.7827389e-06], argmax=3\n",
            "   \u001b[33m|->> #1/t=28-th Action selection: 2/RIGHT (P(a|s) = 0.05400000140070915)\u001b[0m\n",
            "      |->> Bounding box moves to: [314   3  52  59]\n",
            "         |->> Action Probabilities (Rounded): [7.600e-03 1.000e-04 5.420e-02 1.262e-01 1.378e-01 6.452e-01 1.000e-04\n",
            " 0.000e+00 5.000e-04 9.000e-04 2.730e-02], argmax=5\n",
            "         |->> Action Probabilities (RAW): [7.6411935e-03 6.9801812e-05 5.4247834e-02 1.2619893e-01 1.3784410e-01\n",
            " 6.4524984e-01 7.4473188e-05 2.8247649e-05 4.6974828e-04 8.9983200e-04\n",
            " 2.7276011e-02], argmax=5\n",
            "   \u001b[33m|->> #2/t=29-th Action selection: 5/2X UP (P(a|s) = 0.7609999775886536)\u001b[0m\n",
            "      |->> Bounding box moves to: [314   1  52  59]\n",
            "         |->> Action Probabilities (Rounded): [3.000e-04 4.000e-04 1.340e-02 1.960e-01 5.900e-03 7.612e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 9.000e-04 2.180e-02], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.1589635e-04 3.5950434e-04 1.3419393e-02 1.9600278e-01 5.9017832e-03\n",
            " 7.6118797e-01 2.3896169e-05 1.8158331e-05 1.3560578e-05 9.3947287e-04\n",
            " 2.1817584e-02], argmax=5\n",
            "   \u001b[33m|->> #3/t=30-th Action selection: 10/SCALE UP (P(a|s) = 0.8510000109672546)\u001b[0m\n",
            "      |->> Bounding box moves to: [313   0  54  61]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 1.000e-04 1.890e-02 0.000e+00 1.299e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 8.511e-01], argmax=10\n",
            "         |->> Action Probabilities (RAW): [4.06436084e-05 1.03734983e-05 6.17198893e-05 1.88565385e-02\n",
            " 3.60019067e-06 1.29908755e-01 1.18415066e-07 1.66454353e-08\n",
            " 1.71907127e-10 1.52075010e-08 8.51118267e-01], argmax=10\n",
            "   \u001b[33m|->> #4/t=31-th Action selection: 10/SCALE UP (P(a|s) = 0.7829999923706055)\u001b[0m\n",
            "      |->> Bounding box moves to: [312   0  56  63]\n",
            "         |->> Action Probabilities (Rounded): [2.000e-04 1.000e-04 1.400e-03 2.143e-01 0.000e+00 5.000e-04 0.000e+00\n",
            " 1.000e-04 0.000e+00 0.000e+00 7.834e-01], argmax=10\n",
            "         |->> Action Probabilities (RAW): [1.7848131e-04 7.0307709e-05 1.3637495e-03 2.1432520e-01 1.1259638e-06\n",
            " 5.4437411e-04 1.0507931e-05 7.8245721e-05 1.0007009e-09 4.0419373e-08\n",
            " 7.8342795e-01], argmax=10\n",
            "   \u001b[33m|->> #5/t=32-th Action selection: 10/SCALE UP (P(a|s) = 0.8769999742507935)\u001b[0m\n",
            "      |->> Bounding box moves to: [311   0  58  65]\n",
            "         |->> Action Probabilities (Rounded): [8.000e-04 0.000e+00 1.680e-02 9.560e-02 0.000e+00 1.800e-03 1.800e-03\n",
            " 5.900e-03 0.000e+00 0.000e+00 8.773e-01], argmax=10\n",
            "         |->> Action Probabilities (RAW): [7.6550961e-04 9.6640533e-06 1.6767625e-02 9.5564134e-02 3.9288934e-05\n",
            " 1.8297321e-03 1.8320307e-03 5.8811684e-03 2.5897334e-06 4.9880728e-06\n",
            " 8.7730336e-01], argmax=10\n",
            "   \u001b[33m|->> #6/t=33-th Action selection: 10/SCALE UP (P(a|s) = 0.9409999847412109)\u001b[0m\n",
            "      |->> Bounding box moves to: [310   0  60  67]\n",
            "         |->> Action Probabilities (Rounded): [1.00e-04 0.00e+00 1.28e-02 1.59e-02 2.00e-03 2.67e-02 4.00e-04 1.10e-03\n",
            " 0.00e+00 0.00e+00 9.41e-01], argmax=10\n",
            "         |->> Action Probabilities (RAW): [5.8819565e-05 4.1690233e-05 1.2764829e-02 1.5882671e-02 1.9814286e-03\n",
            " 2.6733663e-02 3.7809630e-04 1.0724218e-03 6.2647478e-06 4.2727181e-05\n",
            " 9.4103730e-01], argmax=10\n",
            "   \u001b[33m|->> #7/t=34-th Action selection: 2/RIGHT (P(a|s) = 0.257999986410141)\u001b[0m\n",
            "      |->> Bounding box moves to: [311   0  60  67]\n",
            "         |->> Action Probabilities (Rounded): [0.0005 0.     0.2585 0.064  0.1848 0.1171 0.0046 0.0021 0.     0.\n",
            " 0.3685], argmax=10\n",
            "         |->> Action Probabilities (RAW): [4.6375717e-04 2.8154380e-05 2.5846067e-01 6.3953556e-02 1.8477070e-01\n",
            " 1.1710476e-01 4.5631635e-03 2.0872098e-03 3.4354263e-05 1.3915288e-05\n",
            " 3.6851969e-01], argmax=10\n",
            "|->> Revisiting bbox: [311   0  60  67]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [311,   3,  52,  59] -> [311,   0,  60,  67] (Target was [307,   3,  69,  53])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X RIGHT:bbox transition: [311,   3,  52,  59] -> [313,   3,  52,  59] w/ P(a|s)=0.9999347925186157 and iou=0.6943814562862182 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for RIGHT:bbox transition: [313,   3,  52,  59] -> [314,   3,  52,  59] w/ P(a|s)=0.05424783378839493 and iou=0.6943814562862182 and reward=0.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X UP:bbox transition: [314,   3,  52,  59] -> [314,   1,  52,  59] w/ P(a|s)=0.7611879706382751 and iou=0.6943814562862182 and reward=0.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.006) for SCALE UP:bbox transition: [314,   1,  52,  59] -> [313,   0,  54,  61] w/ P(a|s)=0.851118266582489 and iou=0.6999266324284666 and reward=0.005545176142248476 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.004) for SCALE UP:bbox transition: [313,   0,  54,  61] -> [312,   0,  56,  63] w/ P(a|s)=0.7834279537200928 and iou=0.7038178800094854 and reward=0.003891247581018775 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.002) for SCALE UP:bbox transition: [312,   0,  56,  63] -> [311,   0,  58,  65] w/ P(a|s)=0.8773033618927002 and iou=0.706179646220997 and reward=0.002361766211511629 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.001) for SCALE UP:bbox transition: [311,   0,  58,  65] -> [310,   0,  60,  67] w/ P(a|s)=0.9410372972488403 and iou=0.7071380920613742 and reward=0.0009584458403771867 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (0.0) for RIGHT:bbox transition: [310,   0,  60,  67] -> [311,   0,  60,  67] w/ P(a|s)=0.25846067070961 and iou=0.7071380920613742 and reward=0.0 and discount=0.9320653479069899\n",
            "   |->> Assigned losses: [0.0000000e+00 0.0000000e+00 0.0000000e+00 8.6735573e-04 9.1233646e-04\n",
            " 2.9400899e-04 5.4838540e-05 0.0000000e+00]\n",
            "\u001b[92m>> Total frame loss: 0.0021285396069288254\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 73 with src: [311,   0,  60,  67] and target: [301,   3,  64,  58]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0073.jpg\n",
            "|->> Beginning tracking for bbox:[311   0  60  67]\n",
            "|->> Revisiting bbox: [311   0  60  67]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=35-th Action selection: 8/STOP (P(a|s) = 0.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [311   0  60  67]\n",
            "         |->> Action Probabilities (Rounded): [9.900e-03 2.500e-03 5.000e-04 2.000e-04 3.640e-02 9.338e-01 5.000e-04\n",
            " 1.000e-03 3.000e-04 1.000e-04 1.490e-02], argmax=5\n",
            "         |->> Action Probabilities (RAW): [9.9468185e-03 2.4512964e-03 5.4880203e-04 1.7794545e-04 3.6433585e-02\n",
            " 9.3375796e-01 5.3600088e-04 9.6434582e-04 2.5612957e-04 5.7570014e-05\n",
            " 1.4869481e-02], argmax=5\n",
            "         |->> Hit a STOP on the 35-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [311,   0,  60,  67] -> [311,   0,  60,  67] (Target was [301,   3,  64,  58])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [311,   0,  60,  67] -> [311,   0,  60,  67] w/ P(a|s)=0.0002561295696068555 and iou=0.6808695652173913 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-8.269827]\n",
            "\u001b[31m>> Total frame loss: -8.269826889038086\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 74 with src: [311,   0,  60,  67] and target: [288,   6,  64,  72]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0074.jpg\n",
            "|->> Beginning tracking for bbox:[311   0  60  67]\n",
            "|->> Revisiting bbox: [311   0  60  67]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=35-th Action selection: 8/STOP (P(a|s) = 0.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [311   0  60  67]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [8.47298620e-11 1.42491805e-08 1.14219767e-14 2.09166495e-12\n",
            " 2.57972409e-13 1.00000000e+00 3.40293088e-13 3.07180272e-08\n",
            " 9.21646086e-19 2.30928154e-16 1.00630984e-12], argmax=5\n",
            "         |->> Hit a STOP on the 35-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [311,   0,  60,  67] -> [311,   0,  60,  67] (Target was [288,   6,  64,  72])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [311,   0,  60,  67] -> [311,   0,  60,  67] w/ P(a|s)=9.216460860726554e-19 and iou=0.40819324302268645 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-11.512925]\n",
            "\u001b[31m>> Total frame loss: -11.512925148010254\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 75 with src: [311,   0,  60,  67] and target: [276,  22,  70,  88]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0075.jpg\n",
            "|->> Beginning tracking for bbox:[311   0  60  67]\n",
            "|->> Revisiting bbox: [311   0  60  67]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=35-th Action selection: 8/STOP (P(a|s) = 0.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [311   0  60  67]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 9.300e-03 0.000e+00 9.906e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 1.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.5584999e-09 2.5857196e-07 2.2368682e-09 9.2705283e-03 6.4028907e-11\n",
            " 9.9063790e-01 3.7246394e-13 1.2759842e-08 2.9845091e-13 4.1338458e-06\n",
            " 8.7167566e-05], argmax=5\n",
            "         |->> Hit a STOP on the 35-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [311,   0,  60,  67] -> [311,   0,  60,  67] (Target was [276,  22,  70,  88])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [311,   0,  60,  67] -> [311,   0,  60,  67] w/ P(a|s)=2.9845090700024446e-13 and iou=0.1830331202789076 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-11.512925]\n",
            "\u001b[31m>> Total frame loss: -11.512925148010254\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 76 with src: [311,   0,  60,  67] and target: [288,  59,  67,  92]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0076.jpg\n",
            "|->> Beginning tracking for bbox:[311   0  60  67]\n",
            "|->> Revisiting bbox: [311   0  60  67]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=35-th Action selection: 8/STOP (P(a|s) = 0.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [311   0  60  67]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 2.000e-04 2.500e-03 0.000e+00 1.000e-04 9.915e-01 0.000e+00\n",
            " 5.700e-03 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [8.04803506e-07 2.02661104e-04 2.46767025e-03 2.41135949e-05\n",
            " 8.55586259e-05 9.91540134e-01 4.98774675e-08 5.65086724e-03\n",
            " 4.74404305e-06 1.03935136e-07 2.32951261e-05], argmax=5\n",
            "         |->> Hit a STOP on the 35-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [311,   0,  60,  67] -> [311,   0,  60,  67] (Target was [288,  59,  67,  92])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [311,   0,  60,  67] -> [311,   0,  60,  67] w/ P(a|s)=4.744043053506175e-06 and iou=0.03580146460537022 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-11.512925]\n",
            "\u001b[31m>> Total frame loss: -11.512925148010254\u001b[0m\n",
            "Final bounding box: [311   0  60  67] reached in 35 timesteps (originating from [321   7  54  61]). Target was [288  59  67  92]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 77 in t=35 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[31m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 253.1778564453125\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.649436891078949\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 119.7677230834961\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.7486085295677185\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 141.49554443359375\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.6547691226005554\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 82.18111419677734\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.4582655429840088\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 35.06882858276367\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.4580167531967163\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 97.0901107788086\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 1.2575161457061768\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/Matrix\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Starting bounding box for adnet_datasets/OTB/Matrix: frames 25:35 is [336  32  37  46].\n",
            "\u001b[34m>> Attempting to reach frame 26 with src: [336,  32,  37,  46] and target: [340,  33,  36,  46]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0026.jpg\n",
            "|->> Beginning tracking for bbox:[336  32  37  46]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 5/2X UP (P(a|s) = 0.6740000247955322)\u001b[0m\n",
            "      |->> Bounding box moves to: [336  30  37  46]\n",
            "         |->> Action Probabilities (Rounded): [1.000e-03 1.000e-04 3.570e-02 0.000e+00 0.000e+00 6.743e-01 0.000e+00\n",
            " 2.890e-01 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [9.67067375e-04 6.18703198e-05 3.57014239e-02 1.44653151e-10\n",
            " 1.09940475e-08 6.74294651e-01 6.85203929e-07 2.88971096e-01\n",
            " 2.91775245e-06 6.81364085e-08 1.26080153e-07], argmax=5\n",
            "             |->> IOU declining: [336  30  37  46]:0.7318205260443528 -> [336  28  37  46]:0.6748129675810474.\n",
            "             |->> Overriding with STOP\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 8/STOP (P(a|s) = 0.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [336  30  37  46]\n",
            "         |->> Action Probabilities (Rounded): [0.0023 0.0109 0.     0.     0.     0.9866 0.     0.     0.     0.\n",
            " 0.    ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.34084879e-03 1.09053785e-02 1.10828648e-06 1.97334842e-08\n",
            " 2.82682740e-05 9.86621261e-01 2.92726363e-05 1.40673023e-06\n",
            " 2.11273618e-05 4.06909248e-06 4.72002939e-05], argmax=5\n",
            "         |->> Hit a STOP on the 2-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [336,  32,  37,  46] -> [336,  30,  37,  46] (Target was [340,  33,  36,  46])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.061) for 2X UP:bbox transition: [336,  32,  37,  46] -> [336,  30,  37,  46] w/ P(a|s)=0.674294650554657 and iou=0.7318205260443528 and reward=-0.06102517603786828 and discount=1.0\n",
            "   |->> t=2 Stop-Reward (1.0) for STOP:bbox transition: [336,  30,  37,  46] -> [336,  30,  37,  46] w/ P(a|s)=2.1127361833350733e-05 and iou=0.7318205260443528 and reward=1.0 and discount=0.99\n",
            "   |->> Assigned losses: [-0.0240493 10.657292 ]\n",
            "\u001b[92m>> Total frame loss: 10.6332426071167\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 27 with src: [336,  30,  37,  46] and target: [341,  30,  36,  42]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0027.jpg\n",
            "|->> Beginning tracking for bbox:[336  30  37  46]\n",
            "   \u001b[33m|->> #0/t=2-th Action selection: 2/RIGHT (P(a|s) = 0.9739999771118164)\u001b[0m\n",
            "      |->> Bounding box moves to: [337  30  37  46]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 9.741e-01 1.380e-02 4.000e-04 1.700e-03 4.000e-04\n",
            " 1.400e-03 2.000e-04 0.000e+00 8.000e-03], argmax=2\n",
            "         |->> Action Probabilities (RAW): [5.3809772e-06 3.7527429e-06 9.7406685e-01 1.3776603e-02 4.0093536e-04\n",
            " 1.7213339e-03 4.4349799e-04 1.4216237e-03 1.9107055e-04 1.7871213e-05\n",
            " 7.9511404e-03], argmax=2\n",
            "   \u001b[33m|->> #1/t=3-th Action selection: 5/2X UP (P(a|s) = 0.9940000176429749)\u001b[0m\n",
            "      |->> Bounding box moves to: [337  28  37  46]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 2.700e-03 1.000e-04 2.800e-03 9.942e-01 0.000e+00\n",
            " 0.000e+00 1.000e-04 0.000e+00 2.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.5947911e-06 1.5126671e-05 2.7086292e-03 7.2037350e-05 2.7569295e-03\n",
            " 9.9421036e-01 1.0442681e-06 2.1868652e-06 5.0404884e-05 5.9138847e-06\n",
            " 1.7586877e-04], argmax=5\n",
            "   \u001b[33m|->> #2/t=4-th Action selection: 10/SCALE UP (P(a|s) = 0.6809999942779541)\u001b[0m\n",
            "      |->> Bounding box moves to: [336  27  39  48]\n",
            "         |->> Action Probabilities (Rounded): [0.0009 0.0239 0.0112 0.2602 0.     0.0015 0.0043 0.0174 0.     0.\n",
            " 0.6806], argmax=10\n",
            "         |->> Action Probabilities (RAW): [8.5184170e-04 2.3915693e-02 1.1192742e-02 2.6019466e-01 2.1379921e-05\n",
            " 1.5197578e-03 4.3191845e-03 1.7400663e-02 1.4826828e-06 2.0400164e-05\n",
            " 6.8056220e-01], argmax=10\n",
            "   \u001b[33m|->> #3/t=5-th Action selection: 3/2X RIGHT (P(a|s) = 0.9959999918937683)\u001b[0m\n",
            "      |->> Bounding box moves to: [338  27  39  48]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 4.000e-04 2.000e-04 9.957e-01 0.000e+00 4.000e-04 1.000e-04\n",
            " 2.000e-04 0.000e+00 1.000e-04 3.000e-03], argmax=3\n",
            "         |->> Action Probabilities (RAW): [1.6991276e-05 3.8134062e-04 2.3900867e-04 9.9566597e-01 1.2754564e-05\n",
            " 3.5440939e-04 9.3609997e-05 2.1268660e-04 1.5182270e-07 5.5465422e-05\n",
            " 2.9676501e-03], argmax=3\n",
            "|->> Revisiting bbox: [336  27  39  48]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [336,  30,  37,  46] -> [338,  27,  39,  48] (Target was [341,  30,  36,  42])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.039) for RIGHT:bbox transition: [336,  30,  37,  46] -> [337,  30,  37,  46] w/ P(a|s)=0.9740668535232544 and iou=0.7582056892778993 and reward=0.03948911173779235 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for 2X UP:bbox transition: [337,  30,  37,  46] -> [337,  28,  37,  46] w/ P(a|s)=0.9942103624343872 and iou=0.7582056892778993 and reward=0.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-0.028) for SCALE UP:bbox transition: [337,  28,  37,  46] -> [336,  27,  39,  48] w/ P(a|s)=0.6805621981620789 and iou=0.7300613496932515 and reward=-0.028144339584647793 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.078) for 2X RIGHT:bbox transition: [336,  27,  39,  48] -> [338,  27,  39,  48] w/ P(a|s)=0.995665967464447 and iou=0.8076923076923077 and reward=0.07763095799905617 and discount=0.970299\n",
            "   |->> Assigned losses: [ 0.00103759  0.         -0.01061542  0.00032717]\n",
            "\u001b[31m>> Total frame loss: -0.009250658564269543\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 28 with src: [338,  27,  39,  48] and target: [336,  24,  45,  47]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0028.jpg\n",
            "|->> Beginning tracking for bbox:[338  27  39  48]\n",
            "   \u001b[33m|->> #0/t=6-th Action selection: 5/2X UP (P(a|s) = 0.9990000128746033)\u001b[0m\n",
            "      |->> Bounding box moves to: [338  25  39  48]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 1.000e-04 0.000e+00 0.000e+00 6.000e-04 9.988e-01 0.000e+00\n",
            " 5.000e-04 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.0490553e-05 7.1928989e-05 2.3790547e-07 8.4855118e-09 5.9082930e-04\n",
            " 9.9883908e-01 1.3320074e-07 4.6964691e-04 2.5153490e-10 1.7419039e-05\n",
            " 3.7510617e-07], argmax=5\n",
            "   \u001b[33m|->> #1/t=7-th Action selection: 5/2X UP (P(a|s) = 0.9589999914169312)\u001b[0m\n",
            "      |->> Bounding box moves to: [338  23  39  48]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 1.100e-03 0.000e+00 0.000e+00 1.000e-04 9.586e-01 0.000e+00\n",
            " 4.020e-02 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.5938203e-05 1.0959590e-03 3.2390074e-07 1.6229709e-05 7.8136167e-05\n",
            " 9.5856494e-01 1.1511431e-05 4.0201884e-02 1.0653060e-10 1.3453913e-05\n",
            " 1.5776413e-06], argmax=5\n",
            "   \u001b[33m|->> #2/t=8-th Action selection: 5/2X UP (P(a|s) = 0.5849999785423279)\u001b[0m\n",
            "      |->> Bounding box moves to: [338  21  39  48]\n",
            "         |->> Action Probabilities (Rounded): [2.000e-04 4.089e-01 0.000e+00 0.000e+00 1.800e-03 5.853e-01 1.000e-03\n",
            " 1.000e-04 0.000e+00 0.000e+00 2.800e-03], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.5141652e-04 4.0893072e-01 1.2975795e-06 1.2433096e-06 1.7504116e-03\n",
            " 5.8528572e-01 9.6647645e-04 1.0384370e-04 7.5772982e-06 1.9143004e-05\n",
            " 2.7821928e-03], argmax=5\n",
            "   \u001b[33m|->> #3/t=9-th Action selection: 6/DOWN (P(a|s) = 0.006000000052154064)\u001b[0m\n",
            "      |->> Bounding box moves to: [338  22  39  48]\n",
            "         |->> Action Probabilities (Rounded): [7.910e-02 4.970e-01 0.000e+00 0.000e+00 3.010e-02 1.449e-01 5.600e-03\n",
            " 2.381e-01 0.000e+00 5.200e-03 1.000e-04], argmax=1\n",
            "         |->> Action Probabilities (RAW): [7.9050757e-02 4.9702117e-01 2.4740964e-05 3.6882234e-06 3.0071216e-02\n",
            " 1.4489545e-01 5.5505969e-03 2.3808263e-01 2.6765206e-06 5.2081677e-03\n",
            " 8.8952671e-05], argmax=1\n",
            "   \u001b[33m|->> #4/t=10-th Action selection: 1/2X LEFT (P(a|s) = 0.25600001215934753)\u001b[0m\n",
            "      |->> Bounding box moves to: [336  22  39  48]\n",
            "         |->> Action Probabilities (Rounded): [1.726e-01 2.561e-01 0.000e+00 0.000e+00 3.080e-02 3.347e-01 1.590e-02\n",
            " 1.688e-01 1.000e-04 3.900e-03 1.720e-02], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.7262113e-01 2.5605971e-01 4.3205848e-05 1.2771362e-06 3.0769501e-02\n",
            " 3.3467355e-01 1.5916431e-02 1.6878881e-01 9.8018689e-05 3.8750106e-03\n",
            " 1.7153358e-02], argmax=5\n",
            "   \u001b[33m|->> #5/t=11-th Action selection: 5/2X UP (P(a|s) = 0.3580000102519989)\u001b[0m\n",
            "      |->> Bounding box moves to: [336  20  39  48]\n",
            "         |->> Action Probabilities (Rounded): [0.3646 0.0102 0.0007 0.003  0.0466 0.3577 0.0407 0.0487 0.     0.0107\n",
            " 0.1171], argmax=0\n",
            "         |->> Action Probabilities (RAW): [3.64641994e-01 1.02290390e-02 7.42172822e-04 2.96969083e-03\n",
            " 4.66344431e-02 3.57667297e-01 4.06667180e-02 4.86500040e-02\n",
            " 6.18561080e-06 1.06561305e-02 1.17136315e-01], argmax=0\n",
            "|->> Revisiting bbox: [336  22  39  48]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [338,  27,  39,  48] -> [336,  20,  39,  48] (Target was [336,  24,  45,  47])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.062) for 2X UP:bbox transition: [338,  27,  39,  48] -> [338,  25,  39,  48] w/ P(a|s)=0.9988390803337097 and iou=0.8180574555403557 and reward=0.06244318869755516 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.033) for 2X UP:bbox transition: [338,  25,  39,  48] -> [338,  23,  39,  48] w/ P(a|s)=0.9585649371147156 and iou=0.850974930362117 and reward=0.03291747482176133 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-0.065) for 2X UP:bbox transition: [338,  23,  39,  48] -> [338,  21,  39,  48] w/ P(a|s)=0.5852857232093811 and iou=0.7862903225806451 and reward=-0.06468460778147189 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.032) for DOWN:bbox transition: [338,  21,  39,  48] -> [338,  22,  39,  48] w/ P(a|s)=0.005550596863031387 and iou=0.8180574555403557 and reward=0.031767132959710564 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.0) for 2X LEFT:bbox transition: [338,  22,  39,  48] -> [336,  22,  39,  48] w/ P(a|s)=0.2560597062110901 and iou=0.8180574555403557 and reward=0.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-0.062) for 2X UP:bbox transition: [336,  22,  39,  48] -> [336,  20,  39,  48] w/ P(a|s)=0.35766729712486267 and iou=0.7556142668428005 and reward=-0.06244318869755516 and discount=0.9509900498999999\n",
            "   |->> Assigned losses: [ 7.2533636e-05  1.3790707e-03 -3.3959135e-02  1.6009325e-01\n",
            "  0.0000000e+00 -6.1054595e-02]\n",
            "\u001b[92m>> Total frame loss: 0.06653112918138504\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 29 with src: [336,  20,  39,  48] and target: [338,  19,  44,  42]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0029.jpg\n",
            "|->> Beginning tracking for bbox:[336  20  39  48]\n",
            "   \u001b[33m|->> #0/t=12-th Action selection: 5/2X UP (P(a|s) = 0.8820000290870667)\u001b[0m\n",
            "      |->> Bounding box moves to: [336  18  39  48]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 4.000e-04 5.000e-04 9.000e-04 4.000e-03 8.816e-01 0.000e+00\n",
            " 1.350e-02 0.000e+00 0.000e+00 9.920e-02], argmax=5\n",
            "         |->> Action Probabilities (RAW): [4.0303384e-08 4.0720220e-04 4.9559359e-04 8.7100745e-04 3.9641932e-03\n",
            " 8.8159364e-01 3.7378306e-06 1.3477793e-02 1.2798399e-11 3.0895753e-06\n",
            " 9.9183641e-02], argmax=5\n",
            "|->> Revisiting bbox: [336  20  39  48]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [336,  20,  39,  48] -> [336,  18,  39,  48] (Target was [338,  19,  44,  42])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.029) for 2X UP:bbox transition: [336,  20,  39,  48] -> [336,  18,  39,  48] w/ P(a|s)=0.881593644618988 and iou=0.7174515235457064 and reward=0.02884507778991885 and discount=1.0\n",
            "   |->> Assigned losses: [0.00363517]\n",
            "\u001b[92m>> Total frame loss: 0.0036351734306663275\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 30 with src: [336,  18,  39,  48] and target: [347,  18,  42,  44]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0030.jpg\n",
            "|->> Beginning tracking for bbox:[336  18  39  48]\n",
            "   \u001b[33m|->> #0/t=13-th Action selection: 2/RIGHT (P(a|s) = 0.1340000033378601)\u001b[0m\n",
            "      |->> Bounding box moves to: [337  18  39  48]\n",
            "         |->> Action Probabilities (Rounded): [0.0005 0.0536 0.1343 0.1653 0.1115 0.151  0.0069 0.073  0.0134 0.0064\n",
            " 0.2841], argmax=10\n",
            "         |->> Action Probabilities (RAW): [0.0004647  0.05358037 0.13434671 0.16532494 0.11151982 0.15104158\n",
            " 0.00689106 0.07304448 0.01336989 0.00636029 0.2840562 ], argmax=10\n",
            "   \u001b[33m|->> #1/t=14-th Action selection: 2/RIGHT (P(a|s) = 0.492000013589859)\u001b[0m\n",
            "      |->> Bounding box moves to: [338  18  39  48]\n",
            "         |->> Action Probabilities (Rounded): [0.0007 0.     0.4923 0.3175 0.0017 0.1609 0.0041 0.001  0.0013 0.0011\n",
            " 0.0195], argmax=2\n",
            "         |->> Action Probabilities (RAW): [6.8538706e-04 1.6775104e-05 4.9231058e-01 3.1746820e-01 1.6704041e-03\n",
            " 1.6092609e-01 4.0896446e-03 9.8704384e-04 1.2739889e-03 1.1044135e-03\n",
            " 1.9467480e-02], argmax=2\n",
            "   \u001b[33m|->> #2/t=15-th Action selection: 10/SCALE UP (P(a|s) = 0.2849999964237213)\u001b[0m\n",
            "      |->> Bounding box moves to: [337  17  41  50]\n",
            "         |->> Action Probabilities (Rounded): [2.300e-03 2.000e-04 4.490e-02 2.500e-03 9.090e-02 5.403e-01 3.900e-03\n",
            " 6.000e-04 2.030e-02 9.000e-03 2.849e-01], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.3165431e-03 1.9829444e-04 4.4933762e-02 2.4919927e-03 9.0945788e-02\n",
            " 5.4033673e-01 3.8542834e-03 6.3104957e-04 2.0342952e-02 9.0460647e-03\n",
            " 2.8490245e-01], argmax=5\n",
            "   \u001b[33m|->> #3/t=16-th Action selection: 5/2X UP (P(a|s) = 0.9419999718666077)\u001b[0m\n",
            "      |->> Bounding box moves to: [337  15  41  50]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 1.000e-04 7.100e-03 1.300e-02 1.090e-02 9.417e-01 1.000e-04\n",
            " 5.400e-03 1.100e-03 2.400e-03 1.810e-02], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.46240195e-05 7.08523221e-05 7.14976341e-03 1.29674515e-02\n",
            " 1.09432237e-02 9.41729784e-01 7.18610245e-05 5.41821588e-03\n",
            " 1.12628366e-03 2.39179772e-03 1.80960130e-02], argmax=5\n",
            "   \u001b[33m|->> #4/t=17-th Action selection: 5/2X UP (P(a|s) = 0.8090000152587891)\u001b[0m\n",
            "      |->> Bounding box moves to: [337  13  41  50]\n",
            "         |->> Action Probabilities (Rounded): [7.000e-04 4.000e-04 5.200e-02 1.390e-02 2.610e-02 8.088e-01 6.000e-04\n",
            " 6.000e-04 4.000e-04 5.000e-04 9.610e-02], argmax=5\n",
            "         |->> Action Probabilities (RAW): [7.4683677e-04 4.0532500e-04 5.1965892e-02 1.3876478e-02 2.6138371e-02\n",
            " 8.0876863e-01 5.5052666e-04 5.6774961e-04 3.8009553e-04 4.5120800e-04\n",
            " 9.6148938e-02], argmax=5\n",
            "   \u001b[33m|->> #5/t=18-th Action selection: 5/2X UP (P(a|s) = 0.4189999997615814)\u001b[0m\n",
            "      |->> Bounding box moves to: [337  11  41  50]\n",
            "         |->> Action Probabilities (Rounded): [0.0052 0.0427 0.0031 0.0304 0.0028 0.4189 0.0098 0.4761 0.0005 0.0032\n",
            " 0.0073], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.0051674  0.04267506 0.00310988 0.03035747 0.00283756 0.41892377\n",
            " 0.00980246 0.47612715 0.00050841 0.00322373 0.0072671 ], argmax=7\n",
            "   \u001b[33m|->> #6/t=19-th Action selection: 1/2X LEFT (P(a|s) = 0.5540000200271606)\u001b[0m\n",
            "      |->> Bounding box moves to: [335  11  41  50]\n",
            "         |->> Action Probabilities (Rounded): [2.814e-01 5.543e-01 2.000e-04 0.000e+00 4.800e-02 4.870e-02 2.000e-04\n",
            " 6.020e-02 0.000e+00 6.800e-03 1.000e-04], argmax=1\n",
            "         |->> Action Probabilities (RAW): [2.8136694e-01 5.5434275e-01 2.4886031e-04 2.3597688e-06 4.7991641e-02\n",
            " 4.8737571e-02 1.7538121e-04 6.0236666e-02 1.5305959e-07 6.8170982e-03\n",
            " 8.0517442e-05], argmax=1\n",
            "   \u001b[33m|->> #7/t=20-th Action selection: 5/2X UP (P(a|s) = 0.902999997138977)\u001b[0m\n",
            "      |->> Bounding box moves to: [335   9  41  50]\n",
            "         |->> Action Probabilities (Rounded): [4.000e-04 6.180e-02 1.500e-03 1.320e-02 7.000e-04 9.033e-01 0.000e+00\n",
            " 1.870e-02 0.000e+00 2.000e-04 2.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [4.2176296e-04 6.1822299e-02 1.5370864e-03 1.3167141e-02 6.6233700e-04\n",
            " 9.0332776e-01 4.2857509e-06 1.8730590e-02 2.0847736e-08 1.5118661e-04\n",
            " 1.7555055e-04], argmax=5\n",
            "   \u001b[33m|->> #8/t=21-th Action selection: 1/2X LEFT (P(a|s) = 0.7770000100135803)\u001b[0m\n",
            "      |->> Bounding box moves to: [333   9  41  50]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.7768 0.     0.     0.     0.1489 0.     0.0278 0.     0.0465\n",
            " 0.    ], argmax=1\n",
            "         |->> Action Probabilities (RAW): [4.8802285e-06 7.7677101e-01 1.7322061e-06 4.0164825e-05 2.0517004e-05\n",
            " 1.4890595e-01 5.1320296e-08 2.7789861e-02 9.2848162e-10 4.6465755e-02\n",
            " 1.0299049e-07], argmax=1\n",
            "   \u001b[33m|->> #9/t=22-th Action selection: 5/2X UP (P(a|s) = 0.9100000262260437)\u001b[0m\n",
            "      |->> Bounding box moves to: [333   7  41  50]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 1.870e-02 0.000e+00 1.000e-04 1.000e-04 9.099e-01 0.000e+00\n",
            " 6.950e-02 0.000e+00 1.300e-03 3.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [4.5951205e-07 1.8737493e-02 6.3864413e-06 6.3584892e-05 1.0246116e-04\n",
            " 9.0991569e-01 5.6773420e-08 6.9540560e-02 6.6228383e-09 1.3496039e-03\n",
            " 2.8378094e-04], argmax=5\n",
            "   \u001b[33m|->> #10/t=23-th Action selection: 10/SCALE UP (P(a|s) = 0.18799999356269836)\u001b[0m\n",
            "      |->> Bounding box moves to: [332   6  43  52]\n",
            "         |->> Action Probabilities (Rounded): [0.1272 0.0358 0.0247 0.0026 0.2258 0.3357 0.0022 0.0004 0.0179 0.0399\n",
            " 0.1879], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.1272026  0.03576576 0.02465251 0.00255734 0.22576411 0.33572435\n",
            " 0.00220493 0.00043232 0.01792849 0.03988188 0.18788572], argmax=5\n",
            "   \u001b[33m|->> #11/t=24-th Action selection: 5/2X UP (P(a|s) = 0.675000011920929)\u001b[0m\n",
            "      |->> Bounding box moves to: [332   4  43  52]\n",
            "         |->> Action Probabilities (Rounded): [7.000e-04 0.000e+00 3.390e-02 5.600e-03 2.080e-02 6.755e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 1.000e-04 2.634e-01], argmax=5\n",
            "         |->> Action Probabilities (RAW): [7.1908504e-04 4.1729945e-05 3.3911634e-02 5.6208298e-03 2.0752167e-02\n",
            " 6.7549515e-01 6.4837595e-06 1.2470896e-06 2.8955204e-05 5.5976907e-05\n",
            " 2.6336679e-01], argmax=5\n",
            "   \u001b[33m|->> #12/t=25-th Action selection: 1/2X LEFT (P(a|s) = 0.3310000002384186)\u001b[0m\n",
            "      |->> Bounding box moves to: [330   4  43  52]\n",
            "         |->> Action Probabilities (Rounded): [4.070e-02 3.307e-01 1.900e-03 1.200e-03 2.500e-03 1.233e-01 1.000e-04\n",
            " 0.000e+00 0.000e+00 3.600e-03 4.962e-01], argmax=10\n",
            "         |->> Action Probabilities (RAW): [4.0652033e-02 3.3068070e-01 1.8567612e-03 1.1707682e-03 2.4502855e-03\n",
            " 1.2333725e-01 8.1666178e-05 1.6173864e-06 1.7893524e-05 3.5725229e-03\n",
            " 4.9617863e-01], argmax=10\n",
            "   \u001b[33m|->> #13/t=26-th Action selection: 1/2X LEFT (P(a|s) = 0.061000000685453415)\u001b[0m\n",
            "      |->> Bounding box moves to: [328   4  43  52]\n",
            "         |->> Action Probabilities (Rounded): [0.1037 0.061  0.0042 0.0021 0.0835 0.1178 0.3623 0.02   0.0168 0.1995\n",
            " 0.0292], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.10366105 0.06102591 0.00424908 0.00205736 0.08348364 0.11784993\n",
            " 0.36225185 0.02001932 0.01675413 0.19949277 0.02915503], argmax=6\n",
            "   \u001b[33m|->> #14/t=27-th Action selection: 5/2X UP (P(a|s) = 0.9729999899864197)\u001b[0m\n",
            "      |->> Bounding box moves to: [328   2  43  52]\n",
            "         |->> Action Probabilities (Rounded): [4.000e-04 7.000e-04 6.000e-04 1.180e-02 3.100e-03 9.731e-01 1.000e-04\n",
            " 1.000e-04 1.000e-04 2.000e-04 9.800e-03], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.8404789e-04 7.4421085e-04 5.9543457e-04 1.1810620e-02 3.0660955e-03\n",
            " 9.7309339e-01 7.4531701e-05 5.3119365e-05 1.2526991e-04 2.1696408e-04\n",
            " 9.8364688e-03], argmax=5\n",
            "   \u001b[33m|->> #15/t=28-th Action selection: 5/2X UP (P(a|s) = 0.8360000252723694)\u001b[0m\n",
            "      |->> Bounding box moves to: [328   0  43  52]\n",
            "         |->> Action Probabilities (Rounded): [0.00e+00 1.00e-04 4.00e-03 7.05e-02 7.80e-03 8.36e-01 0.00e+00 7.31e-02\n",
            " 0.00e+00 5.80e-03 2.70e-03], argmax=5\n",
            "         |->> Action Probabilities (RAW): [4.39788437e-06 5.53356804e-05 4.03640931e-03 7.04856440e-02\n",
            " 7.77892070e-03 8.35994244e-01 3.56004675e-05 7.30940402e-02\n",
            " 1.41656565e-05 5.77823445e-03 2.72298255e-03], argmax=5\n",
            "|->> Revisiting bbox: [328   0  43  52]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [336,  18,  39,  48] -> [328,   0,  43,  52] (Target was [347,  18,  42,  44])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.027) for RIGHT:bbox transition: [336,  18,  39,  48] -> [337,  18,  39,  48] w/ P(a|s)=0.13434670865535736 and iou=0.5220949263502455 and reward=0.026918077475647395 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.028) for RIGHT:bbox transition: [337,  18,  39,  48] -> [338,  18,  39,  48] w/ P(a|s)=0.4923105835914612 and iou=0.55 and reward=0.027905073649754586 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-0.012) for SCALE UP:bbox transition: [338,  18,  39,  48] -> [337,  17,  41,  50] w/ P(a|s)=0.2849024534225464 and iou=0.5382794001578532 and reward=-0.011720599842146795 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.0) for 2X UP:bbox transition: [337,  17,  41,  50] -> [337,  15,  41,  50] w/ P(a|s)=0.9417297840118408 and iou=0.5382794001578532 and reward=0.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.0) for 2X UP:bbox transition: [337,  15,  41,  50] -> [337,  13,  41,  50] w/ P(a|s)=0.808768630027771 and iou=0.5382794001578532 and reward=0.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-0.019) for 2X UP:bbox transition: [337,  13,  41,  50] -> [337,  11,  41,  50] w/ P(a|s)=0.4189237654209137 and iou=0.5196881091617934 and reward=-0.01859129099605983 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (-0.049) for 2X LEFT:bbox transition: [337,  11,  41,  50] -> [335,  11,  41,  50] w/ P(a|s)=0.5543427467346191 and iou=0.47038853262919655 and reward=-0.04929957653259687 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (-0.031) for 2X UP:bbox transition: [335,  11,  41,  50] -> [335,   9,  41,  50] w/ P(a|s)=0.9033277630805969 and iou=0.4389073458840901 and reward=-0.03148118674510647 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (-0.042) for 2X LEFT:bbox transition: [335,   9,  41,  50] -> [333,   9,  41,  50] w/ P(a|s)=0.7767710089683533 and iou=0.3966320315299176 and reward=-0.04227531435417248 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (-0.027) for 2X UP:bbox transition: [333,   9,  41,  50] -> [333,   7,  41,  50] w/ P(a|s)=0.9099156856536865 and iou=0.3701230228471002 and reward=-0.026509008682817414 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (0.008) for SCALE UP:bbox transition: [333,   7,  41,  50] -> [332,   6,  43,  52] w/ P(a|s)=0.18788571655750275 and iou=0.37786774628879893 and reward=0.007744723441698742 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (-0.026) for 2X UP:bbox transition: [332,   6,  43,  52] -> [332,   4,  43,  52] w/ P(a|s)=0.6754951477050781 and iou=0.352317880794702 and reward=-0.025549865494096935 and discount=0.8953382542587164\n",
            "   |->> t=13 Diff-Reward (-0.033) for 2X LEFT:bbox transition: [332,   4,  43,  52] -> [330,   4,  43,  52] w/ P(a|s)=0.3306806981563568 and iou=0.31912144702842377 and reward=-0.03319643376627823 and discount=0.8863848717161292\n",
            "   |->> t=14 Diff-Reward (-0.032) for 2X LEFT:bbox transition: [330,   4,  43,  52] -> [328,   4,  43,  52] w/ P(a|s)=0.06102591007947922 and iou=0.287515762925599 and reward=-0.03160568410282477 and discount=0.8775210229989678\n",
            "   |->> t=15 Diff-Reward (-0.019) for 2X UP:bbox transition: [328,   4,  43,  52] -> [328,   2,  43,  52] w/ P(a|s)=0.9730933904647827 and iou=0.2683229813664596 and reward=-0.019192781559139394 and discount=0.8687458127689782\n",
            "   |->> t=16 Diff-Reward (-0.019) for 2X UP:bbox transition: [328,   2,  43,  52] -> [328,   0,  43,  52] w/ P(a|s)=0.8359942436218262 and iou=0.24969400244798043 and reward=-0.018628978918479172 and discount=0.8600583546412884\n",
            "   |->> Assigned losses: [ 0.0540335   0.01957706 -0.01442363  0.          0.         -0.01538289\n",
            " -0.02738331 -0.00298325 -0.00985413 -0.00228611  0.01171045 -0.00897438\n",
            " -0.03256156 -0.07755876 -0.00045478 -0.00287008]\n",
            "\u001b[31m>> Total frame loss: -0.10941185802221298\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 31 with src: [328,   0,  43,  52] and target: [357,  22,  40,  43]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0031.jpg\n",
            "|->> Beginning tracking for bbox:[328   0  43  52]\n",
            "|->> Revisiting bbox: [328   0  43  52]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=29-th Action selection: 8/STOP (P(a|s) = 0.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [328   0  43  52]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.9201947e-17 2.2740691e-16 1.5363088e-22 1.8869570e-27 2.9650191e-15\n",
            " 1.0000000e+00 4.5641498e-34 2.8532273e-22 8.1095431e-28 3.1184195e-28\n",
            " 1.8455340e-14], argmax=5\n",
            "         |->> Hit a STOP on the 29-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [328,   0,  43,  52] -> [328,   0,  43,  52] (Target was [357,  22,  40,  43])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [328,   0,  43,  52] -> [328,   0,  43,  52] w/ P(a|s)=8.109543068745472e-28 and iou=0.11877828054298642 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-11.512925]\n",
            "\u001b[31m>> Total frame loss: -11.512925148010254\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 32 with src: [328,   0,  43,  52] and target: [369,  30,  40,  45]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0032.jpg\n",
            "|->> Beginning tracking for bbox:[328   0  43  52]\n",
            "   \u001b[33m|->> #0/t=29-th Action selection: 1/2X LEFT (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [326   0  43  52]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 9.998e-01 0.000e+00 0.000e+00 0.000e+00 2.000e-04 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=1\n",
            "         |->> Action Probabilities (RAW): [3.5228975e-10 9.9976939e-01 7.7536628e-17 1.8842036e-11 2.1519670e-15\n",
            " 2.2405358e-04 2.0383111e-16 1.1103286e-12 1.7003775e-25 2.7154938e-19\n",
            " 6.5963568e-06], argmax=1\n",
            "   \u001b[33m|->> #1/t=30-th Action selection: 1/2X LEFT (P(a|s) = 0.6650000214576721)\u001b[0m\n",
            "      |->> Bounding box moves to: [324   0  43  52]\n",
            "         |->> Action Probabilities (Rounded): [1.000e-04 6.651e-01 0.000e+00 0.000e+00 0.000e+00 3.348e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=1\n",
            "         |->> Action Probabilities (RAW): [1.0448603e-04 6.6513115e-01 9.1254248e-15 1.6241909e-14 4.7093319e-08\n",
            " 3.3476362e-01 1.2303600e-15 2.1792130e-12 5.9124318e-18 4.9493338e-09\n",
            " 6.9160899e-07], argmax=1\n",
            "   \u001b[33m|->> #2/t=31-th Action selection: 0/LEFT (P(a|s) = 0.6290000081062317)\u001b[0m\n",
            "      |->> Bounding box moves to: [323   0  43  52]\n",
            "         |->> Action Probabilities (Rounded): [0.6287 0.     0.     0.     0.3713 0.     0.     0.     0.     0.\n",
            " 0.    ], argmax=0\n",
            "         |->> Action Probabilities (RAW): [6.28661871e-01 1.19491131e-06 9.26197424e-22 2.79471367e-27\n",
            " 3.71336311e-01 6.19623336e-07 8.50957092e-17 8.27066845e-16\n",
            " 1.19297846e-20 4.42126370e-13 2.19464122e-13], argmax=0\n",
            "|->> Revisiting bbox: [323   0  43  52]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [328,   0,  43,  52] -> [323,   0,  43,  52] (Target was [369,  30,  40,  45])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.011) for 2X LEFT:bbox transition: [328,   0,  43,  52] -> [326,   0,  43,  52] w/ P(a|s)=0.999769389629364 and iou=0.0 and reward=-0.011022044088176353 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for 2X LEFT:bbox transition: [326,   0,  43,  52] -> [324,   0,  43,  52] w/ P(a|s)=0.665131151676178 and iou=0.0 and reward=0.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.0) for LEFT:bbox transition: [324,   0,  43,  52] -> [323,   0,  43,  52] w/ P(a|s)=0.6286618709564209 and iou=0.0 and reward=0.0 and discount=0.9801\n",
            "   |->> Assigned losses: [-2.542091e-06  0.000000e+00  0.000000e+00]\n",
            "\u001b[31m>> Total frame loss: -2.542090896895388e-06\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 33 with src: [323,   0,  43,  52] and target: [381,  43,  42,  43]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0033.jpg\n",
            "|->> Beginning tracking for bbox:[323   0  43  52]\n",
            "|->> Revisiting bbox: [323   0  43  52]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=32-th Action selection: 8/STOP (P(a|s) = 0.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [323   0  43  52]\n",
            "         |->> Action Probabilities (Rounded): [1.000e-04 2.000e-04 4.900e-03 1.540e-02 8.465e-01 1.326e-01 0.000e+00\n",
            " 2.000e-04 0.000e+00 0.000e+00 2.000e-04], argmax=4\n",
            "         |->> Action Probabilities (RAW): [5.5277727e-05 1.5843142e-04 4.9304529e-03 1.5366622e-02 8.4651142e-01\n",
            " 1.3256246e-01 3.5408964e-05 1.8380224e-04 1.6162961e-07 1.7279497e-05\n",
            " 1.7874764e-04], argmax=4\n",
            "         |->> Hit a STOP on the 32-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [323,   0,  43,  52] -> [323,   0,  43,  52] (Target was [381,  43,  42,  43])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [323,   0,  43,  52] -> [323,   0,  43,  52] w/ P(a|s)=1.6162961458121572e-07 and iou=0.0 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-11.512925]\n",
            "\u001b[31m>> Total frame loss: -11.512925148010254\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 34 with src: [323,   0,  43,  52] and target: [395,  66,  36,  39]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0034.jpg\n",
            "|->> Beginning tracking for bbox:[323   0  43  52]\n",
            "   \u001b[33m|->> #0/t=32-th Action selection: 1/2X LEFT (P(a|s) = 0.9990000128746033)\u001b[0m\n",
            "      |->> Bounding box moves to: [321   0  43  52]\n",
            "         |->> Action Probabilities (Rounded): [0.0011 0.9989 0.     0.     0.     0.     0.     0.     0.     0.\n",
            " 0.    ], argmax=1\n",
            "         |->> Action Probabilities (RAW): [1.0917861e-03 9.9890411e-01 6.4383432e-10 1.1176107e-11 4.8451614e-07\n",
            " 3.2362124e-09 2.4889188e-11 3.4712402e-13 1.6200268e-12 3.5296578e-06\n",
            " 2.5094867e-08], argmax=1\n",
            "|->> Revisiting bbox: [321   0  43  52]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [323,   0,  43,  52] -> [321,   0,  43,  52] (Target was [395,  66,  36,  39])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X LEFT:bbox transition: [323,   0,  43,  52] -> [321,   0,  43,  52] w/ P(a|s)=0.9989041090011597 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 35 with src: [321,   0,  43,  52] and target: [397,  82,  38,  39]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0035.jpg\n",
            "|->> Beginning tracking for bbox:[321   0  43  52]\n",
            "|->> Revisiting bbox: [321   0  43  52]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=33-th Action selection: 8/STOP (P(a|s) = 0.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [321   0  43  52]\n",
            "         |->> Action Probabilities (Rounded): [5.000e-04 1.909e-01 0.000e+00 0.000e+00 0.000e+00 8.086e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [4.8326436e-04 1.9093354e-01 2.3289540e-06 1.6295688e-07 4.7933549e-06\n",
            " 8.0856955e-01 7.0049819e-09 1.6055008e-08 6.0714371e-09 4.4240396e-06\n",
            " 1.8966575e-06], argmax=5\n",
            "         |->> Hit a STOP on the 33-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [321,   0,  43,  52] -> [321,   0,  43,  52] (Target was [397,  82,  38,  39])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [321,   0,  43,  52] -> [321,   0,  43,  52] w/ P(a|s)=6.071437130827917e-09 and iou=0.0 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-11.512925]\n",
            "\u001b[31m>> Total frame loss: -11.512925148010254\u001b[0m\n",
            "Final bounding box: [321   0  43  52] reached in 33 timesteps (originating from [336  32  37  46]). Target was [397  82  38  39]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 36 in t=33 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[31m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 207.1870574951172\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.3121560215950012\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 94.23226928710938\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.9773037433624268\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 165.99945068359375\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.8186037540435791\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 113.61151123046875\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.3476765751838684\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 71.2908706665039\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.4015065133571625\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 95.8453140258789\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 1.4661351442337036\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/Matrix\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Starting bounding box for adnet_datasets/OTB/Matrix: frames 22:32 is [323  22  36  45].\n",
            "\u001b[34m>> Attempting to reach frame 23 with src: [323,  22,  36,  45] and target: [325,  26,  37,  47]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0023.jpg\n",
            "|->> Beginning tracking for bbox:[323  22  36  45]\n",
            "             |->> IOU declining: [323  22  36  45]:0.7094147582697201 -> [323  20  36  45]:0.6522380718150517.\n",
            "             |->> Overriding with STOP\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 8/STOP (P(a|s) = 0.0010000000474974513)\u001b[0m\n",
            "      |->> Bounding box moves to: [323  22  36  45]\n",
            "         |->> Action Probabilities (Rounded): [2.150e-02 7.300e-03 7.500e-03 2.000e-04 5.743e-01 3.397e-01 0.000e+00\n",
            " 0.000e+00 6.000e-04 9.800e-03 3.910e-02], argmax=4\n",
            "         |->> Action Probabilities (RAW): [2.1478603e-02 7.3361183e-03 7.4515068e-03 1.9828064e-04 5.7430166e-01\n",
            " 3.3971402e-01 2.4303536e-06 9.8064923e-10 6.3926197e-04 9.7567048e-03\n",
            " 3.9121430e-02], argmax=4\n",
            "         |->> Hit a STOP on the 1-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [323,  22,  36,  45] -> [323,  22,  36,  45] (Target was [325,  26,  37,  47])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [323,  22,  36,  45] -> [323,  22,  36,  45] w/ P(a|s)=0.0006392619688995183 and iou=0.7094147582697201 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [7.355196]\n",
            "\u001b[92m>> Total frame loss: 7.355195999145508\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 24 with src: [323,  22,  36,  45] and target: [329,  30,  37,  48]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0024.jpg\n",
            "|->> Beginning tracking for bbox:[323  22  36  45]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [323  24  36  45]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 1.000e-04 0.000e+00 0.000e+00 2.000e-04\n",
            " 9.996e-01 0.000e+00 0.000e+00 0.000e+00], argmax=7\n",
            "         |->> Action Probabilities (RAW): [2.1358405e-06 1.1721676e-05 3.6187466e-06 1.3657847e-04 2.5976202e-05\n",
            " 1.7908704e-05 2.1175244e-04 9.9958986e-01 6.6732248e-08 1.9322208e-08\n",
            " 3.3645466e-07], argmax=7\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 3/2X RIGHT (P(a|s) = 0.9959999918937683)\u001b[0m\n",
            "      |->> Bounding box moves to: [325  24  36  45]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 2.000e-04 0.000e+00 9.964e-01 0.000e+00 1.000e-03 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 2.400e-03], argmax=3\n",
            "         |->> Action Probabilities (RAW): [3.9045666e-08 2.4049237e-04 1.8294848e-05 9.9641174e-01 7.1730510e-09\n",
            " 9.6531096e-04 5.3406330e-13 2.7681713e-08 1.3846203e-09 2.3653645e-11\n",
            " 2.3641202e-03], argmax=3\n",
            "|->> Revisiting bbox: [323  24  36  45]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [323,  22,  36,  45] -> [325,  24,  36,  45] (Target was [329,  30,  37,  48])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.04) for 2X DOWN:bbox transition: [323,  22,  36,  45] -> [323,  24,  36,  45] w/ P(a|s)=0.9995898604393005 and iou=0.5256064690026954 and reward=0.0400421645407531 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.055) for 2X RIGHT:bbox transition: [323,  24,  36,  45] -> [325,  24,  36,  45] w/ P(a|s)=0.9964117407798767 and iou=0.5810055865921788 and reward=0.05539911758948346 and discount=0.99\n",
            "   |->> Assigned losses: [1.6426246e-05 1.9715245e-04]\n",
            "\u001b[92m>> Total frame loss: 0.00021357869263738394\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 25 with src: [325,  24,  36,  45] and target: [336,  32,  37,  46]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0025.jpg\n",
            "|->> Beginning tracking for bbox:[325  24  36  45]\n",
            "   \u001b[33m|->> #0/t=3-th Action selection: 5/2X UP (P(a|s) = 0.3409999907016754)\u001b[0m\n",
            "      |->> Bounding box moves to: [325  22  36  45]\n",
            "         |->> Action Probabilities (Rounded): [0.0118 0.0747 0.1403 0.0958 0.0778 0.3406 0.0222 0.0842 0.0014 0.0029\n",
            " 0.1485], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.01180665 0.07467019 0.14034934 0.09576754 0.07776042 0.3405588\n",
            " 0.02219254 0.08417802 0.00136784 0.0028614  0.1484873 ], argmax=5\n",
            "   \u001b[33m|->> #1/t=4-th Action selection: 5/2X UP (P(a|s) = 0.6019999980926514)\u001b[0m\n",
            "      |->> Bounding box moves to: [325  20  36  45]\n",
            "         |->> Action Probabilities (Rounded): [0.0018 0.0143 0.0834 0.1738 0.0164 0.6019 0.0169 0.0668 0.0014 0.0032\n",
            " 0.0201], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.0017752  0.01429644 0.08338018 0.1737848  0.01637882 0.60190463\n",
            " 0.0169291  0.06682742 0.00141063 0.00321829 0.02009447], argmax=5\n",
            "   \u001b[33m|->> #2/t=5-th Action selection: 5/2X UP (P(a|s) = 0.9829999804496765)\u001b[0m\n",
            "      |->> Bounding box moves to: [325  18  36  45]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.0145 0.0027 0.9827 0.     0.     0.     0.\n",
            " 0.    ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [5.6986281e-08 2.4031865e-06 2.0814759e-05 1.4533396e-02 2.6714602e-03\n",
            " 9.8271126e-01 6.5907323e-12 1.5186730e-06 8.2861608e-15 1.3264816e-05\n",
            " 4.5893354e-05], argmax=5\n",
            "   \u001b[33m|->> #3/t=6-th Action selection: 4/UP (P(a|s) = 0.3199999928474426)\u001b[0m\n",
            "      |->> Bounding box moves to: [325  17  36  45]\n",
            "         |->> Action Probabilities (Rounded): [6.000e-04 6.000e-04 0.000e+00 1.000e-04 3.205e-01 3.023e-01 0.000e+00\n",
            " 3.760e-01 0.000e+00 0.000e+00 0.000e+00], argmax=7\n",
            "         |->> Action Probabilities (RAW): [5.8422360e-04 5.6549208e-04 5.5769522e-07 8.5542015e-05 3.2049152e-01\n",
            " 3.0226871e-01 3.1724946e-07 3.7600374e-01 7.2799280e-20 1.2457166e-10\n",
            " 3.4437711e-08], argmax=7\n",
            "   \u001b[33m|->> #4/t=7-th Action selection: 7/2X DOWN (P(a|s) = 0.5289999842643738)\u001b[0m\n",
            "      |->> Bounding box moves to: [325  19  36  45]\n",
            "         |->> Action Probabilities (Rounded): [4.600e-03 1.540e-02 2.510e-02 3.460e-02 3.050e-02 2.024e-01 4.800e-03\n",
            " 5.288e-01 0.000e+00 2.000e-04 1.536e-01], argmax=7\n",
            "         |->> Action Probabilities (RAW): [4.6434267e-03 1.5378441e-02 2.5081316e-02 3.4624759e-02 3.0496337e-02\n",
            " 2.0242144e-01 4.7628903e-03 5.2876484e-01 3.2244154e-06 2.4895047e-04\n",
            " 1.5357439e-01], argmax=7\n",
            "|->> Revisiting bbox: [325  17  36  45]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [325,  24,  36,  45] -> [325,  19,  36,  45] (Target was [336,  32,  37,  46])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.028) for 2X UP:bbox transition: [325,  24,  36,  45] -> [325,  22,  36,  45] w/ P(a|s)=0.340558797121048 and iou=0.35758071107478545 and reward=-0.028318329392465258 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.027) for 2X UP:bbox transition: [325,  22,  36,  45] -> [325,  20,  36,  45] w/ P(a|s)=0.6019046306610107 and iou=0.3303964757709251 and reward=-0.027184235303860327 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-0.026) for 2X UP:bbox transition: [325,  20,  36,  45] -> [325,  18,  36,  45] w/ P(a|s)=0.9827112555503845 and iou=0.30427954456223005 and reward=-0.02611693120869507 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-0.013) for UP:bbox transition: [325,  18,  36,  45] -> [325,  17,  36,  45] w/ P(a|s)=0.3204915225505829 and iou=0.291601866251944 and reward=-0.012677678310286045 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.026) for 2X DOWN:bbox transition: [325,  17,  36,  45] -> [325,  19,  36,  45] w/ P(a|s)=0.5287648439407349 and iou=0.317208564631245 and reward=0.02560669837930102 and discount=0.96059601\n",
            "   |->> Assigned losses: [-0.03050358 -0.01366225 -0.00044641 -0.01399746  0.01567393]\n",
            "\u001b[31m>> Total frame loss: -0.04293576627969742\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 26 with src: [325,  19,  36,  45] and target: [340,  33,  36,  46]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0026.jpg\n",
            "|->> Beginning tracking for bbox:[325  19  36  45]\n",
            "   \u001b[33m|->> #0/t=8-th Action selection: 5/2X UP (P(a|s) = 0.9980000257492065)\u001b[0m\n",
            "      |->> Bounding box moves to: [325  17  36  45]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.     0.998  0.     0.     0.     0.\n",
            " 0.0019], argmax=5\n",
            "         |->> Action Probabilities (RAW): [4.0626892e-07 2.0275959e-06 3.7115010e-06 2.6178877e-06 1.4594236e-05\n",
            " 9.9803156e-01 5.0831843e-12 9.8572213e-11 1.6198879e-11 2.9777500e-10\n",
            " 1.9449639e-03], argmax=5\n",
            "   \u001b[33m|->> #1/t=9-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [325  15  36  45]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.8059566e-10 3.0222810e-12 4.2437538e-18 4.4983003e-16 4.6182926e-08\n",
            " 9.9999988e-01 1.3590287e-15 2.1219016e-13 3.0808300e-21 2.1374464e-17\n",
            " 6.2111553e-08], argmax=5\n",
            "   \u001b[33m|->> #2/t=10-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [325  13  36  45]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e-04 9.999e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [5.0595078e-10 8.3235739e-07 1.0783508e-08 2.4785267e-08 1.0066800e-04\n",
            " 9.9989831e-01 7.0879947e-14 6.2369774e-14 1.1568772e-12 4.2076551e-09\n",
            " 1.2120415e-07], argmax=5\n",
            "   \u001b[33m|->> #3/t=11-th Action selection: 2/RIGHT (P(a|s) = 0.2669999897480011)\u001b[0m\n",
            "      |->> Bounding box moves to: [326  13  36  45]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 2.673e-01 6.400e-03 1.000e-04 6.169e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 1.092e-01], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.0675021e-10 3.5767866e-09 2.6733992e-01 6.3892263e-03 1.3612285e-04\n",
            " 6.1690760e-01 2.4042686e-06 4.2959297e-08 1.3969270e-10 4.6351662e-08\n",
            " 1.0922467e-01], argmax=5\n",
            "   \u001b[33m|->> #4/t=12-th Action selection: 2/RIGHT (P(a|s) = 0.04100000113248825)\u001b[0m\n",
            "      |->> Bounding box moves to: [327  13  36  45]\n",
            "         |->> Action Probabilities (Rounded): [1.000e-03 1.400e-03 4.140e-02 1.950e-02 8.000e-04 6.946e-01 5.370e-02\n",
            " 6.000e-04 0.000e+00 0.000e+00 1.870e-01], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.0354574e-03 1.4055807e-03 4.1358456e-02 1.9481175e-02 7.7644858e-04\n",
            " 6.9463807e-01 5.3673666e-02 6.2741915e-04 1.3664467e-05 2.1417087e-05\n",
            " 1.8696858e-01], argmax=5\n",
            "   \u001b[33m|->> #5/t=13-th Action selection: 5/2X UP (P(a|s) = 0.06599999964237213)\u001b[0m\n",
            "      |->> Bounding box moves to: [327  11  36  45]\n",
            "         |->> Action Probabilities (Rounded): [1.398e-01 5.060e-02 2.621e-01 1.200e-03 1.000e-04 6.610e-02 1.040e-02\n",
            " 4.300e-03 2.000e-04 0.000e+00 4.651e-01], argmax=10\n",
            "         |->> Action Probabilities (RAW): [1.3979651e-01 5.0588962e-02 2.6210937e-01 1.2386288e-03 1.0796040e-04\n",
            " 6.6104718e-02 1.0386558e-02 4.3405755e-03 2.2046153e-04 1.2527931e-05\n",
            " 4.6509376e-01], argmax=10\n",
            "   \u001b[33m|->> #6/t=14-th Action selection: 5/2X UP (P(a|s) = 0.7689999938011169)\u001b[0m\n",
            "      |->> Bounding box moves to: [327   9  36  45]\n",
            "         |->> Action Probabilities (Rounded): [1.840e-02 0.000e+00 1.000e-04 0.000e+00 2.000e-04 7.690e-01 0.000e+00\n",
            " 2.000e-04 0.000e+00 0.000e+00 2.121e-01], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.8406319e-02 2.0878224e-05 8.8592213e-05 8.1079202e-07 1.9775431e-04\n",
            " 7.6898062e-01 2.1584645e-09 1.7631154e-04 1.8255727e-07 4.4516572e-08\n",
            " 2.1212856e-01], argmax=5\n",
            "   \u001b[33m|->> #7/t=15-th Action selection: 0/LEFT (P(a|s) = 0.328000009059906)\u001b[0m\n",
            "      |->> Bounding box moves to: [326   9  36  45]\n",
            "         |->> Action Probabilities (Rounded): [0.3283 0.1644 0.     0.     0.     0.     0.     0.0036 0.     0.\n",
            " 0.5037], argmax=10\n",
            "         |->> Action Probabilities (RAW): [3.2830191e-01 1.6442350e-01 2.6933640e-07 1.7529558e-06 3.2732783e-12\n",
            " 8.1250250e-12 1.6869872e-05 3.5816017e-03 1.3116165e-12 2.8673405e-10\n",
            " 5.0367409e-01], argmax=10\n",
            "   \u001b[33m|->> #8/t=16-th Action selection: 0/LEFT (P(a|s) = 0.017999999225139618)\u001b[0m\n",
            "      |->> Bounding box moves to: [325   9  36  45]\n",
            "         |->> Action Probabilities (Rounded): [1.770e-02 9.736e-01 0.000e+00 0.000e+00 2.000e-04 0.000e+00 0.000e+00\n",
            " 4.300e-03 0.000e+00 3.100e-03 1.100e-03], argmax=1\n",
            "         |->> Action Probabilities (RAW): [1.7681923e-02 9.7363394e-01 9.2242631e-09 6.3399166e-06 1.8546090e-04\n",
            " 8.6588061e-06 3.4437758e-06 4.2522484e-03 3.4766355e-08 3.0965223e-03\n",
            " 1.1314419e-03], argmax=1\n",
            "   \u001b[33m|->> #9/t=17-th Action selection: 1/2X LEFT (P(a|s) = 0.7720000147819519)\u001b[0m\n",
            "      |->> Bounding box moves to: [323   9  36  45]\n",
            "         |->> Action Probabilities (Rounded): [2.040e-02 7.721e-01 1.000e-04 1.200e-03 4.000e-04 5.000e-04 1.615e-01\n",
            " 3.100e-02 0.000e+00 1.030e-02 2.500e-03], argmax=1\n",
            "         |->> Action Probabilities (RAW): [2.0403624e-02 7.7211440e-01 7.6099823e-05 1.2075688e-03 3.8411570e-04\n",
            " 4.7894916e-04 1.6146456e-01 3.0995937e-02 4.4473632e-05 1.0328968e-02\n",
            " 2.5013774e-03], argmax=1\n",
            "   \u001b[33m|->> #10/t=18-th Action selection: 7/2X DOWN (P(a|s) = 0.2879999876022339)\u001b[0m\n",
            "      |->> Bounding box moves to: [323  11  36  45]\n",
            "         |->> Action Probabilities (Rounded): [0.0565 0.474  0.     0.0348 0.     0.0006 0.0045 0.2879 0.     0.0006\n",
            " 0.1412], argmax=1\n",
            "         |->> Action Probabilities (RAW): [5.6512501e-02 4.7395107e-01 3.3354572e-05 3.4778178e-02 1.1151135e-05\n",
            " 5.8784802e-04 4.5244223e-03 2.8785241e-01 2.6964010e-08 5.9059501e-04\n",
            " 1.4115849e-01], argmax=1\n",
            "   \u001b[33m|->> #11/t=19-th Action selection: 3/2X RIGHT (P(a|s) = 0.8500000238418579)\u001b[0m\n",
            "      |->> Bounding box moves to: [325  11  36  45]\n",
            "         |->> Action Probabilities (Rounded): [0.0014 0.003  0.     0.8498 0.     0.0099 0.     0.0812 0.     0.\n",
            " 0.0547], argmax=3\n",
            "         |->> Action Probabilities (RAW): [1.4218375e-03 2.9813640e-03 7.1400859e-06 8.4981072e-01 2.6312728e-05\n",
            " 9.8539675e-03 3.9171915e-05 8.1169464e-02 1.1251532e-11 2.2041493e-07\n",
            " 5.4689866e-02], argmax=3\n",
            "|->> Revisiting bbox: [327  11  36  45]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [325,  19,  36,  45] -> [325,  11,  36,  45] (Target was [340,  33,  36,  46])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.02) for 2X UP:bbox transition: [325,  19,  36,  45] -> [325,  17,  36,  45] w/ P(a|s)=0.9980315566062927 and iou=0.2283464566929134 and reward=-0.0196535433070866 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.019) for 2X UP:bbox transition: [325,  17,  36,  45] -> [325,  15,  36,  45] w/ P(a|s)=0.9999998807907104 and iou=0.20930232558139536 and reward=-0.019044131111518037 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-0.018) for 2X UP:bbox transition: [325,  15,  36,  45] -> [325,  13,  36,  45] w/ P(a|s)=0.9998983144760132 and iou=0.19083969465648856 and reward=-0.018462630924906798 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.011) for RIGHT:bbox transition: [325,  13,  36,  45] -> [326,  13,  36,  45] w/ P(a|s)=0.26733991503715515 and iou=0.20176082171680118 and reward=0.010921127060312619 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.011) for RIGHT:bbox transition: [326,  13,  36,  45] -> [327,  13,  36,  45] w/ P(a|s)=0.04135845601558685 and iou=0.21288411699370605 and reward=0.011123295276904865 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-0.02) for 2X UP:bbox transition: [327,  13,  36,  45] -> [327,  11,  36,  45] w/ P(a|s)=0.0661047175526619 and iou=0.19257371678194393 and reward=-0.020310400211762114 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (-0.02) for 2X UP:bbox transition: [327,  11,  36,  45] -> [327,   9,  36,  45] w/ P(a|s)=0.7689806222915649 and iou=0.17293233082706766 and reward=-0.019641385954876273 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (-0.009) for LEFT:bbox transition: [327,   9,  36,  45] -> [326,   9,  36,  45] w/ P(a|s)=0.32830190658569336 and iou=0.16417910447761194 and reward=-0.008753226349455717 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (-0.009) for LEFT:bbox transition: [326,   9,  36,  45] -> [325,   9,  36,  45] w/ P(a|s)=0.017681922763586044 and iou=0.15555555555555556 and reward=-0.008623548922056384 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (-0.017) for 2X LEFT:bbox transition: [325,   9,  36,  45] -> [323,   9,  36,  45] w/ P(a|s)=0.7721143960952759 and iou=0.1386861313868613 and reward=-0.016869424168694247 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (0.015) for 2X DOWN:bbox transition: [323,   9,  36,  45] -> [323,  11,  36,  45] w/ P(a|s)=0.28785240650177 and iou=0.1539274392391687 and reward=0.0152413078523074 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (0.019) for 2X RIGHT:bbox transition: [323,  11,  36,  45] -> [325,  11,  36,  45] w/ P(a|s)=0.8498107194900513 and iou=0.17293233082706766 and reward=0.019004891587898948 and discount=0.8953382542587164\n",
            "   |->> Assigned losses: [-3.8725015e-05 -1.8879389e-07 -1.8401161e-06  1.3979608e-02\n",
            "  3.4036815e-02 -5.2469455e-02 -4.8576482e-03 -9.0872012e-03\n",
            " -3.2109533e-02 -3.9855056e-03  1.7165275e-02  2.7691799e-03]\n",
            "\u001b[31m>> Total frame loss: -0.03459921479225159\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 27 with src: [325,  11,  36,  45] and target: [341,  30,  36,  42]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0027.jpg\n",
            "|->> Beginning tracking for bbox:[325  11  36  45]\n",
            "   \u001b[33m|->> #0/t=20-th Action selection: 0/LEFT (P(a|s) = 0.04800000041723251)\u001b[0m\n",
            "      |->> Bounding box moves to: [324  11  36  45]\n",
            "         |->> Action Probabilities (Rounded): [4.770e-02 9.000e-04 5.322e-01 2.400e-03 1.670e-02 3.412e-01 0.000e+00\n",
            " 7.100e-03 0.000e+00 1.000e-04 5.180e-02], argmax=2\n",
            "         |->> Action Probabilities (RAW): [4.7655426e-02 8.8863622e-04 5.3217185e-01 2.4235731e-03 1.6722310e-02\n",
            " 3.4117225e-01 6.8487057e-06 7.0590861e-03 3.0348704e-07 5.7353023e-05\n",
            " 5.1842324e-02], argmax=2\n",
            "|->> Revisiting bbox: [325  11  36  45]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [325,  11,  36,  45] -> [324,  11,  36,  45] (Target was [341,  30,  36,  42])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.012) for LEFT:bbox transition: [325,  11,  36,  45] -> [324,  11,  36,  45] w/ P(a|s)=0.04765542596578598 and iou=0.18726307808946172 and reward=-0.011818085769650072 and discount=1.0\n",
            "   |->> Assigned losses: [-0.0359714]\n",
            "\u001b[31m>> Total frame loss: -0.03597140312194824\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 28 with src: [324,  11,  36,  45] and target: [336,  24,  45,  47]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0028.jpg\n",
            "|->> Beginning tracking for bbox:[324  11  36  45]\n",
            "   \u001b[33m|->> #0/t=21-th Action selection: 2/RIGHT (P(a|s) = 0.9769999980926514)\u001b[0m\n",
            "      |->> Bounding box moves to: [325  11  36  45]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 9.774e-01 1.910e-02 6.000e-04 0.000e+00 0.000e+00\n",
            " 0.000e+00 0.000e+00 2.300e-03 5.000e-04], argmax=2\n",
            "         |->> Action Probabilities (RAW): [9.38774747e-08 3.66692002e-05 9.77393210e-01 1.91241689e-02\n",
            " 5.57617343e-04 1.88324066e-05 1.04897056e-10 8.90665053e-09\n",
            " 6.42288782e-08 2.34833756e-03 5.20900066e-04], argmax=2\n",
            "   \u001b[33m|->> #1/t=22-th Action selection: 3/2X RIGHT (P(a|s) = 0.6869999766349792)\u001b[0m\n",
            "      |->> Bounding box moves to: [327  11  36  45]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.0109 0.687  0.     0.0334 0.     0.     0.     0.124\n",
            " 0.1447], argmax=3\n",
            "         |->> Action Probabilities (RAW): [4.3320608e-16 5.6274994e-06 1.0886218e-02 6.8702346e-01 2.2746117e-07\n",
            " 3.3369541e-02 5.3543801e-17 3.5874958e-12 6.0756872e-11 1.2401836e-01\n",
            " 1.4469655e-01], argmax=3\n",
            "|->> Revisiting bbox: [327  11  36  45]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [324,  11,  36,  45] -> [327,  11,  36,  45] (Target was [336,  24,  45,  47])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.014) for RIGHT:bbox transition: [324,  11,  36,  45] -> [325,  11,  36,  45] w/ P(a|s)=0.9773932099342346 and iou=0.272572402044293 and reward=0.013725081518509374 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.028) for 2X RIGHT:bbox transition: [325,  11,  36,  45] -> [327,  11,  36,  45] w/ P(a|s)=0.6870234608650208 and iou=0.30094043887147337 and reward=0.028368036827180365 and discount=0.99\n",
            "   |->> Assigned losses: [0.00031384 0.0105425 ]\n",
            "\u001b[92m>> Total frame loss: 0.010856338776648045\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 29 with src: [327,  11,  36,  45] and target: [338,  19,  44,  42]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0029.jpg\n",
            "|->> Beginning tracking for bbox:[327  11  36  45]\n",
            "   \u001b[33m|->> #0/t=23-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [327   9  36  45]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.40138286e-06 2.53128377e-07 2.27924318e-07 1.32899402e-07\n",
            " 5.45056173e-06 9.99976277e-01 8.14863964e-13 1.79452766e-13\n",
            " 3.04038912e-11 7.55100080e-11 1.41835435e-05], argmax=5\n",
            "   \u001b[33m|->> #1/t=24-th Action selection: 4/UP (P(a|s) = 0.8500000238418579)\u001b[0m\n",
            "      |->> Bounding box moves to: [327   8  36  45]\n",
            "         |->> Action Probabilities (Rounded): [2.00e-04 0.00e+00 1.50e-03 0.00e+00 8.50e-01 7.78e-02 0.00e+00 0.00e+00\n",
            " 0.00e+00 4.22e-02 2.83e-02], argmax=4\n",
            "         |->> Action Probabilities (RAW): [2.1726231e-04 1.0590952e-06 1.4579648e-03 5.0799009e-08 8.5001916e-01\n",
            " 7.7773698e-02 4.1615462e-05 1.2445336e-09 2.4279430e-09 4.2226955e-02\n",
            " 2.8262295e-02], argmax=4\n",
            "   \u001b[33m|->> #2/t=25-th Action selection: 2/RIGHT (P(a|s) = 0.2460000067949295)\u001b[0m\n",
            "      |->> Bounding box moves to: [328   8  36  45]\n",
            "         |->> Action Probabilities (Rounded): [1.000e-04 0.000e+00 2.456e-01 3.000e-04 9.300e-03 6.805e-01 3.500e-03\n",
            " 0.000e+00 0.000e+00 8.000e-04 6.000e-02], argmax=5\n",
            "         |->> Action Probabilities (RAW): [8.6451291e-05 5.4465096e-07 2.4556117e-01 3.0418002e-04 9.2505729e-03\n",
            " 6.8048871e-01 3.4926697e-03 2.7977187e-10 1.5006443e-05 8.2066201e-04\n",
            " 5.9979994e-02], argmax=5\n",
            "   \u001b[33m|->> #3/t=26-th Action selection: 10/SCALE UP (P(a|s) = 0.9739999771118164)\u001b[0m\n",
            "      |->> Bounding box moves to: [327   7  38  47]\n",
            "         |->> Action Probabilities (Rounded): [1.000e-04 0.000e+00 5.800e-03 5.900e-03 0.000e+00 1.430e-02 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 9.738e-01], argmax=10\n",
            "         |->> Action Probabilities (RAW): [6.44712782e-05 5.75778472e-07 5.84963989e-03 5.87893371e-03\n",
            " 2.37928962e-05 1.43354125e-02 5.15757179e-08 6.06624083e-12\n",
            " 5.04439879e-10 3.65835604e-07 9.73846793e-01], argmax=10\n",
            "   \u001b[33m|->> #4/t=27-th Action selection: 3/2X RIGHT (P(a|s) = 0.7310000061988831)\u001b[0m\n",
            "      |->> Bounding box moves to: [329   7  38  47]\n",
            "         |->> Action Probabilities (Rounded): [0.005  0.0582 0.1302 0.7311 0.     0.0315 0.     0.     0.     0.\n",
            " 0.044 ], argmax=3\n",
            "         |->> Action Probabilities (RAW): [4.9709617e-03 5.8234695e-02 1.3024679e-01 7.3105359e-01 1.4446071e-05\n",
            " 3.1505872e-02 1.0496658e-07 1.0750058e-09 8.3609912e-08 3.8264629e-06\n",
            " 4.3969549e-02], argmax=3\n",
            "   \u001b[33m|->> #5/t=28-th Action selection: 5/2X UP (P(a|s) = 0.9879999756813049)\u001b[0m\n",
            "      |->> Bounding box moves to: [329   5  38  47]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 2.000e-04 1.000e-04 9.884e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 1.140e-02], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.6808520e-10 3.8964733e-13 8.3678869e-06 1.5313399e-04 6.2456325e-05\n",
            " 9.8842281e-01 4.4332015e-15 5.3260516e-07 9.7394220e-15 1.5465214e-11\n",
            " 1.1352606e-02], argmax=5\n",
            "   \u001b[33m|->> #6/t=29-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [329   3  38  47]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 2.000e-04 0.000e+00 0.000e+00 0.000e+00 9.998e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [5.8959643e-10 1.8666396e-04 3.1618721e-17 3.6209374e-13 4.0950583e-11\n",
            " 9.9981338e-01 4.2162934e-17 3.6598720e-08 1.0009061e-20 5.3233112e-17\n",
            " 6.6091516e-10], argmax=5\n",
            "   \u001b[33m|->> #7/t=30-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [329   1  38  47]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.4323144e-17 2.2213333e-06 1.1054427e-19 1.5163210e-17 6.6796633e-13\n",
            " 9.9999774e-01 3.3207585e-37 4.4040671e-26 0.0000000e+00 1.1823708e-12\n",
            " 1.7148993e-14], argmax=5\n",
            "   \u001b[33m|->> #8/t=31-th Action selection: 10/SCALE UP (P(a|s) = 0.1720000058412552)\u001b[0m\n",
            "      |->> Bounding box moves to: [328   0  40  49]\n",
            "         |->> Action Probabilities (Rounded): [6.730e-02 1.040e-02 7.100e-03 7.372e-01 0.000e+00 5.400e-03 1.000e-04\n",
            " 2.000e-04 0.000e+00 0.000e+00 1.724e-01], argmax=3\n",
            "         |->> Action Probabilities (RAW): [6.7346372e-02 1.0382175e-02 7.0672175e-03 7.3715842e-01 8.7801664e-07\n",
            " 5.3886310e-03 6.5718843e-05 1.9234391e-04 3.3136920e-19 1.2862227e-10\n",
            " 1.7239833e-01], argmax=3\n",
            "   \u001b[33m|->> #9/t=32-th Action selection: 1/2X LEFT (P(a|s) = 0.5170000195503235)\u001b[0m\n",
            "      |->> Bounding box moves to: [326   0  40  49]\n",
            "         |->> Action Probabilities (Rounded): [1.343e-01 5.166e-01 1.111e-01 5.010e-02 0.000e+00 5.180e-02 2.000e-04\n",
            " 3.000e-04 0.000e+00 0.000e+00 1.355e-01], argmax=1\n",
            "         |->> Action Probabilities (RAW): [1.3434751e-01 5.1662207e-01 1.1105587e-01 5.0134726e-02 3.7612281e-08\n",
            " 5.1815189e-02 1.5159711e-04 3.3153323e-04 4.2542797e-20 9.8928636e-11\n",
            " 1.3554151e-01], argmax=1\n",
            "   \u001b[33m|->> #10/t=33-th Action selection: 10/SCALE UP (P(a|s) = 0.9120000004768372)\u001b[0m\n",
            "      |->> Bounding box moves to: [325   0  42  51]\n",
            "         |->> Action Probabilities (Rounded): [2.550e-02 5.960e-02 7.000e-04 0.000e+00 0.000e+00 1.900e-03 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 9.122e-01], argmax=10\n",
            "         |->> Action Probabilities (RAW): [2.5512625e-02 5.9590049e-02 6.8569870e-04 3.5775190e-06 3.0642648e-05\n",
            " 1.9359761e-03 3.5315225e-06 1.3351203e-06 6.0333541e-17 1.8029599e-08\n",
            " 9.1223657e-01], argmax=10\n",
            "|->> Revisiting bbox: [325   0  42  51]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [327,  11,  36,  45] -> [325,   0,  42,  51] (Target was [338,  19,  44,  42])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.026) for 2X UP:bbox transition: [327,  11,  36,  45] -> [327,   9,  36,  45] w/ P(a|s)=0.9999762773513794 and iou=0.3374469726185885 and reward=-0.026296637290967095 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.013) for UP:bbox transition: [327,   9,  36,  45] -> [327,   8,  36,  45] w/ P(a|s)=0.8500191569328308 and iou=0.3246753246753247 and reward=-0.012771647943263853 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.017) for RIGHT:bbox transition: [327,   8,  36,  45] -> [328,   8,  36,  45] w/ P(a|s)=0.2455611675977707 and iou=0.34210526315789475 and reward=0.017429938482570073 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.009) for SCALE UP:bbox transition: [328,   8,  36,  45] -> [327,   7,  38,  47] w/ P(a|s)=0.9738467931747437 and iou=0.3514317590182224 and reward=0.009326495860327633 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.036) for 2X RIGHT:bbox transition: [327,   7,  38,  47] -> [329,   7,  38,  47] w/ P(a|s)=0.7310535907745361 and iou=0.3875525009545628 and reward=0.036120741936340406 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-0.03) for 2X UP:bbox transition: [329,   7,  38,  47] -> [329,   5,  38,  47] w/ P(a|s)=0.9884228110313416 and iou=0.3574897273066866 and reward=-0.030062773647876184 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (-0.029) for 2X UP:bbox transition: [329,   5,  38,  47] -> [329,   3,  38,  47] w/ P(a|s)=0.9998133778572083 and iou=0.3287020109689214 and reward=-0.028787716337765223 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (-0.028) for 2X UP:bbox transition: [329,   3,  38,  47] -> [329,   1,  38,  47] w/ P(a|s)=0.9999977350234985 and iou=0.30110991765127104 and reward=-0.027592093317650335 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (0.008) for SCALE UP:bbox transition: [329,   1,  38,  47] -> [328,   0,  40,  49] w/ P(a|s)=0.17239832878112793 and iou=0.30949105914718017 and reward=0.008381141495909128 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (-0.026) for 2X LEFT:bbox transition: [328,   0,  40,  49] -> [326,   0,  40,  49] w/ P(a|s)=0.5166220664978027 and iou=0.2830188679245283 and reward=-0.026472191222651875 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (0.02) for SCALE UP:bbox transition: [326,   0,  40,  49] -> [325,   0,  42,  51] w/ P(a|s)=0.9122365713119507 and iou=0.3030698889614631 and reward=0.02005102103693479 and discount=0.9043820750088044\n",
            "   |->> Assigned losses: [-6.23833330e-07 -2.05459329e-03  2.39882227e-02  2.39823115e-04\n",
            "  1.08696166e-02 -3.32915719e-04 -5.05850403e-06 -2.57526892e-07\n",
            "  1.35953585e-02 -1.59713775e-02  1.66569545e-03]\n",
            "\u001b[92m>> Total frame loss: 0.031993888318538666\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 30 with src: [325,   0,  42,  51] and target: [347,  18,  42,  44]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0030.jpg\n",
            "|->> Beginning tracking for bbox:[325   0  42  51]\n",
            "|->> Revisiting bbox: [325   0  42  51]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=34-th Action selection: 8/STOP (P(a|s) = 0.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [325   0  42  51]\n",
            "         |->> Action Probabilities (Rounded): [0.    0.    0.    0.007 0.    0.993 0.    0.    0.    0.    0.   ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.7126601e-06 1.0013267e-06 2.5333082e-05 6.9537181e-03 2.5169425e-07\n",
            " 9.9300683e-01 9.6807584e-09 1.4160085e-07 7.5345480e-10 1.7946891e-09\n",
            " 9.0472031e-06], argmax=5\n",
            "         |->> Hit a STOP on the 34-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [325,   0,  42,  51] -> [325,   0,  42,  51] (Target was [347,  18,  42,  44])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [325,   0,  42,  51] -> [325,   0,  42,  51] w/ P(a|s)=7.534547985521556e-10 and iou=0.1981981981981982 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-11.512925]\n",
            "\u001b[31m>> Total frame loss: -11.512925148010254\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 31 with src: [325,   0,  42,  51] and target: [357,  22,  40,  43]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0031.jpg\n",
            "|->> Beginning tracking for bbox:[325   0  42  51]\n",
            "   \u001b[33m|->> #0/t=34-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [325   2  42  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [2.1981304e-11 3.9123461e-12 1.8909158e-24 2.8612252e-16 6.7950319e-21\n",
            " 1.2793076e-07 5.7337168e-31 9.9999988e-01 3.6875577e-33 1.5438348e-29\n",
            " 1.5320221e-14], argmax=7\n",
            "   \u001b[33m|->> #1/t=35-th Action selection: 7/2X DOWN (P(a|s) = 0.6119999885559082)\u001b[0m\n",
            "      |->> Bounding box moves to: [325   4  42  51]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 3.876e-01 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            " 6.121e-01 0.000e+00 0.000e+00 2.000e-04], argmax=7\n",
            "         |->> Action Probabilities (RAW): [2.6687544e-06 3.8764164e-01 1.8875462e-11 2.2763663e-05 6.2952338e-08\n",
            " 3.9420669e-07 2.6051687e-11 6.1205471e-01 3.2804570e-16 4.5374771e-05\n",
            " 2.3238763e-04], argmax=7\n",
            "   \u001b[33m|->> #2/t=36-th Action selection: 10/SCALE UP (P(a|s) = 0.9990000128746033)\u001b[0m\n",
            "      |->> Bounding box moves to: [324   3  44  53]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 4.000e-04 1.000e-04 2.000e-04 0.000e+00 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 9.992e-01], argmax=10\n",
            "         |->> Action Probabilities (RAW): [7.3370277e-10 5.0952799e-08 4.1573617e-04 6.9658738e-05 2.3704181e-04\n",
            " 2.9377992e-05 3.0163314e-16 1.7183829e-11 5.8801251e-18 3.3051469e-06\n",
            " 9.9924481e-01], argmax=10\n",
            "   \u001b[33m|->> #3/t=37-th Action selection: 3/2X RIGHT (P(a|s) = 0.9039999842643738)\u001b[0m\n",
            "      |->> Bounding box moves to: [326   3  44  53]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 2.200e-03 9.043e-01 2.140e-02 0.000e+00 0.000e+00\n",
            " 0.000e+00 0.000e+00 1.000e-04 7.200e-02], argmax=3\n",
            "         |->> Action Probabilities (RAW): [6.73215867e-12 2.74518097e-08 2.23314017e-03 9.04257059e-01\n",
            " 2.14328170e-02 1.14706445e-05 6.10932296e-15 7.03220167e-08\n",
            " 6.44583603e-17 7.27014994e-05 7.19927549e-02], argmax=3\n",
            "   \u001b[33m|->> #4/t=38-th Action selection: 5/2X UP (P(a|s) = 0.9990000128746033)\u001b[0m\n",
            "      |->> Bounding box moves to: [326   1  44  53]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 9.991e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 8.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.7138262e-06 2.0787970e-06 3.5770408e-06 7.7665585e-10 2.7779904e-05\n",
            " 9.9912006e-01 3.1807911e-08 3.6940667e-10 5.2965405e-08 2.6875230e-07\n",
            " 8.4445794e-04], argmax=5\n",
            "   \u001b[33m|->> #5/t=39-th Action selection: 10/SCALE UP (P(a|s) = 0.9909999966621399)\u001b[0m\n",
            "      |->> Bounding box moves to: [325   0  46  55]\n",
            "         |->> Action Probabilities (Rounded): [1.000e-04 0.000e+00 8.500e-03 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 9.914e-01], argmax=10\n",
            "         |->> Action Probabilities (RAW): [7.97953544e-05 7.44599294e-16 8.47656373e-03 7.79341036e-09\n",
            " 3.76468324e-06 8.74003359e-09 3.44632234e-08 3.74041900e-12\n",
            " 1.12212364e-10 5.35126503e-08 9.91439819e-01], argmax=10\n",
            "   \u001b[33m|->> #6/t=40-th Action selection: 2/RIGHT (P(a|s) = 0.5839999914169312)\u001b[0m\n",
            "      |->> Bounding box moves to: [326   0  46  55]\n",
            "         |->> Action Probabilities (Rounded): [0.2825 0.     0.5836 0.     0.     0.     0.     0.     0.     0.\n",
            " 0.1338], argmax=2\n",
            "         |->> Action Probabilities (RAW): [2.8254277e-01 1.2872439e-17 5.8364546e-01 3.9398146e-12 1.9217108e-05\n",
            " 4.3950575e-07 3.3952026e-06 1.5922100e-10 3.7875407e-07 1.2897303e-07\n",
            " 1.3378820e-01], argmax=2\n",
            "   \u001b[33m|->> #7/t=41-th Action selection: 10/SCALE UP (P(a|s) = 0.9810000061988831)\u001b[0m\n",
            "      |->> Bounding box moves to: [325   0  48  57]\n",
            "         |->> Action Probabilities (Rounded): [6.000e-04 0.000e+00 1.000e-04 2.800e-03 7.000e-04 1.000e-04 0.000e+00\n",
            " 1.380e-02 5.000e-04 0.000e+00 9.814e-01], argmax=10\n",
            "         |->> Action Probabilities (RAW): [5.76713588e-04 2.04431899e-06 5.74909645e-05 2.84521142e-03\n",
            " 7.27382489e-04 1.02779326e-04 5.19335019e-09 1.37974769e-02\n",
            " 4.90733248e-04 1.95804819e-06 9.81398165e-01], argmax=10\n",
            "   \u001b[33m|->> #8/t=42-th Action selection: 1/2X LEFT (P(a|s) = 0.4659999907016754)\u001b[0m\n",
            "      |->> Bounding box moves to: [323   0  48  57]\n",
            "         |->> Action Probabilities (Rounded): [1.457e-01 4.663e-01 1.800e-03 1.000e-04 3.200e-03 9.000e-03 1.412e-01\n",
            " 4.080e-02 0.000e+00 5.910e-02 1.328e-01], argmax=1\n",
            "         |->> Action Probabilities (RAW): [1.4565741e-01 4.6629116e-01 1.8146775e-03 1.4601207e-04 3.1892925e-03\n",
            " 8.9909295e-03 1.4121191e-01 4.0783547e-02 9.9560893e-06 5.9134260e-02\n",
            " 1.3277088e-01], argmax=1\n",
            "   \u001b[33m|->> #9/t=43-th Action selection: 10/SCALE UP (P(a|s) = 0.9169999957084656)\u001b[0m\n",
            "      |->> Bounding box moves to: [322   0  50  59]\n",
            "         |->> Action Probabilities (Rounded): [8.140e-02 0.000e+00 4.000e-04 8.000e-04 0.000e+00 0.000e+00 0.000e+00\n",
            " 9.000e-04 0.000e+00 0.000e+00 9.165e-01], argmax=10\n",
            "         |->> Action Probabilities (RAW): [8.1403039e-02 6.7013329e-06 3.8230032e-04 7.6655229e-04 6.0411185e-07\n",
            " 1.3739033e-11 3.6879588e-05 8.6262100e-04 2.5153446e-10 3.8488351e-06\n",
            " 9.1653746e-01], argmax=10\n",
            "   \u001b[33m|->> #10/t=44-th Action selection: 10/SCALE UP (P(a|s) = 0.6259999871253967)\u001b[0m\n",
            "      |->> Bounding box moves to: [321   0  52  61]\n",
            "         |->> Action Probabilities (Rounded): [1.700e-03 7.600e-03 6.000e-04 1.500e-02 2.540e-02 2.750e-01 8.000e-04\n",
            " 5.000e-04 0.000e+00 4.730e-02 6.262e-01], argmax=10\n",
            "         |->> Action Probabilities (RAW): [1.6847558e-03 7.6285796e-03 6.0949882e-04 1.4986811e-02 2.5438167e-02\n",
            " 2.7501494e-01 7.5735676e-04 4.5143516e-04 4.5474280e-07 4.7267303e-02\n",
            " 6.2616068e-01], argmax=10\n",
            "|->> Revisiting bbox: [321   0  52  61]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [325,   0,  42,  51] -> [321,   0,  52,  61] (Target was [357,  22,  40,  43])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.006) for 2X DOWN:bbox transition: [325,   0,  42,  51] -> [325,   2,  42,  51] w/ P(a|s)=0.9999998807907104 and iou=0.08727477477477477 and reward=0.006087764696387318 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.006) for 2X DOWN:bbox transition: [325,   2,  42,  51] -> [325,   4,  42,  51] w/ P(a|s)=0.612054705619812 and iou=0.09343148357870895 and reward=0.00615670880393418 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.008) for SCALE UP:bbox transition: [325,   4,  42,  51] -> [324,   3,  44,  53] w/ P(a|s)=0.9992448091506958 and iou=0.10168569874932028 and reward=0.008254215170611326 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.021) for 2X RIGHT:bbox transition: [324,   3,  44,  53] -> [326,   3,  44,  53] w/ P(a|s)=0.90425705909729 and iou=0.12243767313019391 and reward=0.02075197438087363 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-0.008) for 2X UP:bbox transition: [326,   3,  44,  53] -> [326,   1,  44,  53] w/ P(a|s)=0.9991200566291809 and iou=0.11441144114411442 and reward=-0.00802623198607949 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.008) for SCALE UP:bbox transition: [326,   1,  44,  53] -> [325,   0,  46,  55] w/ P(a|s)=0.9914398193359375 and iou=0.12196409714889124 and reward=0.007552656004776823 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.01) for RIGHT:bbox transition: [325,   0,  46,  55] -> [326,   0,  46,  55] w/ P(a|s)=0.5836454629898071 and iou=0.1318242343541944 and reward=0.009860137205303168 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (0.012) for SCALE UP:bbox transition: [326,   0,  46,  55] -> [325,   0,  48,  57] w/ P(a|s)=0.9813981652259827 and iou=0.1437371663244353 and reward=0.011912931970240903 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (-0.02) for 2X LEFT:bbox transition: [325,   0,  48,  57] -> [323,   0,  48,  57] w/ P(a|s)=0.4662911593914032 and iou=0.12355017650025214 and reward=-0.02018698982418317 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (0.011) for SCALE UP:bbox transition: [323,   0,  48,  57] -> [322,   0,  50,  59] w/ P(a|s)=0.9165374636650085 and iou=0.13487241798298907 and reward=0.01132224148273693 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (0.011) for SCALE UP:bbox transition: [322,   0,  50,  59] -> [321,   0,  52,  61] w/ P(a|s)=0.6261606812477112 and iou=0.14620431115276475 and reward=0.011331893169775675 and discount=0.9043820750088044\n",
            "   |->> Assigned losses: [ 6.0960623e-08  2.9923099e-03  6.1117685e-06  2.0264809e-03\n",
            " -6.7873207e-06  6.1748164e-05  4.9986052e-03  2.0849315e-04\n",
            " -1.4211712e-02  9.0142206e-04  4.7977525e-03]\n",
            "\u001b[92m>> Total frame loss: 0.0017744852229952812\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 32 with src: [321,   0,  52,  61] and target: [369,  30,  40,  45]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0032.jpg\n",
            "|->> Beginning tracking for bbox:[321   0  52  61]\n",
            "|->> Revisiting bbox: [321   0  52  61]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=45-th Action selection: 8/STOP (P(a|s) = 0.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [321   0  52  61]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.8245 0.1755 0.     0.     0.     0.\n",
            " 0.    ], argmax=4\n",
            "         |->> Action Probabilities (RAW): [2.1339245e-05 1.0658115e-05 3.8528169e-06 1.5864453e-07 8.2446653e-01\n",
            " 1.7545921e-01 2.1116422e-08 8.8457648e-07 7.7000767e-15 1.5727405e-10\n",
            " 3.7429472e-05], argmax=4\n",
            "         |->> Hit a STOP on the 45-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [321,   0,  52,  61] -> [321,   0,  52,  61] (Target was [369,  30,  40,  45])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [321,   0,  52,  61] -> [321,   0,  52,  61] w/ P(a|s)=7.700076673825516e-15 and iou=0.02557755775577558 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-11.512925]\n",
            "\u001b[31m>> Total frame loss: -11.512925148010254\u001b[0m\n",
            "Final bounding box: [321   0  52  61] reached in 45 timesteps (originating from [323  22  36  45]). Target was [369  30  40  45]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 33 in t=45 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[31m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 197.67691040039062\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.2430511862039566\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 173.53475952148438\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.4251965880393982\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 293.4392395019531\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.8911300301551819\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 140.01791381835938\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.2843903601169586\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 78.69340515136719\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.19793714582920074\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 105.28436279296875\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 1.2330119609832764\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/Matrix\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Starting bounding box for adnet_datasets/OTB/Matrix: frames 29:39 is [338  19  44  42].\n",
            "\u001b[34m>> Attempting to reach frame 30 with src: [338,  19,  44,  42] and target: [347,  18,  42,  44]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0030.jpg\n",
            "|->> Beginning tracking for bbox:[338  19  44  42]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 6/DOWN (P(a|s) = 0.04399999976158142)\u001b[0m\n",
            "      |->> Bounding box moves to: [338  20  44  42]\n",
            "         |->> Action Probabilities (Rounded): [6.000e-04 1.100e-03 1.610e-02 2.400e-03 2.500e-03 1.543e-01 4.430e-02\n",
            " 7.746e-01 1.000e-04 0.000e+00 4.100e-03], argmax=7\n",
            "         |->> Action Probabilities (RAW): [5.5223319e-04 1.1182671e-03 1.6064188e-02 2.3885979e-03 2.5049523e-03\n",
            " 1.5426537e-01 4.4286501e-02 7.7462018e-01 9.7344244e-05 4.7312573e-05\n",
            " 4.0550590e-03], argmax=7\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 0/LEFT (P(a|s) = 0.17399999499320984)\u001b[0m\n",
            "      |->> Bounding box moves to: [337  20  44  42]\n",
            "         |->> Action Probabilities (Rounded): [0.1735 0.0596 0.0014 0.0017 0.0694 0.6006 0.0134 0.0395 0.0041 0.0091\n",
            " 0.0278], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.17351858 0.05957652 0.00137632 0.00165396 0.06938948 0.6005942\n",
            " 0.01336214 0.03950925 0.00413323 0.00908658 0.0277997 ], argmax=5\n",
            "   \u001b[33m|->> #2/t=3-th Action selection: 5/2X UP (P(a|s) = 0.9419999718666077)\u001b[0m\n",
            "      |->> Bounding box moves to: [337  18  44  42]\n",
            "         |->> Action Probabilities (Rounded): [3.270e-02 8.800e-03 2.000e-04 2.000e-04 7.800e-03 9.417e-01 1.100e-03\n",
            " 2.600e-03 4.000e-04 1.100e-03 3.200e-03], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.2706391e-02 8.8277245e-03 2.4460370e-04 2.4141386e-04 7.8351330e-03\n",
            " 9.4170117e-01 1.0853441e-03 2.5899298e-03 4.2125882e-04 1.1388473e-03\n",
            " 3.2082114e-03], argmax=5\n",
            "|->> Revisiting bbox: [337  20  44  42]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [338,  19,  44,  42] -> [337,  18,  44,  42] (Target was [347,  18,  42,  44])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for DOWN:bbox transition: [338,  19,  44,  42] -> [338,  20,  44,  42] w/ P(a|s)=0.04428650066256523 and iou=0.660377358490566 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.031) for LEFT:bbox transition: [338,  20,  44,  42] -> [337,  20,  44,  42] w/ P(a|s)=0.1735185831785202 and iou=0.6296296296296297 and reward=-0.030747728860936352 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X UP:bbox transition: [337,  20,  44,  42] -> [337,  18,  44,  42] w/ P(a|s)=0.9417011737823486 and iou=0.6296296296296297 and reward=0.0 and discount=0.9801\n",
            "   |->> Assigned losses: [ 0.         -0.05331521  0.        ]\n",
            "\u001b[31m>> Total frame loss: -0.05331520736217499\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 31 with src: [337,  18,  44,  42] and target: [357,  22,  40,  43]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0031.jpg\n",
            "|->> Beginning tracking for bbox:[337  18  44  42]\n",
            "   \u001b[33m|->> #0/t=4-th Action selection: 6/DOWN (P(a|s) = 0.765999972820282)\u001b[0m\n",
            "      |->> Bounding box moves to: [337  19  44  42]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 1.070e-02 9.000e-03 0.000e+00 1.000e-04 7.661e-01\n",
            " 2.129e-01 0.000e+00 3.000e-04 9.000e-04], argmax=6\n",
            "         |->> Action Probabilities (RAW): [2.1464533e-05 1.3828152e-07 1.0679156e-02 9.0186549e-03 3.7843311e-08\n",
            " 8.5740132e-05 7.6608312e-01 2.1289332e-01 5.8210942e-10 3.2053358e-04\n",
            " 8.9781318e-04], argmax=6\n",
            "   \u001b[33m|->> #1/t=5-th Action selection: 5/2X UP (P(a|s) = 0.9959999918937683)\u001b[0m\n",
            "      |->> Bounding box moves to: [337  17  44  42]\n",
            "         |->> Action Probabilities (Rounded): [3.000e-04 4.000e-04 0.000e+00 8.000e-04 0.000e+00 9.963e-01 2.000e-04\n",
            " 5.000e-04 0.000e+00 0.000e+00 1.500e-03], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.7539043e-04 3.6926381e-04 2.6109069e-06 7.9896656e-04 2.3612267e-06\n",
            " 9.9634665e-01 1.7945650e-04 4.8366486e-04 1.5017332e-12 1.1797777e-06\n",
            " 1.5405625e-03], argmax=5\n",
            "|->> Revisiting bbox: [337  19  44  42]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [337,  18,  44,  42] -> [337,  17,  44,  42] (Target was [357,  22,  40,  43])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.012) for DOWN:bbox transition: [337,  18,  44,  42] -> [337,  19,  44,  42] w/ P(a|s)=0.7660831212997437 and iou=0.3556231003039514 and reward=0.01224960632804778 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.024) for 2X UP:bbox transition: [337,  19,  44,  42] -> [337,  17,  44,  42] w/ P(a|s)=0.996346652507782 and iou=0.33134328358208953 and reward=-0.024279816721861858 and discount=0.99\n",
            "   |->> Assigned losses: [ 3.2640863e-03 -8.7976383e-05]\n",
            "\u001b[92m>> Total frame loss: 0.003176109865307808\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 32 with src: [337,  17,  44,  42] and target: [369,  30,  40,  45]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0032.jpg\n",
            "|->> Beginning tracking for bbox:[337  17  44  42]\n",
            "   \u001b[33m|->> #0/t=6-th Action selection: 5/2X UP (P(a|s) = 0.5580000281333923)\u001b[0m\n",
            "      |->> Bounding box moves to: [337  15  44  42]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 3.770e-02 0.000e+00 0.000e+00 0.000e+00 5.582e-01 1.000e-04\n",
            " 3.806e-01 0.000e+00 0.000e+00 2.340e-02], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.0343912e-05 3.7697978e-02 1.2495110e-07 1.9942206e-08 1.4946973e-07\n",
            " 5.5821538e-01 1.3391922e-04 3.8056493e-01 2.4639912e-11 1.4883753e-08\n",
            " 2.3377089e-02], argmax=5\n",
            "   \u001b[33m|->> #1/t=7-th Action selection: 10/SCALE UP (P(a|s) = 0.9980000257492065)\u001b[0m\n",
            "      |->> Bounding box moves to: [336  14  46  44]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.     0.0016 0.     0.     0.     0.\n",
            " 0.9984], argmax=10\n",
            "         |->> Action Probabilities (RAW): [2.4314431e-08 1.7667759e-05 6.5415854e-08 2.0359554e-10 9.7698264e-12\n",
            " 1.5604284e-03 5.1528618e-06 9.4581949e-08 3.5799440e-11 5.5110998e-12\n",
            " 9.9841654e-01], argmax=10\n",
            "   \u001b[33m|->> #2/t=8-th Action selection: 10/SCALE UP (P(a|s) = 0.9980000257492065)\u001b[0m\n",
            "      |->> Bounding box moves to: [335  13  48  46]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 1.800e-03 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            " 1.000e-04 0.000e+00 0.000e+00 9.981e-01], argmax=10\n",
            "         |->> Action Probabilities (RAW): [7.4365212e-06 1.7720256e-03 2.7644151e-09 2.7406835e-10 1.4914407e-13\n",
            " 2.0854159e-06 1.7227849e-05 9.2062335e-05 8.2226259e-14 1.1655482e-12\n",
            " 9.9810910e-01], argmax=10\n",
            "   \u001b[33m|->> #3/t=9-th Action selection: 7/2X DOWN (P(a|s) = 0.996999979019165)\u001b[0m\n",
            "      |->> Bounding box moves to: [335  15  48  46]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 1.800e-03 0.000e+00 0.000e+00 0.000e+00 1.000e-04 0.000e+00\n",
            " 9.966e-01 0.000e+00 0.000e+00 1.600e-03], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.7119843e-09 1.7651973e-03 4.0688212e-12 8.4435641e-08 6.5805905e-10\n",
            " 5.7207286e-05 3.2148009e-06 9.9659258e-01 1.2243191e-17 1.1615979e-15\n",
            " 1.5815810e-03], argmax=7\n",
            "   \u001b[33m|->> #4/t=10-th Action selection: 7/2X DOWN (P(a|s) = 0.8050000071525574)\u001b[0m\n",
            "      |->> Bounding box moves to: [335  17  48  46]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.1954 0.     0.     0.     0.     0.     0.8046 0.     0.\n",
            " 0.    ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [2.6191250e-08 1.9536281e-01 1.3791529e-23 1.1480292e-17 1.8163460e-21\n",
            " 6.3428873e-10 1.1873892e-10 8.0463719e-01 2.4138077e-20 4.6903726e-20\n",
            " 2.3086257e-11], argmax=7\n",
            "   \u001b[33m|->> #5/t=11-th Action selection: 0/LEFT (P(a|s) = 0.8059999942779541)\u001b[0m\n",
            "      |->> Bounding box moves to: [334  17  48  46]\n",
            "         |->> Action Probabilities (Rounded): [8.057e-01 4.800e-03 0.000e+00 1.600e-03 0.000e+00 1.800e-03 0.000e+00\n",
            " 2.000e-04 0.000e+00 0.000e+00 1.859e-01], argmax=0\n",
            "         |->> Action Probabilities (RAW): [8.0570173e-01 4.8309681e-03 6.1182376e-10 1.6035459e-03 2.1394001e-06\n",
            " 1.7722335e-03 5.6078084e-06 2.3368443e-04 4.9770240e-14 1.9026726e-10\n",
            " 1.8585013e-01], argmax=0\n",
            "   \u001b[33m|->> #6/t=12-th Action selection: 1/2X LEFT (P(a|s) = 0.5590000152587891)\u001b[0m\n",
            "      |->> Bounding box moves to: [332  17  48  46]\n",
            "         |->> Action Probabilities (Rounded): [0.0009 0.559  0.     0.0009 0.0125 0.4083 0.     0.0008 0.     0.0034\n",
            " 0.0142], argmax=1\n",
            "         |->> Action Probabilities (RAW): [8.8014937e-04 5.5898798e-01 1.3513196e-05 9.1986620e-04 1.2515908e-02\n",
            " 4.0830728e-01 1.8916828e-06 8.0379663e-04 2.4106157e-06 3.3831499e-03\n",
            " 1.4184005e-02], argmax=1\n",
            "   \u001b[33m|->> #7/t=13-th Action selection: 0/LEFT (P(a|s) = 0.2809999883174896)\u001b[0m\n",
            "      |->> Bounding box moves to: [331  17  48  46]\n",
            "         |->> Action Probabilities (Rounded): [2.811e-01 0.000e+00 3.769e-01 0.000e+00 0.000e+00 3.416e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 3.000e-04], argmax=2\n",
            "         |->> Action Probabilities (RAW): [2.81131864e-01 1.14336244e-05 3.76881540e-01 1.28917605e-08\n",
            " 1.84577473e-07 3.41632575e-01 4.75475503e-07 2.84661473e-05\n",
            " 5.82117946e-06 3.51709950e-08 3.07628565e-04], argmax=2\n",
            "|->> Revisiting bbox: [332  17  48  46]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [337,  17,  44,  42] -> [331,  17,  48,  46] (Target was [369,  30,  40,  45])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.008) for 2X UP:bbox transition: [337,  17,  44,  42] -> [337,  15,  44,  42] w/ P(a|s)=0.5582153797149658 and iou=0.09747292418772563 and reward=-0.007981621266819824 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.008) for SCALE UP:bbox transition: [337,  15,  44,  42] -> [336,  14,  46,  44] w/ P(a|s)=0.998416543006897 and iou=0.10520231213872833 and reward=0.0077293879510026975 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.008) for SCALE UP:bbox transition: [336,  14,  46,  44] -> [335,  13,  48,  46] w/ P(a|s)=0.9981091022491455 and iou=0.11271515824541921 and reward=0.007512846106690882 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.009) for 2X DOWN:bbox transition: [335,  13,  48,  46] -> [335,  15,  48,  46] w/ P(a|s)=0.9965925812721252 and iou=0.12143256855064354 and reward=0.008717410305224327 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.009) for 2X DOWN:bbox transition: [335,  15,  48,  46] -> [335,  17,  48,  46] w/ P(a|s)=0.8046371936798096 and iou=0.13028764805414553 and reward=0.008855079503501992 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-0.01) for LEFT:bbox transition: [335,  17,  48,  46] -> [334,  17,  48,  46] w/ P(a|s)=0.805701732635498 and iou=0.11986588432523052 and reward=-0.010421763728915012 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (-0.02) for 2X LEFT:bbox transition: [334,  17,  48,  46] -> [332,  17,  48,  46] w/ P(a|s)=0.5589879751205444 and iou=0.09958847736625515 and reward=-0.02027740695897537 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (-0.01) for LEFT:bbox transition: [332,  17,  48,  46] -> [331,  17,  48,  46] w/ P(a|s)=0.2811318635940552 and iou=0.08972267536704731 and reward=-0.009865801999207835 and discount=0.9320653479069899\n",
            "   |->> Assigned losses: [-4.6533686e-03  1.2126365e-05  1.3936504e-05  2.8870847e-05\n",
            "  1.8489298e-03 -2.1411874e-03 -1.1103718e-02 -1.1668551e-02]\n",
            "\u001b[31m>> Total frame loss: -0.027662960812449455\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 33 with src: [331,  17,  48,  46] and target: [381,  43,  42,  43]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0033.jpg\n",
            "|->> Beginning tracking for bbox:[331  17  48  46]\n",
            "   \u001b[33m|->> #0/t=14-th Action selection: 5/2X UP (P(a|s) = 0.8100000023841858)\u001b[0m\n",
            "      |->> Bounding box moves to: [331  15  48  46]\n",
            "         |->> Action Probabilities (Rounded): [1.200e-03 1.107e-01 8.000e-04 4.000e-04 4.530e-02 8.102e-01 3.100e-03\n",
            " 2.000e-03 0.000e+00 3.800e-03 2.250e-02], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.1791388e-03 1.1071799e-01 7.6853356e-04 4.4119832e-04 4.5339424e-02\n",
            " 8.1016028e-01 3.1145252e-03 2.0029182e-03 1.7384079e-07 3.7687451e-03\n",
            " 2.2507129e-02], argmax=5\n",
            "   \u001b[33m|->> #1/t=15-th Action selection: 5/2X UP (P(a|s) = 0.9919999837875366)\u001b[0m\n",
            "      |->> Bounding box moves to: [331  13  48  46]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.0079 0.9921 0.     0.     0.     0.\n",
            " 0.    ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.0554645e-05 4.8007059e-05 5.1565710e-08 9.9139379e-07 7.8717498e-03\n",
            " 9.9206263e-01 4.7977560e-06 1.9876950e-07 1.6321939e-08 3.3583692e-07\n",
            " 7.1477592e-07], argmax=5\n",
            "   \u001b[33m|->> #2/t=16-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [331  11  48  46]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e-04 9.999e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [4.41137260e-08 1.49907082e-05 6.50503685e-13 7.22042868e-13\n",
            " 5.16815817e-05 9.99933124e-01 1.11170422e-11 7.29637813e-13\n",
            " 5.51904442e-14 1.58911888e-07 1.19598935e-08], argmax=5\n",
            "   \u001b[33m|->> #3/t=17-th Action selection: 5/2X UP (P(a|s) = 0.9990000128746033)\u001b[0m\n",
            "      |->> Bounding box moves to: [331   9  48  46]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 0.000e+00 4.000e-04 9.988e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 8.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.1634600e-06 1.7222499e-05 1.3316412e-07 3.0465415e-07 3.9530429e-04\n",
            " 9.9882263e-01 5.4615434e-08 5.7124561e-07 5.1155698e-11 2.4216786e-06\n",
            " 7.6020084e-04], argmax=5\n",
            "   \u001b[33m|->> #4/t=18-th Action selection: 5/2X UP (P(a|s) = 0.9679999947547913)\u001b[0m\n",
            "      |->> Bounding box moves to: [331   7  48  46]\n",
            "         |->> Action Probabilities (Rounded): [2.400e-03 1.000e-04 2.600e-03 2.300e-03 1.720e-02 9.679e-01 1.000e-04\n",
            " 0.000e+00 2.000e-04 1.000e-04 7.100e-03], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.4471253e-03 5.7853227e-05 2.5814192e-03 2.2636841e-03 1.7152073e-02\n",
            " 9.6789426e-01 1.2609510e-04 2.5527366e-05 1.9499543e-04 1.4638102e-04\n",
            " 7.1105943e-03], argmax=5\n",
            "   \u001b[33m|->> #5/t=19-th Action selection: 5/2X UP (P(a|s) = 0.925000011920929)\u001b[0m\n",
            "      |->> Bounding box moves to: [331   5  48  46]\n",
            "         |->> Action Probabilities (Rounded): [9.800e-03 1.190e-02 0.000e+00 1.000e-04 3.900e-03 9.253e-01 2.300e-03\n",
            " 2.200e-03 0.000e+00 7.000e-04 4.370e-02], argmax=5\n",
            "         |->> Action Probabilities (RAW): [9.7629381e-03 1.1938296e-02 8.7449116e-06 1.1748373e-04 3.9346982e-03\n",
            " 9.2530215e-01 2.2995630e-03 2.2489149e-03 1.3390792e-08 7.0035167e-04\n",
            " 4.3686822e-02], argmax=5\n",
            "   \u001b[33m|->> #6/t=20-th Action selection: 5/2X UP (P(a|s) = 0.628000020980835)\u001b[0m\n",
            "      |->> Bounding box moves to: [331   3  48  46]\n",
            "         |->> Action Probabilities (Rounded): [0.04   0.0308 0.0341 0.0067 0.0513 0.628  0.0351 0.03   0.0016 0.0219\n",
            " 0.1206], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.03998649 0.03082281 0.03407786 0.00674797 0.05127097 0.62798226\n",
            " 0.03508527 0.02996027 0.00155769 0.02186524 0.12064312], argmax=5\n",
            "   \u001b[33m|->> #7/t=21-th Action selection: 5/2X UP (P(a|s) = 0.9890000224113464)\u001b[0m\n",
            "      |->> Bounding box moves to: [331   1  48  46]\n",
            "         |->> Action Probabilities (Rounded): [1.100e-03 7.000e-04 2.000e-04 2.000e-04 7.700e-03 9.892e-01 4.000e-04\n",
            " 1.000e-04 0.000e+00 0.000e+00 4.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.0509931e-03 7.3683856e-04 2.2032071e-04 2.0292637e-04 7.7058394e-03\n",
            " 9.8921633e-01 4.1919059e-04 5.4252363e-05 8.4530966e-06 1.5019059e-05\n",
            " 3.6976213e-04], argmax=5\n",
            "   \u001b[33m|->> #8/t=22-th Action selection: 5/2X UP (P(a|s) = 0.9760000109672546)\u001b[0m\n",
            "      |->> Bounding box moves to: [331   0  48  46]\n",
            "         |->> Action Probabilities (Rounded): [2.100e-03 1.000e-04 5.000e-04 2.000e-04 1.100e-03 9.755e-01 2.000e-04\n",
            " 2.000e-04 0.000e+00 0.000e+00 2.010e-02], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.1298958e-03 5.1754716e-05 4.7583834e-04 1.7891164e-04 1.1406749e-03\n",
            " 9.7553045e-01 1.9734804e-04 1.7821173e-04 1.6973189e-07 3.3866265e-05\n",
            " 2.0082897e-02], argmax=5\n",
            "|->> Revisiting bbox: [331   0  48  46]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [331,  17,  48,  46] -> [331,   0,  48,  46] (Target was [381,  43,  42,  43])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X UP:bbox transition: [331,  17,  48,  46] -> [331,  15,  48,  46] w/ P(a|s)=0.8101602792739868 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for 2X UP:bbox transition: [331,  15,  48,  46] -> [331,  13,  48,  46] w/ P(a|s)=0.9920626282691956 and iou=0.0 and reward=0.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X UP:bbox transition: [331,  13,  48,  46] -> [331,  11,  48,  46] w/ P(a|s)=0.999933123588562 and iou=0.0 and reward=0.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.0) for 2X UP:bbox transition: [331,  11,  48,  46] -> [331,   9,  48,  46] w/ P(a|s)=0.9988226294517517 and iou=0.0 and reward=0.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.0) for 2X UP:bbox transition: [331,   9,  48,  46] -> [331,   7,  48,  46] w/ P(a|s)=0.9678942561149597 and iou=0.0 and reward=0.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.0) for 2X UP:bbox transition: [331,   7,  48,  46] -> [331,   5,  48,  46] w/ P(a|s)=0.9253021478652954 and iou=0.0 and reward=0.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.0) for 2X UP:bbox transition: [331,   5,  48,  46] -> [331,   3,  48,  46] w/ P(a|s)=0.6279822587966919 and iou=0.0 and reward=0.0 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (0.0) for 2X UP:bbox transition: [331,   3,  48,  46] -> [331,   1,  48,  46] w/ P(a|s)=0.9892163276672363 and iou=0.0 and reward=0.0 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (0.0) for 2X UP:bbox transition: [331,   1,  48,  46] -> [331,   0,  48,  46] w/ P(a|s)=0.9755304455757141 and iou=0.0 and reward=0.0 and discount=0.9227446944279201\n",
            "   |->> Assigned losses: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 34 with src: [331,   0,  48,  46] and target: [395,  66,  36,  39]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0034.jpg\n",
            "|->> Beginning tracking for bbox:[331   0  48  46]\n",
            "   \u001b[33m|->> #0/t=23-th Action selection: 1/2X LEFT (P(a|s) = 0.9480000138282776)\u001b[0m\n",
            "      |->> Bounding box moves to: [329   0  48  46]\n",
            "         |->> Action Probabilities (Rounded): [1.750e-02 9.482e-01 0.000e+00 0.000e+00 3.260e-02 9.000e-04 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 8.000e-04], argmax=1\n",
            "         |->> Action Probabilities (RAW): [1.7515514e-02 9.4816869e-01 8.3833163e-11 2.5165680e-06 3.2582842e-02\n",
            " 9.3859824e-04 5.6879824e-11 1.4852081e-12 3.4875086e-22 9.0365901e-12\n",
            " 7.9180946e-04], argmax=1\n",
            "|->> Revisiting bbox: [329   0  48  46]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [331,   0,  48,  46] -> [329,   0,  48,  46] (Target was [395,  66,  36,  39])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X LEFT:bbox transition: [331,   0,  48,  46] -> [329,   0,  48,  46] w/ P(a|s)=0.9481686949729919 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 35 with src: [329,   0,  48,  46] and target: [397,  82,  38,  39]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0035.jpg\n",
            "|->> Beginning tracking for bbox:[329   0  48  46]\n",
            "|->> Revisiting bbox: [329   0  48  46]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=24-th Action selection: 8/STOP (P(a|s) = 0.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [329   0  48  46]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 4.090e-02 0.000e+00 0.000e+00 0.000e+00 9.444e-01 0.000e+00\n",
            " 1.450e-02 0.000e+00 1.000e-04 1.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.4323276e-06 4.0852990e-02 4.2466432e-05 7.1192017e-06 3.7885395e-05\n",
            " 9.4440526e-01 4.8246169e-05 1.4484305e-02 9.7112884e-10 5.1817977e-05\n",
            " 6.7423469e-05], argmax=5\n",
            "         |->> Hit a STOP on the 24-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [329,   0,  48,  46] -> [329,   0,  48,  46] (Target was [397,  82,  38,  39])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [329,   0,  48,  46] -> [329,   0,  48,  46] w/ P(a|s)=9.711288440072963e-10 and iou=0.0 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-11.512925]\n",
            "\u001b[31m>> Total frame loss: -11.512925148010254\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 36 with src: [329,   0,  48,  46] and target: [400,  97,  39,  32]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0036.jpg\n",
            "|->> Beginning tracking for bbox:[329   0  48  46]\n",
            "|->> Revisiting bbox: [329   0  48  46]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=24-th Action selection: 8/STOP (P(a|s) = 0.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [329   0  48  46]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 7.000e-04 0.000e+00 0.000e+00 0.000e+00 9.985e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 8.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [9.8398195e-06 7.0509379e-04 7.1581352e-10 8.8072820e-09 1.8930759e-06\n",
            " 9.9851388e-01 5.9169711e-08 1.1329781e-06 6.3354778e-15 2.1768939e-08\n",
            " 7.6808344e-04], argmax=5\n",
            "         |->> Hit a STOP on the 24-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [329,   0,  48,  46] -> [329,   0,  48,  46] (Target was [400,  97,  39,  32])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [329,   0,  48,  46] -> [329,   0,  48,  46] w/ P(a|s)=6.335477796678632e-15 and iou=0.0 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-11.512925]\n",
            "\u001b[31m>> Total frame loss: -11.512925148010254\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 37 with src: [329,   0,  48,  46] and target: [403, 105,  38,  36]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0037.jpg\n",
            "|->> Beginning tracking for bbox:[329   0  48  46]\n",
            "   \u001b[33m|->> #0/t=24-th Action selection: 1/2X LEFT (P(a|s) = 0.014999999664723873)\u001b[0m\n",
            "      |->> Bounding box moves to: [327   0  48  46]\n",
            "         |->> Action Probabilities (Rounded): [1.000e-04 1.500e-02 0.000e+00 0.000e+00 6.000e-04 8.128e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 1.715e-01], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.09699649e-04 1.50429895e-02 9.97206598e-07 2.95548634e-05\n",
            " 5.76841296e-04 8.12769413e-01 7.14092357e-06 4.50716300e-07\n",
            " 1.83416702e-11 6.51167909e-07 1.71462193e-01], argmax=5\n",
            "|->> Revisiting bbox: [327   0  48  46]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [329,   0,  48,  46] -> [327,   0,  48,  46] (Target was [403, 105,  38,  36])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X LEFT:bbox transition: [329,   0,  48,  46] -> [327,   0,  48,  46] w/ P(a|s)=0.015042989514768124 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 38 with src: [327,   0,  48,  46] and target: [404, 110,  41,  34]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0038.jpg\n",
            "|->> Beginning tracking for bbox:[327   0  48  46]\n",
            "   \u001b[33m|->> #0/t=25-th Action selection: 1/2X LEFT (P(a|s) = 0.968999981880188)\u001b[0m\n",
            "      |->> Bounding box moves to: [325   0  48  46]\n",
            "         |->> Action Probabilities (Rounded): [0.0299 0.9686 0.     0.     0.     0.0015 0.     0.     0.     0.\n",
            " 0.    ], argmax=1\n",
            "         |->> Action Probabilities (RAW): [2.9892225e-02 9.6858704e-01 6.4827865e-12 8.7852733e-16 4.4673098e-12\n",
            " 1.4730484e-03 9.9248005e-08 7.6926167e-11 3.0097481e-16 4.7582744e-05\n",
            " 2.2601108e-10], argmax=1\n",
            "   \u001b[33m|->> #1/t=26-th Action selection: 1/2X LEFT (P(a|s) = 0.9990000128746033)\u001b[0m\n",
            "      |->> Bounding box moves to: [323   0  48  46]\n",
            "         |->> Action Probabilities (Rounded): [3.00e-04 9.99e-01 0.00e+00 0.00e+00 0.00e+00 1.00e-04 0.00e+00 0.00e+00\n",
            " 0.00e+00 6.00e-04 0.00e+00], argmax=1\n",
            "         |->> Action Probabilities (RAW): [3.1632464e-04 9.9897254e-01 8.1898186e-08 8.1773810e-11 7.6209375e-07\n",
            " 7.2864241e-05 1.1903940e-05 8.7810049e-14 1.4160097e-12 6.2554795e-04\n",
            " 3.1181958e-08], argmax=1\n",
            "   \u001b[33m|->> #2/t=27-th Action selection: 1/2X LEFT (P(a|s) = 0.8080000281333923)\u001b[0m\n",
            "      |->> Bounding box moves to: [321   0  48  46]\n",
            "         |->> Action Probabilities (Rounded): [1.467e-01 8.077e-01 0.000e+00 0.000e+00 0.000e+00 4.510e-02 4.000e-04\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=1\n",
            "         |->> Action Probabilities (RAW): [1.46738485e-01 8.07695389e-01 1.07937129e-12 3.02410630e-09\n",
            " 4.82076139e-05 4.51402441e-02 3.63944855e-04 4.88965171e-08\n",
            " 5.18637563e-12 6.99990892e-08 1.35811615e-05], argmax=1\n",
            "   \u001b[33m|->> #3/t=28-th Action selection: 10/SCALE UP (P(a|s) = 0.9959999918937683)\u001b[0m\n",
            "      |->> Bounding box moves to: [320   0  50  48]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 1.000e-04 2.000e-04 0.000e+00 0.000e+00\n",
            " 3.200e-03 0.000e+00 0.000e+00 9.964e-01], argmax=10\n",
            "         |->> Action Probabilities (RAW): [1.61013115e-16 2.11172296e-20 4.32797751e-05 1.16983065e-04\n",
            " 1.94724722e-04 1.02441579e-14 1.13033291e-12 3.21519887e-03\n",
            " 9.06650832e-16 1.15157153e-20 9.96429861e-01], argmax=10\n",
            "|->> Revisiting bbox: [320   0  50  48]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [327,   0,  48,  46] -> [320,   0,  50,  48] (Target was [404, 110,  41,  34])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X LEFT:bbox transition: [327,   0,  48,  46] -> [325,   0,  48,  46] w/ P(a|s)=0.9685870409011841 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for 2X LEFT:bbox transition: [325,   0,  48,  46] -> [323,   0,  48,  46] w/ P(a|s)=0.9989725351333618 and iou=0.0 and reward=0.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X LEFT:bbox transition: [323,   0,  48,  46] -> [321,   0,  48,  46] w/ P(a|s)=0.8076953887939453 and iou=0.0 and reward=0.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.0) for SCALE UP:bbox transition: [321,   0,  48,  46] -> [320,   0,  50,  48] w/ P(a|s)=0.9964298605918884 and iou=0.0 and reward=0.0 and discount=0.970299\n",
            "   |->> Assigned losses: [0. 0. 0. 0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 39 with src: [320,   0,  50,  48] and target: [400, 111,  41,  38]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0039.jpg\n",
            "|->> Beginning tracking for bbox:[320   0  50  48]\n",
            "   \u001b[33m|->> #0/t=29-th Action selection: 1/2X LEFT (P(a|s) = 0.9779999852180481)\u001b[0m\n",
            "      |->> Bounding box moves to: [318   0  50  48]\n",
            "         |->> Action Probabilities (Rounded): [0.0014 0.9781 0.     0.     0.     0.0204 0.     0.     0.     0.\n",
            " 0.    ], argmax=1\n",
            "         |->> Action Probabilities (RAW): [1.4268949e-03 9.7813600e-01 4.1363688e-08 5.3557669e-09 3.1530002e-05\n",
            " 2.0403482e-02 1.4903663e-09 1.4427869e-06 5.4461680e-10 3.9596202e-07\n",
            " 2.7565261e-07], argmax=1\n",
            "   \u001b[33m|->> #1/t=30-th Action selection: 1/2X LEFT (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [316   0  50  48]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 9.996e-01 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            " 4.000e-04 0.000e+00 0.000e+00 0.000e+00], argmax=1\n",
            "         |->> Action Probabilities (RAW): [3.1023593e-08 9.9963295e-01 6.4688102e-11 2.4966573e-18 4.8733834e-16\n",
            " 8.2850992e-16 4.5698410e-12 3.6705288e-04 2.4871861e-13 5.5862995e-11\n",
            " 3.1489775e-09], argmax=1\n",
            "   \u001b[33m|->> #2/t=31-th Action selection: 1/2X LEFT (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [314   0  50  48]\n",
            "         |->> Action Probabilities (Rounded): [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.], argmax=1\n",
            "         |->> Action Probabilities (RAW): [7.1160925e-18 1.0000000e+00 2.9575463e-19 4.9643730e-23 5.9101267e-25\n",
            " 2.3306055e-12 6.3146744e-23 2.8799378e-17 3.9522102e-23 2.2992937e-18\n",
            " 8.1255994e-24], argmax=1\n",
            "   \u001b[33m|->> #3/t=32-th Action selection: 1/2X LEFT (P(a|s) = 0.9990000128746033)\u001b[0m\n",
            "      |->> Bounding box moves to: [312   0  50  48]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 9.987e-01 0.000e+00 0.000e+00 0.000e+00 4.000e-04 1.000e-04\n",
            " 2.000e-04 0.000e+00 0.000e+00 5.000e-04], argmax=1\n",
            "         |->> Action Probabilities (RAW): [8.0645037e-08 9.9866343e-01 3.2133026e-05 1.0946362e-06 2.0802975e-06\n",
            " 3.7744461e-04 1.4058758e-04 2.2232365e-04 3.8680617e-05 1.0061297e-05\n",
            " 5.1214447e-04], argmax=1\n",
            "|->> Revisiting bbox: [312   0  50  48]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [320,   0,  50,  48] -> [312,   0,  50,  48] (Target was [400, 111,  41,  38])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X LEFT:bbox transition: [320,   0,  50,  48] -> [318,   0,  50,  48] w/ P(a|s)=0.9781360030174255 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for 2X LEFT:bbox transition: [318,   0,  50,  48] -> [316,   0,  50,  48] w/ P(a|s)=0.9996329545974731 and iou=0.0 and reward=0.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X LEFT:bbox transition: [316,   0,  50,  48] -> [314,   0,  50,  48] w/ P(a|s)=1.0 and iou=0.0 and reward=0.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.0) for 2X LEFT:bbox transition: [314,   0,  50,  48] -> [312,   0,  50,  48] w/ P(a|s)=0.9986634254455566 and iou=0.0 and reward=0.0 and discount=0.970299\n",
            "   |->> Assigned losses: [0. 0. 0. 0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "Final bounding box: [312   0  50  48] reached in 33 timesteps (originating from [338  19  44  42]). Target was [400 111  41  38]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 40 in t=33 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[31m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 7.7177324295043945\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.027864469215273857\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 1.434564471244812\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.0174923837184906\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 3.9228274822235107\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.01688236929476261\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 2.3128113746643066\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.006399345118552446\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 1.2638590335845947\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.0073579284362494946\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 2.568579912185669\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 0.04360922425985336\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/Matrix\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Starting bounding box for adnet_datasets/OTB/Matrix: frames 1:11 is [336  30  32  40].\n",
            "\u001b[34m>> Attempting to reach frame 2 with src: [336,  30,  32,  40] and target: [336,  20,  32,  42]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0002.jpg\n",
            "|->> Beginning tracking for bbox:[336  30  32  40]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 5/2X UP (P(a|s) = 0.8029999732971191)\u001b[0m\n",
            "      |->> Bounding box moves to: [336  28  32  40]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.1965 0.     0.     0.     0.8035 0.     0.     0.     0.\n",
            " 0.    ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.7844407e-06 1.9651885e-01 1.6134506e-10 1.9905575e-09 9.8291694e-06\n",
            " 8.0346739e-01 4.5319911e-12 9.3956642e-10 8.2354273e-13 5.9239127e-08\n",
            " 6.9898337e-10], argmax=5\n",
            "             |->> IOU declining: [336  28  32  40]:0.7083333333333334 -> [334  28  32  40]:0.6359102244389028.\n",
            "             |->> Overriding with STOP\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 8/STOP (P(a|s) = 0.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [336  28  32  40]\n",
            "         |->> Action Probabilities (Rounded): [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.], argmax=1\n",
            "         |->> Action Probabilities (RAW): [2.1469474e-20 1.0000000e+00 5.9551221e-31 9.4918630e-30 5.8065871e-34\n",
            " 8.0235744e-19 6.8427244e-25 3.8216509e-16 5.6096574e-33 2.2153760e-29\n",
            " 3.2398455e-15], argmax=1\n",
            "         |->> Hit a STOP on the 2-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [336,  30,  32,  40] -> [336,  28,  32,  40] (Target was [336,  20,  32,  42])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.068) for 2X UP:bbox transition: [336,  30,  32,  40] -> [336,  28,  32,  40] w/ P(a|s)=0.8034673929214478 and iou=0.7083333333333334 and reward=0.06833333333333336 and discount=1.0\n",
            "   |->> t=2 Stop-Reward (1.0) for STOP:bbox transition: [336,  28,  32,  40] -> [336,  28,  32,  40] w/ P(a|s)=5.609657406795657e-33 and iou=0.7083333333333334 and reward=1.0 and discount=0.99\n",
            "   |->> Assigned losses: [ 0.01495261 11.397796  ]\n",
            "\u001b[92m>> Total frame loss: 11.412748336791992\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 3 with src: [336,  28,  32,  40] and target: [334,  16,  35,  39]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0003.jpg\n",
            "|->> Beginning tracking for bbox:[336  28  32  40]\n",
            "   \u001b[33m|->> #0/t=2-th Action selection: 4/UP (P(a|s) = 0.7289999723434448)\u001b[0m\n",
            "      |->> Bounding box moves to: [336  27  32  40]\n",
            "         |->> Action Probabilities (Rounded): [7.320e-02 3.600e-03 1.388e-01 1.600e-03 7.290e-01 3.000e-04 2.800e-03\n",
            " 1.450e-02 1.000e-04 0.000e+00 3.620e-02], argmax=4\n",
            "         |->> Action Probabilities (RAW): [7.3182195e-02 3.5845155e-03 1.3875072e-01 1.6267066e-03 7.2896117e-01\n",
            " 3.3107083e-04 2.8078556e-03 1.4522148e-02 5.9761347e-05 1.9529332e-05\n",
            " 3.6154397e-02], argmax=4\n",
            "   \u001b[33m|->> #1/t=3-th Action selection: 5/2X UP (P(a|s) = 0.5509999990463257)\u001b[0m\n",
            "      |->> Bounding box moves to: [336  25  32  40]\n",
            "         |->> Action Probabilities (Rounded): [0.0278 0.0309 0.0987 0.0195 0.1158 0.5511 0.0098 0.0086 0.0126 0.0277\n",
            " 0.0975], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.027812   0.03092186 0.09868106 0.01951235 0.11575317 0.55109257\n",
            " 0.00977955 0.00863687 0.0125738  0.02770649 0.09753028], argmax=5\n",
            "   \u001b[33m|->> #2/t=4-th Action selection: 5/2X UP (P(a|s) = 0.9110000133514404)\u001b[0m\n",
            "      |->> Bounding box moves to: [336  23  32  40]\n",
            "         |->> Action Probabilities (Rounded): [3.200e-03 2.000e-04 2.000e-04 2.000e-04 8.400e-02 9.106e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 1.600e-03 1.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.1656316e-03 1.8115877e-04 1.7705405e-04 1.5313753e-04 8.4015876e-02\n",
            " 9.1059184e-01 5.9368494e-07 5.0765215e-07 6.2534355e-07 1.5783856e-03\n",
            " 1.3518942e-04], argmax=5\n",
            "   \u001b[33m|->> #3/t=5-th Action selection: 5/2X UP (P(a|s) = 0.9020000100135803)\u001b[0m\n",
            "      |->> Bounding box moves to: [336  21  32  40]\n",
            "         |->> Action Probabilities (Rounded): [3.800e-03 4.600e-03 2.100e-03 4.910e-02 3.900e-03 9.021e-01 4.900e-03\n",
            " 3.000e-04 1.000e-03 2.200e-03 2.600e-02], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.8333619e-03 4.5703757e-03 2.1353327e-03 4.9137928e-02 3.8655482e-03\n",
            " 9.0206355e-01 4.8850826e-03 3.2449642e-04 1.0065802e-03 2.1684743e-03\n",
            " 2.6009219e-02], argmax=5\n",
            "   \u001b[33m|->> #4/t=6-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [336  19  32  40]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 2.000e-04 0.000e+00 9.998e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.9967742e-06 4.4818039e-06 1.0452040e-12 1.7665338e-04 8.9291223e-07\n",
            " 9.9979991e-01 2.1967744e-06 8.8373199e-08 1.4322859e-12 7.5253476e-10\n",
            " 1.3765345e-05], argmax=5\n",
            "   \u001b[33m|->> #5/t=7-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [336  17  32  40]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.6813547e-10 9.6062024e-07 2.2338236e-12 6.3706878e-12 4.2848779e-07\n",
            " 9.9999845e-01 2.1886691e-14 1.6435335e-13 1.7477326e-19 1.4483052e-15\n",
            " 1.1007458e-07], argmax=5\n",
            "   \u001b[33m|->> #6/t=8-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [336  15  32  40]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 1.000e-04 1.000e-04 9.998e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [6.3815755e-06 2.3763630e-05 1.8336518e-06 5.6347108e-05 5.3794178e-05\n",
            " 9.9984145e-01 6.9188488e-08 7.4406594e-06 2.1532118e-10 3.0359578e-07\n",
            " 8.6768650e-06], argmax=5\n",
            "   \u001b[33m|->> #7/t=9-th Action selection: 5/2X UP (P(a|s) = 0.9829999804496765)\u001b[0m\n",
            "      |->> Bounding box moves to: [336  13  32  40]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.310e-02 9.833e-01 4.000e-04\n",
            " 2.700e-03 0.000e+00 0.000e+00 4.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.52136594e-05 3.13356736e-06 1.17371965e-05 2.18852801e-06\n",
            " 1.31421685e-02 9.83290195e-01 4.07093554e-04 2.68419366e-03\n",
            " 2.90592220e-06 7.46564820e-06 4.13779257e-04], argmax=5\n",
            "   \u001b[33m|->> #8/t=10-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [336  11  32  40]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 2.000e-04 0.000e+00 0.000e+00 9.998e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.07097875e-07 8.34908249e-08 1.67685270e-04 8.09587220e-07\n",
            " 4.76258901e-06 9.99822319e-01 2.58214266e-11 5.68577718e-08\n",
            " 3.38204603e-11 5.12640197e-09 4.28482008e-06], argmax=5\n",
            "             |->> IOU declining: [336  11  32  40]:0.7344262295081967 -> [336   9  32  40]:0.6645689112649465.\n",
            "             |->> Overriding with STOP\n",
            "   \u001b[33m|->> #9/t=11-th Action selection: 8/STOP (P(a|s) = 0.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [336  11  32  40]\n",
            "         |->> Action Probabilities (Rounded): [1.600e-03 5.000e-04 2.700e-03 1.400e-03 3.900e-02 9.427e-01 0.000e+00\n",
            " 1.000e-04 1.000e-04 3.700e-03 8.200e-03], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.6277104e-03 4.6810598e-04 2.6624494e-03 1.3987898e-03 3.8954914e-02\n",
            " 9.4268066e-01 2.5325247e-05 1.4285621e-04 6.2985106e-05 3.7360031e-03\n",
            " 8.2401587e-03], argmax=5\n",
            "         |->> Hit a STOP on the 11-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [336,  28,  32,  40] -> [336,  11,  32,  40] (Target was [334,  16,  35,  39])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.027) for UP:bbox transition: [336,  28,  32,  40] -> [336,  27,  32,  40] w/ P(a|s)=0.728961169719696 and iou=0.5122927387078331 and reward=0.027172020010472087 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.057) for 2X UP:bbox transition: [336,  27,  32,  40] -> [336,  25,  32,  40] w/ P(a|s)=0.5510925650596619 and iou=0.56973293768546 and reward=0.057440198977626866 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.062) for 2X UP:bbox transition: [336,  25,  32,  40] -> [336,  23,  32,  40] w/ P(a|s)=0.9105918407440186 and iou=0.6317088217149908 and reward=0.0619758840295308 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.067) for 2X UP:bbox transition: [336,  23,  32,  40] -> [336,  21,  32,  40] w/ P(a|s)=0.9020635485649109 and iou=0.6987797045600513 and reward=0.06707088284506058 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.073) for 2X UP:bbox transition: [336,  21,  32,  40] -> [336,  19,  32,  40] w/ P(a|s)=0.999799907207489 and iou=0.7716008037508373 and reward=0.07282109919078594 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.079) for 2X UP:bbox transition: [336,  19,  32,  40] -> [336,  17,  32,  40] w/ P(a|s)=0.9999984502792358 and iou=0.8509447165850245 and reward=0.07934391283418718 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.042) for 2X UP:bbox transition: [336,  17,  32,  40] -> [336,  15,  32,  40] w/ P(a|s)=0.9998414516448975 and iou=0.8933428775948461 and reward=0.04239816100982163 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (-0.083) for 2X UP:bbox transition: [336,  15,  32,  40] -> [336,  13,  32,  40] w/ P(a|s)=0.9832901954650879 and iou=0.810403832991102 and reward=-0.08293904460374413 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (-0.076) for 2X UP:bbox transition: [336,  13,  32,  40] -> [336,  11,  32,  40] w/ P(a|s)=0.9998223185539246 and iou=0.7344262295081967 and reward=-0.07597760348290528 and discount=0.9227446944279201\n",
            "   |->> t=10 Stop-Reward (1.0) for STOP:bbox transition: [336,  11,  32,  40] -> [336,  11,  32,  40] w/ P(a|s)=6.298510561464354e-05 and iou=0.7344262295081967 and reward=1.0 and discount=0.9135172474836408\n",
            "   |->> Assigned losses: [ 8.5900212e-03  3.3883628e-02  5.6891800e-03  6.7076939e-03\n",
            "  1.3998222e-05  7.5558120e-07  6.3292814e-06 -1.3026590e-03\n",
            " -1.2457986e-05  8.8360977e+00]\n",
            "\u001b[92m>> Total frame loss: 8.889674186706543\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 4 with src: [336,  11,  32,  40] and target: [336,  13,  40,  41]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0004.jpg\n",
            "|->> Beginning tracking for bbox:[336  11  32  40]\n",
            "             |->> IOU declining: [336  11  32  40]:0.7136150234741784 -> [336   9  32  40]:0.6515837104072398.\n",
            "             |->> Overriding with STOP\n",
            "   \u001b[33m|->> #0/t=11-th Action selection: 8/STOP (P(a|s) = 0.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [336  11  32  40]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e-04 9.999e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.4412333e-07 1.7135623e-06 2.3713201e-07 5.6729291e-06 1.1699073e-04\n",
            " 9.9985635e-01 2.1189259e-11 4.0237907e-08 2.3670238e-10 2.2624080e-07\n",
            " 1.8527224e-05], argmax=5\n",
            "         |->> Hit a STOP on the 11-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [336,  11,  32,  40] -> [336,  11,  32,  40] (Target was [336,  13,  40,  41])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (1.0) for STOP:bbox transition: [336,  11,  32,  40] -> [336,  11,  32,  40] w/ P(a|s)=2.3670237991879617e-10 and iou=0.7136150234741784 and reward=1.0 and discount=1.0\n",
            "   |->> Assigned losses: [11.512925]\n",
            "\u001b[92m>> Total frame loss: 11.512925148010254\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 5 with src: [336,  11,  32,  40] and target: [341,  14,  40,  42]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0005.jpg\n",
            "|->> Beginning tracking for bbox:[336  11  32  40]\n",
            "   \u001b[33m|->> #0/t=11-th Action selection: 5/2X UP (P(a|s) = 0.8949999809265137)\u001b[0m\n",
            "      |->> Bounding box moves to: [336   9  32  40]\n",
            "         |->> Action Probabilities (Rounded): [2.000e-04 1.000e-04 0.000e+00 4.100e-03 0.000e+00 8.949e-01 0.000e+00\n",
            " 2.110e-02 0.000e+00 0.000e+00 7.960e-02], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.0274814e-04 7.8378966e-05 7.7115737e-06 4.1215955e-03 4.1226758e-06\n",
            " 8.9485997e-01 1.1105810e-05 2.1086797e-02 9.2703175e-08 1.2739717e-06\n",
            " 7.9626210e-02], argmax=5\n",
            "   \u001b[33m|->> #1/t=12-th Action selection: 10/SCALE UP (P(a|s) = 0.597000002861023)\u001b[0m\n",
            "      |->> Bounding box moves to: [335   8  34  42]\n",
            "         |->> Action Probabilities (Rounded): [3.000e-03 2.500e-03 3.000e-04 1.800e-03 0.000e+00 3.949e-01 0.000e+00\n",
            " 9.000e-04 0.000e+00 0.000e+00 5.966e-01], argmax=10\n",
            "         |->> Action Probabilities (RAW): [2.9891715e-03 2.5424887e-03 3.3374375e-04 1.7507346e-03 1.0917601e-07\n",
            " 3.9491472e-01 4.1032040e-06 8.6511701e-04 6.4302380e-10 2.3919182e-09\n",
            " 5.9659982e-01], argmax=10\n",
            "   \u001b[33m|->> #2/t=13-th Action selection: 5/2X UP (P(a|s) = 0.9679999947547913)\u001b[0m\n",
            "      |->> Bounding box moves to: [335   6  34  42]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 1.150e-02 0.000e+00 0.000e+00 0.000e+00 9.685e-01 0.000e+00\n",
            " 1.000e-04 0.000e+00 0.000e+00 1.990e-02], argmax=5\n",
            "         |->> Action Probabilities (RAW): [4.1095558e-05 1.1518405e-02 1.9458949e-07 1.0877122e-06 7.4256983e-09\n",
            " 9.6847177e-01 3.9698580e-08 6.4696243e-05 1.2966633e-11 1.6549083e-12\n",
            " 1.9902702e-02], argmax=5\n",
            "   \u001b[33m|->> #3/t=14-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [335   4  34  42]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.8947801e-10 2.9535346e-07 5.9028764e-09 1.9043900e-07 4.0385217e-10\n",
            " 9.9997163e-01 5.0849928e-07 2.0736743e-05 5.1163412e-10 1.6826347e-12\n",
            " 6.6652588e-06], argmax=5\n",
            "   \u001b[33m|->> #4/t=15-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [335   2  34  42]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.4456857e-14 2.8513725e-06 2.5807183e-16 5.0026983e-11 8.8558062e-16\n",
            " 9.9999392e-01 1.0645251e-14 2.6851180e-06 3.0227710e-19 1.6148498e-15\n",
            " 4.3879518e-07], argmax=5\n",
            "   \u001b[33m|->> #5/t=16-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [335   0  34  42]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [7.5803895e-16 4.1055970e-10 7.2291733e-09 1.2062463e-13 9.0192651e-07\n",
            " 9.9999893e-01 6.4481806e-17 6.0999213e-08 2.1717803e-20 2.5889363e-15\n",
            " 4.6037243e-08], argmax=5\n",
            "|->> Revisiting bbox: [335   0  34  42]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [336,  11,  32,  40] -> [335,   0,  34,  42] (Target was [341,  14,  40,  42])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.04) for 2X UP:bbox transition: [336,  11,  32,  40] -> [336,   9,  32,  40] w/ P(a|s)=0.8948599696159363 and iou=0.46898263027295284 and reward=-0.0404513319911981 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.011) for SCALE UP:bbox transition: [336,   9,  32,  40] -> [335,   8,  34,  42] w/ P(a|s)=0.596599817276001 and iou=0.48 and reward=0.011017369727047144 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-0.038) for 2X UP:bbox transition: [335,   8,  34,  42] -> [335,   6,  34,  42] w/ P(a|s)=0.9684717655181885 and iou=0.44155844155844154 and reward=-0.03844155844155844 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-0.036) for 2X UP:bbox transition: [335,   6,  34,  42] -> [335,   4,  34,  42] w/ P(a|s)=0.9999716281890869 and iou=0.4050632911392405 and reward=-0.03649515041920104 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-0.035) for 2X UP:bbox transition: [335,   4,  34,  42] -> [335,   2,  34,  42] w/ P(a|s)=0.9999939203262329 and iou=0.37037037037037035 and reward=-0.03469292076887015 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-0.033) for 2X UP:bbox transition: [335,   2,  34,  42] -> [335,   0,  34,  42] w/ P(a|s)=0.999998927116394 and iou=0.3373493975903614 and reward=-0.03302097278000893 and discount=0.9509900498999999\n",
            "   |->> Assigned losses: [-4.4936589e-03  5.6336620e-03 -1.2070047e-03 -1.0046942e-06\n",
            " -3.3371305e-07 -3.1445421e-07]\n",
            "\u001b[31m>> Total frame loss: -6.865438626846299e-05\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 6 with src: [335,   0,  34,  42] and target: [351,  20,  35,  42]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0006.jpg\n",
            "|->> Beginning tracking for bbox:[335   0  34  42]\n",
            "|->> Revisiting bbox: [335   0  34  42]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=17-th Action selection: 8/STOP (P(a|s) = 0.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [335   0  34  42]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 5.000e-04 0.000e+00 5.363e-01 0.000e+00 4.632e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=3\n",
            "         |->> Action Probabilities (RAW): [2.3661432e-08 4.7877250e-04 4.0038884e-08 5.3632128e-01 2.7645384e-09\n",
            " 4.6319932e-01 8.5598883e-19 5.1813847e-09 1.2089202e-27 4.0347983e-16\n",
            " 5.5637469e-07], argmax=3\n",
            "         |->> Hit a STOP on the 17-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [335,   0,  34,  42] -> [335,   0,  34,  42] (Target was [351,  20,  35,  42])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [335,   0,  34,  42] -> [335,   0,  34,  42] w/ P(a|s)=1.2089201890839648e-27 and iou=0.15827338129496402 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-11.512925]\n",
            "\u001b[31m>> Total frame loss: -11.512925148010254\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 7 with src: [335,   0,  34,  42] and target: [352,  27,  43,  40]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0007.jpg\n",
            "|->> Beginning tracking for bbox:[335   0  34  42]\n",
            "   \u001b[33m|->> #0/t=17-th Action selection: 7/2X DOWN (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [335   2  34  42]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.0917887e-24 4.5157678e-09 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            " 6.8581147e-33 6.7523784e-34 1.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            " 5.1184373e-18], argmax=7\n",
            "   \u001b[33m|->> #1/t=18-th Action selection: 0/LEFT (P(a|s) = 0.0010000000474974513)\u001b[0m\n",
            "      |->> Bounding box moves to: [334   2  34  42]\n",
            "         |->> Action Probabilities (Rounded): [8.000e-04 3.770e-01 0.000e+00 0.000e+00 3.872e-01 2.349e-01 0.000e+00\n",
            " 1.000e-04 0.000e+00 0.000e+00 0.000e+00], argmax=4\n",
            "         |->> Action Probabilities (RAW): [7.6964003e-04 3.7697658e-01 9.0686913e-24 4.9828583e-18 3.8722879e-01\n",
            " 2.3489124e-01 2.7979136e-11 1.1754555e-04 1.6874604e-18 5.7901210e-12\n",
            " 1.6117576e-05], argmax=4\n",
            "   \u001b[33m|->> #2/t=19-th Action selection: 1/2X LEFT (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [332   2  34  42]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 9.999e-01 0.000e+00 0.000e+00 0.000e+00 1.000e-04 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=1\n",
            "         |->> Action Probabilities (RAW): [1.1889271e-12 9.9985480e-01 0.0000000e+00 0.0000000e+00 5.2285883e-28\n",
            " 1.4512078e-04 4.7222594e-31 9.5122538e-33 0.0000000e+00 6.1909741e-24\n",
            " 0.0000000e+00], argmax=1\n",
            "   \u001b[33m|->> #3/t=20-th Action selection: 1/2X LEFT (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [330   2  34  42]\n",
            "         |->> Action Probabilities (Rounded): [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.], argmax=1\n",
            "         |->> Action Probabilities (RAW): [8.2727690e-21 1.0000000e+00 0.0000000e+00 7.0050131e-35 4.2355275e-38\n",
            " 6.0068325e-20 5.8115058e-12 1.6779377e-25 0.0000000e+00 9.4215684e-27\n",
            " 3.9622940e-23], argmax=1\n",
            "   \u001b[33m|->> #4/t=21-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [330   0  34  42]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [7.2468228e-17 1.7997565e-13 1.2692543e-16 5.5691272e-32 2.3137887e-15\n",
            " 1.0000000e+00 1.3547327e-30 8.3511260e-34 3.6543224e-36 1.4629539e-25\n",
            " 4.8026658e-09], argmax=5\n",
            "   \u001b[33m|->> #5/t=22-th Action selection: 0/LEFT (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [329   0  34  42]\n",
            "         |->> Action Probabilities (Rounded): [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], argmax=0\n",
            "         |->> Action Probabilities (RAW): [9.9999321e-01 1.1707693e-10 3.6577876e-34 0.0000000e+00 9.0190552e-19\n",
            " 8.6030540e-12 2.9090747e-35 1.1344504e-24 0.0000000e+00 0.0000000e+00\n",
            " 6.8445975e-06], argmax=0\n",
            "|->> Revisiting bbox: [329   0  34  42]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [335,   0,  34,  42] -> [329,   0,  34,  42] (Target was [352,  27,  43,  40])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.013) for 2X DOWN:bbox transition: [335,   0,  34,  42] -> [335,   2,  34,  42] w/ P(a|s)=1.0 and iou=0.10108429520811472 and reward=0.012940499839984757 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.007) for LEFT:bbox transition: [335,   2,  34,  42] -> [334,   2,  34,  42] w/ P(a|s)=0.0007696400280110538 and iou=0.09457579972183588 and reward=-0.00650849548627884 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-0.013) for 2X LEFT:bbox transition: [334,   2,  34,  42] -> [332,   2,  34,  42] w/ P(a|s)=0.9998548030853271 and iou=0.08178694158075601 and reward=-0.01278885814107987 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-0.012) for 2X LEFT:bbox transition: [332,   2,  34,  42] -> [330,   2,  34,  42] w/ P(a|s)=1.0 and iou=0.06929347826086957 and reward=-0.012493463319886447 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-0.009) for 2X UP:bbox transition: [330,   2,  34,  42] -> [330,   0,  34,  42] w/ P(a|s)=1.0 and iou=0.06064690026954178 and reward=-0.008646577991327786 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-0.005) for LEFT:bbox transition: [330,   0,  34,  42] -> [329,   0,  34,  42] w/ P(a|s)=0.9999932050704956 and iou=0.05531344284277573 and reward=-0.005333457426766053 and discount=0.9509900498999999\n",
            "   |->> Assigned losses: [ 1.2958138e-07 -4.6196599e-02 -1.8200824e-06 -1.2138918e-07\n",
            " -8.3171891e-08 -5.0789787e-08]\n",
            "\u001b[31m>> Total frame loss: -0.04619854316115379\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 8 with src: [329,   0,  34,  42] and target: [359,  35,  34,  37]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0008.jpg\n",
            "|->> Beginning tracking for bbox:[329   0  34  42]\n",
            "|->> Revisiting bbox: [329   0  34  42]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=23-th Action selection: 8/STOP (P(a|s) = 0.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [329   0  34  42]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 2.000e-04 0.000e+00 9.998e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [5.4069206e-33 3.0201688e-33 2.4856327e-13 1.6593844e-04 2.5322152e-22\n",
            " 9.9983406e-01 2.7689949e-22 4.3810282e-19 3.4378067e-32 1.2332991e-21\n",
            " 3.3150661e-21], argmax=5\n",
            "         |->> Hit a STOP on the 23-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [329,   0,  34,  42] -> [329,   0,  34,  42] (Target was [359,  35,  34,  37])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [329,   0,  34,  42] -> [329,   0,  34,  42] w/ P(a|s)=3.437806697376706e-32 and iou=0.010534236267870579 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-11.512925]\n",
            "\u001b[31m>> Total frame loss: -11.512925148010254\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 9 with src: [329,   0,  34,  42] and target: [365,  46,  33,  35]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0009.jpg\n",
            "|->> Beginning tracking for bbox:[329   0  34  42]\n",
            "   \u001b[33m|->> #0/t=23-th Action selection: 1/2X LEFT (P(a|s) = 0.34599998593330383)\u001b[0m\n",
            "      |->> Bounding box moves to: [327   0  34  42]\n",
            "         |->> Action Probabilities (Rounded): [2.000e-04 3.456e-01 1.030e-02 5.000e-04 8.800e-03 5.755e-01 0.000e+00\n",
            " 2.000e-04 3.000e-04 7.000e-04 5.790e-02], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.3646657e-04 3.4559688e-01 1.0313796e-02 5.0098303e-04 8.7930122e-03\n",
            " 5.7549518e-01 2.3566968e-09 1.7893492e-04 2.6901384e-04 6.8746728e-04\n",
            " 5.7928242e-02], argmax=5\n",
            "   \u001b[33m|->> #1/t=24-th Action selection: 7/2X DOWN (P(a|s) = 0.7229999899864197)\u001b[0m\n",
            "      |->> Bounding box moves to: [327   2  34  42]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 5.770e-02 0.000e+00 0.000e+00 0.000e+00 2.194e-01 1.000e-04\n",
            " 7.227e-01 0.000e+00 0.000e+00 0.000e+00], argmax=7\n",
            "         |->> Action Probabilities (RAW): [3.9554179e-06 5.7709388e-02 2.0208201e-05 1.0673533e-06 7.5800091e-07\n",
            " 2.1936698e-01 1.0563126e-04 7.2274566e-01 8.3131296e-10 3.7385216e-05\n",
            " 8.9628302e-06], argmax=7\n",
            "|->> Revisiting bbox: [327   0  34  42]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [329,   0,  34,  42] -> [327,   2,  34,  42] (Target was [365,  46,  33,  35])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X LEFT:bbox transition: [329,   0,  34,  42] -> [327,   0,  34,  42] w/ P(a|s)=0.34559687972068787 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for 2X DOWN:bbox transition: [327,   0,  34,  42] -> [327,   2,  34,  42] w/ P(a|s)=0.7227456569671631 and iou=0.0 and reward=0.0 and discount=0.99\n",
            "   |->> Assigned losses: [0. 0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 10 with src: [327,   2,  34,  42] and target: [369,  50,  37,  45]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0010.jpg\n",
            "|->> Beginning tracking for bbox:[327   2  34  42]\n",
            "   \u001b[33m|->> #0/t=25-th Action selection: 5/2X UP (P(a|s) = 0.8769999742507935)\u001b[0m\n",
            "      |->> Bounding box moves to: [327   0  34  42]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.0452 0.074  0.     0.8773 0.     0.0034 0.     0.\n",
            " 0.    ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.51345220e-09 1.39317216e-08 4.52005602e-02 7.40052983e-02\n",
            " 1.50936576e-05 8.77298057e-01 2.31052880e-07 3.44320387e-03\n",
            " 1.58350790e-08 4.95477650e-07 3.70602611e-05], argmax=5\n",
            "   \u001b[33m|->> #1/t=26-th Action selection: 2/RIGHT (P(a|s) = 0.8830000162124634)\u001b[0m\n",
            "      |->> Bounding box moves to: [328   0  34  42]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 8.828e-01 3.900e-03 0.000e+00 8.300e-02 0.000e+00\n",
            " 4.000e-04 1.000e-04 0.000e+00 2.970e-02], argmax=2\n",
            "         |->> Action Probabilities (RAW): [1.9916279e-05 1.9712621e-08 8.8281298e-01 3.8527718e-03 4.4168963e-05\n",
            " 8.3032236e-02 1.5435115e-05 3.7929878e-04 6.6141511e-05 4.5759734e-05\n",
            " 2.9731255e-02], argmax=2\n",
            "   \u001b[33m|->> #2/t=27-th Action selection: 2/RIGHT (P(a|s) = 0.8840000033378601)\u001b[0m\n",
            "      |->> Bounding box moves to: [329   0  34  42]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 8.843e-01 1.680e-02 1.000e-04 1.020e-02 0.000e+00\n",
            " 6.600e-03 1.000e-04 1.000e-04 8.180e-02], argmax=2\n",
            "         |->> Action Probabilities (RAW): [1.34215625e-05 4.78053039e-07 8.84330988e-01 1.67852938e-02\n",
            " 5.40200745e-05 1.01896785e-02 1.55647886e-05 6.57717185e-03\n",
            " 1.33370122e-04 1.07818705e-04 8.17922577e-02], argmax=2\n",
            "|->> Revisiting bbox: [327   0  34  42]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [327,   2,  34,  42] -> [329,   0,  34,  42] (Target was [369,  50,  37,  45])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X UP:bbox transition: [327,   2,  34,  42] -> [327,   0,  34,  42] w/ P(a|s)=0.8772980570793152 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for RIGHT:bbox transition: [327,   0,  34,  42] -> [328,   0,  34,  42] w/ P(a|s)=0.8828129768371582 and iou=0.0 and reward=0.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.0) for RIGHT:bbox transition: [328,   0,  34,  42] -> [329,   0,  34,  42] w/ P(a|s)=0.8843309879302979 and iou=0.0 and reward=0.0 and discount=0.9801\n",
            "   |->> Assigned losses: [0. 0. 0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 11 with src: [329,   0,  34,  42] and target: [372,  60,  35,  41]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0011.jpg\n",
            "|->> Beginning tracking for bbox:[329   0  34  42]\n",
            "|->> Revisiting bbox: [329   0  34  42]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=28-th Action selection: 8/STOP (P(a|s) = 0.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [329   0  34  42]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.0081 0.     0.     0.     0.9919 0.     0.     0.     0.\n",
            " 0.    ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.3218685e-07 8.0704447e-03 1.1124623e-08 9.3039674e-08 3.7560803e-09\n",
            " 9.9192190e-01 1.2951391e-12 7.3455503e-06 3.5382541e-14 2.8856819e-09\n",
            " 3.5197929e-09], argmax=5\n",
            "         |->> Hit a STOP on the 28-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [329,   0,  34,  42] -> [329,   0,  34,  42] (Target was [372,  60,  35,  41])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [329,   0,  34,  42] -> [329,   0,  34,  42] w/ P(a|s)=3.538254148764512e-14 and iou=0.0 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-11.512925]\n",
            "\u001b[31m>> Total frame loss: -11.512925148010254\u001b[0m\n",
            "Final bounding box: [329   0  34  42] reached in 28 timesteps (originating from [336  30  32  40]). Target was [372  60  35  41]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 12 in t=28 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[31m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 94.0540771484375\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.1588076949119568\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 77.15996551513672\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.44491228461265564\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 120.3811264038086\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.5106246471405029\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 84.09928894042969\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.19299204647541046\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 38.50218200683594\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.20927947759628296\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 66.37213897705078\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 1.2276667356491089\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/Matrix\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Starting bounding box for adnet_datasets/OTB/Matrix: frames 30:40 is [347  18  42  44].\n",
            "\u001b[34m>> Attempting to reach frame 31 with src: [347,  18,  42,  44] and target: [357,  22,  40,  43]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0031.jpg\n",
            "|->> Beginning tracking for bbox:[347  18  42  44]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 2/RIGHT (P(a|s) = 0.39399999380111694)\u001b[0m\n",
            "      |->> Bounding box moves to: [348  18  42  44]\n",
            "         |->> Action Probabilities (Rounded): [4.000e-03 0.000e+00 3.941e-01 5.831e-01 4.000e-04 1.000e-04 0.000e+00\n",
            " 0.000e+00 1.820e-02 0.000e+00 0.000e+00], argmax=3\n",
            "         |->> Action Probabilities (RAW): [3.9601806e-03 2.9713287e-09 3.9411464e-01 5.8313119e-01 4.1971632e-04\n",
            " 1.2885747e-04 1.2416341e-08 6.9857835e-09 1.8186834e-02 2.0945885e-05\n",
            " 3.7593192e-05], argmax=3\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 2/RIGHT (P(a|s) = 0.9700000286102295)\u001b[0m\n",
            "      |->> Bounding box moves to: [349  18  42  44]\n",
            "         |->> Action Probabilities (Rounded): [1.000e-04 0.000e+00 9.703e-01 6.000e-04 3.000e-04 1.000e-04 0.000e+00\n",
            " 0.000e+00 2.840e-02 1.000e-04 0.000e+00], argmax=2\n",
            "         |->> Action Probabilities (RAW): [1.1502964e-04 1.6894581e-11 9.7034991e-01 5.7435018e-04 3.1968864e-04\n",
            " 8.7856046e-05 9.5023343e-06 4.4769696e-08 2.8408544e-02 1.0341325e-04\n",
            " 3.1748634e-05], argmax=2\n",
            "   \u001b[33m|->> #2/t=3-th Action selection: 4/UP (P(a|s) = 0.41600000858306885)\u001b[0m\n",
            "      |->> Bounding box moves to: [349  17  42  44]\n",
            "         |->> Action Probabilities (Rounded): [4.000e-04 0.000e+00 5.284e-01 0.000e+00 4.164e-01 1.900e-03 2.400e-03\n",
            " 0.000e+00 6.600e-03 0.000e+00 4.380e-02], argmax=2\n",
            "         |->> Action Probabilities (RAW): [4.0186651e-04 1.0441656e-07 5.2843004e-01 1.1125563e-05 4.1642523e-01\n",
            " 1.8973871e-03 2.3645284e-03 1.6637993e-06 6.6343211e-03 6.9204625e-06\n",
            " 4.3826837e-02], argmax=2\n",
            "   \u001b[33m|->> #3/t=4-th Action selection: 5/2X UP (P(a|s) = 0.32600000500679016)\u001b[0m\n",
            "      |->> Bounding box moves to: [349  15  42  44]\n",
            "         |->> Action Probabilities (Rounded): [1.580e-02 0.000e+00 3.662e-01 3.000e-04 2.049e-01 3.261e-01 3.010e-02\n",
            " 1.030e-02 6.900e-03 1.400e-03 3.800e-02], argmax=2\n",
            "         |->> Action Probabilities (RAW): [1.5844285e-02 2.6495376e-05 3.6622247e-01 2.9597175e-04 2.0489150e-01\n",
            " 3.2608387e-01 3.0104235e-02 1.0285470e-02 6.8612210e-03 1.3502979e-03\n",
            " 3.8034238e-02], argmax=2\n",
            "   \u001b[33m|->> #4/t=5-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [349  13  42  44]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.1377255e-17 2.5091347e-21 2.0348581e-08 5.0283498e-14 3.3699656e-08\n",
            " 1.0000000e+00 2.4064978e-25 5.2244714e-17 8.2231744e-23 1.3910385e-24\n",
            " 5.4208022e-13], argmax=5\n",
            "   \u001b[33m|->> #5/t=6-th Action selection: 2/RIGHT (P(a|s) = 0.8529999852180481)\u001b[0m\n",
            "      |->> Bounding box moves to: [350  13  42  44]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 4.100e-03 8.534e-01 0.000e+00 4.300e-03 7.990e-02 1.000e-04\n",
            " 1.640e-02 0.000e+00 0.000e+00 4.180e-02], argmax=2\n",
            "         |->> Action Probabilities (RAW): [5.0900456e-07 4.0648165e-03 8.5343671e-01 3.9576084e-05 4.3040551e-03\n",
            " 7.9884082e-02 8.6503802e-05 1.6406780e-02 1.9661489e-07 9.9612066e-07\n",
            " 4.1775692e-02], argmax=2\n",
            "   \u001b[33m|->> #6/t=7-th Action selection: 7/2X DOWN (P(a|s) = 0.996999979019165)\u001b[0m\n",
            "      |->> Bounding box moves to: [350  15  42  44]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.0018 0.     0.     0.     0.     0.9968 0.     0.\n",
            " 0.0013], argmax=7\n",
            "         |->> Action Probabilities (RAW): [7.2746498e-09 2.8746401e-08 1.8348051e-03 3.0960695e-05 1.3164200e-06\n",
            " 4.8191208e-07 1.2170896e-05 9.9684310e-01 7.1509298e-10 2.4848286e-09\n",
            " 1.2772275e-03], argmax=7\n",
            "|->> Revisiting bbox: [350  13  42  44]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [347,  18,  42,  44] -> [350,  15,  42,  44] (Target was [357,  22,  40,  43])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.028) for RIGHT:bbox transition: [347,  18,  42,  44] -> [348,  18,  42,  44] w/ P(a|s)=0.3941146433353424 and iou=0.5871886120996441 and reward=0.027748052659084643 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.029) for RIGHT:bbox transition: [348,  18,  42,  44] -> [349,  18,  42,  44] w/ P(a|s)=0.970349907875061 and iou=0.6159420289855072 and reward=0.02875341688586308 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-0.025) for UP:bbox transition: [349,  18,  42,  44] -> [349,  17,  42,  44] w/ P(a|s)=0.4164252281188965 and iou=0.5914362176628011 and reward=-0.024505811322706128 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-0.047) for 2X UP:bbox transition: [349,  17,  42,  44] -> [349,  15,  42,  44] w/ P(a|s)=0.32608386874198914 and iou=0.5445887445887446 and reward=-0.046847473074056456 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-0.044) for 2X UP:bbox transition: [349,  15,  42,  44] -> [349,  13,  42,  44] w/ P(a|s)=1.0 and iou=0.5004205214465938 and reward=-0.04416822314215085 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.022) for RIGHT:bbox transition: [349,  13,  42,  44] -> [350,  13,  42,  44] w/ P(a|s)=0.8534367084503174 and iou=0.5228339735381989 and reward=0.02241345209160517 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.047) for 2X DOWN:bbox transition: [350,  13,  42,  44] -> [350,  15,  42,  44] w/ P(a|s)=0.9968430995941162 and iou=0.5697316322041355 and reward=0.04689765866593654 and discount=0.941480149401\n",
            "   |->> Assigned losses: [ 2.5836583e-02  8.5678155e-04 -2.1041054e-02 -5.0938088e-02\n",
            " -4.2485649e-07  3.3780793e-03  1.3960777e-04]\n",
            "\u001b[31m>> Total frame loss: -0.04176851361989975\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 32 with src: [350,  15,  42,  44] and target: [369,  30,  40,  45]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0032.jpg\n",
            "|->> Beginning tracking for bbox:[350  15  42  44]\n",
            "   \u001b[33m|->> #0/t=8-th Action selection: 3/2X RIGHT (P(a|s) = 0.8429999947547913)\u001b[0m\n",
            "      |->> Bounding box moves to: [352  15  42  44]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 2.200e-02 8.428e-01 4.500e-03 1.238e-01 2.100e-03\n",
            " 4.700e-03 0.000e+00 0.000e+00 1.000e-04], argmax=3\n",
            "         |->> Action Probabilities (RAW): [1.6082287e-06 1.0195159e-07 2.2003274e-02 8.4277421e-01 4.4711274e-03\n",
            " 1.2384488e-01 2.0831814e-03 4.7449246e-03 1.3838032e-07 4.7235844e-06\n",
            " 7.1823197e-05], argmax=3\n",
            "   \u001b[33m|->> #1/t=9-th Action selection: 7/2X DOWN (P(a|s) = 0.7689999938011169)\u001b[0m\n",
            "      |->> Bounding box moves to: [352  17  42  44]\n",
            "         |->> Action Probabilities (Rounded): [2.000e-04 3.000e-04 0.000e+00 0.000e+00 4.500e-03 2.253e-01 0.000e+00\n",
            " 7.690e-01 0.000e+00 5.000e-04 2.000e-04], argmax=7\n",
            "         |->> Action Probabilities (RAW): [2.2654762e-04 3.3293263e-04 2.8347256e-06 2.2923533e-08 4.5076506e-03\n",
            " 2.2528887e-01 4.7478652e-06 7.6895916e-01 1.5753596e-08 5.1811640e-04\n",
            " 1.5899551e-04], argmax=7\n",
            "|->> Revisiting bbox: [352  15  42  44]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [350,  15,  42,  44] -> [352,  17,  42,  44] (Target was [369,  30,  40,  45])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.024) for 2X RIGHT:bbox transition: [350,  15,  42,  44] -> [352,  15,  42,  44] w/ P(a|s)=0.8427742123603821 and iou=0.24803284296955183 and reward=0.024282423647176782 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.022) for 2X DOWN:bbox transition: [352,  15,  42,  44] -> [352,  17,  42,  44] w/ P(a|s)=0.7689591646194458 and iou=0.2697528715628263 and reward=0.02172002859327446 and discount=0.99\n",
            "   |->> Assigned losses: [0.00415366 0.00564917]\n",
            "\u001b[92m>> Total frame loss: 0.00980282761156559\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 33 with src: [352,  17,  42,  44] and target: [381,  43,  42,  43]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0033.jpg\n",
            "|->> Beginning tracking for bbox:[352  17  42  44]\n",
            "   \u001b[33m|->> #0/t=10-th Action selection: 0/LEFT (P(a|s) = 0.9909999966621399)\u001b[0m\n",
            "      |->> Bounding box moves to: [351  17  42  44]\n",
            "         |->> Action Probabilities (Rounded): [0.991  0.0026 0.     0.     0.     0.     0.     0.     0.     0.\n",
            " 0.0065], argmax=0\n",
            "         |->> Action Probabilities (RAW): [9.9097967e-01 2.5559806e-03 1.0097199e-07 2.9788338e-12 3.0575782e-07\n",
            " 5.5127282e-07 5.3993938e-09 4.5670707e-11 9.2737595e-11 4.5920460e-06\n",
            " 6.4588902e-03], argmax=0\n",
            "   \u001b[33m|->> #1/t=11-th Action selection: 9/SCALE DOWN (P(a|s) = 0.7120000123977661)\u001b[0m\n",
            "      |->> Bounding box moves to: [352  18  40  42]\n",
            "         |->> Action Probabilities (Rounded): [1.670e-02 6.610e-02 4.100e-03 2.000e-04 9.710e-02 5.080e-02 0.000e+00\n",
            " 0.000e+00 0.000e+00 7.116e-01 5.340e-02], argmax=9\n",
            "         |->> Action Probabilities (RAW): [1.6690709e-02 6.6060230e-02 4.1432143e-03 2.0910443e-04 9.7110949e-02\n",
            " 5.0763063e-02 3.9465263e-07 2.0748398e-07 2.0252044e-06 7.1162665e-01\n",
            " 5.3393416e-02], argmax=9\n",
            "   \u001b[33m|->> #2/t=12-th Action selection: 9/SCALE DOWN (P(a|s) = 0.9160000085830688)\u001b[0m\n",
            "      |->> Bounding box moves to: [353  19  38  40]\n",
            "         |->> Action Probabilities (Rounded): [1.100e-03 6.200e-03 6.000e-04 0.000e+00 6.100e-02 6.900e-03 0.000e+00\n",
            " 0.000e+00 0.000e+00 9.163e-01 7.800e-03], argmax=9\n",
            "         |->> Action Probabilities (RAW): [1.0827392e-03 6.2481984e-03 5.7272776e-04 2.2577512e-06 6.1036430e-02\n",
            " 6.9201626e-03 5.0517640e-10 4.2304499e-10 4.6856496e-09 9.1633391e-01\n",
            " 7.8035393e-03], argmax=9\n",
            "   \u001b[33m|->> #3/t=13-th Action selection: 9/SCALE DOWN (P(a|s) = 0.5189999938011169)\u001b[0m\n",
            "      |->> Bounding box moves to: [354  20  36  38]\n",
            "         |->> Action Probabilities (Rounded): [0.0026 0.0169 0.0107 0.0144 0.2485 0.1415 0.     0.     0.     0.519\n",
            " 0.0463], argmax=9\n",
            "         |->> Action Probabilities (RAW): [2.5880891e-03 1.6877769e-02 1.0728802e-02 1.4433066e-02 2.4852961e-01\n",
            " 1.4147651e-01 5.2294045e-06 1.2555856e-05 5.1892430e-06 5.1901078e-01\n",
            " 4.6332426e-02], argmax=9\n",
            "   \u001b[33m|->> #4/t=14-th Action selection: 5/2X UP (P(a|s) = 0.9589999914169312)\u001b[0m\n",
            "      |->> Bounding box moves to: [354  18  36  38]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 1.000e-04 2.000e-04 1.000e-03 2.590e-02 9.595e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 1.310e-02 3.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.6242353e-06 9.7725359e-05 1.9548659e-04 9.5133693e-04 2.5926780e-02\n",
            " 9.5945019e-01 4.8041647e-11 9.6304985e-11 2.1087144e-08 1.3052635e-02\n",
            " 3.2323683e-04], argmax=5\n",
            "   \u001b[33m|->> #5/t=15-th Action selection: 5/2X UP (P(a|s) = 0.30399999022483826)\u001b[0m\n",
            "      |->> Bounding box moves to: [354  16  36  38]\n",
            "         |->> Action Probabilities (Rounded): [6.000e-04 1.600e-03 5.042e-01 1.616e-01 1.410e-02 3.037e-01 1.000e-04\n",
            " 0.000e+00 5.000e-04 2.900e-03 1.060e-02], argmax=2\n",
            "         |->> Action Probabilities (RAW): [6.2499469e-04 1.5567166e-03 5.0422519e-01 1.6164435e-01 1.4107507e-02\n",
            " 3.0367619e-01 1.3156566e-04 1.6683811e-05 5.0280860e-04 2.9242348e-03\n",
            " 1.0589709e-02], argmax=2\n",
            "   \u001b[33m|->> #6/t=16-th Action selection: 5/2X UP (P(a|s) = 0.9570000171661377)\u001b[0m\n",
            "      |->> Bounding box moves to: [354  14  36  38]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 1.000e-04 4.100e-03 2.600e-02 2.300e-03 9.571e-01 0.000e+00\n",
            " 0.000e+00 2.200e-03 6.300e-03 1.800e-03], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.6138605e-05 1.4566330e-04 4.0862979e-03 2.6026385e-02 2.3061230e-03\n",
            " 9.5705694e-01 1.2312590e-05 3.6471747e-07 2.2094562e-03 6.2977634e-03\n",
            " 1.8226320e-03], argmax=5\n",
            "   \u001b[33m|->> #7/t=17-th Action selection: 1/2X LEFT (P(a|s) = 0.8339999914169312)\u001b[0m\n",
            "      |->> Bounding box moves to: [352  14  36  38]\n",
            "         |->> Action Probabilities (Rounded): [1.760e-02 8.339e-01 1.880e-02 0.000e+00 4.000e-04 1.150e-02 2.100e-03\n",
            " 9.380e-02 0.000e+00 1.000e-04 2.190e-02], argmax=1\n",
            "         |->> Action Probabilities (RAW): [1.7594695e-02 8.3385998e-01 1.8806141e-02 1.4620390e-05 3.8632765e-04\n",
            " 1.1527884e-02 2.0653352e-03 9.3792245e-02 1.7371931e-07 5.4011864e-05\n",
            " 2.1898624e-02], argmax=1\n",
            "   \u001b[33m|->> #8/t=18-th Action selection: 7/2X DOWN (P(a|s) = 0.7839999794960022)\u001b[0m\n",
            "      |->> Bounding box moves to: [352  16  36  38]\n",
            "         |->> Action Probabilities (Rounded): [5.380e-02 8.690e-02 6.200e-03 1.800e-03 1.100e-03 1.940e-02 2.780e-02\n",
            " 7.839e-01 1.900e-03 7.000e-04 1.650e-02], argmax=7\n",
            "         |->> Action Probabilities (RAW): [5.3752225e-02 8.6885445e-02 6.1773863e-03 1.7570461e-03 1.1122301e-03\n",
            " 1.9442847e-02 2.7789736e-02 7.8389508e-01 1.9168084e-03 7.2876055e-04\n",
            " 1.6542351e-02], argmax=7\n",
            "   \u001b[33m|->> #9/t=19-th Action selection: 10/SCALE UP (P(a|s) = 0.12399999797344208)\u001b[0m\n",
            "      |->> Bounding box moves to: [351  15  38  40]\n",
            "         |->> Action Probabilities (Rounded): [2.756e-01 7.380e-02 5.660e-02 4.120e-02 1.109e-01 2.898e-01 2.550e-02\n",
            " 1.900e-03 2.000e-04 4.000e-04 1.239e-01], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.7563509e-01 7.3827907e-02 5.6613017e-02 4.1246947e-02 1.1088601e-01\n",
            " 2.8984645e-01 2.5503542e-02 1.8901026e-03 2.2519173e-04 4.4745707e-04\n",
            " 1.2387836e-01], argmax=5\n",
            "   \u001b[33m|->> #10/t=20-th Action selection: 5/2X UP (P(a|s) = 0.9629999995231628)\u001b[0m\n",
            "      |->> Bounding box moves to: [351  13  38  40]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 1.000e-04 1.900e-03 1.400e-02 1.950e-02 9.635e-01 0.000e+00\n",
            " 2.000e-04 0.000e+00 0.000e+00 8.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [4.9536357e-06 7.0915776e-05 1.9344559e-03 1.3984578e-02 1.9540239e-02\n",
            " 9.6347195e-01 1.2195661e-06 1.9236800e-04 2.1795984e-08 7.4133600e-06\n",
            " 7.9192739e-04], argmax=5\n",
            "   \u001b[33m|->> #11/t=21-th Action selection: 10/SCALE UP (P(a|s) = 0.13699999451637268)\u001b[0m\n",
            "      |->> Bounding box moves to: [350  12  40  42]\n",
            "         |->> Action Probabilities (Rounded): [2.523e-01 5.110e-02 5.000e-04 8.000e-04 3.000e-04 9.500e-03 1.369e-01\n",
            " 4.107e-01 2.000e-04 6.000e-04 1.371e-01], argmax=7\n",
            "         |->> Action Probabilities (RAW): [2.5225297e-01 5.1073626e-02 5.3275941e-04 8.2067057e-04 3.0382478e-04\n",
            " 9.4926860e-03 1.3692056e-01 4.1071898e-01 1.8982387e-04 5.9396471e-04\n",
            " 1.3710022e-01], argmax=7\n",
            "   \u001b[33m|->> #12/t=22-th Action selection: 5/2X UP (P(a|s) = 0.7409999966621399)\u001b[0m\n",
            "      |->> Bounding box moves to: [350  10  40  42]\n",
            "         |->> Action Probabilities (Rounded): [0.0251 0.176  0.     0.     0.0091 0.7413 0.0013 0.0448 0.     0.0023\n",
            " 0.    ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.5076818e-02 1.7597885e-01 3.4831231e-05 1.4113612e-05 9.0745408e-03\n",
            " 7.4130958e-01 1.3426050e-03 4.4812504e-02 3.1734119e-06 2.3374551e-03\n",
            " 1.5533669e-05], argmax=5\n",
            "   \u001b[33m|->> #13/t=23-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [350   8  40  42]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 1.000e-04 0.000e+00 0.000e+00 9.999e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [5.5700379e-08 1.5736747e-06 6.1070074e-05 6.4196308e-07 2.0906268e-07\n",
            " 9.9990523e-01 1.0743311e-05 1.1147159e-05 1.1822443e-07 1.1128868e-07\n",
            " 9.0464036e-06], argmax=5\n",
            "   \u001b[33m|->> #14/t=24-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [350   6  40  42]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [8.1273306e-14 5.1608731e-11 6.8943728e-16 3.5375399e-15 2.4343544e-10\n",
            " 1.0000000e+00 3.7082843e-16 1.1394933e-17 2.1557420e-15 3.7479072e-11\n",
            " 6.2698002e-12], argmax=5\n",
            "   \u001b[33m|->> #15/t=25-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [350   4  40  42]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [6.5586425e-13 3.9227643e-10 3.2461983e-10 3.9248882e-11 5.2959399e-07\n",
            " 9.9999952e-01 4.3017774e-14 1.4906653e-23 1.8594317e-12 6.2162164e-11\n",
            " 2.8784669e-08], argmax=5\n",
            "   \u001b[33m|->> #16/t=26-th Action selection: 10/SCALE UP (P(a|s) = 0.7419999837875366)\u001b[0m\n",
            "      |->> Bounding box moves to: [349   3  42  44]\n",
            "         |->> Action Probabilities (Rounded): [9.480e-02 3.900e-03 8.000e-03 1.600e-03 6.020e-02 4.100e-03 3.300e-03\n",
            " 3.970e-02 4.220e-02 2.000e-04 7.421e-01], argmax=10\n",
            "         |->> Action Probabilities (RAW): [9.4842754e-02 3.9054663e-03 8.0222208e-03 1.5632495e-03 6.0220044e-02\n",
            " 4.0814532e-03 3.2852492e-03 3.9666250e-02 4.2174578e-02 1.7862536e-04\n",
            " 7.4206012e-01], argmax=10\n",
            "   \u001b[33m|->> #17/t=27-th Action selection: 3/2X RIGHT (P(a|s) = 0.18400000035762787)\u001b[0m\n",
            "      |->> Bounding box moves to: [351   3  42  44]\n",
            "         |->> Action Probabilities (Rounded): [2.700e-03 4.000e-04 4.670e-02 1.840e-01 4.890e-02 6.010e-02 1.000e-04\n",
            " 5.163e-01 3.000e-04 2.000e-04 1.404e-01], argmax=7\n",
            "         |->> Action Probabilities (RAW): [2.7094805e-03 3.6545197e-04 4.6665546e-02 1.8401694e-01 4.8869405e-02\n",
            " 6.0063548e-02 6.4749212e-05 5.1634991e-01 2.5972901e-04 2.4776804e-04\n",
            " 1.4038751e-01], argmax=7\n",
            "   \u001b[33m|->> #18/t=28-th Action selection: 3/2X RIGHT (P(a|s) = 0.9980000257492065)\u001b[0m\n",
            "      |->> Bounding box moves to: [353   3  42  44]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 9.982e-01 0.000e+00 0.000e+00 0.000e+00\n",
            " 3.000e-04 0.000e+00 0.000e+00 1.500e-03], argmax=3\n",
            "         |->> Action Probabilities (RAW): [1.2909822e-14 2.2123141e-13 2.2596197e-07 9.9817181e-01 4.6572182e-09\n",
            " 3.8115090e-06 1.1663305e-09 2.7877354e-04 1.6115169e-19 5.1958719e-19\n",
            " 1.5453272e-03], argmax=3\n",
            "   \u001b[33m|->> #19/t=29-th Action selection: 7/2X DOWN (P(a|s) = 0.6259999871253967)\u001b[0m\n",
            "      |->> Bounding box moves to: [353   5  42  44]\n",
            "         |->> Action Probabilities (Rounded): [3.670e-02 0.000e+00 4.070e-02 3.130e-02 3.000e-04 3.000e-04 1.210e-01\n",
            " 6.263e-01 0.000e+00 0.000e+00 1.434e-01], argmax=7\n",
            "         |->> Action Probabilities (RAW): [3.6660802e-02 1.1621669e-06 4.0749475e-02 3.1327285e-02 2.9684699e-04\n",
            " 2.7137401e-04 1.2099103e-01 6.2626326e-01 1.7529086e-07 9.9223968e-08\n",
            " 1.4343846e-01], argmax=7\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [352,  17,  42,  44] -> [353,   5,  42,  44] (Target was [381,  43,  42,  43])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.006) for LEFT:bbox transition: [352,  17,  42,  44] -> [351,  17,  42,  44] w/ P(a|s)=0.9909796714782715 and iou=0.06282722513089005 and reward=-0.005593827500688903 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.006) for SCALE DOWN:bbox transition: [351,  17,  42,  44] -> [352,  18,  40,  42] w/ P(a|s)=0.7116266489028931 and iou=0.05668384358896635 and reward=-0.006143381541923697 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-0.006) for SCALE DOWN:bbox transition: [352,  18,  40,  42] -> [353,  19,  38,  40] w/ P(a|s)=0.9163339138031006 and iou=0.05053695514845231 and reward=-0.006146888440514045 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-0.006) for SCALE DOWN:bbox transition: [353,  19,  38,  40] -> [354,  20,  36,  38] w/ P(a|s)=0.5190107822418213 and iou=0.044422507403751234 and reward=-0.006114447744701074 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-0.006) for 2X UP:bbox transition: [354,  20,  36,  38] -> [354,  18,  36,  38] w/ P(a|s)=0.9594501852989197 and iou=0.038272816486751716 and reward=-0.006149690916999517 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-0.006) for 2X UP:bbox transition: [354,  18,  36,  38] -> [354,  16,  36,  38] w/ P(a|s)=0.30367618799209595 and iou=0.03219512195121951 and reward=-0.0060776945355322035 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (-0.006) for 2X UP:bbox transition: [354,  16,  36,  38] -> [354,  14,  36,  38] w/ P(a|s)=0.9570569396018982 and iou=0.026188166828322017 and reward=-0.006006955122897496 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (-0.006) for 2X LEFT:bbox transition: [354,  14,  36,  38] -> [352,  14,  36,  38] w/ P(a|s)=0.8338599801063538 and iou=0.020250723240115717 and reward=-0.0059374435882063 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (0.005) for 2X DOWN:bbox transition: [352,  14,  36,  38] -> [352,  16,  36,  38] w/ P(a|s)=0.7838950753211975 and iou=0.02486277042298999 and reward=0.004612047182874272 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (0.005) for SCALE UP:bbox transition: [352,  16,  36,  38] -> [351,  15,  38,  40] w/ P(a|s)=0.1238783597946167 and iou=0.029721362229102165 and reward=0.004858591806112176 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (-0.005) for 2X UP:bbox transition: [351,  15,  38,  40] -> [351,  13,  38,  40] w/ P(a|s)=0.9634719491004944 and iou=0.024645717806531114 and reward=-0.005075644422571052 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (0.005) for SCALE UP:bbox transition: [351,  13,  38,  40] -> [350,  12,  40,  42] w/ P(a|s)=0.1371002197265625 and iou=0.029229406554472984 and reward=0.004583688747941871 and discount=0.8953382542587164\n",
            "   |->> t=13 Diff-Reward (-0.005) for 2X UP:bbox transition: [350,  12,  40,  42] -> [350,  10,  40,  42] w/ P(a|s)=0.7413095831871033 and iou=0.02378854625550661 and reward=-0.005440860298966375 and discount=0.8863848717161292\n",
            "   |->> t=14 Diff-Reward (-0.005) for 2X UP:bbox transition: [350,  10,  40,  42] -> [350,   8,  40,  42] w/ P(a|s)=0.9999052286148071 and iou=0.018404907975460124 and reward=-0.005383638280046486 and discount=0.8775210229989678\n",
            "   |->> t=15 Diff-Reward (-0.005) for 2X UP:bbox transition: [350,   8,  40,  42] -> [350,   6,  40,  42] w/ P(a|s)=1.0 and iou=0.013077593722755012 and reward=-0.005327314252705112 and discount=0.8687458127689782\n",
            "   |->> t=16 Diff-Reward (-0.005) for 2X UP:bbox transition: [350,   6,  40,  42] -> [350,   4,  40,  42] w/ P(a|s)=0.9999995231628418 and iou=0.007805724197745013 and reward=-0.005271869525009999 and discount=0.8600583546412884\n",
            "   |->> t=17 Diff-Reward (0.003) for SCALE UP:bbox transition: [350,   4,  40,  42] -> [349,   3,  42,  44] w/ P(a|s)=0.742060124874115 and iou=0.011068068622025456 and reward=0.0032623444242804427 and discount=0.8514577710948755\n",
            "   |->> t=18 Diff-Reward (0.002) for 2X RIGHT:bbox transition: [349,   3,  42,  44] -> [351,   3,  42,  44] w/ P(a|s)=0.18401694297790527 and iou=0.013311148086522463 and reward=0.002243079464497007 and discount=0.8429431933839268\n",
            "   |->> t=19 Diff-Reward (0.002) for 2X RIGHT:bbox transition: [351,   3,  42,  44] -> [353,   3,  42,  44] w/ P(a|s)=0.9981718063354492 and iou=0.01556420233463035 and reward=0.0022530542481078875 and discount=0.8345137614500875\n",
            "   |->> t=20 Diff-Reward (0.008) for 2X DOWN:bbox transition: [353,   3,  42,  44] -> [353,   5,  42,  44] w/ P(a|s)=0.6262632608413696 and iou=0.023529411764705882 and reward=0.007965209430075532 and discount=0.8261686238355866\n",
            "   |->> Assigned losses: [-5.0687115e-05 -2.0690900e-03 -5.2639307e-04 -3.8909400e-03\n",
            " -2.4453484e-04 -6.8883593e-03 -2.4823032e-04 -1.0054868e-03\n",
            "  1.0361886e-03  9.2694145e-03 -1.7081460e-04  8.1547303e-03\n",
            " -1.4436111e-03 -4.4774546e-07 -4.6343899e-08 -4.5402956e-08\n",
            "  8.2867185e-04  3.2005897e-03  3.4405246e-06  3.0796214e-03]\n",
            "\u001b[92m>> Total frame loss: 0.009033969603478909\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 34 with src: [353,   5,  42,  44] and target: [395,  66,  36,  39]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0034.jpg\n",
            "|->> Beginning tracking for bbox:[353   5  42  44]\n",
            "   \u001b[33m|->> #0/t=30-th Action selection: 5/2X UP (P(a|s) = 0.8830000162124634)\u001b[0m\n",
            "      |->> Bounding box moves to: [353   3  42  44]\n",
            "         |->> Action Probabilities (Rounded): [9.800e-03 1.052e-01 0.000e+00 0.000e+00 0.000e+00 8.832e-01 0.000e+00\n",
            " 1.600e-03 1.000e-04 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [9.83447861e-03 1.05243154e-01 1.38386795e-07 6.82105292e-06\n",
            " 1.91995696e-05 8.83170128e-01 3.19093215e-06 1.62992196e-03\n",
            " 7.55422589e-05 4.14954548e-06 1.32960076e-05], argmax=5\n",
            "   \u001b[33m|->> #1/t=31-th Action selection: 0/LEFT (P(a|s) = 0.6320000290870667)\u001b[0m\n",
            "      |->> Bounding box moves to: [352   3  42  44]\n",
            "         |->> Action Probabilities (Rounded): [0.632  0.0726 0.0468 0.0135 0.0276 0.0204 0.0152 0.0342 0.0172 0.1194\n",
            " 0.0011], argmax=0\n",
            "         |->> Action Probabilities (RAW): [0.63195413 0.07260434 0.0467692  0.01350736 0.02757052 0.02043718\n",
            " 0.01524787 0.03419306 0.01718524 0.11940711 0.0011239 ], argmax=0\n",
            "   \u001b[33m|->> #2/t=32-th Action selection: 3/2X RIGHT (P(a|s) = 0.9459999799728394)\u001b[0m\n",
            "      |->> Bounding box moves to: [354   3  42  44]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 4.700e-03 9.464e-01 0.000e+00 2.000e-04 0.000e+00\n",
            " 0.000e+00 0.000e+00 4.860e-02 0.000e+00], argmax=3\n",
            "         |->> Action Probabilities (RAW): [3.6441159e-07 1.3034967e-08 4.7218129e-03 9.4640696e-01 2.7514087e-08\n",
            " 2.2794912e-04 4.8181778e-06 3.3930857e-07 1.9898853e-05 4.8616953e-02\n",
            " 9.5293029e-07], argmax=3\n",
            "|->> Revisiting bbox: [352   3  42  44]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [353,   5,  42,  44] -> [354,   3,  42,  44] (Target was [395,  66,  36,  39])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X UP:bbox transition: [353,   5,  42,  44] -> [353,   3,  42,  44] w/ P(a|s)=0.8831701278686523 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for LEFT:bbox transition: [353,   3,  42,  44] -> [352,   3,  42,  44] w/ P(a|s)=0.6319541335105896 and iou=0.0 and reward=0.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X RIGHT:bbox transition: [352,   3,  42,  44] -> [354,   3,  42,  44] w/ P(a|s)=0.9464069604873657 and iou=0.0 and reward=0.0 and discount=0.9801\n",
            "   |->> Assigned losses: [0. 0. 0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 35 with src: [354,   3,  42,  44] and target: [397,  82,  38,  39]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0035.jpg\n",
            "|->> Beginning tracking for bbox:[354   3  42  44]\n",
            "   \u001b[33m|->> #0/t=33-th Action selection: 5/2X UP (P(a|s) = 0.15600000321865082)\u001b[0m\n",
            "      |->> Bounding box moves to: [354   1  42  44]\n",
            "         |->> Action Probabilities (Rounded): [0.016  0.0051 0.3592 0.0772 0.2884 0.1565 0.0023 0.     0.002  0.0037\n",
            " 0.0896], argmax=2\n",
            "         |->> Action Probabilities (RAW): [1.5971558e-02 5.0767055e-03 3.5924244e-01 7.7227607e-02 2.8837174e-01\n",
            " 1.5649512e-01 2.3264082e-03 3.1370906e-05 1.9586456e-03 3.7265013e-03\n",
            " 8.9571901e-02], argmax=2\n",
            "   \u001b[33m|->> #1/t=34-th Action selection: 4/UP (P(a|s) = 0.703000009059906)\u001b[0m\n",
            "      |->> Bounding box moves to: [354   0  42  44]\n",
            "         |->> Action Probabilities (Rounded): [1.540e-02 0.000e+00 1.879e-01 7.000e-03 7.030e-01 2.980e-02 2.050e-02\n",
            " 7.000e-04 5.000e-04 2.300e-03 3.290e-02], argmax=4\n",
            "         |->> Action Probabilities (RAW): [1.5354808e-02 8.4737567e-06 1.8788837e-01 7.0184823e-03 7.0304573e-01\n",
            " 2.9829858e-02 2.0458547e-02 7.1852910e-04 4.8246153e-04 2.2716604e-03\n",
            " 3.2923147e-02], argmax=4\n",
            "|->> Revisiting bbox: [354   1  42  44]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [354,   3,  42,  44] -> [354,   0,  42,  44] (Target was [397,  82,  38,  39])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X UP:bbox transition: [354,   3,  42,  44] -> [354,   1,  42,  44] w/ P(a|s)=0.1564951241016388 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for UP:bbox transition: [354,   1,  42,  44] -> [354,   0,  42,  44] w/ P(a|s)=0.7030457258224487 and iou=0.0 and reward=0.0 and discount=0.99\n",
            "   |->> Assigned losses: [0. 0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 36 with src: [354,   0,  42,  44] and target: [400,  97,  39,  32]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0036.jpg\n",
            "|->> Beginning tracking for bbox:[354   0  42  44]\n",
            "   \u001b[33m|->> #0/t=35-th Action selection: 10/SCALE UP (P(a|s) = 0.9480000138282776)\u001b[0m\n",
            "      |->> Bounding box moves to: [353   0  44  46]\n",
            "         |->> Action Probabilities (Rounded): [3.000e-04 8.000e-03 4.120e-02 1.800e-03 0.000e+00 1.000e-04 8.000e-04\n",
            " 2.000e-04 0.000e+00 0.000e+00 9.477e-01], argmax=10\n",
            "         |->> Action Probabilities (RAW): [2.5569237e-04 8.0074677e-03 4.1187223e-02 1.7648918e-03 1.1432997e-05\n",
            " 5.8515925e-05 8.3909498e-04 1.8983713e-04 1.6565240e-05 2.6545415e-06\n",
            " 9.4766670e-01], argmax=10\n",
            "   \u001b[33m|->> #1/t=36-th Action selection: 2/RIGHT (P(a|s) = 0.17000000178813934)\u001b[0m\n",
            "      |->> Bounding box moves to: [354   0  44  46]\n",
            "         |->> Action Probabilities (Rounded): [3.400e-03 8.000e-04 1.703e-01 2.489e-01 1.000e-04 8.000e-04 3.000e-04\n",
            " 1.000e-04 1.700e-03 1.000e-04 5.735e-01], argmax=10\n",
            "         |->> Action Probabilities (RAW): [3.4346925e-03 8.2380470e-04 1.7027418e-01 2.4894467e-01 1.1866583e-04\n",
            " 7.7026658e-04 2.8901172e-04 6.2946907e-05 1.6665603e-03 1.0094568e-04\n",
            " 5.7351428e-01], argmax=10\n",
            "   \u001b[33m|->> #2/t=37-th Action selection: 2/RIGHT (P(a|s) = 0.14800000190734863)\u001b[0m\n",
            "      |->> Bounding box moves to: [355   0  44  46]\n",
            "         |->> Action Probabilities (Rounded): [4.000e-03 2.100e-03 1.476e-01 3.031e-01 4.000e-04 1.400e-03 3.000e-04\n",
            " 1.000e-04 1.500e-03 1.000e-04 5.393e-01], argmax=10\n",
            "         |->> Action Probabilities (RAW): [3.9776256e-03 2.1421623e-03 1.4760344e-01 3.0314732e-01 4.3730042e-04\n",
            " 1.3936479e-03 3.2435733e-04 6.9558628e-05 1.5129304e-03 8.4995234e-05\n",
            " 5.3930670e-01], argmax=10\n",
            "   \u001b[33m|->> #3/t=38-th Action selection: 2/RIGHT (P(a|s) = 0.3930000066757202)\u001b[0m\n",
            "      |->> Bounding box moves to: [356   0  44  46]\n",
            "         |->> Action Probabilities (Rounded): [1.460e-02 2.000e-04 3.926e-01 2.260e-02 0.000e+00 5.000e-04 6.000e-04\n",
            " 0.000e+00 2.000e-04 0.000e+00 5.687e-01], argmax=10\n",
            "         |->> Action Probabilities (RAW): [1.4644652e-02 1.5577790e-04 3.9257935e-01 2.2597525e-02 1.1546081e-05\n",
            " 5.3945772e-04 5.9644965e-04 2.7989201e-06 1.9984650e-04 9.7155262e-06\n",
            " 5.6866288e-01], argmax=10\n",
            "   \u001b[33m|->> #4/t=39-th Action selection: 3/2X RIGHT (P(a|s) = 0.8519999980926514)\u001b[0m\n",
            "      |->> Bounding box moves to: [358   0  44  46]\n",
            "         |->> Action Probabilities (Rounded): [5.000e-04 0.000e+00 2.490e-02 8.519e-01 0.000e+00 2.100e-03 0.000e+00\n",
            " 0.000e+00 4.000e-04 0.000e+00 1.202e-01], argmax=3\n",
            "         |->> Action Probabilities (RAW): [5.2624528e-04 1.2094346e-05 2.4885988e-02 8.5189575e-01 3.7000245e-06\n",
            " 2.0730046e-03 2.4284825e-06 2.6830701e-08 4.2258709e-04 2.7919489e-07\n",
            " 1.2017797e-01], argmax=3\n",
            "|->> Revisiting bbox: [356   0  44  46]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [354,   0,  42,  44] -> [358,   0,  44,  46] (Target was [400,  97,  39,  32])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for SCALE UP:bbox transition: [354,   0,  42,  44] -> [353,   0,  44,  46] w/ P(a|s)=0.9476667046546936 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for RIGHT:bbox transition: [353,   0,  44,  46] -> [354,   0,  44,  46] w/ P(a|s)=0.17027418315410614 and iou=0.0 and reward=0.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.0) for RIGHT:bbox transition: [354,   0,  44,  46] -> [355,   0,  44,  46] w/ P(a|s)=0.14760343730449677 and iou=0.0 and reward=0.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.0) for RIGHT:bbox transition: [355,   0,  44,  46] -> [356,   0,  44,  46] w/ P(a|s)=0.3925793468952179 and iou=0.0 and reward=0.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.0) for 2X RIGHT:bbox transition: [356,   0,  44,  46] -> [358,   0,  44,  46] w/ P(a|s)=0.8518957495689392 and iou=0.0 and reward=0.0 and discount=0.96059601\n",
            "   |->> Assigned losses: [0. 0. 0. 0. 0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 37 with src: [358,   0,  44,  46] and target: [403, 105,  38,  36]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0037.jpg\n",
            "|->> Beginning tracking for bbox:[358   0  44  46]\n",
            "   \u001b[33m|->> #0/t=40-th Action selection: 9/SCALE DOWN (P(a|s) = 0.006000000052154064)\u001b[0m\n",
            "      |->> Bounding box moves to: [359   1  42  44]\n",
            "         |->> Action Probabilities (Rounded): [0.0075 0.2288 0.0031 0.0017 0.0014 0.7148 0.     0.     0.     0.0058\n",
            " 0.0368], argmax=5\n",
            "         |->> Action Probabilities (RAW): [7.4546463e-03 2.2879061e-01 3.0642820e-03 1.7339408e-03 1.4272219e-03\n",
            " 7.1479923e-01 2.9516976e-05 2.5978781e-05 3.2726701e-05 5.8476711e-03\n",
            " 3.6794230e-02], argmax=5\n",
            "   \u001b[33m|->> #1/t=41-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [359   0  42  44]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.2983617e-05 9.2261798e-06 4.2051890e-10 4.2766089e-08 7.4709493e-07\n",
            " 9.9997640e-01 1.5587634e-11 4.8067889e-08 6.3508483e-11 3.1502518e-07\n",
            " 2.7499348e-07], argmax=5\n",
            "|->> Revisiting bbox: [359   0  42  44]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [358,   0,  44,  46] -> [359,   0,  42,  44] (Target was [403, 105,  38,  36])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for SCALE DOWN:bbox transition: [358,   0,  44,  46] -> [359,   1,  42,  44] w/ P(a|s)=0.005847671069204807 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for 2X UP:bbox transition: [359,   1,  42,  44] -> [359,   0,  42,  44] w/ P(a|s)=0.999976396560669 and iou=0.0 and reward=0.0 and discount=0.99\n",
            "   |->> Assigned losses: [0. 0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 38 with src: [359,   0,  42,  44] and target: [404, 110,  41,  34]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0038.jpg\n",
            "|->> Beginning tracking for bbox:[359   0  42  44]\n",
            "   \u001b[33m|->> #0/t=42-th Action selection: 10/SCALE UP (P(a|s) = 0.8169999718666077)\u001b[0m\n",
            "      |->> Bounding box moves to: [358   0  44  46]\n",
            "         |->> Action Probabilities (Rounded): [0.0017 0.0057 0.     0.0016 0.     0.0752 0.0401 0.0589 0.     0.\n",
            " 0.8168], argmax=10\n",
            "         |->> Action Probabilities (RAW): [1.7105149e-03 5.7073883e-03 6.7706230e-07 1.5912582e-03 2.5930624e-06\n",
            " 7.5154044e-02 4.0085640e-02 5.8901735e-02 2.4891392e-07 4.8434531e-06\n",
            " 8.1684113e-01], argmax=10\n",
            "   \u001b[33m|->> #1/t=43-th Action selection: 7/2X DOWN (P(a|s) = 0.6579999923706055)\u001b[0m\n",
            "      |->> Bounding box moves to: [358   2  44  46]\n",
            "         |->> Action Probabilities (Rounded): [1.000e-04 0.000e+00 1.000e-04 7.210e-02 0.000e+00 0.000e+00 2.398e-01\n",
            " 6.583e-01 0.000e+00 0.000e+00 2.970e-02], argmax=7\n",
            "         |->> Action Probabilities (RAW): [5.6461085e-05 1.0346939e-06 1.2357935e-04 7.2098747e-02 4.2438555e-06\n",
            " 6.2325188e-07 2.3976336e-01 6.5826833e-01 9.5853022e-07 9.6827557e-07\n",
            " 2.9681714e-02], argmax=7\n",
            "   \u001b[33m|->> #2/t=44-th Action selection: 7/2X DOWN (P(a|s) = 0.6330000162124634)\u001b[0m\n",
            "      |->> Bounding box moves to: [358   4  44  46]\n",
            "         |->> Action Probabilities (Rounded): [0.0474 0.3199 0.     0.     0.     0.     0.     0.6327 0.     0.\n",
            " 0.    ], argmax=7\n",
            "         |->> Action Probabilities (RAW): [4.7367163e-02 3.1992522e-01 5.8076933e-15 6.6841965e-14 1.6732850e-12\n",
            " 6.2798455e-10 2.8161299e-08 6.3270760e-01 9.4250296e-09 7.7192848e-15\n",
            " 3.5065024e-19], argmax=7\n",
            "   \u001b[33m|->> #3/t=45-th Action selection: 2/RIGHT (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [359   4  44  46]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.], argmax=2\n",
            "         |->> Action Probabilities (RAW): [5.65667133e-26 1.10082689e-11 9.99999762e-01 1.90050697e-14\n",
            " 9.20038061e-24 2.21697263e-07 1.99889367e-12 1.33990735e-11\n",
            " 5.22220271e-23 8.26098690e-25 1.39741007e-16], argmax=2\n",
            "   \u001b[33m|->> #4/t=46-th Action selection: 4/UP (P(a|s) = 0.9990000128746033)\u001b[0m\n",
            "      |->> Bounding box moves to: [359   3  44  46]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 0.000e+00 9.991e-01 6.000e-04 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 3.000e-04], argmax=4\n",
            "         |->> Action Probabilities (RAW): [1.8391462e-07 3.2594094e-11 3.3500926e-13 2.1608861e-37 9.9911028e-01\n",
            " 6.3395390e-04 1.1835165e-15 1.7396647e-19 1.3327658e-16 1.5863877e-06\n",
            " 2.5392824e-04], argmax=4\n",
            "   \u001b[33m|->> #5/t=47-th Action selection: 2/RIGHT (P(a|s) = 0.8059999942779541)\u001b[0m\n",
            "      |->> Bounding box moves to: [360   3  44  46]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 8.065e-01 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            " 0.000e+00 1.000e-04 0.000e+00 1.934e-01], argmax=2\n",
            "         |->> Action Probabilities (RAW): [2.9297098e-10 2.4077608e-12 8.0649453e-01 4.4770186e-16 3.9036323e-07\n",
            " 7.6997108e-15 1.0741667e-05 1.4498248e-10 8.2108141e-05 2.7173303e-12\n",
            " 1.9341217e-01], argmax=2\n",
            "   \u001b[33m|->> #6/t=48-th Action selection: 4/UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [360   2  44  46]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], argmax=4\n",
            "         |->> Action Probabilities (RAW): [8.0586973e-26 4.6405263e-23 1.4860483e-14 2.4101989e-26 9.9999988e-01\n",
            " 7.6853937e-08 5.3460154e-26 1.2710523e-30 1.7130446e-31 5.8681926e-22\n",
            " 2.9705384e-11], argmax=4\n",
            "   \u001b[33m|->> #7/t=49-th Action selection: 2/RIGHT (P(a|s) = 0.328000009059906)\u001b[0m\n",
            "      |->> Bounding box moves to: [361   2  44  46]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.3276 0.5055 0.     0.0924 0.     0.0083 0.     0.\n",
            " 0.0661], argmax=3\n",
            "         |->> Action Probabilities (RAW): [5.6337458e-16 1.1983406e-17 3.2763466e-01 5.0553000e-01 1.4822416e-06\n",
            " 9.2421889e-02 5.0503946e-12 8.3185416e-03 5.5243737e-18 2.9230135e-18\n",
            " 6.6093415e-02], argmax=3\n",
            "   \u001b[33m|->> #8/t=50-th Action selection: 3/2X RIGHT (P(a|s) = 0.8349999785423279)\u001b[0m\n",
            "      |->> Bounding box moves to: [363   2  44  46]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 1.643e-01 8.351e-01 0.000e+00 0.000e+00 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 6.000e-04], argmax=3\n",
            "         |->> Action Probabilities (RAW): [6.4406915e-27 9.8157655e-24 1.6431099e-01 8.3512157e-01 1.5826980e-15\n",
            " 8.4782155e-12 5.6856525e-10 3.8366241e-11 1.5079076e-29 2.3901143e-34\n",
            " 5.6749221e-04], argmax=3\n",
            "   \u001b[33m|->> #9/t=51-th Action selection: 3/2X RIGHT (P(a|s) = 0.6710000038146973)\u001b[0m\n",
            "      |->> Bounding box moves to: [365   2  44  46]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.3268 0.6712 0.     0.     0.     0.     0.     0.\n",
            " 0.002 ], argmax=3\n",
            "         |->> Action Probabilities (RAW): [2.2808432e-13 1.1163030e-16 3.2678437e-01 6.7117828e-01 3.6301506e-10\n",
            " 8.4047726e-13 4.1022405e-10 7.5851754e-13 2.2281404e-12 1.0336912e-14\n",
            " 2.0373666e-03], argmax=3\n",
            "   \u001b[33m|->> #10/t=52-th Action selection: 2/RIGHT (P(a|s) = 0.14000000059604645)\u001b[0m\n",
            "      |->> Bounding box moves to: [366   2  44  46]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 1.403e-01 7.442e-01 1.000e-03 1.000e-04 1.000e-04\n",
            " 0.000e+00 0.000e+00 0.000e+00 1.142e-01], argmax=3\n",
            "         |->> Action Probabilities (RAW): [2.6453681e-05 1.3307537e-06 1.4029823e-01 7.4424618e-01 1.0257591e-03\n",
            " 7.9919773e-05 8.2979081e-05 1.4365645e-05 1.3932128e-06 4.3186154e-07\n",
            " 1.1422286e-01], argmax=3\n",
            "   \u001b[33m|->> #11/t=53-th Action selection: 5/2X UP (P(a|s) = 0.27900001406669617)\u001b[0m\n",
            "      |->> Bounding box moves to: [366   0  44  46]\n",
            "         |->> Action Probabilities (Rounded): [9.000e-04 0.000e+00 4.584e-01 8.290e-02 2.260e-02 2.790e-01 1.500e-03\n",
            " 4.000e-04 0.000e+00 0.000e+00 1.543e-01], argmax=2\n",
            "         |->> Action Probabilities (RAW): [8.7288354e-04 2.6061214e-06 4.5835868e-01 8.2901478e-02 2.2591023e-02\n",
            " 2.7900511e-01 1.5200728e-03 4.1047504e-04 1.7031751e-07 4.7668615e-07\n",
            " 1.5433702e-01], argmax=2\n",
            "|->> Revisiting bbox: [366   0  44  46]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [359,   0,  42,  44] -> [366,   0,  44,  46] (Target was [404, 110,  41,  34])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for SCALE UP:bbox transition: [359,   0,  42,  44] -> [358,   0,  44,  46] w/ P(a|s)=0.8168411254882812 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for 2X DOWN:bbox transition: [358,   0,  44,  46] -> [358,   2,  44,  46] w/ P(a|s)=0.6582683324813843 and iou=0.0 and reward=0.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X DOWN:bbox transition: [358,   2,  44,  46] -> [358,   4,  44,  46] w/ P(a|s)=0.6327075958251953 and iou=0.0 and reward=0.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.0) for RIGHT:bbox transition: [358,   4,  44,  46] -> [359,   4,  44,  46] w/ P(a|s)=0.9999997615814209 and iou=0.0 and reward=0.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.0) for UP:bbox transition: [359,   4,  44,  46] -> [359,   3,  44,  46] w/ P(a|s)=0.9991102814674377 and iou=0.0 and reward=0.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.0) for RIGHT:bbox transition: [359,   3,  44,  46] -> [360,   3,  44,  46] w/ P(a|s)=0.8064945340156555 and iou=0.0 and reward=0.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.0) for UP:bbox transition: [360,   3,  44,  46] -> [360,   2,  44,  46] w/ P(a|s)=0.9999998807907104 and iou=0.0 and reward=0.0 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (0.0) for RIGHT:bbox transition: [360,   2,  44,  46] -> [361,   2,  44,  46] w/ P(a|s)=0.32763466238975525 and iou=0.0 and reward=0.0 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (0.0) for 2X RIGHT:bbox transition: [361,   2,  44,  46] -> [363,   2,  44,  46] w/ P(a|s)=0.8351215720176697 and iou=0.0 and reward=0.0 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (0.0) for 2X RIGHT:bbox transition: [363,   2,  44,  46] -> [365,   2,  44,  46] w/ P(a|s)=0.6711782813072205 and iou=0.0 and reward=0.0 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (0.0) for RIGHT:bbox transition: [365,   2,  44,  46] -> [366,   2,  44,  46] w/ P(a|s)=0.14029823243618011 and iou=0.0 and reward=0.0 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (0.0) for 2X UP:bbox transition: [366,   2,  44,  46] -> [366,   0,  44,  46] w/ P(a|s)=0.27900511026382446 and iou=0.0 and reward=0.0 and discount=0.8953382542587164\n",
            "   |->> Assigned losses: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 39 with src: [366,   0,  44,  46] and target: [400, 111,  41,  38]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0039.jpg\n",
            "|->> Beginning tracking for bbox:[366   0  44  46]\n",
            "   \u001b[33m|->> #0/t=54-th Action selection: 1/2X LEFT (P(a|s) = 0.20800000429153442)\u001b[0m\n",
            "      |->> Bounding box moves to: [364   0  44  46]\n",
            "         |->> Action Probabilities (Rounded): [0.2287 0.208  0.0007 0.0112 0.0006 0.009  0.0036 0.4455 0.     0.\n",
            " 0.0927], argmax=7\n",
            "         |->> Action Probabilities (RAW): [2.2870550e-01 2.0795019e-01 7.1155687e-04 1.1170687e-02 5.7382445e-04\n",
            " 9.0439245e-03 3.5838680e-03 4.4550884e-01 1.4358560e-06 9.0250987e-06\n",
            " 9.2741162e-02], argmax=7\n",
            "|->> Revisiting bbox: [364   0  44  46]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [366,   0,  44,  46] -> [364,   0,  44,  46] (Target was [400, 111,  41,  38])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X LEFT:bbox transition: [366,   0,  44,  46] -> [364,   0,  44,  46] w/ P(a|s)=0.2079501897096634 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 40 with src: [364,   0,  44,  46] and target: [395, 115,  47,  48]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0040.jpg\n",
            "|->> Beginning tracking for bbox:[364   0  44  46]\n",
            "   \u001b[33m|->> #0/t=55-th Action selection: 7/2X DOWN (P(a|s) = 0.47699999809265137)\u001b[0m\n",
            "      |->> Bounding box moves to: [364   2  44  46]\n",
            "         |->> Action Probabilities (Rounded): [2.500e-03 2.300e-03 1.084e-01 2.140e-02 2.030e-02 2.382e-01 3.000e-04\n",
            " 4.774e-01 3.090e-02 9.370e-02 4.600e-03], argmax=7\n",
            "         |->> Action Probabilities (RAW): [2.54073599e-03 2.29807501e-03 1.08417965e-01 2.14113276e-02\n",
            " 2.02540196e-02 2.38213331e-01 2.73523037e-04 4.77409065e-01\n",
            " 3.08710188e-02 9.37236845e-02 4.58738115e-03], argmax=7\n",
            "   \u001b[33m|->> #1/t=56-th Action selection: 9/SCALE DOWN (P(a|s) = 0.2630000114440918)\u001b[0m\n",
            "      |->> Bounding box moves to: [365   3  42  44]\n",
            "         |->> Action Probabilities (Rounded): [4.100e-03 2.000e-04 8.640e-02 1.500e-03 5.400e-03 4.217e-01 3.000e-04\n",
            " 1.764e-01 1.300e-03 2.631e-01 3.950e-02], argmax=5\n",
            "         |->> Action Probabilities (RAW): [4.1099424e-03 2.1191720e-04 8.6395107e-02 1.4863465e-03 5.4470720e-03\n",
            " 4.2170644e-01 3.0872316e-04 1.7644320e-01 1.2683182e-03 2.6312208e-01\n",
            " 3.9500937e-02], argmax=5\n",
            "|->> Revisiting bbox: [364   2  44  46]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [364,   0,  44,  46] -> [365,   3,  42,  44] (Target was [395, 115,  47,  48])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X DOWN:bbox transition: [364,   0,  44,  46] -> [364,   2,  44,  46] w/ P(a|s)=0.4774090647697449 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for SCALE DOWN:bbox transition: [364,   2,  44,  46] -> [365,   3,  42,  44] w/ P(a|s)=0.2631220817565918 and iou=0.0 and reward=0.0 and discount=0.99\n",
            "   |->> Assigned losses: [0. 0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "Final bounding box: [365   3  42  44] reached in 57 timesteps (originating from [347  18  42  44]). Target was [395 115  47  48]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 41 in t=57 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[31m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 10.070384979248047\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.008334357291460037\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 3.306159019470215\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.018421916291117668\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 5.226210594177246\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.0232985932379961\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 3.9439210891723633\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.011119009926915169\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 2.798027992248535\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.013432503677904606\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 5.470489501953125\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 0.07157572358846664\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/Matrix\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Starting bounding box for adnet_datasets/OTB/Matrix: frames 78:88 is [324 138  70  94].\n",
            "\u001b[34m>> Attempting to reach frame 79 with src: [324, 138,  70,  94] and target: [337, 158,  68,  90]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0079.jpg\n",
            "|->> Beginning tracking for bbox:[324 138  70  94]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 9/SCALE DOWN (P(a|s) = 0.06700000166893005)\u001b[0m\n",
            "      |->> Bounding box moves to: [325 139  67  91]\n",
            "         |->> Action Probabilities (Rounded): [4.419e-01 1.100e-02 0.000e+00 2.100e-03 4.297e-01 3.000e-04 0.000e+00\n",
            " 0.000e+00 1.000e-04 6.730e-02 4.760e-02], argmax=0\n",
            "         |->> Action Probabilities (RAW): [4.41916257e-01 1.10362964e-02 2.44397743e-05 2.09027110e-03\n",
            " 4.29695427e-01 3.07005248e-04 1.20586865e-05 2.43451055e-08\n",
            " 5.52418933e-05 6.73103184e-02 4.75526378e-02], argmax=0\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 4/UP (P(a|s) = 0.9539999961853027)\u001b[0m\n",
            "      |->> Bounding box moves to: [325 137  67  91]\n",
            "         |->> Action Probabilities (Rounded): [1.280e-02 1.600e-03 1.000e-04 1.470e-02 9.541e-01 1.800e-03 0.000e+00\n",
            " 0.000e+00 0.000e+00 9.500e-03 5.300e-03], argmax=4\n",
            "         |->> Action Probabilities (RAW): [1.2765697e-02 1.6057530e-03 1.1324419e-04 1.4689143e-02 9.5414859e-01\n",
            " 1.8293628e-03 1.5799643e-06 1.8954425e-07 1.9769537e-05 9.5379828e-03\n",
            " 5.2887113e-03], argmax=4\n",
            "   \u001b[33m|->> #2/t=3-th Action selection: 5/2X UP (P(a|s) = 0.9739999771118164)\u001b[0m\n",
            "      |->> Bounding box moves to: [325 133  67  91]\n",
            "         |->> Action Probabilities (Rounded): [1.00e-04 1.20e-02 0.00e+00 1.00e-04 4.20e-03 9.74e-01 0.00e+00 8.90e-03\n",
            " 0.00e+00 0.00e+00 8.00e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [5.4094620e-05 1.2023257e-02 2.8828968e-06 7.8821526e-05 4.1544707e-03\n",
            " 9.7400415e-01 1.0803890e-07 8.8527622e-03 1.1000222e-07 5.3941021e-06\n",
            " 8.2396041e-04], argmax=5\n",
            "   \u001b[33m|->> #3/t=4-th Action selection: 5/2X UP (P(a|s) = 0.5929999947547913)\u001b[0m\n",
            "      |->> Bounding box moves to: [325 129  67  91]\n",
            "         |->> Action Probabilities (Rounded): [2.800e-03 2.000e-04 1.100e-03 2.900e-03 6.880e-02 5.925e-01 2.000e-04\n",
            " 1.190e-02 4.900e-03 1.100e-03 3.138e-01], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.78185238e-03 1.73627835e-04 1.06144615e-03 2.87358696e-03\n",
            " 6.87677413e-02 5.92522502e-01 1.73179680e-04 1.18778655e-02\n",
            " 4.87085292e-03 1.06912409e-03 3.13828170e-01], argmax=5\n",
            "   \u001b[33m|->> #4/t=5-th Action selection: 5/2X UP (P(a|s) = 0.968999981880188)\u001b[0m\n",
            "      |->> Bounding box moves to: [325 125  67  91]\n",
            "         |->> Action Probabilities (Rounded): [9.000e-04 0.000e+00 1.000e-04 5.000e-04 1.730e-02 9.692e-01 0.000e+00\n",
            " 9.600e-03 0.000e+00 2.300e-03 1.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [9.04145476e-04 3.99000746e-05 6.94676710e-05 4.97952744e-04\n",
            " 1.72909312e-02 9.69212770e-01 2.43946106e-05 9.56719927e-03\n",
            " 1.30736435e-05 2.25674198e-03 1.23451100e-04], argmax=5\n",
            "   \u001b[33m|->> #5/t=6-th Action selection: 5/2X UP (P(a|s) = 0.9610000252723694)\u001b[0m\n",
            "      |->> Bounding box moves to: [325 121  67  91]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 1.000e-04 0.000e+00 1.030e-02 2.760e-02 9.611e-01 0.000e+00\n",
            " 9.000e-04 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.83904012e-05 1.04730752e-04 1.10344445e-05 1.02571715e-02\n",
            " 2.75806058e-02 9.61091876e-01 2.49744232e-07 9.12430813e-04\n",
            " 2.42657894e-09 2.20615148e-05 1.46752052e-06], argmax=5\n",
            "   \u001b[33m|->> #6/t=7-th Action selection: 3/2X RIGHT (P(a|s) = 0.2849999964237213)\u001b[0m\n",
            "      |->> Bounding box moves to: [329 121  67  91]\n",
            "         |->> Action Probabilities (Rounded): [2.70e-03 1.00e-04 3.10e-03 2.85e-01 1.06e-02 6.46e-01 0.00e+00 0.00e+00\n",
            " 4.00e-04 3.00e-04 5.16e-02], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.7064683e-03 5.2069947e-05 3.1220007e-03 2.8504297e-01 1.0592781e-02\n",
            " 6.4603662e-01 2.9985868e-05 4.4610693e-05 4.4237557e-04 3.1068810e-04\n",
            " 5.1619455e-02], argmax=5\n",
            "   \u001b[33m|->> #7/t=8-th Action selection: 5/2X UP (P(a|s) = 0.984000027179718)\u001b[0m\n",
            "      |->> Bounding box moves to: [329 117  67  91]\n",
            "         |->> Action Probabilities (Rounded): [1.000e-04 0.000e+00 2.500e-03 3.300e-03 5.800e-03 9.839e-01 0.000e+00\n",
            " 2.000e-04 0.000e+00 0.000e+00 4.100e-03], argmax=5\n",
            "         |->> Action Probabilities (RAW): [5.1575149e-05 7.8575795e-06 2.5330761e-03 3.3422785e-03 5.8319755e-03\n",
            " 9.8390722e-01 3.1369410e-07 2.0178223e-04 2.7412494e-07 8.9888795e-07\n",
            " 4.1228062e-03], argmax=5\n",
            "   \u001b[33m|->> #8/t=9-th Action selection: 5/2X UP (P(a|s) = 0.9440000057220459)\u001b[0m\n",
            "      |->> Bounding box moves to: [329 113  67  91]\n",
            "         |->> Action Probabilities (Rounded): [1.760e-02 1.150e-02 6.000e-04 1.000e-04 4.000e-04 9.445e-01 1.000e-04\n",
            " 0.000e+00 3.000e-04 0.000e+00 2.480e-02], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.7596869e-02 1.1486053e-02 6.0674176e-04 1.4869882e-04 4.2310974e-04\n",
            " 9.4449437e-01 7.3582130e-05 3.8734768e-05 3.4885987e-04 1.6309323e-05\n",
            " 2.4766555e-02], argmax=5\n",
            "   \u001b[33m|->> #9/t=10-th Action selection: 5/2X UP (P(a|s) = 0.9990000128746033)\u001b[0m\n",
            "      |->> Bounding box moves to: [329 109  67  91]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 2.000e-04 1.100e-03 9.986e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 1.000e-04 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.7033553e-05 1.5757923e-05 7.9510146e-06 1.6357866e-04 1.0597405e-03\n",
            " 9.9863654e-01 6.7627717e-09 8.0310706e-08 2.9012362e-08 6.9883878e-05\n",
            " 2.9345973e-05], argmax=5\n",
            "   \u001b[33m|->> #10/t=11-th Action selection: 5/2X UP (P(a|s) = 0.9919999837875366)\u001b[0m\n",
            "      |->> Bounding box moves to: [329 105  67  91]\n",
            "         |->> Action Probabilities (Rounded): [1.000e-04 2.200e-03 5.000e-04 2.500e-03 2.100e-03 9.922e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 3.000e-04 1.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.3890940e-04 2.1870621e-03 4.8508932e-04 2.4821903e-03 2.1078996e-03\n",
            " 9.9216342e-01 4.4974229e-05 5.7859481e-08 5.4913853e-06 3.2702618e-04\n",
            " 5.7760390e-05], argmax=5\n",
            "   \u001b[33m|->> #11/t=12-th Action selection: 5/2X UP (P(a|s) = 0.7160000205039978)\u001b[0m\n",
            "      |->> Bounding box moves to: [329 101  67  91]\n",
            "         |->> Action Probabilities (Rounded): [1.200e-02 9.220e-02 1.400e-02 1.590e-02 3.070e-02 7.159e-01 9.000e-04\n",
            " 3.000e-04 6.000e-04 6.700e-03 1.109e-01], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.1956814e-02 9.2205070e-02 1.3974287e-02 1.5906615e-02 3.0696696e-02\n",
            " 7.1587247e-01 9.3378581e-04 2.5417883e-04 6.0726481e-04 6.6770245e-03\n",
            " 1.1091584e-01], argmax=5\n",
            "   \u001b[33m|->> #12/t=13-th Action selection: 5/2X UP (P(a|s) = 0.9380000233650208)\u001b[0m\n",
            "      |->> Bounding box moves to: [329  97  67  91]\n",
            "         |->> Action Probabilities (Rounded): [3.000e-04 4.000e-04 4.110e-02 1.800e-03 7.600e-03 9.382e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 1.030e-02 2.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.1815172e-04 3.8362650e-04 4.1146737e-02 1.8475357e-03 7.5919521e-03\n",
            " 9.3817508e-01 3.5993250e-10 1.0288350e-10 2.4270821e-07 1.0328098e-02\n",
            " 2.0854060e-04], argmax=5\n",
            "   \u001b[33m|->> #13/t=14-th Action selection: 5/2X UP (P(a|s) = 0.7039999961853027)\u001b[0m\n",
            "      |->> Bounding box moves to: [329  93  67  91]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 7.000e-04 6.000e-04 1.040e-02 3.000e-04 7.041e-01 1.200e-03\n",
            " 1.295e-01 0.000e+00 0.000e+00 1.532e-01], argmax=5\n",
            "         |->> Action Probabilities (RAW): [4.2941985e-05 7.0840493e-04 6.1432028e-04 1.0387622e-02 2.5008322e-04\n",
            " 7.0410919e-01 1.2047414e-03 1.2951778e-01 4.1497179e-07 3.4057933e-07\n",
            " 1.5316418e-01], argmax=5\n",
            "   \u001b[33m|->> #14/t=15-th Action selection: 4/UP (P(a|s) = 0.20800000429153442)\u001b[0m\n",
            "      |->> Bounding box moves to: [329  91  67  91]\n",
            "         |->> Action Probabilities (Rounded): [5.460e-02 4.810e-02 1.010e-02 2.720e-02 2.079e-01 5.350e-02 6.800e-03\n",
            " 3.000e-04 5.000e-04 4.330e-02 5.477e-01], argmax=10\n",
            "         |->> Action Probabilities (RAW): [5.45726158e-02 4.81392369e-02 1.00595495e-02 2.71973573e-02\n",
            " 2.07873851e-01 5.34550846e-02 6.82619447e-03 3.27603862e-04\n",
            " 5.09512145e-04 4.33010124e-02 5.47738016e-01], argmax=10\n",
            "   \u001b[33m|->> #15/t=16-th Action selection: 1/2X LEFT (P(a|s) = 0.7250000238418579)\u001b[0m\n",
            "      |->> Bounding box moves to: [325  91  67  91]\n",
            "         |->> Action Probabilities (Rounded): [1.999e-01 7.255e-01 5.000e-04 1.000e-04 3.230e-02 8.000e-03 6.500e-03\n",
            " 8.000e-04 1.000e-04 4.100e-03 2.230e-02], argmax=1\n",
            "         |->> Action Probabilities (RAW): [1.99935243e-01 7.25496829e-01 4.66479134e-04 9.52507762e-05\n",
            " 3.22900079e-02 7.96268694e-03 6.46137865e-03 7.70250219e-04\n",
            " 1.07219115e-04 4.10019467e-03 2.23144721e-02], argmax=1\n",
            "   \u001b[33m|->> #16/t=17-th Action selection: 1/2X LEFT (P(a|s) = 0.6790000200271606)\u001b[0m\n",
            "      |->> Bounding box moves to: [321  91  67  91]\n",
            "         |->> Action Probabilities (Rounded): [6.870e-02 6.793e-01 3.400e-03 8.900e-03 1.000e-03 4.570e-02 1.000e-04\n",
            " 1.588e-01 1.000e-04 3.390e-02 1.000e-04], argmax=1\n",
            "         |->> Action Probabilities (RAW): [6.8729877e-02 6.7931241e-01 3.3819280e-03 8.9061614e-03 1.0377206e-03\n",
            " 4.5693181e-02 1.2469493e-04 1.5876889e-01 5.1128740e-05 3.3886835e-02\n",
            " 1.0716640e-04], argmax=1\n",
            "|->> Revisiting bbox: [325  91  67  91]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [324, 138,  70,  94] -> [321,  91,  67,  91] (Target was [337, 158,  68,  90])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.018) for SCALE DOWN:bbox transition: [324, 138,  70,  94] -> [325, 139,  67,  91] w/ P(a|s)=0.06731031835079193 and iou=0.47959307254450767 and reward=-0.017695302838656668 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.019) for UP:bbox transition: [325, 139,  67,  91] -> [325, 137,  67,  91] w/ P(a|s)=0.9541485905647278 and iou=0.46014103023783914 and reward=-0.019452042306668527 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-0.037) for 2X UP:bbox transition: [325, 137,  67,  91] -> [325, 133,  67,  91] w/ P(a|s)=0.9740041494369507 and iou=0.4227320367998137 and reward=-0.03740899343802545 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-0.036) for 2X UP:bbox transition: [325, 133,  67,  91] -> [325, 129,  67,  91] w/ P(a|s)=0.5925225019454956 and iou=0.3871920063585784 and reward=-0.03554003044123527 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-0.034) for 2X UP:bbox transition: [325, 129,  67,  91] -> [325, 125,  67,  91] w/ P(a|s)=0.9692127704620361 and iou=0.3533842915697352 and reward=-0.0338077147888432 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-0.032) for 2X UP:bbox transition: [325, 125,  67,  91] -> [325, 121,  67,  91] w/ P(a|s)=0.9610918760299683 and iou=0.3211852492700335 and reward=-0.03219904229970172 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.032) for 2X RIGHT:bbox transition: [325, 121,  67,  91] -> [329, 121,  67,  91] w/ P(a|s)=0.28504297137260437 and iou=0.35278485217583877 and reward=0.03159960290580527 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (-0.034) for 2X UP:bbox transition: [329, 121,  67,  91] -> [329, 117,  67,  91] w/ P(a|s)=0.9839072227478027 and iou=0.31833387288227044 and reward=-0.03445097929356833 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (-0.033) for 2X UP:bbox transition: [329, 117,  67,  91] -> [329, 113,  67,  91] w/ P(a|s)=0.944494366645813 and iou=0.28559402294012415 and reward=-0.03273984994214629 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (-0.031) for 2X UP:bbox transition: [329, 113,  67,  91] -> [329, 109,  67,  91] w/ P(a|s)=0.9986365437507629 and iou=0.254440907690728 and reward=-0.031153115249396124 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (-0.03) for 2X UP:bbox transition: [329, 109,  67,  91] -> [329, 105,  67,  91] w/ P(a|s)=0.9921634197235107 and iou=0.22476190476190477 and reward=-0.02967900292882325 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (-0.028) for 2X UP:bbox transition: [329, 105,  67,  91] -> [329, 101,  67,  91] w/ P(a|s)=0.7158724665641785 and iou=0.19645480364312995 and reward=-0.028307101118774824 and discount=0.8953382542587164\n",
            "   |->> t=13 Diff-Reward (-0.027) for 2X UP:bbox transition: [329, 101,  67,  91] -> [329,  97,  67,  91] w/ P(a|s)=0.9381750822067261 and iou=0.16942662965444624 and reward=-0.027028173988683707 and discount=0.8863848717161292\n",
            "   |->> t=14 Diff-Reward (-0.026) for 2X UP:bbox transition: [329,  97,  67,  91] -> [329,  93,  67,  91] w/ P(a|s)=0.7041091918945312 and iou=0.1435926237948142 and reward=-0.025834005859632053 and discount=0.8775210229989678\n",
            "   |->> t=15 Diff-Reward (-0.012) for UP:bbox transition: [329,  93,  67,  91] -> [329,  91,  67,  91] w/ P(a|s)=0.2078738510608673 and iou=0.13109897231737802 and reward=-0.012493651477436168 and discount=0.8687458127689782\n",
            "   |->> t=16 Diff-Reward (-0.01) for 2X LEFT:bbox transition: [329,  91,  67,  91] -> [325,  91,  67,  91] w/ P(a|s)=0.7254968285560608 and iou=0.12113425713499128 and reward=-0.009964715182386744 and discount=0.8600583546412884\n",
            "   |->> t=17 Diff-Reward (-0.01) for 2X LEFT:bbox transition: [325,  91,  67,  91] -> [321,  91,  67,  91] w/ P(a|s)=0.6793124079704285 and iou=0.1113435822796325 and reward=-0.009790674855358783 and discount=0.8514577710948755\n",
            "   |->> Assigned losses: [-4.7749743e-02 -9.0386847e-04 -9.6573390e-04 -1.8048005e-02\n",
            " -1.0155467e-03 -1.2152015e-03  3.7340179e-02 -5.2095129e-04\n",
            " -1.7251888e-03 -3.8828952e-05 -2.1117140e-04 -8.4714582e-03\n",
            " -1.5289276e-03 -7.9530897e-03 -1.7049421e-02 -2.7501767e-03\n",
            " -3.2234499e-03]\n",
            "\u001b[31m>> Total frame loss: -0.07603058218955994\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 80 with src: [321,  91,  67,  91] and target: [344, 162,  61,  90]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0080.jpg\n",
            "|->> Beginning tracking for bbox:[321  91  67  91]\n",
            "   \u001b[33m|->> #0/t=18-th Action selection: 5/2X UP (P(a|s) = 0.26100000739097595)\u001b[0m\n",
            "      |->> Bounding box moves to: [321  87  67  91]\n",
            "         |->> Action Probabilities (Rounded): [3.180e-02 2.030e-02 8.000e-04 1.100e-03 3.490e-02 2.608e-01 1.930e-02\n",
            " 4.515e-01 3.000e-04 6.100e-03 1.732e-01], argmax=7\n",
            "         |->> Action Probabilities (RAW): [3.1782940e-02 2.0283438e-02 7.5016118e-04 1.1218879e-03 3.4854241e-02\n",
            " 2.6075950e-01 1.9302273e-02 4.5148730e-01 2.9287278e-04 6.1488994e-03\n",
            " 1.7321645e-01], argmax=7\n",
            "   \u001b[33m|->> #1/t=19-th Action selection: 0/LEFT (P(a|s) = 0.6970000267028809)\u001b[0m\n",
            "      |->> Bounding box moves to: [319  87  67  91]\n",
            "         |->> Action Probabilities (Rounded): [6.972e-01 1.570e-02 4.230e-02 0.000e+00 2.790e-02 2.033e-01 1.000e-04\n",
            " 9.100e-03 0.000e+00 4.200e-03 2.000e-04], argmax=0\n",
            "         |->> Action Probabilities (RAW): [6.97175562e-01 1.56888068e-02 4.23317105e-02 2.20145139e-07\n",
            " 2.78678127e-02 2.03311607e-01 1.07623186e-04 9.08405893e-03\n",
            " 4.69484003e-05 4.20667836e-03 1.78998685e-04], argmax=0\n",
            "   \u001b[33m|->> #2/t=20-th Action selection: 5/2X UP (P(a|s) = 0.9380000233650208)\u001b[0m\n",
            "      |->> Bounding box moves to: [319  83  67  91]\n",
            "         |->> Action Probabilities (Rounded): [7.000e-04 3.000e-04 2.300e-03 2.400e-03 5.060e-02 9.381e-01 1.000e-04\n",
            " 3.600e-03 3.000e-04 3.000e-04 1.300e-03], argmax=5\n",
            "         |->> Action Probabilities (RAW): [7.0538343e-04 2.5864993e-04 2.2750259e-03 2.3803136e-03 5.0624207e-02\n",
            " 9.3809301e-01 1.2919916e-04 3.5554587e-03 3.3017958e-04 3.2950912e-04\n",
            " 1.3190003e-03], argmax=5\n",
            "   \u001b[33m|->> #3/t=21-th Action selection: 4/UP (P(a|s) = 0.07800000160932541)\u001b[0m\n",
            "      |->> Bounding box moves to: [319  81  67  91]\n",
            "         |->> Action Probabilities (Rounded): [6.480e-02 5.760e-02 0.000e+00 1.000e-04 7.800e-02 4.263e-01 4.000e-04\n",
            " 3.100e-02 0.000e+00 1.000e-04 3.415e-01], argmax=5\n",
            "         |->> Action Probabilities (RAW): [6.4842738e-02 5.7620201e-02 3.5819594e-05 1.4211093e-04 7.8030564e-02\n",
            " 4.2625517e-01 3.7353399e-04 3.1030882e-02 6.9512662e-06 1.3553661e-04\n",
            " 3.4152648e-01], argmax=5\n",
            "   \u001b[33m|->> #4/t=22-th Action selection: 7/2X DOWN (P(a|s) = 0.8050000071525574)\u001b[0m\n",
            "      |->> Bounding box moves to: [319  85  67  91]\n",
            "         |->> Action Probabilities (Rounded): [1.000e-04 1.921e-01 0.000e+00 0.000e+00 3.000e-04 1.500e-03 3.000e-04\n",
            " 8.055e-01 0.000e+00 0.000e+00 2.000e-04], argmax=7\n",
            "         |->> Action Probabilities (RAW): [6.5239299e-05 1.9205563e-01 1.2455604e-05 1.9145395e-07 3.2620350e-04\n",
            " 1.5193089e-03 3.3051471e-04 8.0549806e-01 4.1962478e-09 1.3125462e-05\n",
            " 1.7927459e-04], argmax=7\n",
            "|->> Revisiting bbox: [319  83  67  91]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [321,  91,  67,  91] -> [319,  85,  67,  91] (Target was [344, 162,  61,  90])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.018) for 2X UP:bbox transition: [321,  91,  67,  91] -> [321,  87,  67,  91] w/ P(a|s)=0.26075950264930725 and iou=0.06468804557566847 and reward=-0.01750117642862778 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.003) for LEFT:bbox transition: [321,  87,  67,  91] -> [319,  87,  67,  91] w/ P(a|s)=0.6971755623817444 and iou=0.061566651397159874 and reward=-0.0031213941785085964 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-0.016) for 2X UP:bbox transition: [319,  87,  67,  91] -> [319,  83,  67,  91] w/ P(a|s)=0.9380930066108704 and iou=0.04547505188125959 and reward=-0.016091599515900286 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-0.008) for UP:bbox transition: [319,  83,  67,  91] -> [319,  81,  67,  91] w/ P(a|s)=0.07803056389093399 and iou=0.0376108175875347 and reward=-0.00786423429372489 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.016) for 2X DOWN:bbox transition: [319,  81,  67,  91] -> [319,  85,  67,  91] w/ P(a|s)=0.8054980635643005 and iou=0.053459405400490954 and reward=0.015848587812956255 and discount=0.96059601\n",
            "   |->> Assigned losses: [-0.02352433 -0.00111468 -0.00100789 -0.01946317  0.00329289]\n",
            "\u001b[31m>> Total frame loss: -0.041817180812358856\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 81 with src: [319,  85,  67,  91] and target: [336, 173,  61,  79]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0081.jpg\n",
            "|->> Beginning tracking for bbox:[319  85  67  91]\n",
            "   \u001b[33m|->> #0/t=23-th Action selection: 5/2X UP (P(a|s) = 0.9990000128746033)\u001b[0m\n",
            "      |->> Bounding box moves to: [319  81  67  91]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.0011 0.     0.     0.     0.9989 0.     0.     0.     0.\n",
            " 0.    ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [5.9360204e-14 1.1136424e-03 6.5423182e-20 2.0058249e-21 3.5301571e-09\n",
            " 9.9888498e-01 1.4535633e-11 1.4824537e-06 6.6910076e-19 1.4542734e-22\n",
            " 6.0111141e-18], argmax=5\n",
            "   \u001b[33m|->> #1/t=24-th Action selection: 1/2X LEFT (P(a|s) = 0.9179999828338623)\u001b[0m\n",
            "      |->> Bounding box moves to: [315  81  67  91]\n",
            "         |->> Action Probabilities (Rounded): [8.000e-04 9.178e-01 4.100e-03 1.000e-04 0.000e+00 7.670e-02 2.000e-04\n",
            " 1.000e-04 0.000e+00 0.000e+00 1.000e-04], argmax=1\n",
            "         |->> Action Probabilities (RAW): [7.8531378e-04 9.1781932e-01 4.1488619e-03 1.4707104e-04 6.1748087e-06\n",
            " 7.6689564e-02 1.8351106e-04 1.4463966e-04 2.4086349e-08 4.2925831e-06\n",
            " 7.1191855e-05], argmax=1\n",
            "   \u001b[33m|->> #2/t=25-th Action selection: 5/2X UP (P(a|s) = 0.7120000123977661)\u001b[0m\n",
            "      |->> Bounding box moves to: [315  77  67  91]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.2877 0.     0.     0.     0.7123 0.     0.     0.     0.\n",
            " 0.    ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.1335595e-06 2.8769705e-01 7.1095023e-22 4.4162284e-21 3.0503649e-12\n",
            " 7.1230155e-01 5.2715627e-12 1.5515374e-10 9.2447225e-19 1.6749140e-13\n",
            " 2.4426473e-07], argmax=5\n",
            "   \u001b[33m|->> #3/t=26-th Action selection: 10/SCALE UP (P(a|s) = 0.06700000166893005)\u001b[0m\n",
            "      |->> Bounding box moves to: [313  75  69  93]\n",
            "         |->> Action Probabilities (Rounded): [0.1387 0.4335 0.     0.     0.     0.3612 0.     0.     0.     0.\n",
            " 0.0667], argmax=1\n",
            "         |->> Action Probabilities (RAW): [1.3866366e-01 4.3349442e-01 3.0435831e-11 2.2347763e-17 3.0077505e-08\n",
            " 3.6116409e-01 1.0842321e-07 7.0876536e-09 1.5542750e-16 8.7410061e-09\n",
            " 6.6677645e-02], argmax=1\n",
            "   \u001b[33m|->> #4/t=27-th Action selection: 0/LEFT (P(a|s) = 0.9909999966621399)\u001b[0m\n",
            "      |->> Bounding box moves to: [311  75  69  93]\n",
            "         |->> Action Probabilities (Rounded): [0.9914 0.0086 0.     0.     0.     0.     0.     0.     0.     0.\n",
            " 0.    ], argmax=0\n",
            "         |->> Action Probabilities (RAW): [9.9136496e-01 8.6319000e-03 5.0437557e-11 5.3369259e-16 1.6441652e-07\n",
            " 3.0484421e-06 2.4365125e-08 5.1286808e-10 2.1588822e-15 5.6736785e-12\n",
            " 2.0055552e-08], argmax=0\n",
            "   \u001b[33m|->> #5/t=28-th Action selection: 5/2X UP (P(a|s) = 0.3050000071525574)\u001b[0m\n",
            "      |->> Bounding box moves to: [311  71  69  93]\n",
            "         |->> Action Probabilities (Rounded): [6.933e-01 0.000e+00 0.000e+00 0.000e+00 1.000e-03 3.049e-01 3.000e-04\n",
            " 0.000e+00 0.000e+00 0.000e+00 5.000e-04], argmax=0\n",
            "         |->> Action Probabilities (RAW): [6.9333917e-01 8.5050151e-06 6.2041163e-06 2.1149478e-07 1.0372165e-03\n",
            " 3.0486146e-01 2.8554045e-04 6.3225701e-07 8.0437781e-07 2.9309247e-06\n",
            " 4.5727094e-04], argmax=0\n",
            "   \u001b[33m|->> #6/t=29-th Action selection: 5/2X UP (P(a|s) = 0.9950000047683716)\u001b[0m\n",
            "      |->> Bounding box moves to: [311  67  69  93]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.0045 0.     0.     0.     0.9955 0.     0.     0.     0.\n",
            " 0.    ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.7378107e-15 4.5067710e-03 3.2886183e-11 1.5990788e-13 3.2760365e-14\n",
            " 9.9549317e-01 2.1939279e-23 3.8175870e-22 3.1028508e-20 5.3593453e-12\n",
            " 7.2325184e-12], argmax=5\n",
            "   \u001b[33m|->> #7/t=30-th Action selection: 5/2X UP (P(a|s) = 0.968999981880188)\u001b[0m\n",
            "      |->> Bounding box moves to: [311  63  69  93]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 1.800e-03 0.000e+00 0.000e+00 1.000e-04 9.691e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 2.900e-02], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.0666917e-06 1.7775568e-03 8.8172311e-07 1.6466340e-05 8.2713945e-05\n",
            " 9.6908933e-01 8.3737923e-06 1.5077643e-07 3.1333276e-12 4.3472315e-09\n",
            " 2.9023383e-02], argmax=5\n",
            "   \u001b[33m|->> #8/t=31-th Action selection: 1/2X LEFT (P(a|s) = 0.7409999966621399)\u001b[0m\n",
            "      |->> Bounding box moves to: [307  63  69  93]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.7414 0.     0.     0.     0.2586 0.     0.     0.     0.\n",
            " 0.    ], argmax=1\n",
            "         |->> Action Probabilities (RAW): [3.6327509e-07 7.4144673e-01 2.0010553e-07 5.4307547e-15 2.0622477e-09\n",
            " 2.5855237e-01 3.5615866e-09 3.2629265e-07 6.9523471e-12 5.8390345e-14\n",
            " 2.6634722e-10], argmax=1\n",
            "   \u001b[33m|->> #9/t=32-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [307  59  69  93]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [8.1686986e-09 2.4399901e-07 2.0890878e-12 1.5798374e-12 1.3222229e-09\n",
            " 9.9999917e-01 8.5141885e-08 2.5752610e-07 7.1068981e-16 3.4157581e-13\n",
            " 2.6120313e-07], argmax=5\n",
            "   \u001b[33m|->> #10/t=33-th Action selection: 1/2X LEFT (P(a|s) = 0.9940000176429749)\u001b[0m\n",
            "      |->> Bounding box moves to: [303  59  69  93]\n",
            "         |->> Action Probabilities (Rounded): [1.000e-04 9.942e-01 0.000e+00 0.000e+00 0.000e+00 4.000e-04 0.000e+00\n",
            " 5.200e-03 0.000e+00 0.000e+00 0.000e+00], argmax=1\n",
            "         |->> Action Probabilities (RAW): [1.2400986e-04 9.9423176e-01 1.3171836e-22 1.0068076e-15 2.6675494e-17\n",
            " 4.2150906e-04 2.4352545e-07 5.2224468e-03 9.3902033e-32 8.5366633e-28\n",
            " 1.7358350e-12], argmax=1\n",
            "   \u001b[33m|->> #11/t=34-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [303  55  69  93]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 9.998e-01 0.000e+00\n",
            " 2.000e-04 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.1298451e-06 1.8245798e-06 6.1514527e-08 1.4280083e-05 6.0624248e-09\n",
            " 9.9982268e-01 4.8728566e-07 1.5919717e-04 1.9585462e-20 2.0302403e-16\n",
            " 3.5480892e-07], argmax=5\n",
            "   \u001b[33m|->> #12/t=35-th Action selection: 3/2X RIGHT (P(a|s) = 0.39899998903274536)\u001b[0m\n",
            "      |->> Bounding box moves to: [307  55  69  93]\n",
            "         |->> Action Probabilities (Rounded): [0.0273 0.0415 0.0268 0.3989 0.097  0.0901 0.0051 0.2542 0.001  0.0044\n",
            " 0.0538], argmax=3\n",
            "         |->> Action Probabilities (RAW): [0.02730068 0.04145261 0.02676909 0.39892745 0.0969742  0.09007308\n",
            " 0.00510011 0.2541933  0.00098166 0.00441127 0.05381644], argmax=3\n",
            "   \u001b[33m|->> #13/t=36-th Action selection: 5/2X UP (P(a|s) = 0.9929999709129333)\u001b[0m\n",
            "      |->> Bounding box moves to: [307  51  69  93]\n",
            "         |->> Action Probabilities (Rounded): [1.200e-03 1.300e-03 0.000e+00 0.000e+00 4.000e-03 9.926e-01 0.000e+00\n",
            " 5.000e-04 0.000e+00 0.000e+00 3.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.2473854e-03 1.3329211e-03 9.4760402e-08 1.5342183e-08 3.9782552e-03\n",
            " 9.9255002e-01 4.6269273e-05 5.3968868e-04 2.4339153e-10 6.2042709e-08\n",
            " 3.0522086e-04], argmax=5\n",
            "   \u001b[33m|->> #14/t=37-th Action selection: 5/2X UP (P(a|s) = 0.9950000047683716)\u001b[0m\n",
            "      |->> Bounding box moves to: [307  47  69  93]\n",
            "         |->> Action Probabilities (Rounded): [4.000e-04 6.000e-04 0.000e+00 0.000e+00 3.600e-03 9.954e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [4.1475624e-04 5.5581355e-04 1.4283056e-07 1.7459759e-07 3.5812291e-03\n",
            " 9.9543506e-01 1.5886462e-06 8.5063220e-07 1.1275361e-09 9.4674954e-07\n",
            " 9.3704612e-06], argmax=5\n",
            "   \u001b[33m|->> #15/t=38-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [307  43  69  93]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 2.000e-04 0.000e+00 0.000e+00 0.000e+00 9.998e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [6.8109802e-12 2.4289102e-04 7.9118755e-29 7.6759864e-26 6.0779230e-13\n",
            " 9.9975711e-01 5.3523747e-24 2.7699134e-21 1.0386202e-29 1.5589594e-19\n",
            " 1.3912614e-19], argmax=5\n",
            "   \u001b[33m|->> #16/t=39-th Action selection: 5/2X UP (P(a|s) = 0.9950000047683716)\u001b[0m\n",
            "      |->> Bounding box moves to: [307  39  69  93]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 0.000e+00 4.000e-04 9.948e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 4.900e-03], argmax=5\n",
            "         |->> Action Probabilities (RAW): [9.5407904e-10 2.7626963e-06 1.6668849e-07 1.1067479e-07 3.5108221e-04\n",
            " 9.9477470e-01 2.7828159e-10 6.1576534e-12 2.9726870e-12 1.4172230e-09\n",
            " 4.8710392e-03], argmax=5\n",
            "   \u001b[33m|->> #17/t=40-th Action selection: 1/2X LEFT (P(a|s) = 0.4309999942779541)\u001b[0m\n",
            "      |->> Bounding box moves to: [303  39  69  93]\n",
            "         |->> Action Probabilities (Rounded): [4.500e-03 4.312e-01 0.000e+00 0.000e+00 4.000e-04 5.639e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [4.4735842e-03 4.3117505e-01 4.4370331e-08 1.8742475e-07 3.8883454e-04\n",
            " 5.6391948e-01 2.1739236e-06 3.9578463e-05 7.3100803e-10 1.0949813e-07\n",
            " 9.5530891e-07], argmax=5\n",
            "   \u001b[33m|->> #18/t=41-th Action selection: 5/2X UP (P(a|s) = 0.996999979019165)\u001b[0m\n",
            "      |->> Bounding box moves to: [303  35  69  93]\n",
            "         |->> Action Probabilities (Rounded): [1.000e-04 1.300e-03 1.300e-03 7.000e-04 0.000e+00 9.966e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 1.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [6.3308587e-05 1.2729927e-03 1.2605393e-03 6.6477078e-04 1.4662840e-05\n",
            " 9.9659687e-01 3.6566616e-05 1.0368587e-05 4.7437357e-08 1.3214633e-07\n",
            " 7.9748119e-05], argmax=5\n",
            "   \u001b[33m|->> #19/t=42-th Action selection: 5/2X UP (P(a|s) = 0.6769999861717224)\u001b[0m\n",
            "      |->> Bounding box moves to: [303  31  69  93]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 4.500e-03 0.000e+00 3.174e-01 1.000e-04 6.770e-01 4.000e-04\n",
            " 6.000e-04 0.000e+00 0.000e+00 1.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.6298562e-09 4.5395498e-03 1.0843044e-06 3.1740558e-01 7.5071992e-05\n",
            " 6.7697692e-01 3.6964519e-04 5.7457545e-04 1.4585273e-12 6.1566877e-11\n",
            " 5.7627243e-05], argmax=5\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [319,  85,  67,  91] -> [303,  31,  69,  93] (Target was [336, 173,  61,  79])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.014) for 2X UP:bbox transition: [319,  85,  67,  91] -> [319,  81,  67,  91] w/ P(a|s)=0.9988849759101868 and iou=0.0 and reward=-0.013932751253947613 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for 2X LEFT:bbox transition: [319,  81,  67,  91] -> [315,  81,  67,  91] w/ P(a|s)=0.9178193211555481 and iou=0.0 and reward=0.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X UP:bbox transition: [315,  81,  67,  91] -> [315,  77,  67,  91] w/ P(a|s)=0.7123015522956848 and iou=0.0 and reward=0.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.0) for SCALE UP:bbox transition: [315,  77,  67,  91] -> [313,  75,  69,  93] w/ P(a|s)=0.06667764484882355 and iou=0.0 and reward=0.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.0) for LEFT:bbox transition: [313,  75,  69,  93] -> [311,  75,  69,  93] w/ P(a|s)=0.9913649559020996 and iou=0.0 and reward=0.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.0) for 2X UP:bbox transition: [311,  75,  69,  93] -> [311,  71,  69,  93] w/ P(a|s)=0.304861456155777 and iou=0.0 and reward=0.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.0) for 2X UP:bbox transition: [311,  71,  69,  93] -> [311,  67,  69,  93] w/ P(a|s)=0.9954931735992432 and iou=0.0 and reward=0.0 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (0.0) for 2X UP:bbox transition: [311,  67,  69,  93] -> [311,  63,  69,  93] w/ P(a|s)=0.9690893292427063 and iou=0.0 and reward=0.0 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (0.0) for 2X LEFT:bbox transition: [311,  63,  69,  93] -> [307,  63,  69,  93] w/ P(a|s)=0.7414467334747314 and iou=0.0 and reward=0.0 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (0.0) for 2X UP:bbox transition: [307,  63,  69,  93] -> [307,  59,  69,  93] w/ P(a|s)=0.9999991655349731 and iou=0.0 and reward=0.0 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (0.0) for 2X LEFT:bbox transition: [307,  59,  69,  93] -> [303,  59,  69,  93] w/ P(a|s)=0.9942317605018616 and iou=0.0 and reward=0.0 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (0.0) for 2X UP:bbox transition: [303,  59,  69,  93] -> [303,  55,  69,  93] w/ P(a|s)=0.9998226761817932 and iou=0.0 and reward=0.0 and discount=0.8953382542587164\n",
            "   |->> t=13 Diff-Reward (0.0) for 2X RIGHT:bbox transition: [303,  55,  69,  93] -> [307,  55,  69,  93] w/ P(a|s)=0.3989274501800537 and iou=0.0 and reward=0.0 and discount=0.8863848717161292\n",
            "   |->> t=14 Diff-Reward (0.0) for 2X UP:bbox transition: [307,  55,  69,  93] -> [307,  51,  69,  93] w/ P(a|s)=0.9925500154495239 and iou=0.0 and reward=0.0 and discount=0.8775210229989678\n",
            "   |->> t=15 Diff-Reward (0.0) for 2X UP:bbox transition: [307,  51,  69,  93] -> [307,  47,  69,  93] w/ P(a|s)=0.9954350590705872 and iou=0.0 and reward=0.0 and discount=0.8687458127689782\n",
            "   |->> t=16 Diff-Reward (0.0) for 2X UP:bbox transition: [307,  47,  69,  93] -> [307,  43,  69,  93] w/ P(a|s)=0.9997571110725403 and iou=0.0 and reward=0.0 and discount=0.8600583546412884\n",
            "   |->> t=17 Diff-Reward (0.0) for 2X UP:bbox transition: [307,  43,  69,  93] -> [307,  39,  69,  93] w/ P(a|s)=0.9947746992111206 and iou=0.0 and reward=0.0 and discount=0.8514577710948755\n",
            "   |->> t=18 Diff-Reward (0.0) for 2X LEFT:bbox transition: [307,  39,  69,  93] -> [303,  39,  69,  93] w/ P(a|s)=0.4311750531196594 and iou=0.0 and reward=0.0 and discount=0.8429431933839268\n",
            "   |->> t=19 Diff-Reward (0.0) for 2X UP:bbox transition: [303,  39,  69,  93] -> [303,  35,  69,  93] w/ P(a|s)=0.9965968728065491 and iou=0.0 and reward=0.0 and discount=0.8345137614500875\n",
            "   |->> t=20 Diff-Reward (0.0) for 2X UP:bbox transition: [303,  35,  69,  93] -> [303,  31,  69,  93] w/ P(a|s)=0.6769769191741943 and iou=0.0 and reward=0.0 and discount=0.8261686238355866\n",
            "   |->> Assigned losses: [-1.5544021e-05  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
            "  0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
            "  0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
            "  0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
            "  0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
            "\u001b[31m>> Total frame loss: -1.554402115289122e-05\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 82 with src: [303,  31,  69,  93] and target: [328, 169,  61,  79]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0082.jpg\n",
            "|->> Beginning tracking for bbox:[303  31  69  93]\n",
            "   \u001b[33m|->> #0/t=43-th Action selection: 5/2X UP (P(a|s) = 0.9539999961853027)\u001b[0m\n",
            "      |->> Bounding box moves to: [303  27  69  93]\n",
            "         |->> Action Probabilities (Rounded): [1.000e-04 8.000e-04 1.900e-03 2.200e-03 3.280e-02 9.542e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 1.000e-04 7.900e-03], argmax=5\n",
            "         |->> Action Probabilities (RAW): [5.6008645e-05 7.8833336e-04 1.8893727e-03 2.2273147e-03 3.2761768e-02\n",
            " 9.5420510e-01 8.7517819e-06 2.4094465e-05 3.9683327e-05 1.1437331e-04\n",
            " 7.8852428e-03], argmax=5\n",
            "   \u001b[33m|->> #1/t=44-th Action selection: 4/UP (P(a|s) = 0.6150000095367432)\u001b[0m\n",
            "      |->> Bounding box moves to: [303  25  69  93]\n",
            "         |->> Action Probabilities (Rounded): [1.200e-03 2.000e-04 6.730e-02 1.282e-01 6.148e-01 1.263e-01 0.000e+00\n",
            " 2.000e-04 1.000e-04 1.700e-03 6.010e-02], argmax=4\n",
            "         |->> Action Probabilities (RAW): [1.2191124e-03 1.7534278e-04 6.7284450e-02 1.2821081e-01 6.1477369e-01\n",
            " 1.2631774e-01 6.0836010e-06 1.5803133e-04 5.2154664e-05 1.7305358e-03\n",
            " 6.0072061e-02], argmax=4\n",
            "   \u001b[33m|->> #2/t=45-th Action selection: 3/2X RIGHT (P(a|s) = 0.40700000524520874)\u001b[0m\n",
            "      |->> Bounding box moves to: [307  25  69  93]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.0058 0.4071 0.5746 0.0021 0.     0.     0.     0.\n",
            " 0.0104], argmax=4\n",
            "         |->> Action Probabilities (RAW): [1.1046788e-08 1.0051977e-09 5.8238981e-03 4.0714908e-01 5.7456440e-01\n",
            " 2.1077017e-03 7.2938378e-13 1.2168717e-09 7.8796719e-11 1.0395912e-06\n",
            " 1.0353912e-02], argmax=4\n",
            "   \u001b[33m|->> #3/t=46-th Action selection: 4/UP (P(a|s) = 0.22100000083446503)\u001b[0m\n",
            "      |->> Bounding box moves to: [307  23  69  93]\n",
            "         |->> Action Probabilities (Rounded): [3.000e-04 0.000e+00 9.130e-02 6.221e-01 2.207e-01 1.570e-02 0.000e+00\n",
            " 6.100e-03 0.000e+00 1.060e-02 3.320e-02], argmax=3\n",
            "         |->> Action Probabilities (RAW): [3.0269541e-04 1.0482959e-05 9.1313004e-02 6.2212074e-01 2.2071181e-01\n",
            " 1.5651997e-02 1.7152403e-06 6.0871970e-03 7.1650143e-06 1.0575164e-02\n",
            " 3.3218015e-02], argmax=3\n",
            "   \u001b[33m|->> #4/t=47-th Action selection: 10/SCALE UP (P(a|s) = 0.9300000071525574)\u001b[0m\n",
            "      |->> Bounding box moves to: [305  21  71  95]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 3.000e-04 6.670e-02 2.500e-03 3.000e-04 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 9.302e-01], argmax=10\n",
            "         |->> Action Probabilities (RAW): [1.8092403e-06 6.3015042e-09 3.4568165e-04 6.6719569e-02 2.4658630e-03\n",
            " 2.6163290e-04 3.3346164e-09 3.6460958e-07 1.0715769e-11 1.7651681e-08\n",
            " 9.3020511e-01], argmax=10\n",
            "   \u001b[33m|->> #5/t=48-th Action selection: 10/SCALE UP (P(a|s) = 0.5139999985694885)\u001b[0m\n",
            "      |->> Bounding box moves to: [303  19  73  97]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.046  0.4098 0.0231 0.0067 0.     0.     0.     0.\n",
            " 0.5144], argmax=10\n",
            "         |->> Action Probabilities (RAW): [6.8290791e-09 2.5945524e-10 4.6003830e-02 4.0976575e-01 2.3107704e-02\n",
            " 6.6944594e-03 7.8367149e-14 1.5224784e-12 4.4062901e-14 2.3006200e-10\n",
            " 5.1442826e-01], argmax=10\n",
            "   \u001b[33m|->> #6/t=49-th Action selection: 10/SCALE UP (P(a|s) = 0.9679999947547913)\u001b[0m\n",
            "      |->> Bounding box moves to: [301  17  75  99]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.0302 0.0015 0.     0.     0.     0.     0.     0.\n",
            " 0.9683], argmax=10\n",
            "         |->> Action Probabilities (RAW): [3.2380663e-09 3.6742834e-11 3.0187959e-02 1.4735037e-03 2.4687354e-08\n",
            " 7.6176212e-07 2.7409930e-08 1.6093701e-10 2.7503707e-13 4.1937498e-17\n",
            " 9.6833771e-01], argmax=10\n",
            "   \u001b[33m|->> #7/t=50-th Action selection: 10/SCALE UP (P(a|s) = 0.996999979019165)\u001b[0m\n",
            "      |->> Bounding box moves to: [299  15  77 101]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 2.200e-03 3.000e-04 0.000e+00 0.000e+00 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 9.974e-01], argmax=10\n",
            "         |->> Action Probabilities (RAW): [8.5155962e-09 7.5926265e-10 2.2141738e-03 3.4228401e-04 5.7542721e-10\n",
            " 1.0081905e-07 3.5416832e-07 2.2249087e-06 7.4332874e-13 2.2529205e-13\n",
            " 9.9744081e-01], argmax=10\n",
            "   \u001b[33m|->> #8/t=51-th Action selection: 2/RIGHT (P(a|s) = 0.8270000219345093)\u001b[0m\n",
            "      |->> Bounding box moves to: [301  15  77 101]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 8.271e-01 2.040e-02 0.000e+00 0.000e+00 1.000e-04\n",
            " 1.810e-02 0.000e+00 0.000e+00 1.342e-01], argmax=2\n",
            "         |->> Action Probabilities (RAW): [1.2475621e-05 7.1661509e-07 8.2712001e-01 2.0400688e-02 6.8544034e-07\n",
            " 5.9689546e-06 1.2779677e-04 1.8108377e-02 2.2342757e-08 6.6648340e-08\n",
            " 1.3422315e-01], argmax=2\n",
            "   \u001b[33m|->> #9/t=52-th Action selection: 2/RIGHT (P(a|s) = 0.7919999957084656)\u001b[0m\n",
            "      |->> Bounding box moves to: [303  15  77 101]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.7924 0.     0.     0.     0.0015 0.     0.     0.\n",
            " 0.2061], argmax=2\n",
            "         |->> Action Probabilities (RAW): [9.8901346e-08 4.5331535e-06 7.9237109e-01 3.4896275e-05 4.6331805e-10\n",
            " 1.0269059e-05 1.5177194e-03 4.2002412e-06 4.7384919e-08 4.2938847e-10\n",
            " 2.0605719e-01], argmax=2\n",
            "   \u001b[33m|->> #10/t=53-th Action selection: 5/2X UP (P(a|s) = 0.1979999989271164)\u001b[0m\n",
            "      |->> Bounding box moves to: [303   9  77 101]\n",
            "         |->> Action Probabilities (Rounded): [1.230e-01 9.200e-03 2.831e-01 2.900e-03 2.700e-03 1.983e-01 3.186e-01\n",
            " 2.000e-04 1.000e-04 0.000e+00 6.180e-02], argmax=6\n",
            "         |->> Action Probabilities (RAW): [1.2299368e-01 9.1630388e-03 2.8311282e-01 2.8924721e-03 2.7411922e-03\n",
            " 1.9830124e-01 3.1864184e-01 1.6693567e-04 9.8645942e-05 4.3968459e-05\n",
            " 6.1844070e-02], argmax=6\n",
            "   \u001b[33m|->> #11/t=54-th Action selection: 1/2X LEFT (P(a|s) = 0.2759999930858612)\u001b[0m\n",
            "      |->> Bounding box moves to: [299   9  77 101]\n",
            "         |->> Action Probabilities (Rounded): [0.1753 0.276  0.0347 0.0147 0.0054 0.0219 0.0319 0.4196 0.0028 0.0046\n",
            " 0.0133], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.17529525 0.2759544  0.03468776 0.01472793 0.00538569 0.02185178\n",
            " 0.03185687 0.41955355 0.0028368  0.00455387 0.01329613], argmax=7\n",
            "|->> Revisiting bbox: [299   9  77 101]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [303,  31,  69,  93] -> [299,   9,  77, 101] (Target was [328, 169,  61,  79])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X UP:bbox transition: [303,  31,  69,  93] -> [303,  27,  69,  93] w/ P(a|s)=0.9542050957679749 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for UP:bbox transition: [303,  27,  69,  93] -> [303,  25,  69,  93] w/ P(a|s)=0.614773690700531 and iou=0.0 and reward=0.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X RIGHT:bbox transition: [303,  25,  69,  93] -> [307,  25,  69,  93] w/ P(a|s)=0.407149076461792 and iou=0.0 and reward=0.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.0) for UP:bbox transition: [307,  25,  69,  93] -> [307,  23,  69,  93] w/ P(a|s)=0.220711812376976 and iou=0.0 and reward=0.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.0) for SCALE UP:bbox transition: [307,  23,  69,  93] -> [305,  21,  71,  95] w/ P(a|s)=0.9302051067352295 and iou=0.0 and reward=0.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.0) for SCALE UP:bbox transition: [305,  21,  71,  95] -> [303,  19,  73,  97] w/ P(a|s)=0.5144282579421997 and iou=0.0 and reward=0.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.0) for SCALE UP:bbox transition: [303,  19,  73,  97] -> [301,  17,  75,  99] w/ P(a|s)=0.9683377146720886 and iou=0.0 and reward=0.0 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (0.0) for SCALE UP:bbox transition: [301,  17,  75,  99] -> [299,  15,  77, 101] w/ P(a|s)=0.9974408149719238 and iou=0.0 and reward=0.0 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (0.0) for RIGHT:bbox transition: [299,  15,  77, 101] -> [301,  15,  77, 101] w/ P(a|s)=0.8271200060844421 and iou=0.0 and reward=0.0 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (0.0) for RIGHT:bbox transition: [301,  15,  77, 101] -> [303,  15,  77, 101] w/ P(a|s)=0.7923710942268372 and iou=0.0 and reward=0.0 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (0.0) for 2X UP:bbox transition: [303,  15,  77, 101] -> [303,   9,  77, 101] w/ P(a|s)=0.19830124080181122 and iou=0.0 and reward=0.0 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (0.0) for 2X LEFT:bbox transition: [303,   9,  77, 101] -> [299,   9,  77, 101] w/ P(a|s)=0.27595439553260803 and iou=0.0 and reward=0.0 and discount=0.8953382542587164\n",
            "   |->> Assigned losses: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 83 with src: [299,   9,  77, 101] and target: [320, 164,  61,  79]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0083.jpg\n",
            "|->> Beginning tracking for bbox:[299   9  77 101]\n",
            "   \u001b[33m|->> #0/t=55-th Action selection: 5/2X UP (P(a|s) = 0.23899999260902405)\u001b[0m\n",
            "      |->> Bounding box moves to: [299   3  77 101]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.7612 0.     0.     0.     0.2388 0.     0.     0.     0.\n",
            " 0.    ], argmax=1\n",
            "         |->> Action Probabilities (RAW): [1.3751895e-08 7.6117766e-01 1.7103471e-09 2.0915241e-09 8.6091143e-09\n",
            " 2.3881498e-01 3.4350942e-12 7.6201125e-09 1.2787105e-17 1.8484699e-12\n",
            " 7.3604001e-06], argmax=1\n",
            "   \u001b[33m|->> #1/t=56-th Action selection: 5/2X UP (P(a|s) = 0.7850000262260437)\u001b[0m\n",
            "      |->> Bounding box moves to: [299   0  77 101]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.1757 0.0396 0.     0.     0.7847 0.     0.     0.     0.\n",
            " 0.    ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.9186435e-05 1.7572947e-01 3.9571173e-02 2.4929489e-06 6.6641519e-06\n",
            " 7.8465754e-01 2.8563077e-08 1.2808033e-05 2.2585912e-11 1.5490022e-07\n",
            " 5.1717035e-07], argmax=5\n",
            "   \u001b[33m|->> #2/t=57-th Action selection: 1/2X LEFT (P(a|s) = 0.996999979019165)\u001b[0m\n",
            "      |->> Bounding box moves to: [295   0  77 101]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.9967 0.     0.     0.     0.0033 0.     0.     0.     0.\n",
            " 0.    ], argmax=1\n",
            "         |->> Action Probabilities (RAW): [2.5180609e-09 9.9668992e-01 1.1628483e-06 8.4505110e-08 3.6059101e-13\n",
            " 3.3088471e-03 2.1625774e-15 4.0608275e-13 4.2051586e-17 4.1020941e-13\n",
            " 3.3637762e-10], argmax=1\n",
            "|->> Revisiting bbox: [295   0  77 101]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [299,   9,  77, 101] -> [295,   0,  77, 101] (Target was [320, 164,  61,  79])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X UP:bbox transition: [299,   9,  77, 101] -> [299,   3,  77, 101] w/ P(a|s)=0.23881497979164124 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for 2X UP:bbox transition: [299,   3,  77, 101] -> [299,   0,  77, 101] w/ P(a|s)=0.7846575379371643 and iou=0.0 and reward=0.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X LEFT:bbox transition: [299,   0,  77, 101] -> [295,   0,  77, 101] w/ P(a|s)=0.9966899156570435 and iou=0.0 and reward=0.0 and discount=0.9801\n",
            "   |->> Assigned losses: [0. 0. 0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 84 with src: [295,   0,  77, 101] and target: [300, 149,  61,  79]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0084.jpg\n",
            "|->> Beginning tracking for bbox:[295   0  77 101]\n",
            "   \u001b[33m|->> #0/t=58-th Action selection: 7/2X DOWN (P(a|s) = 0.9909999966621399)\u001b[0m\n",
            "      |->> Bounding box moves to: [295   6  77 101]\n",
            "         |->> Action Probabilities (Rounded): [1.000e-04 7.400e-03 0.000e+00 0.000e+00 1.000e-04 3.000e-04 3.000e-04\n",
            " 9.911e-01 0.000e+00 1.000e-04 6.000e-04], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.2009398e-04 7.3672323e-03 1.8944615e-05 6.3375282e-06 9.0789094e-05\n",
            " 3.1506017e-04 2.8828427e-04 9.9107087e-01 1.5142153e-05 1.3763696e-04\n",
            " 5.6967058e-04], argmax=7\n",
            "   \u001b[33m|->> #1/t=59-th Action selection: 1/2X LEFT (P(a|s) = 0.13600000739097595)\u001b[0m\n",
            "      |->> Bounding box moves to: [291   6  77 101]\n",
            "         |->> Action Probabilities (Rounded): [1.100e-03 1.356e-01 1.993e-01 1.500e-03 2.050e-02 2.000e-04 6.000e-04\n",
            " 1.486e-01 0.000e+00 5.400e-03 4.872e-01], argmax=10\n",
            "         |->> Action Probabilities (RAW): [1.0812585e-03 1.3558233e-01 1.9933315e-01 1.5487509e-03 2.0454405e-02\n",
            " 1.9472401e-04 6.2646100e-04 1.4858052e-01 5.6914860e-07 5.4103676e-03\n",
            " 4.8718745e-01], argmax=10\n",
            "   \u001b[33m|->> #2/t=60-th Action selection: 10/SCALE UP (P(a|s) = 0.2980000078678131)\u001b[0m\n",
            "      |->> Bounding box moves to: [289   4  79 104]\n",
            "         |->> Action Probabilities (Rounded): [1.234e-01 2.500e-03 2.080e-02 4.000e-04 3.006e-01 2.428e-01 1.090e-02\n",
            " 4.000e-04 0.000e+00 1.000e-04 2.978e-01], argmax=4\n",
            "         |->> Action Probabilities (RAW): [1.2341309e-01 2.4890264e-03 2.0840082e-02 4.2996556e-04 3.0062947e-01\n",
            " 2.4284174e-01 1.0924642e-02 4.2546744e-04 2.9046723e-05 1.3834651e-04\n",
            " 2.9783911e-01], argmax=4\n",
            "   \u001b[33m|->> #3/t=61-th Action selection: 1/2X LEFT (P(a|s) = 0.06700000166893005)\u001b[0m\n",
            "      |->> Bounding box moves to: [285   4  79 104]\n",
            "         |->> Action Probabilities (Rounded): [9.280e-02 6.690e-02 3.700e-03 0.000e+00 8.900e-03 8.109e-01 1.000e-04\n",
            " 1.000e-04 0.000e+00 1.400e-03 1.500e-02], argmax=5\n",
            "         |->> Action Probabilities (RAW): [9.2844889e-02 6.6896662e-02 3.7404555e-03 9.6646982e-06 8.9175645e-03\n",
            " 8.1094748e-01 6.9143411e-05 8.4020394e-05 6.0691985e-07 1.4434749e-03\n",
            " 1.5046080e-02], argmax=5\n",
            "   \u001b[33m|->> #4/t=62-th Action selection: 4/UP (P(a|s) = 0.843999981880188)\u001b[0m\n",
            "      |->> Bounding box moves to: [285   1  79 104]\n",
            "         |->> Action Probabilities (Rounded): [5.170e-02 3.150e-02 0.000e+00 0.000e+00 8.439e-01 7.150e-02 0.000e+00\n",
            " 0.000e+00 0.000e+00 1.100e-03 2.000e-04], argmax=4\n",
            "         |->> Action Probabilities (RAW): [5.1749766e-02 3.1500276e-02 4.4102680e-06 2.0794243e-08 8.4392816e-01\n",
            " 7.1521372e-02 1.1167750e-06 9.2905284e-06 1.0212616e-05 1.1030772e-03\n",
            " 1.7235188e-04], argmax=4\n",
            "   \u001b[33m|->> #5/t=63-th Action selection: 1/2X LEFT (P(a|s) = 0.9470000267028809)\u001b[0m\n",
            "      |->> Bounding box moves to: [281   1  79 104]\n",
            "         |->> Action Probabilities (Rounded): [5.000e-04 9.467e-01 0.000e+00 1.000e-04 6.000e-04 3.860e-02 3.000e-04\n",
            " 7.400e-03 0.000e+00 5.300e-03 5.000e-04], argmax=1\n",
            "         |->> Action Probabilities (RAW): [5.4764276e-04 9.4665486e-01 3.4386596e-06 9.9890603e-05 5.7302450e-04\n",
            " 3.8648259e-02 3.1831508e-04 7.3535293e-03 2.3703217e-08 5.3471695e-03\n",
            " 4.5373588e-04], argmax=1\n",
            "   \u001b[33m|->> #6/t=64-th Action selection: 5/2X UP (P(a|s) = 0.9449999928474426)\u001b[0m\n",
            "      |->> Bounding box moves to: [281   0  79 104]\n",
            "         |->> Action Probabilities (Rounded): [2.100e-03 2.910e-02 0.000e+00 2.000e-04 4.200e-03 9.453e-01 9.900e-03\n",
            " 4.500e-03 0.000e+00 1.200e-03 3.500e-03], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.1196757e-03 2.9070910e-02 3.0826792e-05 1.8934174e-04 4.2413492e-03\n",
            " 9.4529283e-01 9.9021625e-03 4.4519589e-03 1.8395129e-05 1.2045668e-03\n",
            " 3.4779091e-03], argmax=5\n",
            "   \u001b[33m|->> #7/t=65-th Action selection: 1/2X LEFT (P(a|s) = 0.01899999938905239)\u001b[0m\n",
            "      |->> Bounding box moves to: [277   0  79 104]\n",
            "         |->> Action Probabilities (Rounded): [1.510e-02 1.870e-02 1.000e-04 0.000e+00 5.010e-02 6.084e-01 1.747e-01\n",
            " 1.740e-02 4.000e-04 2.180e-02 9.330e-02], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.5079219e-02 1.8657945e-02 6.9826441e-05 2.3231583e-05 5.0143402e-02\n",
            " 6.0843164e-01 1.7473787e-01 1.7363947e-02 4.3350912e-04 2.1766448e-02\n",
            " 9.3293086e-02], argmax=5\n",
            "|->> Revisiting bbox: [277   0  79 104]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [295,   0,  77, 101] -> [277,   0,  79, 104] (Target was [300, 149,  61,  79])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X DOWN:bbox transition: [295,   0,  77, 101] -> [295,   6,  77, 101] w/ P(a|s)=0.9910708665847778 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for 2X LEFT:bbox transition: [295,   6,  77, 101] -> [291,   6,  77, 101] w/ P(a|s)=0.1355823278427124 and iou=0.0 and reward=0.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.0) for SCALE UP:bbox transition: [291,   6,  77, 101] -> [289,   4,  79, 104] w/ P(a|s)=0.29783910512924194 and iou=0.0 and reward=0.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.0) for 2X LEFT:bbox transition: [289,   4,  79, 104] -> [285,   4,  79, 104] w/ P(a|s)=0.06689666211605072 and iou=0.0 and reward=0.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.0) for UP:bbox transition: [285,   4,  79, 104] -> [285,   1,  79, 104] w/ P(a|s)=0.8439281582832336 and iou=0.0 and reward=0.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.0) for 2X LEFT:bbox transition: [285,   1,  79, 104] -> [281,   1,  79, 104] w/ P(a|s)=0.9466548562049866 and iou=0.0 and reward=0.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.0) for 2X UP:bbox transition: [281,   1,  79, 104] -> [281,   0,  79, 104] w/ P(a|s)=0.9452928304672241 and iou=0.0 and reward=0.0 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (0.0) for 2X LEFT:bbox transition: [281,   0,  79, 104] -> [277,   0,  79, 104] w/ P(a|s)=0.018657945096492767 and iou=0.0 and reward=0.0 and discount=0.9320653479069899\n",
            "   |->> Assigned losses: [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 85 with src: [277,   0,  79, 104] and target: [281, 128,  61,  79]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0085.jpg\n",
            "|->> Beginning tracking for bbox:[277   0  79 104]\n",
            "|->> Revisiting bbox: [277   0  79 104]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=66-th Action selection: 8/STOP (P(a|s) = 0.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [277   0  79 104]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.7080782e-14 1.6261531e-12 8.4436459e-17 2.4603750e-16 1.9414827e-08\n",
            " 1.0000000e+00 2.8612006e-18 6.3305675e-16 1.1696959e-19 2.8288095e-15\n",
            " 7.4779850e-14], argmax=5\n",
            "         |->> Hit a STOP on the 66-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [277,   0,  79, 104] -> [277,   0,  79, 104] (Target was [281, 128,  61,  79])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [277,   0,  79, 104] -> [277,   0,  79, 104] w/ P(a|s)=1.1696959416838055e-19 and iou=0.0 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-11.512925]\n",
            "\u001b[31m>> Total frame loss: -11.512925148010254\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 86 with src: [277,   0,  79, 104] and target: [251, 102,  79,  79]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0086.jpg\n",
            "|->> Beginning tracking for bbox:[277   0  79 104]\n",
            "|->> Revisiting bbox: [277   0  79 104]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=66-th Action selection: 8/STOP (P(a|s) = 0.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [277   0  79 104]\n",
            "         |->> Action Probabilities (Rounded): [6.000e-04 5.000e-03 0.000e+00 0.000e+00 6.000e-04 9.931e-01 1.000e-04\n",
            " 0.000e+00 0.000e+00 5.000e-04 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [5.6615513e-04 5.0206664e-03 6.2256245e-06 1.4771545e-05 6.1804382e-04\n",
            " 9.9307430e-01 1.2700753e-04 4.0142619e-05 4.2398082e-07 5.0620496e-04\n",
            " 2.5997957e-05], argmax=5\n",
            "         |->> Hit a STOP on the 66-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [277,   0,  79, 104] -> [277,   0,  79, 104] (Target was [251, 102,  79,  79])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [277,   0,  79, 104] -> [277,   0,  79, 104] w/ P(a|s)=4.2398082200634235e-07 and iou=0.007386244860985297 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-11.512925]\n",
            "\u001b[31m>> Total frame loss: -11.512925148010254\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 87 with src: [277,   0,  79, 104] and target: [241,  81,  74,  79]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0087.jpg\n",
            "|->> Beginning tracking for bbox:[277   0  79 104]\n",
            "|->> Revisiting bbox: [277   0  79 104]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=66-th Action selection: 8/STOP (P(a|s) = 0.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [277   0  79 104]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.5758329e-27 2.3762190e-12 8.7959414e-21 2.3937222e-13 5.0399185e-22\n",
            " 1.0000000e+00 9.9878966e-27 9.8302338e-20 0.0000000e+00 8.9089624e-22\n",
            " 2.0069871e-18], argmax=5\n",
            "         |->> Hit a STOP on the 66-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [277,   0,  79, 104] -> [277,   0,  79, 104] (Target was [241,  81,  74,  79])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [277,   0,  79, 104] -> [277,   0,  79, 104] w/ P(a|s)=0.0 and iou=0.06627236882013952 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-11.512925]\n",
            "\u001b[31m>> Total frame loss: -11.512925148010254\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 88 with src: [277,   0,  79, 104] and target: [228,  54,  80,  89]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0088.jpg\n",
            "|->> Beginning tracking for bbox:[277   0  79 104]\n",
            "   \u001b[33m|->> #0/t=66-th Action selection: 1/2X LEFT (P(a|s) = 0.9919999837875366)\u001b[0m\n",
            "      |->> Bounding box moves to: [273   0  79 104]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 9.922e-01 0.000e+00 0.000e+00 1.000e-04 7.700e-03 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=1\n",
            "         |->> Action Probabilities (RAW): [3.0522959e-05 9.9217188e-01 8.7380614e-10 1.1664701e-10 6.9733876e-05\n",
            " 7.7102217e-03 3.9854395e-08 5.8982232e-07 3.3960185e-12 5.0831295e-06\n",
            " 1.1963374e-05], argmax=1\n",
            "   \u001b[33m|->> #1/t=67-th Action selection: 2/RIGHT (P(a|s) = 0.9760000109672546)\u001b[0m\n",
            "      |->> Bounding box moves to: [275   0  79 104]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 9.759e-01 2.390e-02 0.000e+00 0.000e+00 0.000e+00\n",
            " 2.000e-04 0.000e+00 0.000e+00 0.000e+00], argmax=2\n",
            "         |->> Action Probabilities (RAW): [9.6695082e-11 6.4047214e-08 9.7588444e-01 2.3867354e-02 3.7828786e-06\n",
            " 4.8147253e-08 4.7598376e-05 1.9530058e-04 4.6083767e-10 1.0274927e-06\n",
            " 3.2269909e-07], argmax=2\n",
            "|->> Revisiting bbox: [277   0  79 104]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [277,   0,  79, 104] -> [275,   0,  79, 104] (Target was [228,  54,  80,  89])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.016) for 2X LEFT:bbox transition: [277,   0,  79, 104] -> [273,   0,  79, 104] w/ P(a|s)=0.9921718835830688 and iou=0.12880906815839835 and reward=0.01637616521338167 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.008) for RIGHT:bbox transition: [273,   0,  79, 104] -> [275,   0,  79, 104] w/ P(a|s)=0.9758844375610352 and iou=0.12056115738711091 and reward=-0.008247910771287434 and discount=0.99\n",
            "   |->> Assigned losses: [ 0.0001287  -0.00019933]\n",
            "\u001b[31m>> Total frame loss: -7.062828808557242e-05\u001b[0m\n",
            "Final bounding box: [275   0  79 104] reached in 68 timesteps (originating from [324 138  70  94]). Target was [228  54  80  89]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 89 in t=68 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[31m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 11.211698532104492\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.01933440752327442\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 4.310771942138672\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.0158557016402483\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 3.8855245113372803\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.018905799835920334\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 2.2678005695343018\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.008795596659183502\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 1.4000850915908813\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.009738256223499775\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 3.28130841255188\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 0.07796532660722733\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/Matrix\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Starting bounding box for adnet_datasets/OTB/Matrix: frames 35:45 is [397  82  38  39].\n",
            "\u001b[34m>> Attempting to reach frame 36 with src: [397,  82,  38,  39] and target: [400,  97,  39,  32]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0036.jpg\n",
            "|->> Beginning tracking for bbox:[397  82  38  39]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [397  80  38  39]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [5.7868160e-20 5.9545087e-16 3.2373450e-18 4.3284174e-12 5.4281482e-13\n",
            " 1.0000000e+00 2.3534892e-24 2.4467557e-17 5.9150412e-26 3.1223152e-26\n",
            " 1.7784458e-17], argmax=5\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [397  78  38  39]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.3574603e-13 3.3704797e-12 1.3561683e-14 5.1319468e-18 8.1332402e-10\n",
            " 1.0000000e+00 3.0523007e-20 2.7565171e-18 1.7277220e-20 2.5444783e-15\n",
            " 2.9700567e-15], argmax=5\n",
            "   \u001b[33m|->> #2/t=3-th Action selection: 5/2X UP (P(a|s) = 0.9900000095367432)\u001b[0m\n",
            "      |->> Bounding box moves to: [397  76  38  39]\n",
            "         |->> Action Probabilities (Rounded): [1.000e-04 9.000e-04 0.000e+00 0.000e+00 9.400e-03 9.896e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [6.4545522e-05 9.0599933e-04 1.6249991e-09 1.5315677e-09 9.4093466e-03\n",
            " 9.8960614e-01 1.3540267e-07 6.1582059e-11 1.7433513e-11 1.3851468e-05\n",
            " 6.5186676e-08], argmax=5\n",
            "   \u001b[33m|->> #3/t=4-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [397  74  38  39]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [4.6592856e-19 9.7699496e-13 1.1393398e-27 2.4752981e-22 3.2120296e-14\n",
            " 1.0000000e+00 9.3750158e-38 2.3911752e-36 1.3412633e-33 5.1474189e-17\n",
            " 2.7876902e-26], argmax=5\n",
            "   \u001b[33m|->> #4/t=5-th Action selection: 5/2X UP (P(a|s) = 0.902999997138977)\u001b[0m\n",
            "      |->> Bounding box moves to: [397  72  38  39]\n",
            "         |->> Action Probabilities (Rounded): [0.    0.097 0.    0.    0.    0.903 0.    0.    0.    0.    0.   ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.5275272e-08 9.6999601e-02 3.6511008e-10 1.0285987e-08 1.7852289e-09\n",
            " 9.0300035e-01 2.1993792e-11 2.1035795e-11 1.6279597e-14 3.4642415e-08\n",
            " 6.7661737e-10], argmax=5\n",
            "   \u001b[33m|->> #5/t=6-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [397  70  38  39]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.2980432e-15 1.2467695e-12 3.2833086e-20 5.6230262e-18 1.5174589e-09\n",
            " 1.0000000e+00 8.2416436e-22 1.4131725e-29 7.5604651e-25 7.6326012e-15\n",
            " 1.6647621e-14], argmax=5\n",
            "   \u001b[33m|->> #6/t=7-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [397  68  38  39]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 2.000e-04 0.000e+00 0.000e+00 0.000e+00 9.998e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.8304856e-07 1.5558816e-04 7.2271866e-10 3.7736797e-06 7.4718932e-06\n",
            " 9.9980658e-01 1.1460042e-11 1.9721082e-11 7.6213580e-13 2.2022502e-07\n",
            " 2.6144715e-05], argmax=5\n",
            "   \u001b[33m|->> #7/t=8-th Action selection: 5/2X UP (P(a|s) = 0.9990000128746033)\u001b[0m\n",
            "      |->> Bounding box moves to: [397  66  38  39]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 5.000e-04 0.000e+00 0.000e+00 0.000e+00 9.986e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 9.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.6755710e-05 4.5723681e-04 4.9375020e-09 3.7512420e-09 2.9921261e-05\n",
            " 9.9859852e-01 2.2099184e-06 1.3908914e-06 9.3177110e-09 5.1166936e-08\n",
            " 8.9396228e-04], argmax=5\n",
            "   \u001b[33m|->> #8/t=9-th Action selection: 5/2X UP (P(a|s) = 0.9769999980926514)\u001b[0m\n",
            "      |->> Bounding box moves to: [397  64  38  39]\n",
            "         |->> Action Probabilities (Rounded): [0.0161 0.0027 0.     0.     0.     0.9765 0.     0.     0.     0.\n",
            " 0.0046], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.6137494e-02 2.7410737e-03 3.6132789e-07 8.7297614e-10 7.8987496e-06\n",
            " 9.7654891e-01 8.4849089e-06 1.7092148e-08 1.4845683e-10 6.4120592e-10\n",
            " 4.5557516e-03], argmax=5\n",
            "   \u001b[33m|->> #9/t=10-th Action selection: 4/UP (P(a|s) = 0.9940000176429749)\u001b[0m\n",
            "      |->> Bounding box moves to: [397  63  38  39]\n",
            "         |->> Action Probabilities (Rounded): [6.000e-03 3.000e-04 0.000e+00 0.000e+00 9.936e-01 1.000e-04 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=4\n",
            "         |->> Action Probabilities (RAW): [6.0018473e-03 3.1573736e-04 2.8286069e-14 4.0711005e-16 9.9361789e-01\n",
            " 6.4403386e-05 3.3048442e-11 6.9265901e-08 4.1071689e-14 3.3019032e-14\n",
            " 4.0977911e-12], argmax=4\n",
            "   \u001b[33m|->> #10/t=11-th Action selection: 1/2X LEFT (P(a|s) = 0.9980000257492065)\u001b[0m\n",
            "      |->> Bounding box moves to: [395  63  38  39]\n",
            "         |->> Action Probabilities (Rounded): [0.0024 0.9976 0.     0.     0.     0.     0.     0.     0.     0.\n",
            " 0.    ], argmax=1\n",
            "         |->> Action Probabilities (RAW): [2.3985435e-03 9.9760109e-01 6.0647136e-16 1.2402206e-12 2.3132984e-07\n",
            " 4.4860563e-08 2.3868278e-09 5.5869393e-08 3.2223480e-15 1.2448379e-11\n",
            " 8.4049323e-10], argmax=1\n",
            "   \u001b[33m|->> #11/t=12-th Action selection: 4/UP (P(a|s) = 0.9169999957084656)\u001b[0m\n",
            "      |->> Bounding box moves to: [395  62  38  39]\n",
            "         |->> Action Probabilities (Rounded): [4.890e-02 3.000e-04 5.200e-03 0.000e+00 9.169e-01 3.000e-03 1.890e-02\n",
            " 4.800e-03 8.000e-04 8.000e-04 4.000e-04], argmax=4\n",
            "         |->> Action Probabilities (RAW): [4.8911732e-02 3.2498181e-04 5.1725665e-03 7.9273796e-06 9.1693234e-01\n",
            " 3.0346129e-03 1.8861845e-02 4.7593759e-03 8.2311296e-04 7.7419862e-04\n",
            " 3.9737014e-04], argmax=4\n",
            "   \u001b[33m|->> #12/t=13-th Action selection: 0/LEFT (P(a|s) = 0.257999986410141)\u001b[0m\n",
            "      |->> Bounding box moves to: [394  62  38  39]\n",
            "         |->> Action Probabilities (Rounded): [2.583e-01 6.203e-01 4.000e-04 0.000e+00 1.700e-03 5.900e-03 1.060e-02\n",
            " 6.740e-02 4.000e-04 1.620e-02 1.880e-02], argmax=1\n",
            "         |->> Action Probabilities (RAW): [2.58347452e-01 6.20325446e-01 3.86741041e-04 1.47418905e-05\n",
            " 1.67474453e-03 5.85692469e-03 1.06498320e-02 6.73715398e-02\n",
            " 3.80616664e-04 1.61976926e-02 1.87943168e-02], argmax=1\n",
            "   \u001b[33m|->> #13/t=14-th Action selection: 1/2X LEFT (P(a|s) = 0.3400000035762787)\u001b[0m\n",
            "      |->> Bounding box moves to: [392  62  38  39]\n",
            "         |->> Action Probabilities (Rounded): [6.092e-01 3.396e-01 6.000e-04 6.000e-04 1.400e-03 3.370e-02 1.000e-04\n",
            " 1.000e-04 0.000e+00 8.000e-04 1.390e-02], argmax=0\n",
            "         |->> Action Probabilities (RAW): [6.0918456e-01 3.3958974e-01 6.0981110e-04 6.1951793e-04 1.4116294e-03\n",
            " 3.3653278e-02 1.1093835e-04 5.4239066e-05 7.9173478e-06 8.4602018e-04\n",
            " 1.3912335e-02], argmax=0\n",
            "   \u001b[33m|->> #14/t=15-th Action selection: 10/SCALE UP (P(a|s) = 0.8090000152587891)\u001b[0m\n",
            "      |->> Bounding box moves to: [391  61  40  41]\n",
            "         |->> Action Probabilities (Rounded): [1.110e-02 3.000e-03 1.027e-01 4.000e-04 6.480e-02 3.600e-03 0.000e+00\n",
            " 0.000e+00 6.000e-04 5.100e-03 8.086e-01], argmax=10\n",
            "         |->> Action Probabilities (RAW): [1.1082152e-02 3.0326967e-03 1.0273712e-01 3.5438372e-04 6.4841665e-02\n",
            " 3.6096426e-03 3.5592986e-06 3.9334623e-06 6.1369344e-04 5.0995327e-03\n",
            " 8.0862159e-01], argmax=10\n",
            "   \u001b[33m|->> #15/t=16-th Action selection: 5/2X UP (P(a|s) = 0.953000009059906)\u001b[0m\n",
            "      |->> Bounding box moves to: [391  59  40  41]\n",
            "         |->> Action Probabilities (Rounded): [4.100e-02 2.200e-03 0.000e+00 0.000e+00 6.000e-04 9.531e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 3.100e-03], argmax=5\n",
            "         |->> Action Probabilities (RAW): [4.0967733e-02 2.1687022e-03 1.0478490e-05 4.1284647e-09 6.2330888e-04\n",
            " 9.5314485e-01 3.8598788e-08 7.1891090e-11 4.7853177e-07 5.0415338e-08\n",
            " 3.0843613e-03], argmax=5\n",
            "   \u001b[33m|->> #16/t=17-th Action selection: 10/SCALE UP (P(a|s) = 0.9990000128746033)\u001b[0m\n",
            "      |->> Bounding box moves to: [390  58  42  43]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.0012 0.     0.     0.     0.     0.     0.     0.\n",
            " 0.9988], argmax=10\n",
            "         |->> Action Probabilities (RAW): [1.6780507e-07 7.8612777e-07 1.1730582e-03 9.3180892e-15 1.7469006e-06\n",
            " 2.4246095e-08 2.8859606e-07 4.5941952e-06 7.2551757e-08 5.4683525e-08\n",
            " 9.9881917e-01], argmax=10\n",
            "   \u001b[33m|->> #17/t=18-th Action selection: 10/SCALE UP (P(a|s) = 0.3569999933242798)\u001b[0m\n",
            "      |->> Bounding box moves to: [389  57  44  45]\n",
            "         |->> Action Probabilities (Rounded): [1.000e-04 3.000e-04 1.800e-03 0.000e+00 1.350e-02 6.268e-01 0.000e+00\n",
            " 5.000e-04 0.000e+00 2.000e-04 3.568e-01], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.4334742e-04 3.1849273e-04 1.7933252e-03 4.0661143e-07 1.3470228e-02\n",
            " 6.2684035e-01 8.6056125e-06 4.6073689e-04 2.1761683e-07 1.6283859e-04\n",
            " 3.5680145e-01], argmax=5\n",
            "   \u001b[33m|->> #18/t=19-th Action selection: 5/2X UP (P(a|s) = 0.9679999947547913)\u001b[0m\n",
            "      |->> Bounding box moves to: [389  55  44  45]\n",
            "         |->> Action Probabilities (Rounded): [1.000e-04 1.000e-04 0.000e+00 0.000e+00 3.150e-02 9.678e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 3.000e-04 3.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [5.2660733e-05 5.4542983e-05 1.9163406e-06 1.1707899e-06 3.1453114e-02\n",
            " 9.6781009e-01 1.7632719e-06 3.2967528e-06 1.1738364e-08 3.2137346e-04\n",
            " 3.0002132e-04], argmax=5\n",
            "   \u001b[33m|->> #19/t=20-th Action selection: 5/2X UP (P(a|s) = 0.7300000190734863)\u001b[0m\n",
            "      |->> Bounding box moves to: [389  53  44  45]\n",
            "         |->> Action Probabilities (Rounded): [5.830e-02 1.416e-01 1.400e-03 2.000e-04 2.640e-02 7.297e-01 4.000e-03\n",
            " 8.700e-03 3.000e-04 1.160e-02 1.780e-02], argmax=5\n",
            "         |->> Action Probabilities (RAW): [5.8316104e-02 1.4158364e-01 1.4136938e-03 1.8340789e-04 2.6398892e-02\n",
            " 7.2974175e-01 4.0314272e-03 8.6872587e-03 2.5340382e-04 1.1592084e-02\n",
            " 1.7798327e-02], argmax=5\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [397,  82,  38,  39] -> [389,  53,  44,  45] (Target was [400,  97,  39,  32])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.052) for 2X UP:bbox transition: [397,  82,  38,  39] -> [397,  80,  38,  39] w/ P(a|s)=1.0 and iou=0.39285714285714285 and reward=-0.05158730158730157 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (-0.048) for 2X UP:bbox transition: [397,  80,  38,  39] -> [397,  78,  38,  39] w/ P(a|s)=1.0 and iou=0.3448275862068966 and reward=-0.048029556650246275 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (-0.045) for 2X UP:bbox transition: [397,  78,  38,  39] -> [397,  76,  38,  39] w/ P(a|s)=0.9896061420440674 and iou=0.3 and reward=-0.044827586206896586 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (-0.042) for 2X UP:bbox transition: [397,  76,  38,  39] -> [397,  74,  38,  39] w/ P(a|s)=1.0 and iou=0.25806451612903225 and reward=-0.04193548387096774 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (-0.039) for 2X UP:bbox transition: [397,  74,  38,  39] -> [397,  72,  38,  39] w/ P(a|s)=0.9030003547668457 and iou=0.21875 and reward=-0.03931451612903225 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (-0.037) for 2X UP:bbox transition: [397,  72,  38,  39] -> [397,  70,  38,  39] w/ P(a|s)=1.0 and iou=0.18181818181818182 and reward=-0.03693181818181818 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (-0.035) for 2X UP:bbox transition: [397,  70,  38,  39] -> [397,  68,  38,  39] w/ P(a|s)=0.9998065829277039 and iou=0.14705882352941177 and reward=-0.034759358288770054 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (-0.033) for 2X UP:bbox transition: [397,  68,  38,  39] -> [397,  66,  38,  39] w/ P(a|s)=0.9985985159873962 and iou=0.11428571428571428 and reward=-0.03277310924369749 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (-0.031) for 2X UP:bbox transition: [397,  66,  38,  39] -> [397,  64,  38,  39] w/ P(a|s)=0.9765489101409912 and iou=0.08333333333333333 and reward=-0.030952380952380953 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (-0.015) for UP:bbox transition: [397,  64,  38,  39] -> [397,  63,  38,  39] w/ P(a|s)=0.9936178922653198 and iou=0.0684931506849315 and reward=-0.014840182648401826 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (-0.004) for 2X LEFT:bbox transition: [397,  63,  38,  39] -> [395,  63,  38,  39] w/ P(a|s)=0.9976010918617249 and iou=0.06432748538011696 and reward=-0.0041656653048145476 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (-0.014) for UP:bbox transition: [395,  63,  38,  39] -> [395,  62,  38,  39] w/ P(a|s)=0.9169323444366455 and iou=0.050808314087759814 and reward=-0.013519171292357142 and discount=0.8953382542587164\n",
            "   |->> t=13 Diff-Reward (-0.002) for LEFT:bbox transition: [395,  62,  38,  39] -> [394,  62,  38,  39] w/ P(a|s)=0.25834745168685913 and iou=0.04919292851652575 and reward=-0.001615385571234064 and discount=0.8863848717161292\n",
            "   |->> t=14 Diff-Reward (-0.003) for 2X LEFT:bbox transition: [394,  62,  38,  39] -> [392,  62,  38,  39] w/ P(a|s)=0.3395897448062897 and iou=0.04597701149425287 and reward=-0.0032159170222728767 and discount=0.8775210229989678\n",
            "   |->> t=15 Diff-Reward (0.011) for SCALE UP:bbox transition: [392,  62,  38,  39] -> [391,  61,  40,  41] w/ P(a|s)=0.8086215853691101 and iou=0.056714233443102814 and reward=0.010737221948849941 and discount=0.8687458127689782\n",
            "   |->> t=16 Diff-Reward (-0.023) for 2X UP:bbox transition: [391,  61,  40,  41] -> [391,  59,  40,  41] w/ P(a|s)=0.9531448483467102 and iou=0.0332737030411449 and reward=-0.023440530401957912 and discount=0.8600583546412884\n",
            "   |->> t=17 Diff-Reward (0.01) for SCALE UP:bbox transition: [391,  59,  40,  41] -> [390,  58,  42,  43] w/ P(a|s)=0.9988191723823547 and iou=0.043745727956254275 and reward=0.010472024915109374 and discount=0.8514577710948755\n",
            "   |->> t=18 Diff-Reward (0.01) for SCALE UP:bbox transition: [390,  58,  42,  43] -> [389,  57,  44,  45] w/ P(a|s)=0.35680145025253296 and iou=0.05386875612144956 and reward=0.010123028165195287 and discount=0.8429431933839268\n",
            "   |->> t=19 Diff-Reward (-0.022) for 2X UP:bbox transition: [389,  57,  44,  45] -> [389,  55,  44,  45] w/ P(a|s)=0.9678100943565369 and iou=0.031639501438159155 and reward=-0.022229254683290407 and discount=0.8345137614500875\n",
            "   |->> t=20 Diff-Reward (-0.021) for 2X UP:bbox transition: [389,  55,  44,  45] -> [389,  53,  44,  45] w/ P(a|s)=0.7297417521476746 and iou=0.010328638497652582 and reward=-0.021310862940506575 and discount=0.8261686238355866\n",
            "   |->> Assigned losses: [-5.1657616e-07 -4.7614074e-07 -4.5904933e-04 -4.0745422e-07\n",
            " -3.8532887e-03 -3.5169660e-07 -6.3302336e-06 -4.2840715e-05\n",
            " -6.7776861e-04 -8.6797991e-05 -9.0483909e-06 -1.0496982e-03\n",
            " -1.9379418e-03 -3.0478458e-03  1.9814754e-03 -9.6745684e-04\n",
            "  1.0535055e-05  8.7940451e-03 -6.0696504e-04 -5.5471417e-03]\n",
            "\u001b[31m>> Total frame loss: -0.007507869973778725\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 37 with src: [389,  53,  44,  45] and target: [403, 105,  38,  36]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0037.jpg\n",
            "|->> Beginning tracking for bbox:[389  53  44  45]\n",
            "   \u001b[33m|->> #0/t=21-th Action selection: 5/2X UP (P(a|s) = 0.9980000257492065)\u001b[0m\n",
            "      |->> Bounding box moves to: [389  51  44  45]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.0015 0.     0.     0.     0.9985 0.     0.     0.     0.\n",
            " 0.    ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [7.38512043e-08 1.51458872e-03 2.45520209e-17 2.15318909e-15\n",
            " 1.43210768e-08 9.98469055e-01 2.14294554e-12 1.62037595e-05\n",
            " 8.93174891e-20 1.05486336e-07 1.74760423e-12], argmax=5\n",
            "   \u001b[33m|->> #1/t=22-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [389  49  44  45]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.35967116e-12 1.39664875e-08 6.06561720e-20 3.03865006e-12\n",
            " 1.97825697e-12 9.99999881e-01 5.94699119e-17 1.19037104e-07\n",
            " 1.31766939e-28 4.52995295e-15 1.17574263e-14], argmax=5\n",
            "   \u001b[33m|->> #2/t=23-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [389  47  44  45]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.8992527e-08 2.1284279e-06 1.2994622e-10 2.3897512e-08 2.0400967e-05\n",
            " 9.9997747e-01 1.5794544e-11 1.6831647e-08 4.6290071e-13 2.6775152e-10\n",
            " 1.7865411e-10], argmax=5\n",
            "   \u001b[33m|->> #3/t=24-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [389  45  44  45]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e-04 9.999e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.0289732e-07 1.5757205e-07 2.6103214e-07 7.4822246e-09 1.1992031e-04\n",
            " 9.9987936e-01 1.1105303e-10 1.0560545e-12 5.3309414e-12 2.7649284e-08\n",
            " 1.1625312e-08], argmax=5\n",
            "   \u001b[33m|->> #4/t=25-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [389  43  44  45]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.9705979e-13 1.0368886e-11 5.1793301e-16 1.4122685e-12 1.5129670e-10\n",
            " 1.0000000e+00 1.0869787e-20 3.3878180e-19 5.9564413e-23 5.0610640e-18\n",
            " 1.1758235e-14], argmax=5\n",
            "   \u001b[33m|->> #5/t=26-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [389  41  44  45]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e-04 9.999e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.4737803e-06 1.1049912e-06 5.3449289e-10 6.1755632e-09 9.0561072e-05\n",
            " 9.9990678e-01 4.6306729e-14 9.2144589e-15 7.9200632e-11 8.5681606e-10\n",
            " 4.0178945e-09], argmax=5\n",
            "   \u001b[33m|->> #6/t=27-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [389  39  44  45]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [7.0208053e-08 3.7070029e-07 5.0761008e-07 7.2181507e-07 1.8379316e-05\n",
            " 9.9997985e-01 2.7439999e-09 1.0149325e-09 2.0119068e-10 7.6370178e-08\n",
            " 1.9424881e-08], argmax=5\n",
            "   \u001b[33m|->> #7/t=28-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [389  37  44  45]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.7078378e-08 5.5383731e-10 4.6157378e-08 7.4313644e-09 4.5976885e-05\n",
            " 9.9995387e-01 8.3297126e-11 3.1559976e-12 1.8190007e-11 6.1504905e-11\n",
            " 3.7723321e-08], argmax=5\n",
            "|->> Revisiting bbox: [389  37  44  45]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [389,  53,  44,  45] -> [389,  37,  44,  45] (Target was [403, 105,  38,  36])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X UP:bbox transition: [389,  53,  44,  45] -> [389,  51,  44,  45] w/ P(a|s)=0.9984690546989441 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for 2X UP:bbox transition: [389,  51,  44,  45] -> [389,  49,  44,  45] w/ P(a|s)=0.9999998807907104 and iou=0.0 and reward=0.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X UP:bbox transition: [389,  49,  44,  45] -> [389,  47,  44,  45] w/ P(a|s)=0.9999774694442749 and iou=0.0 and reward=0.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.0) for 2X UP:bbox transition: [389,  47,  44,  45] -> [389,  45,  44,  45] w/ P(a|s)=0.9998793601989746 and iou=0.0 and reward=0.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.0) for 2X UP:bbox transition: [389,  45,  44,  45] -> [389,  43,  44,  45] w/ P(a|s)=1.0 and iou=0.0 and reward=0.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.0) for 2X UP:bbox transition: [389,  43,  44,  45] -> [389,  41,  44,  45] w/ P(a|s)=0.9999067783355713 and iou=0.0 and reward=0.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.0) for 2X UP:bbox transition: [389,  41,  44,  45] -> [389,  39,  44,  45] w/ P(a|s)=0.9999798536300659 and iou=0.0 and reward=0.0 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (0.0) for 2X UP:bbox transition: [389,  39,  44,  45] -> [389,  37,  44,  45] w/ P(a|s)=0.9999538660049438 and iou=0.0 and reward=0.0 and discount=0.9320653479069899\n",
            "   |->> Assigned losses: [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 38 with src: [389,  37,  44,  45] and target: [404, 110,  41,  34]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0038.jpg\n",
            "|->> Beginning tracking for bbox:[389  37  44  45]\n",
            "   \u001b[33m|->> #0/t=29-th Action selection: 10/SCALE UP (P(a|s) = 0.18199999630451202)\u001b[0m\n",
            "      |->> Bounding box moves to: [388  36  46  47]\n",
            "         |->> Action Probabilities (Rounded): [0.0573 0.0522 0.0563 0.0037 0.1613 0.0996 0.2684 0.029  0.0366 0.0539\n",
            " 0.1819], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.05728589 0.05223631 0.05626785 0.00366777 0.16126496 0.09957352\n",
            " 0.26841006 0.02896714 0.03660206 0.05385248 0.18187198], argmax=6\n",
            "   \u001b[33m|->> #1/t=30-th Action selection: 4/UP (P(a|s) = 0.28299999237060547)\u001b[0m\n",
            "      |->> Bounding box moves to: [388  35  46  47]\n",
            "         |->> Action Probabilities (Rounded): [0.1014 0.0106 0.0441 0.0022 0.2831 0.0218 0.2968 0.003  0.0411 0.0233\n",
            " 0.1726], argmax=6\n",
            "         |->> Action Probabilities (RAW): [0.10137677 0.01064003 0.0441393  0.00215434 0.28307715 0.0218018\n",
            " 0.2967518  0.00299633 0.04111577 0.02333436 0.17261238], argmax=6\n",
            "   \u001b[33m|->> #2/t=31-th Action selection: 4/UP (P(a|s) = 0.6949999928474426)\u001b[0m\n",
            "      |->> Bounding box moves to: [388  34  46  47]\n",
            "         |->> Action Probabilities (Rounded): [4.330e-02 6.000e-04 2.900e-03 3.100e-03 6.955e-01 7.290e-02 3.430e-02\n",
            " 7.000e-04 1.800e-03 8.200e-03 1.368e-01], argmax=4\n",
            "         |->> Action Probabilities (RAW): [4.3265622e-02 6.4089790e-04 2.8924579e-03 3.1167159e-03 6.9547617e-01\n",
            " 7.2892189e-02 3.4279618e-02 7.2172319e-04 1.7952258e-03 8.1524123e-03\n",
            " 1.3676693e-01], argmax=4\n",
            "|->> Revisiting bbox: [388  34  46  47]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [389,  37,  44,  45] -> [388,  34,  46,  47] (Target was [404, 110,  41,  34])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for SCALE UP:bbox transition: [389,  37,  44,  45] -> [388,  36,  46,  47] w/ P(a|s)=0.18187198042869568 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for UP:bbox transition: [388,  36,  46,  47] -> [388,  35,  46,  47] w/ P(a|s)=0.2830771505832672 and iou=0.0 and reward=0.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.0) for UP:bbox transition: [388,  35,  46,  47] -> [388,  34,  46,  47] w/ P(a|s)=0.6954761743545532 and iou=0.0 and reward=0.0 and discount=0.9801\n",
            "   |->> Assigned losses: [0. 0. 0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 39 with src: [388,  34,  46,  47] and target: [400, 111,  41,  38]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0039.jpg\n",
            "|->> Beginning tracking for bbox:[388  34  46  47]\n",
            "   \u001b[33m|->> #0/t=32-th Action selection: 5/2X UP (P(a|s) = 0.9559999704360962)\u001b[0m\n",
            "      |->> Bounding box moves to: [388  32  46  47]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 1.000e-04 0.000e+00 0.000e+00 1.000e-04 9.559e-01 0.000e+00\n",
            " 3.700e-02 0.000e+00 0.000e+00 6.900e-03], argmax=5\n",
            "         |->> Action Probabilities (RAW): [7.4114196e-06 8.4751460e-05 7.5526395e-06 4.5993085e-07 6.5088432e-05\n",
            " 9.5589536e-01 6.8675295e-06 3.7031811e-02 3.6677207e-07 2.2673287e-06\n",
            " 6.8979934e-03], argmax=5\n",
            "   \u001b[33m|->> #1/t=33-th Action selection: 10/SCALE UP (P(a|s) = 0.2160000056028366)\u001b[0m\n",
            "      |->> Bounding box moves to: [387  31  48  49]\n",
            "         |->> Action Probabilities (Rounded): [0.3491 0.0434 0.0051 0.     0.0371 0.0695 0.2151 0.0293 0.0157 0.0198\n",
            " 0.2159], argmax=0\n",
            "         |->> Action Probabilities (RAW): [3.4910962e-01 4.3396480e-02 5.1086512e-03 2.2538341e-05 3.7053756e-02\n",
            " 6.9459759e-02 2.1508271e-01 2.9311767e-02 1.5687712e-02 1.9847922e-02\n",
            " 2.1591902e-01], argmax=0\n",
            "   \u001b[33m|->> #2/t=34-th Action selection: 10/SCALE UP (P(a|s) = 0.13199999928474426)\u001b[0m\n",
            "      |->> Bounding box moves to: [386  30  50  51]\n",
            "         |->> Action Probabilities (Rounded): [2.590e-02 2.700e-03 3.450e-02 5.000e-04 8.750e-02 6.128e-01 1.940e-02\n",
            " 3.680e-02 6.100e-03 4.230e-02 1.317e-01], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.5883241e-02 2.6793329e-03 3.4496441e-02 4.5896534e-04 8.7497726e-02\n",
            " 6.1275440e-01 1.9380866e-02 3.6836404e-02 6.0722968e-03 4.2258848e-02\n",
            " 1.3168146e-01], argmax=5\n",
            "   \u001b[33m|->> #3/t=35-th Action selection: 5/2X UP (P(a|s) = 0.9990000128746033)\u001b[0m\n",
            "      |->> Bounding box moves to: [386  28  50  51]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 9.991e-01 0.000e+00\n",
            " 1.000e-04 0.000e+00 0.000e+00 8.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [5.8507844e-06 1.9994113e-06 1.2639146e-06 8.9817752e-07 1.0078580e-05\n",
            " 9.9906307e-01 1.6226199e-06 6.8916961e-05 7.6848451e-08 3.9334307e-05\n",
            " 8.0687524e-04], argmax=5\n",
            "   \u001b[33m|->> #4/t=36-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [386  26  50  51]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 9.998e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 2.000e-04 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.8655279e-05 1.3317642e-06 4.9973033e-07 1.2028952e-06 1.8537114e-05\n",
            " 9.9975592e-01 1.4931459e-10 8.1218499e-09 4.6093832e-10 1.7800459e-04\n",
            " 2.5791442e-05], argmax=5\n",
            "   \u001b[33m|->> #5/t=37-th Action selection: 4/UP (P(a|s) = 0.03999999910593033)\u001b[0m\n",
            "      |->> Bounding box moves to: [386  25  50  51]\n",
            "         |->> Action Probabilities (Rounded): [2.070e-02 1.544e-01 3.000e-04 1.900e-03 3.990e-02 7.752e-01 0.000e+00\n",
            " 5.000e-04 1.000e-04 2.300e-03 4.700e-03], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.0698689e-02 1.5438512e-01 2.9481651e-04 1.9193646e-03 3.9892174e-02\n",
            " 7.7520996e-01 2.4521669e-05 5.4888078e-04 7.2393181e-05 2.2670038e-03\n",
            " 4.6871807e-03], argmax=5\n",
            "   \u001b[33m|->> #6/t=38-th Action selection: 5/2X UP (P(a|s) = 0.9959999918937683)\u001b[0m\n",
            "      |->> Bounding box moves to: [386  23  50  51]\n",
            "         |->> Action Probabilities (Rounded): [9.000e-04 0.000e+00 0.000e+00 0.000e+00 3.300e-03 9.957e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [9.0112112e-04 2.2081565e-05 9.7985885e-06 1.0255737e-07 3.3343316e-03\n",
            " 9.9569535e-01 7.2417606e-08 6.7182609e-06 6.9268395e-07 2.2382674e-05\n",
            " 7.4882955e-06], argmax=5\n",
            "   \u001b[33m|->> #7/t=39-th Action selection: 5/2X UP (P(a|s) = 0.18400000035762787)\u001b[0m\n",
            "      |->> Bounding box moves to: [386  21  50  51]\n",
            "         |->> Action Probabilities (Rounded): [1.289e-01 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.840e-01 3.000e-04\n",
            " 4.436e-01 0.000e+00 0.000e+00 2.431e-01], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.2892383e-01 1.6768206e-05 3.6246103e-05 2.4477306e-10 8.1044652e-07\n",
            " 1.8400474e-01 3.2159497e-04 4.4357976e-01 2.8008825e-14 2.3482211e-05\n",
            " 2.4309273e-01], argmax=7\n",
            "   \u001b[33m|->> #8/t=40-th Action selection: 5/2X UP (P(a|s) = 0.9990000128746033)\u001b[0m\n",
            "      |->> Bounding box moves to: [386  19  50  51]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 0.000e+00 0.000e+00 9.000e-04 9.989e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 1.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.3305268e-05 7.0755482e-07 2.7494693e-07 9.9217822e-08 9.3318155e-04\n",
            " 9.9893981e-01 1.7885739e-06 2.9954529e-07 1.7991022e-11 2.2810036e-05\n",
            " 8.7707813e-05], argmax=5\n",
            "   \u001b[33m|->> #9/t=41-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [386  17  50  51]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.0479730e-08 1.3248797e-10 6.1221584e-08 4.3901616e-09 4.0366769e-05\n",
            " 9.9995089e-01 2.5895767e-08 4.5212379e-11 9.4606120e-12 4.7683329e-08\n",
            " 8.5745969e-06], argmax=5\n",
            "   \u001b[33m|->> #10/t=42-th Action selection: 5/2X UP (P(a|s) = 0.9980000257492065)\u001b[0m\n",
            "      |->> Bounding box moves to: [386  15  50  51]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.     0.     0.0024 0.9976 0.     0.     0.     0.\n",
            " 0.    ], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.3364143e-09 2.3075527e-08 7.3077523e-08 1.3401832e-09 2.4236410e-03\n",
            " 9.9756771e-01 4.2626971e-11 1.3493083e-10 4.1608880e-11 1.8954280e-06\n",
            " 6.4941291e-06], argmax=5\n",
            "   \u001b[33m|->> #11/t=43-th Action selection: 5/2X UP (P(a|s) = 0.9789999723434448)\u001b[0m\n",
            "      |->> Bounding box moves to: [386  13  50  51]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 1.600e-03 1.000e-04 7.200e-03 9.793e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 3.000e-04 1.140e-02], argmax=5\n",
            "         |->> Action Probabilities (RAW): [9.77356152e-08 2.25633627e-08 1.63745857e-03 7.22448167e-05\n",
            " 7.18137063e-03 9.79337692e-01 1.00172075e-08 1.77887882e-09\n",
            " 2.46146592e-09 3.44764965e-04 1.14262728e-02], argmax=5\n",
            "   \u001b[33m|->> #12/t=44-th Action selection: 5/2X UP (P(a|s) = 0.32100000977516174)\u001b[0m\n",
            "      |->> Bounding box moves to: [386  11  50  51]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.     0.5835 0.0016 0.0027 0.3213 0.     0.     0.     0.0087\n",
            " 0.0821], argmax=2\n",
            "         |->> Action Probabilities (RAW): [1.8684400e-06 2.2044460e-05 5.8350515e-01 1.5968414e-03 2.7429974e-03\n",
            " 3.2126117e-01 5.9125267e-07 1.9727931e-05 4.5805718e-06 8.6957021e-03\n",
            " 8.2149260e-02], argmax=2\n",
            "   \u001b[33m|->> #13/t=45-th Action selection: 5/2X UP (P(a|s) = 0.8460000157356262)\u001b[0m\n",
            "      |->> Bounding box moves to: [386   9  50  51]\n",
            "         |->> Action Probabilities (Rounded): [4.000e-04 2.000e-04 1.600e-02 3.000e-04 9.300e-03 8.455e-01 0.000e+00\n",
            " 0.000e+00 1.000e-04 6.700e-03 1.216e-01], argmax=5\n",
            "         |->> Action Probabilities (RAW): [4.3160835e-04 1.5813284e-04 1.5954265e-02 3.4193325e-04 9.2610382e-03\n",
            " 8.4552866e-01 2.5829829e-06 5.6463773e-06 6.5062421e-05 6.6735488e-03\n",
            " 1.2157749e-01], argmax=5\n",
            "   \u001b[33m|->> #14/t=46-th Action selection: 10/SCALE UP (P(a|s) = 0.08799999952316284)\u001b[0m\n",
            "      |->> Bounding box moves to: [385   8  52  53]\n",
            "         |->> Action Probabilities (Rounded): [8.000e-04 3.000e-04 1.200e-03 1.000e-04 6.070e-02 8.439e-01 1.000e-04\n",
            " 0.000e+00 0.000e+00 4.600e-03 8.830e-02], argmax=5\n",
            "         |->> Action Probabilities (RAW): [8.4404228e-04 2.9306897e-04 1.1629907e-03 7.6476259e-05 6.0685590e-02\n",
            " 8.4392929e-01 6.5088221e-05 1.9217174e-05 1.5366094e-06 4.6113767e-03\n",
            " 8.8311337e-02], argmax=5\n",
            "   \u001b[33m|->> #15/t=47-th Action selection: 5/2X UP (P(a|s) = 0.7879999876022339)\u001b[0m\n",
            "      |->> Bounding box moves to: [385   6  52  53]\n",
            "         |->> Action Probabilities (Rounded): [8.000e-04 4.000e-04 1.000e-02 4.000e-04 1.040e-02 7.881e-01 1.000e-04\n",
            " 1.000e-04 0.000e+00 6.800e-03 1.829e-01], argmax=5\n",
            "         |->> Action Probabilities (RAW): [8.1284699e-04 4.2986378e-04 9.9513866e-03 4.1391829e-04 1.0369899e-02\n",
            " 7.8805065e-01 1.4857737e-04 8.1491664e-05 2.7193839e-05 6.7979903e-03\n",
            " 1.8291615e-01], argmax=5\n",
            "   \u001b[33m|->> #16/t=48-th Action selection: 5/2X UP (P(a|s) = 0.7799999713897705)\u001b[0m\n",
            "      |->> Bounding box moves to: [385   4  52  53]\n",
            "         |->> Action Probabilities (Rounded): [7.500e-03 1.500e-02 5.200e-03 1.000e-04 1.071e-01 7.802e-01 1.600e-03\n",
            " 4.000e-04 1.000e-04 7.530e-02 7.400e-03], argmax=5\n",
            "         |->> Action Probabilities (RAW): [7.47824227e-03 1.49989314e-02 5.17837983e-03 1.22242680e-04\n",
            " 1.07106365e-01 7.80201435e-01 1.61907659e-03 3.88083921e-04\n",
            " 1.36182076e-04 7.53244683e-02 7.44646648e-03], argmax=5\n",
            "   \u001b[33m|->> #17/t=49-th Action selection: 5/2X UP (P(a|s) = 0.8790000081062317)\u001b[0m\n",
            "      |->> Bounding box moves to: [385   2  52  53]\n",
            "         |->> Action Probabilities (Rounded): [1.800e-03 2.700e-03 7.170e-02 6.000e-03 1.490e-02 8.787e-01 9.000e-04\n",
            " 2.100e-03 2.000e-04 1.550e-02 5.400e-03], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.8325283e-03 2.6578209e-03 7.1730338e-02 5.9762602e-03 1.4910162e-02\n",
            " 8.7871563e-01 9.3537394e-04 2.1193197e-03 2.4399061e-04 1.5504234e-02\n",
            " 5.3744195e-03], argmax=5\n",
            "   \u001b[33m|->> #18/t=50-th Action selection: 3/2X RIGHT (P(a|s) = 0.07000000029802322)\u001b[0m\n",
            "      |->> Bounding box moves to: [387   2  52  53]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 0.000e+00 4.727e-01 7.020e-02 5.000e-04 4.385e-01 0.000e+00\n",
            " 1.000e-04 0.000e+00 4.000e-04 1.750e-02], argmax=2\n",
            "         |->> Action Probabilities (RAW): [3.38760032e-07 1.28759575e-05 4.72732127e-01 7.02413693e-02\n",
            " 5.01643110e-04 4.38489735e-01 8.55059852e-07 9.15346827e-05\n",
            " 6.71933208e-07 4.17626841e-04 1.75111443e-02], argmax=2\n",
            "   \u001b[33m|->> #19/t=51-th Action selection: 5/2X UP (P(a|s) = 0.625)\u001b[0m\n",
            "      |->> Bounding box moves to: [387   0  52  53]\n",
            "         |->> Action Probabilities (Rounded): [1.500e-03 1.289e-01 1.270e-02 5.200e-02 1.260e-02 6.254e-01 1.930e-02\n",
            " 1.463e-01 0.000e+00 1.100e-03 2.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.4624005e-03 1.2889926e-01 1.2679278e-02 5.2030567e-02 1.2570598e-02\n",
            " 6.2540168e-01 1.9302512e-02 1.4633624e-01 1.3037420e-08 1.1076805e-03\n",
            " 2.0984469e-04], argmax=5\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [388,  34,  46,  47] -> [387,   0,  52,  53] (Target was [400, 111,  41,  38])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X UP:bbox transition: [388,  34,  46,  47] -> [388,  32,  46,  47] w/ P(a|s)=0.9558953642845154 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for SCALE UP:bbox transition: [388,  32,  46,  47] -> [387,  31,  48,  49] w/ P(a|s)=0.21591901779174805 and iou=0.0 and reward=0.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.0) for SCALE UP:bbox transition: [387,  31,  48,  49] -> [386,  30,  50,  51] w/ P(a|s)=0.13168145716190338 and iou=0.0 and reward=0.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.0) for 2X UP:bbox transition: [386,  30,  50,  51] -> [386,  28,  50,  51] w/ P(a|s)=0.9990630745887756 and iou=0.0 and reward=0.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.0) for 2X UP:bbox transition: [386,  28,  50,  51] -> [386,  26,  50,  51] w/ P(a|s)=0.9997559189796448 and iou=0.0 and reward=0.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.0) for UP:bbox transition: [386,  26,  50,  51] -> [386,  25,  50,  51] w/ P(a|s)=0.03989217430353165 and iou=0.0 and reward=0.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.0) for 2X UP:bbox transition: [386,  25,  50,  51] -> [386,  23,  50,  51] w/ P(a|s)=0.9956953525543213 and iou=0.0 and reward=0.0 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (0.0) for 2X UP:bbox transition: [386,  23,  50,  51] -> [386,  21,  50,  51] w/ P(a|s)=0.1840047389268875 and iou=0.0 and reward=0.0 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (0.0) for 2X UP:bbox transition: [386,  21,  50,  51] -> [386,  19,  50,  51] w/ P(a|s)=0.9989398121833801 and iou=0.0 and reward=0.0 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (0.0) for 2X UP:bbox transition: [386,  19,  50,  51] -> [386,  17,  50,  51] w/ P(a|s)=0.9999508857727051 and iou=0.0 and reward=0.0 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (0.0) for 2X UP:bbox transition: [386,  17,  50,  51] -> [386,  15,  50,  51] w/ P(a|s)=0.9975677132606506 and iou=0.0 and reward=0.0 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (0.0) for 2X UP:bbox transition: [386,  15,  50,  51] -> [386,  13,  50,  51] w/ P(a|s)=0.9793376922607422 and iou=0.0 and reward=0.0 and discount=0.8953382542587164\n",
            "   |->> t=13 Diff-Reward (0.0) for 2X UP:bbox transition: [386,  13,  50,  51] -> [386,  11,  50,  51] w/ P(a|s)=0.3212611675262451 and iou=0.0 and reward=0.0 and discount=0.8863848717161292\n",
            "   |->> t=14 Diff-Reward (0.0) for 2X UP:bbox transition: [386,  11,  50,  51] -> [386,   9,  50,  51] w/ P(a|s)=0.8455286622047424 and iou=0.0 and reward=0.0 and discount=0.8775210229989678\n",
            "   |->> t=15 Diff-Reward (0.0) for SCALE UP:bbox transition: [386,   9,  50,  51] -> [385,   8,  52,  53] w/ P(a|s)=0.0883113369345665 and iou=0.0 and reward=0.0 and discount=0.8687458127689782\n",
            "   |->> t=16 Diff-Reward (0.0) for 2X UP:bbox transition: [385,   8,  52,  53] -> [385,   6,  52,  53] w/ P(a|s)=0.788050651550293 and iou=0.0 and reward=0.0 and discount=0.8600583546412884\n",
            "   |->> t=17 Diff-Reward (0.0) for 2X UP:bbox transition: [385,   6,  52,  53] -> [385,   4,  52,  53] w/ P(a|s)=0.7802014350891113 and iou=0.0 and reward=0.0 and discount=0.8514577710948755\n",
            "   |->> t=18 Diff-Reward (0.0) for 2X UP:bbox transition: [385,   4,  52,  53] -> [385,   2,  52,  53] w/ P(a|s)=0.8787156343460083 and iou=0.0 and reward=0.0 and discount=0.8429431933839268\n",
            "   |->> t=19 Diff-Reward (0.0) for 2X RIGHT:bbox transition: [385,   2,  52,  53] -> [387,   2,  52,  53] w/ P(a|s)=0.07024136930704117 and iou=0.0 and reward=0.0 and discount=0.8345137614500875\n",
            "   |->> t=20 Diff-Reward (0.0) for 2X UP:bbox transition: [387,   2,  52,  53] -> [387,   0,  52,  53] w/ P(a|s)=0.6254016757011414 and iou=0.0 and reward=0.0 and discount=0.8261686238355866\n",
            "   |->> Assigned losses: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 40 with src: [387,   0,  52,  53] and target: [395, 115,  47,  48]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0040.jpg\n",
            "|->> Beginning tracking for bbox:[387   0  52  53]\n",
            "|->> Revisiting bbox: [387   0  52  53]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=52-th Action selection: 8/STOP (P(a|s) = 0.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [387   0  52  53]\n",
            "         |->> Action Probabilities (Rounded): [1.997e-01 3.000e-04 1.230e-02 0.000e+00 7.712e-01 1.620e-02 0.000e+00\n",
            " 0.000e+00 0.000e+00 2.000e-04 0.000e+00], argmax=4\n",
            "         |->> Action Probabilities (RAW): [1.9968899e-01 3.1147426e-04 1.2267351e-02 4.3568633e-09 7.7123314e-01\n",
            " 1.6221723e-02 8.5616184e-06 2.2420404e-06 9.3733684e-07 2.2649908e-04\n",
            " 3.8984388e-05], argmax=4\n",
            "         |->> Hit a STOP on the 52-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [387,   0,  52,  53] -> [387,   0,  52,  53] (Target was [395, 115,  47,  48])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [387,   0,  52,  53] -> [387,   0,  52,  53] w/ P(a|s)=9.373368357046274e-07 and iou=0.0 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-11.512925]\n",
            "\u001b[31m>> Total frame loss: -11.512925148010254\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 41 with src: [387,   0,  52,  53] and target: [394, 114,  44,  48]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0041.jpg\n",
            "|->> Beginning tracking for bbox:[387   0  52  53]\n",
            "   \u001b[33m|->> #0/t=52-th Action selection: 9/SCALE DOWN (P(a|s) = 0.28999999165534973)\u001b[0m\n",
            "      |->> Bounding box moves to: [388   1  50  51]\n",
            "         |->> Action Probabilities (Rounded): [1.410e-02 1.000e-04 1.870e-02 8.500e-03 2.884e-01 2.415e-01 6.870e-02\n",
            " 6.950e-02 7.000e-04 2.898e-01 0.000e+00], argmax=9\n",
            "         |->> Action Probabilities (RAW): [1.4128417e-02 9.7107215e-05 1.8661994e-02 8.4583322e-03 2.8839952e-01\n",
            " 2.4147616e-01 6.8742871e-02 6.9514826e-02 6.7650876e-04 2.8983855e-01\n",
            " 5.6973831e-06], argmax=9\n",
            "   \u001b[33m|->> #1/t=53-th Action selection: 9/SCALE DOWN (P(a|s) = 0.28999999165534973)\u001b[0m\n",
            "      |->> Bounding box moves to: [389   2  48  49]\n",
            "         |->> Action Probabilities (Rounded): [5.800e-03 0.000e+00 4.200e-03 3.100e-03 1.766e-01 4.911e-01 9.600e-03\n",
            " 1.960e-02 1.000e-04 2.899e-01 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [5.8264188e-03 9.2355531e-06 4.2399275e-03 3.1282383e-03 1.7657329e-01\n",
            " 4.9105987e-01 9.5676305e-03 1.9576671e-02 1.2521846e-04 2.8988314e-01\n",
            " 1.0397258e-05], argmax=5\n",
            "   \u001b[33m|->> #2/t=54-th Action selection: 5/2X UP (P(a|s) = 0.5490000247955322)\u001b[0m\n",
            "      |->> Bounding box moves to: [389   0  48  49]\n",
            "         |->> Action Probabilities (Rounded): [1.240e-02 0.000e+00 5.000e-02 5.700e-03 2.879e-01 5.492e-01 1.400e-03\n",
            " 1.000e-04 1.000e-04 9.160e-02 1.700e-03], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.2410330e-02 2.4063302e-06 5.0047312e-02 5.6864377e-03 2.8785110e-01\n",
            " 5.4915786e-01 1.3947826e-03 5.6747573e-05 1.1193592e-04 9.1612905e-02\n",
            " 1.6681370e-03], argmax=5\n",
            "|->> Revisiting bbox: [389   0  48  49]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [387,   0,  52,  53] -> [389,   0,  48,  49] (Target was [394, 114,  44,  48])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for SCALE DOWN:bbox transition: [387,   0,  52,  53] -> [388,   1,  50,  51] w/ P(a|s)=0.2898385524749756 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for SCALE DOWN:bbox transition: [388,   1,  50,  51] -> [389,   2,  48,  49] w/ P(a|s)=0.2898831367492676 and iou=0.0 and reward=0.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X UP:bbox transition: [389,   2,  48,  49] -> [389,   0,  48,  49] w/ P(a|s)=0.5491578578948975 and iou=0.0 and reward=0.0 and discount=0.9801\n",
            "   |->> Assigned losses: [0. 0. 0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 42 with src: [389,   0,  48,  49] and target: [395, 106,  45,  54]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0042.jpg\n",
            "|->> Beginning tracking for bbox:[389   0  48  49]\n",
            "   \u001b[33m|->> #0/t=55-th Action selection: 1/2X LEFT (P(a|s) = 0.4350000023841858)\u001b[0m\n",
            "      |->> Bounding box moves to: [387   0  48  49]\n",
            "         |->> Action Probabilities (Rounded): [4.213e-01 4.351e-01 1.200e-03 0.000e+00 1.600e-03 1.189e-01 2.000e-04\n",
            " 7.000e-04 0.000e+00 1.000e-04 2.100e-02], argmax=1\n",
            "         |->> Action Probabilities (RAW): [4.2125404e-01 4.3509284e-01 1.2172317e-03 3.6752535e-05 1.5768352e-03\n",
            " 1.1889781e-01 1.7665475e-04 6.6143909e-04 9.5723608e-06 9.3936491e-05\n",
            " 2.0982837e-02], argmax=1\n",
            "|->> Revisiting bbox: [387   0  48  49]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [389,   0,  48,  49] -> [387,   0,  48,  49] (Target was [395, 106,  45,  54])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X LEFT:bbox transition: [389,   0,  48,  49] -> [387,   0,  48,  49] w/ P(a|s)=0.43509283661842346 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> Assigned losses: [0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 43 with src: [387,   0,  48,  49] and target: [390,  95,  42,  49]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0043.jpg\n",
            "|->> Beginning tracking for bbox:[387   0  48  49]\n",
            "|->> Revisiting bbox: [387   0  48  49]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=56-th Action selection: 8/STOP (P(a|s) = 0.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [387   0  48  49]\n",
            "         |->> Action Probabilities (Rounded): [1.000e-04 5.200e-03 2.100e-03 3.490e-02 2.000e-04 4.516e-01 4.742e-01\n",
            " 2.840e-02 0.000e+00 4.000e-04 2.900e-03], argmax=6\n",
            "         |->> Action Probabilities (RAW): [7.1765586e-05 5.2296720e-03 2.1297145e-03 3.4860205e-02 1.7915896e-04\n",
            " 4.5156643e-01 4.7415891e-01 2.8444801e-02 1.6820743e-05 3.9488432e-04\n",
            " 2.9476536e-03], argmax=6\n",
            "         |->> Hit a STOP on the 56-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [387,   0,  48,  49] -> [387,   0,  48,  49] (Target was [390,  95,  42,  49])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [387,   0,  48,  49] -> [387,   0,  48,  49] w/ P(a|s)=1.6820742530399002e-05 and iou=0.0 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-10.992898]\n",
            "\u001b[31m>> Total frame loss: -10.992897987365723\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 44 with src: [387,   0,  48,  49] and target: [378,  71,  43,  55]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0044.jpg\n",
            "|->> Beginning tracking for bbox:[387   0  48  49]\n",
            "   \u001b[33m|->> #0/t=56-th Action selection: 0/LEFT (P(a|s) = 0.9829999804496765)\u001b[0m\n",
            "      |->> Bounding box moves to: [386   0  48  49]\n",
            "         |->> Action Probabilities (Rounded): [9.827e-01 8.300e-03 0.000e+00 0.000e+00 0.000e+00 4.000e-04 1.000e-04\n",
            " 0.000e+00 0.000e+00 0.000e+00 8.400e-03], argmax=0\n",
            "         |->> Action Probabilities (RAW): [9.8269582e-01 8.2828030e-03 1.6262246e-07 2.0993070e-09 1.6932168e-05\n",
            " 4.4964388e-04 8.9788744e-05 4.3233126e-08 2.8140852e-09 2.3683599e-05\n",
            " 8.4410841e-03], argmax=0\n",
            "   \u001b[33m|->> #1/t=57-th Action selection: 1/2X LEFT (P(a|s) = 0.9879999756813049)\u001b[0m\n",
            "      |->> Bounding box moves to: [384   0  48  49]\n",
            "         |->> Action Probabilities (Rounded): [1.000e-04 9.884e-01 0.000e+00 0.000e+00 0.000e+00 1.080e-02 0.000e+00\n",
            " 0.000e+00 0.000e+00 7.000e-04 0.000e+00], argmax=1\n",
            "         |->> Action Probabilities (RAW): [7.7618104e-05 9.8841465e-01 1.7551616e-17 2.2316044e-21 5.5035434e-07\n",
            " 1.0828489e-02 2.9535915e-08 1.3462055e-11 2.0533994e-19 6.7851384e-04\n",
            " 1.8523052e-08], argmax=1\n",
            "|->> Revisiting bbox: [384   0  48  49]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [387,   0,  48,  49] -> [384,   0,  48,  49] (Target was [378,  71,  43,  55])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for LEFT:bbox transition: [387,   0,  48,  49] -> [386,   0,  48,  49] w/ P(a|s)=0.9826958179473877 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for 2X LEFT:bbox transition: [386,   0,  48,  49] -> [384,   0,  48,  49] w/ P(a|s)=0.9884146451950073 and iou=0.0 and reward=0.0 and discount=0.99\n",
            "   |->> Assigned losses: [0. 0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 45 with src: [384,   0,  48,  49] and target: [368,  48,  41,  53]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0045.jpg\n",
            "|->> Beginning tracking for bbox:[384   0  48  49]\n",
            "|->> Revisiting bbox: [384   0  48  49]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=58-th Action selection: 8/STOP (P(a|s) = 0.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [384   0  48  49]\n",
            "         |->> Action Probabilities (Rounded): [6.900e-03 7.200e-03 7.000e-04 7.000e-04 4.120e-02 8.954e-01 1.200e-03\n",
            " 4.000e-04 1.000e-04 3.730e-02 8.800e-03], argmax=5\n",
            "         |->> Action Probabilities (RAW): [6.8929931e-03 7.1785375e-03 7.4077758e-04 7.0101878e-04 4.1215084e-02\n",
            " 8.9540756e-01 1.2163746e-03 4.4638661e-04 1.4170181e-04 3.7284497e-02\n",
            " 8.7750359e-03], argmax=5\n",
            "         |->> Hit a STOP on the 58-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [384,   0,  48,  49] -> [384,   0,  48,  49] (Target was [368,  48,  41,  53])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [384,   0,  48,  49] -> [384,   0,  48,  49] w/ P(a|s)=0.00014170180656947196 and iou=0.005555555555555556 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-8.861786]\n",
            "\u001b[31m>> Total frame loss: -8.861785888671875\u001b[0m\n",
            "Final bounding box: [384   0  48  49] reached in 58 timesteps (originating from [397  82  38  39]). Target was [368  48  41  53]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 46 in t=58 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[31m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 325.13739013671875\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.02572837471961975\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 375.93768310546875\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.720059871673584\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 542.4647216796875\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 1.8087737560272217\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 125.22001647949219\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 1.0110951662063599\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 62.725059509277344\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.49238190054893494\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 106.64356231689453\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 2.4499268531799316\n",
            "#################################################\n",
            "#################################################\n",
            "\n",
            "\n",
            "#############################################\n",
            "Dataset=adnet_datasets/OTB/Matrix\n",
            "#################################################\n",
            "\n",
            "\u001b[36m####################### EPISODE # 1 ############################\u001b[0m\n",
            "Starting bounding box for adnet_datasets/OTB/Matrix: frames 74:84 is [288   6  64  72].\n",
            "\u001b[34m>> Attempting to reach frame 75 with src: [288,   6,  64,  72] and target: [276,  22,  70,  88]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0075.jpg\n",
            "|->> Beginning tracking for bbox:[288   6  64  72]\n",
            "   \u001b[33m|->> #0/t=1-th Action selection: 5/2X UP (P(a|s) = 1.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [288   2  64  72]\n",
            "         |->> Action Probabilities (Rounded): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.1128136e-18 7.3764445e-21 0.0000000e+00 2.5782890e-27 1.6761855e-24\n",
            " 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            " 1.5310965e-36], argmax=5\n",
            "   \u001b[33m|->> #1/t=2-th Action selection: 1/2X LEFT (P(a|s) = 0.9419999718666077)\u001b[0m\n",
            "      |->> Bounding box moves to: [286   2  64  72]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.9415 0.     0.     0.0041 0.0543 0.     0.     0.     0.\n",
            " 0.    ], argmax=1\n",
            "         |->> Action Probabilities (RAW): [2.0745199e-05 9.4151336e-01 1.0085052e-17 5.7724103e-11 4.1485312e-03\n",
            " 5.4317396e-02 5.0258862e-17 2.9488185e-09 2.3484131e-20 4.7492492e-12\n",
            " 1.1855434e-09], argmax=1\n",
            "   \u001b[33m|->> #2/t=3-th Action selection: 1/2X LEFT (P(a|s) = 0.9990000128746033)\u001b[0m\n",
            "      |->> Bounding box moves to: [284   2  64  72]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 9.991e-01 0.000e+00 0.000e+00 0.000e+00 9.000e-04 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=1\n",
            "         |->> Action Probabilities (RAW): [1.01243194e-10 9.99119937e-01 7.77022257e-35 2.29110477e-29\n",
            " 9.54185830e-23 8.80072359e-04 1.87905724e-27 2.56124129e-14\n",
            " 0.00000000e+00 1.74132884e-33 1.97748894e-16], argmax=1\n",
            "|->> Revisiting bbox: [286   2  64  72]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [288,   6,  64,  72] -> [284,   2,  64,  72] (Target was [276,  22,  70,  88])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.043) for 2X UP:bbox transition: [288,   6,  64,  72] -> [288,   2,  64,  72] w/ P(a|s)=1.0 and iou=0.3890608875128999 and reward=-0.04285400610412138 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.019) for 2X LEFT:bbox transition: [288,   2,  64,  72] -> [286,   2,  64,  72] w/ P(a|s)=0.9415133595466614 and iou=0.40794979079497906 and reward=0.01888890328207915 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.019) for 2X LEFT:bbox transition: [286,   2,  64,  72] -> [284,   2,  64,  72] w/ P(a|s)=0.9991199374198914 and iou=0.42735949098621423 and reward=0.01940970019123517 and discount=0.9801\n",
            "   |->> Assigned losses: [-4.2912419e-07  1.1269889e-03  1.6749194e-05]\n",
            "\u001b[92m>> Total frame loss: 0.0011433089384809136\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 76 with src: [284,   2,  64,  72] and target: [288,  59,  67,  92]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0076.jpg\n",
            "|->> Beginning tracking for bbox:[284   2  64  72]\n",
            "   \u001b[33m|->> #0/t=4-th Action selection: 5/2X UP (P(a|s) = 0.13699999451637268)\u001b[0m\n",
            "      |->> Bounding box moves to: [284   0  64  72]\n",
            "         |->> Action Probabilities (Rounded): [1.308e-01 3.630e-01 0.000e+00 0.000e+00 3.636e-01 1.375e-01 3.000e-04\n",
            " 0.000e+00 0.000e+00 4.700e-03 0.000e+00], argmax=4\n",
            "         |->> Action Probabilities (RAW): [1.3082810e-01 3.6295989e-01 5.3686945e-06 5.5362687e-08 3.6363655e-01\n",
            " 1.3746849e-01 3.2874686e-04 4.5668476e-05 6.1969636e-06 4.6891635e-03\n",
            " 3.1752741e-05], argmax=4\n",
            "|->> Revisiting bbox: [284   0  64  72]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [284,   2,  64,  72] -> [284,   0,  64,  72] (Target was [288,  59,  67,  92])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (-0.013) for 2X UP:bbox transition: [284,   2,  64,  72] -> [284,   0,  64,  72] w/ P(a|s)=0.13746848702430725 and iou=0.07806244995996797 and reward=-0.013104486830955858 and discount=1.0\n",
            "   |->> Assigned losses: [-0.02600403]\n",
            "\u001b[31m>> Total frame loss: -0.02600402757525444\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 77 with src: [284,   0,  64,  72] and target: [310, 103,  65,  90]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0077.jpg\n",
            "|->> Beginning tracking for bbox:[284   0  64  72]\n",
            "   \u001b[33m|->> #0/t=5-th Action selection: 1/2X LEFT (P(a|s) = 0.9129999876022339)\u001b[0m\n",
            "      |->> Bounding box moves to: [282   0  64  72]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.9129 0.     0.     0.     0.0871 0.     0.     0.     0.\n",
            " 0.    ], argmax=1\n",
            "         |->> Action Probabilities (RAW): [1.2460866e-05 9.1285414e-01 2.4229951e-10 1.5231862e-12 5.3690815e-06\n",
            " 8.7128036e-02 5.4303857e-12 3.1429276e-11 2.2092567e-14 1.6396916e-08\n",
            " 2.8552487e-09], argmax=1\n",
            "   \u001b[33m|->> #1/t=6-th Action selection: 1/2X LEFT (P(a|s) = 0.8320000171661377)\u001b[0m\n",
            "      |->> Bounding box moves to: [280   0  64  72]\n",
            "         |->> Action Probabilities (Rounded): [0.     0.8324 0.     0.     0.     0.1676 0.     0.     0.     0.\n",
            " 0.    ], argmax=1\n",
            "         |->> Action Probabilities (RAW): [1.4046165e-07 8.3236384e-01 2.5805202e-09 1.5022697e-13 6.7891083e-06\n",
            " 1.6762905e-01 3.6261074e-15 1.5306647e-12 1.3017171e-12 5.1964884e-11\n",
            " 2.1087480e-07], argmax=1\n",
            "|->> Revisiting bbox: [280   0  64  72]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [284,   0,  64,  72] -> [280,   0,  64,  72] (Target was [310, 103,  65,  90])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for 2X LEFT:bbox transition: [284,   0,  64,  72] -> [282,   0,  64,  72] w/ P(a|s)=0.9128541350364685 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for 2X LEFT:bbox transition: [282,   0,  64,  72] -> [280,   0,  64,  72] w/ P(a|s)=0.8323638439178467 and iou=0.0 and reward=0.0 and discount=0.99\n",
            "   |->> Assigned losses: [0. 0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 78 with src: [280,   0,  64,  72] and target: [324, 138,  70,  94]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0078.jpg\n",
            "|->> Beginning tracking for bbox:[280   0  64  72]\n",
            "   \u001b[33m|->> #0/t=7-th Action selection: 10/SCALE UP (P(a|s) = 0.8610000014305115)\u001b[0m\n",
            "      |->> Bounding box moves to: [279   0  66  74]\n",
            "         |->> Action Probabilities (Rounded): [3.100e-02 7.440e-02 0.000e+00 0.000e+00 1.000e-03 1.400e-03 2.340e-02\n",
            " 5.500e-03 1.000e-04 1.700e-03 8.615e-01], argmax=10\n",
            "         |->> Action Probabilities (RAW): [3.1043315e-02 7.4356318e-02 6.5807430e-06 1.4867109e-10 1.0189636e-03\n",
            " 1.3654128e-03 2.3433490e-02 5.4753437e-03 9.2198163e-05 1.7452424e-03\n",
            " 8.6146319e-01], argmax=10\n",
            "   \u001b[33m|->> #1/t=8-th Action selection: 1/2X LEFT (P(a|s) = 0.6549999713897705)\u001b[0m\n",
            "      |->> Bounding box moves to: [277   0  66  74]\n",
            "         |->> Action Probabilities (Rounded): [3.290e-02 6.546e-01 0.000e+00 0.000e+00 1.000e-04 5.330e-02 7.690e-02\n",
            " 1.000e-04 0.000e+00 1.334e-01 4.860e-02], argmax=1\n",
            "         |->> Action Probabilities (RAW): [3.2935012e-02 6.5462971e-01 4.4234739e-06 3.8293533e-09 1.1058264e-04\n",
            " 5.3250052e-02 7.6903805e-02 8.9454043e-05 2.9092153e-05 1.3340728e-01\n",
            " 4.8640613e-02], argmax=1\n",
            "|->> Revisiting bbox: [277   0  66  74]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [280,   0,  64,  72] -> [277,   0,  66,  74] (Target was [324, 138,  70,  94])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for SCALE UP:bbox transition: [280,   0,  64,  72] -> [279,   0,  66,  74] w/ P(a|s)=0.861463189125061 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for 2X LEFT:bbox transition: [279,   0,  66,  74] -> [277,   0,  66,  74] w/ P(a|s)=0.6546297073364258 and iou=0.0 and reward=0.0 and discount=0.99\n",
            "   |->> Assigned losses: [0. 0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 79 with src: [277,   0,  66,  74] and target: [337, 158,  68,  90]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0079.jpg\n",
            "|->> Beginning tracking for bbox:[277   0  66  74]\n",
            "|->> Revisiting bbox: [277   0  66  74]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=9-th Action selection: 8/STOP (P(a|s) = 0.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [277   0  66  74]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 1.000e-04 0.000e+00 0.000e+00 2.300e-03 9.976e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [3.4420864e-07 5.0056427e-05 1.9534027e-10 2.9350892e-07 2.3439529e-03\n",
            " 9.9760461e-01 1.6904420e-10 4.1339573e-10 1.2722382e-14 1.4598177e-09\n",
            " 6.5668411e-07], argmax=5\n",
            "         |->> Hit a STOP on the 9-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [277,   0,  66,  74] -> [277,   0,  66,  74] (Target was [337, 158,  68,  90])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [277,   0,  66,  74] -> [277,   0,  66,  74] w/ P(a|s)=1.2722382351716861e-14 and iou=0.0 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-11.512925]\n",
            "\u001b[31m>> Total frame loss: -11.512925148010254\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 80 with src: [277,   0,  66,  74] and target: [344, 162,  61,  90]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0080.jpg\n",
            "|->> Beginning tracking for bbox:[277   0  66  74]\n",
            "   \u001b[33m|->> #0/t=9-th Action selection: 9/SCALE DOWN (P(a|s) = 0.16599999368190765)\u001b[0m\n",
            "      |->> Bounding box moves to: [278   1  64  71]\n",
            "         |->> Action Probabilities (Rounded): [0.0035 0.1589 0.008  0.0355 0.2119 0.3128 0.0078 0.0401 0.0005 0.1657\n",
            " 0.0554], argmax=5\n",
            "         |->> Action Probabilities (RAW): [0.00348679 0.15887468 0.00800053 0.03554747 0.21187434 0.31277448\n",
            " 0.00775106 0.0400887  0.00048373 0.1656797  0.05543848], argmax=5\n",
            "   \u001b[33m|->> #1/t=10-th Action selection: 7/2X DOWN (P(a|s) = 0.2409999966621399)\u001b[0m\n",
            "      |->> Bounding box moves to: [278   5  64  71]\n",
            "         |->> Action Probabilities (Rounded): [2.282e-01 4.960e-02 1.550e-02 2.400e-03 2.500e-03 2.000e-04 1.690e-02\n",
            " 2.414e-01 9.000e-04 1.000e-04 4.422e-01], argmax=10\n",
            "         |->> Action Probabilities (RAW): [2.2819825e-01 4.9604505e-02 1.5521628e-02 2.3610760e-03 2.4956085e-03\n",
            " 1.5913379e-04 1.6947115e-02 2.4140760e-01 9.1747474e-04 1.4870733e-04\n",
            " 4.4223887e-01], argmax=10\n",
            "   \u001b[33m|->> #2/t=11-th Action selection: 1/2X LEFT (P(a|s) = 0.2809999883174896)\u001b[0m\n",
            "      |->> Bounding box moves to: [276   5  64  71]\n",
            "         |->> Action Probabilities (Rounded): [0.2021 0.2812 0.0042 0.0109 0.0828 0.2629 0.003  0.0145 0.0203 0.0847\n",
            " 0.0334], argmax=1\n",
            "         |->> Action Probabilities (RAW): [0.20205434 0.28116268 0.00422281 0.01093132 0.08275094 0.2629022\n",
            " 0.00304066 0.01450824 0.02033781 0.08465182 0.03343718], argmax=1\n",
            "   \u001b[33m|->> #3/t=12-th Action selection: 4/UP (P(a|s) = 0.2540000081062317)\u001b[0m\n",
            "      |->> Bounding box moves to: [276   3  64  71]\n",
            "         |->> Action Probabilities (Rounded): [4.996e-01 5.090e-02 1.059e-01 1.030e-02 2.542e-01 1.870e-02 4.900e-03\n",
            " 1.000e-04 2.400e-03 0.000e+00 5.300e-02], argmax=0\n",
            "         |->> Action Probabilities (RAW): [4.9961156e-01 5.0906822e-02 1.0594584e-01 1.0293663e-02 2.5422335e-01\n",
            " 1.8689906e-02 4.8629558e-03 6.4994245e-05 2.3953707e-03 4.7362711e-05\n",
            " 5.2958246e-02], argmax=0\n",
            "   \u001b[33m|->> #4/t=13-th Action selection: 4/UP (P(a|s) = 0.4009999930858612)\u001b[0m\n",
            "      |->> Bounding box moves to: [276   1  64  71]\n",
            "         |->> Action Probabilities (Rounded): [1.518e-01 2.650e-02 3.800e-03 4.200e-03 4.012e-01 1.000e-04 1.700e-02\n",
            " 7.800e-03 6.200e-03 4.000e-04 3.812e-01], argmax=4\n",
            "         |->> Action Probabilities (RAW): [1.5180226e-01 2.6475511e-02 3.7645283e-03 4.1576982e-03 4.0119410e-01\n",
            " 5.7541991e-05 1.6979098e-02 7.8419112e-03 6.2026666e-03 3.5433137e-04\n",
            " 3.8117033e-01], argmax=4\n",
            "   \u001b[33m|->> #5/t=14-th Action selection: 1/2X LEFT (P(a|s) = 0.3269999921321869)\u001b[0m\n",
            "      |->> Bounding box moves to: [274   1  64  71]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 3.272e-01 0.000e+00 0.000e+00 3.000e-04 0.000e+00 0.000e+00\n",
            " 6.622e-01 0.000e+00 0.000e+00 1.030e-02], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.79964479e-06 3.27184170e-01 7.09909713e-08 7.84342228e-06\n",
            " 3.05437308e-04 8.02509348e-09 1.31457355e-05 6.62227333e-01\n",
            " 3.66153115e-11 5.98481171e-13 1.02601424e-02], argmax=7\n",
            "   \u001b[33m|->> #6/t=15-th Action selection: 1/2X LEFT (P(a|s) = 0.7009999752044678)\u001b[0m\n",
            "      |->> Bounding box moves to: [272   1  64  71]\n",
            "         |->> Action Probabilities (Rounded): [1.000e-04 7.013e-01 0.000e+00 0.000e+00 4.500e-03 2.200e-03 0.000e+00\n",
            " 2.668e-01 0.000e+00 0.000e+00 2.500e-02], argmax=1\n",
            "         |->> Action Probabilities (RAW): [1.2269705e-04 7.0130777e-01 3.7055452e-05 6.9648939e-07 4.4704229e-03\n",
            " 2.2149773e-03 2.0993493e-05 2.6676914e-01 1.0903262e-07 1.5307898e-05\n",
            " 2.5040824e-02], argmax=1\n",
            "   \u001b[33m|->> #7/t=16-th Action selection: 1/2X LEFT (P(a|s) = 0.9879999756813049)\u001b[0m\n",
            "      |->> Bounding box moves to: [270   1  64  71]\n",
            "         |->> Action Probabilities (Rounded): [1.400e-03 9.876e-01 0.000e+00 0.000e+00 2.000e-04 2.000e-04 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 1.060e-02], argmax=1\n",
            "         |->> Action Probabilities (RAW): [1.3875490e-03 9.8763591e-01 6.9054527e-06 3.7442155e-07 1.7768105e-04\n",
            " 1.8694157e-04 2.4425460e-06 2.2336442e-05 1.6189171e-06 4.3104905e-07\n",
            " 1.0577905e-02], argmax=1\n",
            "   \u001b[33m|->> #8/t=17-th Action selection: 5/2X UP (P(a|s) = 0.13099999725818634)\u001b[0m\n",
            "      |->> Bounding box moves to: [270   0  64  71]\n",
            "         |->> Action Probabilities (Rounded): [0.0293 0.0317 0.0267 0.0408 0.1979 0.1309 0.0089 0.2653 0.0005 0.0112\n",
            " 0.2567], argmax=7\n",
            "         |->> Action Probabilities (RAW): [0.02931364 0.0317182  0.02670679 0.04081034 0.19791815 0.13091016\n",
            " 0.00887805 0.26533478 0.00046101 0.01123507 0.2567138 ], argmax=7\n",
            "   \u001b[33m|->> #9/t=18-th Action selection: 1/2X LEFT (P(a|s) = 0.20200000703334808)\u001b[0m\n",
            "      |->> Bounding box moves to: [268   0  64  71]\n",
            "         |->> Action Probabilities (Rounded): [1.900e-02 2.024e-01 1.250e-02 3.300e-03 5.500e-03 1.872e-01 2.000e-03\n",
            " 2.878e-01 0.000e+00 2.000e-04 2.801e-01], argmax=7\n",
            "         |->> Action Probabilities (RAW): [1.9036273e-02 2.0236006e-01 1.2547583e-02 3.2612365e-03 5.5135190e-03\n",
            " 1.8719068e-01 1.9961423e-03 2.8778023e-01 8.1857230e-08 1.7805782e-04\n",
            " 2.8013617e-01], argmax=7\n",
            "   \u001b[33m|->> #10/t=19-th Action selection: 0/LEFT (P(a|s) = 0.515999972820282)\u001b[0m\n",
            "      |->> Bounding box moves to: [267   0  64  71]\n",
            "         |->> Action Probabilities (Rounded): [5.159e-01 2.060e-02 7.000e-04 1.230e-02 3.500e-03 1.600e-03 2.000e-04\n",
            " 5.000e-04 2.500e-03 2.000e-04 4.420e-01], argmax=0\n",
            "         |->> Action Probabilities (RAW): [5.1594156e-01 2.0571519e-02 6.5674377e-04 1.2274126e-02 3.5214804e-03\n",
            " 1.6414196e-03 2.1128850e-04 5.0107803e-04 2.5058216e-03 2.0553956e-04\n",
            " 4.4196945e-01], argmax=0\n",
            "   \u001b[33m|->> #11/t=20-th Action selection: 1/2X LEFT (P(a|s) = 0.3529999852180481)\u001b[0m\n",
            "      |->> Bounding box moves to: [265   0  64  71]\n",
            "         |->> Action Probabilities (Rounded): [5.963e-01 3.527e-01 0.000e+00 1.000e-04 3.080e-02 1.400e-03 0.000e+00\n",
            " 0.000e+00 1.000e-04 8.000e-04 1.770e-02], argmax=0\n",
            "         |->> Action Probabilities (RAW): [5.96273541e-01 3.52701366e-01 8.82809218e-06 1.45858081e-04\n",
            " 3.08025721e-02 1.40303851e-03 1.21342009e-06 1.31699744e-05\n",
            " 1.19041346e-04 7.99277914e-04 1.77321211e-02], argmax=0\n",
            "|->> Revisiting bbox: [265   0  64  71]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [277,   0,  66,  74] -> [265,   0,  64,  71] (Target was [344, 162,  61,  90])\u001b[0m\n",
            "   |->> t=1 Diff-Reward (0.0) for SCALE DOWN:bbox transition: [277,   0,  66,  74] -> [278,   1,  64,  71] w/ P(a|s)=0.1656796932220459 and iou=0.0 and reward=0.0 and discount=1.0\n",
            "   |->> t=2 Diff-Reward (0.0) for 2X DOWN:bbox transition: [278,   1,  64,  71] -> [278,   5,  64,  71] w/ P(a|s)=0.2414076030254364 and iou=0.0 and reward=0.0 and discount=0.99\n",
            "   |->> t=3 Diff-Reward (0.0) for 2X LEFT:bbox transition: [278,   5,  64,  71] -> [276,   5,  64,  71] w/ P(a|s)=0.28116267919540405 and iou=0.0 and reward=0.0 and discount=0.9801\n",
            "   |->> t=4 Diff-Reward (0.0) for UP:bbox transition: [276,   5,  64,  71] -> [276,   3,  64,  71] w/ P(a|s)=0.2542233467102051 and iou=0.0 and reward=0.0 and discount=0.970299\n",
            "   |->> t=5 Diff-Reward (0.0) for UP:bbox transition: [276,   3,  64,  71] -> [276,   1,  64,  71] w/ P(a|s)=0.40119409561157227 and iou=0.0 and reward=0.0 and discount=0.96059601\n",
            "   |->> t=6 Diff-Reward (0.0) for 2X LEFT:bbox transition: [276,   1,  64,  71] -> [274,   1,  64,  71] w/ P(a|s)=0.32718417048454285 and iou=0.0 and reward=0.0 and discount=0.9509900498999999\n",
            "   |->> t=7 Diff-Reward (0.0) for 2X LEFT:bbox transition: [274,   1,  64,  71] -> [272,   1,  64,  71] w/ P(a|s)=0.7013077735900879 and iou=0.0 and reward=0.0 and discount=0.941480149401\n",
            "   |->> t=8 Diff-Reward (0.0) for 2X LEFT:bbox transition: [272,   1,  64,  71] -> [270,   1,  64,  71] w/ P(a|s)=0.9876359105110168 and iou=0.0 and reward=0.0 and discount=0.9320653479069899\n",
            "   |->> t=9 Diff-Reward (0.0) for 2X UP:bbox transition: [270,   1,  64,  71] -> [270,   0,  64,  71] w/ P(a|s)=0.13091015815734863 and iou=0.0 and reward=0.0 and discount=0.9227446944279201\n",
            "   |->> t=10 Diff-Reward (0.0) for 2X LEFT:bbox transition: [270,   0,  64,  71] -> [268,   0,  64,  71] w/ P(a|s)=0.20236006379127502 and iou=0.0 and reward=0.0 and discount=0.9135172474836408\n",
            "   |->> t=11 Diff-Reward (0.0) for LEFT:bbox transition: [268,   0,  64,  71] -> [267,   0,  64,  71] w/ P(a|s)=0.5159415602684021 and iou=0.0 and reward=0.0 and discount=0.9043820750088044\n",
            "   |->> t=12 Diff-Reward (0.0) for 2X LEFT:bbox transition: [267,   0,  64,  71] -> [265,   0,  64,  71] w/ P(a|s)=0.3527013659477234 and iou=0.0 and reward=0.0 and discount=0.8953382542587164\n",
            "   |->> Assigned losses: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\u001b[31m>> Total frame loss: 0.0\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 81 with src: [265,   0,  64,  71] and target: [336, 173,  61,  79]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0081.jpg\n",
            "|->> Beginning tracking for bbox:[265   0  64  71]\n",
            "|->> Revisiting bbox: [265   0  64  71]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=21-th Action selection: 8/STOP (P(a|s) = 0.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [265   0  64  71]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 6.420e-02 0.000e+00 0.000e+00 0.000e+00 9.358e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 1.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.4741661e-07 6.4158805e-02 7.4098658e-08 3.3814438e-06 3.9427669e-11\n",
            " 9.3578386e-01 5.9553362e-15 4.8127806e-15 2.6230420e-13 9.7758555e-12\n",
            " 5.3606098e-05], argmax=5\n",
            "         |->> Hit a STOP on the 21-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [265,   0,  64,  71] -> [265,   0,  64,  71] (Target was [336, 173,  61,  79])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [265,   0,  64,  71] -> [265,   0,  64,  71] w/ P(a|s)=2.623042028807726e-13 and iou=0.0 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-11.512925]\n",
            "\u001b[31m>> Total frame loss: -11.512925148010254\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 82 with src: [265,   0,  64,  71] and target: [328, 169,  61,  79]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0082.jpg\n",
            "|->> Beginning tracking for bbox:[265   0  64  71]\n",
            "|->> Revisiting bbox: [265   0  64  71]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=21-th Action selection: 8/STOP (P(a|s) = 0.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [265   0  64  71]\n",
            "         |->> Action Probabilities (Rounded): [6.000e-04 6.800e-03 0.000e+00 0.000e+00 1.120e-02 9.771e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 3.900e-03 3.000e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [6.3764019e-04 6.8071894e-03 3.6347528e-06 2.6752922e-08 1.1209685e-02\n",
            " 9.7706294e-01 3.6323738e-05 4.9397222e-05 2.0353301e-07 3.8809136e-03\n",
            " 3.1214822e-04], argmax=5\n",
            "         |->> Hit a STOP on the 21-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [265,   0,  64,  71] -> [265,   0,  64,  71] (Target was [328, 169,  61,  79])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [265,   0,  64,  71] -> [265,   0,  64,  71] w/ P(a|s)=2.0353300556053e-07 and iou=0.0 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-11.512925]\n",
            "\u001b[31m>> Total frame loss: -11.512925148010254\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 83 with src: [265,   0,  64,  71] and target: [320, 164,  61,  79]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0083.jpg\n",
            "|->> Beginning tracking for bbox:[265   0  64  71]\n",
            "|->> Revisiting bbox: [265   0  64  71]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=21-th Action selection: 8/STOP (P(a|s) = 0.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [265   0  64  71]\n",
            "         |->> Action Probabilities (Rounded): [0.000e+00 1.000e-04 0.000e+00 0.000e+00 0.000e+00 9.999e-01 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00], argmax=5\n",
            "         |->> Action Probabilities (RAW): [1.7001751e-09 1.3877335e-04 4.8619359e-12 1.5438121e-07 2.7002516e-06\n",
            " 9.9985778e-01 6.4951227e-21 3.0476552e-20 1.6974463e-21 1.4240470e-08\n",
            " 4.1350981e-07], argmax=5\n",
            "         |->> Hit a STOP on the 21-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [265,   0,  64,  71] -> [265,   0,  64,  71] (Target was [320, 164,  61,  79])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [265,   0,  64,  71] -> [265,   0,  64,  71] w/ P(a|s)=1.6974463086378793e-21 and iou=0.0 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-11.512925]\n",
            "\u001b[31m>> Total frame loss: -11.512925148010254\u001b[0m\n",
            "\u001b[34m>> Attempting to reach frame 84 with src: [265,   0,  64,  71] and target: [300, 149,  61,  79]\u001b[0m\n",
            "Frame path: adnet_datasets/OTB/Matrix/img/0084.jpg\n",
            "|->> Beginning tracking for bbox:[265   0  64  71]\n",
            "|->> Revisiting bbox: [265   0  64  71]. Breaking action sequence\n",
            "   |->> Trajectory ending is FORCED\n",
            "   \u001b[33m|->> #0/t=21-th Action selection: 8/STOP (P(a|s) = 0.0)\u001b[0m\n",
            "      |->> Bounding box moves to: [265   0  64  71]\n",
            "         |->> Action Probabilities (Rounded): [2.00e-04 1.00e-04 1.00e-04 4.70e-03 7.52e-02 9.19e-01 1.00e-04 0.00e+00\n",
            " 0.00e+00 1.00e-04 5.00e-04], argmax=5\n",
            "         |->> Action Probabilities (RAW): [2.2920652e-04 7.9526842e-05 1.1913997e-04 4.6979343e-03 7.5227536e-02\n",
            " 9.1899323e-01 9.0486799e-05 4.7975459e-06 5.9204222e-08 6.8436755e-05\n",
            " 4.8954133e-04], argmax=5\n",
            "         |->> Hit a STOP on the 21-th action!\n",
            "    \u001b[31m|->> Completed tracking\u001b[0m\n",
            "\u001b[34m>> Calculating frame loss : [265,   0,  64,  71] -> [265,   0,  64,  71] (Target was [300, 149,  61,  79])\u001b[0m\n",
            "   |->> t=1 Stop-Reward (-1.0) for STOP:bbox transition: [265,   0,  64,  71] -> [265,   0,  64,  71] w/ P(a|s)=5.92042219693667e-08 and iou=0.0 and reward=-1.0 and discount=1.0\n",
            "   |->> Assigned losses: [-11.512925]\n",
            "\u001b[31m>> Total frame loss: -11.512925148010254\u001b[0m\n",
            "Final bounding box: [265   0  64  71] reached in 21 timesteps (originating from [288   6  64  72]). Target was [300 149  61  79]\n",
            "\n",
            "\u001b[36m############# END EPISODE # 85 in t=21 timesteps ################\u001b[0m\n",
            "Avg Loss Across Trajectories: \u001b[31m\u001b[0m\n",
            "Layer Name: conv_1/kernel:0, GRAD NORM = 1.9937382936477661\n",
            "Layer Name: conv_1/bias:0, GRAD NORM = 0.0020237290300428867\n",
            "Layer Name: conv_2/kernel:0, GRAD NORM = 0.9810222387313843\n",
            "Layer Name: conv_2/bias:0, GRAD NORM = 0.0028268878813833\n",
            "Layer Name: conv_3/kernel:0, GRAD NORM = 1.9141494035720825\n",
            "Layer Name: conv_3/bias:0, GRAD NORM = 0.004880937747657299\n",
            "Layer Name: fc1/kernel:0, GRAD NORM = 1.458067774772644\n",
            "Layer Name: fc1/bias:0, GRAD NORM = 0.003042403142899275\n",
            "Layer Name: fc2/kernel:0, GRAD NORM = 0.7146102786064148\n",
            "Layer Name: fc2/bias:0, GRAD NORM = 0.0027285299729555845\n",
            "Layer Name: fc3/kernel:0, GRAD NORM = 1.5257493257522583\n",
            "Layer Name: fc3/bias:0, GRAD NORM = 0.014543072320520878\n",
            "#################################################\n",
            "#################################################\n",
            "Finished Training On: ['adnet_datasets/OTB/Matrix']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot losses\n",
        "fig = plt.figure()\n",
        "all_losses = np.concatenate([v for _, v in losses.items()])\n",
        "plt.plot(np.arange(len(all_losses)), all_losses) \n",
        "plt.xlabel('Number of Episodes')\n",
        "plt.ylabel('Avg Trajectory Loss')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "K8lR0icde6QZ",
        "outputId": "51d77c9d-e4f0-4846-93b3-a97841b33688"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Avg Trajectory Loss')"
            ]
          },
          "metadata": {},
          "execution_count": 97
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEGCAYAAACO8lkDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2dd3gVVfrHv+9NAqHX0JHQFQVEioKCqIDYy1rXvpbVde2LYvnZXdta1rV3d+0dFRUREARECL1DwIChN0MJBJK8vz9m5mbutDtz78y9k9z38zx5cqedeefMmfOe877vOYeYGYIgCIKgJ5JuAQRBEITwIcpBEARBMCHKQRAEQTAhykEQBEEwIcpBEARBMJGdbgH8oHnz5pyfn59uMQRBEKoVs2fP3srMeVbHaoRyyM/PR0FBQbrFEARBqFYQ0Rq7Y2JWEgRBEEyIchAEQRBMiHIQBEEQTIhyEARBEEyIchAEQRBMiHIQBEEQTIhyEARBEEyIcvDA8o27MKtoe7rFEARBCJwaMQguVZz47BQAQNFjp6RZEkEQhGCRnoMgCIJgQpSDIAiCYEKUgyAIgmBClIMgCIJgQpSDIAiCYEKUgyAIgmBClIMgCIJgQpSDIAiCYEKUgyAIgmBClIMgCIJgQpSDIAiCYEKUgyAIgmAibcqBiHKJaCYRzSeixUT0gLq/IxH9SkSFRPQREdVKl4yCIAiZSjp7DmUAjmfm3gAOBzCSiI4C8DiAZ5i5C4AdAK5Mo4yCIAgZSdqUAyvsVjdz1D8GcDyAT9X97wA4Mw3iCYIgZDRp9TkQURYRzQOwGcB4AKsA/MHM5eopxQDa2lx7DREVEFHBli1bUiOwIAhChpBW5cDMFcx8OIB2AAYAONjDta8ycz9m7peXlxeYjIIgCJlIKKKVmPkPAJMADATQmIi0FeraAViXNsEEQRAylHRGK+URUWP1dx0AwwEshaIkzlFPuwzAmPRIKAiCkLmkcw3p1gDeIaIsKErqY2b+hoiWAPiQiB4GMBfAG2mUURAEISNJm3Jg5gUA+ljsXw3F/yAIgiCkiVD4HARBEIRwIcpBEARBMCHKQRAEQTAhykEQBEEwIcpBEARBMCHKQRAEQTAhykEQBEEwIcpBSIr1f+xFZSWnWwxBEHxGlIOQMGu3lWLQYxPx/KTCdIsiCILPiHIQEmZ9yV4AwNTCrWmWRBAEvxHlIAiCIJgQ5SAIgiCYEOUgCIIgmBDlIAiCIJgQ5SAIgiCYEOUgCIIgmBDlIAiCIJgQ5SAIgiCYEOXgwNPjVyB/9FiZHkIQhIxDlIMDz09cCQAQ1RAHySBBqHGIchAEQRBMiHIQkofSLYAgCH4jysEFzGI3EQQhsxDlIAiCIJgQ5eAC6TcIgpBpiHIQBEEQTIhycIG4HOIg+SMINQ5RDoIgCIIJUQ4uYGkaC4KQYYhyEARBEEyIcnCB+BziIIPgBKHG4Uk5EFETIuoVlDCCIAhCOIirHIjoJyJqSERNAcwB8BoRPR28aKnlQEUlSvYeSLcYgiAIocBNz6ERM+8EcDaA/zLzkQCGBStW6rnlo3no/cAP6RZDEAQhFLhRDtlE1BrAeQC+CVietPHNgg22x8TnIAhCpuFGOTwIYByAQmaeRUSdAKxM9sZE1J6IJhHREiJaTEQ3qfubEtF4Ilqp/m+S7L0E98wq2o7Xf17t7SJRnoJQ44irHJj5E2buxcx/U7dXM/OffLh3OYDbmLkHgKMAXE9EPQCMBjCBmbsCmKBuCyni3Jd/wcNjl6ZbDEEQ0owbh/QTqkM6h4gmENEWIro42Rsz8wZmnqP+3gVgKYC2AM4A8I562jsAzkz2Xskig+AEQcg03JiVRqgO6VMBFAHoAmCUn0IQUT6APgB+BdCSmTUHwEYALW2uuYaICoioYMuWLX6K44mr/1uAHvd+n7b7C4IgBIErh7T6/xQAnzBziZ8CEFF9AJ8BuFlVQlFYWWXHstnOzK8ycz9m7peXl+enSBb3sj82fskmlO6vCPT+oUcGwQlCjcONcviGiJYB6AtgAhHlAdjnx82JKAeKYniPmT9Xd29So6Og/t/sx70EQRDCBjOHdqVJNw7p0QAGAejHzAcA7IHiF0gKIiIAbwBYysz6QXVfAbhM/X0ZgDHJ3itZwvnqBEGo7nS881uc98ov6RbDkux4J6it+4sBDFHqc0wG8LIP9z4awCUAFhLRPHXfXQAeA/AxEV0JYA2U8RVCmBHtKQgJM6toR7pFsCSucgDwEoAcAC+q25eo+65K5sbMPBX21uoTkknbb8La7RMEQQgKN8qhPzP31m1PJKL5QQmUbpgZag9JEAQhY3HjkK4gos7ahjpCOqPCc6TfIAhCpuGm5zAKwCQiWg3FDNQBwBWBSpVGmAHpOHhE8ksQahxxlQMzTyCirgC6q7uWQxkQlzGIy0EQhEzD1WI/zFzGzAvUvzIAzwQsV9pItx5YumEnduzZn2YpBEHIdBJdJjSzDAkp1Bgn/ftnnPnitNTd0A/SrVEFQfCdRJVDja0O9GGr6YpaWrOtNC33FQRB0LD1ORDRQlgrAYLNZHg1FZmVVRCETMPJIZ1RTmcNUQOCIAgOyoGZ16RSkDAj0UqCIGQaifocaiyiCARBEEQ5uEL0RRwyK3ZNEDICN8uEnkZEGaNExPmcAJJlvrN3fwV27TuQbjGEDMZNpX8+gJXqWtIHBy1QGJFZWYVUM/iJSeh5/w/pFkPIYNws9nMxlPWdVwF4m4h+UddvbhC4dGmgJuiBvfsrkD96LN6a9lu6RcHW3WX4ccmmdItR7di6uyzdIggZjtvpM3YC+BTAhwBaAzgLwBwiuiFA2UJDddMXO0qV6TdenbI6zZIAl7wxE1f9twD7DmTURL6CUO1x43M4g4i+APATlEV/BjDzSQB6A7gtWPGERAiTMivaugcAUFkTumSCkEG46TmcBeAZZu7JzE8y82YAYOZSAFcGKl1IcFuvbd65DwcqKk37S/YewIWvzsC6P/b6LJk1mo9EgogEQUgUR+VARFkAOjDzFKvjzDwhEKnSSKIN3H0HKjDgnxNw5+cLTcfGLtiAX1Zvw/MTVyYpnTdkRTtBEBLFUTkwcwWASiJqlCJ5Qomb8NayA0qP4YfFG03HImodXWnuVISe5Rt3YeWmXZbHRPUIQs3FzUpwuwEsJKLxAPZoO5n5xsCkSiOJjnNwui6ituCro939xGeVTmPRY6eYjlW/pxEEd+wpK8eUFVtwUs/W6RYlbbhRDp+rf5mLRS1435hF6N6qobvrtZ5DimrTaqiDBCFU3P3FQnw5bz2+vXEwerRx+Z3XMNwsE/oOEdUC0E3dtZyZM37o5ju/xM5LSA5GFq3nkMmjr6uTwpq4bBPy6ueiZ7uMtqZmNMU7lOCRPfvL0yxJ+nATyjoUwEoALwB4EcAKIhoSsFxpw6oSS7Zeq/I5VKMasoayastuvDnVeXDgX94uwGnPT02RRIIQTtyYlZ4CMIKZlwMAEXUD8AGAvkEKVt1w53NIlTQKYQpWCotaPPP5adhVVo7LBuUjKxKiDBJCSXXq8fqNm3EOOZpiAABmXgFlMFyNxKoseCkgVuGj2q5UlbMwFuiwzE+1qyxzzQSCe8LUsEoXbnoOBUT0OoB31e2LABQEJ1JqmbB0E658x7/HsaoE0xWtFHQB95J8OFRDFcp78p5BpfvLESFCbk6W/0IJoUHzIYalUZMO3PQcrgOwBMCN6t8SANcGKVQq+Xzuuphtq8LgxpHsVIaiPYcUFbQwOr5ryjfW495xGPzEpHSLIQRNinv7YcSNcriWmZ9m5rPVv2egKIwaSen+CsspMOLhVIiiPYcUDYJzWxEX7yjF7DU7bNKo2Z+F/uk279qHtdtKXV+7ZVewM6Z+v2hDoOnXZDaU7MXqLbt9S6+GfwaOuFEOl1nsu9xnOdKH4eUf+c8JuOSNX2NPcVFARjwzGYDZ5/Dzyi1YUFwCoMqstHV3GZas32kWRXej8gQUVDQdl+cd8/gk/Oml6ZbHFq4r8e0+3k8OHv07HfDIBAx5MtjewPH/+glHPzYx7nnFO0px7btzApWlJjPw0Yk4/qnJSacjLgcH5UBEFxLR1wA6EtFXur9JALanTsTUM2O198fbunu/5f5L3piJlyevAlAVrTTy2Sk4+bmfHdP7z8RCzzJoVEYn3nNfxPeXV2Lu2qpexOnPT0OpjzHeYTR1pZLVW/e4mngxk1uqfrJy0y7MKkpNNXX8v35Cv4fHp+ReqcTJIT0dwAYAzaGEs2rsArAgSKHChvF7/XX1trjXTFmxxWISPq3nYK1I9BVD4ebYrnFZeQVu/GAuRp3YHV1aKOss/bR8M9o1qRPdtkrHLQ99swT/mxE7sO++MYu9J2RD2Co9TVn5qQD9oFa2ub22sWQfdpeVo0uL+mmQKHh27TuAK96ahSfP7Y2Ozev5kubwZ+ynffGCm0bN6q174p5THbFVDsy8BsAaIroIwHpm3gcARFQHQDsARSmRMGgS6D+e/+oMx+MVlYyHvlliainGG+egP1yvdmw0TEHRDoxbvAklew/gw2sGAgAuf2sWgNgP4LkJK/HdImXyPy/RSovWm81IG0r2uU8gDtqzTV6xBRtL9uL8/gf5lnZC8qgCBe0/8IrxlT349RK8qa7ol2xFp2fe738AAA5v39i3NBNl4rLNKFizA0+PX4H/XNgn3eIA0H07IWvUpBI3PoePAegN4BUAPglGnHDixTlbsvcAOt/1LVZuNjvFJi7b7NqXULdWrN4u2avMWLKxZB9emGRvcnp6/Aos3WD2Z4SFy96ciTs+M09rLigYS9qbAS31euYL03DmC9MCSTtRvp6/Hte/Hw5/i2aS/fPrv2LXvsycLciNcshm5qgdRP1dKziRwkMQTqkXf1ple0yvhNo3rQsAmLt2B35dvS2qHIq2leLJccstrzeiyb+g+A/sUQd//e+XIny3MPXRMGGNfvLil/GL4h2lWLPN2hQR0mxKGWMXhCNSS9/rXmwRPJIJuFEOW4jodG2DiM4AsNWPmxPRm0S0mYgW6fY1JaLxRLRS/d/Ej3slg58fbPEOdyGTDXKVnsNZL07H+a/OMIXXuq1sd+07gNOfn4YbPpgLAPi/MYtx3XuJtc5e/KkwJvS1eg+CS9+9j3l8Eo598ifLY5nkuP9+0Ubkjx4bbfgI4cLVOAcAdxHR70S0FsAdAP7q0/3fBjDSsG80gAnM3BXABHU7I2DbDYtzXdYh+8sVpaLZmL1g9Fk88f3ymNBXNyJUDQD0fPtA8VoJL1pXEl0PO0jClk9B8trPqwGYgy/CQLKzC5SUHoiJ/quOxFUOzLyKmY8CcAiAHsw8iJkTj7OMTXsKzGGxZwB4R/39DoAz/bhXWNCbMbbv2Y++D43HQnUchL5iiFd5uauYq+6VrFmn70NVoXrDn57sKmZfuW9Stw0Mr3Kd+p+pGPqvn3yVoaBoOwo378L2PVXRayHNLsEjl775K856cXpozalucDNld0siegPAJ8y8m4h6ENGVAcrUkpk1w+NGAC1t5LqGiAqIqGDLli0BihMc0wq3Ytue/Xh5itkPEa9MuS10moLYUXoAm3baRx/FS26brgJbuXk31v2x11MFG6S5pHR/eehCUt1wzsu/YNjTUzD86apBW9W5MqluLCwuCSy/51s0+KobbsxKbwMYB6CNur0CwM1BCaSHlTdnmb3M/Coz92Pmfnl5eUncxI0ciSfvhOYHqBKFdb+Tx9gzfnt6kQ+pJkiAH0mPe8fh0PvG2R6/49MFuOqdWZbihGH2Tb3irc6VSXXixyWbcNrzU/Fxwe+Wx/U9fGbg8znF2HegwvN9qvPrdKMcmjNzNJyVmcuhhLMGxSYiag0A6v/NAd4rtMTtOaRGDEcufM15vIeeoOV1yq+PCn7Hj0tji9Ff3pqFVybbR44J7nl1yirkjx5rW9GGkdVbFT/Hyk3W/g59o2Fq4Rbc+vF8PPbdMtfpa9dXx3XjNdwohz1E1Azq901ERwGIP/FO4nyFqvmcLgMwJsB7ucJPk4hTS9WTz8GlSOk2U4TVIT2zaDse9fCxp4qw5ZOR139ejckrYs24r05RxmLc/qm3iRPSXTYBdz3HXfsUk+XmXe4HhWrJVmfl4GY9h1uhVNidiWgagDwA5/hxcyL6AMBQAM2JqBjAfQAeA/Cx6tdYA+A8P+4VFj6c5a51Fb/nUD0KXZi+jXu+DP/gu7C/14fHLgUQO1o7WdNcope//+tadG/VAH07BBvtnoh8RAQwh6r8eyWucmDmOUR0LIDuUPJpOTP7EpjMzBfaHDrBj/T9Ih0vON4tXclkKNUvOQzACxoG204PnirenbE2rfd3Q3WsTJJ121itnuiGu75QlL2f04poJCqTker4PjVslQMRHc/ME4nobMOhbkTEUEJQpzJzkP6HjCKmIFXnUmUBM2ynB08nYXBI66lOb33b7jI0q187dHnoN4m8k5puVjoWwEQAp9kcbwbgHgDD/RYqbKTj9RrvmUgZI4t0Uk2q18+u7gRph5+4bBOmrtyGe0/rkXRaPyzeiGv+NxvvX31kdDGrmkTyvSHlf41UDsx8n/r/Crtz1PEPgk/EhLL6NEI6LGUzDM7H6kCQufSXt5W10v1QDgWqiXBBcYnrirSsvAK1s6vH2ttW+s5LEVbMUhx3JuYw48YhDSI6BcChAHK1fcz8IDMHORguNKSjYot3TzeOSyJKu4NTdII3qkt+6etON/b5hcUlOO35qXj90n4Y1sNyXGtoScghrf6vzo0iNyOkXwZwPoAboDzzuQA6BCxXRlFVkKr2+eKQdpOQA3455YDwVnrhkyt0AjniNv/mqPMM6cNg0/mk8eT2q+SHr3y5x804h0HMfCmAHcz8AICBALoFK1a4CHwAl9U+w84dpdarxzkRJp+D4I5UVyYHKipxz5cLsaEk/hKmdlTnd0xEKCk9gAtfnYH1LpZxdZ+u8r86+xzcKAdt5EcpEbUBcABA6+BEylzY5jcAfDl3ne25jmmGpGyGRY6wk+psmla4Fe/OWGuxpG0cdAqhujukv5hbjF9Wb4uu9Q7Y95rHzFuHr+avj5umNv1GTfc5fE1EjQE8CWAOlPL7WqBSZSh6+6TRVrlpZ5ntuY5phsTnUF7pbgW8VBMvG39csgl9DkrdUpqpVqLa7RK9L4OrZc9B/7gV6oadktMrips+nAcAOL13G8tzq65R7+MxYysrlfz006SbKI49ByKKQFlb4Q9m/gyKr+FgZr43JdKFhDC0eo3dU3dTdodDdgA4UJE6QT6bXYyzXlSWwNy623mNaCflubusHFf9twBXvD3L9hy/Sbcyt2LC0k34Ym5xzD79xHRueg4hqOssIVRV4BEiFG7ehd+3lyYfyqr+31Hqbbxwp7u+xRkhWb7VUTkwcyWAF3TbZcwc5LxKGYnVWubGSj3RcQ9hqWqMK9kFyW2fzMfctcriRv0e/tHxXKd8HKFOpZ2KRX400qXMnW575TsFuOWj+dbXsTvnrdVzpUJf5I8ei9/ivD+t4ZUVAYY9PQWDn5iU/JQgagInPjvF87ULis1VbGUl442pvyU0M2yiuPE5TCCiP1EY+jlpIw2hrHGXgoufBoFsu7Vuurt+vHCt1JRXQ+Pr+hL3E635RaqVQ6LveEFx1cqCq1OoPBNh7AJnH4HWbvHTd+J3Zfn1gvV46JsleOoHd+vH+4GtciCif6o//wrgEwBlRLSTiHYRUWauuB0QVnZfvyoJu3RSXVlXBORzSDaOPGwqK4xmJSumr9oGANiyy9ls50SqntSqXasvNlrPIRKJGb3heE38m3o41wV79ys9hp17U7eolVPPYSQAMHMDZo4wcy1mbqhuN0yRfKEgZa05L+McqkklouVdULoo2XfjRrmkMqe9PM+Xc9eZVvf77y9FyB89Nmbp0a/nr8f4JZvi3Dexpywr96b0rRrndg32rbvL8MDXi1EepEmSgAq1cGaluOeQSJ5/VPA7xsxbF/9EH3BSDllE1ISImlr9pUS6DMZUbow+iCSnz4jn0/CCG0VVEZB2SDbV6qFizezadwA3fzQPF7/+a8z+D2cqU8LrY/Zv+GAurv5vgWU6xlb1O9OLogPW3JF8DhrL4guTlCXq7xuzGG9NK8KEZQGu98W6noMuK/zyOfiFPjktYiponEJZDwYwG9ZKkAF0CkSiFOOmYgu6AqlySOtCWeMt9uMmXbIfhONnz8NJUUUHAwWlHBxu7qpX4Mp3kzrcKn1N2W42mHWWbEjO4nvfV4sBBDMNtlueHLcc1x/XJRrEkKzpMF49rZXN7xdvjO5Lthfh5vKwRBLa4aQcljBzn5RJIsQQr+C4HXlpd5afBdNKFmbGMz+uRKlqK60I6Etw0jlh//iscKu0tWdLpA5zU9me+p+fcXLP1vjb0C7RfcaBmHo5wow+7La8ohKHPzgerRpFp4mLliFtxTcAyIokqRxcnBP2rHMTrZTxpOoDcLqPsdJwrRxso5XiX+u24rGqoFdt2Y3nJqyMbgflAHeqTCev3GJ7TJ9CmEhFiLL+Vdi94kXrduKJ72MjY27+yGzOiCfvjNXbsHi9dfT7uh3O01X4tcSsvhzvKavA7rJyFG5W146mqoaLPi+SVg41ILjTSTn8O2VSZDhWZT9u687FB1NRaV91+mtWMqdl1AVBzU7plOwLEwuTut6JikrG6z+vjkaR+IVbcdiiQnN9jxQ29y94dQZOeW6q5T2NJjEj5JNBb6vuPlblXmto6Sv0lPQcPLwHv/LCC7bKgZnfTqEcoSZVkUGOg+AM224a4hUOa9jq9+8pSy48zuoWxqIcVMDJlBX2vQM3pqzF6xOz0T/0zRI8PHYpnh5vjjtnZlsfy+44ee1+WhSFRFqofpZmp29DPxbCyMRlztFTfvL61N8cj2vvSp+VyY55sF4Pgh3zxDnBpMRJCDErhQCrud/jBCu5Misphd76PP31Ax5xHkUc9z4Wshg/jiCilZgZ1/xvtsPx+GnoTSW7y8pRULTdnI7Fde/OWAMg1k6tT7PTXd9a3u+w+8Y5yuO+56D8T6TOSNVMoac/XzUNxB97Y6eR0BYeAlLbkzEWQwJZNrSyLGpGb41E85v5ZHYxTn9+Gn5QHd/hMmiacbXYT6aTDqebuefg3efg2HPQ/d6TpGnEenxb7MfhtUL6fE4xBnRsinZN6tqe89Gs353l8njPv78/Bz8td+OnsP+wl23ciTHz4s/aaZuuS5GrTCHJ3ePSN2d6T8AmLSee/VHxPy1Zv7PK3q+lYXNNEEvMWjVSrKbD15uVElFeVu9llfrc2ohyY7JzHUKI0+HBiKsciOg5i90lAAqYeYz/ImUuMWYlwydh6klYlFfjvCsVFQ4+h4CjlYw4OaR/316KrbvL0OegJsq5FZW49eP5aNMoF5NGDTUtLblz3wF8PX89xi12Nk14VQ6L1lk7Ti1juW3SHvnsz9Hf3e75DtcO6YRbR3T3IIU7mauezZ9qI9HyYHytv28vRcuGuaiVbW2UKFizA8PUOauSIdHehlWZ+HzOOjXNqn0xyiGhO5nRTIB25fKsF6f7dCd/cGNWygVwOICV6l8vAO0AXElEzwYoW0pw4+gJR8/BeRsAXvppVcx2JTvI7iZaKf4ptrIYW05OH/PgJybFfBiar2B9yT50v+d7jNPFnwPA3V8swt1fLMKcNc6DtfyascMyYMDFdfvLK/GcC6d4TLquew6ekjVc61+BNqY1+IlJGP35Ak9pJOLUT/T5jT2H2WuqzIj6Z8mOVFWN2u5SD3JafTta+lp6XsxUVr6lykrGK5NXYdc+bzO/usWNWakXgKOZuQIAiOglAD8DOAaAxxVCwkeYpqGImVspzrlWH/i/daGjgGpWcuFzSBarexiT9+JzMFbqk5ZtxomHtopub1On4Y43Q6X3Z7RWh1Z+BS9J/8fwXpxwm6yVE9X1PXws8lbvdcqKrZ7S+GR2cfyTdFRWMn79bVvMvp73jcPJPeOvQWaUd1aRdQND75DWyvfUQufn+nX1NhzZqZnpeo1Xp6yOkcHNeyivqMRLP63Cm9PMTvUfl27Co98tQ9G2Ujx6ds/4iXnETc+hCYD6uu16AJqqyiLxWbeqEaX7y7F8467A7xNTycYpOfpInO8WbrBsmVdUuvM5JEslKxOw6SN0jPJ4UQ5+DZhbloJ35oanxq9wfa7bR9dWI9u7vwL5o8dGp5xwdQ/LfYnludWqaH6F+Nul89rPq/Hn12KnDdlVVo6PCpx9UIBzgyHWrGS9X6OgaDuO/OePKNE52vW+C6c88PItfD53HZ4av8JyXQitJ5NstKEdbpTDEwDmEdFbRPQ2gLkAniSiegCSC3OpJlz33pyE5mVPhnjFR1/5XvfeHMuP1FE5GA7M/z3BEDsAxTtK0f+RH/HiT4XR+/7j01jTgvGjfMMivFBbN8Htx+N3ny8M45bc2tKfHKeE0Gqhsc8bzFdOyVS3dY2N4q7ekvgU4U5ly36qGbMcD3y9BJt2lqFwc1UDJMcqxMkqPZf5//6va/GVQ3BDdMLAJMdk2BH3aZj5DQCDAHwJ4AsAxzDz68y8h5lHBSJVyEhmWmIv6AtC/OkzYretZKysdDIreRbPln0HFDvQJDXSZ9nGnSZlY3RIvzI51j8CAO/PXKvIZjjXWGknugRjPFL1nu34fXupbyG/blvIQbBlVxm+X7TB93SZGS9PXmUZXeQWx3yJuVfsfY3sVO38uTlVwRJ6J7xTda31jOO9h7u+WOhoyqqaMDAY5eAmWulrAO8D+IqZw72qRzXmjk8XxHSL43XzjYXcqtA7hbIuXBe/p+B1gFUkWmmbj5lGTFtcr32Ebs1KVmcF1cUOmk0792HwE5NwWNvEZsM3vqonxy3HJQM7YOZvFuM2LPJ3WuE25I8em9C9rVi7vdS3tDTm/v4HHvtuWVJpOA3GtPP5WRVHrUIu1y1/q+85OH07law0gMYvrYq2m5TAzLNWs8n6iZt+0L8ADAawhIg+JaJziCg33kWCN4z20nj1o7FlbnW+U/iofhCSX8wq2oH80WPxy6ptpmPG3kBFJePSN2di+qqqlpH2DPFmcJ1WaE4fUOZzusgwhXUqSSZqRLNdL1pnP2LbS48bUloAACAASURBVE9pauFW/PV/sy3Nd9XFqqSPJNy7v8KXJTKde2ZeooeU/9ostoD7FnxlJeP9mWtx4wdzo/v+8UnsMqxLXcyuqym6oMxKcXsOzDwZwGQiygJwPICrAbwJIKMW/AkS/dz7GvGK6R2fxQaKWZX5SgefQ5A88u1S0z7jR7l9z35MWbElZmyBdobxWRav34kv5hbjrD7tHO97wlPJx88nw8Qk1h2o5cJezeyPXyQVRcLPuYA+m1OM69+f40taTsqhIiagApa/NbSnm6drpOmv17+n+79ajF7tGkW3X5myGqf2io2s2rYn1lRmDN+2wnoFO/9wNUKaiOoAOA3A+QCOAPBOINJkKHPWmk08Xit1q2U4K5hD43y0k+MPC/ux0ay0oLgEt3w036QcQvJoAJKfHsRNq9Ovx01FmSjZm3zs/diFit8intJ1k/efFPyOId3yHE2W+oigeGurrLJwiuvzVf86355eZDr324XOPpk/LKKT7O4XlFnJjc/hYwADAHwP4HkAk5k5wHX7BMB7aOF+i+UamcMzf4vdB1xpaKHd+fkCfDDTOiTx8Ad/wE0ndA1CvKTpfNe3aFw3J+Hr3fhZFLMSWfY0veBFN+zYk5jz93kPobVW2E3zbcXPLqZmH/XpAvRu3xj3ntrDVZrxeg5WxPQc4vScko07+GjWWtw7RjFp+bm8qR43Poc3AHRm5muZeRKAQUT0QiDSCFV4LDz7K6wvSOWkZk64qvzAtooBUFpTD3y9xE+xfEFbscxNa88ON63fV9RBVIMem2g65uU1e7HdH/HwePcJ+8gpz011fe7lb81ydV5J6f6Eek1ur9CX8WQH11r1NvTozcpBmZXchLKOA9CLiJ4goiIADwFILmQgRDiVlXTGvW/auQ/T44zI1HPAJgwjmSLq5+MHtUxoGLAaQe0VN5XWW9OKUJKEAtIY/MQk1+eGpG3hC9lZEddTYMTMkOwyD654axbenPpbyhtkQfUcbM1KRNQNwIXq31YAHwEgZj4uEEnM9x8JZcGhLACvM/NjqbhvWPhy3np86WF2T7tCH5aPWxsL4URYZPWKHxFSbnoOlcxYtjG5NaIzmcLNu7F2m7to/Hd+WRP9/cVc99N7PPjNEjz63dKY8Q9Bk45opWVQ5lA6lZkLAYCIbglECgNqZNQLAIYDKAYwi4i+Yubw2RRCwgfqADIzide4e/b7N2ZgdpxJ8gD73k+Y+aP0gKuww3i4UQ7b9+zH+a/OsDxGZO3cF2L5vzGL459kwGun90AF40BF6sbbpMOsdDaADQAmEdFrRHQCUjet+AAAhcy8mpn3A/gQwBl+32Tx+hJ8t8g6ZOyBrxfjgI0dvzphnDvfCzNWmwdQJcovq63HJuh571c7BRdevncRcuiGR78zh/96oXR/BQ5/MD3+ASG9pHwQHDN/ycwXADgYwCQANwNoQUQvEdGIYMSJ0haA3jNZrO6LQkTXEFEBERVs2eJugRYjxQ4LnL81rSihNMOGcTyEEE7sBvYJQjzSFq2kzqH0PjOfBmUdh7kA7ghEGg8w86vM3I+Z++Xl5SWURtvGdXyWShDST8+2jdCiQe10i1GtaVI3B/Vqpc5vkAxpi1bSw8w71Er5hECkqWIdgPa67XbqPl85rG2j+CdlIA+ecWi6RQAQnKMt7Nx50sEJX3vpwA74+oZj8OS5vX2UKPOYe+8ILLz/xMDvc3rvNmjdKLnZiIKaeM+TckghswB0JaKORFQLwAUAvkqzTNWa3Bz3r9rt1MNBs+yhkbhteLd0i5Fy6ucmvrS7Vk0c2y0Pc/9vOO4/zXrQ19lHtPWl53xKr/gL7FRXgmqR63n8T72STiNtU3anA2YuB/B3AOMALAXwMTN7DzNIEWFYB8DI4K7NY7a9tC6yU9Ri79KivuPx7Aihbu3EK8rqSn2fnrlJvVrIslH0XVrUx5Tbk49K/+eZ/q9AFjR/PbYTlj000vb4ab3b+Hq/CwccZHusTohNV6FUDgDAzN8yczdm7szMj6RbHieGH9LScr9ms+zesgEOalo3bjp3n3yIbzJ1bF4vZttLdZ9Mz+HgVg1cnTe8R0u8dXl/x3OICIe3zyzTX6fm9VDHxxh5u/dOIH9anAG2IxJRksMOaYF+HZo4nnPHiQfbNuhycyL4z4V9otuz7xnmWQYj3VvWx8y7TsCUUe6UccuG4fAXhVY5pAtji1tP/3zrQmfXKv/8b0cDUGZcdGPHb+FjoTB++F56Dsl0p+u6bAldN7Qz2jetixMObuF4Xt8OTTFt9PGm/Wcc7m/rLpX0bmev8P56bCdkZ/lX49q9dm1/3zgVqZv0j+nSHNcN7ZzQ9Y+cdZjtsTF/P9pzeoM6N8en1w1yPCcSIdu5j4xjGprVT/6bJCK0aJiLg5rVdRV2+uJFfT2lH9TsA6IcDBzdxV45tGxo7TiK6HLxvH7KzKHZEUKnPKX1ftJhrTCgY9OYa24Z1g0L7o+NCNZX4PGUSae8enjt0n4x+4Z0y0Nn9Z7Gwq+v8M/t6zz1tZvh/3Y9hLq17Ft7esebNkX1c7pWmh1tG9fBA6cfihuP7xLdl2j43vXHJVaJ+UlWhGwjYdo0roOsiPVnWScny7MJ064S1PYm23kgAO9edSTuGOnOiT7htmPxxmVV5TbH5lkBIC9OxJVTOY7X+tav2hZDwEOb3PTKm9evFf2tfc9OBDUzjSgHA9kRiim8empnx37QWgE8qlOz6L5LjsoHALRqlIucrAgW3D8C959uruhvGtYVDXNz8PCZh+FvQzvjlUv6Rlv7ww5piUsH5jvKeUbvtjje0Ooe0aMl3r5iAO4/rQeGdItVclql8sudx+N2lx+yE3fYRNQ4TRtw9ylVZjOtdVyvdjam3nEcbowz2+plg/IxVP+8DpXakQZFrCfebJmXDuxge6xdE7MDt00CkSbZkYjtBz24a56tz+eGE7qgZQPz/QbkOzyvzeNqDRGvq/2Z07e+3q5H0jmvfky5JQI+uXag5fn6NS6sevT/OLG77RKy5S4GsF7Qv71pn9sJ8yaPGoqf/jHU8lhPhyhIN9mtbyS66fEHNQW7KAcDESK0tagEAHNro2+HJlj64EgM1CmHurWz8MSfeuGjvw4EADTMzUGWQzf24qM64PaRB+PEQ1tFW3HafycTTVZEaYHePrJ7tIdSXlGJ9k3r4vKjO2Jo9xaYcacScdy4bk5VZQCK21qMZ+v97LqBOK67tTmol4PJRP+x61tQ7ZrUxS3D4k/F3VXnwHbqSjt9T/E+pAfPsDdzDLPwLdmVFaepoQ9qVtdRDjtfgDIFu/k621Yw7HsGRM7HrZhuYd6zunza6OPxiVr+re9N0XJSr3Y2+uc3ReM65unO9eXFaqp2srk/APQ5yFo56adVf+CMQ/HtjYNjjlu9Fitl3aFZPeQ3t27Vv3/1kbFy6i7XV/bPnn+45fX69+9qnQ9RDsGimUmyIoTOefVx0mGt8Mz5sbHih7aJXfxuf3kl6tTKimk9ZRHhvP7tTWGCXloMWsVhnG+na4v6aKBW3JqZ6G9Du+CL647Gef3a4dx+sS2hVo1yMXnUUIy/5VhdS9G5wL3w5yNw/MEt8PCZ9pVk3w7mlurlg/IBALUdKiq9QjCaE4wtUKu1lBvk5kTNUPpnGHVidzSrV9UVd+q6200d3r5pHZOZzkiECD8bInzsvstmOtOAxrKHRuL5P/fBg2ccGn3HFx9ljmSx6zn0aGO9+KKTcjA2SrRyrpn/tHwcdkjLGLOdFQ1ys029J6uiVL9Wdly/VQM1XLeeWp6tslGfhtVxIjLt1yrW5y6sqnhPOqyVpQy1s7NMeWqltL047mfceQIa5Nqv66Gl9JejO+LMPjGTPuC9q47EtzcOjr6T3JwIRlrIbgxLD8oSJspBRevWRiKEnKwIXrq4Lw5upRSc7i0bYNI/hmJo99iR2NoaChGbloFXctSPPFutOLWCOlo14dStlYULBrRXz6m6T6O6OXjinN7RD01Ph2b1kNegtm3rBYit0E/p1RpEhIuP6hDtuVw6sAMuH5Rv65DX4/Qh6R2tVk7X7i2r/BhH2LT8Rh7aCpcPysfdpxyCH289FhNvOxbXH9cFs/9vePSc+07rYVnpAvY9jiuP7ojhPayjzjTaN62D9rqos6LHTrH9MK3KQVaEcGqvNqhbK9vRTqzPQ+09f3PDMba9NcclRg1i7FXXcmhYJzvmXpcO7IAj4jinc7Ii+ODqo/DY2VXhq1Y94iwXDnXtWTSbutvWrz4SyepTO09tINWtlR1tSL10sXsHr5UUWh69eNERca+PNzJ9mFrGbh/Z3XSsbeM66NGmYYwP86YTumLevcNjztNnVVaEAjMrZV4QuQ1aBusdnVqeEymhoesMK3BpBVrf6nWjG8bdPMRy/5CuefjrsZ1w9eBOAKp6DlprLRIhlKv77JyWdmj1TSUzyHCpXeH68dZjsWZbKQZ2Vsxme/dX4I+9zjN/6ivF4T1aYuWmXSjaVgqgSukBQEMLM8K4W4bgnelFMYu2G6mVHYn6cOwiSfLq5+LhM3vi3RlrcXLPVqhXKxufzFamXbab+DWeU++ty/vj2G5K42DW3cOQo1aAdpWaVTnQly0tz60qV30edmxeDys378ZBzexDoWs7DHDUUjq5Zyuc0rMNKphx4wdzcXj7xqqcVb1V7f0c3aWZ5VxP2RFC+6Z1ccGAgzD684W2z2ns+Qzo2BQdm9XDuCVVkxReeUxHnNuvPRqp5cCYi/HCnPXPBiiBIHv2V8T4vKaOPh5l5e4XNgKse4KacujuIkw7Xo/piXN6YdSJ3S19c9p715eTSITQuG5sL/TPRx6Et6YV4fTebfD9oo2BOaRFOahoDix9I6x7qwY4v197XD2kIwBzq7Pcoudgh/4jsitkWRHCnSdVOW2122mmgGsGd4rObuo12jErWgmYW7WVDDx2dk9Tz6NN4zpoozOP1amVhTq1zDb2p8/rjbnqOtj6HoFmpskfPRYAohVqm0a5tn4NP+ynmg5a/c+TQQTc/umC6DE7RWi1v2XD2ti0swwAcJzOiaqPohnUubnlGuCWlX7E3PCwlF99P4e1bYjXL+2PqYVb0dDBVNGvQxOMUdf+MCarmZzq186OjmY+Te0dKvdSzqtkjppY/nJ0R0vloO/RjDqxO6av2mppRtTMeuf1a4ePC4rRq20j3HNqDzyOqtHARBRVDIA5P4y9GH1DTZ+Gxl0nH2KqRJX0vS3dajV1iabsErUJ6K+rnZ2Fdk2sFb1Wbp1630WPnYIx86pmEjq1V2vXY4u8IspBRbNF6yvOrAjh8XOqCrRW6GtlRbC/otLyGjviRck4kVc/F0WPnQIAmKquDud1AFO0hVjJJmVWyYwLHEZxxuPsI9phVpGyXoNVXlw+KB+rtuyOyuxH7LgTmgxaZewUQdWsXi1s27Pf0iSnvbNPr7V3rt4yvBvO79/etLqa29dj5WDWsrCyUvEbnRMn9PjMPm1t1yk4uWdrLCguwd+Pq/InGH1k2r2a1qsVLWeDuzbHll1lWLZxFwDgn2f1jLnu+uO64PrjrH0U2nu+bUR3TCvchouPso8A0zDmglHpsEVPi6BXGu4y3Oks7dmNKOXnAIgIlw/KN0UJ+oUxgkz/rA+deRgaWkyr8rSNU9sPRDmojOjRCp/PWRftblvRqlGuEnJKhKv+W5CypS9zsqsKiebs8jr/jvbtsKHn0KVF/ZiKwwvvX30k9pcrdhqtFWhlLtLMQAuLlUXjg7KRahgV1KiR3fG/GWsAKONL9OvzvnDREVi5aVfUVq1HS6aNwxxEWaqpxUjTemaHtFui78rl+XqHtLHyy8mK4P8cIqe0isjoqP/flUrEzchnp0QVhFdaNsy1HMBohbHH6BTYoKF/zfEaS59cOxDnvvyLK1mMaCPWKyorLcPS4+LRD2n1LJfoFKxVLyoIxCGtMvKwVlj1z5PRtaVzF+3EQ1uhifrha/Z//UvSh8rpSeZF6qNvbh7WFfeccghO793W4Qoz1x6rDP4yRtH8eOuxpqgJtwzq3BxDVcfizcO64oHTD8WpPe0nYtO6zW5WPUsGozumYW4O3r/qSEweNRSN6ubgymMUM+FNJ3TFUZ2a4ZKB+ZYfpLbHi7T/Orc3nruwD47s1MyVA99KT2otRrcmttrZWdEJCvs7jPGwQov1t5uh2KmxFCTGnoBltBLIdUhu8yR6q9r8R3v3e1+psFPzerbRUnZEoo0D6/fvdixGskjPQYdbU412XqXBrNS8fm3bMLZklLzewZebk4WrVIe1Fy4+qkO0e6+19v0kNycLl6nhrHYY882JZPLLyrQ1yGLkewOXvS8vfhC9CeiTawdheuFW/NlhjWkrPakpNy8drBtO6IoLBhwUd1SxkWE9WtqaU1KJViYOa9sQi9Y5LLtKsb+1PIpn2o147I3p0aL2tEgvL0y0GSjnBwF3HKTnkAianbbC0HNwjChMoOswRI2OSXYUqxHtQ3HTsvUTY745kUzbyK+VsbR8T8YKpvUujzEop0+vHYgrj+mIPIvxEFrPwav5zatiCCOjRx7iWlk5hWebzk2iKv3HiO5oUjcHB7c2WxVGndg97vgQr9TJycJVx3TEp9dazxEVsFU2ivQcEsBoHon4UIlY8eolffFH6QF/EwWQnRXBV38/2jRza9BEoj2HYO8TTze4fU+DuzbHh7N+T2oKbc0kYRwU2S+/KfrlN8X+8kp0zKuHd2esxdrtSshvMq3coAjavn12n3aYVrgNnVtYl0lr81sV8Tr9mvyJPMaRnZph7r3WKyNrTvnnJhbG7D+uex42lOxzlf4RHZpg7IINUd8GEeEeBz+R1pMxRmf5jSiHBDAOUotGlzh8zYkUytycLLRqFMx8773apd6WXBVOG6xZya+e1oNnHIbrhnaO+pgSoV+HJnjq3N44qae13blWdgRn9WmHs/pUmaPym9fD4K7NcUsGLXT0p77t8Kc4UVmAUSEQ2jWpg+Ide+P3HAJWbtkRium5vXXFANfXPnVub/zNQzkb0aMV7jutBy7on3iEoRsyXjm8dNER2G83MsoGzXwUdUi7cCCGcUGgVBPxYFYKA7WyI+jQzF3v6uWL+2L6qq2m/UTkqtLTk5MViUYLGRnSNS86oO+24d2wu6zcU9pe0cathHHFVm3Svrlr/4g7+Mxv06wR4wzLXsjNycKhbdyvWxKJEK44umPC93NLxiuHkxyia+wwmpE000Gyc+PXdLRIKaeVsc46oh0mLNuMvyUYXpsuRh7WynIeHL955KyeUeVwZp+2lmG0fjJqxMHIyYq4imj7+fbjULLXXzPo9zcPRmUlLEfmEwitG9VB657xlzt10h2tGuZi4053JiA7nKaqr67UvCdKAVrUjdYCrl87G9/dNBj5Dq3MoFsuYULr6hupVzs7OmrZjkZ1cmxbzfG4oH97fDjr94SurS7Uyo7gs+sG4vmJhUkvTO+GRnVzcN9p7mL72zetC/NokeTQ5jfbd6ACAzs1w72n9cBJ//4ZgLfeuJNDetwtQwLvgVVHRDkkgBau2lM3PfUhra1nzDRiNw6iJjHxtqG2sdhBLtr+6Nk98ejZ1W9NY6/07dDUk027JpCbk4UPrjkq4evjNUgaWQzezHREOSRA03q18M0Nx6BzXv34J+v417m9HRdmqSk4TSEdJJnUOxM89hykaHhGlEOC2I0odSLeHDlCOMjNiWDfAf8HCgr+4mXsQjLjHDIVUQ5CxhFv+oHpo0/AHrFBhx4vvYEwRluFHVEOQsZiZ4ZqWq9WUhPnCalB6vtgkekzBEGoliTiYxK/lHtEOQiCUC0RU1GwiHIQBKFaIr2AYBHlIAhCxuDHMrSZgigHQRAEwYQoB0EQqhWDu5oXbnKLmKLcI6GsQsYhloXqzWuX9sPW3WWermlStxZOOLgFrh7ifRXFTEWUg5CxSBuyepKbk4V2TbzNRhuJEN64vH9AEtVMxKwkCIIgmBDlIAiCIJgQ5SAIgiCYEOUgCIIgmEiLciCic4loMRFVElE/w7E7iaiQiJYT0YnpkE8QBCHTSVe00iIAZwN4Rb+TiHoAuADAoQDaAPiRiLoxc0XqRRQEQchc0tJzYOalzLzc4tAZAD5k5jJm/g1AIYDMWg9RSBkyHkoQ7Ambz6EtAP0K8cXqPhNEdA0RFRBRwZYtW1IinCAIQqYQmFmJiH4E0Mri0N3MPCbZ9Jn5VQCvAkC/fv1kzKsgCIKPBKYcmHlYApetA9Bet91O3ScIgiCkkLCZlb4CcAER1SaijgC6ApiZZpkEQRAyjnSFsp5FRMUABgIYS0TjAICZFwP4GMASAN8DuF4ilQRBEFJPWkJZmfkLAF/YHHsEwCOplUgQBEHQEzazkiAETk6WEsOanSXFXxDskCm7hYzjpmHdECHC+f3axz9ZEDIUUQ5CxlG/djbuPPmQdIshCKFG+tWCIAiCCVEOgiAIgglRDoIgCIIJUQ6CIAiCCVEOgiAIgglRDoIgCIIJUQ6CIAiCCVEOgiAIgglirv5LIRDRFgBrEry8OYCtPooTBGGXUeRLDpEvecIuY1jl68DMeVYHaoRySAYiKmDmfumWw4mwyyjyJYfIlzxhlzHs8lkhZiVBEATBhCgHQRAEwYQoB3Ud6pATdhlFvuQQ+ZIn7DKGXT4TGe9zEARBEMxIz0EQBEEwIcpBEARBMJHRyoGIRhLRciIqJKLRaZKhPRFNIqIlRLSYiG5S9zclovFEtFL930TdT0T0nCrzAiI6IkVyZhHRXCL6Rt3uSES/qnJ8RES11P211e1C9Xh+CmRrTESfEtEyIlpKRAPDlH9EdIv6bhcR0QdElJvu/COiN4loMxEt0u3znGdEdJl6/koiuixg+Z5U3/ECIvqCiBrrjt2pyreciE7U7Q/kG7eST3fsNiJiImqubqc8/3yBmTPyD0AWgFUAOgGoBWA+gB5pkKM1gCPU3w0ArADQA8ATAEar+0cDeFz9fTKA7wAQgKMA/JoiOW8F8D6Ab9TtjwFcoP5+GcB16u+/AXhZ/X0BgI9SINs7AK5Sf9cC0Dgs+QegLYDfANTR5dvl6c4/AEMAHAFgkW6fpzwD0BTAavV/E/V3kwDlGwEgW/39uE6+Hur3WxtAR/W7zgryG7eST93fHsA4KINym6cr/3x5xnQLkLYHBwYCGKfbvhPAnSGQawyA4QCWA2it7msNYLn6+xUAF+rOj54XoEztAEwAcDyAb9RCvlX3oUbzUv0wBqq/s9XzKEDZGqmVLxn2hyL/oCiH39UKIFvNvxPDkH8A8g2Vr6c8A3AhgFd0+2PO81s+w7GzALyn/o75drU8DPobt5IPwKcAegMoQpVySEv+JfuXyWYl7aPVKFb3pQ3VhNAHwK8AWjLzBvXQRgAt1d/pkPtZALcDqFS3mwH4g5nLLWSIyqceL1HPD4qOALYAeEs1e71ORPUQkvxj5nUA/gVgLYANUPJjNsKTf3q85lk6v6G/QGmNw0GOlMpHRGcAWMfM8w2HQiGfVzJZOYQKIqoP4DMANzPzTv0xVpoVaYk5JqJTAWxm5tnpuL8LsqF0719i5j4A9kAxiURJc/41AXAGFCXWBkA9ACPTIYsX0pln8SCiuwGUA3gv3bJoEFFdAHcBuDfdsvhFJiuHdVDsgxrt1H0ph4hyoCiG95j5c3X3JiJqrR5vDWCzuj/Vch8N4HQiKgLwIRTT0r8BNCaibAsZovKpxxsB2BagfMUAipn5V3X7UyjKIiz5NwzAb8y8hZkPAPgcSp6GJf/0eM2zlH9DRHQ5gFMBXKQqsLDI1xlKA2C++q20AzCHiFqFRD7PZLJymAWgqxo1UguK8++rVAtBRATgDQBLmflp3aGvAGjRC5dB8UVo+y9VIyCOAlCiMwX4DjPfycztmDkfSh5NZOaLAEwCcI6NfJrc56jnB9YCZeaNAH4nou7qrhMALEFI8g+KOekoIqqrvmtNvlDknwGveTYOwAgiaqL2kEao+wKBiEZCMW+ezsylBrkvUCO9OgLoCmAmUviNM/NCZm7BzPnqt1IMJdBkI0KSf55Jt9MjnX9QoghWQIlouDtNMhwDpfu+AMA89e9kKHbmCQBWAvgRQFP1fALwgirzQgD9UijrUFRFK3WC8gEWAvgEQG11f666Xage75QCuQ4HUKDm4ZdQIj9Ck38AHgCwDMAiAP+DElWT1vwD8AEUH8gBKBXZlYnkGRTbf6H6d0XA8hVCsdFr38nLuvPvVuVbDuAk3f5AvnEr+QzHi1DlkE55/vnxJ9NnCIIgCCYy2awkCIIg2CDKQRAEQTAhykEQBEEwIcpBEARBMCHKQRAEQTAhykEILerMlk/ptv9BRPf7lPbbRHRO/DOTvs+5pMwUO8mwP5+I9hLRPN3fpXHSepCIhvkg0+5k0xBqPtnxTxGEtFEG4GwiepSZt6ZbGA0iyuaqeZHicSWAq5l5qsWxVcx8uNv7MnONmZpBCD/ScxDCTDmUtXdvMR4wtvy11jARDSWiyUQ0hohWE9FjRHQREc0kooVE1FmXzDAiKiCiFeocUtq6FU8S0Sx17v2/6tL9mYi+gjLC2SjPhWr6i4jocXXfvVAGOb5BRE+6fWgi2k1Ez5CyBsQEIsozPrP6XEtUGf+l7ssnoonqvglEdJC6vyMR/aLK97DhXqN0z/qAuq8eEY0lovnq85zvVnah5iDKQQg7LwC4iIgaebimN4BrARwC4BIA3Zh5AIDXAdygOy8fwAAApwB4mYhyobT0S5i5P4D+AK5Wp2QAlDmbbmLmbvqbEVEbKOsLHA9ltHZ/IjqTmR+EMnL7ImYeZSFnZ4NZabC6vx6AAmY+FMBkAPcZ7tcMypTVhzJzLwBahf8fAO+o+94D8Jy6/99QJibsCWVUr5bOCChTTQxQ5e5LREOgTAy4npl7M/NhAL63kF2o4YhyEEINKzPU/hfAjR4um8XMG5i5DMqUBT+o0ngtLwAAAkFJREFU+xdCUQgaHzNzJTOvhLLQysFQ5re5lIjmQZk6vRmUChQAZjLzbxb36w/gJ1Ym19NmCx3iQs5VzHy47u9ndX8lgI/U3+9C6X3oKQGwD0qP5GwA2jxDA6EsyAQo03Ro1x0NZboHbb/GCPVvLoA56vN3hZJPw4nocSIazMwlLp5FqGGIz0GoDjwLpfJ6S7evHGrjhogiUFb60ijT/a7UbVcitswb545hKPPg3MDMMROgEdFQKNOBp4MYOZm5nIgGQJnE7xwAf4fSa3GdhgoBeJSZXzEdUJayPBnAw0Q0Qe0FCRmE9ByE0MPM26Esq3mlbncRgL7q79MB5CSQ9LlEFFH9EJ2gTNo2DsB1pEyjDiLqRsriQU7MBHAsETUnoiwoK3xNTkAejQiqZmz9M4AYZzYpa380YuZvofhjequHpkOZeRQALgKg9USmGfZrjAPwFzU9EFFbImqhmslKmfldAE9CMacJGYb0HITqwlNQWsgarwEYQ0TzodjEE2nVr4VSsTcEcC0z7yOi16GYnuYQEUFZZe5Mp0SYeQMpi9dPgtIaH8vMY5yuUemsmq803mTm56A8ywAiugfKmgpGh3ADKM+eq97vVnX/DVBWxBulyn2Fuv8mAO8T0R2omoYbzPwDER0C4BflUbEbwMUAugB4kogqocw6ep2LZxFqGDIrqyCEDCLazcz10y2HkNmIWUkQBEEwIT0HQRAEwYT0HARBEAQTohwEQRAEE6IcBEEQBBOiHARBEAQTohwEQRAEE/8PE1I2zwlvwB8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot losses\n",
        "fig = plt.figure()\n",
        "all_losses = np.concatenate([v for _, v in losses.items()])\n",
        "plt.plot(np.arange(len(all_losses)), all_losses) \n",
        "plt.xlabel('Number of Episodes')\n",
        "plt.ylabel('Avg Trajectory Loss')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "6BIwuoV4WAry",
        "outputId": "a9e0e170-0de8-4a7e-a723-28642633e7f9"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Avg Trajectory Loss')"
            ]
          },
          "metadata": {},
          "execution_count": 84
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot losses\n",
        "fig = plt.figure()\n",
        "all_losses = np.concatenate([v for _, v in losses.items()])\n",
        "plt.plot(np.arange(len(all_losses)), all_losses) \n",
        "plt.xlabel('Number of Episodes')\n",
        "plt.ylabel('Avg Trajectory Loss')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "avUfbzc8LVLU",
        "outputId": "66c2724f-52ae-46f6-b74d-d92bf2238c5c"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Avg Trajectory Loss')"
            ]
          },
          "metadata": {},
          "execution_count": 55
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot losses\n",
        "fig = plt.figure()\n",
        "all_losses = np.concatenate([v for _, v in losses.items()])\n",
        "plt.plot(np.arange(len(all_losses)), all_losses) \n",
        "plt.xlabel('Number of Episodes')\n",
        "plt.ylabel('Avg Trajectory Loss')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "GoaTVVfx8o7J",
        "outputId": "4f456032-4d46-42e6-80c2-238c1cf35356"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Avg Trajectory Loss')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot losses\n",
        "fig = plt.figure()\n",
        "all_losses = np.concatenate([v for _, v in losses.items()])\n",
        "plt.plot(np.arange(len(all_losses)), all_losses) \n",
        "plt.xlabel('Number of Episodes')\n",
        "plt.ylabel('Avg Trajectory Loss')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "FU_qZWFkZpPp",
        "outputId": "ecf45862-1678-4b34-9ba3-99482ff5f64d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Avg Trajectory Loss')"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot losses\n",
        "fig = plt.figure()\n",
        "all_losses = np.concatenate([v for _, v in losses.items()])\n",
        "plt.plot(np.arange(len(all_losses)), all_losses) \n",
        "plt.xlabel('Number of Episodes')\n",
        "plt.ylabel('Avg Trajectory Loss')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "vPEQ2VCeF97E",
        "outputId": "0803aba5-1d6e-4a13-de2b-16d09f0d529d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Avg Trajectory Loss')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot losses\n",
        "fig = plt.figure()\n",
        "all_losses = np.concatenate([v for _, v in losses.items()])\n",
        "plt.plot(np.arange(len(all_losses)), all_losses) \n",
        "plt.xlabel('Number of Episodes')\n",
        "plt.ylabel('Avg Trajectory Loss')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "XewrLtH0YWJB",
        "outputId": "16faa3a1-6bf0-4743-aafa-7ea2cc97064b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Avg Trajectory Loss')"
            ]
          },
          "metadata": {},
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VIDEO GENERATION AND PREDICTION\n",
        "###############################"
      ],
      "metadata": {
        "id": "It4L0M5m44zp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def standardize_bbox(img: np.array, bbox: np.array):\n",
        "  '''\n",
        "  Refits the bounding box to ensure that it is valid. X and Y get clipped first.\n",
        "  Assumes reasonable bounding boxes and solely for the bad data we found in\n",
        "  our ground truth dataset\n",
        "  '''\n",
        "  x, y, w, h = bbox\n",
        "  nx, ny, nw, nh = bbox\n",
        "\n",
        "  is_invalid = False\n",
        "  import pdb\n",
        "  # pdb.set_trace()\n",
        "  if x < 0 or x + w >= img.shape[1]:\n",
        "    w = np.clip(w, MIN_WINDOW_SIZE, img.shape[1])\n",
        "    # clip whichever keeps the most area    \n",
        "    x1 = np.clip(x, 0, img.shape[1] - 1)\n",
        "    w1 = np.clip(w, MIN_WINDOW_SIZE, img.shape[1] - x1)\n",
        "    x2 = np.clip(x, 0, img.shape[1] - w)\n",
        "    w2 = np.clip(w, MIN_WINDOW_SIZE, img.shape[1])\n",
        "    nx, nw = (x1, w1) if x1 + w1 > x2 + w2 else (x2, w2)\n",
        "    is_invalid = True\n",
        "\n",
        "  if y < 0 or y + h >= img.shape[0]:\n",
        "    h = np.clip(h, MIN_WINDOW_SIZE, img.shape[0])\n",
        "    # clip whichever keeps the most area\n",
        "    y1 = np.clip(y, 0, img.shape[0] - 1)\n",
        "    h1 = np.clip(h, MIN_WINDOW_SIZE, img.shape[0] - y1)\n",
        "    y2 = np.clip(y, 0, img.shape[0] - h)\n",
        "    h2 = np.clip(h, MIN_WINDOW_SIZE, img.shape[0])\n",
        "    ny, nh = (y1, h1) if y1 + h1 > y2 + h2 else (y2, h2)\n",
        "    is_invalid = True\n",
        "  \n",
        "  stdzd_bbox = np.array([nx, ny, nw, nh])\n",
        "  if is_invalid: \n",
        "    print(\"WARNING: Bounding box: {0} had to be standardized to {1}\".format(bbox, stdzd_bbox))\n",
        "  return stdzd_bbox"
      ],
      "metadata": {
        "id": "pZCDbWo0NA9D"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model: tf.keras.Model,img: np.array,bbox: np.array) -> np.array:\n",
        "  ACTION_DIM=11\n",
        "  seen_bboxes = set()\n",
        "  for t in range(MAX_TRAJECTORY_LENGTH):\n",
        "    patch = getPatch(img, bbox)\n",
        "    a_prob, score = model(patch)\n",
        "    maxaction = np.argmax(a_prob)\n",
        "    a, bbox = selectAction(np.array(img), bbox, maxaction)\n",
        "    model.updateActionHistory(a)\n",
        "    if isStop(a) or tuple(bbox) in seen_bboxes:\n",
        "      break \n",
        "  return bbox"
      ],
      "metadata": {
        "id": "yiVT6QYnThPs"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getPredictedBoxes(model: tf.keras.Model,dataset_index: int):\n",
        "  dataset = ALL_DATASETS_LIST[dataset_index]\n",
        "  model.clearActionHistory()\n",
        "  gt = get_ground_truths(\"%s/groundtruth_rect.txt\" % dataset)     \n",
        "  frames = sorted(glob.glob(os.path.join('%s/img' % dataset, '*.jpg')))\n",
        "  number_of_frames = len(frames)\n",
        "  start_frame = 1\n",
        "  predicted_boxes =[]\n",
        "  predicted_box = gt[0]\n",
        "  imgs = []\n",
        "  for f in range(len(frames)-10):\n",
        "    img = cv2.imread(frames[f + start_frame])\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    predicted_box = predict(model,img, predicted_box)\n",
        "    predicted_box = standardize_bbox(img,predicted_box)\n",
        "    predicted_boxes.append(predicted_box)\n",
        "    imgs.append(img)\n",
        "  return predicted_boxes,gt,imgs"
      ],
      "metadata": {
        "id": "p3WuC_B0mlMR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotNpImageBBoxesVideo(img: np.array,target_bbox: np.array, \n",
        "                      pred_bbox: np.array,directory) -> np.array:\n",
        "  '''\n",
        "  Plots the bounding boxes on an image and returns the bounding box\n",
        "  '''\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.imshow(img)\n",
        "  x2, y2, w2, h2 = target_bbox\n",
        "  x3, y3, w3, h3 = pred_bbox\n",
        "  rect2 = patches.Rectangle((x2, y2), w2, h2, linewidth=1, edgecolor='g', facecolor='none')\n",
        "  rect3 = patches.Rectangle((x3, y3), w3, h3, linewidth=1, edgecolor='r', facecolor='none')\n",
        "  ax.add_patch(rect2)\n",
        "  ax.add_patch(rect3)\n",
        "  plt.savefig(directory)\n",
        "  plt.close()\n",
        "  return img"
      ],
      "metadata": {
        "id": "iRDP-zb_xTxl"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createVideo(imageDir,videoDirectory):\n",
        "  img_array = []\n",
        "  for filename in glob.glob(imageDir+'/*.jpg'):\n",
        "      img = cv2.imread(filename)\n",
        "      height, width, layers = img.shape\n",
        "      size = (width,height)\n",
        "      img_array.append(img)\n",
        "  out = cv2.VideoWriter(videoDirectory+\".mp4\",cv2.VideoWriter_fourcc(*'MP4V'), 15, size)\n",
        "  for i in range(len(img_array)):\n",
        "      out.write(img_array[i])\n",
        "  out.release()"
      ],
      "metadata": {
        "id": "Sipelg4BxihA"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_boxes,gt,imgs = getPredictedBoxes(adnet_model)"
      ],
      "metadata": {
        "id": "K7Z6HS27mpES"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#first you need to save the figures to create the video\n",
        "for i in range(len(imgs)):\n",
        "  plotNpImageBBoxesVideo(imgs[i],gt[i+1],predicted_boxes[i],\"/content/gdrive/MyDrive/man-images/{}\".format(str(i)+\".jpg\"))"
      ],
      "metadata": {
        "id": "6ADsQuSuBg2g"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "createVideo(\"/content/gdrive/MyDrive/man-images/\",\"/content/man-1\")"
      ],
      "metadata": {
        "id": "akdMFk5tyV5I"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "END OF VIDEO GENERATION AND PREDICTION\n",
        "######################################"
      ],
      "metadata": {
        "id": "KvMg4PPW5Ap-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot losses\n",
        "fig = plt.figure()\n",
        "all_losses = np.concatenate([v for _, v in losses.items()])\n",
        "plt.plot(np.arange(len(all_losses)), all_losses) \n",
        "plt.xlabel('Number of Episodes')\n",
        "plt.ylabel('Avg Trajectory Loss')"
      ],
      "metadata": {
        "id": "eLw0pVFIUQfe",
        "outputId": "9851e5f9-080a-47d9-84d1-4fc1fa2a974d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Avg Trajectory Loss')"
            ]
          },
          "metadata": {},
          "execution_count": 204
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEGCAYAAACO8lkDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2dd5gW1dXAf2eXpjTpIipIExEEFBEUFYVgQcUSW6yJid1YEo1RE01M7JrYPo3dJGpi19gVwQ64Ik2kS0dYeoct5/tjZt6dt8/b3909v+fZZ2fulHtm3jv33HvOveeKqmIYhmEYfkoKLYBhGIZRfJhyMAzDMKIw5WAYhmFEYcrBMAzDiMKUg2EYhhFFg0ILkApt27bVLl26FFoMwzCMWsU333yzSlXbpXJNrVIOXbp0oaysrNBiGIZh1CpEZGGq15hZyTAMw4jClINhGIYRhSkHwzAMIwpTDoZhGEYUphwMwzCMKEw5GIZhGFGYcjAMwzCiqNfKYcL81cxZsbHQYhiGYRQdtWoSXLY5/bHxACy4Y1SBJTEMwygu6nXPwTAMw4iNKQfDMAwjClMOhmEYRhSmHAzDMIwoTDkYhmEYUZhyMAzDMKLIuXIQkT1EZKyIzBCR70TkSje9tYh8KCJz3P+tci2LYRiGEYx89Bwqgd+oam9gMHCZiPQGrgfGqGoPYIy7bxiGYRQBOVcOqrpcVSe52xuB74FOwGjgWfe0Z4ETcy2LYRiGEYy8+hxEpAswAJgAdFDV5e6hH4EOca65UETKRKSsvLw8L3IahmHUd/KmHESkGfAKcJWqbvAfU1UFNNZ1qvqYqg5U1YHt2qW0PrZhGIaRJnlRDiLSEEcxPKeqr7rJK0Sko3u8I7AyH7IYhmEYycnHaCUBngS+V9X7fIfeBM5zt88D3si1LIZhGEYw8hGV9RDgHGCaiEx2024A7gBeFJELgIXAaXmQxTAMwwhAzpWDqn4OSJzDw3Odv2EYhpE6NkPaMAzDiMKUg2EYhhGFKQfDMAwjClMOhmEYRhSmHAzDMIwoTDkYhmEYUZhyMAzDMKIw5WAYhmFEYcrBMAzDiMKUg2EYhhGFKQfDMAwjClMOhmEYRhSmHAzDMIwoTDkYhmEYUZhyMAzDMKIw5WAYhmFEYcrBMAzDiMKUg2EYhhGFKQfDMAwjClMOhmEYRhSmHAzDMIwoTDkYhmEYUZhyMAzDMKIw5WAYhmFEYcrBMAzDiMKUg2EYhhGFKQfDMAwjClMOPqYuWce2iqpCi2EYhlFwcq4cROQpEVkpItN9abeIyFIRmez+HZtrOZKxbN1WTnjoC256fXrykw3DMOo4+eg5PAMcHSP9b6ra3/17Jw9yJGTDtgoApi1ZX2BJDMMwCk/OlYOqfgqsyXU+hmEYRvYopM/hchGZ6pqdWsU7SUQuFJEyESkrLy/Pp3yGYRj1lkIph0eAbkB/YDlwb7wTVfUxVR2oqgPbtWuXL/kMwzDqNQVRDqq6QlWrVLUaeBwYVAg5DMMwjNgURDmISEff7kmADREyDMMoIhrkOgMReQEYBrQVkSXAzcAwEekPKLAAuCjXcgRF0UKLYBiGUXByrhxU9cwYyU/mOt9U+Pf4hYyfv7rQYhiGYRQNKSkHd1TRHqo6NUfyFAT/xDdBCiiJYRhGcZDU5yAi40SkhYi0BiYBj4vIfbkXzTAMwygUQRzSLVV1A3Ay8E9VPQgYkVuxDMMwjEISRDk0cEcXnQa8lWN5Co45pA3DMIIphz8D7wNzVfVrEekKzMmtWIZhGEYhSeqQVtWXgJd8+/OBU3IplGEYhlFYgjik73Id0g1FZIyIlIvI2fkQzjAMwygMQcxKI12H9HE4E9a6A9fmUijDMAyjsARySLv/RwEvqaoteGAYhlHHCTIJ7i0RmQlsBS4RkXbAttyKZRiGYRSSpD0HVb0eOBgYqKoVwGZgdK4FMwzDMApH0p6DiDQEzgYOExGAT4BHcyyXYRiGUUCCmJUeARoC/+fun+Om/TJXQhmGYRiFJYhyOFBV+/n2PxaRKbkSyDAMwyg8QUYrVYlIN2/HnSFdlTuRDMMwjEITpOdwLTBWROYDAnQGfp5TqQzDMIyCEiR8xhgR6QHs7SbNwpkQZxiGYdRRAq0hrarbVXWq+7cd+FuO5TIMwzAKSCDlEANbLs0wDKMOk65yqNWLHqzfWsGWHZWFFiOrvFS2mPemLy+0GIZh1BHi+hxEZBqxlYAAHXImUR7o96cP2GXnhoUWI6tc+7KzrPeCO0YVWBLDMOoCiRzSddrpvG5LRaFFMAzDKFriKgdVXZhPQYqNKYvX8d53P/K7o3sVWhTDMIy8k67Poc4z+uEveGTcvEKLYRiGURBMORiGUefZXlnFyg220kAqBFkm9HgRMSWSI14sW8w3C9cWWgzDqNNc9twkBt02ptBi1CqCVPqnA3PctaTrnQFeNbejdq97eSqnPPJlTvMwjPrOR9+vLLQItY4gi/2cDQwA5gHPiMhXInKhiDTPuXSGYRhGQQgaPmMD8DLwH6AjcBIwSUSuSHatiDwlIitFZLovrbWIfCgic9z/rdKUP+fkuONgGIZRlATxOYwWkdeAcTiL/gxS1WOAfsBvAuTxDHB0RNr1wBhV7QGMcfcNwzCMIiFIyO6TgL+p6qf+RFXdIiIXJLtYVT8VkS4RyaOBYe72sziK53cBZMk71nEwDKM+krDnICKlQOdIxeChqum6/zuoqhcI6EcShONw/RtlIlJWXl6eZnaGYRhGKiRUDqpaBVSLSMtcCaDOcKC4DXRVfUxVB6rqwHbt2uVKDF9+UfnnPE/DMPKDfc/BCWJW2gRME5EPgc1eoqr+OoN8V4hIR1VdLiIdARtnZhiGUUQEUQ6vun/Z5E3gPOAO9/8bWb5/1rB2hmHUHVRBbDWaQARZJvRZEWkE9HSTZqlq4JCmIvICjvO5rYgsAW7GUQovug7thcBpqQpuGIaRKtbYC05S5SAiw3BGFC3AWcthDxE5L56TOhJVPTPOoeEBZcwrka0KM1EahlEfCWJWuhcYqaqzAESkJ/ACcEAuBSsUUQ5pa2sYRp3BcUibXSkIQWZIN/QUA4CqzsaZDGcYhmHUUYL0HMpE5Ang3+7+WUBZ7kQqLsysZBh1B/ucgxNEOVwCXAZ4Q1c/Ax7OmUSGYRg5whp7wQmiHC5W1fuA+7wEEbkSuD9nUhUQG+ZmGIYRzOdwXoy087MsR9FgLQujrlJdrVRV1+8CbgNMghO35yAiZwI/A/YSkTd9h5oDa3ItWLFgysKoK1z+wiTemfYjC+4YVWhRjFpAIrPSl8ByoC3OcFaPjcDUXAplGEb2eWfaj4UWoeBYYy84cZWDqi4EForIWcAyVd0GICI7AbvjTIqr81g31DCM+kgQn8OLQLVvvwp4KTfiGEZu2VZRxdyVmwothmEUPUGUQwNV3eHtuNuNcidScWHd0LrFdS9PZcR9n7BhW+DwYEYdwr7n4ARRDuUicoK3IyKjgVW5Eyk3fDq7nC7Xv80PqzYnP9mos3w1fzUA23ZUFVgSwyhuAs1zAJ4TkYdxJhguAc7NqVQ54MMZKwAYNyu1pSOsoVE3sd+1fmI+xOAECdk9DxgsIs3c/VppsG3TzLGErdm8I8mZ4djKUYZh1EeSmpVEpIOIPAm8pKqbRKS3uw5DraLUnfpsdX3tYsayDTz6ybys39cmwtdP7PsPThCfwzPA+8Bu7v5s4KpcCVRsWFkqLMc+8Bl3vDuz0GIYdQT7noMTRDm0VdXQcFZVrcQZzlorMZujAVZJGEYygiiHzSLSBvd7EpHBwPqcSpUDvIB6qXYrrRtqGMFYvGYLn80pL7QYCTEfYnCCKIdrgDeBbiLyBfBP4IqcSpUDxMKt1moy+aif/PwHFq3eEpZmpSH7HHnvOM55cmKhxTCyRFLloKqTgMOBg4GLgH1VtVbFVtq4rYJVm7and7E1NIqCdHXDhm0V3PrWDM58fHx2BTKiqKgq/o+l+CUsHhJFZT1SVT8WkZMjDvUUEcWJzPq5qha9/+HO92by7/GLACsctZV0fzd1A79Ezoi2cmAYiUk0z+Fw4GPg+DjH2wA3AT/JtlDZRjIwIpgDuzhIe2F4Sbhr1DPM5RCcRFFZb3b//zzeOe78h6LH3A21n2x901Y31HOsAAQmSPgMRGQUsC/QxEtT1T+raq2YDJeJbrCWRnGQ7d/B2guGkZggM6QfBU7HGaEkwKlA5xzLlVX8I5Wssq+dZNu8Z8WgfmJm4uAEGcp6sKqeC6xV1T8BQ4CeuRUrd6RaOHJVlCqqqvnIDQZoJCdbSt16DIYRjCBmpW3u/y0ishuwGuiYO5GyTyo+h8g6KFeTZu7/aA4PjZ2bk3sbhhEbsxwEJ4hy+J+I7ALcDUzCqT8fz6lUWSaT0Uq5YvHaLclPMkKk/VFrwl3DMOKQUDmISAkwRlXXAa+IyFtAE1XNSvgMEVkAbMSJ1VSpqgOzcd/ofHw7SWqHSDWSq8rEWjCpka6tOHRdpJKw918vsZ89OAmVg6pWu4v8DHD3twNpTjWOyxGqmtOV5bZWFP08PSMJ6Vbmkdd5yt8ck/UTi60UnCAO6TEicorU4uBEW7ZXpn1trspS7X2bhSFLVqWadKsjDCMhcZWDiNzmbl4EvARsF5ENIrJRRDZkKX8FPhCRb0TkwizdM2YmuTi3LrOjspq/vDWD9Vsqkp+cB9Jt8cW7rj7/zvW59Vx/nzx1EvUcjgZQ1eaqWqKqjVS1hbvfIkv5D1XV/YFjgMtE5LDIE0TkQhEpE5Gy8vLMwwGnWjjqq/nhzSnLeOLzH7jz/eJYaCfbPQfDMBKTSDmUikgrEWkd6y8bmavqUvf/SuA1YFCMcx5T1YGqOrBdu3bZyDYhxWbtqaiq5pr/TmZeeX6X7q6udqrVisrqvOYbj0wbu/kaolwbqMePXq+fPVUSOaR7Ad8Qu75UoGsmGYtIU6BEVTe62yOBP2dyzyAkqxSijha4ME1dsp5Xv13KD6s389qlh+Qt36LrMWXJIZ0svT5Qjx+9+Mp1EZNIOcxQ1QE5zLsD8Jrr524APK+q7+UiI39FsHJjtgdbGfkg46GsRoi0I9wa9YpAgfdygarOB/rlJS/f9udzUhs1a/McioNsTYLL+H5G7cZ+98Ak8jncnzcpjKKj2GaVZ6ob6rOPIRJ7E0YQ4ioHVX0mj3LklFQqhqgZ0vYlFQXpD2WNk16Pq8hcl+liVsTFK1nxEWQSXL0ialRLkRSnbH9vN7w2jQNu/TDj+6gqi9fkPk5U+j2HOPMciuNnLQi5LtP1+d3WJeqFctA424Wk0DOkn5+wiNWbdyQ9L9n7evLzHzj0rrHMWJateZFx5MhW+Az3vRdLOaiLFPO7NcUVnKQOaRF5IEbyeqBMVd/IvkjZx9/NXROgQgy/NtvSxOaNyUsZ3b9T3ON5VyYB85v4wxoAFq3ZTO/dsjU3Mpr0RytF7FvlkCezUnH5rDwSlaPqakUkfHGw+kyQnkMToD8wx/3bD9gduEBE/p5D2bJGbagQPvp+ZcLjxfoMoZZ4ruVLu+cQz6xUpC+0DlAb3+yazTvoesM7PPPlgpzn9d2y9bw6aUnO88mUIENZ9wMOUdUqABF5BPgMGApMy6FsWaM6g4rAu3J7ZRVTl6znwC5ZmRxetJV9quRrVFPaPoe4Dun6S+57Drm9fybEk23Zuq0AvFS2hJ8fsldOZRj1wOcAnLz/7jnNJ1OC9BxaAc18+02B1q6yqBUzyrJRWG99awanPvoVc1duzPxmMUjWki1UTzfou8t5xyFby4Tmq6cTwZYd6UcGrm0UyyCOdDCLUg1BlMNdwGQReVpEngG+Be52Q158lEvhskV1BmXVq7S/X+4ohXUFilKa78os6DeSr8o2bZ9D3Mvy90K/nLuK3n98ny/n5nTZksDU59FKRSxa0ZFUOajqk8DBwOs4wfGGquoTqrpZVa/NtYDZwOzLuaNm9E9xVjieXDWT4bIjTyqMd532ExesyX/mMagLn8Mns8uZvSL1Xnx8H5Tz33oONQQZrfQ/4HngTVXdnHuRsk8m34JXaPyF6tVJS+jcpikHdG6VmWApUKyF1vM55L7nkOZ1xRA+o8hq4+KSJj3Oe2oiAAvuGJWV+3mNiGKLDFBIgpiV7gEOBWaIyMsi8lMRaZJjubJKJg7pWFzz4hROeeTLrN4zmYSFql+S9gjyNG8g7RnSEfuFnOdQXyqeVH+qCfNXs2LDttwIE0GR6emiJohZ6RNVvRQnRPc/gNOAxOMuiwwrEKkTdKx3vqq7jNdz0MT79Ylcm1lTNTGe/th4Rj3wWY6kCUZ9Lg/xCBSVVUR2Ao4HTgf2B57NpVDZJhu/e6EnxuQ7+9++NAWASQvXsqOymkYNErcjitWvE3+Z0OKUNx8U48iyVZtSm5yaK4rVfFsIkvYcRORF4HvgSOAhoJuqXpFrwbJJJhVXtuu8yqo4K6slyadQde+C1Vv4y9sz4h7Pl9JM3yFtRFKs/qGgVGUy/DAOie5YVa3c+No0FqyqlS7XtAnic3gSRyFcrKpjgYNF5OEcy5VVUvkYIv0TqbYwN22v5OwnJrBodXQwuv9+vYjuN74bmnBTW/h+efy4SZmohmlL1gdW3NkeylqkHZ2s0feW9/nbh7Ozdj9VZcnaYAEWc92L7P+nD9K+Nn558BzS0UxZso7nJiziqv9OTjvf2kgQn8P7wH4icpeILABuBYpj1fmApOKQzrR18JP7PuHzuau4+4NZVFUrG7fVzIt4/dtlAExdsi7l+xayuxvk9aVaH3w1bzXHP/Q5T37+Q2AZvl6whnVbUjU/1M+orBu3VXL/mDmxD6bx7E9+/gND7xzLzB+TB1jM9avduD39CYXpNDJCiqOemZziKgcR6SkiN4vITOBBYDEgqnqEqj6YNwmzQGo9h/SvBVi+3hl1USJw0+vT6XvLB1GmpIv/PYlvF68NdL9tFVVpyZErKqqqw54n3XkOi91W6Mwfg41VH3bPOE599CvOdYcwBqUurecwfel6tu6oyvg+6Tz7+PlugMUYPeJInhu/KLgsxVKwPWJoAK9OKKln2iFRz2Emjp/hOFUd6iqEzEtmAUh1KOuZj43POE8BXvnGCa5VGcNGunhNuGkp3gd71hMTwva37Kjkgme+ztoaCql+nD1vepej768ZWZLtz2V7ZVXC3tv0peuj0qoT2KBDk98i3m8mddKkRWvpcv3bfLsomILPRvW3fksFxz34Ode8OBlVZW2K0YXD5ElDoLUp9NhmJDBDZkOWTEgnv9AEuSTn/fGN6Rx0W60IGhGIRMrhZGA5MFZEHheR4RRrHN4kpFoevpq/Ou1rPfyO2mzMvvSu/XjmSsbMXMnt734f+Nou17/N/R/FNjEE8e35T1GFuSs3RZ+TpY/8+lemMeyecXw5L3aoichsvpi7iq43vMOUxbFNdUHk+t+UZfS88d1QL81j0/ZK5pVHP+u4WeWAM0s3CNn4/bdUOKaUSYvW8vQXCxhw64csXJ0fB+mGbRV8szCYIoTUGmNVAc9dvGYLK3M4F6I6gQLwnidZz+GfXy1kxYbE4eYiy1gxk2iZ0NdV9QygFzAWuApoLyKPiMjIfAmYDbLZdf3Hp/MDnecvRpXVcUYopYD3CA1KnDtXVgV05LoX/u0jxzk5r3wTY2fWTFP59/iFfPDdj8xesZGhd37M6k2pxVL80f1gk73iaUvW89e3ZyT9LT6b41S4P3t8QsLzPLxn8daViCSICeXO92ayo6qalREf9rlPTmD4vZ8EkiMI6eiGd6YtD/NbCcLH7jMvitN7TNSTgtQbPBu2phZPLNlv/L8py+hy/dssX781sCI59K6xDLptTMojlR4eO5cHfb6XeFcn8itUZ9Hn8Pc4jbRiJOk8BzdkxvPA8yLSCjgV+B2Q/pCBPJOJbogs6B/OWBHsQl9Bqq6GwbeNCVWkmeC1XoJ+VJEfU2Rld/Ob3wFweM92LFm7lcc/+4E9W+8c6N6fzC4P2aIjpfm/cXM5pFtb+u2xCwCnPPolOyqrufaoXjRqkL0OaLozy/3p8T76SYviDBzIky1k7spNXPrcJI7atwM3H79vTDHml2+ieZOGtGveOJSerDWeazt/srbQi2WLAZi9YhODUgyBf+8HswKfu2VHJXe/H37+EfeMY+atR9OkYWlYeiKd472ubPgc/AMqVLXg86cSkdIyoaq6VlUfU9XhuRIoF2Q7fIbH+Pmruef92IXVX5Aqq6uTKoZkInq3a1Dq9hwCtqCCnueZSB79ZB43vBa+TEe8ysRv//efo6rc9d4sRj/8he8mzr9Yv8WqTdtZmqPhvbXZIe2ZIBavid/CPvLeTxh8+5iwtGSt61SfPFYFtnD1Zm5587uYvZRk35snX6lIyt/mp3OCmfIcOWKn+/0n42atZNm6rQnfmXcsG/W4/3GLzRcfSb1bQzpVbntnJvNj2J0BznhsPA+NnRva/9oXddNfjoLaVSPxF9jI1ot3TFUpSxDt068cXvx6cVpyxCNMIfjSt1dGNx29yrgixiTAgX/5iEPu+DhgnuH7yb5XL99tFdVJTWb5UBjD7x3HEfeMS/k6fwUVWUlFVmzJKtxUi6NfAXhblz43iWe+XMC703+k503vhg0i8PKfvHhdzKHHnrwlJblruPnliMTfcDv/6a8Z/fAXCec5eGbhbPQc/GXML901L06my/VvZ3z/bBIofEZtJ5MJlR99v4JFazbTrHHiV6WqnProV6H9Hb5KMJ0ZncvXbw2tGOWnNMLn8P53P3LxvyfFvU+Vzzdx3StTU5YjEfG+6y3ucEtP1jB5sjS7dcGqzRxz/2cc0r1NwvO+mlczuOCk/6sJlhhL9niiRXb/vXH26QTSm1ee3Im8raKK/n/+gAuGOiuSKTVK3p9jvDfpf8drNu/g87mrOKHfbinL6hGrkvXK3xuTl7Kjspo3Ji8LHatwj5348Bf02rU5M3/cyO+P6cVFh3cLu1+pSFITVCTJdIkz1FrZqVFpXN9LRVU1qsqrk5YCUL5xe8I6wnueoLohkbnIL3+1KlQTJksxUT96Dhm2TqqqNVThBT3+xuRloVbCkNuTt4on+YZFzl25iSG3f8wa33DFyEV1vN7IwiTjzrPiDHf/Ry5Wo3F2vFXPnPcSPmEpmZkryE+1eXslr0xawtaKqqRrb//l7ZpRXYvWbAmNJvFn41XyVXHeVaTIT3+xIGz/oxkrOP0fX6VUzhL19pas3cK2imoeHjvPkVXV13OIXen4W+j+x7joX2X8+oVvWbmxxqyZag8p1m/mlb9YrelPZpeH5PXmsdzj8xWEzEolqZuVknHukxPZ54/vheUTSWWV8uaUZfzGjR8GUOG+tFgNGq+3G/nuf//qVN6YHF2pJ2oA+Y+oOj3JvrcUp/u2niiHzK4vLZGEk7UqqqpZF2NER0XAEUVA2BC4EfdFj5AJKQW34FVVK/+bsizMlBWLoD6HRHy7aB1V1crPfHMuulz/Nvf5wjP4Kxz/RK3RD/n8DsDqiABrL38TvtB6EHlP+8dX7IhhukqF2Ss2hkaxeN98vLyTVfqXPjeJCT+sYVtFuEzV1crF//om5m/0U18vM5LI+0BNS33puq18Nid6mO/vX63xE/nNmF7jwa8wjr3/s6TzJMoWrGHGsg0sjWOP91rlpa4PLFLhRP4+/lfofRYlJcL8VbFNtvH4blniORT+YehxlUN1NeUba763EoHXv3Uq+QYl0VWi9+4j9cYLExdz5X+iQ2rEKkdjvl/BhPmrw30OKAtWb2Grb3hrMU0KrBfKIdPWyewViQvw7BUbA80czQZegd+8vZIrXvg2quUc+dFnQzkAPPhx4iF4OyqrWbxmCxc883Vo5TOAORFzIk76vy8iLw1RXa2sDzBs8rtlG0KmnRgNPcAZm//slwvi3uO6l6dy74ezmbZkPdvdyjje8ODP5qxKOKfAGyQQOYZ99eYdvPfdj0yIM8w2HpE+mx2V1UnNcf7Kzt9b9Mq+3wm7atOOmC1eD1Xlp49+xbEPfMYhd3wclvcr3yzhy7mrko793xyjx9jl+reZ+MOaUAVYIsIpj0Qrycqqal75ZglbdlTy3bL1DL93XFxZq6qVh8fOZVOMkBrxyv7V/50S1oCpVkJmMe+39OOZiMfNKo8zx0f53KewY+V7wbNlnP7Y+HCfQwzxUmlQ5pp64XMY2qNt0hZHJpzwUPwKLxXemLw0ZksEolu38Xoyv/xnGSf0242zDtqTZ79aSOMkobaDkmx89h/e+A5whsWOmRmusL5esCZUwWzZUUWX69/myF7to+6Ryizc5yc4IRpEJPSVjZ21kutenso5gzvz368XBxoBdfxDNX6dnz76JTNvPYZ55ZvYuK2msvn5M18D8PT5B4a2/XimiAG3fshzvzyI+eWb6NOpJR1ahK+JFVmPrt9aQWVVNW2aNUZVWbh6C13aNo2q6NZvrQiT08PfytxW6VR2/xq/kD+8Pj2U7pk7b3snfNLkLf+bwRG92tO4QSm7tqyRc+yslcyI+FaO8c2I/2DGCj6YsYI9Wu8EOHMWAH5cHz4a79LnYvvB/vv14lBZOPHh2N/Nz56YwMQf1jBudjmTF6+Niibgp9sN7wDOiDf/cN/1WyrCelN+pi1dz7QYM+3BaQic//REHj37AOaXb2bRmi1hjYZznpzAV78fHvbu353+Y9jzbq+oiu+jTDJaqbK6mkZF0mYvqHIQkaOB+4FS4AlVvSMX+Vx3VC/+8UmwyWuFJJ5iANi0rTLQaIZvFq7lm4VreX7CImalscZuLnh10pIou/3HM6N9Bb97Jfxjfu3bJVHnROJVNJ/OKeevbgV4X5rRSLdVVPPPrxbwxze+i3k8UjG8WLaYqurqMMenP9zJwz/bP+z8yMqgnxtd9M5T+vKv8QuZvnQDz/z8QDZvD++BxPN3+SfBTV+6gcVrtoQpBv+1sWY4H373uND2yft34rAe7QJHHo2ssP8TMRIu3qTEtVt2JOwFrd9SEbp26pJ1gR3WT3+xgJW+3lO/P6dvxx83q5xef3gvtP+nE2qUzvL129jr929zzuDOobTIUDYbt1XSppkz72TFhm3c90FNeXzd12OLNWrtbx/O5sZRvfY2j54AABzKSURBVAFnwur0pes5tm9HGpbmX2FIoWxcIlIKzAZ+AiwBvgbOVNW4iwcMHDhQy8rK0sqv2IaJGfWPfnvsEjfMh1H3OLhbG770jZYLyjF9dqV7+2Y8+HHNMPnfHd2L0wbuHlI6qSIi36jqwFSuKWTPYRAwV1XnA4jIf4DRQPyVZQyjFmOKoX6RjmIAx0wVyZ3vzaRXx+YcsXe0OTZXFNK41QknDLjHEjctDBG5UETKRKSsvDz47Mig/P30/mH7I/bpEPfcH24/lqtG9Mg4z6Hd2/KH43rz8W8O595T+/H0+QfStV3TmOce02fXsP1euzbPOP9ipHv7Zmld99uRPRMev+fUfpTdNCLK9zI8hs8DoHmT6PZS66aNwvwFfTq14PpjevH4uQM5/+AuUefv1LCUPp1acN3Re7NTw1IO2iu1EBHxaNusMZcM68Yp+++e8LwR+7TnzcsPiXns5uN7R6X945wDQtuj+nakddNGMa/9y4l9eOFXg8PSTuxfM39iUJfW7LtbC248dh8O7NKKMwftGTo2sHMrrjiye9i1vXZtzi/duRyJOLhbzVyWswfvyW9H9uT3x/RiaPe2UedeEOd+j51zAK9fFvudJOOmUftw06h9eODMAaG0iTcO55Jh3aLOve2kvindu2Gp0LRRTSiPePKfOWhPDujcKqV7Z0rRO6RV9THgMXDMStm67/zbjqWyWmnUoIQTB3Tilje/45kvF5BoPrWI8IuhewUOnnX5Ed3DZlADTL1lJM0aNaDEdWJ2bedUike4ldXlz0/iranLQ+d3a1dTaTZqUMJ7Vx2WFRPZGQfuEWUnTpUXfjWYMx93wpv/45wDuOhf3wS67j8XDuaMiLDofz+9P8c96Dhd+3ZqGXIYfvX7IxPOE7nwsG7c80FsH8P9Z/RndH+nvfHZdUcw8u+fsm6LMxrq8XMH0tV1ZvoZ85vDGfRXJxxF744tmLF8AycN6MT+e7bisucn8b/Lh9J395ah83/SuwMvTFzE9spqhu3djnGzynn4rAEc2ctpZFw6zKkQl6zdQseWO3HIHR+nHWOr7KYRoe1XJsX2x/xw+7GISEy7/uPnDuQnvTvwzrTlfL3A8UF0bduUo/bdlY9/czg/rNrM8H2c5/E7c08e0IkbRu1DW9ek0aZpI1a7o+Ia+GzhL148JLT9q8O6AnDDsb0o37g9VM79ppLddtmJm47rzSezy6NGtfl5/leDOfj2MSxbv41zBndhb7eBdNHh3Tjx4S9otXNDxrqRcs8b0iXmAlIj9901Ki0RLZo0YMO2Snp2aMYvD3WepbKqml+7x9s3b8J1R+3N8nVbOf3APdl71+bsqKxm15ZN+NlBe/Le9OV0b9+MEfd9Gnbf84Z05uNZK1m8Zmvo95i7ciMj7vuUkb078IfjerNuSwWvTFrCnaf0Dfnhbj85NaWTDQrZc1gK7OHb391NywslJUIjX2vSG5KXzAXToklD5vz1mITnfHj1YUy8cTi/PWrvqGPNG9cohlj07OAU/JP370S3dk352UE1ra9GMZxSz//qII5OUvDvO60fPz0gvLV5xyn7xT0/aEu3R4caxXVIjFZcJOcO6cwFQ/dicNfoWc3+3+J/VwwNbXdsuRPvXnkoH//m8Jj3LBHijgzxFANA+xZN+OJ3R9ZcVyJRvZXXLj2Yljs1DO2HonECo/bryJSbR4YpBo+JN4xg4g3DQ7OXYzlRd2+1M6UlEjeUyoI7RsVMTxVvolasIuYlPXzW/tw6el+eOn8gL1zo9AS6tmvG8Di95p0alYYUA4SHQElQlAFo3qRhSDEA7Ltbiyh5guDpusge4OuXHcLTPx/E7q124tqj9qZZjJ6fnw4twm32/t6Nn14dW/DyxUPCekoNSktoVFrClcMd64GI8PczBjCkWxtaN20UNurr6D4d6d4+vJf/6NkH8KfRfUINPi/Ccvf2zfn76f25+9R+ALRt7vTcOrbcKeGz5JpCKoevgR4ispeINALOAN4slDBeIfc+3UF7teaz644IHfeHaWhYWkKnXaJ/uBuP3Yfnf3kQPTo0p31zp6BEdtGTRWH0jnZs2YQxvxnGbr58Yo3BbrlTw6TzOLq1axbYHHVwtzZhZoZ7Tu0X6j4/9LMBYef6x7jHe6pWO9dUtn8e3Yc/HOeYNd698lD+elIfAM4/uEvMmake+3RsQdd2zbjosK4c2KVVWEVaWiLs3irYR9S0cYMwc9JH19QonF67NmfAnq1o3KA0Stl6ytyvOPy03Lkh7Vs0CRQxNzKkw19P6sODrrmiYanQpGEJT543kOd+eRAfXn1Y6Lwnzk3JlxiznHlJ7Zs34ZwhXTiyV4eo4bYQ/VsmKrKJfrdYvOVT/BLxzXk8+4tB7NwoMmqqc1ajOEOzP//dkVx2RHdaN23EixcNiXkOECp/4PTEbh1dMxIpUlEM7NI6ygE8+6/HcPVPEpsy4+E9r3+GuMeJAzqFytfVI3rywJkDOLRH8gZXLimYWUlVK0XkcuB9nKGsT6lq7DGEWeCgvVonnIzk/VCh0VsKe/hCVz953oFh57931aFMX7ohZFYBZ20Drzvt8eHVh7Fq0w6O+nt49zIekWEywo7FOL9xg9KkwRBKRMIqi0S2y3/+YhANSkvYd7cWfLdsA712bc5x+3WkW7tmjOrbkcd3n8+UJevd+0bLHY/HfAoHnAp/n44tOOsgZ0jgDwHW7v79sftEpYlISsP8njw//Hcc1bcjb09bHvah7uRWTP6eQxC8d5zo94icIOU9P8DUm48Ky9/PiN7hrfrzD+7imkGTc2iPtnw2Z1Xg2ECR50XGkPI/QYkIvx3Zkw3bgq3rHK60wu87qm9HLhnWjT6dWnLWQXvy+Gc15iHvtTUIoIx6+3onUfm7efbfY5ew3hDAX0/swwsTgy9xmi5ezyveszRpWJpRLKxsUdDZFqr6jqr2VNVuqvrXXOb11PkHMsY1TewXwzRwzpDO9OzQjIvd4GADOu8SdjyyhdS8ScOoLurWGKs8tWnWOGQjDUKQ+O7nDampUJo0LGG/TtHPE37P2N3/d688lFtP7BPaLy2R0HN6BbeiqpomDUv56QG7IyK8cbm/5efvOdRsP3p2uCIAGLBnYmdapCP4yF7t4zpGI/Eq0yYNUy/OZ7vj1WO1gGtWcAtWqx7fryOQeNBAol7FTo1KYyqGWNxywr706RReCV49InaLNtXniKRzm/jre5SIcPmRPbghhuJOhieOJ9UVw7vTxy3LpRFhLLzfNpFJ1iORAgnlGeOUIPfOBrF6DsVI0Tuks0XTxg3o1q4ZU24eGXPW8O6tduaDqx3l8f5Vh9EtYvRQacxuekSLKotTRhLd6k+j+/DsVwsBp+dw6RHdObh7m5ihCMDtOcRI91rvUxev47Ce7Tje11rxCm6iCUv+x/dvH90n2geS7DuIbMU9FdHCT4R368N7tuP97wIuxuTiPWfMCLKhMA/B7jW6fydG9e0Y5qSNJNkqbZH07NCMBatih2aJ/FUvHtY15nk156fO8F7t+cUhESNofI+QSQUXeaXfTOlV8N4Ip2d/MYi3piynTYAGQ0LlECfvfOL1HmOZiYuJeqMcPOLZjf3EaunHalVEJ2WuHbzvw9/CfPTs/eOG5W7csITSEuGAzvGdyKUlkrDV6DnCwu7bwGnBJorNFCS+fc8OzZnww5qEFWa2yEQ5x1L+hFrcwe+T7Dm9OD0vXjQkkK/krSsOjdvbGNqjbVgYiGS/Rzo9h0N7tE3Yos5kjYMgvgxP5m7tmnFlwGHkiRSWl2c21mZIF6/BFSvIXyQv/GowP27IzUJYyah3yiGbRLbcshAdOzSSoYdvpEOiOQBNGiQ3Q0QuEBPks7j3tH7845N5HJhgGccgPofHzhnIlCXrAinlTElHN9QsPBPDrOT+T2fdhnh4gdUG7LlLIF9JPAcswG9H7s0j4+aF9uNJGWm+SUYqzxs5Ci4VEuXjVfCp9rQgXAn+4bje9AszI3tKpyalRDJb8yUono6/99R+PPjx3IS+EY8h3RKvV5JLTDkk4aWLh/DJrNiT7yIrxGysJHbUvrvyv8uHhtmTE7X4Gsbomr55+SFhwQCFYIvE+Nltl5340+g+Cc8JH60ULse1R+1Ns8YNaLlzQw7r2S5AjoXBv/BMvGPZNA2/eunBlC1Yk5VYOZEt5Fit4bQayL5rYpUVL+3L648MG02XcjYJZMv0lbdt1phVm7Zz3H4dw0ZklYQUZU0O3/5xZNYWoQpCjw7NwybUFSumHJJwYJfWcVvPUcohS+Urciy9l02s28dSHH0jHNQipFlLJCaezwHgsiPCZ8MG4a5T9mPDtuQhuyPJ5LUnsv+GRitl8d3tv2cr9k/inE+XSDHfu+pQWu3ciN+8OCX2BRmSrr/h6hE9+dtHswMVyUwbXFEjr2Jkmo9ebSxZih1TDhkQ2VI7/5Aucc/974WDAw3XDJIPOJN/YkXahDhj3ONsZ0KQeQ6pcNqBeyQ/KQHpKGfPbBHrHWsaPodCEvm799q1RcTxNO4ZI82/HkM6eKFiEpmVcvXOJWrDiEdxBA6vpUQW4D1bxx/yd1DXNpwRZzZmMryP0J9d/z12iRuHJRLV3DjgCunU83PHyX0Z1bcjA/bcJfnJEbRr7oySijW8OaQc6khNku0AzBkPxXQv9xpV/hnGmRP7YWsc0lnMqo5iyiEDIivHXFWW8WaSRtK1bezgfRAe6iJbhDukC/e1dW3XjIfP2j80+ueYPrsGDrLWp1NL3rjsEK6KMUfAG1lUgFD6WSXVnybo6TFHeAWgxtHvcNZBnVlwxyhaNIk276Sr0LwQLTs1DB+wUeOcN+2QDDMrZUC0PTM/+cTjlUsOZslaZ9ibFzTOu/7ALq2559R+/Pal7NmfJctmpVTYZeeGoSB6Hif0243mTRowrGf7lCY09dsjvMfhXdmxZRPKN25POEy4NpBJj+HkGKORvNsFGIkZR57kvpwgs80Tcc+p/bhqRA+aRygciTFaKRb+sC/1FVMOGRDZ+shVzyGWWSkWrZo2opU7SeitK4Yy/L5PwvwcicxemZLvjsOYaw5nbYRyEJFQNNRscPbgzuy7Wwv23S3xDPTaQvDwGc6JJ+/fKWFrvljMirFo0rA0KvAdEPqIkol+1ynRc38ypUDrqqVNLe8wF5Z82S2DmpX8lJRIXPly8U3n26zUplnjtNeACEqpSNErhtH9cxiDJ06By7Tcd2njmD8H5nl9AvDPkE78EC2t52A9h0yIrBBzVT+m20Jr3bQR88o3R8WpMYJRGxp6w/fpwBuTlwU6N2jLNVlpe/HiIbw5eVlU5NSg9NtjFz65dlignmyuWtvxPql3fn1ozAWf6iP2FjIgsgWVM4d0mtc9fNb+vP/dCvZK4Kg2ajcn9NuNX7/wbcJzsl0s992tZcY9qs5tEpfJXDW0Qs7wOBkEmbVcX7AmZQZEdk1zZVhJ12TTvnkTzhncOfmJRkyK16KeGum2vmtDzyllQsOTjWSYcsgAiXh7uXNIZ+c+Wts8YgWmrr2toMXTC9G9bxG0orMRkibW/YrYl140mFkpAyLLV+6GshZvSW7SsIRtFc58gAfOHMDCNGeBG8XDwC6teffKQwOvHpgLQr3yLGtozXPP4ezBe/Lv8blfQCgXmHLIgMieQq4q8eJVDY4DzwvjUQyrVxnxSaXjuE/HwvcackGmCx+lyl9O7MvKDdv5YEZq64wUA6YcMqCIG/QJyXR26MsXD6HMVQhd2zULW0DeKD5qaznNBZGzs434mHLIgGKeBJRLBnZpzcAE6zwYxUVtdDWlM7cnCDWzs7N84zqIOaQNI5I6WnHUpgoxV6LWKJta9DIKhCmHDKhNH5thGLUvDHshMeVQC2jc0PmZBu+V2ZKBtdC6UBA6t3YmaLVtlnwx+9pEbTQvZX/4tWtWyvJdk+dY+zCfQwY0blDKtUftzd3vz8ppPjs3asBH1xzG7q2yFDjPWk0JueyIbuy3e0uG7d2+0KLUW0I+hyzXrNW1IGhgsWA9hwxJZznMdOjevjlNGqYXyyaK2tqUyRMNSks4olftUQyvXDKE207qm/Q8qw8LY1aqra/deg6GUcs5oHPrWr/mRL4oxAxpb4W72hbQr3ZJa2REp12cldIO69m2wJIYRmK8uTjZH8oafv98cMOx+zBgz104uFtmPsN8Y8qhHrFH652ZeMNw2jZrXGhRjAJQmxzSuY7Kmk9bT5OGpZw0IHpFvWLHlEM9o32LbC7ibhi1C2/0kzmkk1MQh7SI3CIiS0Vksvt3bCHkMIz6RG2sD7Pd28l34L3aTCF7Dn9T1XsKmL9hGEXKId0dv9hR+2ZvTXCwkN2pYGalLPDWFUOZsXxDocUwjDrDPh1bsOCOUVm/r/UcglPIeQ6Xi8hUEXlKROKuNC4iF4pImYiUlZeX51O+wPTp1JLTBu5RaDEMIyaXDutGiUDfTpkt7VmXKOY1UoqFnCkHEflIRKbH+BsNPAJ0A/oDy4F7491HVR9T1YGqOrBdu3a5Etcw6iwHd2/L/NtHscvOdSscSDqUussqNm5g83+TkTOzkqqOCHKeiDwOvJUrOQzDMDyO7duR75dv5JJh3QotStFTEJ+DiHRU1eXu7knA9ELIYRhG/aJhaQnXH9Or0GLUCgrlkL5LRPrjzElZAFxUIDkMwzCMGBREOajqOYXI1zAMwwiGeWUMwzCMKEw5GIZhGFGYcjAMwzCiMOVgGIZhRGHKwTAMw4jClINhGIYRhWgtWgFERMqBhWle3hZYlUVx8oHJnB9qm8y1TV4wmfNFPJk7q2pK8YdqlXLIBBEpU9WBhZYjFUzm/FDbZK5t8oLJnC+yKbOZlQzDMIwoTDkYhmEYUdQn5fBYoQVIA5M5P9Q2mWubvGAy54usyVxvfA6GYRhGcOpTz8EwDMMIiCkHwzAMI4p6oRxE5GgRmSUic0Xk+kLLAyAie4jIWBGZISLficiVbvotIrJURCa7f8f6rvm9+wyzROSoAsm9QESmubKVuWmtReRDEZnj/m/lpouIPODKPFVE9i+AvHv73uVkEdkgIlcV23t211JfKSLTfWkpv1cROc89f46InFcAme8WkZmuXK+JyC5uehcR2ep734/6rjnALVNz3efKyQLPceRNuRzksz6JI/N/ffIuEJHJbnp237Gq1uk/oBSYB3QFGgFTgN5FIFdHYH93uzkwG+gN3AL8Nsb5vV3ZGwN7uc9UWgC5FwBtI9LuAq53t68H7nS3jwXeBQQYDEwogrLwI9C52N4zcBiwPzA93fcKtAbmu/9budut8izzSKCBu32nT+Yu/vMi7jPRfQ5xn+uYPMqbUjnId30SS+aI4/cCf8zFO64PPYdBwFxVna+qO4D/AKMLLBOqulxVJ7nbG4HvgU4JLhkN/EdVt6vqD8BcnGcrBkYDz7rbzwIn+tL/qQ7jgV1EpGMhBHQZDsxT1USz7AvynlX1U2BNDFlSea9HAR+q6hpVXQt8CBydT5lV9QNVrXR3xwO7J7qHK3cLVR2vTi32T2qeM+fyJiBeOchrfZJIZrf1fxrwQqJ7pPuO64Ny6AQs9u0vIXElnHdEpAswAJjgJl3udsuf8kwJFM9zKPCBiHwjIhe6aR20Zk3wH4EO7naxyOxxBuEfUjG/Z0j9vRaT7AC/wGmleuwlIt+KyCcicqib1glHTo9CyJxKOSimd3wosEJV5/jSsvaO64NyKGpEpBnwCnCVqm4AHgG6Af2B5TjdxmJiqKruDxwDXCYih/kPui2TohsfLSKNgBOAl9ykYn/PYRTre42HiNwIVALPuUnLgT1VdQBwDfC8iLQolHw+alU5iOBMwhs7WX3H9UE5LAX28O3v7qYVHBFpiKMYnlPVVwFUdYWqVqlqNfA4NSaNongOVV3q/l8JvIYj3wrPXOT+X+meXhQyuxwDTFLVFVD879kl1fdaFLKLyPnAccBZrlLDNc+sdre/wbHb93Tl85ue8ipzGuWgWN5xA+Bk4L9eWrbfcX1QDl8DPURkL7f1eAbwZoFl8uyFTwLfq+p9vnS/Tf4kwBul8CZwhog0FpG9gB44Tqa8ISJNRaS5t43jfJzuyuaNjDkPeMMn87nu6JrBwHqfmSTfhLWyivk9+0j1vb4PjBSRVq55ZKSbljdE5GjgOuAEVd3iS28nIqXudlec9zrflXuDiAx2v4lzqXnOfMibajkolvpkBDBTVUPmoqy/41x52YvpD2d0x2wcTXpjoeVxZRqKYyaYCkx2/44F/gVMc9PfBDr6rrnRfYZZ5GhERxKZu+KMzpgCfOe9S6ANMAaYA3wEtHbTBXjYlXkaMLBA77opsBpo6UsrqveMo7iWAxU4NuEL0nmvOHb+ue7fzwsg81wcm7xXph91zz3FLTOTgUnA8b77DMSplOcBD+FGbsiTvCmXg3zWJ7FkdtOfAS6OODer79jCZxiGYRhR1AezkmEYhpEiphwMwzCMKEw5GIZhGFGYcjAMwzCiMOVgGIZhRGHKwSg4IqIicq9v/7cickuW7v2MiPw0G/dKks+pIvK9iIyNSI+MlDlZRM5Ncq8/i8iILMi0KdN7GPWXBoUWwDCA7cDJInK7qq4qtDAeItJAa4LIJeMC4Feq+nmMY/NUtX/QfFX1j0HPNYxcYT0HoxioxFn79urIA5Etf681LCLD3OBib4jIfBG5Q0TOEpGJbtz6br7bjBCRMhGZLSLHudeXirP2wNdu0LWLfPf9TETeBGbEkOdM9/7TReRON+2POJManxSRu4M+tIhsEpG/ibOexxgRaRf5zO5zzXBlvMdN6yIiH7tpY0RkTzd9LxH5ypXvLxF5Xet71j+5aU1F5G0RmeI+z+lBZTfqPqYcjGLhYeAsEWmZwjX9gIuBfYBzgJ6qOgh4ArjCd14XnJg5o4BHRaQJTkt/vaoeCBwI/MoNkwBO/PwrVbWnPzMR2Q1njYIjcQK1HSgiJ6rqn4EynFhC18aQs1uEWcmLltkUKFPVfYFPgJsj8muDE9JhX1XdD/Aq/AeBZ92054AH3PT7gUdUtS/OrFrvPiNxQikMcuU+QJyAiUcDy1S1n6r2Ad6LIbtRTzHlYBQF6kSk/Sfw6xQu+1qddTG244QF+MBNn4ajEDxeVNVqdUIbzwd64cQdOlecVbQm4ISq6OGeP1GdGP6RHAiMU9Vy19z0HM5iLMmYp6r9fX+fuenV1ARO+zdO78PPemAbTo/kZMCLVTQEeN7d/pfvukOoiR/1L999Rrp/3+KEVejlPus04CcicqeIHKqq6wM8i1FPMJ+DUUz8HafyetqXVonbiBGREpzVtzy2+7arffvVhJftyBgxihOf6ApVDQtMJyLDgM3piZ8xYXKqaqWIDMJZpOinwOU4vZbA93AR4HZV/UfUAWeJ0WOBv4jIGLcXZBjWczCKB1VdA7yIY/LxWAAc4G6fADRM49anikiJ64foihNI7X3gEnHCpiMiPcWJNJuIicDhItLWjX55Jo45KF1KcCp9gJ8BYc5scdb6aKmq7+D4Y/q5h77EiQYKcBbg9US+iEj3eB/4hXs/RKSTiLR3zWRbVPXfwN045jTDAKznYBQf9+K0kD0eB94QkSk4NvF0WvWLcCr2FjiRLLeJyBM4pqdJbhjjcpIsnaiqy8VZUH4sTmv8bVUNEl66m2u+8nhKVR/AeZZBInITzloNkQ7h5jjP3sTN7xo3/QrgaRG51pX75276lTgLvPwOX0hmVf1ARPYBvnIelU3A2UB34G4RqcaJ+nlJgGcx6gkWldUwCoSIbFLVZoWWwzBiYWYlwzAMIwrrORiGYRhRWM/BMAzDiMKUg2EYhhGFKQfDMAwjClMOhmEYRhSmHAzDMIwo/h8F+ljAjKIrkwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot losses\n",
        "fig = plt.figure()\n",
        "all_losses = np.concatenate([v for _, v in losses.items()])\n",
        "plt.plot(np.arange(len(all_losses)), all_losses) \n",
        "plt.xlabel('Number of Episodes')\n",
        "plt.ylabel('Avg Trajectory Loss')\n",
        "\n"
      ],
      "metadata": {
        "id": "9LF9uTq5yY31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "a230b6be-99a4-4843-8113-9c6988f595d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Avg Trajectory Loss')"
            ]
          },
          "metadata": {},
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save weights\n",
        "dt_string = datetime.now().strftime(\"%d-%m-%Y_%H%M%S\")\n",
        "model.save_weights(\"checkpoints/derek-{0}.h5\".format(dt_string))"
      ],
      "metadata": {
        "id": "-ZTaifbPkHeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1SsVnMeg8Up"
      },
      "outputs": [],
      "source": [
        "%debug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbUe72jpsol6"
      },
      "outputs": [],
      "source": [
        "# UNTESTED; uncomfirmed if works\n",
        "\n",
        "def move2Frame(model: ADNET, img: np.array, src_frame: int, src_bbox: np.array, \n",
        "               target_frame: int, target_bbox: np.array) -> np.array:\n",
        "  \n",
        "  bbox = src_bbox\n",
        "  actions = []\n",
        "  img = getFrame(dataset, target_frame) \n",
        "  target_bbox = gt[i]\n",
        "  for t in range(model.K):\n",
        "    patch = getPatch(img, bbox)\n",
        "    probs, conf_score = model(patch)\n",
        "    a_prob = tf.reshape(probs, (model.ACTION_DIM)) \n",
        "    a, bbox = selectMaxAction(np.array(img), bbox, a_prob)\n",
        "\n",
        "    actions.append(a)\n",
        "    model.updateActionHistory(a)\n",
        "    if isStop(a):\n",
        "        break  \n",
        "  \n",
        "  target_iou = calculate_IOU(bbox, target_bbox)   \n",
        "  return bbox, target_iou, actions\n",
        "\n",
        "\n",
        "def predict(model: ADNET, d: str, start_frame: int, end_frame: int):\n",
        "  gt = get_ground_truths(\"%s/groundtruth_rect.txt\" % d)\n",
        "  frames = sorted(glob.glob(os.path.join('%s/img' % d, '*.jpg'))) \n",
        "\n",
        "  ious = []\n",
        "  bbox = gt[start_frame]\n",
        "  model.clearActionHistory()\n",
        "  for i in range(start_frame+1, end_frame+1):\n",
        "    img = getFrame(dataset, i) \n",
        "    bbox, iou, actions = move2Frame(model, img, d)\n",
        "    ious.append(iou)\n",
        "  return model, ious\n",
        "\n",
        "\n",
        "def predict(model: ADNET, d: str):\n",
        "  gt = get_ground_truths(\"%s/groundtruth_rect.txt\" % d)\n",
        "  frames = sorted(glob.glob(os.path.join('%s/img' % d, '*.jpg'))) \n",
        "  return predict(model, d, 0, len(frames)-1)\n",
        "\n",
        "\n",
        "\n",
        "rand_idx = 11\n",
        "d = ALL_DATASETS_LIST[rand_idx] \n",
        "model, ious = predict(adnet_model, d)\n",
        "\n",
        "fig = plt.figure()\n",
        "for e in losses:\n",
        "  plt.plot(np.arange(len(ious)), ious) \n",
        "plt.xlabel('Frame')\n",
        "plt.ylabel('IOU')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMtzZ9r5nu8A"
      },
      "source": [
        "### Observations\n",
        "\n",
        "* The paper sums all sequence rewards. However, we found this to produce too much variance. We reduce_mean instead to address this. If we had"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmQvTRA7j9ET"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkTBunYkHcUQ"
      },
      "outputs": [],
      "source": [
        "print(erroneous_datasets)\n",
        "\n",
        "# !ls adnet_datasets/OTB/Diving/img/\n",
        "# ! wc -l adnet_datasets/OTB/Diving/groundtruth_rect.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0g-v8GupB9y"
      },
      "outputs": [],
      "source": [
        "def predict(model: tf.keras.Model,img: np.array,bbox: np.array) -> np.array:\n",
        "  ACTION_DIM=11\n",
        "  K=10\n",
        "  \n",
        "  action_hist = np.zeros((ACTION_DIM * K, 1))\n",
        "  seen_bboxes = set()\n",
        "  for t in range(K):\n",
        "    #model.setActionHistory(action_hist.reshape((1, 1, 1, ACTION_DIM * K)))\n",
        "    model.setActionHistory(action_hist.reshape((1,ACTION_DIM * K))) ### For ADNET_v2\n",
        "    patch = tf.image.resize(img[bbox[1]:(bbox[1] + bbox[3]), \n",
        "                                bbox[0]:(bbox[0] + bbox[2])], [112, 112])\n",
        "    patch = tf.reshape(patch, (1, 112, 112, 3))\n",
        "    a_prob = tf.reshape(model(patch)[0], (ACTION_DIM)) \n",
        "    a, bbox = selectAction(np.array(img), bbox, a_prob)\n",
        "    if isStop(a) or tuple(bbox) in seen_bboxes:\n",
        "      break\n",
        "\n",
        "    action_hist[t * ACTION_DIM + a] = 1 \n",
        "    seen_bboxes.add(tuple(bbox))\n",
        "  return bbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03dOCNAKz6sg"
      },
      "outputs": [],
      "source": [
        "def plotNpImageBBoxGT(img: np.array, bbox: np.array,gbbox: np.array) -> np.array:\n",
        "  '''\n",
        "  Plots the bounding box on an image and returns the bounding box\n",
        "  '''\n",
        "  fig, ax = plt.subplots()\n",
        "  x_pre,y_pre, w_pre, h_pre = bbox\n",
        "  x_gr,y_gr, w_gr, h_gr = gbbox\n",
        "  predicted_rect = patches.Rectangle((x_pre, y_pre), w_pre, h_pre, linewidth=1, edgecolor='r', facecolor='none')\n",
        "  gt_rect = patches.Rectangle((x_gr, y_gr), w_gr, h_gr, linewidth=1, edgecolor='b', facecolor='none')\n",
        "  ax.add_patch(predicted_rect)\n",
        "  ax.add_patch(gt_rect)\n",
        "  plt.imshow(img)\n",
        "  return bbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAvwFremUHsQ"
      },
      "outputs": [],
      "source": [
        "ALL_DATASETS_LIST = glob.glob(\"adnet_datasets/OTB/*\")\n",
        "j = random.randint(0, len(ALL_DATASETS_LIST)) \n",
        "dataset = ALL_DATASETS_LIST[j] \n",
        "frames = sorted(glob.glob(os.path.join('%s/img' % dataset, '*.jpg')))\n",
        "gt = get_ground_truths(\"%s/groundtruth_rect.txt\" % dataset)\n",
        "\n",
        "predicted_bbox = gt[0]\n",
        "for i, frame in enumerate(frames[1:]):\n",
        "  img = cv2.imread(frame)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  print(img.shape)\n",
        "  predicted_bbox=predict(model,img,predicted_bbox)\n",
        "  print(predicted_bbox)\n",
        "  gtbbox=gt[i]\n",
        "  plotNpImageBBoxGT(img,predicted_bbox,gtbbox)\n",
        "  #print(gtbbox)\n",
        "  #print(predicted_bbox)\n",
        "  break\n",
        "  #bbox = \n",
        "  #print(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_metrics( model: tf.keras.Model, model2:tf.keras.Model  ):\n",
        "    all_boxes = []\n",
        "    all_gt = []\n",
        "    time_perframe_for_each_video =[]\n",
        "    test_list = glob.glob(\"adnet_datasets/Test/*\")\n",
        "    d = ALL_DATASETS_LIST[rand_idx] \n",
        "    gt = get_ground_truths(\"%s/groundtruth_rect.txt\" % d)\n",
        "  \n",
        "    for  i in range(len(test_list)):  # start with 1\n",
        "      dataset = test_list[i]\n",
        "      print(dataset)\n",
        "      #frames = sorted(glob.glob(os.path.join('%s/img' % dataset, '*.jpg')))\n",
        "      gt = get_ground_truths(\"%s/groundtruth_rect.txt\" % dataset)     \n",
        "      all_gt.append(gt)\n",
        "      frames = sorted(glob.glob(os.path.join('%s/img' % dataset, '*.jpg')))\n",
        "      print(frames)\n",
        "      number_of_frames = len(frames)\n",
        "      #start_frame = random.randint(0, number_of_frames) maybe to test robustnes do not start always with first frame TRE\n",
        "      start_frame = 0\n",
        "      boxes_m1 =[]\n",
        "      boxes_m2 = []\n",
        "      time_perframe = []\n",
        "      predicted_box = gt[0]\n",
        "      predicted_box2 = gt[0]\n",
        "      start = time.time()\n",
        "      for f in range(len(frames) - start_frame):\n",
        "        img = cv2.imread(frames[f])\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        predicted_bbox=predict(model,img,predicted_box)\n",
        "        #predicted_bbox2 = predict(model, img,predicted_bbox) if we want to compare 2 models\n",
        "        boxes_m1.append(predicted_box)\n",
        "        #boxes_m2.append(predicted_bbox)\n",
        "      end = time.time()\n",
        "      time_perframe = (start-end)/len(frames)\n",
        "      all_boxes.append(boxes_m1)\n",
        "      time_perframe_for_each_video.append(time_perframe)\n",
        "    return all_boxes, all_gt , time_perframe_for_each_video\n",
        "\n",
        "\n",
        "\n",
        "all_boxes, all_gt , time_perframe_for_each_video = test_metrics(model , adnet_model)\n",
        "print (all_boxes)\n",
        "print(all_gt)"
      ],
      "metadata": {
        "id": "DhMMozN6J64i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9712yCAxLmtI"
      },
      "source": [
        "# TESTING & DEBUGGING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Me8c91RVoLvD"
      },
      "outputs": [],
      "source": [
        "# Update this with the appropriate dataset\n",
        "TEST_IMAGE_PATH = \"adnet_datasets/OTB/Couple/img/0082.jpg\"\n",
        "TEST_BBOX = get_ground_truths(\"adnet_datasets/OTB/Couple/groundtruth_rect.txt\")[82]\n",
        "TEST_IMAGE = cv2.imread(TEST_IMAGE_PATH)\n",
        "\n",
        "\n",
        "# Update the following two vars\n",
        "src_bbox = np.array([143, 131, 34, 87]) \n",
        "pred_bbox = np.array([138, 41, 32, 89])\n",
        "print(plotNpImageBBoxes(TEST_IMAGE, src_bbox, TEST_BBOX, pred_bbox))\n",
        "\n",
        "\n",
        "print(\"IOU: {0}\".format(calculate_IOU(pred_bbox, src_bbox)))\n",
        "\n",
        "print(\"Test bbox is: {0}\".format(TEST_BBOX))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzbeopDmi6q_"
      },
      "outputs": [],
      "source": [
        "# VERTICAL MOVEMENT TESTING \n",
        "TEST_IMAGE_PATH = \"adnet_datasets/OTB/Skater2/img/0005.jpg\"\n",
        "TEST_BBOX = get_ground_truths(\"adnet_datasets/OTB/Skater2/groundtruth_rect.txt\")[4]\n",
        "TEST_IMAGE = cv2.imread(TEST_IMAGE_PATH)\n",
        "\n",
        "# Test move down\n",
        "print(\"Down-shifted bounding box\")\n",
        "bbox = move2(img, TEST_BBOX, \"down\")\n",
        "print(plotNpImageBBox(img, bbox))\n",
        "\n",
        "print(\"Down-shifted bounding box\")\n",
        "bbox = move2(img, bbox, \"down\")\n",
        "print(plotNpImageBBox(img, bbox))\n",
        "\n",
        "print(\"Down-shifted bounding box\")\n",
        "bbox = move2(img, bbox, \"down\")\n",
        "print(plotNpImageBBox(img, bbox))\n",
        "\n",
        "print(\"Down-shifted bounding box\")\n",
        "bbox = move2(img, bbox, \"down\")\n",
        "print(plotNpImageBBox(img, bbox))\n",
        "\n",
        "\n",
        "print(\"Down-shifted bounding box\")\n",
        "bbox = move2(img, bbox, \"down\")\n",
        "print(plotNpImageBBox(img, bbox))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNBblMU8d4qh"
      },
      "outputs": [],
      "source": [
        "# HORIZONTAL MOVEMENT TESTING \n",
        "TEST_IMAGE_PATH = \"adnet_datasets/OTB/Skater2/img/0005.jpg\"\n",
        "TEST_BBOX = get_ground_truths(\"adnet_datasets/OTB/Skater2/groundtruth_rect.txt\")[4]\n",
        "TEST_IMAGE = cv2.imread(TEST_IMAGE_PATH)\n",
        "\n",
        "img, bbox = TEST_IMAGE, TEST_BBOX\n",
        "print(\"Original bounding box\")\n",
        "print(plotNpImageBBox(img, TEST_BBOX))\n",
        "\n",
        "# Test move left\n",
        "print(\"Left-shifted bounding box\")\n",
        "bbox = move2(img, TEST_BBOX, \"left\")\n",
        "print(plotNpImageBBox(img, bbox))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1MXfEC2IDNk"
      },
      "outputs": [],
      "source": [
        "# MOVEMENT TEST\n",
        "\n",
        "print(\"IOU between {1} and {2} is {0}\".format(calculate_IOU(np.array([143, 131,  34,  87]), np.array([138,  41,  32,  89])), [143, 131,  34,  87], [138,  41,  32,  89]))\n",
        "\n",
        "for i in range(11):\n",
        "  print(selectAction(np.zeros([300, 300, 3]), np.array([252, 65, 25, 30]), i))\n",
        "\n",
        "print(selectAction(np.zeros([300, 300, 3]), np.array([131,7,117,168]), 5))\n",
        "print(\"The following UP should do nothing because 0.03 * 168 * 2 is too large\")\n",
        "print(selectAction(np.zeros([300, 300, 3]), np.array([131,7,117,168]), 5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1j-Ud5nXofHE"
      },
      "outputs": [],
      "source": [
        "print(selectAction(np.zeros([450, 450, 3]), np.array([315,  0, 32,  35]), 5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBBRcPEAohhe"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "safe_reinforce-kaan.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}